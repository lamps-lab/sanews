{
    "19": {
        "gold_standard": [
            "Interestingly, unlike milk, when the dairy product was fermented, like in yoghurt, the results were reversed. The participants who consumed more yoghurt showed a decreased risk of experiencing bone fractures. Michaelsson told BBC News that the difference could be down to the sugars that are found in milk - lactose and galactose. Both have been shown to accelerate ageing processes such as inflammation and oxidative stress in previous research using animals.While the study involved a good amount of participants and was conducted over a relatively long period of time, the researchers are careful to point out that they're not ready to draw causal conclusions just yet. Something they want to look at in the future is if alcohol consumption and weight could have had an effect on the results.\"As milk features in many dietary guidelines and both hip fractures and cardiovascular disease are relatively common among older people, improving the evidence base for dietary recommendations could have substantial benefits for everyone,\" epidemiologist Mary Schooling from the City University of New York in the US, wrote in an accompanying editorial in the BMJ",
            "We've been brought up to think that drinking milk is good for our bones, but new research suggests that not only is this false, but the sugars in it may actually be accelerating the ageing process.\nA research team from Uppsala University in Sweden has found that women who drink more than three glasses of milk per day were more likely to break their bones than women who drank less.\u00a0This finding was part of a study conducted on more than 100,000 people in Sweden, based on how much dairy they habitually consumed. The researchers monitored the diets of 61,400 women between 1987 and 1990 and 45,300 men through 1997 by asking them to fill out questionaries on how often they ate common dairy products such as milk, cheese, and yoghurt. The health of the female participants was monitored for 20 years after the questionnaires, and for 11 years afterwards for the males.\u00a0Publishing their results in the BMJ, the team says that in women, high milk intake led to a greater risk of bone fracture, and in both men and women, it was associated with a higher mortality rate.\"Women who drank three or more glasses a day had twice the chance of dying at the end of the study than those who drank less than one glass a day,\" lead researcher Karl Michaelsson, a professor in medical epidemiology at Uppsala University, told BBC News. \"And those who had a high milk intake also had a 50 percent higher risk of hip fracture."
        ]
    },
    "37": {
        "gold_standard": [
            "A new study suggests that playing music is instrumental to being able to smoothly switch between tasks - even more so than learning another language.In psychology, the term 'task switching' describes the ability to quickly shift your attention between two tasks. Previous studies have suggested that there are many benefits to playing a musical instrument or being bilingual, including enriching mental development and better cognitive function  published in the journal Cognitive Science"
        ]
    },
    "66": {
        "gold_standard": [
            "published in the journal Hepatolog published in the journal Hepatology Scientists have discovered that chemical compounds present in coffee - both regular and decaffeinated - can help to protect your liver.Previous research has suggested that coffee has many health benefits, including providing support to the liver and preventing it from developing cancer. However, until now, it remained unclear whether these potential benefits extended to decaffeinated coffee Researchers from the National Cancer Institute in the US have reported in a study published in the journal Hepatology, that higher coffee consumption prevents the liver from abnormal enzymes - whether it's decaffeinated or notThe researchers used data from the US National Health and Nutrition Examination Survey that recorded the coffee-drinking habits of 27,793 participants. The team measured blood levels of four enzymes, including aminotransferase (ALT), aminotransferase (AST), alkaline phosphatase (ALP) and gamma glutamyl transaminase (GGT), that indicate the health of an individual's liver.\u00a0The results indicated that participants who consumed three or more cups of coffee a day, were about 25 percent less likely to have abnormal liver enzyme levels, compared to those who don't drink coffee.\u00a0Interestingly, the researchers found similarly low enzyme levels in participants who consume decaffeinated coffee, indicating that the unique ingredient that promotes liver health is in the coffee, not the caffeine. The chemical compound behind this effect is not yet known, and further research is required to identify the reaso reason behind the fascinating result"
        ]
    },
    "98": {
        "gold_standard": [
            "Scientists have found that discarded cigarette ash can cheaply and easily remove more than 96 percent of poisonous arsenic from water.As a result of mining and other industries, the toxin arsenic has contaminated groundwater at high levels in countries such as China, Chile, Hungary and Mexico. The poison is odourless and tasteless so it's hard to detect, but it can cause skin discolouration, stomach pain, partial paralysis and a range of other serious health problems A team of researchers, led by Jiaxing Li from the North China Electrical Power University in Beijing, decided to investigate whether porous cigarette ash might do a better job.The scientists coated cigarette ash in aluminium oxide, a simple, one-step method, and then tested it on contaminated ground water. They found the material removed more than 96 percent of the arsenic, reducing it to a safe level according to the World Health Organisation standards where they published their results",
            "EurekAlert Scientists have found that discarded cigarette ash can cheaply and easily remove more than 96 percent of poisonous arsenic from water.As a result of mining and other industries, the toxin arsenic has contaminated groundwater at high levels in countries such as China, Chile, Hungary and Mexico. The poison is odourless and tasteless so it's hard to detect, but it can cause skin discolouration, stomach pain, partial paralysis and a range of other serious health problems Technology already exists to help eliminate arsenic from water, but it's expensive and requires a high level of expertise, which makes it impractical for use in rural and developing regions.Scientists have already started trying to use natural waste materials, such as banana peels, to clean up arsenic, but so far most projects have proved ineffective"
        ]
    },
    "155": {
        "gold_standard": [
            "Advanced Materials We could soon be able to convert more of the Sun's energy into power using fewer solar panels, thanks to a new breakthrough by Swinburne University of Technology researchers in Australi Working with researchers from Nankai University in China, the team has managed to enhance the efficiency of silicon solar cells by 3.8 percent - almost five times more than the current record.\"One of the critical challenges the solar cell faces is low energy conversion efficiency due to insufficient absorption from the thin silicon layer, To achieve the impressive upgrade, the engineers synthesised one-dimensional graphenised carbon nanofibre, and used it to help solar cells capture sunlight more efficiently.\"This nanofibre exhibits superior light-scattering properties, ultralow absorption loss and high electrical conductivity, By integrating the nanofibres with solar cells, the team have demonstrated one of the highest-performing silicon thin-film solar cells in existence.\nThe nanofibres are also extremely cheap to make and can be adapted to be used in a range of technology, such as photodetectors, supercapacitors and biosensors, as well as solar cells"
        ]
    },
    "185": {
        "gold_standard": [
            "published in Angewandte Chemie. Plastic is notoriously difficult to get rid of - it's toxic to melt or burn and when left to its own devices in landfill, can hang around for hundreds of years.\u00a0Now scientists have developed a new type of plastic that breaks down upon exposure to light, and, impressively, degrades fully within just three hours To make the plastics, the researchers from North Dakota State University in the US created a solution from fructose, a sugar found in fruit, and molecules that can absorb light known as phototriggers. They then heated this solution to make long, repeating chains that formed solid, pale brown plastic when cooled.As soon as this plastic was exposed to ultraviolet light at 350 nanometres wavelength (the Sun gives off light ranging from around 290 nanometres to 3,200 nonametres) the light-absorbing molecules broke off from the chains and the plastics started to degrad.\u00a0\"In a proof-of-concept experiment, the new plastics dissolved into a clear solution after being exposed to ultraviolet light for three hours, indicating that they were completely reduced to their soluble building-block molecules,\" writes XiaoZhi Lim for Science.These building blocks can then be fully recovered and recycled to make new plastic"
        ]
    },
    "230": {
        "gold_standard": [
            "published in the journal Environmental Science and Technology. Furniture and textiles are often coated with flame-retardants\u00a0- chemicals that help products meet fire safety standards. These chemicals have been previously confirmed toxic, but a new study has revealed what happens when they come into contact with humans - and it isn't pretty.\nTo investigate the affect of flame-retardants on humans, researchers from the Silent Spring Institute in the US tested the urine samples of 16 California residents. The team detected biomarkers of six chemicals that are commonly found in flame-retardants, including a carcinogen called TCEP that's never before been seen in humans. Not only can TCEP increase the risk of a person developing cancerous tumours, it can also harm the nervous and reproductive systems - and it was found in 75 percent of the participants.\u00a0The team also detected another carcinogen called TDCIPP. This chemical was banned from children's pyjamas in the 1970's, but it's still being added to furniture.\"We found that several toxic flame-retardants are in people's bodies,\" said Robin Dodson, environmental scientist and lead researcher, in a press release. \"When you sit on your couch, you want to relax, not get exposed to chemicals that may cause cancer. Some flame-retardants have been targeted for phase out, but unfortunately there are others that have largely been under the radar.\"But it's not all bad news. You can reduce your exposure to these nasty chemicals by opting to buy furniture free of toxic flame-retardants. The other thing that the team suggests is to try and keep your home dust-free, as these chemicals love flying into the air and collecting in dust particles.The findings are published in the journal Environmental Science and Technology"
        ]
    },
    "265": {
        "gold_standard": [
            "The debate over how violence in video games, films and television correlates to a higher rate of violence in society has been raging since the 1920s, and it's only gotten more heated with the increase of mass shootings in the US. But a new study by clinical psychologist Christopher Ferguson from Stetson University in the US has shown that across several decades, there have been no significant links between the consumption of media violence and instances of societal violence In the past, researchers have investigated this issue by conducting lab experiments that test the aggression levels of people playing violent video games and watching violent films. But Ferguson argues that these lab tests aren't helpful, as they don't accurately mirror what goes on in real-life. So he decided to take a look across several recent decades to see if he could spot any trends.First off, Ferguson analysed the instances of movie violence and actual homicide rates between the years of 1920 and 2005. He used independent rating experts to evaluate the frequency and level of violence in the most popular movies released during these decades and then correlated the data to homicide rates in corresponding years No link could be made, he found, except perhaps in the mid-20th century.At this point in history, homicide rates and instances of violent movies both increased briefly, but then the trend reversed after 1990, to the point where movie violence became correlated with fewer homicides. This was also the case during the two decades between the 1920s and '40s.\u00a0Next, Ferguson investigated the consumption of violent video games and and the rates of youth violence from 1996 to 2011. Independent ratings experts from the US Entertainment Software Ratings Board (ESRB) were used to quantify the frequency and level of violence in popular video games between these years and the data were correlated against federal information on the rate of youth violence at the time published in the  While the data did appear to show a link between an increase in violent video game consumption and a decrease in youth violence, just as it did for films after 1990, Ferguson is not prepared to say the result is anything other than a coincidence. But what he can say for sure is that while media violence is definitely being consumed more now than ever before, there is absolutely no clear evidence to link media violence with societal violence.The results have been published in the Journal of Communication.\u00a0\"Society has a limited amount of resources and attention to devote to the problem of reducing crime. There is a risk that identifying the wrong problem, such as media violence, may distract society from more pressing concerns such as poverty, education and vocational disparities and mental health,\" Ferguson said in a press release. \"This research may help society focus on issues that really matter and avoid devoting unnecessary resources to the pursuit of moral agendas with little practical value.\"Which is basically the polite way of saying \"everyone shut up and find something that's actually real to fret about."
        ]
    },
    "282": {
        "gold_standard": [
            "published in the current issue of  French researchers have pinpointed a genetic mutation that has resulted in two men showing no symptoms or clinical traces of HIV, despite being infected by the virus for at least three years.\nThey've found that, in both patients, the HIV virus was shut down as a result of its genetic code being altered - something they believe was triggered by the activation of a group of enzymes known as APOBEC enzymes.The research suggests that by activating these enzymes in other patients, we may be able to disable the AIDS-causing virus even after someone's already been infected. In fact, it's one of the first potential \"cures\" put forward that would result in a patient remaining infected by HIV.The scientists were so fascinated by the two patients because neither had developed any symptoms, despite being infected with HIV for years. One of the men had been diagnosed as HIV positive 30 years ago, and the other was diagnosed in 2011. But despite that, the virus was present in such low levels that it could not be detected in routine blood tests, and it also wasn't causing them any symptoms or ill health.The researchers from France's Institute of Health and Medical Research believe that these two patients are not unique, and their lack of symptoms are a result of an evolutionary shift between some humans and the virus - a spontaneous phenomenon known as endogenisation.\nTheir results are published in the current issue of Clinical Microbiology and Infection.In the paper they explain that it's well known that around 1 percent of people infected with HIV are naturally able to keep the virus at clinically undetectable level.\u00a0However, no one quite knew what this genetic mechanism was until now.To work out what was going on, the researchers used deep sequencing to track down\u00a0the small amounts of HIV DNA that were present in the patients' cells (when a HIV virus infects a human cell, it translates its viral RNA into DNA and inserts itself into our genome).They then studied the chunk of viral genetic code, as well as the infected human genome, to work out what was making HIV harmless in both of the men and stopping it from replicating itself.What they found was that the genetic code that usually stops the human cell from expressing the APOBEC enzymes had been altered.\nThis alteration had resulted in the APOBEC enzymes being expressed and going on to cause further mutations in the HIV's genome - changes that effectively stopped it from replicating and spreading throughout the body.\"This finding represents an avenue for a cure,\" biologist Didier Raoult, co-author of the study, told AFP.Fascinatingly, this cure would be completely different to anything tried before because, instead of trying to eradicate HIV from the body, it suggests that someone needs to actually remain infected by the virus to be cured.\"The work opens up therapeutic avenues for a cure, using or stimulating this enzyme, and avenues for identifying individuals among newly infected patients who have a chance of a spontaneous cure,\" the authors told International Business Times.\"We suggest that persistence of integrated HIV DNA is not a barrier, but on the contrary, may be a prerequisite to HIV cure."
        ]
    },
    "330": {
        "gold_standard": [
            "If you've ever been unlucky enough to find them hiding in your mattress, or underneath your pillow, you know the headaches that can arise from an infestation of bedbugs.The common bedbug (Cimex lectularius) is a small, flat parasitic insect that feeds primarily on human blood\u2026 while we're sleeping.\nImmunity to pesticides has allowed these insects to make a strong recovery in the developed world in recent decades, and has led to an increase in infestations. \u00a0\u00a0Althoughthe bites don't necessarily hurt, they can lead to skin irritations from scratching, psychological distress, and in some cases, severe allergic reactions. Furthermore, getting rid of bed bugs can be a nightmarish process involving costly fumigation bills. \u00a0There has been lots of research\u00a0into the early detection of bed bugs, and several groups are working on developing traps baited with pheromones. Pheromones are chemicals produced by animals that trigger a behavioural response from animals of the same species. For instance, they might indicate where an animal can find food, or shelter.\u00a0The problem with bed bugs is that the appropriate chemicals have been hard to identify, specifically, the chemical that bedbugs use to communicate that a particular habitat is safe.\nNow, thanks to a scientist who was willing to sacrifice her own skin for the greater good, researchers at Simon Fraser University (SFU) in British Columbia, Canada, have uncovered that compound, and in doing so, have taken a big step toward developing a pheromone trap for these pesky parasites. \u00a0In a research project few would envy, biologist Regine Gries allowed bed bugs to feast on her blood, enduring thousands of bites each week for five years. In total, it's estimated she has been bitten more than 180,000 times. Watch the CBC news report.Regine agreed to play host for her biologist husband, Gerhard Gries, because her skin was only minimally affected by the bedbug bites. It may seem like a high price to pay (for love or for science), but it could soon be worth it.\u00a0The couple, along with chemist Robert Britton, and a team of SFU students, found that bedbugs release very small amounts of histamine in their faeces and in the skin they shed after feeding.\nResearchers say the presence of histamine signals to bedbugs that a given shelter is safe, and keeps them stationary regardless of whether they've recently fed on human blood.In addition to histamine, the team has identified and synthesised five other chemical components needed to lure bed bugs into traps.\u00a0Testing the response of the bugs to each potential pheromone, however, meant collecting an enormous amount of shed skin and faeces, which required a lot of feeding \u2013 hence, the feasted-upon-forearm of Regine Gries.After a series of successful trials in bedbug-infested apartments in Metro Vancouver, the team has this month published their research in the chemistry journal Angewandte Chemie.Kenneth Haynes, an entomologist at the University of Kentucky, told Chemical & Engineering News this study could be the basis of \"the breakthrough that is required to deal with this difficult pest\".The researchers are now working with Canadian company Contech Enterprises and expect an affordable commercial trap to be available next year"
        ]
    },
    "403": {
        "gold_standard": [
            "There has been significant interest in high-entropy alloys of late, and according to a review of them earlier this year in the journal Materials Research Letters, their unique set of properties mean they can be used as \"hydrogen storage materials, radiation resistant materials, diffusion barriers for electronics, precision resistors, electromagnetic shielding materials, soft magnetic materials, thermoelectric materials, and anti-bacterial materials\", to name just a few.The main challenge in getting this new alloy to the market is the fact that it's made of 20 percent scandium, which is an extremely expensive materia",
            "( Ashby plot of strength vs. density for engineering materials. Credit: Elsevier 2010 / Khaled M. Youssef et. al.) An international team of researchers has developed a new metal alloy that has a higher strength-to-weight ratio than any other known metal material on the planet.The team, from North Carolina State University in the US and Qatar University, combined lithium, magnesium, titanium, aluminium and scandium to make a nanocrystalline alloy that has low density, but extremely high strength.\nThe strength-to-weight ratio - also known as specific strength - relates to how long a piece of the material can be to suspend its own weight when held up vertically and supported only at the top. Strong but light, high specific strength metals such as titanium, aluminium, and magnesium are often used in aerospace design, where any increase in weight is a major concern. \"The density is comparable to aluminum, but it is stronger than titanium alloys,\" lead researcher and materials science and engineering professor at North Carolina State University, Carl Koch,\u00a0said in a press release.\u00a0\"It has a combination of high strength and low density that is, as far as we can tell, unmatched by any other metallic material. The strength-to-weight ratio is comparable to some ceramics, but we think it's tougher - less brittle - than ceramics,\" says Koch.\u00a0The new material is also a high-entropy alloy - a recently-developed class of material that includes equal amounts of five or more types of metals. There has been significant interest in high-entropy alloys of late, and according to a review of them earlier this year in the journal Materials Research Letters, their unique set of properties mean they can be used as \"hydrogen storage materials, radiation resistant materials, diffusion barriers for electronics, precision resistors, electromagnetic shielding materials, soft magnetic materials, thermoelectric materials, and anti-bacterial materials\", to name just a few.The main challenge in getting this new alloy to the market is the fact that it's made of 20 percent scandium, which is an extremely expensive material. \"We still have a lot of research to do to fully characterise this material and explore the best processing methods for it,\" Koch said. \"One thing we'll be looking at is whether scandium can be replaced or eliminated from the alloy.\"The results have been published in the current editon of Materials Research Letters"
        ]
    },
    "474": {
        "gold_standard": [
            "published in the Journal of Vertebrate Paleontology The myth of the dragon that began in ancient China was very likely inspired by the inadvertent discovery of dinosaur fossils. \u00a0But perhaps it took a super-sized dinosaur skeleton - with a freakishly long neck - to really get the myth kick-started.\nThis is the suggestion of a team of palaeontologists from the University of Alberta in Canada, who recently discovered a new species of sauropod dinosaur whose enormously long neck (7.5-metres-long) was half the length of its body.\u00a0The fossil was uncovered by construction workers in 2006 at a build site near Quijiang City in southern China. It included a large neck vertebra, and importantly, the head was still attached, which researchers said was quite rare. \u00a0The dinosaur has since been named Qijianglong, which translates to \"Dragon of Qijiang.\"\u00a0\"China is home to the ancient myths of dragons,\" said PhD student Tetsuto Miyashita in a statement . \u00a0\"I wonder if the ancient Chinese stumbled upon a skeleton of a long-necked dinosaur like Qijianglong and pictured that mythical creature.\"\nMost sauropod dinosaurs had necks that were about one-third the length of their body, but a select few belonging to the Mamenchisauridae family\u00a0had necks that could grow up to half their body's length. \u00a0Interestingly, all of these dinosaurs have been found in Asia.\u00a0\"It is still a mystery why Mamenchisaurids did not migrate to other continents,\" said Miyashita in the press release. \"It is possible that the dinosaurs were once isolated as a result of a large barrier such as a sea, and lost in competition with invading species when the land connection was restored later.\"Qijianglong was a herbivore that lived about 160 million years ago in the Late Jurassic period and was about 15-metres-long. (As a reference point, an average city bus is about 12-metres-long).Of course, having a 7.5-metre-long neck could cause certain issues with balance and mobility.\nThe researchers say the dinosaur was able to avoid being too top-heavy due to an evolutionary feature whereby its vertebrae \"were filled with air, making their necks relatively lightweight.\"\u00a0But their mobility would have still been limited.\u00a0According to the press release, the dinosaur had interlocking joints between the vertebrae, which \"indicate a surprisingly stiff neck that was much more mobile bending vertically than sideways, similar to a construction crane.\"The University of Alberta team has described its newly discovered species in a paper published in the Journal of Vertebrate Paleontolog"
        ]
    },
    "492": {
        "gold_standard": [
            "(Vibrational bonding of the lightest isotopomer BrMuBr. Credit: Flemming et. al.) It's taken decades to nail down, but researchers in Canada have finally identified a new chemical bond, which they're calling a 'vibrational bond'.This vibrational bond seems to break the law of chemistry that states if you increase the temperature, the rate of reaction will speed up. Back in 1989, a team from the University of British Columbia investigated the reactions of various elements to muonium (Mu) - a strange, hydrogen isotope made up of an antimuon and an electron. They tried chlorine and fluorine with muonium, and as they increased the heat, the reaction time sped up, but when they tried bromine (br), a brownish-red toxic and corrosive liquid, the reaction time sped up as the temperature decreased. The researchers, Amy Nordrum writes for Scientific American, \"were flummoxed\".\nPerhaps, thought one of the team, chemist Donald Flemming, when the bromine and muonium made contact, they formed a transitional structure made up of a lightweight atom flanked by two heavier atoms. And the structure was joined not by van der Waal's forces - as would usually be expected - but by some kind of temporary 'vibrational' bond that had been proposed several years earlier.Nordrum explains:\"In this scenario, the lightweight muonium atom would move rapidly between two heavy bromine atoms, 'like a Ping Pong ball bouncing between two bowling balls,' Fleming says. The oscillating atom would briefly hold the two bromine atoms together and reduce the overall energy, and therefore speed, of the reaction.\"But back then, the team didn't have the technology needed to actually see this reaction take place, because it lasts for just a few milliseconds. But now they do, and the team took their investigation to the nuclear accelerator at Rutherford Appleton Laboratory in England.\nWith the help of theoretical chemists from the Free University of Berlin and Saitama University in Japan, Flemming's team watched as the light muonium and heavy bromine formed a temporary bond. \"The lightest isotopomer, BrMuBr, with Mu the muonium atom, alone exhibits vibrational bonding in accord with its possible observation in a recent experiment on the Mu + Br2 reaction,\" the team reports in the journal Angewandte Chemie International Edition.\u00a0\"Accordingly, BrMuBr is stabilised at the saddle point of the potential energy surface due to a net decrease in vibrational zero point energy that overcompensates the increase in potential energy.\"\u00a0In other words, the vibration in the bond decreased the total energy of the BrMuBr structure, which means that even when the temperature was increased, there was not enough energy to see an increase in the reaction time.\u00a0While the team only witnessed the vibrational bond occurring in a bromine and muonium reaction, they suspect it can also be found in interactions between lightweight and heavy atoms, where van der Waal's forces are assumed to be at play.\"The work confirms that vibrational bonds - fleeting though they may be - should be added to the list of known chemical bonds,\" says Nordrum at Scientific American.Sorry, future high school chemistry students, here's another thing you'll probably have to rote lear"
        ]
    },
    "493": {
        "gold_standard": [
            "Led by Joshua Lambert, associate professor of food science and co-director of Pennsylvania State University's Centre for Plant and Mushroom Foods for Health, researchers have watched as the compound epigallocatechin-3-gallate (EGCG) - the most abundant antioxidant in green tea - triggers a cycle of damage in the mitochondria of cancer cells, which essentially causes them to disintegrate from the inside-out.\n\"EGCG is doing something to damage the mitochondria and that mitochondrial damage sets up a cycle causing more damage, and it spirals out, until the cell undergoes programmed cell death,\" says Lambert in a press release. \"It looks like EGCG causes the formation of reactive oxygen species in cancer cells, which damages the mitochondria, and the mitochondria responds by making more reactive oxygen species.\"These reactive oxygen species - also known as free radicals - are oxygen-containing molecules that, if allowed to accumulate in numbers that overwhelm the cell's antioxidant defence, will cause oxidative stress. If left untreated, oxidative stress can damage all components of the cell, including the proteins, lipids, and DNA, and lead to the development of all kinds of devastating diseases including cancer, Parkinson's and Alzheimer's disease, infections, and chronic fatigue syndrome.\u00a0While the cancer cell is undergoing oxidative stress thanks to the green tea compound EGCG, the researchers found that the damage to the mitochondria grows progressively worse. While at the same time, the cell's expression of its antioxidant genes - which are supposed to fight the reactive oxygen species - is reduced. This means the cancer cell is switching off its main defence mechanism while EGCG is further weakening it with oxidative stress.And curiously, the devastating effects on cancer cells were not seen in normal, healthy cells. Quite the opposite - the researchers found that the compound actually increased what's known as the mitochondrial membrane potential, which is essential for a healthy metabolism within the cell.\nThe team figured this out by growing normal, healthy cells and oral cancer cells in petri dishes, and then exposing them to EGCG. They say the amount they used was equivalent to how much would end up in your saliva after chewing green-tea gum. The cells were then periodically monitored for oxidative stress and signs of defensive antioxidant response.\u00a0Through this process, they identified the protein sirtuin 3 (SIRT3), as playing a crucial role in the process. \"It plays an important role in mitochondrial function and in antioxidant response in lots of tissues in the body, so the idea that EGCG might selectively affect the activity of sirtuin 3 in cancer cells - to turn it off - and in normal cells - to turn it on - is probably applicable in multiple kinds of cancers,\" said Lambert.While EGCG significantly reduced protein and messenger RNA levels - the molecules that carry DNA codes in the cell's nucleus to sites of protein synthesis - of SIRT3 in oral cancer cells, the researchers found that it had no effect on the SIRT3 expression in normal cells.\u00a0The team published their results in the online issue of Molecular Nutrition and Food Research. Lambert says the results tie in to previous findings of separate studied, where green tea compounds have been shown to treat and prevent oral cancer in animal studies.\nIn 2014, it was estimated that 42,440 new cases and 8,390 deaths from oral cancer will occur in the US this year. Smokers are the most vulnerable group, because tobacco is known to induce genetic changes that irreversibly increase the risk of developing the disease.\u00a0The team would now like to do their own studies on animals in the lab, to see if the effects they observed in the petri dishes can be replicated in a living creature.\u00a0\"The problem with a lot of chemotherapy drugs - especially early chemotherapy drugs - is that they really just target rapidly dividing cells, so cancer divides rapidly, but so do cells in your hair follicles and cells in your intestines, so you have a lot of side effects,\" said Lambert. \"But you don't see these sorts of side effects with green tea consumption."
        ]
    },
    "513": {
        "gold_standard": [
            "Australian and US chemists have figured out how to unboil a hen's egg, in an effort to figure out what to do with the masses of valuable molecular proteins that could be used for many different applications in the biotechnology industry, if it weren't for their tendency to frequently 'misfold' themselves into useless shapes.\n\"Yes, we have invented a way to unboil a hen egg,\" said one of the team, Gregory Weiss, a professor of chemistry and molecular biology and biochemistry at the University of California, Irvine, in a press release. \"In our paper, we describe a device for pulling apart tangled proteins and allowing them to refold. We start with egg whites boiled for 20 minutes at 90 degrees Celsius and return a key protein in the egg to working order.\"The secret, says Mary Beth Griggs at Popular Science, was adding urea - yes, the stuff that's passed out of your body via urine, formed due to the breakdown of proteins - to the boiled eggs. This saw the knotted proteins break down into pieces, and the solid, cooked eggs restored to a clear, liquid protein known as lysozyme. This liquid egg was then processed using a special piece of equipment at Flinders University in South Australia known as a vortex fluid device, which untangled and re-joined the pieces together in a matter of minutes.\u00a0\"It's not so much that we're interested in processing the eggs; that's just demonstrating how powerful this process is. The real problem is there are lots of cases of gummy proteins that you spend way too much time scraping off your test tubes, and you want some means of recovering that material,\" says Weiss.\u00a0Publishing in the journal ChemBioChem, the team says this new method of protein detangling is a vast improvement on current techniques, which can take up to four days to complete. Taking mere minutes, Weiss says, their technique \"speeds things up by a factor of thousands\".This could solve a problem I was not aware of - pharmaceutical companies commonly produce cancer antibodies for treatment using hamster ovary cells, which are expensive, but valuable, as they don't often misfold proteins. The same goes for industrial cheese makers and farmers who need these kinds of proteins to drive the fermentation process. Using this new technique, scientists could instead use proteins extracted super-cheaply from yeast and E. coli bacteria and restore them to a useable form"
        ]
    },
    "515": {
        "gold_standard": [
            "In an experiment that could nearly double the rate of solar energy conversion from 32 to 60 percent, scientists in Switzerland have used the super-material graphene to convert a single photon into many electrons to produce an electric current.\nThe team, from the Swiss \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), demonstrates how graphene could join cadmium telluride, copper indium gallium selenide/sulphide, and various silicon structures as one of the few known photovoltaic materials - high-efficiency, solar energy-producing materials.\u00a0They achieved this by placing a sample of graphene - a thin layer of pure carbon that's around 100 times stronger than steel and a very efficient heat and electricity conductor - into an ultra-high vacuum chamber. The graphene they used was 'doped', which means electrons were added or subtracted chemically before the experiment.\u00a0The graphene was then blasted with a super-fast pulse of laser light, which 'excites' the electrons floating around in the graphene and puts the whole material into a higher energy state than before the laser blast. In this state, says Michael Byrne at Motherboard, an excited - or 'hot' - electron might \"pop loose from its atomic home\", and when it very quickly falls back into its regular state of energy, it excites an average of two more electrons as a knock-on effect. This phenomenon can then be conducted as an electric current and used for power, and it all happens in a matter of femtoseconds, so a few quadrillionths of a second.The team observed this phenomenon for the first time by recording the energy of each electron at different points in time, over and over again, like \"a kind of stop-motion movie of the conversion process\", says Dexter Johnson at IEEE Spectrum.\n\"This indicates that a photovoltaic device using doped graphene could show significant efficiency in converting light to electricity,\" one of the team, materials scientist Marco Grioni, said in a press release.The amount of energy you need to force an electron free depends on the material you're using. If the amount of energy you need to achieve this phenomenon is too great, the material will be considered inefficient, because the leftovers will end up as wasted heat energy. But this new technique, known as carrier multiplication, uses that leftover energy to 'pop loose' more electrons so they can be harvested for power.The results have been published in Nano Letters.It's pretty exciting stuff, because graphene is even better at conducting electricity than copper. But there's one big problem - graphene isn't great at absorbing light, which is pretty crucial if you want to make solar panels and the like out of it"
        ]
    },
    "530": {
        "gold_standard": [
            "A team of engineers and clinicians has, for the first time, tested the performance of drug-delivering micro-motors inside a living creature.\u00a0An artificial micro-motor made from polymers coated in zinc, and carrying gold nanoparticles, was developed by the team and tested inside a mouse with encouraging results, which were\u00a0described in the journal ACS Nano.\n\"Most previously reported self-propelled motors rely on non-biocompatible chemical fuels such as hydrogen peroxide,\" lead author Wei Gao\u00a0from the University of California, Berkeley told New Scientist. Importantly, their micro-motor is self-propelled using stomach acid.\u00a0\"We demonstrated that the acid-driven propulsion in the stomach effectively enhances the binding and retention of the motor, as well as the cargo payload [drugs] on the stomach wall,\" the team wrote.They say the work could \"significantly advance\" the emerging field of micromotors, and \"open the door to in vivo evaluation and clinical applications of these synthetic motors.\" \u00a0The development of small-scale synthetic motors, or nano-robots, as some people have referred to them, has advanced significantly over the past decade. It is expected that these tiny motors will improve drug delivery and disease diagnosis, and possibly enable nano-surgery.\nVarious types of synthetic motors, using different propulsion mechanisms, have previously been made to operate inside biological fluids. But the University of California researchers say the performance of these motors has only ever been tested outside of the body. \u00a0The believe their zinc-based motors hold \"great promise\" for use inside the body - particularly for gastric drug delivery - due to several important features. In addition to being self-propelled by stomach acid, they can be loaded up with relatively large payloads of drugs, which they can auonomously release, and when their job is done they simply self-destruct, dissolving in the gastric acid and leaving nothing toxic behind.\u00a0The motors are polymer tubes - about 20 micrometres long, or about the width of a human hair - lined with zinc. Inside the stomach, the zinc reacts with gastric acid producing hydrogen bubbles, which propels the motors into the organ's tissue.\u00a0The team applied its zinc-based motor to the stomach of living mice via something called gavage administration, which means they essentially force-fed them through tubes. In order to test the importance of their motor's propulsion, they administered a control to another set of mice - a similarly constructed micro-motor unable to move in the stomach.\nThey ensured the mice had fasted overnight, to avoid any unwanted influence of food on the mobility, or performance of their motor.\u00a0Two hours after the motors were ingested, the mice were killed and the inside of their stomachs were examined. The zinc-based motors were far more effective at penetrating and staying put inside the thin layer of mucus protecting the stomach tissue.\u00a0The researchers suggest this is because the tube-shaped motors are actively propelled, almost like small missiles, and therefore they are more likely to get trapped in the stomach lining - which is the end goal.\u00a0The researchers also tested the release of a \"cargo\" - in this case, gold nanoparticles, which are commonly used as imaging agents and drug carriers.They said the gold nanoparticle-loaded motors did not affect the propulsion ability. They also found that when loaded onto their zinc-based motor, the retention of gold nanoparticles in the stomach tissue was three times greater than when it was administered orally.\nBradley Nelson at the Swiss Federal Institute of Technology in Zurich told New Scientist\u00a0that more evidence was needed to prove the design was responsible for the higher retention of gold nanoparticles.\"From the description of the experiments performed, the micromotors move randomly and some appear to diffuse more rapidly into the mucosal lining,\" he said. \"The mechanism of enhanced diffusion is not yet clear.\"But other have applauded the achievement. \"This is really a first-of-a-kind study and a very important one in the micromotors field,\" Chemist Tom Mallouk at Pennsylvania State University in the US told New Scientist. \"Importantly, it shows that micromotors can be more effective for the delivery of nanoparticles than passive carriers"
        ]
    },
    "578": {
        "gold_standard": [
            "So, we all like our mobile phones. Maybe a little too much. Maybe, it's gotten so bad that we actually need them. And perhaps that needy feeling is so strong, that when we're apart we begin to feel\u2026 separation anxiety.\nYou may say, \"not me\", but a team of researchers from the University of Missouri has recently found that separation from smartphones during a basic cognitive test can have physiological impacts, such as increased heart rate and blood pressure.\u00a0Furthermore, when people were temporarily separated from their smartphones, they seemed to be slightly less intelligent, underperforming on the tests. The results of the study - titled \"The Extended iSelf\"\u00a0- were published in the Journal of Computer Mediated Communication.\u00a0\"Our findings suggest that iPhone separation can negatively impact performance on mental tasks,\" said lead author Russell Clayton in the University of Missouri press release.\u00a0\"Additionally, the results from our study suggest that iPhones are capable of becoming an extension of ourselves such that when separated, we experience a lessening of 'self' and a negative physiological state.\"\nForty smartphone users were asked to perform two five-minute word searches. These were performed individually. They were told by researchers that the objective of the experiment was to test the reliability of a new wireless blood-pressure monitor.\u00a0Participants completed the first word search with their mobile phones handy. For the second test, however, the researchers took the phones away, telling participants that they were causing a signal interference, and disrupting the blood-pressure monitor. The phones were placed at an inaccessible distance within the room, but still within earshot.\u00a0During the second test, the researchers called the phones at minute three. They allowed six rings before ending the call. The inability to answer these phone calls had a measurable impact on the participants. \u00a0Heart rate and blood pressure increased during the second test, and participants reported heightened feelings of anxiety and \"unpleasantness\". They were also less adept at the tests, finding fewer words"
        ]
    },
    "585": {
        "gold_standard": [
            "Engineers from the University of California, San Diego have developed an ultra-thin temporary tattoo that can painlessly and accurately monitor the glucose levels of diabetics.\nThe flexible device costs just a few cents and lasts for a day at a time, and early tests have shown that it's just as sensitive as a finger-prick test.But even cooler is the fact that the system works without blood, by extracting and measuring the glucose from the fluid in between skin cells, and could eventually be adapted to detect other important metabolites in the body, or deliver medicine.It also looks awesome, as you can see below.Jacobs School of Engineering/UC San DiegoAt the moment, people with diabetes need to monitor their glucose levels multiple times a day by pricking their finger and assessing their blood. But in the future the tattoo will allow their levels to be continuously measured throughout the day. This means they'll be able to more sensitively maintain their glucose levels and better manage their condition.\nCreated by graduate student Amay Bandodkar, the device is made up of woven electrodes printed out on rub-on tattoo paper, and works by applying a very mild electrical current to the skin for 10 minutes. This forces sodium ions from the fluid between skin cells, which carry glucose, to flow towards the tattoo.A sensor built into the tattoo then measures the strength of the electrical charge produced by this glucose. The levels of glucose in this fluid are, overall, around 100 times lower than the levels found in someone's blood, so the device requires a more sensitive sensor. But an early trial on seven men and women aged aged between 20 and 40 without diabetes has revealed that it's just as accurate as a finger-prick test. The users also couldn't feel anything while wearing the device, other than a mild tingling in the first 10 seconds of use.The results of the trial have been described in the journal Analytical Chemistry.Right now, the tattoo can't provide a numerical read-out that diabetics would need in order to regulate their blood sugar levels, but it's an important proof-of-concept. The team is now working on adding that user-friendly capabilit"
        ]
    },
    "591": {
        "gold_standard": [
            "Indoor heating is one of life's wonderful little treasures, but it's doing awful things to our environment. According to the International Energy Agency, almost half our global energy is spent on indoor heating, and of that, 42 percent is reserved just for heating our homes. As my mother used to say when I sat in front of our heater in a t-shirt and shorts while complaining about how cold it was, \"Put a jumper on!\" I could put a jumper on, I used to say, but it would never be as warm as sitting this close to the heater.\nWell, she'll be pleased to know that researchers in the US have invented a type of clothing can be dip-coated in a silver nanowire solution, called AgNW, to keep a person so warm, they'll need significantly less or no indoor heating at all in the winter months.Led by engineer and materials scientist Yi Cui, and PhD student Po-Chun Hsu from Stanford University, the team looked at the problem of keeping everyone warm by trying to figure out how to turn the warmth generated by our own bodies - called infrared radiation - back on us. \"Let's say you want to make your clothes reflect heat,\" Yi Cu told Lidia Ramsey at Popular Science. \"You need metal. But you're not going to put metal on your body.The problem with metal? Too rigid and heavy. Soft and breathable? Nope. But a porous layer of tiny silver nanowires - weighing just 1 gram at a cost of $1 when applied to an entire outfit - could be applied on top of clothing and the wearer wouldn't even notice the difference.\u00a0According to Lisa Zyga at Phys.org, the special coating works because there are gaps in it, measuring about 300 nanometres wide between each nanowire. This allows water vapour molecules to pass through unfettered, but not body heat, because the wavelength of the infrared radiation that humans give off is about 9 micrometres. That's much too large to make it through the holes, so it's reflected back onto the body.\nThe material is so effective at trapping heat, it\u00a0will reflect back over 90 percent of a person's infrared radiation. Which is pretty impressive, when you consider the average piece of clothing only reflects back about 20 percent of our body heat, according to Zyga at Phys.org.\"This increase in reflectance is due to differences in the materials' emissivity, which is a measure of heat radiation,\" says Zyga. \"Low-emissivity materials like silver, which has an emissivity of 0.02, emit less radiation and so provide much better insulation than high-emissivity materials like common textiles, which have an emissivity of about 0.8.\"The other way the clothing works to keep the wearer warm is it can be charged up, say, while you're sitting at the computer. According to Ramsey at\u00a0Popular Science, the movement of electricity from devices such as your computer or television across the nanowire-coated cloth creates a phenomenon known as Joules heating, which is heat that's generated as electricity is travelling across a current.You could even plug it in - if the clothing is connected to a battery, or some other kind of power source, it would take just 0.9 volts to heat it to a toasty 30 degrees Celsius.\nThe team calculated that if people wore nanowire-coated outfits during winter instead of heating their homes, they would save an average of 1,000 kWh per year across the four coldest months. This would shave about $200 off your electricity bill.But what about when you want to wash them? The team reports that even when the clothing was put through multiple cycles, it was able to retain its heat-trapping properties. They report their findings in the journal Nano Letters.One problem with this whole idea, says Reddit, is what happens to the pipes in your house when you're no longer using internal heating? Not something we have to worry about in Australia, but maybe those in the coldest places should hold onto their heating systems just a little while longer, until scientists can create little nanowire-coated jumpers for their pipes too"
        ]
    },
    "608": {
        "gold_standard": [
            "A composite perovskite solar cell developed by Korean engineers has achieved a record-setting power conversion efficiency of 20.1 percent.\u00a0Importantly, the new cell - described this week in the journal Nature - has also sidestepped issues with performance variability that have plagued other perovskite solar cells.\nCrystal structures of hybrid perovskites have, in the last few years, captured the attention of the solar photovoltaic industry and research community.\u00a0The first reported perovskite cell, developed in 2009, yielded an efficiency value of only 3.5 percent. But since 2012, efficiencies have dramatically improved. \u00a0According to an editorial in Nature Materials, \"the exceptional performance of hybrid perovskite materials may revolutionise the field of renewable energy with cheap solar cells having power-conversion efficiencies comparable to those of silicon photovoltaic devices\".\u00a0Not only are the materials being investigated by researchers more abundant and more affordable than silicon, they are also very good at absorbing light.\u00a0According to an article from MIT Technology Review written in August 2013, \"while conventional silicon solar panels use materials that are about 180 micrometers thick, the new solar cells use less than one micrometer of material to capture the same amount of sunlight. Furthermore, the pigment is a semiconductor that can effectively transport the electric charge created when light hits it\".\nThe materials are also relatively easy to incorporate into working devices: the pigment can be spread on a sheet of glass, and covered with several layers of other materials that enable the movement of electrons through the cell - sort of like a sandwich.IEEE's Spectrum points out, however, that two main barriers have impeded \"rapid progress\" for perovskite solar cells.\u00a0The first issue is that the cells' power conversion efficiency often varies depending on how it is measured.\u00a0This performance variability - known as hysteresis\u00a0-\u00a0was highlighted in the afortementioned Nature Materials editorial, which raised concerns about the validity of efficiency values being reported.\u00a0Secondly, researchers have been working on extending the range of the light wavelengths that perovskite cells can trap, and convert to electricity. Doing so is necessary to achieve efficiencies comparable to silicon cells"
        ]
    },
    "611": {
        "gold_standard": [
            "The asphalt that forms our roads can be modified to store carbon and help reduce the amount of CO2 entering the atmosphere, new research as found.A team from Rice University in the US has used asphalt, or bitumen, to make a cheap porous material that can store an impressive 114 percent of its weight in carbon dioxide.\nKnown as asphalt-porous carbon (A-PC), the new material stores the carbon dioxide like a sponge at room temperature, but lets other gasses, such as methane flow through freely.This means it's an ideal material to use as a filter in natural gas wellheads, which currently release a lot of carbon dioxide into the atmosphere in addition to the desired methane. The captured CO2 could later be extracted for other practical purposes, and the study shows that the material can store and then release CO2 over and over again without degrading.\u00a0\"This provides an ultra-inexpensive route to a high-value material for the capture of carbon dioxide from natural gas streams,\" said chemist James Tour, who led the research, in a press release. \"Not only did we increase its capacity, we lowered the price substantially.\"\u00a0The team made several variation of the material, which is made by mixing asphalt with potassium hydroxide at a high temperature, but the cheapest cost was just 30 cents per pound (~0.4 kg).\nTheir research has been published in the journal\u00a0Applied Materials and Interfaces.Tour notes that this makes the material better than any other that's currently in use. And they're hoping to tweak it further to make it more efficien"
        ]
    },
    "709": {
        "gold_standard": [
            "A device that can detect gases found exclusively in the breath of people with lung cancer has been developed by researchers in China.\u00a0The low-cost screening device, which was designed and built by a team from Chongqing University in China, has 35 chemically responsive fluroescent sensors. This array of sensors has been designed to change colour when exposed even to very low concentrations of specific volatile organic compounds, or gases, which have been directly linked to lung cancer.\nPrevious studies\u00a0have shown that there are specific gases related to lung cancer, which originate from the oxidation of unsaturated fatty acid. This occurs as normal cells transform into cancer cells and begin to form tumours.\u00a0Because these gases appear only in the exhaled air of people with lung cancer,\u00a0several different research teams\u00a0have been targeting them as possible biomarkers for early diagnosis of the disease.\u00a0Lung cancer is the deadliest form of cancer, resulting in an estimated\u00a01.59 million deaths annually. Current diagnostic methods include imaging techniques such as x-rays, CT scans and MRIs, but these are generally quite expensive, and\u00a0some studies\u00a0have suggested they're not that effective for early detection, which is crucial for improving survival rates.So far, the team from Chongqing University has only tested their device in the lab, but their experiments have been promising: \"Our results show that the device can discriminate different kinds and concentrations of cancer related volatile organic compounds with a nearly 100 percent accurate rate,\" said lead investigator and optoelectronic engineer Jin-can Lei, in a statement prepared by the American Institute of Physics (AIP). \"This would also be a rapid method in that the entire detection process in our experiment only takes about 20 minutes.\"The new breathalyser device, developed by Lei and his colleagues, has a rotating chamber, which evenly distributes the gas molecules across 35 chemically-responsive sensors, located around the edge of a 5-cm-wide circular plate inside. A light source then produces three lasers with different nanometre wavelengths, which excite the fluorescent spectra of the array of sensors. By collecting the \"initial\" fluorescent spectrum of the array before exposure and the \"final\" spectrum, the researchers can identify and quantify a specific gas.\nIn their most recent experiment, the team looked at four gases known to be present in the breath of people with lung cancer: p-xylene, styrene, isoprene and hexanal. Using their device, they were able to consistently discriminate between the four gases with high accuracy, and quantify how much of each gas was present in the sample, even at concentrations as low as 50 parts per billion.\u00a0The team has\u00a0described their breathalyser device and published their findings\u00a0in the AIP journal\u00a0Review of Scientific Instruments, where they noted that \"the proposed detection device has brilliant potential application for early clinical diagnosis of lung cancer.\"The researchers say\u00a0their next step is to refine the method and establish a complete fluorescent database for lung cancer-related gases.Breath tests for lung and other types of cancer could play a big role in the future after another breathalyser device, developed by a UK-based company called Owlstone Nanotech, was\u00a0recently approved for clinical trials"
        ]
    },
    "718": {
        "gold_standard": [
            "Alzheimer's disease is difficult to detect in its early stages, and is often diagnosed only after it begins deteriorating someone's memory and thinking abilities. \u00a0Researchers around the world have been looking at ways to improve the way Alzheimer's disease is diagnosed. While lots of research is\u00a0focused on the brain, there could also be clues in your bloodstream as to how the disease manifests \u2013 possibly in the form of trace metals.\nA team of researchers from the University of Technology, Sydney (UTS) Faculty of Science in Australia have taken the approach of scouring the blood for possible early warning signs, and are now closing in on a disease indicator for Alzheimer's. Their suspected culprit: iron.\u00a0Specifically, the team is studying a protein called transferrin, which helps shuttle iron around the body. Iron binds to the transferrin proteins in your blood. When these proteins encounter corresponding transferrin receptors on the surfaces of cells, the iron is then transferred to those cells. \u00a0If transferrin fails to do its job, so to speak, iron that was meant to be distributed throughout the body might end up accumulating in the brain. According to the UTS:Science press release, this accumulation \"contributes to the build-up of 'plaques' and 'tangles'. Plaques impede the transmission of signals among brain cells and tangles kill them.\"The research is led by neurochemist Dominic Hare from UTS:Science and Blaine Roberts from the Florey Institute in Melbourne, Australia, who investigates the way trace metals move through the blood and influence protein functions. Together they have used blood samples collected for the Australian Imaging, Biomarker & Lifestyle Flagship Study of Ageing (AIBL) to carry out an extensive study searching for biomarkers, cognitive characteristics and lifestyle factors that might combine in some way to help indicate the onset of Alzheimer's.\n\"The unique thing about AIBL is that it's following 1,000 people through time,\" said Hare in the\u00a0release.\u00a0\"That gives us statistical power.\"\u00a0The researchers used samples from 34 AIBL participants \u2013 who are all being tracked for more than four years - and samples from 36 healthy participants, and analysed their blood with specialised mass spectrometry equipment, which allowed them to detect minuscule concentrations of trace metals.\u00a0Their results showed that, overall, participants with Alzheimer's had lower levels of iron in their blood compared to the healthy volunteers.\u00a0Interestingly, both groups of participants had the same amount of transferrin in their blood. The key difference, they found, is in how efficiently the transferrin is working. In the blood samples from the participants with Alzheimer's, the transferrin proteins were carrying less iron away from the brain. It's a subtle difference that the researchers say is \"not observed through routine pathological testing.\"\nThe team's results have been described in the journal ACS Chemical Neuroscience.\"The disease develops so slowly and has so many effects on the body, being able to separate what's cause and what's effect is a big problem,\" Hare says in the release. \"If we can identify why the disease is happening, we could intervene to alleviate the symptoms and potentially halt the disease process.\"\"The next step is to look at a copper-binding protein called ceruloplasmin that interacts with transferrin. Putting all these pieces together will help find methods to maintain quality of life, possibly slowing or even halting the progress of the disease.\"Find out more about the world-leading research happening at UTS:Science, and how you can be involved"
        ]
    },
    "721": {
        "gold_standard": [
            "Researchers have known about the healing properties of collagen, which is the main structural protein found in the connective tissues of animals, for many years. Mammal collagen, especially from pigs and cows, has been extensively used for skin wound healing in hospitals all over the world. But the problem with mammal collagen is that it carries the risk of disease transmission, such as foot-and-mouth disease and bovine spongiform encephalopathy, plus many people can't receive it due to their religious beliefs.\nBut fish collagen? It's cheaper, safer, and there's a whole lot of it to go around.\u00a0Back in 2008, research showed that nanofibres made from collagen-rich, discarded fish scales had enough tensile strength to be used as a wound-dressing material, and when applied topically, encouraged the growth of skin cells. Containing around 70 percent collagen, fish skin is even better than fish scales, and is closer in form and structure to human skin, so a team of scientists from the Shanghai Jiaotong University School of Medicine in the US decided to test out its healing powers.Using a series of processing and purification technologies, the team managed to extract pieces of high-quality collagen sponge from discarded tilapia skin. They first tested to see if it would provoke an immune response, which would be bad, because it means the body is rejecting it.\u00a0To find out, they mixed mouse spleen lymphocytes - a type of white blood cell - and mixed them with the tilapia collagen sponge. The contact did not cause the lymphocytes to proliferate, which means there was no immune response. \"Furthermore, tilapia collagen encouraged the growth of fibroblasts and increased the expression of genes involved in wound healing,\" Alex B. Berezow reports at Real Clear Science. \"Thus, these experiments indicated that tilapia collagen is well-suited for regenerative medicine.\"\nNext, the researchers tested the strength of a wound dressing made from tilapia collagen and found that it was tough, and stable at temperatures up to around 300 degrees Celsius.The final test was its actual wound-healing ability. Rats with 1.8-centimetre long wounds on their backs were treated with either the new fish collagen wound dressings, an algae-based wound dressing called Kaltostat, or nothing at all. You can see the results below:Credit: Tian Zhou et. al.\"Compared to the control groups, the wound-healing rate was significantly improved, crust started to disappear at day seven, and most of the wound area was covered with a continuous epidermis at day 14 in the collagen nanofibres group, while the skin wounds in the other two groups were not fully healed,\" the team reports in Applied Materials & Interfaces. \"The histopathological results confirmed that the collagen nanofibres caused the lowest degree of inflammatory response and induced the best growth status of new epidermis throughout the process of wound healing.\"\nThe next step will be human trials, and turning it into a commercially viable product. But it won't be easy. \"They will face a tough marketplace,\" says Berezow at Real Clear Science. \"For instance, the company Eqalix, which uses a soybean protein to promote wound healing, has a head start of a few years. Currently, Eqalix is seeking FDA clearance for its product.\"I hope they get there. What they're using is an abundant and cheap waste product, which is just sitting there waiting to be recycled. It's not clear if Eqalix is using discarded soybean parts, but if they're not, well, we really don't need another excuse to grow more of them"
        ]
    },
    "731": {
        "gold_standard": [
            "When you think of humanity's legacy, the most powerful message for us to leave behind for future civilisations would surely be our billions of terabytes of data. But right now the hard drives and discs that we use to store all this information are frustratingly vulnerable, and unlikely to survive more than a couple of hundred years.\nFortunately scientists have built a DNA time capsule that's capable of safely preserving all of our data for more than a million years. And we're kind of freaking out over how huge the implications are.\u00a0Researchers already knew that DNA was ideal for data storage. In theory, just 1 gram of DNA is capable of holding 455 exabytes, which is the equivalent of one billion gigabytes, and more than enough space to store all of Google, Facebook and pretty much everyone else's data.Storing information on DNA is also surprisingly simple - researchers just need to program the A and C base pairs of DNA as a binary '0', and the T and G as a '1'.\u00a0But the researchers, led by Robert Grass from ETH Z\u00fcrich in Switzerland, wanted to find out just how long this data would last.DNA can definitely be durable - in 2013 scientists managed to sequence genetic code from 700,000-year-old horse bones - but it has to be preserved in pretty specific conditions, otherwise it can change and break down as it's exposed to the environment. So Glass's team decided to try to replicate a fossil, to see if it would help them create a long-lasting DNA hard drive.\n\"Similar to these bones, we wanted to protect the information-bearing DNA with a synthetic 'fossil' shell,\" explained Grass in a press release.In order to do that, the team encoded Switzerland's Federal Charter of 1921 and The Methods of Mechanical Theorems by Archimedes onto a DNA strand - a total of 83 kilobytes of data. They then encapsulated the DNA into tiny glass spheres, which were around 150 nanometres in diameter.\u00a0The researchers compared these glass spheres against other packaging methods by exposing them to temperatures of between 60 and 70 degrees Celsius - conditions that replicated the chemical degradation that would usually occur over hundreds of years, all crammed into a few destructive weeks.They found that even after this sped-up degradation process, the DNA inside the glass spheres could easily be extracted using a fluoride solution, and the data on it could still be read. In fact, these glass casings seem to work much like fossilised bones.\nBased on their results, which have been published in Angewandte Chemie,\u00a0the team predicts that data stored on DNA could survive over a million years if it was stored in temperatures below -18 degrees Celsius, for example, in a facility like the Svalbard Global Seed Vault, which is also known as the 'Doomsday Vault'. They say it could last 2,000 years if stored somewhere less secure at 10 degrees Celsius - a similar average temperature to central Europe.The tricky part of this whole process is that the data stored in DNA needs to be read properly in order for future civilisations to be able to access it. And despite advances in sequencing technology, errors still arise from DNA sequencing.The team overcame this by embedding a method for correcting any errors within the glass spheres, based on the Reed-Solomon Codes, which help researchers transmit data over long distances. Basically, additional information is attached to the actual data, to help people read it on the other end.This worked so well that even after the test DNA had been kept in scorching and degrading conditions for a month, the team could still read Switzerland's Federal Charter and Archimedes' wise words at the end of the stud"
        ]
    },
    "736": {
        "gold_standard": [
            "(Noah MacCallum et. al.) Scientists in the US have invented a new material that makes urinary catheters, intravenous catheters, and implants so slippery, life-threatening colonies of E. coli and Staph bacteria struggle to accumulate on them.\nIt's estimated that biofilms -\u00a0adhesive colonies of harmful bacteria that form on medical equipment - are responsible for more than\u00a080 percent of all microbial infections in the body, and there are a select few species of bacteria that are becoming increasingly difficult to deal with in hospitals, even with copious amounts of antibiotics on hand.For example, urinary tract infections (UTIs) represent 40 percent of all hospital-acquired infections, and 11 percent of those are caused by the bacterium Pseudomonas aeruginosa. In fact,\u00a0P. aeruginosa\u00a0 currently accounts for up to 15 percent of all hospital-acquired infections in the US, and it's notoriously resistant to the drugs we try to combat it with. Two of the most significant human pathogens,\u00a0E. coli and Staphylococcus epidermidis,\u00a0are similarly troublesome, causing all kinds of tissue and blood infections thanks to their continued and widespread existence in even the world's cleanest and best-staffed hospital environments. If you're really unlucky, you could go in for a routine surgical procedure, and die from a severe bacterial infection.Long story short, we need better ways of keeping our medical equipment free from bacteria, and antibiotic treatments are becoming less and less of an option.So a team led by chemist Joanna Aizenberg from the Kavli Institute for Bionano Science and Technology at Harvard University has come up with a solution: commercially available silicone tubing - the same kind that's already being used in today's medical tubing - infused with high-purity silicone oil. This silicone mixture releases a self-lubricating, slippery coating that's super-repellent, long-lasting, non-toxic, and cheap to produce.\nSuitable for all kinds of medical surfaces, including those of mechanical heart valves, urinary catheters, intravenous catheters, and implants, this silicone material has been engineered to take up and store large amounts of lubricating silicone oil in its molecule structure, just like a sponge. This means where ever it's used, the substance will form a smooth lubricant layer over the surface, making it a whole lot more difficult for bacteria to hold on to and colonise the area.\"The solid silicone tubing is saturated with silicone oil, soaking it up into all of the tiny spaces in its molecular structure so that the two materials really become completely integrated into one,\" one of the team, Caitlin Howell, said in a press release.And the best part is it doesn't lose its slipperiness over time, because the silicone oil is only released onto the surface of the silicone when needed, so to replace any oil that's been wiped away by other liquids such as urine, blood, or gastro-intestinal fluids.To test their new coating, the team exposed treated and untreated medical tubing to P. aeruginosa, E.coli, and Staphylococcus epidermidis. They found that the silicone oil-infused tubing greatly reduced bacterial adhesion and largely eliminated biofilm formation.\nThe researchers discuss their results in the journal ACS Biomaterials Science & Engineering:\"We have demonstrated that P. aeruginosa biofilm formation can be reduced in various shear conditions, including those representative of indwelling catheters, by at least 10-fold. After a five-second wash with water, the biofilm volume can be almost completely removed, while a robust biofilm remained on the untreated control silicone surfaces. Further, the materials passively resist bacterial accumulation without the use of bactericidal agents, and could thus be developed as an important component in reducing excessive antibiotic usage.\"\u00a0\"With widespread antibiotic resistance cropping up in many strains of infection-causing bacteria, developing out-of-the-box strategies to protect patients from bacterial biofilms has become a critical focus area for clinical researchers,\" added one of the team, bioengineer Donald Ingber, in the press release. \"Liquid-infused polymers could be used to prevent biofilms from ever taking hold, potentially reducing rates of infection and therefore reducing dependence on antibiotic use.\"The next step is to get FDA approval so the new material can be used in hospitals. As the silicone parts have already been approved, this will hopefully only take a couple of years. The team is also now working on expanding the technology to other applications, such as keeping the surfaces of waste-water management systems, maritime vessels, and oil pipes clean.\u00a0\"Each technology in our portfolio has different properties and potential uses, but collectively this range of approaches to surface coatings can prevent a broad range of life-threatening problems,\" says Aizenberg, \"from ice accumulation on airplane wings to bacterial infections in the human body.\"\u00a0Game on, bacteri"
        ]
    },
    "792": {
        "gold_standard": [
            "The good news here is that over the past decade, the amount of trees we've cut down for wood or to clear land has declined. But, unfortunately, the environmental benefits of those improvements are almost being cancelled out by our efforts to feed the world's rapidly growing population, a new study has revealed.\nAn international team of scientists, led by the Food and Agriculture Organisation of the United Nations, has analysed three datasets available from the Intergovernmental Panel on Climate Change (IPCC) Fifth Assessment Report, and found that, in 2010, agriculture contributed around 11.2 percent of all greenhouse gas emissions.Publishing in\u00a0Global Change Biology,\u00a0the team explains that this means it now does more damage, climate change-wise, than deforestation, which for years has been pinpointed as one of the worst environmental activities.\"Deforestation was responsible for only 8 percent of total anthropogenic emissions in 2010, compared to 12 percent in the 1990s,\" the researchers write.\"We're seeing an expansion of agricultural lands in some areas because of the growing global population,\" Rob Jackson, who is a co-chair of the Global Carbon Project, told John Upton from Climate Central. \"We're also seeing intensification of agriculture.\"\nAccording to the study, the greenhouse gases released by farming have risen 13 percent since 1990 - as a result of methane from livestock and rice paddies, and nitrous oxides from fertilisers and other soil chemicals.However, despite the growing impact of agriculture on climate change, it's not something that policy makers have paid much attention to, writes Upton.\"While United Nations climate negotiations focus heavily on forest protections, the researchers note that delegates to the talks ignore similar opportunities to reform farming,\"\u00a0explains Upton over at Climate Central.The research revealed that meat - in particular our love of beef - as well as dairy, is one of the worst offenders when it comes to food. In fact, as Upton reports, livestock produces so much methane and eat so much fertilised feed that they're responsible for around two-thirds of agriculture's climate pollution every year"
        ]
    },
    "829": {
        "gold_standard": [
            "For those of us who have woken up in the middle of the night to scribble down an idea, only to realise that it was completely crazy and unrealistic when you read it back to yourself the next morning, the fact that the human brain can get pretty wacky when it's tired is nothing new.\nBut this wackiness is actually key to how the brain handles brainstorming and riddle-solving - tasks that require you to, yep, \"think outside the box\", and come up with strange and less obviously feasible solutions to a problem.Over at Smithsonian Magazine, Marissa Fessenden quotes a Harvard Business Review podcast by American author and screenwriter Ron Friedman, where he explains the basic theory behind this:\u00a0\"[I]t's partly because, in order to be creative, sometimes you need to consider some ideas that don't necessarily feel like they're on track with what you're trying to achieve. And so having all these ideas come into your mind because you're not quite as good at putting them off when you're tired can actually make you more creative.\"And there's actually some pretty fascinating science to back this up. In 2011, a study led by psychologist Marieke Wieth at Albion University in the US set out to investigate the effects of tiredness on a person's ability to perform certain mental tasks. They gathered together 428 university student volunteers and first tested them to see if they were morning people or night owls. They found that 195 participants were evening-type night owls, 28 were morning types, and 205 were neutral.\nNext, they got the volunteers to solve several creative problem-solving tasks and more straightforward analytical problems at both their optimal and non-optimal times. Morning sessions were between 8:30am and 9:30am and then there were late afternoon sessions between 4pm and 5:30pm. The volunteers were tested in groups, and were given four minutes to solve each question.\u00a0The results showed that the students performed just as well, regardless of the time of day, on the analytical problems, but when it came to the more creative task, the students actually performed better when they were sleepy. This meant in the morning for night owls, and at night for the morning people.The team discusses the findings in the journal Thinking & Reasoning:\"Given the presumed differences in the cognitive processes involved in solving these two types of problems, it was expected that the reduced inhibitory control associated with non-optimal times of the day would differentially impact performance on the two types of problems.\nIn accordance with this expectation, results showed consistently greater insight problem solving performance during non-optimal times of day compared to optimal times of day but no consistent time of day effects on analytic problem solving. The findings indicate that tasks involving creativity might benefit from a non-optimal time of day.\"The team ended up suggesting that if you're a student, you should try and schedule your more creative classes, such as art and creative writing, at a time when you're not at your best. Night owls, this means sucking it up and doing your creative classes bright and early at 9am.\u00a0And while you're at it, try to refrain from drowning your vampire tendencies in coffee, because that will ruin the effects, says Marissa Fessenden at Smithsonian Magazine:\"This effect makes tired people better at solving problems that require insight. That's also why grabbing a cup of coffee isn't always the best way to seek eureka moments. The focus caffeine lends can get in the way of those stray thoughts. Maybe that's also why messy desks often go hand-in-hand with a creative mind - the clutter could be stimulating.\"So no coffee, messy desk, sleepy as hell = creative success. Science, you cruel mistress, yo"
        ]
    },
    "849": {
        "gold_standard": [
            "Research by Swinburne University of Technology\u00a0and Monash University in Australia has revealed that, when it comes to stalking, there's an underlying community perception that 'victims are to blame', 'stalking is romantic' and 'stalking isn't serious' - and, worryingly, these three beliefs affect whether or not people believe someone is guilty in a fictional stalking case.\nThe study set out to investigate whether community attitudes towards stalking could be minimising the criminal behaviour, which affects around one in six women and one in 19 men in their lifetime. After studying 244 community members and 280 police officers, they found that, worryingly, many people downplay stalking, and tend to think that it can be a normal part of dating.\"Understanding and being able to reliably measure stalking-related attitudes and beliefs would be of use in anti-stalking education campaigns and offender and victim treatment programs,\" said study leader Troy McEwan, from Swinburne's Centre for Forensic and Behavioural Science, in a press release.To work out how people felt about stalking behaviour, the researchers sent out a Stalking Related Attitudes Questionnaire (SRAQ), a scale that attempts to measure stalking-related attitudes and beliefs by asking people to agree or disagree with certain statements, such as \"A woman who dates a lot would be more likely to be stalked\", \"A man should be allowed to pursue a woman to a certain extent, if it is part of romance\", \"Women often say one thing but mean another\" and \"Those who are upset by stalking are likely more sensitive than others\".The results revealed that some participants had underlying beliefs that victims were to blame for being stalked, that stalking could be romantic and that it wasn't that serious. Men were overwhelmingly more likely to believe these statements than women, but perhaps most concerning was the fact that police officers didn't differ much from the general population in their opinions, except that they were more likely to take stalking seriously than members of the public.\nThe team then looked into whether these beliefs would affect whether or not the participants believed someone was guilty in a fictional stalking case, and found that those who believed stalking was 'romantic' or 'not that serious' were more likely to find a stalker not guilty. The results have now been published in the journal\u00a0Psychiatry, Psychology and Law,\u00a0and highlight that not only are some public perceptions of stalking incorrect, they can also affect whether or not stakling is dealt with effectively.\"The study provides preliminary evidence that these attitudes are related to failure to recognise stalking behaviour when it is present,\" said McEwan in the release.\u00a0\"Specific education for helping professionals may be necessary to ensure that appropriate responses are given to all stalking victims.\"Love science?\u00a0Find out more about the research happening at Swinburne University of Technology"
        ]
    },
    "870": {
        "gold_standard": [
            "(Yep, that's a rat erection. Credit: Taeuk Kim el. al.) Scientists in Switzerland have figured out how to control brain function using simple flashes of coloured light, and have now effectively induced erections in mice using the same method.\nThe technique is called optogenetics, and what scientists are doing with it will blow your mind. It all starts with a simple species of pond algae that uses a primitive organelle called an eye spot to respond to sources of light for photosynthesis. A particular type of light-sensitive protein inside the eye spot responds to blue light by moving positively charged ions across the eye spot membrane, and this causes the voltage of the eye spot to change.\u00a0Scientists figured out that this process could be replicated in neurons in the brain, so they synthesised the fragment of pond algae DNA that encodes for this blue light-receptive protein, and using a harmless virus, inserted the genes into the specific types of mouse and rat neurons.\u00a0The rodent neurons expressed the genes, and their neural membranes soon became covered in the light-responsive protein. When the researchers shone a blue light, the proteins activated, just like they did in the pond algae. When the blue light was turned off, the neurons instantly deactivated.\u00a0Why is this so cool? Well, our brains contain thousands, if not tens of thousands, of different types of neurons, each one with a distinct shape, molecular composition, and function. Using optogenetics, scientists are now able to manipulate the behaviour of one specific type of neuron without affecting the activity of those around it. If you're still confused, you can watch the video below for a really clear explanation of the whole process. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">So far, optogenetics has only been used on mice and rats, but it's opened up an intriguing possibility for humans\u2026 as a potential new sex aid that improves penis function.\nThe part of the penis in question is the corpus cavernosum, which is the region that gets filled up with blood to facilitate an erection. That's if everything goes to plan. There can be lots of reasons for why the muscles in the corpus cavernosum can fail to relax and let the blood flow through it - you're nervous, depressed, low on testosterone, and so on.And then even if you manage to get an erection thanks to a cooperating corpus cavernosum, you risk losing it again, thanks to a defective enzyme called cGMP, which traffics the blood flow in and out of the penis. \"Viagra slows down that degradation, allowing you to maintain an erection, but it doesn't actually induce an erection without sexual stimuli,\"\u00a0says Jason Koebler at Motherboard. \"Optogenetics, on the other hand, can be used to trigger erections without any other stimulus.\"This week, a team led by bioengineer Martin Fussenegger, from the Swiss Federal Institute of Technology, published a paper in\u00a0Angewandte Chemie\u00a0describing the technique they used to control erections in rats using optogenetics.\u00a0\"He calls it an 'erectile optogenetic stimulator,' and it's quite simple, once you get past the gene-therapy part of it,\"\u00a0says Koebler. \"Shine a blue light (a Philips goLITE BLU, designed to treat seasonal affective disorder, if you must know) on a rat dick, cause dick to get hard.\"\nAll Fussenegger's team had to do was insert the light-sensitive protein DNA into the rats' corpa cavernosa to make them respond to blue light within 55 seconds of exposure. The DNA worked perfectly in relaxing the corpa cavernosa muscles to facilitate blood flow, and the scientists report being able to induce all the erections and ejaculations they wanted, even without a single lady rat in the room. When coupled with Viagra, the technique worked even better.\u00a0\"Current treatment strategies focus either on restoring erection-promoting pathways or maintaining an established erection, but fail to provide a trigger-inducible erection on demand,\"\u00a0the team wrote in the paper. \"EROS decouples penile erection from physiological control, bypasses the causes for erectile dysfunction, and providers trigger-inducible erection on demand by simple illumination with a portable commercial light-therapy device.\"Will we see this used on humans any time soon? Doubtful, but don't rule it out just yet. The technique used to insert the DNA is the same as that being used in human gene therapy trials, so that part at least has experimental precedence in human, not just animal, models. We just have to figure out the ethics of manipulating human functions using a little blue ligh"
        ]
    },
    "923": {
        "gold_standard": [
            "Scientists in the US have figured out how to magnetise large areas of graphene, which they say could revolutionise our current technique for storing data.Graphene the wonder-material has got some pretty strange properties, but one of the most unexpected is magnetism. Over the past 10 years, researchers have been intensely investigating the various characteristics of this multi-purpose material - made from multiple stacks of 1-atom-thick carbon layers - and have only been able to explain its occasional magnetism though manufacturing defects or through the binding of certain chemical groups that give it this property.\nBut making graphene reliably electromagnetic - and therefore usefully electromagnetic - has proven difficult. Until now, because a team from the US Naval Research Laboratory have just figured out how to achieve what they're calling \"a simple and robust means to magnetise graphene\", over a large array of the material, and they do it using plain old hydrogen.\u00a0The technique, which they've outlined in the journal Advanced Materials, involves sitting some graphene on a silicon wafer, which they will submerge in a pool of cryogenic ammonia and lithium for about a minute. They then add hydrogen atoms to the mix, which renders the graphene electromagnetic. \"This method of hydrogenation gives us access to a much wider range of hydrogen coverage than previous methods allowed,\" one of the team, chemist Keith Whitener, said in a press release.\"I was surprised that the partially hydrogenated graphene prepared by our method was so uniform in its magnetism and apparently didn't have any magnetic grain boundaries,\"\u00a0his colleague, Paul Sheehan, added.The technique is also adjustable - you can turn the magnetic strength up and down using an electron beam that can shave off hydrogen atoms when there are too many in the mix. It does this by breaking the chemical bond between the graphene and the hydrogen, which renders the graphene no longer magnetic. What this also allows is for \"magnetic patterns\" - which means data - to be written into the graphene structure"
        ]
    },
    "929": {
        "gold_standard": [
            "Researchers in South Korea have invented a fabric patch that can be worn around your arm, and it can harvest enough energy from your regular arm moments to charge a small electronic device, such as a smartphone.\nThe charging fabric works using what's known as the triboelectric effect, which the principle behind static electricity. It's also known as contact electrification, which means you can render certain types of materials electrically charged by rubbing them against another type of surface. If you get the right combination of materials, just a small amount of fiction is all that's needed to convert mechanical energy into usable electricity.The triboelectric effect works when you rub materials together and they form a chemical bond known as adhesion. Thanks to this bond, electrons are freely transferred from one material to the other, creating a build-up of positive charge in one, and a negative charge in the other. When the bond between the two materials is broken, an electric voltage is generated.With this in mind, a team led by materials scientist Sang-Woo Kim from Sungkyunkwan University have invented a double-layer fabric made from woven fibres with one layer coated in silver and the other layer coated in minuscule zinc oxide nanorods that have been dipped in polydimethylsiloxane.\u00a0As Prachi Patel explains at Chemical & Engineering News, these nanorods help to increase the contact surface area between the two layers, which means a better output of friction, and more voltage. \"When the researchers compressed a 4-cm by 4-cm patch of the two-layer textile with a 98-Newton force and then released it, the fabric generated 120 V and a 65-\u00b5amp current,\"\u00a0says Patel. \"To increase the power output, the team stacked four triboelectric generators to make a device that put out 170 V and 120 \u00b5amp. The device is mechanically strong, and it maintained this output for more than 12,000 compression cycles,\"\nThe fabric, which the team has called a wearable triboelectric nanogenerator (WTNG), was then woven into a jacket sleeve, along with six LED lights, a small liquid crystal display, and a remote control car key. When the team asked a volunteer to put it on, all he had to do was move his arm and/or wrist to generate enough charge to power up each of those small devices, one at a time, without any help from external power sources.\u00a0This \"proves potential applications of WTNGs in self-powered smart clothes, health care monitoring and self-powered wearable devices, and even personal electronics\", the team concludes in the journal ACS Nano.\u00a0The technology is cheap to use and make, and will probably be more feasible than embedding solar cells into our clothes for the sam effect, says Patel at Chemical & Engineering News. Of course, no one's going to use it if it doesn't look great, so that's the next challenge researchers are going to have to overcome"
        ]
    },
    "936": {
        "gold_standard": [
            "This article was written by Imogen Rehm, Hailey Meaklim, and Jo Abbott from Swinburne University of Technology in Australia, and was originally published at The Conversation.We all have a poor night's sleep from time to time: those nights when you lie awake for hours trying desperately to go to sleep but can't stop worrying about tomorrow. Or when you repeatedly wake up throughout the night, or can't get back to sleep in the early hours of the morning.\nOne-third of the world's population experience short-term sleeping difficulties. These usually last only a few weeks. But for an unlucky 3 percent of Australians, these sleep disturbances may last a lot longer and lead to a diagnosis of insomnia.A person with insomnia is unable to fall asleep, stay asleep, and/or wakes up too early at least three times a week for at least three months. This can lead to considerable distress.Sufferers experience persistent tiredness, low energy and difficulties with concentration, attention and memory. They may feel down, stressed or anxious, not only about getting a good night's sleep but about their ability to do their daily activities.What causes insomnia?Biological, social and psychological factors interact to trigger and maintain sleeping difficulties.\nBiological factors include changes to the body's natural 24-hour body clock, or circadian rhythms, which control the timing of when we feel sleepy and awake throughout the day. Circadian rhythms are sensitive to body temperature, light and physical alertness. When there is too much or too little of a combination of these factors, the body doesn't release enough sleep-inducing hormones such as melatonin to feel sleepy.Social factors, such as shift work or frequent international travel, can contribute by causing our body clock to become out of sync with the environment it's in. Our bodies adjust slowly to these changes and depend on our being able to get sunlight exposure and exercise.Psychological factors, including unhelpful thoughts (\"I'm never going to get to sleep tonight\") and behaviours (watching the clock during the night), can reduce the amount and quality of sleep a person gets.These factors interact in complex ways. Sleep sensitivity, or a family history of sleep disturbance, for example, make some individuals vulnerable to developing insomnia because they're more likely to have their sleep disturbed by stressful events, such as a relationship breakdown.\nBeing unable to fall asleep often leads to bedtime worrying, which makes it even harder to fall asleep. To try to make up for a lack of sleep, you might then start going to bed earlier, sleep in or take daytime naps. Over time, these unhelpful thoughts and behaviours can create a cycle that makes the insomnia worse.How do you treat insomnia?Successful treatment of insomnia requires getting help to change as many of the interacting factors as possible, rather than trying one or two things in isolation. This is what cognitive-behavioural therapy, or CBT, tries to do.CBT re-trains people to view the bedroom as a place of sleeping instead of a place where they lie awake tossing and turning and worrying about not sleeping. CBT also helps people change their lifestyle and sleeping environment, learn relaxation skills and challenge the unhelpful worries and beliefs that contribute to insomnia.\nCBT has been found to reduce sleeping difficulties by 50 percent\u00a0on average, and reduces insomnia symptoms to a level where they are no longer considered clinically severe.When people visit their GP for insomnia treatment, they're often encouraged to use many of the techniques CBT uses. But these skills are difficult to teach in a short consultation, so many patients don't use them.Sleeping medications may then be prescribed to help a person fall asleep and stay asleep when correctly used for a short period. But sleeping medications only provide short-term relief and can be harmful or addictive if used longer term.If your symptoms persist, your GP may refer you to a specialist doctor or psychologist for CBT.Another credible alternative is web-based treatment. Research from Japan to America shows that, for some people, online insomnia treatment modules may be as effective as visiting a health professional in person"
        ]
    },
    "972": {
        "gold_standard": [
            "Ballpoint pens loaded with sensor-laden inks could eliminate finger pricks for diabetics, and help them test their blood glucose levels simply by drawing cartoons - or just a few dots - on their skin.\nThe innovative new ink could also be used to test for pollutants in the environment by drawing on leaves or on buildings' surfaces, and could help soldiers search for explosives and chemical weapons, the developers say. \u00a0The team of engineers from the University of California, San Diego, who developed the ink, used it to fill up regular, off-the-shelf ballpoint pens. The aim was to enable a new type of do-it-yourself sensor with rapid diagnostic capabilities for people with diabetes.\u00a0The ink is made from the enzymes glucose oxidase, which responds to sugar in the blood, and tyrosinase, which can help detect common pollutants known as phenols. These compounds\u00a0are found in cosmetics and can be toxic at high enough concentrations. \u00a0\u00a0Charles Choi explains for IEEE Spectrum what else was needed to make the inks operate like on-demand sensors: \"To make these bio-inks serve as electrodes, they added electrically conductive graphite powder. They also added: chitosan, a clotting agent used in bandages, to help the ink stick to surfaces; xylitol, a sugar substitute, to help stabilize the enzymes during chemical reactions; and biocompatible polyethylene glycol, which is used in several drug delivery applications, to help bind all these ingredients together.\"\nThe\u00a0team has described its \"enzymatic ink\" and do-it-yourself sensor in the journal Advanced Healthcare Materials.\u00a0Using their pens, they were able to draw sensors to measure glucose directly onto the wrist of a willing participant. They say this ink drawing could be \"easily interfaced with a Bluetooth-enabled\" device that can provide the read-out.\u00a0The researchers also used the ink to draw on and measure chemicals on leaves, and\u00a0according to Choi at IEEE Spectrum, \"the inks could be modified to react with many other pollutants, such as heavy metals or pesticides\".\u00a0The main purpose of the ink, and probably the most immediate impact, will be to enable multiple-use testing strips for diabetes monitoring. As the authors note in their paper, handheld glucose metres rely on single use sensor strips, and each test is expensive for the user.\nThey demonstrated that when applied to a flexible strip that included an electrode, their ink functioned like a sensor. When a blood drop from a pricked finger was placed on the sensor, the ink reacted and the sensor measured this reaction, accurately determining the blood sugar level.Importantly, the researchers say their ink only needs to be wiped off for the strip to be re-used - and they say one pen-load has enough ink for 500 tests.\u00a0The authors write\u00a0that the most attractive feature of their pen \"is the immense freedom available to incorporate high-fidelity inexpensive sensors of any design on a wide variety of surfaces with minimal user training.\"\u00a0The same team has previously developed temporary tattoos to help diabetics continuously monitor their blood-sugar levels. They\u00a0say the next step is to connect the sensors wirelessly to monitoring devices and test their performance in different climatic condition"
        ]
    },
    "1047": {
        "gold_standard": [
            "The Journal of Arachnology Most mothers would do just about anything for their kids, and while this can be downright draining, it usually doesn't result in an untimely death.But this doesn't ring true for all species.For a species of spider called\u00a0Stegodyphus lineatus, motherhood has some irreversible and gruesome consequences.\nAfter giving birth, these spider mothers regurgitate food for their young and then allow themselves to be cannibalised by their babies, making the ultimate sacrifice for reproductive success.Entomologist Mor Salomon from the Hebrew University of Jerusalem in Israel recently studied this process of self-sacrifice - known as matriphagy - to see what, if any, changes take place in the mother's body as she prepares to be devoured.Salomon found her spider specimens by seeking out their webs, which the spiders tend to spin in low-lying shrubs. She searched near dry riverbeds in the Negev Desert in southern Israel.These webs are often attached to conical retreats, which are like silk-spun hollows. This is where the mothers come to lay their batches of eggs.When the spiderlings hatch, the mother has to pierce the silk cocoon to free them. She then stops eating for the rest of her life - which isn't very far off.\nAs Susan Milius explains for Science News, \"For the next two weeks or so, she feeds the dozens of young by regurgitating a transparent liquid. This slurry mixes what's left of her last meals plus some of her own guts.\"The final stage in the process sees the mother become lunch.But interestingly, Salomon and her team have discovered that the mother's body has begun preparing for this event in advance, with the tissue in her abdomen starting to break down and soften while she's still guarding her eggs.This means that once her babies hatch, the tissue in her gut is soft enough for them to pierce, and begin eating, even with their juvenile mouth parts. And so, the cannibalisation of mum begins.Milius from Science News\ndescribes the gory scene: \"As liquid wells out on mum's face, spiderlings jostle for position, swarming over her head like a face mask of caramel-colored beads.\"\nFun times. But for the mother, this's basically what she's been waiting her whole life to do. It's the only reproductive event in her lifetime, and she's going to make damn sure her offspring get the nutrients they need. Even if it means committing suicide.\u00a0\"She makes no attempt to escape,\"\u00a0Salomon told Science News.\u00a0\"If you touch a leg, she will pull it back. She's definitely alive.\"Over a period of several hours, the dozens of hatchlings drain her insides. When all's said and done, the mother has contributed all but 4 percent of her body mass to feeding her spider hatchlings, that now, presumably, have the strength they need to get on in life.Strangely, the one organ they don't devour is the heart.\u00a0The team has reported its findings in The Journal of Arachnolog"
        ]
    },
    "1070": {
        "gold_standard": [
            "Researchers from the University of Wollongong in Australia have 4D printed a valve that automatically opens and contracts under the influence of water and temperature - and it's just one of the many applications of technology that promises to revolutionise how we build objects forever.\nAlready, 3D printing has opened up a whole world of research possibilities. We're now able to custom-print bionic body parts, print our own guns and even print entire buildings. But 4D printing adds a whole other dimension to this technology: time.This means that researchers are now able to custom-design and print an object, but also give it the ability to change its shape, fold itself or even self-assemble under the influence of different factors, such as temperature, pressure, magnetic field or even vibrations.\"4D printing is in essence 3D printed structures that can change their shape over time,\" lead researcher Marc in het Panhuis, from the University of Wollongong's ARC Centre of Excellence for Electromaterials Science, told Nicky Phillips from the Sydney Morning Herald\u200b. \"They're like transformers.\"For example, 4D printing can be used to create furniture that assembles itself when you heat it with a hairdryer - no Allen Key required. Or from a more scientific point of view, it can help create sensitive and responsive parts for machinery, medical research and robotics.\nJust picture medical implants that can change their shape inside the body, or buildings that adjust themselves when it's hot, in order to save on heating and cooling requirements.But this new development by the University of Wollongong is the first time researchers have been able to combine a 4D printer with four different types of hydrogel 'ink'. The process has been described in the journal\u00a0Macromolecular Rapid Communications.The valve itself was 3D printed using both tough and soft hydrogels, which are flexible but strong materials that can be embedded with different properties.\u00a0But what's really cool about this valve, is it's created a mechanic device that's completely autonomous - no power source or programming required.\"The cool thing about it is, is it's a working functioning device that you just pick up from the printer,\" in het Panhuis explained in a press release. \"There's no other assembly required."
        ]
    },
    "1099": {
        "gold_standard": [
            "A new system that uses sunlight to convert waste carbon dioxide into valuable chemical products - like biodegradable plastics, pharmaceuticals, and liquid fuels - has been demonstrated by scientists in the US.\nIn their hybrid system, metal nanowires and bacteria work together to mimic photosynthesis - the process whereby organisms can harvest energy from sunlight to produce nutrients from carbon dioxide and water.But rather than producing nutrients, this engineered system uses sunlight to convert captured carbon dioxide emissions and water into acetate - a versatile chemical building block that can be used to synthesise more complex molecules.While it's still some way off being commercially viable, a scaled-up version of the system could one day provide an alternative to carbon capture and storage, offering a clean option to keep carbon dioxide emissions from entering the atmosphere.\"We believe our system is a revolutionary leap forward in the field of artificial photosynthesis,\" said chemist and lead researcher, Peidong Yang, from the University of California Berkeley, in a press release.\n\"Our system has the potential to fundamentally change the chemical and oil industry in that we can produce chemicals and fuels in a totally renewable way, rather than extracting them from deep below the ground.\"The system is comprised of vertically arranged silicon and titanium oxide nanowires. These wires absorb sunlight, which triggers the reduction of carbon dioxide.\u00a0This structure of wires is then populated with bacteria.This is a cross-sectional SEM image of the nanowire-bacteria hybrid array used in a revolutionary new artificial photosynthesis system. (Credit: Berkeley Lab)For this study, the team used Sporomusa ovata, a type of anaerobic bacteria that readily accepts electrons directly from the surrounding environment and uses them to reduce carbon dioxide.\n\"S. ovata is a great carbon dioxide catalyst as it makes acetate, a versatile chemical intermediate that can be used to manufacture a diverse array of useful chemicals,\" said co-author Michelle Chang, from UC Berkeley, in the release.Once the carbon dioxide has been reduced by S. ovata to acetate, genetically engineered E.coli are used to synthesise targeted chemical products.The team achieved a solar energy conversion efficiency of up to 0.38 percent for about 200 hours under simulated sunlight, which is about the same as that of a leaf, they say.\u00a0But they still have some way to go before their system is solving the world's carbon dioxide storage problem.The team says it's now working on a second-generation system, which has a solar-to-chemical conversion efficiency of three percent. They say if 10 percent efficiency can be attained in a cost-effective way, then the technology could become commercially viable.The researchers have described their system in the journal Nano Letters, which is published by the American Chemical Societ"
        ]
    },
    "1115": {
        "gold_standard": [
            "While we spend a lot of our lives sleeping - a third of it, give or take - it doesn't mean that we're exactly good at getting rest.A bunch of factors contribute to quality of sleep, from exercise to muscle tension to before-bed routines. And according to a 2014 study, an even more essential part of your day predicts your rest at night - sunlight.\nLead author and University of Illinois architecture professor Mohamed Boubekri tracked the sleep and behaviour of 49 office workers, 22 of whom worked in environments with lots of windows and 27 in windowless spaces.And in a result that will want you to park your desk next to the nearest window, Boubreki's team found that people who worked in environments where they could be exposed to some sunlight not only got better quality of sleep, but more sleep.\"Workers in workplaces with windows not only had significantly more light exposure during work hours but also slept an average of 46 minutes more per night during the workweek than workers in workplaces without windows,\" Boubekri and his colleagues wrote.The takeaway? The study was far too small to draw any firm conclusions, but as Kristin Wong notes at Lifehacker, the results suggest that giving yourself more light during the day is associated with better rest at night.\nThe finding also squares with our understanding of how internal clocks work. Sunlight suppresses the production of melatonin, the hormone your body releases that makes you feel sleepy. That's why you want exposure to lots of light during the day, but not at night.Other research has pointed to a similar theme. Psychiatrists with patients who have Seasonal Affective Disorder - where moods tend toward depression as the days get shorter in the fall and winter - recommend taking walks early in the day in order to enable better rest at night. And a 2004 study of newborns found that those exposed to more light during the day slept more soundly at night.This article was originally published by Business Insider"
        ]
    },
    "1156": {
        "gold_standard": [
            "Bacteria engineered to produce hunger suppressing molecules have been used to prevent mice from overeating, and could one day be used to help people lose weight, researchers say.\nPharmacologists from Vanderbilt University in the US have programmed a strain of E. coli, which is prescribed as a digestive probiotic in Europe,\u00a0to produce a compound called N-acyl-phosphatidylethanolamines - or NAPE.This compound is produced naturally in the small intestine following a meal, and is converted to a form that acts as an appetite suppressant, basically telling our bodies to stop eating. However, people who are obese sometimes don't produce enough of this compound, says lead researcher Sean Davis, which can make effective long-term treatment very difficult.Davis hopes that by modifying bacteria to secrete certain therapeutic compounds, he can help treat diseases related to obesity and ageing, such as diabetes and heart disease. Importantly, this could also help eliminate the need to remember to take medication.Davis and his team examined the effects of the genetically modified bacteria on mice that were fed a high-fat diet. Mice that drank water laced with the bacteria gained 15 percent less weight than mice in a control group over an eight-week treatment period.\nThese mice ate less food, had lower body fat, and staved off diseases such as diabetes and fatty liver disease, better than their counterparts. Furthermore, the researchers report that the beneficial effects of the bacteria lasted for about four to six weeks, which suggests that the microbes were able to colonise in the gut once ingested.Davis presented his findings at the American Chemical Society spring meeting\u00a0and addressed questions about the research at a press conference in the below video. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\" style=\"vertical-align: middle;\">In earlier work, the team learned that mice needed to be able to convert the NAPE compound into an active metabolite in order for the ingested bacteria to prevent weight gain. This was problematic, as some mice lacked the enzyme needed to trigger this conversion, rendering the bacteria ineffective.\n\"But we could overcome that by further engineering our bacteria so they had that enzyme\u2026 and then, even in the mice that lacked the enzyme, we were able to inhibit the obesity,\" explained Davis.As Katherine Bourzac at MIT Technology Review points out, bacteria have a distinct advantage for delivering certain compounds, such as NAPE, which cannot be administered orally because it wouldn't survive digestion.Other teams are working on ways to deliver the compound, but Davis says this will likely require an injection - and perhaps several per day to achieve the same effect.He says his team noticed that they need much less of the compound when it's being delivered by the bacteria, versus an injection, which he suspects is due to the fact that the bacteria are very close to the site where the NAPE needs to act"
        ]
    },
    "1175": {
        "gold_standard": [
            "While more people appear to be purchasing breast milk over the Internet to feed to their babies, new research suggests the quality of the product isn't always so pure.As part of a recent experiment, scientists at Nationwide Children's Hospital in Columbus in the US anonymously purchased 102 samples of human breast milk from popular websites, and after running a genetic analysis on each, found that 10 percent contained cow's milk.\nAnd it wasn't just a little bit of cow's milk. In each of the contaminated samples, the level of cow's milk was roughly 10 percent.In addition to cow's milk being potentially dangerous to children with allergies or intolerance, the findings - which were reported in the journal Pediatrics\u00a0-\u00a0raise more questions about the murky online market for human breast milk.\"We racked our brains to think of an explanation for how so much cow's milk could get into a baggie of breast milk,\" lead author and public health researcher from Nationwide Children's Hospital, Sarah Keim,\u00a0told Michaeleen Doucleff at NPR.The team says the concentrations in these contaminated samples were too high to be accidental, and they speculate that sellers are intentionally adding cow milk, possibly as a way to bulk up their sample, which can sell for between US$1 and $3 per 30 millilitres (one ounce).\nThat means if you're shopping for the high-end breast milk, you might be forking out upwards of $100 for a litre.\"It really is, 'Buyer beware',\" Keim told NPR. \"When you are purchasing milk from a source you're not familiar with, you can't tell by looking at it if it's safe. It's really a risky activity that we don't recommend.\"In 2010, the US Food and Drug Administration warned mothers against feeding their babies breast milk purchased online from unknown donors. They said babies could be exposed to infectious diseases, such as HIV, or toxins from cigarettes, or other illegal or prescription drugs.Furthermore, the agency advised that poor handling and storage could make the milk unsuitable to drink.This fact was highlighted by a separate study carried out by Keim and her team in 2013. They bought 60 litres of breast milk online for about $8,000. Almost all the bags arrived above the recommended temperature of minus 20 degrees Celsius, and half were warmer than refrigerator temperatures.\nOn top of that, they found that three-quarters of the samples had bacterial contamination or contained detectable levels of pathogens, such as salmonella and E. coli.Nevertheless, buying breast milk online is big business.A quick Google search turns up 'Only The Breast'. This is a classified site, somewhat like Craigslist or Gumtree, which bills itself as a \"community for mom's to buy, sell, and donate natural breast milk.\"Sarah Steele, a public health specialist at Queen Mary University of London,\u00a0told\u00a0Time\u00a0that 'Only The Breast' had about 27,000 members in 2014, and gains between 700 and 800 new members each month.\u00a0Steele recently co-authored\u00a0an editorial\u00a0published in the\u00a0British Medical Journal,\u00a0outlining the risks of an unregulated online market for breast milk, saying that in the \"absence of warnings\", women don't realise that they are putting their children's health at risk.\u00a0\"I'm a proponent of breast milk,\" Amy Hair, who directs the neonatal nutrition program at Texas Children's Hospital, and wasn't involved in the study, told NPR. \"But if the option is buying breast milk online from an unscreened donor, and not from a reputable milk bank, I would recommend formul"
        ]
    },
    "1186": {
        "gold_standard": [
            "Nature A new rechargeable aluminium battery has been developed by researchers in the US, and they're saying the prototype can charge a smartphone in 60 seconds, plus it's more environmentally friendly, durable, and cheaper than anything currently on the market. And it won't spontaneously burst into flames like certain widely used lithium-ion batteries are capable of\u2026\n\"We have developed a rechargeable aluminium battery that may replace existing storage devices, such as alkaline batteries, which are bad for the environment, and lithium-ion batteries, which occasionally burst into flames,\" said one of the team, chemist Hongjie Dai from Stanford University, in a press release. \"Our new battery won't catch fire, even if you drill through it.\"The new technology has done something scientists around the world have been chasing for decades - it puts aluminium to good use in the high-demand battery industry. The pros for aluminium are many, including its cheapness, availability, low-flammability, and high-charge storage capacity. But the challenge in building a viable aluminium battery has been in finding a material for the cathode - the device through which the electrical current flows - that can produce enough voltage to sustain it across a whole lot of charges.Fortunately for the Stanford team, they found the perfect material\u2026 by accident.\u00a0\"People have tried different kinds of materials for the cathode,\" said Dai. \"We accidentally discovered that a simple solution is to use graphite, which is basically carbon. In our study, we identified a few types of graphite material that give us very good performance.\"\u00a0The team figured out that if they placed an aluminium anode - the part through which the electrical current enters the device - together with an graphite cathode, in a solution of iconic liquid electrolyte. This arrangement was then placed inside a flexible, polymer-coated pouch, which means it could be installed in a flexible and bendy device.\n\"The electrolyte is basically a salt that's liquid at room temperature, so it's very safe,\" said one of the team, graduate student Ming Gong. They tried their prototype out on some smartphones and report that they could fully charge one in 60 seconds - a vast improvement on the several hours it currently takes lithium-ion batteries to charge our phones. Plus the battery lasts for more than 7,500 recharge cycles, while current lithium-ion batteries can only withstand about 1,000 cycles. \"This was the first time an ultra-fast aluminium-ion battery was constructed with stability over thousands of cycles,\" the team reports"
        ]
    },
    "1187": {
        "gold_standard": [
            "Scientists have confirmed that two California fault lines - the Calaveras Fault and the Hayward Fault - are connected, meaning earthquakes resulting from ground movement in these zones could be larger and more destructive than originally thought.\nThe team from the University of California, Berkeley says the 70-km-long Hayward Fault is \"already known as one of the most dangerous in the country because it runs through large population areas.\" The line begins near Santa Rosa in the north, passes east of San Francisco, and ends near San Jose in the south.And now that they know it's connected to the 123-km-long Calaveras Fault, they say the risk it poses could be even greater.\"The maximum earthquake on a fault is proportional to its length, so by having the two directly connected, we can have a rupture propagating across from one to the other, making a larger quake,\" said lead researcher and seismologist, Estelle Chaussard, in a press release.In an update of seismic hazards last month, the US Geological Survey estimated a 14.3 percent likelihood of a magnitude 6.7 or greater earthquake on the Hayward Fault in the next 30 years, and a 7.4 percent chance of a similar earthquake on the Calaveras Fault. But the researchers say these estimates were based on the assumption that the two fault systems were independent.\n\"We thought we could have a magnitude 6.9 earthquake. Now that the two fault lines are connected, we could have magnitude 7+ earthquakes, 7.3 or even larger depending on where the rupture goes,\" Chaussard told Michele Berger at The Weather Channel.\"Going from a magnitude 6.9 to a magnitude 7.3, that's 2.5 times the amount of energy released. We have to expect that we could have larger shaking earthquakes than we previously thought.\"Researchers have previously suspected that the two faults were connected, but were never able to show this definitively.The team used two decades worth of data from the European Space Agency's ERS and Envisat satellites to measure ground deformations and creep along the southern end of the Hayward Fault. 'Creeping' refers to very subtle but continuous movement at the surface.\nThey found that the creep didn't stop at the presumed southern end of the fault, but continued for another 15 kilometres, ultimately merging with the Calaveras Fault.The researchers say this extension was previously hidden by vegetation covering the ground.In addition to their aerial data, seismic tests show that micro-earthquakes on these faults between 3 and 5 kilometres underground also merge.\"With this evidence from surface creep and seismicity, we can argue for a direct junction on the surface and at depth for the two faults,\" said Chaussard.\"People have been looking for evidence of this for a long time, but only now do we have the data to prove it.\"The team has reported its findings in the journal Geophysical Research Letters, and they say the next stage of the research is to refine their \"magnitude estimates\" for specific spots along the fault line to help predict potential damag"
        ]
    },
    "1219": {
        "gold_standard": [
            "Environmental engineers in the UK have been using tampons to help detect sewage seeping into waterways, and say their unusual tool is an affordable and effective option to help pinpoint sources of pollution.\nThe team from the University of Sheffield began looking at tampons because they are made from natural, untreated cotton, which can absorb tiny amounts of chemicals called optical brighteners, which are found in household products, such as detergents, toothpaste and shampoo.\u00a0These chemicals are essentially what keep your lemon-scented laundry looking super fresh, and your teeth sparkling. And importantly, they absorb ultraviolet light, causing them to glow in the dark.\u00a0The team used tampons to detect pollutants at several surface water outlets connected to local rivers and streams.\u00a0This pollution, they say, is resulting from faulty sewer connections, which is leading to waste water from houses being prematurely discharged into waterways, rather than being sent to treatment plants. \u00a0\"The main difficulty with detecting sewage pollution by searching for optical brighteners is finding cotton that does not already contain these chemicals. That's why tampons, being explicitly untreated, provide such a neat solution,\" said lead researcher David Lerner in a press release.\n\"Our new method may be unconventional \u2013 but it's cheap and it works.\"The team is trying to locate housing developments where sewage pipes are incorrectly linked to the surface water network, resulting in pollution. This is difficult because the discharges are intermittent and often invisible. \u00a0\"Often the only way to be sure a house is misconnected is through a dye test \u2013 putting dye down a sink or toilet and seeing where the coloured water appears in the sewer,\" said Lerner.\u00a0But he says this is impractical for water companies, as it's costly and time-consuming. He says the tampon test could offer a low-cost solution to detect pollution, and to work backwards to pinpoint faulty sections of the sewage infrastructure, or specific houses that need to be inspected.\u00a0In their lab experiments, they found that after submerging a tampon for five seconds in a solution containing just 0.01ml of detergent per litre of water - a concentration 300 times less than what's expected in waste water pipes - they were able to immediately identify optical brighteners. And these chemicals continued to be visible for up to 30 days afterward.\nThe team then headed outside. They suspending tampons for three days in 16 surface water outlets, which ran into streams and rivers in Sheffield, UK. When they tested the tampons under UV light afterward,\u00a0nine of them glowed, confirming the presence of optical brighteners and sewage pollution.With the help of a local water company, the team followed the pipe network back from four of the nine polluted outlets they identified. They dipped tampons at each of the manholes along the pipeline to try to figure out where the sewage was entering the system, and were able to locate several housing developments that needed a more detailed inspection.Their results were published in the\u00a0Water and Environment Journal.The team is now conducting a larger-scale study with their glowing tampons. We wish them luck"
        ]
    },
    "1302": {
        "gold_standard": [
            "Scientists have built a tiny, long-term memory cell that can both store and process information at the same time, just like the human brain. This is one of the first multi-state electronic memory cells, and it represents a crucial step towards building a bionic brain.\nNot only does this new cell - which is 10,000 times thinner than a human hair - open up the potential to store and process way more data than ever before, scientists are even more excited about the fact that it has 'memristive' abilities. This means that it's able to retain remember and be influenced by information that has previously been stored on it - something that our current storage devices aren't capable of.\"This is the closest we have come to creating a brain-like system with memory that learns and stores analog information and is quick at retrieving this stored information,\" project leader Sharath Sriram, from RMIT University in Australia said in a press release.\u00a0\"The human brain is an extremely complex analog computer \u2026 its evolution is based on its previous experiences, and up until now this functionality has not been able to be adequately reproduced with digital technology.\"The cell's new abilities add another dimension beyond the on/off memory cells we currently use to store our data on conventional devices, such as USBs, which are only capable of storing one binary digit (either a 0 or a 1) at a time. The researchers are comparing this to the difference between a regular light switch, which either turns the light on or off, and a dimmer switch, which gives you access to all the shades of light in-between.\"It can give you much more flexibility in terms of what information you store and what functionality you get,\" one of the researchers, Hussein Nili, told Jessica Kidd over at ABC News.\nPublishing in Advanced Functional Materials, the researchers explain that the cells are made out of a functional oxide material in the form of an ultra-thin film. The team created the material last year, and demonstrated that it was highly stable and reliable. But they've now successfully introduced controlled defects into the film, which allow the cell to be influenced by previous events.\"We have now introduced controlled faults or defects in the oxide material along with the addition of metallic atoms, which unleashes the full potential of the 'memristive' effect - where the memory element's behaviour is dependent on its past experiences,\" Nili explained in the release.All this means that the cells could one day be used to build an artificial system that mimics the extraordinary abilities of the human brain, which is extremely fast, requires very little energy input, and has almost limitless memory storage. While the benefits to artificial intelligence and computing are obvious, such a 'bionic brain' could also greatly help human health by allowing researchers to create and study diseases such as Alzheimer's and Parkinson's outside of the body.\"In terms of those diseases, there are two problems: it is very hard to read what is going on inside a live brain, and the ethical aspect - you cannot experiment on live subjects without repercussions,\" Nili told Ariel Bogle from Mashable. \"If you can have a bionic brain and you can replicate those kinds of [diseased] brains \u2026 it will make research much easier and accessible.\"We're pretty excited to see what these little cells can do"
        ]
    },
    "1338": {
        "gold_standard": [
            "The dinosaur Anchiornis (left), and a modern bird called the tinamou from Mexico, Central America, and South America . Credit: John Conway (right)\nIn an effort to gain a better understanding of how avian beaks evolved, scientists in the US have altered the DNA of chicken embryos, causing them to grow the broader, more robust snouts of their ancient ancestors. By figuring out the genetic requirements of transitioning from one type of snout to another, the team hopes to explain how one of the most specialised appendages in the animal kingdom came to be.\n\"The beak is a crucial part of the avian feeding apparatus, and is the component of the avian skeleton that has perhaps diversified most extensively and most radically - consider flamingos, parrots, hawks, pelicans and hummingbirds, among others,\" one of the team, palaeontologist and developmental biologist, Bhart-Anjan Bhullar from Yale University, said in a press release. \"Yet little work has been done on what exactly a beak is, anatomically, and how it got that way either evolutionarily or developmentally.\"While the likes of 'traditional' dinosaurs such as\u00a0T.rex, Triceratops, and the Velociraptor went extinct 65 million years ago due to a colossal impact from an asteroid, so-called avian dinosaurs managed to survive to this very day by evolving into modern birds. The fossil record shows that 150 million years ago, dinosaurs made a very gradual but clear transition into birds as we know them, with the appearance of aerodynamic feathers instead of insular or decorative fluff, wings instead of digits, and beaks instead of muzzles.\u00a0Looking at what makes beaks so distinct from snouts - elongated, sharp, pointy-ended - scientists have suggested that they evolved to give the earliest birds better grasping and riffling abilities, in lieu of similar qualities in their hands and feet. \"The beaks help make up for the dinosaurs' grasping arms, which evolved into wings, giving them the ability to peck at food such as seeds and bugs,\" says Charles Choi at LiveScience.After having spent time analysing and comparing the skeletons and individual bones of modern species of birds, extinct birds, bird-like dinosaurs, and distant reptilian relatives such as alligators and turtles, Bhullar and his team looked for genetic differences across the four groups.\n\"The researchers focused on two genes that help control the development of the middle of the face,\" Choi reports. \"The activity of these genes differed from that of reptiles early in embryonic development. They developed molecules that suppressed the activity of the proteins that these genes produced, which led to the embryos developing snouts that resembled their ancestral dinosaur state.\"By modifying the proteins that are produced by these particular genes - rather than modifying the genes themselves - the team was able to control the growth of the chickens' beaks. Describing their experiment in the journal Evolution, they say that instead of growing regular beaks, the modified chicken embryos developed wide snouts, with a blunt, rounded end, like an Archaeopteryx's, except with no teeth.While they decided not to let them hatch, Bhullar told LiveScience that they were healthy enough to survive if they did. \"They actually probably wouldn't have done that badly if they did hatch,\" said Bhullar. \"Mostly, though, we were interested in the evolution of the beak, and not in hatching a 'dino-chicken' just for the sake of it.\"As Choi points out at LiveScience, the results are intriguing because these aren't genetically modified chickens - they've just had certain proteins altered in order to completely change the way their skulls developed. And if such a relatively small change in the lab can have a significant effect on the physicality of these unborn organisms, it hints at the small series of evolutionary changes that could have occurred hundreds of millions of years ago to facilitate the transition from dinosaurs to bird-like dinosaurs, and then from bird-like dinosaurs to birds as we know them today.Who knows, maybe one day science will get crazy - and ethically ambiguous - enough to let 'dino-chicks' out of their eggs"
        ]
    },
    "1377": {
        "gold_standard": [
            "Over the past 20 years, the rates of autism spectrum disorder have been steadily climbing in developing countries, with a reported 30 percent increase in the US in just two years. But scientists have struggled to work out what's behind this epidemic, and now a new study suggests that we may have been looking in the wrong places. In fact, the epidemic might not exist at all.\nA study of more than one million children in Sweden has shown that, over the 10-year period from 1993 to 2002, the number of autism spectrum disorder diagnoses increased significantly (just like it did in the US), but the number of patients who actually displayed symptoms remained stable.This suggests that, rather than being in the middle of an 'autism epidemic', there might be a range of factors that are simply causing us to diagnose the disorder more often - something that's previously been suggested, but has been hard to test.To investigate further, researchers from the University of Gothenburg in Sweden looked at two datasets - one that involved a comprehensive study of nearly 20,000 twins, and one that involved more than one million children, all born in Sweden between 1993 and 2002.They then contacted the parents to find out whether their children showed any symptoms associated with autism. The researchers found that, surprisingly, the number of children who met the criteria for having an autism spectrum disorder remained the same over the 10-year study period. Despite the fact that the official prevalence of children diagnosed with autism had gone up.\nAfter lengthy analysis of the data, the researchers\u00a0published their findings in the new issue of the\u00a0British Medical Journal.\u00a0The results suggest that it's administrative changes, not an increase in the prevalence of the condition, that's pushing diagnoses up. Earlier this year, a Danish study came to a similar conclusion, suggesting that almost two-thirds of the increase in autism diagnoses in Denmark were due to the way the disorder is diagnosed and monitored.If scientists hadn't already put to bed the myth\u00a0that vaccines and autism are linked, this new research could help put the nail in the coffin.However, we may already have taken a promising step towards reducing over-inflated autism rates. At the start of last year, the diagnostic criteria changed, and it's predicted that diagnoses may drop as a result.While the Swedish researchers are convinced that the prevalence of autism spectrum disorders isn't on the rise, they also think we shouldn't waste too much time and money trying to figure out what was causing the perceived epidemic.\n\"The research and clinical resources currently devoted to dealing with these problems relate to the possibly mistaken notion that there is an actual increase,\" they write in the\u00a0British Medical Journal.\u00a0Instead, they say that funds would be better spent helping to treat people who have a range of intellectual or developmental disabilities. As Russell Saunders reports for The Daily Beast: \"However symptoms are classified and defined, it will be no less important for those with special needs to get the services to help them.\"Hopefully this new research won't take anything away from those with autism spectrum disorder, but will allow doctors and researchers to focus more time and energy working with those who need a little extra support"
        ]
    },
    "1403": {
        "gold_standard": [
            "Scientists have discovered that a particular type of enzyme can cut away antigens in blood types A and B, to make them more like Type O - considered the 'universal' blood type, because it's the only type that can be donated to anyone without the risk of provoking a life-threatening immune response.\nThe team, from the University of British Columbia of Canada, worked with a family of enzymes called 98 glycoside hydrolase, extracted from a strain of Streptococcus pneumoniae. Over many generations, they were able to engineer a super high-powered enzyme strain that can very effectively snip away blood antigens where previous generations of the enzyme struggled. \"A major limitation has always been the efficiency of the enzymes,\" one of the team, Stephen Withers, said in a press release. \"Impractically large amounts of enzyme were needed.\"Getting the right type of blood when you need it is crucial, and it has to do with the different types of residue that can accumulate the surface of red blood cells. Both blood types A and B have this residue - A has an N-acetylgalactosamine residue, and B has a galactose residue - and Type AB has a mixture of both. Only Blood Type O is free from this residue, which means it can be received by any patient, no matter what type they're carrying.Withers and his team managed to create their 'mutant' enzyme strain using a technology called directed evolution, which allows them to insert many different types of mutations into the gene that codes for it, and by progressively selecting strains that are the best at snipping away the blood antigens, were able to create an enzyme that's 170 times more effective at it than its parent strain. They published their results in the Journal of the American Chemical Society"
        ]
    },
    "1442": {
        "gold_standard": [
            "Researchers from the Faculty of Science, University of Technology Sydney (UTS Science) have created a material that can stay cooler than the ambient air temperature, even in the height of Australian summer. And it could help to greatly reduce cooling costs and the environmental impact of air-conditioning.\nThe roofing material is made from stacked polymers on top of a thin silver film, and only absorbs an incredible 3 percent of sunlight. Impressively, it also radiates heat out at specific infrared wavelengths that aren't absorbed by the atmosphere - allowing it to beam the heat directly into space.\"We demonstrate for the first time how to make a roof colder than the air temperature around it, even under the most intense summer conditions,\" one of the lead researchers, Geoff Smith,\u00a0told the press.\u00a0\"Roofs heat up by absorbing sunlight, so darker roofs can get very hot. Even white roofs still absorb enough sunlight to warm up by 9 degrees Celsius to 12 degrees Celsius.\"Scientists have been working for years to create increasingly more heat-repellant materials to cover our houses with, but they've struggled to find anything that approaches 100 percent solar reflectance.\u00a0\"This new surface, however, stayed 11 degrees or more colder than an existing state-of-the-art white roof nearby,\" Smith added.\u00a0Infrared image of the new material (purple) on top of a regular white roof. Credit: UTS ScienceEven better, the materials used to create the demo-roof are already commercially available, and so far seem to be suited to creating basic roofing, which means they could easily be integrated by the construction industry.\nThe team has tested the roof on the top of the UTS Science building in Sydney, which is on a busy road and has no cover from the hot summer sun.\u00a0Despite the conditions, they showed that the roof was able to stay significantly colder than the air around it, even in direct summer sunlight and when it became covered with traffic-produced dirt and grime. The results have been published open access in Advanced Science.And while its energy-saving abilities overall haven't been tested as yet, Smith believes that it could substantially help to reduce the environmental costs of cooling.\"Cool roofing reduces the severity of the urban heat island problem in towns and cities and helps eliminate peak power demand problems from the operation of many air conditioners,\" he said.\u00a0\"The added feedback benefits from cool roofs are not yet widely appreciated, but recent reports have shown they are substantial. Examples include ventilation with cooler air and higher performance of rooftop air-conditioning installations.\"\u00a0We're pretty excited about a world where our homes are kept cool by their roofs, rather than electricity-guzzling air-conditioners. Someone get the technology commercialised, ASAP.Love science? Find out more about the research happening at UTS Scienc"
        ]
    },
    "1466": {
        "gold_standard": [
            "Doctors have revealed the case of an Adelaide women who ended up in hospital after she spent hours squatting in skinny jeans while helping a relative move house.The blood supply to the 35-year-old's leg was dangerously reduced. She had numbness in her feet, making it so difficult to walk that she fell and couldn't get up.\nThe doctors found damaged muscle and nerve fibres in her lower legs as a result of prolonged compression from the tight pants.The case study, reported by Karmen Wai and colleagues at the Royal Adelaide Hospital, is published in the Journal of Neurology Neurosurgery and Psychiatry.The woman, who had been emptying cupboards, said she recalled the skinny jeans feeling increasingly tight and uncomfortable as the day wore on.Later that evening, she tripped. Unable to get up, she spent several hours lying on the ground before she was found.Her calves were so swollen her jeans had to be cut off. She couldn't move her ankles or toes properly and had lost feeling in her lower legs and feet.The doctors say the jeans had prompted the development of compartment syndrome \u2014 reduced blood supply to the legs, causing muscle swelling and compression of nerves.\nShe was put on an intravenous drip. Four days later she could walk unaided again and was discharged from hospital.Previous reports of injuries from tight jeans have been limited to sores on the thighs.This article was originally published by Business Insider"
        ]
    },
    "1489": {
        "gold_standard": [
            "This article was written by Giuliana Mazzoni from the University of Hull in the UK, and was originally published by The Conversation.Urging a depressed person to stay positive by remembering the good things in life is unlikely to be helpful advice. That is because depression blocks access to happy memories. But what if we could somehow artificially recreate such memories to allow for some more positive thinking? A study suggests that this is indeed possible - at least in rats.\nSurprisingly, the psychology and physiology of rodents is not so distant from our own. And if the same effect could be observed in humans, it might help open depressed individuals up to positive general interpretation of life experiences that make it possible to lift the dark veil of depression.The brain and depressionClinical depression, which is different from a temporary bout of sadness, is a rather common psychopathological disorder characterised by persistent negative moods, feelings of sadness, loss of interest and motivation. It has negative consequences on sleep and affects many aspects of an individual's life, including what would otherwise be rewarding behaviours - like eating.In humans it affects both adults and children, but general behaviour consistent with depression can be observed in animals. This has limits of course. For example, human depression is characterised by hopelessness and suicidal thoughts, which cannot be detected in animals. However, loss of interest is present in both. In rodents, more specifically, loss of interest can be easily detected by measuring sucrose preference - depressed animals lose interest in sugar.\nAnimal models for depression are extremely helpful in trying to understand biological, physiological and genetic bases of this pathology. The new research does shows that the artificial reactivation of brain cells spontaneously active during positive experiences, substantially decreases depression (anhaedonia) in rats.\u00a0A cross-section of a positive memory. Seen here is the hippocampus; the brain cells glowing in red were previously active during the encoding of a positive memory. Credit: Steve Ramirez The researchers used a method called optogenetics, in which specific brain cells are genetically sensitised to light and then activated using pulses of light, in the experiment. Light-sensitive molecules were in this way used to detect which brain cells were activated by a certain experience in the animals. The area of the brain chosen by the researchers to be tagged by these molecules is the hippocampus, more specifically a subarea of the hippocampus called the dentate gyrus. This is linked to the formation of memories and to responses of avoidance and of appetite, and thus records positive and negative experiences.\nThe researchers first induced anhaedonia in male rodents by exposing them to repeated stress by making it impossible for them to move, such as hanging them by the tail. They then exposed them to three types of experiences: positive (being put in a cage with a female), negative (being immobilised in a cage) or neutral (being put in an empty cage) and recorded which brain cells were active during these experiences.Lori Leaumont/FlickrThe researchers then used pulses of light to activate the cells they had pinpointed. They found that only the reactivation of cells in the dentate gyrus that were active during positive experiences (but not the reactivation of those active during negative or neutral experiences) made rats show interest in sugar again, meaning they had been relieved from depression.\nNext stepsWhat's so interesting about this, particularly for a memory researcher, is that it was the artificial reactivation of the cells (the reactivation of the positive memories) and not re-exposure to these positive experiences that did the trick.In other words, being put again in a cage with a female did not lift the rats from depression. One can speculate that being put again in a cage with a female does not necessarily reactivate a memory, as it can be encoded as a new experience. It seems, then, that it is the reactivation of the neural network linked with a positive past experience, and not the positive experience in itself, that helps.But can these results be extended to humans as they are? Not immediately, of course. However there is hope, as for example clinical studies have shown that therapeutic cognitive-behavioral interventions using positive mental imagery or the restructuring of how past experiences are interpreted, might be of help. The link between personal memories and depression is also currently experimentally investigate"
        ]
    },
    "1552": {
        "gold_standard": [
            "Journal of Cognitive Neuroscience If you've ever felt the obsessive need to check Facebook - usually while you're putting off working or doing something productive - then you'll be interested in the findings of a new study from the University of California, Los Angeles. Researchers have found that our brains have an in-built need to be social, and Facebook scratches that mental itch.\nThe team of UCLA neuroscientists discovered that even during quiet moments, our brains are preparing to be socially connected to other people, craving the next like, timeline post or message. \"The brain has a major system that seems predisposed to get us ready to be social in our spare moments,\" Matthew Lieberman, who headed up the research, said in a press release. \"The social nature of our brains is biologically based.\"The new study builds on discoveries made in the 1990s: that there are regions of the brain that become more active when we're resting. Until now, scientists have known little about what that brain activity is or what it's leading to - but it appears our innate need to interact with others is at the centre of it, our need to \"see the world through a social lens\" in the words of the study (sounds like Facebook to us).By tracking the brain activity of 21 volunteers using functional magnetic resonance imaging (fMRI), researchers found a link between the brain activity when resting and when looking at a series of images and captions that made them think about other people's emotions. These activity patterns disappeared when participants were asked to focus on a maths problem or to think about more physical topics.It appears that during our downtime, the brain switches on the dorsomedial prefrontal cortex to prepare for social engagement. Subsequent engagements are then faster and more fluid because we're prepared for them - Lieberman calls the dorsomedial prefrontal cortex the \"CEO of the social brain\" and it's also active when we're dreaming.\n\"[This part of the brain is] getting us ready to see the world socially in terms of other people's thoughts, feelings and goals,\" adds Lieberman. \"That indicates it is important; the brain doesn't just turn systems on. We walk around with our brain trying to reset itself to start thinking about other minds.\"Which brings us back to Facebook: it would seem that the social network Mark Zuckerberg created is built to fit the natural rhythms of the brain, which may explain why more than a billion people have signed up to use it.\"When I want to take a break from work, the brain network that comes on is the same network we use when we're looking through our Facebook timeline and seeing what our friends are up to,\" explains Lieberman. \"That's what our brain wants to do, especially when we take a break from work that requires other brain networks.\"The research has been published in the Journal of Cognitive Neuroscienc"
        ]
    },
    "1590": {
        "gold_standard": [
            "This article was written by Mark Lorch from the University of Hull, and was originally published by The Conversation.Did you know that the discovery of a way to make ammonia was the single most important reason for the world's population explosion from 1.6 billion in 1900 to 7 billion today? Or that polythene, the world's most common plastic, was accidentally invented twice?\nThe chances are you didn't, as chemistry tends to get overlooked compared to the other sciences. Not a single chemist made it into Science magazine's Top 50 Science stars on Twitter. Chemistry news just don't get the same coverage as the physics projects, even when the project was all about landing a chemistry lab on a comet.So the Royal Society of Chemistry decided to look into what people really think of chemistry, chemists and chemicals. It turns out most people just don't have a good idea of what it is chemists do, or how chemistry contributes to the modern world.Andy Brunning/[Compound Interest]This is a real shame, because the world as we know it wouldn't exist without chemistry. Here's my top five chemistry inventions that make the world you live in.\n1. PenicillinWellcome ImagesThere's a good chance that penicillin has saved your life. Without it, a prick from a thorn or sore throat can easily turn fatal. Alexander Fleming generally gets the credit for penicillin when, in 1928, he famously observed how a mould growing on his petri dishes suppressed the growth of nearby bacteria. But, despite his best efforts, he failed to extract any usable penicillin. Fleming gave up and the story of penicillin took a 10-year hiatus. Until in 1939 it took Australian pharmacologist Howard Florey and his team of chemists to figure out a way of purifying penicillin in useable quantities.\nHowever, as World War II was raging at the time, scientific equipment was in short supply. The team therefore cobbled together a totally functional penicillin production plant from from bath tubs, milk churns and book shelves. Not surprisingly the media were extremely excited about this new wonder drug, but Florey and his colleagues were rather shy of publicity. Instead Fleming took the limelight.Full-scale production of penicillin took off in 1944 when the chemical engineer Margaret Hutchinson Rousseau took Florey's Heath Robinson-esque design and converted it into a full-scale production plant.2. The Haber-Bosch processeutrophication&hypoxia/FlickrNitrogen plays a critical role in the biochemistry of every living thing. It is also the most common gas in our atmosphere. But nitrogen gas doesn't like reacting with very much, which means that plants and animals can't extract it from the air. Consequently a major limiting factor in agriculture has been the availability of nitrogen.\nIn 1910, German chemists Fritz Haber and Carl Bosch changed all this when they combined atmospheric nitrogen and hydrogen into ammonia. This in turn can be used as crop fertiliser, eventually filtering up the food chain to us.Today about 80 percent of the nitrogen in our bodies comes from the Haber-Bosch process, making this single chemical reaction probably the most important factor in the population explosion of the past 100 years.3. Polythene - the accidental inventionDavidd/FlickrMost common plastic objects, from water pipes to food packaging and hardhats, are forms of polythene. The 80m tonnes of the stuff that is made each year is the result of two accidental discoveries.\nThe first occurred in 1898 when German chemist Hans von Pechmann, while investigating something quite different, noticed a waxy substance at the bottom of his tubes. Along with his colleagues he investigated and discovered that it was made up of very long molecular chains which they termed polymethylene. The method they used to make their plastic wasn't particularly practical, so much like the penicillin story, no progress was made for some considerable time.Then in 1933 an entirely different method for making the plastic was discovered by chemists at, the now defunct chemical company, ICI. They were working on high-pressure reactions and noticed the same waxy substance as von Pechmann. At first they failed to reproduce the effect until they noticed that in the original reaction oxygen had leaked into the system. Two years later ICI had turned this serendipitous discovery into a practical method for producing the common plastic that's almost certainly within easy reach of you now.4. The Pill and the Mexican yamKatja Schulz/FlickrIn the 1930s physicians understood the potential for hormone-based therapies to treat cancers, menstrual disorders and of course, for contraception. But research and treatments were held back by massively time-consuming and inefficient methods for synthesising hormones. Back then progesterone cost the equivalent (in today's prices) of $1,000 per gram while now the same amount can be bought for just a few dollars. Russel Marker, a professor of organic chemistry at Pennsylvania State University, slashed the costs of producing progesterone by discovering a simple shortcut in the synthetic pathway. He went scavenging for plants with progesterone-like molecules and stumbled upon a Mexican yam. From this root vegetable he isolated a compound that took one simple step to convert into progesterone for the first contraceptive pill.\n5. The screen you are reading onIan T. McFarland/FlickrIncredibly, plans for a flat-screen colour displays date back to the late 1960s! When the British Ministry of Defence decided it wanted flat-screens to replace bulky and expensive cathode ray tubes in its military vehicles. It settled on an idea based on liquid crystals. It was already known that liquid crystal displays (LCDs) were possible, the problem was that they only really worked at high temperatures. So not much good unless you are sitting in an oven.In 1970 the MoD commissioned George Gray at the University of Hull to work on a way to make LCDs function at more pleasant (and useful) temperatures. He did just that when he invented a molecule known as 5CB). By the late 1970s and early 1980s, 90 percent of the LCD devices in the world contained 5CB and you'll still find it in the likes of cheap watches and calculator. Meanwhile derivates of 5CB make the phones, computers and TVs possible"
        ]
    },
    "1595": {
        "gold_standard": [
            "San Andreas is currently packing out cinemas with a rather outlandish account of what could (but probably won't) happen in the event of a huge earthquake in California - but back in the real world, scientists say the tsunami threat to the west coast of the United States could be greater than was previously thought.\nGeologists have pinpointed a number of major faults close to the southern California coast that are capable of producing magnitude 7.9 to 8.0 earthquakes.\u00a0The newly explored faults highlighted by researchers are not quite on the scale of the San Andreas fault, but still have the potential to send tsunamis crashing into San Diego and Los Angeles.\u00a0\"There is no need to panic and worry but you should be prepared now that we know there is a local tsunami potential,\" lead researcher and geologist Mark Legg, from consulting firm Legg Geophysical, told CBS News. \"We know in the recent past, probably in the last few hundred years, there have been large magnitude 7-plus earthquakes on these offshore faults. So we should not be surprised if we have another one.\"The last major quake generated by these particular faults was the magnitude 7 Lompoc earthquake. It hit in 1927 and created a 1.8-metre (6-foot) tsunami about 160 km west of Santa Barbara. Unfortunately, due to the high cost of mapping the ocean floor, scientists don't know as much about these faults as they would like to, and that makes predicting when the next earthquake will hit more difficult.Geologists have known about these faults for some time, but what Legg and his team have done is study them in greater detail, and they've managed to spot evidence of upward and sideways movement. The researchers measured seafloor depth along a 4,500 km-stretch of the Santa Cruz-Catalina Ridge Fault and the Ferrelo Fault. Movement of the Earth's Pacific plate - sliding away from California - against the North American plate has caused these faults as well as the more well-known San Andreas one.As the faults do not run straight through cities or populated areas, they tend to attract less attention, but Legg says a tsunami could still wreak havoc on cities, beaches and ports along the Californian coast. \"We should not ignore the faults offshore,\" Legg says. \"Yes, we should put our priorities on the faults onshore that go directly through cities and have the highest slip rates and most likely to produce large earthquakes \u2026 But the offshore faults are a major player in the movement of the Pacific plate along the North American coast.\"The group's findings have just been published in the\u00a0Journal of Geophysical Research. If you do catch San Andreas and the Rock in a movie theatre this week, remember that it's not quite as fictionalised as you might think"
        ]
    },
    "1642": {
        "gold_standard": [
            "Despite all the glitz and glamour on show in glossy magazine ads, it seems no amount of spin can make the claims of cosmetic advertising as scientifically grounded as the beauty industry would like us to believe. A new US study of magazine advertising in titles including Vogue, Glamour,\u00a0and Marie Claire has found that the majority of cosmetic product claims appear to be bogus, with a significant portion even constituting \"outright lies\".\nResearchers from Valdosta State University assessed 289 full-page cosmetic ads from the pages of seven magazines published in April 2013, categorising the claims made by the ads into various categories. These declarations included environmental claims (eg. \"no testing on animals\"), endorsement claims (eg. \"recommended by dermatologists\"), and scientific claims (eg. \"clinically proven\"). Ads were sourced from a number of product categories within female cosmetics, including make-up, facial skincare, body products, fragrances, and others.Once categorised by the researchers, the cosmetic claims made by the advertisements were evaluated by a panel of judges and classified according to four scales of truthfulness: outright lie, omission, vague, and acceptable.Although many of us are already inclined to think skeptically about the claims made by cosmetic manufacturers, the results from the study are still pretty mind-blowing. Ultimately, only 18 percent of the claims made in the ads were found to be acceptable by the judges, with more than 4 out of 5 product claims being seen as vague or untruthful.In terms of scientific claims made by products, just 14 percent were seen as being acceptable. Environmental claims were accepted with less cynicism, although even then, only half such claims were found to be acceptable. Performance claims also fared poorly. About one in four performance-based claims were found to be acceptable, but almost as many were considered to be outright lies (23 percent)"
        ]
    },
    "1666": {
        "gold_standard": [
            "Hate the way you look in all your photos? Sorry, but that might actually be your face, new research suggests. In fact, the study shows that we're so terrible at recognising what we really look like in images, we'd\u00a0be better off letting a stranger choose our next profile pic or passport photo.\nScientists from the University of New South Wales (UNSW) in Australia have found that people are 7 percent worse than a stranger at ranking which of their photos look the most like them.\u00a0The research was intended to provide insight into the challenges of photo identification in situations such as border control, but it might also shed some light on why it's so hard to find a picture we like of ourselves - apparently, we're just deluded about how the rest of the world sees us.\"It seems counter-intuitive that strangers who saw the photo of someone's face for less than a minute were more reliable at judging likeness,\" lead researcher Davie White said in a press release. \"However, although we live with our own face day-to-day, it appears that knowledge of one's own appearance comes at a cost. Existing memory representations interfere with our ability to choose images that are good representations or faithfully depict our current appearance.\"White's team had previously shown that passport controllers are no better than university students when it comes to identifying people based on their photo, and that the ability to identify a face varies widely between different photos. But this time they decided to take the research further, and find out how well people could recognise their own face.To do this, they asked more than 130 undergraduate students to download 10 photos of themselves from Facebook, and then rate them in order of which looked the most to least like them in real life.\u00a0They then got the students to film a one-minute webcam video of their face, and took two still photos of them - one smiling, and one neutral.\nBased on this, the researchers asked 16 strangers to rate the same Facebook photos. They also had another group of 73 strangers complete an online face-matching test to impartially rank which photos looked the most like the participants.The researchers found that not only did strangers rank the 10 profile pictures in a very different order to the participants, but their results were actually 7 percent more accurate when compared to the online face-matching test.So why are strangers better at identifying your face than you are? This is because of something called the mere-exposure effect, which\u00a0is where we grow to prefer something the more familiar we are with it. It's the reason we hate the sound of our own voice played back - we're so used to hearing it reverberating inside our head, that its real tone seems wrong to us - and studies have shown the effect applies to everything from art and literature to music.When\u00a0it comes to the way we look, the appearance we're most familiar with is the one we see in the mirror every day, where our features are reversed. That doesn't mean we look better or worse in real life, just that we're going to prefer our reflection - which also explains why people often favour their reverse camera selfies over photos someone else has taken of themselves.\nInterestingly, the research also found that people were better at assessing whether someone looked like their photo when they smiled.\u00a0\"Given that faces are generally pictured smiling, and these images are rated as being more like familiar faces, it may be beneficial to permit expression in passport photographs,\" said White. The results have been published in the\u00a0British Journal of Psychology.So now we have scientific evidence that we're terrible judges of what we really look like and when we look best, maybe we'll finally give up on all the duck-face selfies\u2026 please?Find out more about the research happening at UNSW Scienc"
        ]
    },
    "1915": {
        "gold_standard": [
            "Surgeons in the UK have implanted an 8-inch (20-cm) 'bionic penis' into\u00a043-year-old Mohammed Abad, a Scottish man who lost his own penis and left testicle in a car accident when he was six. And although headlines are calling this a world-first operation, doctors claim that it's actually far more common than people think.\nAbad's new penis was constructed over a three-year period using his own skin grafts, and it comes with a mechanical interior that's connected to a fluid pouch. The whole thing is controlled by an on/off button located on Abad's scrotum that pumps fluid into the tube on command to produce an erection. According to the surgeons involved, its function is complete enough for Abad to be able to father a child with his still-intact right testicle.\"When you want a bit of action, you press the 'on' button,\" Abad told The Sun. \"When you are finished you press another button. It takes seconds. Doctors have told me to keep practising.\" Unfortunately, the implant doesn't respond to sexual stimulus.As a child, Abad was hit by a car and dragged 180 metres, effectively ripping off his left testicle and penis. The new, impressively proportioned model was implanted during a marathon 11-hour operation at University College London.But we shouldn't get too caught up in the hype of this being the world's first 'bionic penis', as Elizabeth Kavaler,\u00a0a urologist at Lenox Hill Hospital in New York, told Rachael Rettner from Live Science. \"It's not a 'bionic penis'; it's a penile implant,\" she said. \"We do this all the time.\"\nIn fact, a\u00a0study published in July stated that around 53,000 men in the US alone have received a penile implant as a result of erectile dysfunction, which can often be caused by prostate removal after cancer, or pelvis and penis trauma. What's different about this case is that Abad required his entire penis to be replaced, not just the inner machinery, so the surgeons took skin grafts from his arm to fashion the outside skin.Still, it's a pretty impressive operation that will allow Abad to experience an erection and have sex for the first time. He can now even start thinking about having a family of his own, once he masters the implant.Last year, a 21-year-old man from South Africa received the first successful penis transplant, and in June the surgeons responsible announced that he was about to become a father. Let's hope Abad has similar good luck"
        ]
    },
    "1741": {
        "gold_standard": [
            "In many cultures, a kiss is as familiar as a handshake and wouldn't raise any eyebrows in the street. But in some parts of the world, the action is considered awkward or even unpleasant - which is something to bear in mind if you get caught up in a holiday romance over the summer.\nA new study in the American Anthropologist Journal looked at 168 different cultures across a wide range of geographical locations to track current attitudes to smooching. In only 46 percent of these cultures is kissing used as a sign of romantic affection, so relationships in more than half of these areas are kissing-free (kissing in this case defined as deliberate and prolonged contact with the lips).The study found plenty of variation across the globe: the habit of kissing was observed in seven out of 10 cultures in Europe, 18 out of 33 cultures in North America, four out of 33 cultures in South America, and 10 out of 10 of the cultures studied in the Middle East (obviously the place to be if you enjoy locking lips with your partner).The researchers say that there's little evidence for 'romantic-sexual' kissing in hunter-gatherer or forager communities, and the suggestion is it's not something our ancestors particularly went in for. According to the report, it's \"Western ethnocentrism\" that's \"driving the common misconception that romantic-sexual kissing is [near] universal\".So why do we do it? The theories include the idea that it was originally a way of assessing a potential mate's health and compatibility, or that it's a natural way of spreading germs and thus increasing resistance to them. Class could be a factor too: based on the findings, it's possible that \"the emergence of the romantic-sexual kiss may coincide with other factors, such as oral hygiene or the rise of elite social classes that value self-control of affect and emotional displays\",\u00a0say the researchers"
        ]
    },
    "1791": {
        "gold_standard": [
            "In the first study of its kind, a team of scientists at Carnegie Mellon University have upended the common notion that having more sex will make you happier.In fact, more sex might even generate unhappiness, George Leowenstein, a professor of economics and psychology at Carnegie Mellon, and his colleagues report in their recent paper.\nSeveral studies over the last decade have found evidence to suggest that sex is directly linked with happiness, so that more sex means greater happiness. One study even found that changing the amount of sex you had from once a month to once a week would give you the same amount of happiness as receiving an extra US$50,000.However, what these studies missed and what's causing some\u00a0misconceptions about sexual frequency and joy, Leowenstein recently told\u00a0The New York Times, was to determine which element - sex or happiness - was the cause and which was the effect. Not only that, other factors besides sex, such as income, location, or age, could be better gauges of what makes us happy.\"Although it seems plausible that sex could have beneficial effects on happiness, it is equally plausible that happiness affects sex,\" the team wrote in their paper. \"\u2026or that some third variable, such as health, affects both.\"To help settle this riddle, the team carefully designed an experiment that would clearly determine, once and for all, if more sex causes greater happiness.\nA straightforward experiment to solve a confusing riddleThe experiment was straightforward: Measure how happy couples were with their current sex schedules. Then, split them into two groups and ask one group to have more sex (twice as much, to be exact) and ask the other group to change nothing about their sex live. Finally, compare their how happy they were afterward. (As part of the experiment, for example, couples having sex three times a week had sex six times a week; those having sex once a month had it twice a month).A total of 64 adult couples volunteered. Each pair was legally married and heterosexual, and all volunteers were between the ages of 35 and 65.The team asked half of the couples to double the amount of sex they were having while the other half of couples kept their normal sex schedule.\nThroughout the duration of the experiment, which lasted 90 days, both sets of couples completed the same online questionnaire at the end of each day. This questionnaire helped the researchers measure each couple's mood as well as how satisfied they were with each sexual episode - the quality of the sex.What they found surprised them. \"Contrary to what one would expect if the causal story running from sexual frequency to happiness were true,\" the team wrote in their paper, \"we observed a weak negative impact of inducing people to have more sex on mood.\"In general, the researchers found that the couples who doubled the amount of sex didn't enjoy the sex as much and were less happy overall. Although the team can only speculate as to why this was, they did answer their question: More sex does not make us happier.Moreover, the researchers stipulate that by being forced to have more sex, the selected couples actually developed, over time, less motivation to have sex. That, in turn, is what might have led to an overall downturn in the quality of their sex as well as their overall moo"
        ]
    },
    "1956": {
        "gold_standard": [
            "The genetic coding system known as DNA (deoxyribonucleic acid) stores a huge amount of data about our biological make-up on double-helix molecules - and that's led scientists to wonder whether it could be rewritten with other types of data. In theory, it could replace the storage offered by today's hard drives and servers in a microscopic space.\nNot only is that useful for the photos and music that we all store, but it could transform the way that larger companies such as Google and Facebook work. Many of the major innovations in technology today, from artificial intelligence to medical research, often rely on gigantic databases of 1s and 0s, and anything that makes these bytes easier to store is a potential game-changer.A team led by ETH Zurich's Robert Grass has just presented a proof-of-concept demonstration of how DNA data storage could potentially work. The scientists were able to encode molecules with 83 kilobytes of text taken from the 1291 Swiss Federal Charter and the 10th century Method of Archimedes. That's roughly 40 times the amount of text in this article, so it's a promising start.The coding language of nature is \"very similar\" to the computing coding language we've created for ourselves, Grass says in a press release, though there are some differences. DNA uses four chemical bases (A, T, C and G) to store data rather than two numbers (1 and 0) but both systems can expand to create combinations that store an infinite amount of data.Grass says just a fraction of an ounce of DNA molecules could store around 300,000 TB of information - that's an impressive figure, considering the largest hard drives of today top out at around 16 TB (though you can of course string many hundreds together in servers and data centres). Another advantage is the longevity of DNA, which we know can remain intact for thousands of years"
        ]
    },
    "1978": {
        "gold_standard": [
            "A new report from tech giant Samsung proposes that a fleet of roughly 4,600 micro-satellites orbiting Earth could solve our impending data crisis.\u00a0Predicting that by 2028, 5 billion Internet users around the world will be collectively chewing through at least 1 zettabyte per month - to put that in perspective, 1 zettabyte is 1,000 exabytes, 1 exabyte is 1,000 petabytes, and 1 petabyte is 1,000 terabytes - the report says we're going to have to think seriously about how we can deliver that. A constellation of tiny Internet-beaming satellites could be a viable option, it says, and Samsung could be the one to build it.\nThe report, entitled Mobile Internet from the Heavens,\u00a0describes an Internet satellite system that will avoid the latency issues of current communications satellites by being positioned much closer to Earth.\u00a0\"Most modern communications satellites live in geostationary orbit, roughly 35,000 kilometres above the surface, and this imposes a hard limit on speed due to travel time for the data transmissions,\" Graham Templeton writes for ExtremeTech. \"Samsung wants to position its constellation in Low Earth Orbit (LEO) and thus reduce this delay.\"Since the fleet of micro-satellites will be constantly moving around, with no one satellite dedicated to a particular patch of Earth, Samsung predicts that it will need about 4,600 of them to ensure constant coverage everywhere on the planet.This is not the first time a universal 'space Internet' has been proposed. In June, SpaceX's Elon Musk requested permission from the FCC to launch a constellation of Internet-beaming satellites into Low Earth Orbit for testing, and Sir Richard Branson has raised US$500 million to develop and launch his own OneWeb space telescope system by 2019.\u00a0Closer to the ground, we have Google working on making Sri Lanka the first country on Earth with universal Internet coverage via its helium ballon system, and Facebook is following close on its heals with plans to launch Internet-beaming drones"
        ]
    },
    "1984": {
        "gold_standard": [
            "New research has found that the most cost-effective way to help save 148 endangered plant and animal species in Australia's famous Lake Eyre Basin is to control the numbers of feral pigs in the area.\nTalking about species control is always controversial, but a three-year study led by the Queensland University of Technology (QUT) has shown that the strategy could help us protect native plants and animals, as well as save money, as climate change intensifies. Not only that, the researchers also suggest that the strategy would increase food production in the area by 10 percent.The Lake Eyre Basin might sound like a pretty specific region, but it covers almost one-sixth of the entire Australian continent. Stretching across the borders of New South Wales, Queensland, the Northern Territory, and South Australia, it's the world's largest internally draining lake system, and it\u00a0has a huge impact on Australia's agriculture industry and river health. Needless to say, it's pretty important to maintain the ecosystem's health.\"The Lake Eyre Basin is crucial to Australia's biodiversity - at least 65 animal species and 13 plant species are found in its iconic and threatened Mound Spring ecosystems, and other threatened species such as the Greater Bilby, Yellow-Footed Rock Wallaby also live there,\" lead researcher and ecologist Jennifer Firn said in a press release.Her team looked into which of the 11 feral animal and 12 invasive plant species in the region would be the most beneficial to control in order to protect native species. And when it comes to the most cost-effective strategy, culling feral pigs has the biggest impact, the research found.\n\"The most cost-effective measure we could take is the control of feral pigs at a cost of $2 million per annum in targeted locations across the Basin, as they have a negative impact on both native plants and animals,\"\u00a0she said. \"Managing the populations of other feral predators such as cats, dogs, and foxes follows as the best strategy for threatened mammals.\"The researchers also looked at how their strategies would work under climate change conditions predicted over the next 50 years, and found that controlling feral plants and animals will become increasingly important over the coming decades.\"Time is of the essence as we found that 29 of the 148 species are at risk of becoming extinct in the Lake Eyre Basin within 50 years if invasive plants and animals are not controlled,\" said Firn.The study also rated the benefits of their 23 different strategies based on effectiveness per dollar spent, and found that the financial benefits would be significant. \"It's been estimated feral animals and plants cost the Australian economy more than $5 billion in lost agricultural productivity each year, quite apart from the loss of our rare and unique species,\" said Firn.\n\"If we implemented our recommended strategies for the feral predators (cats, dogs and foxes) and the goats and rabbits, experts who participated in the study estimated that we could increase agricultural production by 10 percent or more,\" she added.The research has been published in\u00a0Global Change Biology, and Firn's team believes that the findings will be applicable for the whole of Australia.\u00a0But given the importance of the region, the Lake Eyre Basin is undoubtedly a pretty important place to start. Now that we know how much of a different controlling feral populations could have, the next challenge will be to find a humane and effective way to control them.Love the environment?\u00a0Find out more about ways you can help protect it by studying at QU"
        ]
    },
    "2012": {
        "gold_standard": [
            "French researchers have found a new way to levitate liquid droplets by using a stream of electricity to create a tiny cushion of plasma. In doing so, they may have also found a cheap and easy method to generate freely movable microplasma - and put on a very pretty blue light show to boot.\nWhile levitation may sound like it belongs in the realm of fantasy, scientists have actually become quite skilled at levitating small objects using sound waves and magnets. But researchers from the French Alternative Energies and Atomic Energy Commission have now devised a new method, managing to float liquid droplets using plasma.More than just a cool party trick, the new technique provides some important insight into the production of plasma. It works in a very similar way to something called the\u00a0Leidenfrost effect, where liquid droplets sitting on an incredibly hot surface begin to levitate on a hot cushion of vapour. Although you may not have heard of it before, you've probably used it without realising when you sprinkle water on your pan to see if it's hot enough to cook with - if the water droplets skitter across the pan, you're good to go, and that's the Leidenfrost effect in action.But in this experiment, instead of using a hot surface, the French team dropped watered-down hydrochloric acid, which is known for its conductive abilities, onto a metal plate and then began to run an electrical charge through it.Immediately the water in the acid solution began to break down into hydrogen and oxygen gas. At 50 volts, the bottom of the droplet began to spark and levitate slightly off the surface, with an incredibly beautiful blue glow emanating from the tiny gap in between.\nThe researchers initially thought that the drop might be floating on top of the hydrogen gas from the breakup of the water. But after further research, they found that by using electricity to make the vapour cushion instead of heat, they'd actually managed to ionise the gas into plasma.\"This method is probably an easy and original way to make a plasma,\" lead researcher and physicist Cedric Poulain said in a press release.\u00a0But he admits that this was far from the original reason for the experiment, which was more to do with simple scientific curiosity.\"We were interested in a better understanding of the boiling mechanism,\" Poulain told Chuck Bednar over at redOrbit. \"Namely, the formation of bubbles (nucleation), as well as what happens at high heat flux when suddenly all the bubbles coalesce, leading to the well-known film boiling.\"Although they weren't expecting to generate plasma at all, what surprised the team most of all was the blue light emission, seeing as they were only using a relatively low 50 volts. Poulain explains that this was caused by the tiny gap between the droplet and the metal plate, which gave rise\u00a0to the very high electric field necessary to generate a long-term and dense plasma with little energy.\nThe next step is for the team to analyse the composition of the plasma cushion, which appears to be a superposition of two types of plasma - something that scientists known very little about.\"It's very exciting,\" said Poulain of the research's unexpected turn. Even though it wasn't what they set out to do, their results could could provide some fascinating insight into the physics of plasma and potentially lead to new, inexpensive ways to form it. And if that fails, they could always just put a grape in a microwave.The research has been published in\u00a0Applied Physics Letter"
        ]
    },
    "2018": {
        "gold_standard": [
            "There's no meal more divisive than breakfast - some of us swear by it and insist that we cannot function without it, while others say they'll throw up if they're faced with anything other than coffee before 10am. (Weekends are a whole other story, everyone loves breakfast on the weekend.)\nAnd just as all of us can't agree on the virtues of breakfast, neither can researchers, it appears. It's now gotten to the point where the conventional wisdom that \"Breakfast is the most important meal of the day\" might be edited right out of the US government's official Dietary Guidelines this year, if the 2015 advisory committee takes the results of recent research into account.Late last year, researchers from Columbia University in the US compared the effects on 36 overweight participants of eating a high-fibre breakfast (oats), a breakfast with minimal fibre (frosted corn flakes), and no breakfast at 8:30am each day over a four-week period. While we should expect evidence of weight loss in the people who had breakfast and weight gain in the people who skipped it, the team found that the only change in weight was experienced by the no-breakfast group. And they ended up losing it, not gaining it.\"In overweight individuals, skipping breakfast daily for four weeks leads to a reduction in body weight,\" the team concluded in the Journal of Nutritional Science. According to Korin Miller at Yahoo News, their hypothesis is that while skipping breakfast made the participants more likely to eat bigger meals later, their bodies were still unable to make up for the lost calories in that missing meal.\u00a0In other words, guilt people into accepting breakfast into their life with lines like \"Skip Breakfast, Get Fat\", and what they're really doing is accepting more calories into their life, potentially leading to weight gain, not loss.\nSo why then do the US federal guidelines state the opposite? \"Eat a nutrient-dense breakfast,\" they advise. \"Not eating breakfast has been associated with excess body weight, especially among children and adolescents. Consuming breakfast also has been associated with weight loss and weight-loss maintenance.\"The above is scientifically backed information, of course, but what's interesting is the difference between the Columbia study and the studies that support the government recommendations.\u00a0One of the most high-profile studies that support the \"skip breakfast, get fat\" notion was conducted in 2007, and looked at more than 20,000 American men aged between 46 and 81. It found that those who ate breakfast were less likely to gain weight over time than those who skipped it. \"Our study suggests that the consumption of breakfast may modestly lower the risk of weight gain in middle-aged and older men,\" the researchers said in the journal Obesity.But the problem here is that the methodology of the study brings into question the results, as Peter Whoriskey explains at The Washington Post:\n\"The advisory committee cited this and similar research, known as 'observational studies', in support of the notion that skipping breakfast might cause weight gain. In observational studies, subjects are merely observed, not assigned randomly to 'treatment' and 'control' groups as in a traditional experiment.\"In fact, Whoriskey even points to a statistic that for observational studies in the medical field, \"over 90 percent of the claims fail to replicate\".That's where the Columbia study gains a scientific advantage over the observational ones cited by the US Dietary Guidelines, because the team behind it exercised far greater control over what could be confounding factors. \"Though small, [it] was a randomised, controlled trial, which is widely considered to be the gold standard of scientific research for its exacting results (researchers can control literally every aspect of the experiment),\" says Miller at Yahoo News"
        ]
    },
    "2020": {
        "gold_standard": [
            "Regular exercise does more than keep your muscles toned and your heart healthy: it's also likely to give you an appetite for fruits and vegetables that further improve your overall wellbeing, new research has found. The insight comes from a study of\u00a0more than 6,000 people born between\u00a01980 and 1984, which tracked their eating and exercise habits from the ages of\u00a018-22 and 23-27,\u00a0and then their eating habits alone from the ages of 27-31 years old.\nThe team from Indiana University in the US link this to a known phenomenon, known as the transfer effect, where learning new skills and improving in one area of your life automatically triggers a desire for improvements in another. In this case, exercise triggers diet, which is why you might see someone start eating more healthily not long after starting a new gym regime - even if diet changes weren't originally part of the plan.\u00a0The researchers adjusted the figures gathered by the US Department of Labor's National Longitudinal Survey of Youth 1997 to take into account differences in sex, race, education, income and body-mass index. With other factors eliminated, there was a distinct correlation: the more we exercise, the more fresh produce we eat.\u00a0Those who regularly got at least an adequate amount of exercise (defined as 30 minutes for five times or more a week) ate the most fruit and vegetables; those who exercised the least also ate the least. As the healthier respondents grew older, they ate even more fruit and veg.There are two main reasons for this, according to the academics behind the study published in the Journal of American College Nutrition. Firstly, exercising regularly and eating well both lead to the same goal of better overall health, so people are able to switch between them easily. Secondly, once someone has made exercise a habit, it no longer needs as much mental effort - that frees up the brain to start scheming about new ways to feel better. On the flip-side, a more intensive workout regime may not leave enough mental energy to focus on a healthy diet as wel"
        ]
    },
    "2039": {
        "gold_standard": [
            "In the struggle to help people give up cigarettes, scientists have tried everything from slow-release nicotine patches and gums to nicotine vaccines. But now researchers in the US have found a bacterial enzyme that devours nicotine in the bloodstream, and it could be the tool that helps people quit for good.\nThe goal is to turn the enzyme into a therapeutic drug that would be used to eat up the nicotine in a smoker's body before the chemical gets a chance to deliver that addictive feel-good hit to the brain. No nicotine high = no overwhelming biological urge to keep smoking.\"The bacterium is like a little Pac-Man,\" lead researcher Kim Janda, a chemical biologist at the Scripps Research Institute, said in a press release. \"It goes along and eats nicotine.\"So far, the enzyme, which is called NicA2, has only been trialled in the blood of mice, but the researchers are already testing its potential as a human drug.\"Our research is in the early phase of drug development process, but the study tells us the enzyme has the right properties to eventually become a successful therapeutic,\" said Janda.\nThe discovery of NicA2 couldn't have come soon enough - Janda and his team have spent the past 30 years trying to create an artificial enzyme capable of seeking out and destroying nicotine in the body. The idea was to eliminate nicotine before it could stimulate the brain's reward system, which is what keeps people hooked on cigarettes. However, making that type of enzyme in the lab proved to be a whole lot more difficut than they'd anticipated.But it turns out that such an enzyme already exists in nature - inside bacteria that live in the soil of tobacco fields. One of these bacteria,\u00a0Pseudomonas putida, uses\u00a0nicotine as its sole source of carbon and nitrogen, and NicA2 is the enzyme that helps it do this.To test whether that same enzyme might also be able to breakdown nicotine in the body, the researchers combined serum from mouse blood with a hit of nicotine equivalent to the amount you'd get from one cigarette. When they added NicA2 to this cocktail, the nicotine's half-life was cut down dramatically, from somewhere between 2 to 3 hours to 9 to 15 minutes.The team then subjected NicA2 to temperatures of 36.7 degrees Celsius (98 degrees Fahrenheit) for three weeks, and checked to see whether it was releasing any toxic byproducts as it chowed down on all that nicotine, in an attempt to figure out if it could actually work as a drug in the human body.\nThe results were all extremely encouraging, and the researchers comment that by upping the dose of NicA2, the half-life of nicotine in the bloodstream could be decreased further.\"Hopefully we can improve its serum stability with our future studies so that a single injection may last up to a month,\" said Song Xue, a graduate student who worked on the research.The results have been published in The Journal of the American Chemical Society, and although we're still a long way off turning this enzyme into a useable treatment, the research is pretty exciting.Right now, around 80 to 90 percent of smokers who try to quit using aids like patches and gum will end up relapsing. But if scientists can figure out a way to remove that compulsive, feel-good effect of nicotine in the first place, we could see those statistics drastically chang"
        ]
    },
    "2069": {
        "gold_standard": [
            "There's some encouraging news for those of you who enjoy a curry on a Friday or a Saturday night: research from China suggests that adding a regular spicy meal to your diet can reduce the risk of mortality. The study was extensive in its scope - close to half a million people were surveyed - and the difference was substantial.\nThe research was carried out over a period of seven years and involved 487,375 participants keeping track of how much spicy food they were eating. The responses were \"never\" or \"almost never\", \"only occasionally\", \"one or two days a week\", \"three to five days a week\", or \"six or seven days a week\". On average, those who ate spicy food six or seven days a week had a 14 percent lower mortality risk than those who never or almost never ate it; for those who had it once or twice a week, the reduction was 10 percent.This isn't conclusive proof that there's a link between a hot curry or two and longer life, because other factors can't be ruled out. Spicy food eaters tended to live in more rural areas, for example, and it could also be possible that some other accompanying food is the real reason for the discrepancy. Nevertheless, it's something to bear in mind the next time you're making a choice from a restaurant menu.It's not the first time scientists have suggested a link between health benefits and chillies, which have been variously promoted as antioxidant, anti-inflammatory, and anti- cancer agents down the years. However, no one has yet put together a truly scientific, laboratory-controlled experiment into the effects of spicy food - something that may now happen thanks to the newly published research.The study was controlled to take into account factors such as family medical history, age, education, diabetes, smoking, and many other variables, though there's still not enough yet to make a 'causal inference' - that is, to say that hot and spicy foods can definitely help to avoid death for longer.\"Consumption of spicy foods may be correlated with other dietary habits and lifestyle behaviours,\" explains the report, published in the BMJ. \"For example, in Chinese cuisine the cooking of chilli pepper and the production of chilli sauce and oil usually requires more oil, and intake of pungent foods may be accompanied by an increased intake of carbohydrate-rich foods such as rice to relieve the burning sensation.\"\"Further prospective studies in other populations would be essential to demonstrate generalisability of these findings,\" concludes the report. \"More evidence will lead to updated dietary recommendations and development of functional foods, such as herbal supplements."
        ]
    },
    "2204": {
        "gold_standard": [
            "You may think you know what peace and quiet sounds like, but you don't - not really. In fact, in the total absence of noise, the human brain can start inventing sounds of its own,\u00a0because it relies so much on the audio cues we usually hear around us.\nWith that in mind, consider the new system developed by scientists at the Hong Kong University of Science and Technology, which is capable of absorbing almost all the sound that hits it - 99.7 percent of that sound, to be precise. The new set-up uses not one but two resonators, tuned to vibrate at whatever the frequency of the acoustic waves they're being hit with.The problem with traditional approaches to sound absorption is that the sonic insulators used are composites designed to handle different frequencies of audio - building something that can cover every possible frequency is beyond the capabilities of modern materials, and thus no matter how good your home cinema set-up is, you're still going to get some sound leakage somewhere.That's where the resonators come in. The first one is \"impedance-matched\" to the open air or whatever is surrounding the absorber - this provides a convenient route for sound waves to pass through. The second resonator is there to cancel out any scattered noise produced by the first, and it's this combination that achieves the 99.7 percent absorption level, no matter what the volume of the noise.The new system is actually building on a previous experiment conducted last year by some of the same team. In that case, a thin absorbing material was used in conjunction with a hard reflecting layer, with the sound waves caught in the air between and silenced. The new approach follows a similar strategy, but uses a single layer of material"
        ]
    },
    "2373": {
        "gold_standard": [
            "Physicists in France have figured out how to optimise an advanced type of electric rocket thruster that uses a stream of plasma travelling at 72,420 km/h (45,000 mph)\u00a0to propel spacecraft forward, allowing them to run on 100 million times less fuel than conventional chemical rockets.\nKnown as a Hall thruster, these engines have been operating in space since 1971, and are now routinely flown on communication satellites and space probes to adjust their orbits when needed. These things are awesome, and scientists want to use them to get humans to Mars, except there's one - rather large - problem: the current lifespan of a Hall thruster is around 10,000 operation hours, and that's way too short for most space exploration missions, which require upwards of 50,000 hours.Hall thrusters work just like regular ion thrusters, which blast a stream of charged ions from an anode to a cathode (positively and negatively charged electrodes), where they get neutralised by a beam of electrons. This causes the elections to shoot one way, and the attached rocket to shoot another, propelling it forward.\u00a0The difference with Hall thrusters is instead of having a physical cathode, they combine a magnetic field and a trapped electron cloud to create a completely hollow, 'virtual' cathode. A small amount of propellant gas - typically xenon - is injected into the thruster's channel to produce a charged ion stream, and because these\u00a0ions are too heavy to be caught up in the magnetic field of the virtual cathode, they can zip through unimpeded to be neutralised.\u00a0This creates a low-pressure plasma discharge, which produces thrust in the opposite direction from that of the ion flow.\u00a0All of this is fine and works great, but the part of the Hall thruster that contains the anode, virtual cathode, and electron cloud is what's holding it back. This container, called the discharge channel wall, is being constantly bombarded with high-energy ions, and this wears it down so much, the whole engine will eventually need to be recalled to have the wall repaired or replaced.\nSo scientists from the French National Centre for Scientific Research decided to remove the discharge channel wall altogether. \"An effective approach to avoid the interaction between the plasma and the discharge channel wall is to move the ionisation and acceleration regions outside the cavity, which is an unconventional design named a Wall-Less Hall Thruster,\" said lead researcher, Julien Vaudolon.Applied Physics LettersUnfortunately,\u00a0as Esther Inglis Arkell explains at Gizmodo, their first prototype (on the left in the image above) was a total failure.\"The red anode should be lined up on the wall emitting xenon. Instead, it's in the magnetic field, allowing electrons to glom onto it, reducing performance,\"\u00a0she says. \"The new design (on the right) makes the small change, which allows the anode to keep clear of the field. This one seems to work.\"\nThe research has been published in\u00a0Applied Physics Letters.Because the engine consumes a whole lot less fuel than conventional chemical rockets, this frees up room in the spacecraft to send large amounts of cargo, or perhaps more people. That\u00a0means the potential for long-duration, deep space missions, like the ones we'd need to transport humans and regular supplies to Mars.\u00a0There's no word yet on how much this new design could extend the lifespan of the Hall thruster, but if the researchers can get it up around the 50,000-hours mark, it could revolutionise space exploration in the future. They just have to get it done before scientists figure out the \"impossible\" EM Drive, which can theoretically blast us to Mars in just 70 days"
        ]
    },
    "2378": {
        "gold_standard": [
            "ACS Biomaterials Science and Engineering Snake venom might not be top of your mind when it comes to handy medical aids to keep around the house, but new research could have you rethinking what's in your first aid kit.\nResearchers at Rice University in the US have developed a new nanofibre hydrogel infused with snake venom that may amount to the most effective substance yet to stop bleeding quickly \u2013 especially since it works well even in the presence of anti-coagulant medications that thin the blood.\"It's interesting that you can take something so deadly and turn it into something that has the potential to save lives,\" says one of the team, chemist Jeffrey Hartgerink.The hydrogel, called SB50, incorporates batroxobin, a type of venom produced by two species of pit viper found in South America \u2013 including the Brazilian lancehead (Bothrops moojeni) pictured above.The coagulant properties of batroxobin have long been known, but fusing the venom with the hydrogel \u2013 which is composed of synthetic, self-assembling nanofibres \u2013 has produced an even faster-setting coagulant. Injected as a liquid to the site of a wound, the substance quickly thickens into a gel and conforms to the available space in the wound, promoting clotting in as little as 6 seconds in the researchers' tests.\nThe extremely fast action of the hydrogel could mean the difference between life and death for patients in emergency surgery \u2013 especially for those who take blood-thinning medications like heparin to prevent harmful clots forming in the veins, arteries or lungs.\"From a clinical perspective, that's far and away the most important issue here,\" said Hartgerink. \"There's a lot of different things that can trigger blood coagulation, but when you're on heparin, most of them don't work, or they work slowly or poorly. That obviously causes problems if you're bleeding.\"According to Hartgerink, heparin blocks the function of thrombin, an enzyme that helps our blood clot under normal circumstances (to prevent excessive bleeding from cuts or injuries). Batroxobin performs a similar function to thrombin, but it's not impeded by heparin \u2013 which could make it a life-saver for patients whose blood is too thin to clot without assistance.\"This is important because surgical bleeding in patients taking heparin can be a serious problem,\" said Hartgerink. \"The use of batroxobin allows us to get around this problem because it can immediately start the clotting process, regardless of whether heparin is there or not.\"Unfortunately, the hydrogel is expected to undergo several more years of testing before it can be approved for use as a therapeutic product. And interestingly enough, this isn't because of the snake venom. The batroxobin used in the hydrogel \u2013 which isn't taken directly from snakes, but is produced by genetically modified and purified bacteria \u2013 is already approved by the US FDA. The researchers' synthetic nanofibre gel, however, will require extensive testing before it's deemed safe for people to use for medical purposes.The findings are published in ACS Biomaterials Science and Engineerin"
        ]
    },
    "2423": {
        "gold_standard": [
            "It's not for the squeamish, but there's a relatively new medical procedure called faecal transplanting which is outperforming antibiotics against severe infections.\u00a0Doctors essentially take poo from a healthy person, freeze it, liquidise it in a blender, then add it to a sick person's bowel either by a tube through the nose or via the rectum.\nThe method, which colonises the gut with healthy bacteria, has a 85 percent success rate against life-threatening infections such as Clostridium compared to only 20 percent for standard antibiotic treatment.Australian regulators are yet to make a decision on the use of faecal transplants but local clinics are reportedly offering the procedure.\u00a0A report in the British Medical Journal (BMJ)\u00a0says long term trials and monitoring are urgently needed to provide sensible advice to patients.\u00a0However, so far few adverse effects are being reported after more than 7,000 transplants.And the transplants seem relatively safe for elderly patients and those with impaired immune systems, say Tim Spector from King's College London and Rob Knight from the University of California San Diego.More than 500 centres in the US now offer faecal transplantation, with most using frozen donations from the not-for-profit stool bank organisation, OpenBiome, in Boston. The UK regulator (MRHA) has temporarily classed faecal transplants as a medicinal product"
        ]
    },
    "2454": {
        "gold_standard": [
            "We already know what MDMA (aka ecstasy) does to your brain, but just how far-reaching are the physiological effects of taking the drug? You might be surprised.New research has shown for the first time that hair samples taken from ecstasy users can indicate stress levels caused by the drug, even months later. \"Cortisol is a stress hormone that we all produce in our bodies and interestingly it is deposited in our hair. Looking at cortisol in hair is a way for us to see how stressed we've been in the past,\" said lead researcher Luke Downey from Swinburne University of Technology in Australia.\nMeasuring cortisol levels through saliva samples is already an established way of detecting somebody's stress levels, but the test needs to be taken pretty much in the moment to detect the extent of stress.By contrast, the hair sampling technique enables retrospective measuring of stress during MDMA use, with cortisol levels effectively recorded in the hair growing when the drug was taken (provided the individual in question hasn't succumbed to the temptations of a buzzcut in the interim).\"Hair grows 1 centimetre per month,\" said Downey. \"We took 3 centimetres of hair from the scalp of non-ecstasy users (control group), light ecstasy users and heavy ecstasy users to assess the level of stress on their bodies over a three month period.\"Among the 101 volunteers who took part in the study, 27 were light users (having only taken ecstasy one to four times in the previous three months), 23 were heavy users (five or more times in the same period) and 51 did not use the drug.\nLooking at hair samples, the researchers found that the cortisol levels of light ecstasy users were 50 percent higher than the control group, and heavy users showed cortisol levels that were four times higher than light users \u2013 indicating significantly raised stress levels.Perhaps more alarmingly for ecstasy users is the fact that the researchers also tested participants' memory performance, and found that ecstasy users fared worse in word recall tests and also reported significantly more retrospective and prospective memory problems.However, the extent to which ecstasy users' memories were impaired did not correlate with the cortisol levels detected in their hair samples, indicating no real link between cortisol spikes and the cognitive deficits that ecstasy use brings about.\"Interestingly, no significant relationship between the memory deficits and levels of stress (indexed by the amount of cortisol) emerged,\" said Downey. \"This increased experience of stress appears not to be the mechanism that produces the memory deficit.\"\nThe findings are published in Human Psychopharmacology.Update 19 October:\u00a0We'd previously said that measuring cortisol through saliva samples was an established method of testing for ecstasy use. That was incorrect - it's only a way to measure someone's cortisol levels, and therefore their stress levels.Swinburne University of Technology is a sponsor of ScienceAlert.\u00a0Find out more about their research"
        ]
    },
    "2478": {
        "gold_standard": [
            "Cancer People who haven't had cancer might assume that those who have would take the opportunity to embrace their second chance and live as healthily as possible. But while those intentions might often be in the right place, it's another thing to successfully realise them.\nA study in the US has found that many cancer survivors maintain poor diets and food choices after making their recoveries \u2013 worse than the diets of people who have never had cancer, in fact \u2013 highlighting the need for dietary intervention in what researchers say is a vulnerable population within the community.\"Cancer survivors are usually motivated to improve their health, so I think it is remarkable that they are still burdened by a sub-optimal diet,\" said Fang Fang Zhang, an epidemiologist at Tufts University and co-author of the study, as reported by Deborah Netburn at the Los Angeles Times.The researchers compared the dietary intake of 1,533 cancer survivors with that of 3,075 individuals who had never had cancer. Viewed in light of the 2010 Dietary Guidelines for Americans, neither group scored particularly well in terms of nutritional intake, but the Healthy Eating Index score of 47.2 out of 100 for cancer survivors was lower than the 48.3 for those with no history of cancer. While there's not a huge degree of difference between the two poor scores, it's enough to have researchers concerned.The study also found that cancer survivors consume less fibre and more empty calories than people who have not had cancer. Survivors have low dietary intake of vitamin D, vitamin E, potassium, and calcium, and consume too much saturated fat and sodium. About the only good thing you can say is that the diet of cancer survivors improves with age, with the oldest cancer survivors maintaining the healthiest food intake.\nAmong survivors, breast cancer survivors were found to have the best diets, while lung cancer survivors had the worst \u2013 and cancer survivors who currently smoke had worse diet quality than non-smokers or former smokers.While the exact reasons for why cancer survivors are maintaining poor eating habits are unknown, it's possible that their experience in surviving a life-threatening illness has somehow altered their dietary intake for the worse.According to Zhang, cancer treatments can cause people to experience food cravings or can alter the way foods taste, with the effects persisting long after recovery. Or high levels of stress resulting from the episode could affect diet or make it difficult to prioritise the right sorts of foods.Of course, the reverse scenario is also true. Some survivors may have had poor diets to begin with \u2013 which in some instances could have contributed to their cancer \u2013 and despite medical advice for them to improve their nutrition, they may have been unwilling or unable to make the right changes.\nFuture research may provide the answers on causation, but in any case the results of the current study show that cancer survivors \u2013 a group that already faces higher risk of chronic health complications \u2013 need all the help they can get in getting their diets on track.\"Dietary changes that include more fibre, fruit, and vegetables in the diet and less fat, sodium, and added sugar would be important for cancer survivors,\" Zhang said in a press release. \"Oncology care providers can play critical roles in reinforcing the importance of a healthful diet, and can refer patients to registered dieticians who are experts in oncology care or to other reputable sources in order to improve survivors' overall health.\"The research is published in Cancer"
        ]
    },
    "2482": {
        "gold_standard": [
            "Making a run to the local coffee shop to secure your caffeine fix (and maybe picking up a little snack on the side while there\u2026) is something many of us do every day at least once, but just a single visit could see you hit a number of your daily dietary limits all at once, according to a new study.\nAustralian researchers from Cancer Council NSW say many people may be unaware that they're consuming their entire daily sugar or saturated fat limits in one trip to the coffee shop, and consuming half of their suggested energy intake for the whole day in a single hit.When you think about how for most people a coffee run is just a quick beverage and/or snack in between, you know, actual meals, this starts to get a little scary.\"Many Australians rely on a take away coffee for their morning kick start but people might be unaware of just how much sugar, saturated fat and kilojoules they are consuming each day if they're ordering anything more than the standard flat white, cappuccino or latte,\" said Clare Hughes, a nutrition programs manager and co-author of the study.The researchers looked at 564 menu items available from five popular Australian coffee shop chains to assess the energy, saturated fat, and sugar content of beverages and snacks, to see how they stack up against the average daily allowances health authorities recommend.\nMore than half (54 percent) of the cold beverages tested, such as iced coffees and chocolate drinks, contained more than half of the daily recommended sugar allowance in one serving. One such beverage, McCaf\u00e9's Coffee Kick Frappe, may sound entirely delicious, but contains a whopping 19 teaspoons of sugar in just one drink \u2013 86 percent of the amount a person is supposed to consume in a whole day.Beverages can also conceal high amounts of saturated fat, especially if you opt for a larger size, with the researchers noting a large iced coffee from Coffee Club contains 39 grams of saturated fat, 163 percent of the recommended daily limit (and even a large chai latte can hit half the daily allowance for saturated fats).And if you think opting for skim or low-fat options makes for a healthy choice with these kinds of beverages, guess again. Selecting skim milk for a large Tim Tam iced chocolate from Gloria Jeans may make it healthier than opting for full cream milk, but it doesn't do anything to change the fact that the drink contains 20 teaspoons of sugar \u2013 a third of the average person's entire daily kilojoule allowance.The fact that some low-fat items are marketed as 'healthy options' for consumers concerns researchers, especially when deceptively energy-rich snacks are thrown into the mix alongside drinks.\n\"We found McCaf\u00e9's banana bread contained 14 teaspoons of sugar and 2,570 kilojoules \u2013 that's four times the kilojoules that we should be consuming from a between-meal treat,\" said Hughes. \"This is about the same as a McDonald's Big Mac, which we're more likely to have as part of a meal.\"The researchers hope the study will bolster public awareness of the true nutritional content (or lack thereof) in coffee shop indulgences, so that people can make more informed choices about what they consume when they're out and about.\"With Australians spending a third of their weekly food budgets eating at caf\u00e9s, restaurants and fast food outlets, and 63 percent of Australian adults overweight or obese, it's more important than ever to have access to healthy options,\" said Hughes.\"If we can stabilise or decrease obesity levels in Australia, half a million lives could be saved by 2050.That would mean fewer cases of obesity related cancers, such as bowel, endometrial and post-menopausal breast cancer; as well as heart disease and type 2 diabetes.\"The research is published in Nutrition & Dietetics"
        ]
    },
    "2579": {
        "gold_standard": [
            "Garbage is a big problem. Even with so many of us doing our bit to help out with recycling, the amount of unrecyclable and discarded plastics in the US alone comes close to 30 million tonnes annually, thanks to things like disposable coffee cups (2.5 billion of which are thrown away by Americans every year). We're looking at you, Starbucks.\nNow, for the first time, researchers have found detailed evidence that bacteria in an animal's gut can safely biodegrade plastic and potentially help reduce the environmental impact of plastic in landfill and elsewhere. The animal in question? The humble mealworm \u2013 which turns out to be not so humble after all.Researchers led by Stanford University in US and Beihang University in China found that the mealworm \u2013 the larval form of the darkling beetle \u2013 can safely subsist on a diet of Styrofoam and other kinds of polystyrene, with bacteria in the worm's gut biodegrading the plastic as part of its digestive process. The findings are significant because it was previously thought that these substances were non-biodegradable \u2013 meaning they ended up in landfill (or worse, our oceans, where they'd accumulate for decades).\"Our findings have opened a new door to solve the global plastic pollution problem,\" co-author Wei-Min Wu, a senior research engineer in the Department of Civil and Environmental Engineering at Stanford, said in a statement.In the study, 100 mealworms ate between 34 and 39 milligrams of Styrofoam each day, converting about half into carbon dioxide and the other excreting the bulk of the rest as biodegraded droppings. They remained healthy on the plastic diet, and their droppings appeared to be safe for use as soil for crops"
        ]
    },
    "2607": {
        "gold_standard": [
            "This article was written by\u00a0David Greenberg\u00a0from the\u00a0University of Cambridge\u00a0and was originally published by The Conversation.We're exposed to music for nearly 20 percent of our waking lives. But much of our musical experience seems to be a mystery. Why does some music bring us to tears while other pieces make us dance? Why is it that the music that we like can make others agitated? And why do some people seem to have a natural ability to play music while others have difficulty carrying a tune? Science is beginning to show that these individual differences are not just random but are, in part, due to people's personalities.\nMy colleagues and I have published research showing that people's musical preferences are linked to three broad thinking styles. Empathisers (Type E) have a strong interest in people's thoughts and emotions. Systemisers (Type S) have a strong interest in patterns, systems and the rules that govern the world. And those who score relatively equally on empathy and systemising are classified as Type B for 'balanced'.Research from the past decade has shown that 95 percent of people can be classified into one of these three groups and that they predict a lot of human behaviour. For example, they can predict things such as whether someone studies maths and science, or humanities at university. For the first time, we have shown that they can predict musical behaviour, too.Matching music with thinking styleTo study this phenomenon, we conducted multiple studies with over 4,000 participants. We took data on these participants' thinking styles and asked them to listen to and indicate their preferences for up to 50 musical excerpts, representing a wide range of genres.\nAcross these studies, we found that empathisers preferred mellow music that had low energy, sad emotions, and emotional depth, as heard in R&B, soft rock, and singer-songwriter genres. For example, empathising was linked to preferences for Come Away With Me\u00a0by Norah Jones and Jeff Buckley's recording of Hallelujah. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">\nOn the other hand, systemisers preferred more intense music, as heard in hard rock, punk and heavy metal genres. Systemisers also preferred music with intellectual depth and complexity as heard in avant-garde classical genres. For example, systemising was linked to preferences for Alexander Scriabin's Etude opus 65 no 3.\nImportantly, those who are Type B had a tendency to prefer music that spans more of a range than the other two thinking styles. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">\nIn our most recent study, published in the Journal of Research of Personality, we found that people's personality traits can also predict their musical ability, even if they don't play an instrument. Our team worked with BBC Lab UK to recruit over 7,000 participants and assess them for five distinct personality dimensions: openness, conscientiousness, extroversion, agreeableness, and neuroticism/emotionality stability. We also asked them to conduct various tasks that measured their musical ability, including remembering melodies and picking out rhythms.\nWe found that, next to musical training, the personality trait of openness was the strongest predictor of musical sophistication. People who score highly for openness are imaginative, have a wide range of interests, and are open to new ways of thinking and changes in their environment. Those who score low on openness (or who are 'closed') are more set in their ways, prefer routine and the familiar, and tend to have more conventional values. We also found that extroverts who are often more talkative, assertive, and excitement-seeking had greater singing abilities.Furthermore, we could apply this even to people who did not currently play a musical instrument, meaning there are people who have a potential for musical talent but are entirely unaware of it.Music therapyThese new findings tell us that from a person's musical taste and ability, we can infer a range of information about their personality and the way that they think.\nThis research shows there are factors beyond our awareness that shape our musical experiences. We hope that these findings can be of help to teachers, parents, and clinicians. Based on information about personality, educators can ensure that children with the potential for musical talent have the opportunity to learn a musical instrument. Music therapists can use information about thinking style to help tailor their therapies for clients, too.We are also interested in how knowledge gained from science can help children and adults on the autism spectrum who have difficulties with communication, as we recently wrote in the journal Empirical Musicology Review.This could also help people process emotions after experiencing a psychological trauma and when grieving a loss. In fact, initial findings from our lab suggest that people who experienced a traumatic event in childhood engage with music quite differently in adulthood than those who did not experience a trauma.If you want to find out how you score on musical ability, preferences, and personality, you can take these tests at www.musicaluniverse.org.David Greenberg, PhD candidate, psychology, University of Cambridge.This article was originally published by\u00a0The Conversatio"
        ]
    },
    "2659": {
        "gold_standard": [
            "Long before TV shows like CSI made us aware of high-tech forensic techniques at crime scenes, pretty much everybody already had some basic familiarity with the concept of fingerprinting, an identification method with roots going as far back as the 19th century.\nWhile fingerprinting is still a thoroughly useful method for discovering who may have been present at the scene of a crime, the basic premise of the technique used by crime scene investigators \u2013 visual comparisons between two sets of fingerprints \u2013 hasn't changed in a very long time. However, a new way of taking people's prints not only records what their fingerprints look like, but could help investigators determine whether the person was a man or a woman \u2013 and maybe even a lot more about them too.\"Fingerprints have really been treated as pictures for more than a hundred years,\" Jan Halamek, a forensic scientist at the State University of New York at Albany, told Sindya N. Bhanoo at The New York Times. \"The only major improvements in recent years have been due to software and databases that make it faster to match fingerprints.\"Halamek and fellow researchers have instead developed a system where fingerprints aren't just treated as visual records. Rather, the sweat deposits left in fingerprints are analysed for their biochemical content \u2013 specifically, the amino acids they contain, which can reveal the sex of the person who left the print. This is because the levels of amino acid in female sweat are about twice as high as that of males.It's not the first time scientists have run biochemical analyses on fingerprints, but the early results of the researchers' methods are promising, with the technique giving a 99 percent chance of correctly identifying whether prints are male or female.\nIn addition to testing their system on a series of 50 mimicked fingerprint samples, the researchers ran the procedure on a very small sample group of three males and three females.When doing so, the team was able to successfully distinguish between the fingerprints of male and female subjects on a number of surfaces, including a polyethylene sheet, a door knob, a laminated desktop, a composite bench top, and a computer screen. The findings are published in Analytical Chemistry.To extract the amino acids, the researchers transfer the print to a polyethylene film, separating the amino acids from the lipids with a drop of diluted hydrochloric acid. The amino acid levels are then measured using an enzyme-based colorimetric test. Compared to other means of analysing prints, such as mass spectrometry, it's relatively simple and inexpensive to perform.The researchers acknowledge they'll need to replicate their findings with a larger sample, but also hope to refine the system and develop means of finding out even more about a person based on their fingerprint, using other bio-markers in addition to amino acids. As Halamek told Bhanoo, \"We want to create a very simple kit which can determine on the spot whether the person was young or old, male or female, and their ethnicity."
        ]
    },
    "2771": {
        "gold_standard": [
            "Premature ejaculation should not be classed as a male sexual dysfunction, according to a new review published in Clinical Anatomy \u2013 a verdict that could cause problems for the companies making millions of dollars from treating the condition.\nIn fact it may be more accurately described as \"an illness constructed by sexual medicine experts under the influence of drug companies\" according to the authors of the review.The researchers behind the report say premature ejaculation is a natural occurrence, especially among younger men, and that those affected can learn to control their response to stimulation themselves without recourse to any drugs or therapies.They also point out that false assumptions about sexual intercourse aren't helping to dispel the idea that premature ejaculation is an illness to be treated.\"It is important for men to understand that in premature ejaculation the physiology of ejaculation and orgasm is not impaired, and that it is normal in adolescent males especially during their first sexual encounters,\" said report co-author Vincenzo Puppo. \"Teens and men can understand their sexual response during masturbation and learn ejaculatory control without drug therapy.\"\nThe review goes on to say that penile-vaginal intercourse isn't important for a woman's orgasm, so in that respect it doesn't matter how long the sex lasts.\"In all women, orgasm is always possible if the female erectile organs are effectively stimulated during masturbation, cunnilingus, or partner masturbation, before and after male ejaculation, or during vaginal intercourse if the clitoris is simply stimulated with a finger,\" explains the report's other author, and Vincenzo's daughter, Giulia Puppo.As many as one in three men may experience premature ejaculation during sex, though reliable statistics are hard to come by, and that means the report is likely to generate a lot of interest \u2013 especially one that says pills and surgery aren't necessary to help men last longer in bed.The term 'premature ejaculation', or PE, was first used in 1915 and for a long time has been associated with psychological issues. Other medical researchers suggest there's a link between PE and genetics.According to Puppo and Puppo, couples shouldn't be embarrassed about premature ejaculation and can find natural ways around it, and those experiencing their first sexual encounters might find that idea more reassuring than most.\"Urologists, sexologists, and sexual medicine experts must acknowledge that PE is really normal in adolescent males, especially during their first sexual encounters,\" says the report, which has been published in the journal Clinical Anatom"
        ]
    },
    "2775": {
        "gold_standard": [
            "It's one of the holy grails of scientific research: discovering a way of replicating the natural process of photosynthesis, such that light could be easily converted into energy for other purposes, just like a plant does. And now researchers in the US have discovered an artificial material that lets them mimic this system to create a clean, sustainable source of power.\nResearchers at Florida State University have discovered a method of using manganese oxide \u2013 also known as birnessite \u2013 to capture sunlight and then use that solar energy to create an oxidation reaction, breaking down water (H2O) into hydrogen (H) and oxygen (O2). Oxidation occurs during photosynthesis, and by replicating this part of the natural process, we might be able to produce energy in new ways via a simple, practical mechanism.\"In theory, this should be a self-sustaining energy source,\" said Jose L. Mendoza-Cortes, assistant professor of chemical engineering. \"Perhaps in the future, you could put this material on your roof and it could turn rain water into energy with the help of the sun.\"Best of all, using manganese oxide in this kind of way would be an entirely carbon-neutral method of producing energy sources like hydrogen fuel, and wouldn't have any negative impacts on the environment. \"You won't generate carbon dioxide or waste,\" said Mendoza-Cortes.Once produced, hydrogen can be used as a fuel and burned with oxygen to form H2O, releasing energy in the process. But usually the creation of hydrogen fuel is powered by burning fossil fuels, which is why this new technology is so exciting.\nWhen looking to find a material that would be able to facilitate the process of breaking down water but also capturing the energy from the Sun, the researchers faced two initial challenges: finding a material that didn't rust due to exposure to the water, and also one which wasn't too expensive to create.The answer Mendoza-Cortes and his team came up with \u2013 which is described in their paper in The Journal of Physical Chemistry \u2013 was to develop a multilayered material out of manganese oxide. However, it was only when they stripped back the multiple layers to a single layer that they struck what they were looking for. When they did this, the material was able to trap light at a much faster rate.How is this possible? According to the researchers, the single layer of the manganese oxide material provides what's called a direct band gap, whereas multiple layers constituted an indirect band gap. Light penetrates different sorts of materials differently, but its energy is only effectively captured and stored by materials with a direct band gap.What's remarkable about the material the researchers developed in this instance is that it is more effective at capturing energy when there is only a single layer of it \u2013 a desirable outcome for the purposes of any potential real-world applications, as it will be cheaper and easier to manufacture.\"This is why the discovery of this direct band gap material is so exciting,\" said Mendoza-Cortes. \"It is cheap, it is efficient and you do not need a large amount to capture enough sunlight to carry out fuel generation.\"It's early days yet and there's no word so far on when we can expect to see this kind of material manufactured for domestic purposes, but with the researchers already envisaging potential applications like household roof-top energy generators, it's an incredibly exciting developmen"
        ]
    },
    "2814": {
        "gold_standard": [
            "Researchers from Canada have used computer models to show that our Solar System could have had an extra gas giant planet in the mix around 4 billion years ago \u2013 until Jupiter booted it out, that is.\nThe idea that there were originally five gas giants \u2013 in addition to Jupiter, Saturn, Uranus, and Neptune \u2013 was first proposed back in 2011, to help explain why the Solar System currently looks the way it does. As it turns out, the orbit of Mars and Earth don't really make sense if there were only ever the planets we have today.But researchers haven't been able to explain until now what could have happened to that extra planet, with both Jupiter and Saturn named as potential culprits for doing the kicking out.\u00a0\"Our evidence points to Jupiter,\" said lead researcher Ryan Cloutier\u00a0from the University of Toronto, who describes the whole thing as an \"interplanetary chess game\".The mystery lost planet in question is believed to have had the mass of an ice giant, which means that it was heavier than Saturn and Jupiter, and in the same class as Neptune and Uranus.\u00a0So how exactly does a lighter planet suddenly kick an ice giant clear out of the Solar System?\nPlanetary ejections generally happen as a result of a close planetary encounter - but not necessary a collision - which causes one of the objects to accelerate so rapidly that it's able to break free from the massive gravitational pull of the Sun and go slingshotting out into the galaxy, becoming what's known as a rogue planet.\u00a0In this case, the ejection could be the result of Jupiter moving closer to the Sun from further out in the Solar System, affecting the orbit of other planets on its way.Earlier studies had struggled to work out exactly which of the remaining planets could have done this, but in the new research, the astronomers from the University of Toronto realised that up until now, no one had factored in the effect this encounter would have had on the moons orbiting the giant planets.So the team decided to look at the trajectories of Callisto and Iapetus \u2013 two of the regular moons orbiting Jupiter and Saturn respectively.\u00a0Using computer models, they investigated the likelihood of the moons having the same orbit as they do today if they'd been involved in a mass planetary ejection 4 billion years ago.\n\"Ultimately, we found that Jupiter is capable of ejecting the fifth giant planet while retaining a moon with the orbit of Callisto,\" said Cloutier. \"On the other hand, it would have been very difficult for Saturn to do so because Iapetus would have been excessively unsettled, resulting in an orbit that is difficult to reconcile with its current trajectory.\"The computer model showed that there's about a 42 percent chance that Callisto would have its current orbit around Jupiter if it had been involved in the planetary ejection. The results have been published in\u00a0The Astrophysical Journal.But to be clear, this doesn't mean that we have any evidence this interaction actually took place, or even that there was an extra planet in the Solar System in the first place. This is all based off computer models, and while they can explain the current state of the planets in our Solar System, they're not the only possibilities out there.\"We do know that rogue planets roam the galaxy, and they were almost certainly ejected in this manner, so the idea of a lost solar system planet isn't crazy,\" wrote astronomer Phil Plait for Discover\u00a0back in 2011 when the missing planet hypothesis was first proposed.\u00a0\"But it's only one possible scenario.\"Still, it's kind of cool to think that, somewhere out there in the galaxy, a frozen ice giant is roaming, a lost remnant from the formation of our Solar Syste"
        ]
    },
    "2816": {
        "gold_standard": [
            "Australian scientists have found the gene that allows a native tobacco plant to grow and reproduce in an incredibly short amount of time, and in arid, desert conditions.If applied to other plants, this gene could be the key to getting crops to survive and grow fast enough in the harsh environment of space, such as on board the International Space Station (ISS), or even in enclosed habitats on Mars.\u00a0\"The plant has worked out how to fight drought \u2013 its number one predator \u2013 in order to survive through generations,\" said lead researcher Julia Bally, from Queensland University of Technology (QUT).\nThe native tobacco plant in question is\u00a0Nicotiana benthamiana, or Pitjuri as Indigenous tribes call it, and by looking at the fossil record scientists have found that it's been thriving in the harsh Australian climate for around 750,000 years.The plant also has the unique ability to receive genes from other species and viruses without rejecting them, which makes it the perfect 'lab rat' \u2013 and because of this it's been used in labs for genetic testing for decades, acting as a model plant on which to test viruses and vaccines.This whole time, scientists haven't understood what makes the plant so receptive to novel genes. But the QUT researchers have finally found the answer \u2013 and interestingly, it's the same gene that has helped the plant survive in the harsh climate of Australia for so long.Publishing their results in\u00a0Nature Plant, the researchers describe a genetic insertion found in Pitjuri, which\u00a0has completely removed its ability to fight pathogens. The gene literally seems to shut down the plant's desire to fight any invaders, which sounds like a bad thing, but it means that the plant can direct all its energy on growing like mad in a short period of time.\n\"The plant has lost its 'immune system' and has done that to focus its energies on being able to germinate and grow quickly, rapidly flower, and set seed after even a small amount of rainfall,\" said Bally. \"Its focus is on creating small flowers but large seeds and on getting these seeds back into the soil in time for the next rain. What we found may have a big impact on future plant biotechnology research.\"Having no immune system wouldn't be a good thing for crops here on Earth \u2013 in a regular farm or plantation these plants would be overrun with pathogens immediately \u2013 but it's ideal for sterile environments, such as the lab, or space, according to the researcher team.\u00a0\"So the recent film The Martian, which involved an astronaut stranded on Mars growing potatoes while living in an artificial habitat, had a bit more science fact than fiction than people might think,\" said one of the researchers, Peter Waterhouse.Already scientists are experimenting with growing crops on board the ISS \u2013 back in August, astronauts took their first bite of space-grown lettuce. But currently they're working on fine-tuning the wavelengths of lights that could be used to trigger photosynthesis and encourage plant growth"
        ]
    },
    "2887": {
        "gold_standard": [
            "One of the limitations of current solar panel technology is the panels need to be facing in a certain direction to make the most of the Sun's rays, otherwise the amount of energy they can absorb drops off dramatically. A newly invented material could make the direction of solar panels much less of a concern in the future.\nThe material has been produced by electrical engineers at the King Abdullah University of Science & Technology (KAUST) in Saudi Arabia and Taiwan's National Central University. Not only does the glass coating they've come up with soak up sunlight from multiple angles more effectively, it's also able to keep itself clean - the newly treated panels were able to maintain 98.8 percent of their efficiency after six weeks outdoors.For several years now experts have debated whether solar panels are more productive when facing south or west, with the majority concluding that it really depends on where in the world you live. If the new coating can be produced on a mass scale, not only will panels become more efficient, they can also be placed in all kinds of positions to catch the sunlight.To create the glass coating, the researchers integrated ultrathin nanorods and larger honeycomb-shaped nanowalls into the existing material: the ability of the nanorods to capture subwavelengths of light and the scattering ability of the nanowalls combine to lead to a boost in efficiency of between 5.2 and 27.7 percent. In the long term, as much as a 46 percent efficiency improvement could be possible, depending on the angle of the light.Even as the Sun moves across the sky, upgraded solar panels would be able to capture much more energy, and that makes a big difference when it comes to working out the economics of solar power in different regions of the world.\nMaking solar energy more competitive and scalable is an important part of maintaining the momentum behind it, as indeed was the message at the recent Solar Future 2015 Symposium held at KAUST.\"We've achieved a lot, but we've got a long way to go as well,\" said Saudi Aramco's Chief Technology Officer Ahmed Al Khowaiter at the Symposium, emphasising the need to \"scale up the industry as quickly as possible\u2026 maintaining the momentum we've had over the last five years while ensuring the sustainability of growth.\" The new class coating produced with help from KAUST researchers could play a big role in that.The team's findings have been published in the journal ACS Nan"
        ]
    },
    "2894": {
        "gold_standard": [
            "Calorie restriction diets have previously been shown to slow down the ageing process, and strangely enough, a common ingredient in face creams appears to mimic these life-extending effects \u2013 and all without the pain of going hungry.\nResearchers in the UK have found that allantoin, a chemical compound found in botanical extracts of the comfrey plant and an ingredient in many anti-ageing skin creams, can increase the lifespan of certain worms by more than 20 percent \u2013 comparable to the manner in which calorie restriction achieves the same effect.If drugs developed for humans could reproduce this, it's possible that we could help slow down the clock when it comes to genetic ageing \u2013 and 20 percent extra lifespan is a pretty amazing boost to try to replicate.\"Calorie restriction has been shown to have health benefits in humans and, while more work is necessary, our findings could potentially result in human therapies for age-related diseases,\" said Jo\u00e3o Pedro de Magalh\u00e3es, a researcher in ageing genomics at the University of Liverpool.To identify what kinds of compounds might mimic the effects of calorie restriction in humans, the team sourced data from the Connectivity Map, a comprehensive database of molecular signatures from human cells treated with a variety of small-molecule drug candidates.\nUsing pattern-matching algorithms to find links between drug compounds and the effects of calorie restriction, the researchers found 11 potential matches, and tested five of the compounds on nematode worms.What they found was that allantoin, and three of the other compounds \u2013 rapamycin, trichostatin A, and LY\u2013294002 \u2013 made the treated worms live healthy lives for longer. Three of the compounds, including allantoin, also extended the lifespan in a strain of mutant worms via anti-ageing mechanisms similar to the way in which calorie restriction works.\"We have shown so far that our compounds work in worms, but studies in mammalian models are now necessary,\" said one of the team, Shaun Calvert. \"The next step for us is to understand the mechanisms by which allantoin extends lifespan, as this could reveal new longevity pathways.\"If those same pathways can be effected in humans \u2013 although there's no guarantee they will be, as many results from experiments on animals are not replicated in people \u2013 it may well mean we can find ways to live longer, and do so without the pain, inconvenience, and risks of committing to so-called starvation diets.\"We have known for many years that caloric restriction diets increase lifespan in all manner of organisms,\" said Stephen Simpson from the University of Sydney in Australia), in reference to separate research he published earlier in the year. \"However, except for the fanatical few, no one can maintain a 40 percent caloric reduction in the long term, and doing so can risk loss of bone mass, libido and fertility.\"The findings have been reported in Aging Cell"
        ]
    },
    "2897": {
        "gold_standard": [
            "The team from Ko\u00e7 University has developed a road material that delays the formation of ice. Starting with a salt potassium formate, the researchers mixed in a styrene-butadiene-styrene polymer and added the mixture to bitumen - a major component of asphalt. When tested in the lab, it \"significantly\" delayed ice formation when compared with a regular road surface, they report, while at the same time remaining just as sturdy as unmodified bitumen.According to the American Chemical Society, the new composite was able to release de-icing salt over a period of two months, but the effects could last even longer when used on real roads. With the salt-polymer composite spread out evenly through the asphalt, the pressure of cars and trucks wearing away the road would slowly release the mixture and keep the surface ice-free - perhaps even for several years at a time.Of course, it wouldn't just be drivers who would benefit. Local authorities have to spend money and use up other resources clearing roads during the winter, not just once, but time and time again if the conditions persist. A road surface that de-ices itself would take these gritting lorries off the streets, easing congestion and saving funds for local governments.\"Salt can be easily removed by rain or automobiles and requires frequent application on roads,\" notes the team.\u00a0\"Besides this economic consideration, anti-icing agents compromise the mechanical properties of asphalt and have a negative impact on living organisms and the environment when used in large amounts.\"If the new bitumen composite can be made commercially viable and replicate the same effects in real-world testing, driving in snowy or freezing cold conditions might soon be a lot less hazardous than it currently is. It's not the only innovation potentially coming to our streets, though: other teams of researchers are busy working on embedding solar panels, recycled plastic and car recharging capabilities into the road surfaces of tomorrow.The study has been published in\u00a0Industrial & Engineering Chemistry Researc"
        ]
    },
    "2912": {
        "gold_standard": [
            "Neural Computation The human brain is a wonderful thing. Consider the way it can recognise faces and objects despite a multitude of variations: we can always identify an \"A\" as an \"A\" for example, no matter what colour, size, or shape it comes in. And now researchers have come up with an algorithm that could show just how clever the brain's way of working is, and how we're able to process so much data all at once.\nA team from Georgia Tech\u00a0has discovered that a human brain can categorise data using just 1 percent or less of the original information.\u00a0\"We hypothesised that random projection could be one way humans learn,\" said one of the team, Rosa Arriaga. \"The short story is, the prediction was right. Just 0.15 percent of the total data is enough for humans.\"As part of the experiment, test subjects were asked to view several original, abstract images, and were then challenged to identify the same images when shown a small portion of each one.The researchers then came up with a computational algorithm based on the idea of random projection.\u00a0The random projection technique compresses information in a certain way, sacrificing accuracy for speed of processing. Using the technique, the AI was\u00a0able to complete the tests just as well as human participants.This shows that the human brain network and artificial neural networks are in fact very similar in their behaviour, the team says, adding that both human and machine found the same types of data difficult to process.\n\"We were surprised by how close the performance was between extremely simple neural networks and humans,\" said one of the researchers, Santosh Vempala. \"The design of neural networks was inspired by how we think humans learn, but it's a weak inspiration. To find that it matches human performance is quite a surprise.\"While the study's results aren't enough to prove that the brain naturally uses a random projection as a way to process information, the findings are enough to indicate that it's a \"plausible explanation\" for what's happening inside our minds.Learning based on random projection already plays a role in computers involved in the processing of large amounts of data, and the new research could lead to further developments in the same area.\"How do we make sense of so much data around us, of so many different types, so quickly and robustly?\" says Vempala. \"At a fundamental level, how do humans begin to do that? It's a computational problem.\"The team's findings have been published in the journal\u00a0Neural Computatio"
        ]
    },
    "2915": {
        "gold_standard": [
            "Our sleep is much more efficient than that of our closest animal relatives, a new study has found, allowing us to spend less time in the light stages of sleep, so we can drift more quickly into the deeper states that work so well at restoring our bodies and minds.\nBy evolving a more efficient method of sleep, we can get by on less - about 7 hours, on average - than other primate species. The southern pig-tailed macaque and the grey mouse lemur, for example, snooze for as many as 14 to 17 hours a day. What's more, some lemurs and monkeys enter the\u00a0Rapid Eye Movement\u00a0(REM) mode of sleep - which is of\u00a0better quality than light dozing -\u00a0for just 5 percent of the total time they're asleep, compared to around 25 percent for humans.For the purposes of the study, the researchers from Duke University looked at data collected on hundreds of mammals across 21 different species of primates. The data was then analysed to look for slumber patterns in each species.It turns out human beings are top of the tree in terms of both the brevity and the efficiency of sleep - we've somehow evolved to get better quality shut-eye in a shorter span of time. Chimpanzees, meanwhile - our closest animal relatives - sleep for an average of 11.5 hours a night.Study co-author David Samson previously logged nearly 2,000 hours watching orangutans in REM and non-REM sleep as part of his dissertation research. He suggests that the shift in humans could have been caused by a switch from building beds in the trees to sleeping on the ground, and then to the comfortable beds we know today.\nA more relaxed and warm sleep by the campfire may have originally helped us get more sustenance from a shorter period of slumber, they suggest.The researchers also hypothesise that, as a species, we gradually cut down our sleeping hours to spend more time on more interesting pursuits: specifically, learning new skills and forging social bonds. Today, of course, it's Netflix binges and the glare of smartphones that are cutting down on our time in bed - but the research indicates the shift started happening a long time ago.They also looked at a separate study of three remote hunter-gatherer societies in Tanzania, Namibia, and Bolivia, and found that they sleep for slightly longer than the rest of us. This suggests that it's not just the spread of electricity, technology, and an 'always-on' lifestyle that's behind our sleeping patterns, they say.The researche has been published in Evolutionary Anthropology"
        ]
    },
    "2933": {
        "gold_standard": [
            "Advanced Functional Materials. Scientists have developed a new type of blood test that promises a quick and cheap diagnosis of diseases such as HIV, Ebola, and malaria, and can also identify levels of glucose or cholesterol in the blood, thanks to a 'quirk' in the laws of physics called birefringence.\nThe term refers to the way that light waves behave when passing through materials with a slightly more complicated crystal structure than normal - rather than the light bending slightly, as it does when passing through water or glass, it splits in two and essentially bends at two different angles. By adding certain enzymes to blood, birefringence can be used to identify the crystals that form to diagnose different types of disease.One of the main advantages of this new blood test is that changes in the crystal patterns are visible to the naked eye, which makes a big difference for hospitals in remote parts of the world where the latest equipment or even electricity aren't always available.All that's required for an accurate diagnosis, according to the researchers, is a couple of cheap, polarised filters (similar to those found in some sunglasses); the right enzymes; a blood sample; and the knowledge of which patterns to look out for. That means almost anyone could be given access to the technology at very little cost and only basic equipment.In addition, by using a light meter and an app running on a smartphone, doctors are able to measure how far the disease has developed.\n\"Our test system can be extended to a large number of different viruses or bacteria. It is totally flexible,\" said one of the team, Jijo Vallooran from ETH Zurich in Switzerland. \"Other than a refrigerator to store the antibodies and enzymes, the user needs only the box to detect the polarised light and the lipid carrier substance. This is very inexpensive. Our technology is very suitable for use in the field and the early detection of diseases.\"The research team is now seeking funding and further support to make its proposed system a reality. The paper outlining the new test procedure has been published in Advanced Functional Materials"
        ]
    },
    "2934": {
        "gold_standard": [
            "The findings, reported in Bioinspiration & Biomimetics, are more than just the latest in wearable technology. Provided you're happy to sport socks filled with your own urine \u2013 which we imagine may prove a bit of a challenge for the marketing department \u2013 such a system could very well save your life in an emergency when no other power sources are around.\"This work opens up possibilities of using waste for powering portable and wearable electronics,\" said Ieropoulos. \"For example, recent research shows it should be possible to develop a system based on wearable MFC technology to transmit a person's coordinates in an emergency situation. At the same time this would indicate proof of life since the device will only work if the operator's urine fuels the MFCs.\"While we're not sure if the technology in its current incarnation is something that campers and hikers would ever readily toss in to their backpacks for a weekend away, the research is the latest proof of concept showing how waste \u2013 whether animal-derived or otherwise \u2013 is a potent, tappable energy source we really shouldn't squande"
        ]
    },
    "2938": {
        "gold_standard": [
            "Nanomaterials have been crucial in many recent scientific advancements, but the miniature size of these objects makes it difficult to clear them up when they end up in places they shouldn't, like our oceans and waterways. Fortunately, researchers in the US have come up with a method that could see these nanomaterials filtered from contaminated water.\n\"Look at plastic,\" explains one of the team, Yoke Khin Yap from Michigan Technological University. \"These materials changed the world over the past decades - but can we clean up all the plastic in the ocean? We struggle to clean up metre-scale plastics, so what happens when we need to clean on the nano-scale?\"The method sounds like something out of a recipe book: add a little water, and a little oil, then shake. As oil and water don't mix well, they separate out during the shaking process, with the oil trapping any nanomaterials in the solution as it goes.Experiments were run using different types of nanomaterials, including carbon nanotubes, graphene, boron nitride nanotubes, boron nitride nanosheets, and zinc oxide nanowires, which you can find in items such as carbon fibre golf clubs and sunscreen. If we're going to be relying on these super-materials in the future, we need to be sure they won't have an adverse effect on our environment, and this study is a part of that analysis.\"Ideally, for a new technology to be successfully implemented, it needs to be shown that the technology does not cause adverse effects to the environment,\" explains the report, published in\u00a0Applied Materials & Interfaces. \"Therefore, unless the potential risks of introducing nanomaterials into the environment are properly addressed, it will hinder the industrialisation of products incorporating nanotechnology.\"\nAccording to the US Environmental Protection Agency, more than 1,300 commercial products use some kind of nanomaterial - a figure that's likely to rise sharply in the future - and at the moment we don't know as much as we really should about their full impact on health and the environment.Alternative methods such as filter paper and meshes often aren't effective enough at cleaning up nanomaterials, says team leader Dongyan Zhang, which is why he and his colleagues settled on the oil and water solution.\u00a0\"These materials are very, very tiny, and that means if you try to remove them and clean them out of contaminated water, that it's quite difficult,\" he said.His team's findings should help spur nanotechnology development, as cleaning up after these materials is relatively straightforwar"
        ]
    },
    "2951": {
        "gold_standard": [
            "There's no doubting that water repellent is a great way to keep clothing, shoes, and all sorts of other products safe and dry from water damage, but it can also involve toxic chemicals that aren't good for us or the environment.\nFortunately, a new water-repellent coating developed by researchers from Rice University is not only environmentally friendly, it's also inexpensive to make. The repellent, composed of a new class of superhydrophobic nanomaterials, takes its inspiration from a humble but nonetheless remarkable example of natural water repelling: the lotus leaf.\"Nature knows how to make these materials and stay environmentally friendly,\" said chemist Andrew Barron. \"Our job has been to figure out how and why, and to emulate that.\"The researchers' repellent can be applied to a variety of surfaces via spray- or spin-coating and is hydrocarbon-based, making it an economic and green alternative to conventional fluorocarbon-based repellents that are both hazardous and costly to manufacture.According to the researchers, the lotus leaf's remarkable ability to repel water is due to its hierarchy of microscopic and nanoscale double structures.\n\"In the lotus leaf, these are due to papillae within the epidermis and epicuticular waxes on top,\" said Barron. \"In our material, there is a microstructure created by the agglomeration of alumina nanoparticles mimicking the papillae and the hyperbranched organic moieties simulating the effect of the epicuticular waxes.\"To qualify as superhydrophobic, a material needs to demonstrate a water contact angle larger than 150 degrees. A water contact angle is the angle at which the surface of the water meets the surface of the material, quantifying the wettability (yes, it's a word) of a material.The researchers' repellent has an angle of about 155 degrees, making it essentially equivalent to the best fluorocarbon-based superhydrophobic coatings on the market. The findings are reported in Applied Materials & Interfaces.In addition to helping keep your hiking jacket dry, the researchers say the coating will also be useful in marine applications, especially in environments where water needs to be kept safe from potentially dangerous additives like fluorocarbons"
        ]
    },
    "2972": {
        "gold_standard": [
            "Self-awareness might seem like the most basic part of life to us humans, but it's a surprisingly rare concept when it comes to other animals. While great apes, dolphins, orcas, rhesus macaques, Eurasian magpies, and a single Asiatic elephant have all passed the self-recognition test, everything from pandas and pigeons to sea lions, gorillas, and several species of monkey have failed to show signs of consciousness.\nDogs were also on that list of failures - until now. Traditionally, self- consciousness is evaluated via the 'mirror test'. If an animal uses its own reflection to examine or touch a red mark that's been applied to its body without its knowledge, scientists can confirm that they possess some sense of self. But what if the animal isn't that visually oriented?\"I believed that because dogs are much less sensitive to visual stimuli with respect to what, for example, humans and many apes are, it is likely that the failure of this and of other species in the mirror test is mainly due to the sensory modality chosen by the investigator to test the self-awareness and not, necessarily, to the absence of this latter,\" says evolutionary biologist Roberto Cazzolla Gatti from Tomsk State University in Russia.Gatti was prompted into this line of thinking by the fact that in past mirror tests, dogs have shown no interest in looking at their reflection in the mirror, but they will go ahead and sniff the area and possibly even urinate around it. While this got them a big old \"fail\" in previous studies, Gatti thought the behaviour warranted a closer look.\u00a0Back in 2001, renowned animal behaviour expert, Marc Bekoff, investigated the 'mirror sniffing' phenomenon via an experiment dubbed the 'yellow snow test'. Yep it's exactly what it sounds like. Over a five-year period, Bekoff took his dog Jethro on walks during the winter months, and timed how long he would sniff clumps of snow soaked in his own or other dogs' urine.\nThe AnimalWise blog explains:\n\"Bekoff would wait until Jethro or other known female and male dogs urinated on snow, and then scoop up the clump of yellow snow as soon as Jethro was elsewhere and did not see him pick it up or move it (Bekoff used clean gloves each time and took other precautions to minimise odour and visual cues).\nBekoff then moved the yellow snow varying distances down the path so that Jethro would run across the displaced urine: (i) within about 10 seconds, (ii) between 10 and 120 seconds later, or (iii) between 120 and 300 seconds later. After Jethro arrived, Bekoff recorded how long he sniffed at the yellow snow, whether he urinated over it using the typical male raised-leg posture, and whether urination immediately followed the sniffing ('scent marking').\"\nNot surprisingly, Jethro paid a lot less attention to his own urine than he did to that of other dogs, so Bekoff concluded that his pet had to have some sense of self to be able to distinguish between scents. But with a sample size of one, the experiment wasn't exactly going to set the scientific community on fire.Gatti decided to come up with something a little more convincing. Called the Sniff Test of Self-Recognition (STSR), the experiment involved collecting urine samples from four stray dogs and systematically exposing them to the scents. He repeated this four times a year at the beginning of every season.\n\"I placed within a fence five urine samples containing the scent of each of the four dogs and a 'blank sample', filled only with cotton wool odourless,\" he says. \"The containers were then opened and each dog was individually introduced to the inside of the cage and allowed to freely move for 5 minutes. The time taken by each dog to sniff each sample was recorded.\"Just like Jethro, each dog spent way more time smelling the urine samples of other dogs than their own, which supports the hypothesis that they know their own scent and aren't that interested in it. The result was stronger the older the dog, which suggests that self-awareness develops with age.\u00a0It might seem obvious that dogs would know their own scent, but if you've ever seen a dog bark at its own reflection, or completely ignore it - totally unaware of its own appearance and movements - you can see the significance.\"I demonstrated that even when applying it to multiple individuals living in groups and with different ages and sexes, this test provides significant evidence of self-awareness in dogs and can play a crucial role in showing that this capacity is not a specific feature of only great apes, humans, and a few other animals, but it depends on the way in which researchers try to verify it,\" says Gatti.\nThe findings are published in the journal Ethology, Ecology and Evolution.Now, I know what you're thinking: that sample size of four is pretty crap. And yep, it is, so we can't really call this an official \"pass\" just yet. But the fact that we may well need to rethink the mirror test and figure out how to better align it with how certain species see the world is certainly worthy of a proper investigation. Certain behaviours such as empathy have been linked to self-awareness, and thanks to the 'yawn test', there's evidence that dogs feel empathy towards their owners.We'll just have to wait and see if scientists are prepared to conduct a giant yellow snow test to put this conundrum to bed once and for al"
        ]
    },
    "2997": {
        "gold_standard": [
            "Human beings have been dressing wounds with various kinds of bandages for thousands of years, but it's unlikely an injured person ever wore a Band-Aid quite like this.Researchers in the US have developed a sticky, stretchable gel-like material that can be used as a \"smart wound dressing\". Incorporating temperature sensors and drug reservoirs, the hydrogel bandage can release medicine in response to changes in skin temperature, and embedded LEDs even light up to let you know when your meds are running low.\n\"Electronics are usually hard and dry, but the human body is soft and wet. These two systems have drastically different properties,\" said Xuanhe Zhao, a mechanical engineer at the Massachusetts Institute of Technology (MIT).\"If you want to put electronics in close contact with the human body for applications such as health care monitoring and drug delivery, it is highly desirable to make the electronic devices soft and stretchable to fit the environment of the human body. That's the motivation for stretchable hydrogel electronics.\"The hydrogel matrix that makes up the dressing has numerous advantages over conventional cloth-based bandages. It's highly flexible and stretches easily so can be applied to any area of the body, including joints like elbows or knees.The rubbery material is mostly composed of water and can be embedded with a range of electronics such as conductive wires, semiconductor chips, LED lights, and temperature sensors.\nDescribing the dressing in Advanced Materials, the researchers say their bandage can deliver different drugs to different segments of skin in relation to their respective temperature, with medication flowing through pathways in the gel created via tube insertions or drilled holes.\"It's a very versatile matrix,\" said one of the team, Hyunwoo Yuk. \"The unique capability here is, when a sensor senses something different like an abnormal increase in temperature, the device can on demand release drugs to that specific location and select a specific drug from one of the reservoirs, which can diffuse in the hydrogel matrix for sustained release over time.\"The hydrogel would prove an efficient salve for things like burns and skin conditions, but according to the researchers, it's not limited to external use, and could even theoretically be used inside the body to house implanted electronics, such as glucose sensors or neural probes.\"The brain is a bowl of Jell-O,\" said Zhao. \"Currently, researchers are trying different soft materials to achieve long-term biocompatibility of neural devices. With collaborators, we are proposing to use robust hydrogel as an ideal material for neural devices, because the hydrogel can be designed to possess similar mechanical and physiological properties as the brain"
        ]
    },
    "3018": {
        "gold_standard": [
            "Scientists in Sweden have developed what they call \"power paper\" \u2013 a thin, paper-like material with a remarkable capacity to store energy.Just one sheet of the material measuring 15 centimetres in diameter and less than 0.5 millimetre thick can store 1 farad of electrical capacitance, which is about the same as many supercapacitors used in electric devices today.\nThe material, which is made from nanocellulose and a conductive polymer, can be used then recharged, lasting for hundreds of charge cycles. And best of all, it only takes a few seconds to power up again.\"Thin films that function as capacitors have existed for some time,\" said Xavier Crispin, a researcher from Link\u00f6ping University's Laboratory of Organic Electronics. \"What we have done is to produce the material in three dimensions. We can produce thick sheets.\"The researchers' material looks like black paper, but to the touch, has a more plasticky feel. Nonetheless, it exhibits other paper-like qualities too, such as strength, as demonstrated by its ability to be folded into origami shapes (the researchers apparently amused themselves by making an origami swan!).The team created the sheets by breaking down cellulose fibres using high-pressure water. These fibres measure just 20 nanometres in diameter, and are added to a water solution containing an electrically charged polymer. The polymer then forms a thin coating over the fibres.\n\"The covered fibres are in tangles, where the liquid in the spaces between them functions as an electrolyte,\" said one of the team, Jesper Edberg. The full process is described in Advanced Science.The material, which the researchers claim sets new records for simultaneous conductivity for ions and electrons, could have a significant impact on how we store charge in small devices, and with further research might even be able to serve higher-capacity power needs.Unlike the batteries and capacitors we currently use \u2013 which use large amounts of metal and often contain toxic chemicals \u2013 the power paper is made from simple materials: renewable cellulose and readily available polymer.According to the researchers, the paper is light, requires no dangerous chemicals or heavy metals, and is waterproof to boot. The one challenge is developing an industrial process to manufacture it on a large scale.Like regular pulp paper, the material has to be dehydrated to make the sheeting. If the team can solve this puzzle, possibly with the help of commercial partners, power paper could be something we see a lot more of in the futur"
        ]
    },
    "3074": {
        "gold_standard": [
            "APL Materials Just when we thought we knew pretty much everything there was to know about carbon, researchers have discovered a brand new phase of solid carbon, called Q-carbon. And they've shown they can use it to create cheap diamonds at room temperature and regular air pressure.\nPhases are distinct forms of the same material, and currently there are two known solid phases of carbon: graphite and diamond. But this research reveals a whole new, super rare, phase.\"We've now created a third solid phase of carbon,\" said lead researcher Jay Narayan from North Carolina State University. \"The only place it may be found in the natural world would be possibly in the core of some planets.\"In addition to being a novel phase of matter, Q-carbon also has some pretty weird characteristics that the scientists are getting excited about \u2013 for example, it's harder than diamond and glows when exposed to even low levels of energy.It's also ferromagnetic, which neither diamond or graphite are.\u00a0\"We didn't even think that was possible,\" adds Narayan.\u00a0\"Q-carbon's strength and low work-function \u2013 its willingness to release electrons \u2013 make it very promising for developing new electronic display technologies.\"\nBut for now what's most interesting about Q-carbon is that it can greatly reduce the cost and effort required to make diamond structures, which are used throughout the medical and technology industries. Right now, it usually takes incredible amounts of heat and pressure to produce synthetic diamonds, but the new technique works at room temperature and at ambient pressure.So how does it work? It all comes down to how Q-carbon is made \u2013 the scientists start with a substrate like glass or a plastic polymer, and then coat it with amorphous carbon (a type of carbon that doesn't have a well-defined crystalline structure).When that carbon is hit with a short laser pulse, the temperature skyrockets to around 3,727 degrees Celsius, before rapidly cooling down and forming a thin film of Q-carbon. But by mixing up the substrate and the duration of the laser pulse, the researchers can change how quickly the material cools down, which means they can create diamond structures with then Q-carbon.\"We can create diamond nanoneedles or microneedles, nanodots, or large-area diamond films, with applications for drug delivery, industrial processes and for creating high-temperature switches and power electronics,\" said Narayan.\nNanoneedles and microneedles are tiny needles that can be used in high-precision medical techniques. Nanodots are tiny structures that create super-small magnetic or electrical fields, and can be used to store huge amounts of information and energy, as well as create light emitting devices.\u00a0\"These diamond objects have a single-crystalline structure, making them stronger than polycrystalline materials,\"\u00a0added Narayan. \"And it is all done at room temperature and at ambient atmosphere \u2013 we're basically using a laser like the ones used for laser eye surgery. So, not only does this allow us to develop new applications, but the process itself is relatively inexpensive.\"The ability to quickly, cheaply, and easily make diamonds will be huge for a whole range of industries \u2013 not only because of the financial savings, but also because this new technique requires such little equipment.But the big question is, if Q-carbon is harder than diamond, why don't we just replace diamonds with the new phase? The short answer is because the phase of material is simply too new to be useful just yet.\u00a0\"We can make Q-carbon films, and we're learning its properties, but we are still in the early stages of understanding how to manipulate it,\" said Narayan. \"We know a lot about diamond, so we can make diamond nanodots. We don't yet know how to make Q-carbon nanodots or microneedles. That's something we're working on.\"The discovery will be published across two papers in the\u00a0Journal of Applied Physics\u00a0and\u00a0APL Material"
        ]
    },
    "3077": {
        "gold_standard": [
            "You only need to take a look at the hefty mainframes of the 1950s and 1960s to understand how quickly computers and electronics have been miniaturised, but there's room for them to go smaller still, if this new research is any indication. Scientists have come up with a new chip fabrication approach that they say could lead to much thinner and flexible computer chips in the future.\nDeveloped by a team at MIT, it's the\u00a0first chip fabrication technique where significantly different materials are deposited in the same layer. Today's computer chips, in contrast, are built from (very thin) layers stacked on top of one another, with precise patterns etched into them. The researchers say they've refined the process far enough to be able to build chips containing \"all the circuit components necessary to produce a general-purpose computer\".\"The methodology is universal for many kinds of structures,\" says Xi Ling, one of the authors of the paper. \"This offers us tremendous potential with numerous candidate materials for ultra-thin circuit design.\"The layers of material are just 1-3 atoms thick, and they chose graphene as one of the materials used - the 'wonder material' has already been used in a variety of different innovations and experiments, and its thinness and strength makes it perfect for use in thin-film electronics.In fact, the new process can mix any material that combines elements from group 6 of the periodic table (including chromium, molybdenum, and tungsten) and elements from group 16 (including sulphur, selenium, and tellurium). As many of these compounds are semiconductors - which form the basis of transistor design - they can prove very useful in extremely thin layers of electronics.\nIn the tests run by the MIT team, a layer of graphene is deposited on a silicon substrate, with gaps etched in for the second material to fill. This second material, molybdenum disulphide, is applied using a solid bar of material known as a PTAS. As the PTAS passes over the chip, its molecules cause a reaction with the exposed silicon, and a layer of molybdenum disulphide is formed. The same process can be used to combine several different materials in the same way.While the science is tricky to wrap your head around, the eventual applications are simple: thinner, more flexible electronics that take new shapes, set new levels of portability, or attach themselves to other objects as a layer of film. The next step is to use the technology to try and create tunnelling-transistor processors, which use a quantum mechanical effect to block a charge or allow it through.The work has been published in the journal Advanced Materials.*Image above: The researchers used the MIT and Tim the Beaver logos to show photoluminescence emissions from a monolayer of molybdenum disulfide inlayed onto graphene. The arrow indicates the graphene-MoS2 lateral heterostructure, which could potentially form the basis for ultrathin computer chip"
        ]
    },
    "3117": {
        "gold_standard": [
            "A team of Russian physicists has figured out how to keep a key component in light-based computers from overheating, which means one of the biggest obstacles standing between us and processing data at the speed of light might have just been overcome.\nThe simple act of replacing electrons with light particles (photons) in our microprocessors would not only result in computers that run tens of thousands of times faster, it would also solve a very big problem that affects us all - we've just about hit the limit for how fast electrons can travel between the processor and the memory.Known as the von-Neumann bottleneck, this problem means there's no point developing faster processors for electron-based computer systems if we've already hit the limit for how fast information can be transported to and from the memory. We need to completely rethink the system, and that's where quantum computers (which replace bits with qubits) and light-based computers (which replace electrons with photons) come in.While the idea of replacing electrons with photons sounds pretty simple, actually making it happen is anything but. As we explained back in September, while running current computers on light instead of electricity would effectively speed up the rate at which we could transmit data, silicon chips still require the photons to be converted back to electrons in order to be processed.\u00a0This means everything would be slowed back down again, and the system would consume a whole lot of extra energy during the conversion process, which makes it even less efficient than if we'd just used electrons in the first place.\nSo we need to rebuild our computers from the ground-up to handle photons, that much is clear, and the likes of IBM, Intel, HP, and the US Defense Force are currently investing billions of dollars into developing the 'optoelectronic chips' required. These chips compute electronically, but use light to move information.\u00a0If you've ever seen a microchip up close, you'll know they're composed of all kinds of tightly wound channels along which the electrons travel. The problem with building a photon-compatible version of this is that it's extremely difficult to get light to travel around bends. The answer? Plasmonic components, \"which take advantage of the unique oscillating interactions of photons and electrons on the surface of metal\", Patrick Tucker explains over at Defense One.Sounds good right? But once again, it's not that simple. A lightwave is approximately 1 micrometre (1,000 nanometres), but we're close to making transistors as small as 10 nanometres. So we have two options: transmit lightwaves 'as is' and destroy an efficiency gains by having enormous components, or confine the light into nanoscale surface waves known as surface plasmon polaritons (SPPs).We can do all of this already, but in the process, the plasmonic components will experience temperature increases of around 100 Kelvin, and basically fizzle out and die. And keeping them cool isn't as easy as simply running a fan over them.\u00a0\"You need a cooling system that works on the scale of the photonic chip's key features, less than a billionth of a metre in size,\" says Tucker. \"It's one reason why many don't consider fully light-based transistors a practical possibility for decades.\"\nIn the words of George Constanza himself, \"Why must there always be a problem?\"But for the first time, researchers from the Moscow Institute of Physics and Technology say they've come up with a solution. The heat comes from when the SPPs are absorbed by the metal in the components, so the Russian researchers have inserted what they call 'high-performance thermal interfaces' into the components to protect them from the metal.These interfaces are basically just layers of thermally conductive materials placed between the chip and a conventional cooling system to ensure efficient heat removal from the chip, the team explains in the journal\u00a0ACS Photonics. They say this method can keep temperature increases to within 10 degrees Celsius.It's now up to the researchers to demonstrate this working within a more complete computer system, and they've got their work cut out. Late last year, UK-based researchers made their own significant advances towards light-based computer technology, so it's 'game on' for everybody involve",
            "A team of Russian physicists has figured out how to keep a key component in light-based computers from overheating, which means one of the biggest obstacles standing between us and processing data at the speed of light might have just been overcome.\nThe simple act of replacing electrons with light particles (photons) in our microprocessors would not only result in computers that run tens of thousands of times faster, it would also solve a very big problem that affects us all - we've just about hit the limit for how fast electrons can travel between the processor and the memory.Known as the von-Neumann bottleneck, this problem means there's no point developing faster processors for electron-based computer systems if we've already hit the limit for how fast information can be transported to and from the memory. We need to completely rethink the system, and that's where quantum computers (which replace bits with qubits) and light-based computers (which replace electrons with photons) come in.While the idea of replacing electrons with photons sounds pretty simple, actually making it happen is anything but. As we explained back in September, while running current computers on light instead of electricity would effectively speed up the rate at which we could transmit data, silicon chips still require the photons to be converted back to electrons in order to be processed.\u00a0This means everything would be slowed back down again, and the system would consume a whole lot of extra energy during the conversion process, which makes it even less efficient than if we'd just used electrons in the first place.\nSo we need to rebuild our computers from the ground-up to handle photons, that much is clear, and the likes of IBM, Intel, HP, and the US Defense Force are currently investing billions of dollars into developing the 'optoelectronic chips' required. These chips compute electronically, but use light to move information.\u00a0If you've ever seen a microchip up close, you'll know they're composed of all kinds of tightly wound channels along which the electrons travel. The problem with building a photon-compatible version of this is that it's extremely difficult to get light to travel around bends. The answer? Plasmonic components, \"which take advantage of the unique oscillating interactions of photons and electrons on the surface of metal\", Patrick Tucker explains over at Defense One.Sounds good right? But once again, it's not that simple. A lightwave is approximately 1 micrometre (1,000 nanometres), but we're close to making transistors as small as 10 nanometres. So we have two options: transmit lightwaves 'as is' and destroy an efficiency gains by having enormous components, or confine the light into nanoscale surface waves known as surface plasmon polaritons (SPPs).We can do all of this already, but in the process, the plasmonic components will experience temperature increases of around 100 Kelvin, and basically fizzle out and die. And keeping them cool isn't as easy as simply running a fan over them.\u00a0\"You need a cooling system that works on the scale of the photonic chip's key features, less than a billionth of a metre in size,\" says Tucker. \"It's one reason why many don't consider fully light-based transistors a practical possibility for decades.\"\nIn the words of George Constanza himself, \"Why must there always be a problem?\"But for the first time, researchers from the Moscow Institute of Physics and Technology say they've come up with a solution. The heat comes from when the SPPs are absorbed by the metal in the components, so the Russian researchers have inserted what they call 'high-performance thermal interfaces' into the components to protect them from the metal.These interfaces are basically just layers of thermally conductive materials placed between the chip and a conventional cooling system to ensure efficient heat removal from the chip, the team explains in the journal\u00a0ACS Photonics"
        ]
    },
    "3135": {
        "gold_standard": [
            "This article was written by Emma Stone and Alex Farnsworth from the University of Bristol, and was originally published by The Conversation.It's official: 2015 was the warmest year on record. But those global temperature records only date back to 1850 and become increasingly uncertain the further back you go. Beyond then, we're reliant on signs left behind in tree rings, ice cores or rocks. So when was Earth last warmer than the present?\nThe Medieval Warm Period is often cited as the answer. This spell, beginning in roughly 950AD and lasting for three centuries, saw major changes to population centres across the globe. This included the collapse of the Tiwanaku civilisation in South America due to increased aridity, and the colonisation of Greenland by the Vikings.But that doesn't tell the whole story. Yes, some regions were warmer than in recent years, but others were substantially colder. Across the globe, averaged temperatures then were in fact cooler than today.To reach a point when Earth was significantly warmer than today we'd need to go back 130,000 years, to a time known as the Eemian.\u00a0For about 1.8 million years the planet had fluctuated between a series of ice ages and warmer periods known as 'interglacials'. The Eemian, which lasted around 15,000 years, was the most recent of these interglacials (before the one we're currently in).Although global annual average temperatures were approximately 1 to 2\u02daC warmer than preindustrial levels, high latitude regions were several degrees warmer still. This meant ice caps melted, Greenland's ice sheet was reduced and the West Antarctic ice sheet may have collapsed. The sea level was at least 6 m higher than today.\nAcross Asia and North America forests extended much further north than today and straight-tusked elephants (now extinct) and hippopotamuses were living as far north as the British Isles.How do we know all this? Well, scientists can estimate the temperature changes at this time by looking at chemicals found in ice cores and marine sediment cores and studying pollen buried in layers deep underground. Certain isotopes of oxygen and hydrogen in ice cores can determine the temperature in the past while pollen tells us which plant species were present and therefore gives us an indication of climatic conditions suitable for that species.We know from air bubbles in ice cores drilled on Antarctica that greenhouse gas concentrations in the Eemian were not dissimilar to preindustrial levels. However orbital conditions were very different \u2013 essentially there were much larger latitudinal and seasonal variations in the amount of solar energy received by Earth.So although the Eemian was warmer than today the driving mechanism for this warmth was fundamentally different to present-day climate change, which is down to greenhouses gases. To find a warm period caused predominantly by conditions more similar to today, we need to go even further back in time.Glen Fergus/WikimediaAs climate scientists, we're particularly interested in the Miocene (around 23 to 5.3 million years ago), and in particular a spell known as the Miocene-Climate Optimum (11-17 million years ago). Around this time CO2\u00a0values (350-400 parts per million) were similar to today and it therefore potentially serves as an appropriate analogue for the future.\nDuring the Optimum, those carbon dioxide concentrations were the predominant driver of climate change. Global average temperatures were 2 to 4\u02daC warmer than preindustrial values, sea level was around 20 m higher and there was an expansion of tropical vegetation.However, during the later Miocene period CO2\u00a0declined to below preindustrial levels, but global temperatures remained significantly warmer. What kept things warm, if not CO2? We still don't know exactly - it may have been orbital shifts, the development of modern ocean circulation or even big geographical changes such as the Isthmus of Panama narrowing and eventually closing off\u00a0- but it does mean direct comparison with the present day is problematic.Currently orbital conditions are suitable to trigger the next glacial inception. We're due another ice age. However, as pointed out in a recent study in Nature, there's now so much carbon in the atmosphere the likelihood of this occurring is massively reduced over the next 100,000 years.Emma Stone, Research Associate in Climatology, University of Bristol and Alex Farnsworth, Postdoctoral Researcher in Climatology, University of Bristol.This article was originally published by\u00a0The Conversation. Read the original article"
        ]
    },
    "3183": {
        "gold_standard": [
            "This article was written by\u00a0Paul Coxon\u00a0from the\u00a0University of Cambridge, and was originally published by The Conversation.Ask most people what the hardest material on Earth is and they will probably answer \"diamond\". Its name comes from the Greek word \u1f00\u03b4\u03ac\u03bc\u03b1\u03c2 (ad\u00e1mas) meaning \"unbreakable\" or \"invincible\" and is from where we get the word \"adamant\". Diamond's hardness gives it incredible cutting abilities that - along with its beauty - have kept it in high demand for thousands of years.\u00a0Modern scientists have spent decades looking for cheaper, harder and more practical alternatives and every few years the news heralds the creation of a new \"world's hardest material\". But are any of these challengers really up to scratch?\nDespite its unique allure, diamond is simply a special form, or 'allotrope', of carbon. There are several allotropes in the carbon family including carbon nanotubes, amorphous carbon, diamond, and graphite. All are made up of carbon atoms, but the types of atomic bonds between them differ which gives rise to different material structures and properties.The outermost shell of each carbon atom has four electrons. In diamond, these electrons are shared with four other carbon atoms to form very strong chemical bonds resulting in an extremely rigid tetrahedral crystal. It is this simple, tightly-bonded arrangement that makes diamond one of the hardest substances on Earth.How hard?Vickers test anvil. R Tanaka, CC BYHardness is an important property of materials and often determines what they can be used for, but it is also quite difficult to define. For minerals, scratch hardness is a measure of how resistant it is to being scratched by another mineral.\nThere are several ways of measuring hardness but typically an instrument is used to make a dent in the material's surface. The ratio between the surface area of the indentation and the force used to make it produces a hardness value. The harder the material, the larger the value. The Vickers hardness test uses a square-based pyramid diamond tip to make the indent.Mild steel has a Vickers hardness value of around 9GPa while diamond has a Vickers hardness value of around 70 - 100GPa. Diamond's resistance against wear is legendary and today 70 percent of the world's natural diamonds are found in wear-resistant coatings for tools used in cutting, drilling and grinding, or as additives to abrasives.The problem with diamond is that, while it may be very hard, it is also surprisingly unstable. When diamond is heated above 800\u2103 in air its chemical properties change, affecting its strength and enabling it to react with iron, which makes it unsuitable for machining steel.These limits on its use have led to a growing focus on developing new, chemically-stable, superhard materials as a replacement. Better wear-resistant coatings allow industrial tools to last longer between replacing worn parts and reduce the need for potentially environmentally-hazardous coolants. Scientists have so far managed to come up with several potential rivals to diamond.\nBoron nitrideMicroscopic BN crystal. NIMSoffice/WikimediaThe synthetic material boron nitride, first produced in 1957, is similar to carbon in that it has several allotropes. In its cubic form (c-BN) it shares the same crystalline structure as diamond, but instead of carbon atoms is made up of alternately-bonded atoms of boron and nitrogen. c-BN is chemically and thermally stable, and is commonly used today as a superhard machine tool coating in the automotive and aerospace industries.But cubic boron nitride is still, at best, just the world's second hardest material with a Vickers hardness of around 50GPa. Its hexagonal form (w-BN) was initially reported to be even harder but these results were based upon theoretical simulations that predicted an indentation strength 18 percent higher than diamond. Unfortunately w-BN is extremely rare in nature and difficult to produce in sufficient quantities to properly test this claim by experiment.\nSynthetic diamondSynthetic diamond has also been around since the 1950s and is often reported to be harder than natural diamond because of its different crystal structure. It can be produced by applying high pressure and temperature to graphite to force its structure to rearrange into the tetrahedral diamond, but this is slow and expensive. Another method is to effectively build it up with carbon atoms taken from heated hydrocarbon gases but the types of substrate material you can use are limited.Producing diamonds synthetically creates stones that are polycrystalline and made up of aggregates of much smaller crystallites or 'grains' ranging from a few microns down to several nanometres in size. This contrasts with the large monocrystals of most natural diamonds used for jewellery. The smaller the grain size, the more grain boundaries and the harder the material. Recent research on some synthetic diamond has shown it to have a Vickers hardness of up to 200 GPa.Q-carbonMore recently, researchers at North Carolina State University created what they described as a new form of carbon, distinct from other allotropes, and reported to be harder than diamond. This new form was made by heating non-crystalline carbon with a high-powered fast laser pulse to 3,700\u00b0C then quickly cooling or 'quenching' it - hence the name Q-carbon - to form micron-sized diamonds.\nThe scientists found Q-carbon to be 60 percent harder than diamond-like carbon (a type of amorphous carbon with similar properties to diamond). This has led them to expect Q-carbon to be harder than diamond itself, although this still remains to be proven experimentally. Q-carbon also has the unusual properties of being magnetic and glowing when exposed to light. But so far its main use has been as an intermediate step in producing tiny synthetic diamond particles at room temperature and pressure. These nanodiamonds are too small for jewellery but ideal as a cheap coating material for cutting and polishing tools.Paul Coxon, Postdoctoral research associate, University of Cambridge.This article was originally published by\u00a0The Conversation"
        ]
    },
    "3188": {
        "gold_standard": [
            "Research in mice has shown that high doses of cocaine can trigger \"out-of-control autophagy\" in the brain - which means that the drug causes brain cells to literally digest themselves at an unprecedented rate. And that's not great news, considering around 1.9 million people in the US admit to regularly taking cocaine.\nAlthough it sounds scary, autophagy is actually a totally normal way for our cells clean up their waste and stay healthy. But when mice are given a hefty dose of cocaine, that process goes dangerously into overdrive, a team from the Johns Hopkins University School of Medicine has discovered.\"A cell is like a household that is constantly generating trash,\" said lead author of the study, Prasun Guha. \"Autophagy is the housekeeper that takes out the trash - it's usually a good thing. But cocaine makes the housekeeper throw away really important things, like mitochondria, which produce energy for the cell.\"So why were the researchers so interested in how cocaine affects the brain? It's been known for years that cocaine can trigger cell death, but until now, no one has been able to confirm how this happens, and - more importantly - how to stop it.\u00a0There are three different ways that cells can commit suicide, but after examining neurons taken from mice that had been given cocaine, the team was able to clearly determine that the cells were dying as a result of out-of-control autophagy.\n\"We performed 'autopsies' to find out how cells die from high doses of cocaine,\" said one of the researchers, Solomon Snyder. \"That information gave us immediate insight into how we might use a known compound to interfere with that process and prevent the damage.\"The known compound he's talking about is called CGP3466B. It's an experimental drug that's been used in clinical trials against Parkinson's and motor neurone disease, so it's known to be safe in humans.The researchers have now also shown that the compound can protect mouse neurons from being destroyed by cocaine use.\u00a0Unfortunately, just because CGP3466B\u00a0protects mouse brain cells against the drug, doesn't mean it'll work in humans, and the researchers stress that we're a long way being able to protect our brains against the damage of cocaine.\u00a0But it's a good place to start. \"Since cocaine works exclusively to modulate autophagy versus other cell death programs, there's a better chance that we can develop new targeted therapeutics to suppress its toxicity,\" said one of the team, Maged M. Harraz.Some people might argue that there's no point in protecting people against the effects of cocaine when they're choosing to take it. But the research, which has been published in the\u00a0Proceedings of the National Academy of Sciences,\u00a0also found signs of out-of-control autophagy in mouse pups after their mothers had been given the drug - making it clear that it's not just users who are at risk"
        ]
    },
    "3201": {
        "gold_standard": [
            "A defence mechanism secreted by hagfish could be the key to developing super hydrogels for human use, scientists say.Researchers in Switzerland have been studying the Atlantic hagfish (Myxine glutinosa), and specifically the slimy material it secretes when attacked by a predator. The slime, an extremely soft and elastic hydrogel, might not look dangerous in the image above, but it can be lethal to sea creatures.\nWhen secreted in water from the glands of an agitated hagfish, the defensive liquid gels together with tiny fibres in a split second, creating a slimy mass to protect the hagfish. The slime forms a thick, viscous network that can immobilising the surrounding water and suffocate potential threats.When Simon Kuster, a researcher at ETH Zurich, saw footage of the remarkable slime on a TV documentary, he was immediately fascinated. Hydrogels are a form of super-absorbent polymer with a hydrophilic molecular structure, which means they can hold large amounts of water. They're of great interest to scientists for their use in fields such as tissue engineering, drug delivery, and biosensors, among other applications.\"As a chemist and material scientist, I couldn't help but wonder what this slime consists of and what factors allow it to immobilise such enormous amounts of water,\" he said.Kuster set about examining the natural hydrogel to see what makes it so dangerously slimy. The gel is composed of two elements: long protein threads measuring 15-to\u201330 centimetres (6-to\u201312 inches) in length, and mucin, a protein constituent of mucus.\nThe protein threads are much like spider thread, being extremely tear-resistant and moist. When the threads and mucin are released into seawater, they form a matrix that absorbs and immobilises water and solids in the immediate area.To study hagfish slime, the Kuster and his team travelled to Norway, where a research partner was authorised to catch hagfish in the wild and keep them in an aquarium. While research back at their facilities would be more sophisticated, ferrying the animals back home was not an option.\"The transport would stress the hagfish too much,\" said Lukas B\u00f6cker, one of the team. \"They would secrete slime throughout the journey and eventually suffocate in their own slime.\"The researchers' preliminary analysis of the slime, reported in ACS Biomaterials Science & Engineering, details how they found a way to stabilise the glandular secretion using negatively charged biopolymers to form fibre-enforced hydrogels. Without this, the hydrogel eventually collapses in seawater"
        ]
    },
    "3216": {
        "gold_standard": [
            "A team in Germany has developed tiny robot suits that can help sperm become more mobile, solving one of the biggest causes of infertility in men. If the researchers can successfully replicate their lab results inside the human body, it could be a new option for couples struggling to conceive.\nThese 'spermbots' are miniature metal helixes just large enough to completely wrap around the tail of a single sperm and help it along its way towards the egg. The bots are powered with the assistance of a magnetic field controlled by the scientists, though all of the experiments undertaken so far have been with bull sperm in the confines of a petri dish. Once the sperm has reached its target and become embedded in the egg, the metal casing can reverse direction to detach itself.While still at an early stage, the new spermbots could theoretically provide a more effective and less expensive alternative to artificial insemination and in vitro fertilisation (where the egg is removed from the body before being fertilised) for couples. The work of the group from the Institute for Integrative Nanosciences at IFW Dresden has now been published in the journal Nano Letters.\"Our results indicate that metal-coated polymer microhelices are suitable for this task due to potent, controllable, and non-harmful 3D motion behaviour,\" explains the report.\u00a0\"Despite the fact that there still remain some challenges on the way to achieve successful fertilisation with artificially motorised sperms, we believe that the potential of this novel approach toward assisted reproduction can be already put into perspective with the present work.\"\nNew Scientist reports that the tiny bots are 50 microns long, 5-8 microns in diameter and made from iron and titanium nanoparticles (1,000 microns makes up a millimetre); eventually, they could find a broader range of uses. The University of Toronto's Eric Diller, who wasn't involved in the research, told the publication: \"This type of hybrid approach could lead the way in making efficient robotic micro-systems,\"The next stages for the team are working out an improved method of controlling the direction of these spermbots, upgrading the micromotor construction that they're built on, and investigating any potential issues with the body's immune system"
        ]
    },
    "3218": {
        "gold_standard": [
            "There's no shortage of research on the physiological health benefits of standing up\u00a0during the day instead of spending your time in sedentary positions, but what about the effects on mental performance?\nA new study in the US has found that high school students demonstrated improved cognitive functioning after half a year of using standing desks, prior to which they had only used conventional sitting desks during lessons.\"There has been lots of anecdotal evidence\u00a0from teachers that students focused and behaved better while using standing desks,\" said Mark Benden, one of the researchers from Texas A&M University. \"This is the first examination of students' cognitive responses to the standing desks, which to date have focused largely on sedentary time as it relates to childhood obesity.\"The researchers recruited 34 freshman high school students to assess their executive functions via a series of computerised tests at two points during the school year. Executive functions\u00a0are the kinds of cognitive functions we use to analyse tasks, and they're directly related to academic skills such as our ability to memorise and comprehend facts, organise our thoughts, and solve problems.Executive functions are largely regulated in frontal brain regions, and the researchers used functional near-infrared spectroscopy\u00a0(fNIRS) to image the students' brains as they did the tests. The two tests were roughly half a year apart, during which time the students involved continuously used the standing desks.\nThe results, reported in the International Journal of Environmental Research and Public Health, showed that \"continued use of standing desks was associated with significant improvements in executive function and working memory capabilities,\" according to one of the team, Ranjana Mehta. \"Changes in corresponding brain activation patterns were also observed.\"The boosts were significant too, with the students showing an approximate 7 to 14 percent improvement in cognitive performance across several executive function and working memory tasks after half a year of standing lessons. Further, brain imaging using fNIRS revealed significant left frontal lobe activation during three of the five tasks.\u00a0Despite the promise of the research, there are a number of caveats to this study, which the authors acknowledge, calling their exploratory paper\u00a0a \"first contribution to the existing knowledge base\" in this area.Specifically, only two testing sessions were recorded with the students, and the number of volunteers was very small (and dropped to just 27 students by the end of the study). It's also important to bear in mind that there was no control group with which to contrast the results of the students using standing desks.\nHowever, the authors are also involved in a larger two-year study converting a Texas high school from traditional seated classrooms to stand-biased classrooms. If that larger study and subsequent research in the field can back up some of the preliminary findings here, a move to standing desks could well turn out to be a simple and effective change for schools to implement \u2013 and one which may improve students' health and academic performance at the same time.\"Interestingly, our research showed the use of standing desks improved neurocognitive function, which is consistent with results from previous studies on school-based exercise programs,\" said Mehta. \"The next step would be to directly compare the neurocognitive benefits of standing desks to school-based exercise programs.\"One of the advantages of standing desks over exercise programs is\u00a0 the ease with which they can be installed and used within schools.\u00a0\"In comparison to most school-based physical activity programs, standing desk interventions are non-intrusive \u2013 i.e. does not require any additional training, instructional time, nor accommodations and therefore does not tax school resources,\" the authors write. Sounds like a win-win, provided these encouraging early results can be replicated in future researc"
        ]
    },
    "3230": {
        "gold_standard": [
            "This article was written by\u00a0Rob Knell\u00a0from\u00a0Queen Mary University of London,\u00a0and was originally published by The Conversation.Part of dinosaurs' popularity has to be their fascinating, bizarre appearance. There's the Stegosaurus with the famous row of plates down its back, the Triceratops with its giant frilled skull, and the 'duck-billed'\u00a0hadrosaurs with their peculiar and diverse array of crests.\nPalaeontologists have been trying to decipher the function of these extravagant traits for many years. The Stegosaurus plates have been described as a way to regulate body temperature and it's even been suggested that the hadrosaur crest might have been a kind of snorkel.More recently, it has become increasingly popular to see these kind of features in the same way as the enlarged fins of male Siamese fighting fish or the plumes of birds of paradise. These are best explained as traits that evolved not because they improve survival but because they improve the mating success of the bearer. My colleagues and I at Queen Mary University of London have now found what we believe to be some of the best evidence of unusual dinosaur features that were primarily used in this way.Sexual selection'Sexual selection'\u00a0explains how animals can evolve features that may even reduce the bearer's survival. For example, some male birds such as widowbirds or pheasants have extraordinarily long tail feathers that require a lot of protein to grow and reduce the male bird's ability to fly. Because the females of these species choose the males with the longest tails to father their chicks, those males have the highest evolutionary fitness despite being effectively handicapped by their ornaments.\nWe now know that sexual selection is the driving force behind the great majority of the extravagant, ornamental and showy traits that we find in the animal kingdom. This has led more and more palaeontologists to ask whether sexual selection might also be behind the apparently ornamental traits that we find in many extinct species.The problem is that it's extremely difficult to tell if a particular feature of an extinct, prehistoric animal gave it an advantage in the mating game. What's more, there are examples of apparently pointless features of animals that have turned out to have had 'normal'\u00a0functional roles, such as the protruding snouts of paddlefish used as sensory organs. If we just decide that anything that seems a bit strange and inexplicable on a dinosaur fossil must have arisen by sexual selection, we run the risk of misinterpreting odd-looking but functional traits in these ancient animals, and palaeontologists have avoided using sexual selection as an explanation for the evolution of extravagant traits for this reason.Your horns are showing. Daderot/Wikimedia CommonsOne thing we can do to try to work out if a feature has evolved through sexual selection is study its size compared to the rest of the animal's body. When something gets proportionally bigger as an animal gets bigger we say that it has positive allometry. Although it's by no means a universal rule, there seems to be a strong tendency for sexually selected traits, especially those that function as signals for attracting females or intimidating rivals, to be positively allometric. Positive allometry is also quite rare among traits that are not sexually selected.\nMeasuring the allometry of these extravagant traits in dinosaurs isn't possible for many species because most extinct animals are only known from one or a few fossils. Complete specimens of dinosaurs are the exception and it's difficult to even tell males from females. One of the few species we have decent numbers of specimens of is the dinosaur Protoceratops andrewsi. This smaller relative of the famous Triceratops had a skull that elongated into a large frill.My colleagues and I were able to put together a set of 37 Protoceratops fossils ranging in size from tiny juveniles up to the largest adults. By measuring the specimens' skulls, we found that bigger Protoceratops had proportionally longer and wider frills \u2013 positive allometry. What's more, larger animals seemed to have frills that spread more widely around the head whereas those of smaller animals were almost flat against the neck.Colourful animalsThis information strongly supports the idea that the frills of these animals, and by extension those of other related dinosaurs, were primarily a signal for other members of their species"
        ]
    },
    "3256": {
        "gold_standard": [
            "Advanced Materials The idea of kitting out rooftops with environmentally friendly gardens or solar panels has been around for some time, but an international team of scientists has hit upon the idea of carpeting roofs with plastic grass-like material instead. Each plastic blade acts as a miniature wind turbine, generating power for the home below with each gust.\nThe so-called turboelectric generator (TENG) uses strips of upright plastic 'grass' blades. One side of each blade is coated with nanowires while the other is coated with indium tin oxide. As the wind brushes the blades, they come into contact with each other, allowing electrons to pass from one piece of grass to the next and generating an electric current as a result.It's known as the triboelectric effect, where contact between two dissimilar surfaces builds up an electric charge (it's the same principle that causes static electricity). The team behind the new power-generating artificial grass, from China's Southwest Jiaotong University and the Georgia Institute of Technology in the US, says\u00a0it would be especially suitable in areas where the wind is often changing direction, as well as locations where windmills are impractical.When they tested an iteration with 60 strips of plastic grass on a model rooftop, it was enough to power 60 LED lights once the blast of an electric fan was trained on them. The system can reportedly work with winds as light as 21 km/h (13 mph), while the sweet spot in terms of energy efficiency is a rather blustery 100 km/h (62 mph).After doing the maths, the researchers predict that a 300-square-metre (3,230-square-foot) rooftop would produce about 7.11 kilowatts - almost enough energy to power a home on its own. Putting this idea into practice is still a long way off though - not only do they need to find an efficient way of storing the energy before it's used, they also need to find a replacement for indium tin oxide, which is both toxic and expensive.\n\"The concept is highly promising but its realisation depends on shifting to other materials,\" energy researcher Fernando Galembeck told James Urquhart at\u00a0New Scientist.One possible approach would be to combine the new artificial grass material with efficient solar panels on top of the building, with photovoltaic cell technology getting more advanced all the time.The study has been published in the journal Advanced Material"
        ]
    },
    "3259": {
        "gold_standard": [
            "A new half-solid, half-liquid adaptive material created by scientists in the US displays a number of amazing properties, including the ability to self-heal \u2013 stitching itself back together once divided \u2013 and self-stiffen back into its original shape after being compressed.\nThe material, called SAC \u2013 which stands for self-adaptive composite \u2013 is composed of a mass of sticky, micron-scale rubber balls that cling together to create a solid matrix. The composite is capable of healing itself repeatedly when cracked, and behaves kind of like a sponge, regaining its original form after being disturbed.Unlike similar self-healing materials that behave more like liquids, SAC is remarkably solid. \"We wanted a biomimetic material that could change itself, or its inner structure, to adapt to external stimulation and thought introducing more liquid would be a way,\" said one of the researchers, Alin Cristian Chipara from Rice University. \"But we wanted the liquid to be stable instead of flowing everywhere.\"The solution was to mix two polymers together with a solvent. When heated the solvent evaporates, leaving a porous mass of gooey spheres. The liquid-encasing spheres are made from polyvinylidene fluoride (PVDF) and are coated in a viscous layer of polydimethylsiloxane (PDMS).\"The sample doesn't give you the impression that it contains any liquid,\" said material scientist, Jun Lou. \"That's very different from a gel. This is not really squishy; it's more like a sugar cube that you can compress quite a lot. The nice thing is that it recovers.\"\nThe researchers say the composite is easy to manufacture, and the liquid:solid ratio of the final mix can be tweaked depending on how you ultimately want SAC to behave.\"Gels have lots of liquid encapsulated in solids, but they're too much on the very soft side,\" said one of the team, Pulickel Ajayan. \"We wanted something that was mechanically robust as well. What we ended up with is probably an extreme gel in which the liquid phase is only 50 percent or so.\"In testing, SAC demonstrated up to a 683 percent increase in its storage modulus \u2013 a parameter used to characterise self-stiffening behaviour. According to the team, this is much larger than that reported for solid composites and other materials.The findings are reported in Applied Materials & Interfaces.While the material is currently only being made in the 150-millilitre containers the researchers use in the lab, they say they have a design that could scale up process, and believe SAC could be used in a wide range of applications, including as a biocompatible material for tissue-engineering, or as a lightweight, defect-tolerant structural component"
        ]
    },
    "3280": {
        "gold_standard": [
            "Advanced Energy Materials As solar power becomes a bigger part of our overall energy mix, scientists are working on more efficient ways of storing the power of the Sun for use during the night-time, or on particularly cloudy days. And now a new type of material has been developed that can do just that - store solar energy when it's in abundance, and release it as heat later on as required.\nThe transparent polymer film developed by a team from MIT can be applied to many surfaces, including glass and clothing. So imagine a warm jumper that goes with you from room to room, so there's no need to fiddle with your central heating controls. Or a windshield overlay system that can burn away the ice on your car first thing in the morning, thanks to energy it had built up from the previous day.\u00a0\"This work presents an exciting avenue for simultaneous energy harvesting and storage within a single material,\" the University of Toronto's Ted Sargent, who wasn't involved in the research, told MIT News. \"The approach is innovative and distinctive.\"Many solar energy storage initiatives focus on converting the energy to electricity and then keeping the electricity saved for later use. This approach instead uses a chemical reaction that produces heat rather than power: in this way the energy can be retained indefinitely in \"a stable molecular configuration\", until it's ready to be deployed, the researchers explain.The key to the process is a molecule that can remain stable in one of two configurations. Sunlight kicks it into a long-lasting 'charged' mode, and then another stimulus - such as light, heat, or electricity - is used to return it to its original, 'not charged' state, and a burst of heat given off as a result.\nSuch solar thermal fuels (STF) have been developed before, but this new method is the first based on a solid-state material (in this case a polymer) rather than a liquid, and that can make all the difference in terms of how it can be used. What's more, it's based on inexpensive materials and with widespread manufacturing in mind.The researchers are continuing to tweak the existing formula: they want to remove the slight yellowish tinge that the polymer currently has, and boost the heat level increase from 10\u00b0C up to 20\u00b0C. One of the first practical uses could be in electric cars, which can suffer from reduced driving ranges in cold weather due to the extra energy required for heating.The research has been published i"
        ]
    },
    "3304": {
        "gold_standard": [
            "A section of the serpentine channel reactor. Credit: Oak Ridge National Laboratory\nIn remote parts of the world, getting vital medication to the people who need them can be a real challenge, so researchers in the US have developed a tiny, portable bioreactor that can generate a variety of drugs from any location.\nWhen a mixture of acids and cell extracts are fed into the reactor, it can produce proteins needed to treat everything from diabetes to anaemia, and various kinds of infections, and more efficiently than\u00a0commercial devices in use today. \"We show that the microscale bioreactor design produces higher protein yields than conventional\u00a0tube-based batch formats and that product yields can be dramatically improved by facilitating small molecule exchange with the dual-channel bioreactor,\" the team from Oak Ridge National Laboratory\u00a0reports.At the heart of the miniature bioreactor are two tightly wound, 4.9-metre-long (16 feet)\u00a0channels that have been etched into a microscopic, porous silicon membrane. The reaction takes place in one channel, then the proteins pass through a special membrane into the other channel, ready for collection.The exchange of metabolites, energy, and species that would otherwise inhibit protein production can be controlled through the membrane and the serpentine channels enclosing it.Although there's still plenty of work to be done to make the device a commercial reality, it could one day provide vital treatments for those living or working in the middle of nowhere. The team hasn't yet made a full assessment of the costs of such a bioreactor, but it's believed that it would be less expensive than existing solutions"
        ]
    },
    "3320": {
        "gold_standard": [
            "The beginning of the year is a time when many of us are trying to shed a bit of weight. Sadly, it's not always an easy thing to do, especially when so-called universal diets don't really seem to work for everybody.\nFortunately, help is on its way, with the advent of genetic sequencing expected to soon play a role in personalised weight management strategies tailored to the needs of each individual. It might sound a little bit like science fiction, but it could be here sooner than you expect.\"I think within five years, we'll see people start to use a combination of genetic, behavioural and other sophisticated data to develop individualised weight management plans,\" said Molly Bray, a geneticist and nutrition scientist at the University of Texas at Austin, who recently led a report on the genetics of weight loss for the US National Institutes of Health (NIH).The report, published in Obesity, suggests precision medicine techniques, including genomic data, will help health experts move obesity prevention and management from a universal model to a personalised format, with custom diets and activity plans specifically designed for particular people.According to Bray, it's likely patients will soon be able to submit saliva samples for gene sequencing purposes. Along with fitness and stress data collected from automated sensors (like personal activity trackers) and information about a patient's environment and diet, this will enable computer algorithms to generate specific recommendations for how people can hit their target healthy weight.Due to the popularity of fitness devices like Fitbits and Jawbones, consumers are already generating a lot of this data voluntarily. With access to genetic sequencing ramping up as costs of the procedure begin to fall, Bray says the challenge is for researchers to develop the tools that can analyse this flood of new health-related data. And not just for short-term diets here and there, but to secure ongoing healthy weight management.\"We are pretty good at helping people lose weight in the short term, but the stats on long-term weight loss are pretty dismal,\" said Bray. \"We've made great strides in our understanding of what drives eating behaviour, how fat cells are formed and how metabolism is altered before and after the onset of obesity. The time is ripe to take this wealth of data and find ways to utilise it more effectively to treat people in need"
        ]
    },
    "3364": {
        "gold_standard": [
            "There's a general awareness today that China and its massive industrial sector generate more carbon emissions than any other country, which is one of the reasons that parts of the nation have to endure some serious issues with smog and airborne pollutants.\nBut according to a new study, if you want to know what's really driving the impact on the planet, you need to look past the obvious primary factors taking a toll on the environment \u2013 like industry and agriculture \u2013 and instead realise whose needs those things are servicing.From that perspective, researchers say household consumers are by far the biggest drain on the planet, which makes for a very different picture to purely nation-focused analyses of environmental impact. In other words, before we start blaming whole countries for the state of the planet, we should probably be looking at our own habits and demands.\"If you look at China's per capita consumption-based (environmental) footprint, it is small,\" said researcher Diana Ivanova from the Norwegian University of Science and Technology. \"They produce a lot of products but they export them. It's different if you put the responsibility for those impacts on the consumer, as opposed to the producer.\"In their analysis, published in the Journal of Industrial Ecology, the researchers examined the environmental impact of consumers across 43 countries and 5 rest-of-the-world regions.\nBy measuring 'secondary impacts' \u2013 the environmental effects of producing the goods and products we buy every day \u2013 the researchers say consumers are responsible for more than 60 percent of the world's greenhouse gas emissions, and up to 80 percent of global water use.Norwegian University of Science and Technology\"We all like to put the blame on someone else, the government, or businesses,\" said Ivanova. \"But between 60\u201380 per cent of the impacts on the planet come from household consumption. If we change our consumption habits, this would have a drastic effect on our environmental footprint as well.\"When you look at the impacts of consumers based on where they live, the researchers found a pattern: the richer a country is, the more its inhabitants consume, and the greater each person's impact on the planet. Food is of particular importance here. Rich nations eat more meat, dairy produce, and processed food, which have a huge impact on land and water resources"
        ]
    },
    "3372": {
        "gold_standard": [
            "Mechanical engineer Asegun Henry is figuring out the unique 'musical' signatures of every element on the period table to give scientists a new way of analysing their constantly shifting molecular structure - as well as science nerds like us the chance to actually hear how different arrangements of molecules and chemical bonds can behave.\n\"My hope is that it will be an interesting tool to teach the periodic table, but also to give people some notion about the idea that the entire Universe is moving around and making noise,\" Henry told Jennifer Ouellette from Gizmodo. \"You just can't hear it.\"So why does every chemical element have a unique musical signature? We all know that everything in the Universe is made up of atoms, and these atoms are in a constant state of motion.\u00a0Depending on the speed at which these atoms are vibrating within the bonds between larger molecules, you'll get a solid, liquid, gas, or plasma. These vibrations - or 'waves' - determine the specific properties of an element, such as its density and thermal conductivity, so the better our understanding of how atoms are zipping around, the more we'll know about the capabilities of a particular element.\"How the energy of the interaction changes with respect to the distance between the molecules dictates a lot of the physics,\" said Henry, who's putting together the catalogue of musical signatures for elements at Georgia Tech"
        ]
    },
    "3436": {
        "gold_standard": [
            "Viagra has quite literally changed the lives of millions of men around the world dealing with erectile dysfunction, but you'd be hard-pressed to find anyone who thinks the little blue pill is perfect. Once you dose up, you're going to have to plan your sex around all the side effects, such as headaches, hearing loss, dizziness, and stomach pain. Romantic.\nThe good news is researchers say they've come up with the most viable alternative to Viagra in 15 years, and it offers a longer-term solution that can be used by men who don't respond to traditional drugs: extra-corporeal shock wave therapy (ESWT) - in other words, zapping the penis with low-intensity sound waves.As\u00a0New Scientist\u00a0reports, earlier this month,\u00a0several research teams presented their findings on ESWT treatments at a meeting of the European Society for Sexual Medicine in Spain, and the evidence from the past few years is looking really promising.\u00a0Back in 2013, a team from the Rambam Medical Centre in Haifa, Israel reported that in a trial with 20 men who had been experiencing erectile dysfunction for at least three years, 15 of them were having spontaneous erections that were strong enough to achieve penetration six months after undergoing ESWT treatment.They're now conducting a larger study with 60 men to see how the effects progress over a two-year period.\nIn 2014, a team led by urologist Anne B. Olsen from Denmark's Viborg Hospital recruited 112 men with erectile dysfunction who found it impossible to have penetrative sex without medication, and split them up into two groups - one received five weekly doses of the low-intensity sound waves to six sites along their penis, and the other group got placebos.They found that 29 men (57 percent) in the ESWT group were able to obtain an erection and have sexual intercourse without the use of medication some five weeks after the treatment, while only five men (9 percent) in the placebo group showed similar results. When the patients were followed-up on 12 weeks after the treatment, 28 percent were still able to get erections without medication.\"The treatment is patient friendly, has no side-effects requiring treatment, and can be used for all patients,\" the team describes in the Scandinavian Journal of Urology. Another plus? Unlike Viagra, the treatment gives men with erectile dysfunction the ability to have spontaneous erections.And late last year at the American Urological Association's 2015 annual meeting, the results of recent multinational clinical trials were\u00a0discussed, and\u00a0ESWT was deemed to be a \"safe, effective, and well-tolerated treatment for erectile dysfunctio"
        ]
    },
    "3526": {
        "gold_standard": [
            "This article was written by\u00a0Jonathan Jong\u00a0from\u00a0Coventry University, and was originally published by The Conversation.If death is the final taboo, it might not be for much longer. There has, in recent years, been increasing effort to promote conversations about death and dying, both in the home and in more public settings. For example, death cafes, first launched in Switzerland in 2004, have spread around the world, enabling people to speak about their fears over cake and coffee Our reluctance to talk about death is often taken as evidence that we are afraid, and therefore suppress thoughts about it. However, there is little direct evidence to support that we are. So what is a 'normal' amount of death anxiety? And how does it manifest itself?Judging by studies using questionnaires, we seem more bothered by the prospect of losing our loved ones than we do about dying ourselves. Such studies also show that we worry more about the dying process\u00a0- the pain and loneliness involved, for example - than about the end of life itself. In general, when we are asked if we are afraid to die, most of us deny it, and report only mild levels of anxiety.The minority who report high levels of death anxiety are even considered psychologically abnormal - thanatophobic - and recommended for treatment.On the other hand, our tendency to report only low levels of death anxiety might be a result of our reluctance to admit to our fear, to others and ourselves. Based on this hypothesis, social psychologists have, for almost 30 years now, examined the social and psychological effects of being confronted with our own mortality. In well over 200 experiments, individuals have been instructed to imagine themselves dying.\nThe first study of this kind was conducted on US municipal court judges, who were asked to set bond for an alleged prostitute in a hypothetical scenario. On average, judges who were confronted with their mortality beforehand set a much higher bail than those who were not confronted - $455 versus $50. Since then, many other effects have been found among groups including the general population in many different countries.Besides making us more punitive, thinking about death also increases our nationalistic bias, makes us more prejudiced against other racial, religious and age groups, and leads to other such parochial attitudes. Taken together, these dozens of studies show that being reminded of death strengthens our ties to the groups we belong to, to the detriment of those who are different from us.Reminders of death also affect our political and religious beliefs in interesting ways. On the one hand, they polarise us: political liberals become more liberal while conservatives become more conservative. Similarly, religious people tend to assert their beliefs more fervently while nonreligious people disavow more.On the other hand, these studies have also found that thinking about death tempts us all - religious or otherwise - towards more religious belief in subtle, perhaps unconscious ways. And when the reminder of death is sufficiently powerful and when participants are not mindful of their prior political commitments, liberals as well as conservatives tend to endorse conservative ideas and candidates. Some researchers claim that this could explain the US political shift to the right after 9/11.\nWhat do the results mean?But why does the prospect of death make us more punitive, conservative and religious? According to many theorists, reminders of death compel us to seek immortality. Many religions offer literal immortality, but our secular affiliations - such as our nation states and ethnic groups - can provide symbolic immortality. These groups and their traditions are a part of who we are, and they outlive us.Defending our cultural norms can boost our sense of belonging and being more punitive against individuals who violate cultural norms - such as prostitutes - is symptom of this.Consistent with this interpretation, researchers have also found that reminders of death increase our desire for fame and for children, both of which are commonly associated with symbolic immortality. It turns out that we do want to be immortalised through our work and our DNA.Thinking about death makes us dream of being famous. Andrea RaffinWhen asked, we do not seem, perhaps not even to ourselves, to fear death. Nor would we guess that thinking about death has such widespread effects on our social attitudes. But there are limits to our introspective powers. We are notoriously bad at predicting how we will feel or behave in some future scenario, and we are similarly bad at working out why we feel the way we do, or even why we have behaved a certain way"
        ]
    },
    "3608": {
        "gold_standard": [
            "We know that the Moon plays a significant role in our lives on Earth, from lighting up the night sky to setting the times of the ocean's tides. But a new study suggests that our favourite cratered satellite also influences something else on our planet: the chances of rainfall.\nScientists from the University of Washington looked at 15 years' worth of data supplied by NASA and the Tropical Rainfall Measuring Mission satellite owned by Japan's space agency. They found that when the Moon is high in the sky, it creates 'bulges' in Earth's atmosphere that cause a slight change in precipitation levels. The higher air pressure created by each oscillation leads to an increase in temperature, and because warmer air can hold more moisture, that means less chance of rain.\"As far as I know, this is the first study to convincingly connect the tidal force of the Moon with rainfall,\" said one of the researchers, Tsubasa Kohyama. \"When the Moon is overhead or underfoot, the air pressure is higher\u2026 it's like the container becomes larger at higher pressure.\"However, \"No one should carry an umbrella just because the Moon is rising,\" he adds.\u00a0The variations in rainfall levels are so slight as to be almost imperceptible to most of us.Where the researchers' findings are going to be practically useful is in climate change modelling and long-term weather forecasts, where these differences can add up. In the future, the researchers also want to investigate whether heavy downpours and other extreme weather types are influenced by the lunar cycle.The new report builds on earlier research carried out by Kohyama and his colleague John Wallace, published in 2014. This paper looked at the way in which the phases of the Moon influenced air pressure down on Earth - a phenomenon scientists have hypothesised about since the mid-19th century. The latest study, published in Geophysical Research Letters, links those same variations with rainfall.The change caused by the Moon is about 1 percent of the total variation in rainfall, according to the researchers, so you probably won't see weather forecasters adjusting their maps with lunar data anytime soon. Statistically speaking, the variation caused by lunar activity works out as 0.78 micrometres (1 micrometre is 0.001 millimetres) per hour. The findings are more likely to be used in computer models of how weather patterns might evolve in the future"
        ]
    },
    "3611": {
        "gold_standard": [
            "There are lots of different strategies for maximising your learning potential, but one of the easiest study-boosters is literally at your fingertips.Australian researchers have discovered that school children fare better at solving maths problems when they trace their fingers over practice examples, outperforming students who simply read the questions without touching them.\n\"Our findings have a range of implications for teachers and students alike,\" said educational psychologist Paul Ginns from the University of Sydney. \"They show maths learning by young students may be enhanced substantially with the simple addition of instructions to finger-trace elements of maths problems.\"The researchers conducted two separate studies involving 275 school children between the ages of nine and 13, and found that finger-tracing over geometric shapes and digits in previously unseen maths problems involving geometry, algebra, and arithmetic helped the students solve the questions more quickly and easily.One of the experiments showed a gradient of results, with students who traced directly over characters outperforming those who traced near them, who in turn outperformed those who did not trace at all.It's not fully understood why the simple act of running your finger over a question while you read it would make the answer easier to arrive at, but the researchers believe it's one way of easing the cognitive burden involved in processing information.\nFor example, physically touching and tracing the angles of a triangle might result in that information getting priority in your brain, whereas registering the same information by visual means alone wouldn't incur the same effect.By doing this, it's possible the physical act could reduce the load on working memory and the brain's ability to store and retain complex material by 'chunking' information together, according to the researchers.While the findings of the studies are new, the learning method itself is not. Students in Montessori schools have long used a tactile approach of teaching the alphabet via sandpaper letters, designed to help introduce the physical form of individual characters to children to help them learn more easily.This research backs up that technique, and if future studies can back up the findings, it could be an easy, cost-effective way to boost educational outcomes in schools.\n\"At the classroom level, teachers can assist students to learn new mathematical content by giving instructions to 'trace over' the important elements of worked examples that already appear in mathematics textbooks or worksheets,\" said Ginns. \"This simple, zero-cost teaching approach can enhance the effectiveness of mathematics instruction across multiple areas of the subject.\"So can anybody benefit from doing this during study or homework sessions? The researchers don't know for sure, but it's entirely possible that the same approach could work for older students \u2013 and in subject areas other than those the researchers have so far examined.\"We are cautiously confident such effects could be applied in the classroom and to subjects outside of maths, but more research is clearly required,\" said Ginn.The findings are published in Learning and Instruction and Applied Cognitive Psychology"
        ]
    },
    "3676": {
        "gold_standard": [
            "About 2,000 years ago, Mount Vesuvius erupted explosively and burned down a library full of ancient scrolls. Since researchers found the texts - known as the Herculaneum scrolls\u00a0-\u00a0back in the 18th century, scientists around the world have been trying to read them\u2026 without much success. But it may have just got a bit easier thanks to X-ray scans from the\u00a0European Radiation Synchrotron Facility.\nBut to step back a second, here's a brief summary of what the scrolls are and what scientists think they know about them. Back in 79 AD, Mount Vesuvius erupted and buried two towns: Pompeii, which gets most of the spotlight, and Herculaneum.Inside a library at Herculaneum were a bunch of hand-written, fragile papyrus scrolls that researchers think most likely contain works by Philodemus and Virgil - two extremely influential teachers, philosophers, and writers. In 1752, researchers found 1,800 of these charred, rolled scrolls and have since been trying to unlock their secrets, which has proven ridiculously difficult, since a strong breeze is enough to ruin them forever.Now, according to a report from The Guardian, researchers from the European Radiation Synchrotron Facility, who are able to produce an X-ray beam \"100 billion times brighter than anything used in a hospital\", were able to look inside the charred scrolls without damaging them.When the analysis was complete, the team found that the scrolls were written with metallic ink, a medium that researchers didn't even think existed back when the scrolls were penned.\nThough researchers still haven't been able to really read anything inside the scrolls, understanding how they were written will allow them to better design methods to eventually decipher the text.However, the new findings are an even bigger deal for historians and archaeologists, because it completely changes the way they thought people wrote. Daniel Delattre, one of the study's authors, told The Guardian:\n\"For nearly 2,000 years, we thought we knew everything, or almost everything, about the composition of antique ink used to write on papyrus. The highly specialised studies carried out at the European synchrotron show us that we must be wary of our ideas and that the ink also contained metal, notably lead in sizeable quantities.\"\nThis new information means that researchers may be able to read other unread texts using similar X-rays, which could unlock a treasure trove of new data about the ancient world. It's a very exciting time for archaeologists and historians, to say the least.Obviously, the real hope is to one day read the scrolls. There's no estimate of when that day might come, however, since X-ray technology and other techniques are moving along at such a decent clip, it isn't a stretch think that that may happen in our lifetimes.You can read about the team's latest findings in\u00a0Proceedings of the National Academy of Sciences"
        ]
    },
    "3678": {
        "gold_standard": [
            "Applied Physics Letters If you're always running out of room for photos, videos, and music on your laptop, then science might have the answer. Using a laser to write data to magnetic storage, researchers have been able to increase the potential data storage capacity of hard drives by as much as 10 times - a process konwn as heat-assisted magnetic recording (HAMR).\nOur computers write, read, and store information by controlling and detecting whether tiny regions of the disk are magnetised or not. This magnetic state corresponds to either a \"1\" or a \"0\" in the binary code - known as a bit - and our files are stored across thousands (or millions) of these bits at once. So if we want more space, we need to find a way to shrink those magnetic regions - which are made up of magnetic grains. And that's where this new development comes in.\u00a0As Gizmodo reports, the new technique relies on shrinking the size of the magnetic grains used to store data, while minimising the interference with surrounding grains, and the researchers have now done that more effectively than ever before by using a precise laser alongside a magnetic field.\u00a0But what does that mean? To unpack that, you need to understand a little bit about the limitations of today's magnetic storage, where there's a need to balance readability, writability, and stability.Manufacturers have previously hit a limit in terms of making magnetic grains smaller and smaller, because the surrounding grains caused their magnetic field to drift and thus destroy the files saved on disk.\nThere's magnetic material that's more resistant to this drift, but it's also harder to write, and requires a bigger magnetic field to store data, which in turn causes more interference. That's where this new laser technique can help - it allows more precision (the resulting grains are just a few nanometres long) with a lower magnetic field by heating the grains first.It's an approach that's actually been around for a while, but scientists are still working out the limitations of it. Enter a team of researchers from TU Wien in Austria, who've been able to use the technique to squeeze 13.23 terabits into a single square-inch of computer drive. That type of storage compares favourably to both Blu-ray (12.5 gigabits per square-inch) and the best hard drives on the market (1.34 terabits per square-inch).\"We have developed a realistic simulation model of the whole complex HAMR process, which allows to accurately calculate the write dynamics of a device in a reasonable amount of simulation time,\" study co-author Christoph Vogler told Phys.org. \"Consequently, we could systematically optimise the major parameters of the write process in order to show that a HAMR device with 10 Tb/in\u00b2 and more is feasible and how such densities can be reached.\"Unfortunately, writing data in a laboratory simulation is not the same as packing it into a laptop that can sit on your desk, and the team says it will be a few years before the technology becomes viable enough to use in consumer electronics. So in the meantime, you might have to buy an external hard drive for all those photos.The research has now been published in Applied Physics Letter"
        ]
    },
    "3696": {
        "gold_standard": [
            "Journal of Geophysical Research - Space Physics Though the Northern Lights on Earth are undoubtedly beautiful, they're nothing compared to the amped-up X-ray version found on Jupiter. And now, astronomers in the UK have finally figured out what causes them: crazy solar storms.\nFirst, for the uninitiated, let's talk about what creates the Aurora Borealis - Earth's Northern Lights. Basically, aurorae - on any planet - are caused when charged particles from the Sun interact with planetary magnetic fields. The different colours are produced by different ions. On Earth, this means aurorae are best seen from the Northern Hemisphere in areas like Siberia, Iceland, Alaska, and Canada.\u00a0While we look up in wonder at this spectacle in the night sky, there's an insane version of the same thing happening on Jupiter. In fact, Jupiter's X-ray aurora covers an area bigger than the surface of Earth.We've known about Jupiter's version of the Northern Lights for a long time now, but researchers from University College London report being the first to\u00a0witness how it changes when a solar storm moves in. \"When giant storms erupt, the winds become much stronger and compress Jupiter's magnetosphere, shifting its boundary with the solar wind 2 million kilometres through space,\" the team explains. \"The study found that this interaction at the boundary triggers the high energy X-rays in Jupiter's Northern Lights.\"\nTo come to this conclusion, the team used NASA's Chandra X-Ray Observatory to monitor the amount of X-rays emitted by the planet for two 11-hour stretches in October 2011 as a solar storm overtook the gas giant.With that data in hand, the team constructed an image to see where all of these X-rays were forming. As it turns out, they stemmed from mainly the northern and southern magnetic poles.\u00a0Artist's concept of Jupiter's magnetosphere interacting with the solar wind. Credit: JAXAWilliam Dunn, the study's lead author, explains the team's reasoning:\n\"In 2000, one of the most surprising findings was a bright 'hot spot' of X-rays in the aurora which rotated with the planet. It pulsed with bursts of X-rays every 45 minutes, like a planetary lighthouse.\nWhen the solar storm arrived in 2011, we saw that the hot spot pulsed more rapidly, brightening every 26 minutes. We're not sure what causes this increase in speed but, because it quickens during the storm, we think the pulsations are also connected to the solar wind, as well as the bright new aurora.\"\nBesides offering new insights into how Jupiter's X-ray aurorae form, the findings have far wider-reaching implications, because understanding how 'space weather' affects planets is vitally important to Earth's future. Also, findings like these can help us understand how planets form, and how different atmospheres could support life.\u00a0To make it even more important, the findings will directly aid NASA's Juno spacecraft that's on schedule to reach Jupiter some time this summer. It's going to be exploring its magnetic field, aurorae, and atmosphere, ultimately so scientists can figure out how Jupiter, the second cosmic body in our Solar system, formed.\u00a0You can check out the team's full report in the Journal of Geophysical Research - Space Physic"
        ]
    },
    "3801": {
        "gold_standard": [
            "Until very recently, one of the biggest myths in science was that all dinosaurs have been extinct for the past 65 million years. But thanks to new fossil discoveries that filled in our knowledge about avian dinosaurs, we now know that only some dinosaurs went extinct following an asteroid collision with Earth - others survived and gave rise to the birds we live with today.\nTo figure out how this evolution occurred, researchers in Chile have manipulated the genes of regular chickens so they develop tubular, dinosaur-like fibulas on their lower legs - one of the two long, spine-like bones you'll find in a drumstick.In avian dinosaurs such as the Archaeopteryx, the fibula was a tube-shaped bone that reached all the way down to the ankle. Another bone, the tibia, grew to a similar length alongside it.As evolution progressed through to a group of avian dinosaurs known as the\u00a0Pygostylians,\u00a0the fibula became shorter than the tibia, and sharper and more splinter-like towards the end, and it no longer reached the ankle.While modern bird embryos still show signs of developing long, dinosaur-like fibulae, as they grow, these bones become shorter, thinner, and also take on the splinter-like ends of the Pygostylian bones, and never make it far enough down to the leg to connect with the ankle.\nResearchers led by Jo\u00e2o Botelho from the University of Chile decided to investigate how this transition from a long, tubular fibula in dinosaurs to a short, splinter-like fibula in birds actually came to be.They achieved this by inhibiting the expression of a gene called IHH or Indian Hedgehog (seriously), which saw their chickens continue to grow the long, dinosaur-like fibulae that originated in their embryonic form.\u00a0In doing so, the team discovered something bizarre. Regular bone development sees cell division and therefore growth halt in the shaft long before the ends stop growing, but in modern chickens, the growth of the fibula halts first at the ends. This means the fibulae of modern chickens are actively blocked from reaching the lengths of their ancient relatives' bones.Jo\u00e2o Botelho et. al.Publishing their observations in the journal Evolution, the researchers suggest that the early maturation of the lower end of the fibula in modern chickens is prompted by a bone in the ankle, called the calcaneum.\n\"Unlike other animals, the calcaneum in bird embryos presses against the lower end of the fibula,\" the team explains in a press release. \"They are so close, they have even been mistaken for a single element by some researchers.\"The team suggests that in regular chickens, interactions between the calcaneum and the end of the fibula result in signals that are similar to the ones that prompt the bone shaft to stop growing, preventing the fibula from reaching anywhere near the ankle bone.\u00a0But when the Indian Hedgehog gene was turned off, the calcaneum strongly expresses the gene Parathyroid-related protein (PthrP), which allows for growth at the ends of bones. This caused their chickens to grow long fibulae that connected with the ankle, just like they would in the\u00a0Archaeopteryx.\u00a0\"Experimental downregulation of IHH signalling at a postmorphogenetic stage led to a tibia and fibula of equal length,\" the team writes in the report. \"The fibula is longer than in controls and fused to the fibulare, whereas the tibia is shorter and bent."
        ]
    },
    "3857": {
        "gold_standard": [
            "It's International Women's Day, and while we don't need an excuse to talk about the many awesome things achieved by women in science now and many decades ago, we're certainly not going to let an opportunity like this go by without introducing you guys to what might be a few new faces.\nWhile the contributions of extraordinary women such as Elizabeth Blackburn and Henrietta Lacks to the advancement of science are well documented, there are countless other female scientists whose stories you might not have come across, and we're here to show you a few of the ones that have inspired us so much.Why highlight women in science? Put simply, women working in science - particularly the STEM (Science, Technology, Engineering, Maths) fields - do so in the face of challenges that are unique to them because of their gender.\u00a0Whether it's systematic sexism, highlighted by the #ILookLikeAnEngineer and \"Writing about male scientists as if they were female\" Tweets, or feelings of isolation - in the US, women make up just 12 percent of the engineering and 26 percent of the computing workforce - many women in science have to go through hell to pursue their research and leadership goals in the field.So give it up for these 10 incredibly strong, intelligent, creative, and determined women (listed here in no particular order). They've inspired us to do better, hopefully they'll do the same for you.\n1. Carolyn Porco, planetary scientist\u00a0TEDPorco is on is the leader of the imaging science team on the Cassini mission, which is scheduled to launch its second mission later this year to orbit Saturn. During the first Cassini mission, Porco was part of the team that discovered the seven moons of Saturn and several new rings on the planet itself, and this time around, she'll be responsible for making sure it captures images of Saturn's poles, upper atmosphere, and innermost ring.\u00a0Her TED talks are unmissable.\u00a02. Lynn Margulis, evolutionary theorist (1938 - 2011)Jpedreira/WikimediaIf anyone has had to deal with serious crap in her career, it's American evolutionary theorist, Lynn Margulis, whose pioneering work in the field of evolutionary biology transformed our understanding of the process of symbiosis in biological evolution.\u00a0Before she received praise for her revolutionary research, Margulis dealt with intense criticism - one grant application was denied with the response, \"Your research is crap, do not bother to apply again.\"\nBut success is the best revenge, with English evolutionary biologist Richard Dawkins saying of Margulis's work,\u00a0\"I greatly admire Lynn Margulis's sheer courage and stamina in sticking by the endosymbiosis theory, and carrying it through from being an unorthodoxy to an orthodoxy. This is one of the great achievements of 20th-century evolutionary biology, and I greatly admire her for it.\"3.\u00a0Sameera Moussa, nuclear physicist (1917 - 1952)Al Ahram Daily News/WikimediaAfter graduating from Cairo University in Egypt, Moussa became the first woman at the institution to hold a PhD in atomic radiation, and the first to hold a staff position as an assistant professor.\nMoussa set up the international Atomic Energy for Peace Conference, which brought scientists together from around the world to create a committee to protect against nuclear hazards and make nuclear treatment more accessible. She was known for saying, \"I'll make nuclear treatment as available and as cheap as Aspirin,\" but died before she could finish her work.4.\u00a0Marie Maynard Daly, biochemist (1921 - 2003)WP:NFCC#4/WikimediaDaly was the first African American woman in the United States to earn a PhD in chemistry, awarded by Columbia University in 1947. She made many contributions to our current understanding of the composition and metabolism of components in the cell nucleus, and later in her career, Daly developed programs to increase the number of minorities in medical schools and graduate science programs.\n5. Peggy Whitson, NASA astronautNASAPeggy has had two long-duration stays aboard the International Space Station, making her the most experienced female astronaut at NASA. She became the first female commander of the ISS in 2007, and during Expedition 16 she broke the female record for spacewalks.6.\u00a0Ayanna Howard,\u00a0robot scientist\u00a0Georgia Institute of Technology Howard is an American robot scientist who's been named one of the top young innovators in the world. One of her most notable contributions to science is designing robots that study the impact of global warming on Antarctic ice shelfs.\u00a0Howard interned at NASA's Jet Propulsion Laboratory, and ended up working there for several years before moving to her current position as a robotics professor at Georgia Institute of Technology"
        ]
    },
    "3873": {
        "gold_standard": [
            "Those who are familiar with the viral street artist Banksy will be aware that his identity has been one of the art world's most closely guarded secrets for the past 20 years. But now scientists have released the name of the man who - mathematically speaking - they predict is most likely to be Banksy.\nTo figure this out, the team analysed the location of more than 140 of Banksy's artworks around the UK, and used an algorithm to determine how likely it was that a leading suspect could have created them, based on where he was living at the time. And if you don't want any spoilers, now is the time to stop reading.According to the researchers, the man most likely to be Banksy is UK resident Robin Gunningham. For fans, that won't come as a surprise - Gunningham was named by The Daily Mail as being the artist back in 2008. But this is the first time that science has been used to back up that claim - and while Banksy's team hasn't confirmed or denied the findings, according to the BBC, they tried to stop the paper from being published.Below is the only publicly available image of Gunningham, from The Daily Mail's front page:The Daily MailWhile it's kind of a bummer that the identity of Banksy might now be one less mystery in the world, the research is a demonstration of how powerful a new technique called Dirichlet process mixture (DPM) model can be when it comes to solving crimes.\nRight now, geographic profiling tools used by police simply take into account one place of reference - usually a suspect's house - and expects to see a somewhat circle-shaped pattern of crime scenes appearing around it. But the DPM model also factors in that crimes could be committed away from home too - for example, near places of employment, pit stops along a commute, or favourite pubs - and runs an algorithm to identify the most likely sources of crime scenes, with an accuracy of up to 50 metres.To test the system out on Banksy, a team from Queen Mary University of London programmed in more than 140 of his artwork locations around the UK to see whether there was any connection with places Gunningham has been known to live and hang out.They found that, although Banksy's art is spread out across 400 square kilometres in London, the peak of the activity is less than 500 metres from Gunningham's wife's former address, and close to the house that Gunningham used to live in. Coincidentally, Bristol is another hot-spot of Banksy activity, and is also where Gunningham grew up.\"The case hinges on a number of striking coincidences between Banksy and Robin Gunningham. First, both appear to have spent their early years in Bristol. [And then] Banksy moved to London around 2000, as did Robin Gunningham,\" lead researcher Steve Le Comber and team write in the Journal of Spatial Science. \"This analysis does provide some support for the theory that [Gunningham] is Banksy,\" the authors conclude.\nOf course, with no other suspects to look into, it's impossible to say conclusively that Gunningham is Banksy. This is pretty much a study being run without a control, and there's no way to know that there aren't more likely candidates out there.What the research does demonstrate is that the DPM model can be used to accurately identify hang-outs of potential criminals, based on patterns of illegal activity. The team is now using the system to map the origin of disease outbreaks, and hopes that it could one day be used to stop terrorist networks, based on the patterns of vandalism and anti-government activity known to occur in the lead up to an attack.When you think about it, Banksy really just took one for the team in the name of scientific progress. Whoever you are, we salute you"
        ]
    },
    "3943": {
        "gold_standard": [
            "Astrophysical Journal When stars are young, they're usually surrounded by a cloud of cosmic gas and dust left over from when it formed. This dense ring, called a protoplanetary disk, is actually where planets themselves are born, as all that matter slowly combines together into spherical worlds over millions of years.\nBut how big a physical scale are we talking here? Well, we've now got a better idea than ever, with astronomers figuring out how to measure the distance between a star and its surrounding protoplanetary disk for the first time, using a method called 'light echoes'.\"Understanding protoplanetary disks can help us understand some of the mysteries about exoplanets, the planets in solar systems outside our own,\" said astronomer Huan Meng from the University of Arizona. \"We want to know how planets form and why we find large planets called 'hot Jupiters' close to their stars.\"So how did they do it? After all, the star in question \u2013 a 'baby' star called YLW 16B, at only about 1 million years old \u2013 isn't exactly nearby. At a distance of 400 light-years from Earth, YLW 16B is a long, long way away, and has about the same mass as the Sun, despite being much younger (the Sun is approximately 4.6 billion years old).To gauge the distance between YLW 16B and the stardust around it, the team used data from NASA's Spitzer Space Telescope and four ground-based telescopes in Arizona, Chile, and Mexico.\nUsing a technique called photo-reverberation (aka light echoes) to measure the travel time of light, the researchers performed a comparison: measuring the difference between the amount of time it took for light to travel from YLW 16B directly to Earth, versus the time it took for light from YLW 16B to bounce off the inner edge of protoplanetary disk and then get here.Since the speed of light is itself a constant, that short gap in time \u2013 about 74 seconds \u2013 let them calculate the distance between the star and its surroundings. It turns out that YLW 16B is approximately 0.08 astronomical units from its protoplanetary disk, which is around 8 percent of the distance between Earth and the Sun (which equals about 12 million kilometres or 7.5 million miles, if that helps).For the method to work, the astronomers needed to find a star with variable emission, with brightness noticeably changing at different times, unlike the steady and therefore less-traceable glow of our Sun. Young stars often demonstrate this unevenness, and YLW 16B turned out to be a suitable candidate.YLW 16B's own particular stats aren't of particular importance to the team, but the star turned out to be a great test case for this new way of measuring star-to-disk distances, and one which the team thinks could prove more reliable than the previous astronomical method, called interferometry.\"Knowing the exact position of the inner boundary of a protoplanetary disk is important to anyone who wants to understand planet evolution,\" says Meng.The findings will be published in the Astrophysical Journa"
        ]
    },
    "3957": {
        "gold_standard": [
            "Scientists around the world are constantly cooking up new and better ways to develop nanotechnologies that can be used in everything from detecting breast cancer to building better touchscreens.\nBut there's a one big problem with working on such a small scale: it's nearly impossible to monitor how temperatures rise and fall within these structures, because the normal tools are just too big for the job.\u00a0With this in mind, researchers in Canada have created the world's tiniest programmable thermometer - and they made it out of actual DNA. The new device is about 20,000 times smaller than a human hair.According to the University of Montreal team, the new device was inspired by a 60-year-old discovery that DNA molecules unfold when heated to a certain temperature. Could this be the basis of new tiny thermometer technology?\"In recent years, biochemists also discovered that biomolecules such as proteins or RNA (a molecule similar to DNA) are employed as nanothermometers in living organisms and report temperature variation by folding or unfolding,\" said one of the team,\u00a0Alexis Vall\u00e9e-B\u00e9lisle.\n\"Inspired by those natural nanothermometers, which are typically 20,000 times smaller than a human hair, we have created various DNA structures that can fold and unfold at specifically defined temperatures.\"Basically, since DNA consists of four nucleotides (A, T, C, and G), the team was able to simply design a mechanism that would force the molecule to fold or unfold at a given temperature, which is a very rudimentary form of a thermometer - it's more of a temperature signalling device.\"By adding optical reporters to these DNA structures, we can\u00a0therefore create 5 nm-wide thermometers that produce an easily detectable signal as a function of temperature,\" said one of the researchers,\u00a0Arnaud Desrosiers.The new thermometer will hopefully allow researchers to answer a slew of questions that have gone unanswered for years, such as whether or not the human body runs hotter than 37 degrees Celsius on the nanoscale, or if naturally occurring nanomachines overheat when functioning at high rate.The team is now working on improving their tiny DNA thermometer to incorporate it into new electronic devices.Their findings have been published in the journal Nano Letters"
        ]
    },
    "3966": {
        "gold_standard": [
            "If you're like most of us, you probably have a bottom drawer somewhere filled with old, cracked, or outdated mobile phones that you're planning to drop off to be recycled any day now, any day.\nBut a new study suggests that there's actually a way better alternative to recycling - using your old batteries to provide safer lighting for people in developing countries and remote areas instead.On average, mobile phones today are replaced every two years, but the lithium-ion batteries inside them are still good for around five years of use. That means they end up being thrown out or recycled while they've still got a good three years' worth of juice left - more than enough\u00a0to store power for LED solar lamps, as a researcher from Kyung Hee University in Seoul has discovered.That's a big deal in remote regions and developing countries, where they currently have to rely on kerosene lamps for lighting, which pump out dangerous, toxic fumes, provide inconsistent light, and easily cause burns and start fires.\"Used mobile phone batteries associated with a solar panel and a light emitting diode lamp can be a good replacement for candles or kerosene lamps that generate pollution, are hazardous, and only give poor lighting,\" lead researcher Boucar Diouf writes\u00a0in the\u00a0Journal of Renewable and Sustainable Energy.\nTo test the idea out, Diouf hooked up a single lithium-ion battery from a mobile phone and used it to run a 1 Watt solar lamp for just over three hours. When he swapped the LED bulb for a 0.5 Watt one, which still provides enough light for reading and writing, the system lasted for six hours.Diouf also took things one-step further and built a 12-volt system out of three batteries, a 5 Watt lamp, and a solar panel for less than US$25. That provided enough power to light a room five hours a day for three years, without needing any maintenance.You can see the set-up below:Diouf/Kyung Hee UniversityOnce the battery dies, the solar panel should still be working fine, so the user can just swap it for a new one. That dead battery can then be sold \"for a final recycling for rare metal recollection\",\u00a0Diouf writes. Win/win.\nThe solar lamps would also save a whole heap of carbon emissions that are currently pumped out by candles. Diouf estimates that if every family without a lamp swapped out five hours of candle use daily for a solar lamp system, it could save a grand total more than 36,000 tons (32,658 tonnes) of CO2 per day globally.\"When one mobile phone battery is recycled, about 130\u2009g of CO2\u00a0will be kept away from the environment daily,\" writes Diouf. \"When three batteries are assembled in a system, a full room will be illuminated allowing studying, safety, healthy lighting, or other income generating activities.\"It's a great idea, but there are no shortage of those\u00a0when it comes to environmental solutions. The hardest part is putting them into practice, and setting up infrastructure that will make it easy for people with too many old phones cluttering up their drawers to get them to people who need them to light up their homes.Let's just hope there are other great thinkers like Diouf out there coming up with solutions to these practical problems, because we're running out of excuses when it comes to taking action against climate change and povert"
        ]
    },
    "3980": {
        "gold_standard": [
            "Some 42 years ago, renowned theoretical physicist Stephen Hawking proposed that not everything that comes in contact with a black hole succumbs to its unfathomable nothingness. Tiny particles of light (photons) are sometimes ejected back out, robbing the black hole of an infinitesimal amount of energy, and this gradual loss of mass over time means every black hole eventually evaporates out of existence.\nKnown as Hawking radiation, these escaping particles help us make sense of one of the greatest enigmas in the known Universe, but after more than four decades, no one's been able to actually prove they exist, and Hawking's proposal remained firmly in hypothesis territory.\u00a0But all that could be about to change, with two independent groups of researchers reporting that they've found evidence to back up Hawking's claims, and it could see one of the greatest living physicists finally win a Nobel Prize.So let's go back to 1974, when all of this began. Hawking had gotten into an argument with Princeton University graduate student, Jacob Bekenstein, who suggested in his PhD thesis that a black hole's entropy - the 'disorder' of a system, related to its volume, energy, pressure, and temperature - was proportional to the area of its event horizon.\u00a0As Dennis Overbye explains for The New York Times, this was a problem, because according to the accepted understanding of physical laws at the time - including Hawking's own work - the entropy and the volume of a black hole could never decrease.\nHawking investigated the claims, and soon enough, realised that he had been proven wrong. \"[D]r Hawking did a prodigious calculation including quantum theory, the strange rules that govern the subatomic world, and was shocked to find particles coming away from the black hole, indicating that it was not so black after all,\" Overbye writes.Hawking proposed that the Universe is filled with 'virtual particles' that, according to what we know about how quantum mechanics works, blink in and out of existence and annihilate each other as soon as they come in contact - except if they happen to appear on either side of a black hole's event horizon. Basically, one particle gets swallowed up by the black hole, and the other radiates away into space.\u00a0The existence of Hawking radiation has answered a lot of questions about how black holes actually work, but in the process, raised a bunch of problems that physicists are still trying to reconcile.\"No result in theoretical physics has been more fundamental or influential than his discovery that black holes have entropy proportional to their surface area,\" says Lee Smolin, a theoretical physicist from the Perimeter Institute for Theoretical Physics in Canada.\nWhile Bekenstein received the Wolf Prize in 2012 and the American Physical Society's Einstein prize in 2015 for his work, which The New York Times says\u00a0are\u00a0often precursors to the Nobel Prize, neither scientist has been awarded the most prestigious prize in science for the discovery. Bekenstein passed away last year, but Hawking is now closer than ever to seeing his hypothesis proven.The problem? Remember when I said the escaping photons were stealing an \u00a0infinitesimal amount of energy from a black hole every time they escaped? Well, unfortunately for Hawking, this radiation is so delicate, it's practically impossible to detect it from thousands of light-years away.But physicist Jeff Steinhauer from Technion University in Haifa, Israel, thinks he's come up with a solution - if we can't detect Hawking radiation in actual black holes thousands of light-years away from our best instruments, why not bring the black holes to our best instruments?As Oliver Moody reports for The Times, Steinhauer has managed to created a lab-sized 'black hole' made from sound, and when he kicked it into gear, he witnessed particles steal energy from its fringes.\nReporting his experiment in a paper posted to the physics pre-press website, arXiv.org, Steinhauer says he cooled helium to just above absolute zero, then churned it up so fast, it formed a 'barrier' through which sound should not be able to pass.\"Steinhauer said he had found signs that phonons, the very small packets of energy that make up sound waves, were leaking out of his sonic black hole just as Hawking's equations predict they should,\" Moody reports.To be clear, the results of this experiment have not yet been peer-reviewed - that's the point of putting everything up for the public to see on arXiv.org. They're now being mulled over by physicists around the world, and they're already proving controversial, but worthy of further investigation.\"The experiments are beautiful,\" physicist Silke Weinfurtner from the University of Nottingham in the UK, who is running his own Earth-based experiments to try and detect Hawking radiation, told The Telegraph. \"Jeff has done an amazing job, but some of the claims he makes are open to debate. This is worth discussing"
        ]
    },
    "4087": {
        "gold_standard": [
            "This article was written by\u00a0Vytas A. Bankaitis\u00a0and Zhigang Xie\u00a0from\u00a0Texas A&M University, and was originally published by The Conversation.\u00a0\u00a0 Autism spectrum disorders (ASDs) affect about 1 percent of the world's population. In the United States alone, about 1 in 68 children are on the spectrum, and between 40 and 60 percent of them are also diagnosed with some degree of intellectual disability.\nThe annual cost associated with ASD in the United States is high - presently estimated to be US $236-$262 billion. If diagnoses continue to grow at the current pace, it will exceed $460 billion by 2025, more than the total cost of diabetes.Scientists still aren't sure what causes ASD, but evidence suggests it's probably the result of complex interactions between genetic and environmental factors that affect brain development.So far, hundreds of genes whose mutations are associated with ASD have been identified. Many of them are known or predicted to play critical roles in the cells that make up the building blocks of the brain.Learning more about these genes - and their mutations - might help us understand some of the root causes of ASD, and perhaps find ways to lower the risk that a child will have it.\nWe decided to take a closer look at mutations in one of these genes, called TMLHE, which is required for a critical chemical reaction that lets cells burn fat molecules to produce energy. We wanted to understand how a TMLHE mutation could increase autism risk and whether we could counteract the effect of the mutation.Neural stem cells and the developing brainWhen we examined the effect of TMLHE mutations in mice, we found these mutations specifically affect neural stem cells during early stages of brain development.Neural stem cells create all of the specialised cells that make up the brain. When they divide to create two \"daughter\" cells, one typically becomes a specialised brain cell, such as a neuron, and the other remains a neural stem cell.This means that the population of neural stem cells is maintained, and the brain building work can continue. Although this process occurs throughout one's lifetime, it is the most active during embryonic brain development.\nIf the neural stem cell population is not maintained at the proper level when the brain is developing, there won't be enough stem cells left to produce the right number and right kind of specialised brain cells. The result is an abnormally wired brain.We find this to be precisely the problem that TMLHE mutations created in mice. Too often, neural stem cell division created two specialised cells, instead of one specialised cell and one neural stem cell.What does a TMLHE mutation do to neural stem cells?TMLHE mutations make it difficult for neural stem cells to produce energy, or to maintain a correctly oxidised environment, which is why they often don't divide properly.Cells produce energy by processing fat molecules. For this to happen, fat molecules need to get to the mitochondria, the powerhouses of the cell, to be broken down. A nutrient called carnitine helps transport fat to these parts of the cell.\nThis is where TMLHE comes in. While we can get carnitine from food - milk and meat, for instance - our bodies can also produce it. But the TMLHE gene is required for carnitine synthesis, so a mutation in this gene can lead to carnitine deficiency.This affects energy production in cells and can also result in a cellular environment that is too oxidised for the cell to function properly, which makes problems for the neural stem cell when it divides.But we also found that this neural stem cell defect is corrected when carnitine is added to TMLHE-deficient cells. This restores their ability to burn fat into energy and to maintain a proper environment within mitochondria, and restores proper cell division behavior to TMLHE-deficient neural stem cells.TMLHE mutations are surprisingly commonTwo recent studies have found that the prevalence of TMLHE mutations in human populations may range from about 1 in 350 to about 1 in 900. In most cases, these people would be unaware that they carry a copy of the defective gene"
        ]
    },
    "4110": {
        "gold_standard": [
            "While the use of antibacterial soap is beneficial in certain situations, for everyday use, they can end up doing more harm than good. That's the message from a growing number of studies casting doubt on the safety of these microbe-killing soaps, and now\u00a0the US Food and Drug Administration (FDA) is demanding more data from the makers of antibacterial soap so it can make a final ruling.\nThese bacteria-killing soaps have been under close scrutiny for several years now, and have been banned in certain parts of the US. Some researchers believe their use is contributing to the rise of 'superbugs' - in other words, chemicals in antibacterial products are causing the bugs to mutate and become more resistant.Add to this the evidence that antibacterial soap doesn't actually clean your hands any better than normal soap and warm water - at least not if you're only cleaning your hands for a couple of minutes at a time - and you can see why experts are saying it's causing more harm than good.A study presented earlier this month\u00a0to the US Endocrine Society found that mother rats exposed to triclocarban - a chemical most commonly found in antimicrobial\u00a0bar soaps - was\u00a0passed onto their offspring. It was also altering the microbiomes of both mothers and babies, which is a worry, because we're learning more and more about how crucial our internal bacteria are for our health.Also under suspicion is triclosan, another antimicrobial widely used in hand soaps and many other products, from shampoos to cosmetics. A 2014 study found exposure to triclosan could make both humans and rats more susceptible to \u00a0a potentially infectious type of bacteria called Staphylococcus.\nMore recent research has found triclosan affecting the microbiomes, diversity, and community structure of zebrafish.If that wasn't enough bad news for antibacterial soaps, other studies are looking at their impact on the wider environment.Two recent studies from Marquette University in Milwaukee, Wisconsin found that both triclosan and triclocarban interfered with microbial communities that break down sewage, reducing their effectiveness, and encouraged bacteria to become more resistant to drugs.The FDA is expected to make a decision in September about whether these antimicrobials should be banned from all soap products. While they're technically safe, they might not be doing us or the environment around us much good. In the meantime, you could consider replacing the antibacterial handwash you keep in the kitchen or bathroom with just plain, old soap.\"We want to slow the proliferation of antibiotic-resistant bacteria so that our current antibiotics can continue to help medical patients,\" said one of the team from Marquette University, Dan Carey. \"If using hand soap without antimicrobials can help, I think it would be worth it to try and change consumer behaviour",
            "While the use of antibacterial soap is beneficial in certain situations, for everyday use, they can end up doing more harm than good. That's the message from a growing number of studies casting doubt on the safety of these microbe-killing soaps, and now\u00a0the US Food and Drug Administration (FDA) is demanding more data from the makers of antibacterial soap so it can make a final ruling.\nThese bacteria-killing soaps have been under close scrutiny for several years now, and have been banned in certain parts of the US. Some researchers believe their use is contributing to the rise of 'superbugs' - in other words, chemicals in antibacterial products are causing the bugs to mutate and become more resistant.Add to this the evidence that antibacterial soap doesn't actually clean your hands any better than normal soap and warm water - at least not if you're only cleaning your hands for a couple of minutes at a time - and you can see why experts are saying it's causing more harm than good.A study presented earlier this month\u00a0to the US Endocrine Society found that mother rats exposed to triclocarban - a chemical most commonly found in antimicrobial\u00a0bar soaps - was\u00a0passed onto their offspring. It was also altering the microbiomes of both mothers and babies, which is a worry, because we're learning more and more about how crucial our internal bacteria are for our health.Also under suspicion is triclosan, another antimicrobial widely used in hand soaps and many other products, from shampoos to cosmetics. A 2014 study found exposure to triclosan could make both humans and rats more susceptible to \u00a0a potentially infectious type of bacteria called Staphylococcus.\nMore recent research has found triclosan affecting the microbiomes, diversity, and community structure of zebrafish.If that wasn't enough bad news for antibacterial soaps, other studies are looking at their impact on the wider environment.Two recent studies from Marquette University in Milwaukee, Wisconsin found that both triclosan and triclocarban interfered with microbial communities that break down sewage, reducing their effectiveness, and encouraged bacteria to become more resistant to drugs.The FDA is expected to make a decision in September about whether these antimicrobials should be banned from all soap products. While they're technically safe, they might not be doing us or the environment around us much good. In the meantime, you could consider replacing the antibacterial handwash you keep in the kitchen or bathroom with just plain, old soap.\"We want to slow the proliferation of antibiotic-resistant bacteria so that our current antibiotics can continue to help medical patients,\" said one of the team from Marquette University, Dan Carey. \"If using hand soap without antimicrobials can help, I think it would be worth it to try and change consumer behaviour."
        ]
    },
    "4154": {
        "gold_standard": [
            "Solar power is making huge strides\u00a0as a reliable, renewable energy source, but there's still a lot of untapped potential in terms of the efficiency of photovoltaic cells and what happens at night and during inclement weather. Now a solution has been put forward in the form of producing energy from raindrops.\nKey to the new process\u00a0is graphene: a 'wonder' material we've heard plenty about before. Because raindrops are not made up of pure water, and contain various salts that split up into positive and negative ions, a team from the Ocean University of China in Qingdao\u00a0thinks we can harness power via a simple chemical reaction. Specifically, they want to use graphene sheets to separate the positively charged ions in rain (including sodium, calcium, and ammonium) and in turn generate electricity.Early tests, using slightly salty water to simulate rain, have been promising: the researchers were able to generate hundreds of microvolts and achieve a respectable 6.53 percent solar-to-electric conversion efficiency from their customised solar panel.\u00a0For the experiment, the team used an\u00a0inexpensive, thin-film solar cell called a dye-sensitised solar cell. After adding a layer of graphene to the cell, it was put on a transparent backing of indium tin oxide and plastic.\u00a0The resulting 'all-weather' solar cell concept was then equipped to produce power from both sunshine and the rain substitute.What's happening here is that the positively charged ions are binding to the ultra-thin layer of graphene and forming a double layer (technically referred to as a pseudocapacitor) with the electrons already present. The potential energy difference between the two layers is strong enough to generate an electric current.\nThe experiment is still just in the 'proof of concept' phase, so there's work to be done, but the researchers hope their findings can \"guide the design\" of future all-weather solar cells and contribute to the growing influence of renewable energy.They're now working on adjusting the technology to\u00a0handle the variety of ions found in real raindrops and figuring how to generate enough electricity from the typically low concentrations they come in.It's not the first time graphene has been used to boost solar energy technologies: earlier this year, a team from the UK was able to create a graphene-based material that's very effective at absorbing ambient heat and light, and which could eventually lead to solar panels that can work with the diffuse sunlight that finds its way indoors.\u00a0If these scientists get their way, in the future, photovoltaic cells may not be hampered by a lack of direct sunshine at all.The study has been\u00a0published in the journal\u00a0Angewandte Chemie"
        ]
    },
    "4173": {
        "gold_standard": [
            "Numerous studies point to the benefits of speaking more than one language, with research showing that bilingual adults have a higher volume of grey matter and could recover more easily from brain injuries.\nScientists have also found that the positive effects of bilingualism can be seen in young children, but a new study suggests that the benefits of exposing a person to more than one language can be seen even when we're just a few months old.\"Our results suggest that before they even start talking, babies raised in bilingual households are getting practice at tasks related to executive function,\" said neuroscientist Naja Ferjan Ram\u00edrez from the University of Washington. \"This suggests that bilingualism shapes not only language development, but also cognitive development more generally.\"According to the researchers, just as babies are about to turn 1 year old and start speaking themselves, they begin to make a change in how they process the sounds of spoken words, and this is where being raised in a bilingual household can be an advantage.\"Monolingual babies show a narrowing in their perception of sounds at about 11 months of age \u2013 they no longer discriminate foreign-language sounds they successfully discriminated at six months of age,\" said one of the team, Patricia Kuhl. \"But babies raised listening to two languages seem to stay 'open' to the sounds of novel languages longer than their monolingual peers, which is a good and highly adaptive thing for their brains to do.\"\nThe findings, published in Developmental Science, are based on observations made of 16 11-month-old babies who took part in the experiment. Eight of the babies came from families where English was the only language spoken, whereas the remaining eight came from Spanish-English households.The scientists used magnetoencephalography (MEG) imaging to monitor the babies' brain activity as they listened to an 18-minute stream of speech sounds specific to either English or Spanish, or common to both.The team found that when listening to the audio, the bilingual babies showed stronger responses in their prefrontal and orbitofrontal cortices \u2013 regions of the brain associated with things like cognitive processing and decision making.Interestingly, the researchers found that the bilingual babies displayed neural sensitivity to both English and Spanish sounds, suggesting they were indeed learning both languages"
        ]
    },
    "4250": {
        "gold_standard": [
            "When it comes to creatures that threaten our existence, sharks get a pretty bad rap (thanks, Jaws).In 2015,\u00a0we experienced the highest amount of unprovoked shark\u00a0attacks ever, with 99 reported cases\u00a0around the globe, and in\u00a02014, that number was 72.\u00a0Though this means sharks do attack and kill people on occasion, the numbers don't even compare to the estimated 25,000 deaths that dogs\u00a0cause every year (mostly because of rabies).\nMany people view sharks as monsters because they're scary-looking predators that live underwater - an environment where\u00a0humans already feel extremely vulnerable - but instead of thinking of them as hidden death machines,\u00a0we should see them for what they really are: complex creatures that\u00a0have different personalities, just like us.For the first time, researchers from Macquarie University in Sydney, Australia have found that Port Jackson sharks have individual personalities that they express habitually, suggesting that they're ingrained just like our own personalities are.In the study, the team designed a set of experiments to test how bold several of their sharks were.In the first experiment, they introduced sharks to a new tank that had a shelter inside. They monitored how long it took for the shark to be brave enough to venture out of the shelter and explore its new surroundings.\u00a0A second experiment had a handler pick up the sharks and release them back into the tank.\nBoth of these activities - handling the shark and introducing it to a strange environment - served to stress the sharks out a bit so the team could see how long it took them to calm down.The team found that each shark handled these situations in their own way, and continued to react in a similar manner each time,\u00a0with\u00a0some of the sharks appearing more bold than others. Though simplistic, the findings suggest that some sharks are, in essence, more outgoing and adventurous than others, signalling that they have different personality traits.\"We are excited about these results because they demonstrate that sharks are not just mindless machines. Just like humans, each shark is an individual with its unique preferences and behaviours,\" said one of the team, Culum Brown.Besides showing sharks in a new light, the team says that knowing the breadth of responses displayed by these creatures to certain situations\u00a0will help us better interpret - and maybe even predict - how certain types of predators behave around humans.\n\"Understanding how personality influences variation in shark behaviour - such as prey choice, habitat use and activity levels - is critical to better managing these top predators that play important ecological roles in marine ecosystems,\"\u00a0says Brown.The study has been published in the Journal of Fish Biology, and adds to a growing body of research that shows we have a whole lot more to learn about the animals we share the planet with, and it's in our best interest to get to know them better.\"Over the past few decades, personality research has shown that nearly 200 species of animals demonstrate individual personality,\" says lead researcher,\u00a0Evan Byrnes. \"Personality is no longer considered a strictly human characteristic - rather, it is a characteristic deeply engrained in our evolutionary past."
        ]
    },
    "4318": {
        "gold_standard": [
            "An international team of scientists has found the faintest early-Universe galaxy ever, catching a glimpse of the star system as it would have looked some 13 billion years ago, shortly after the Big Bang itself.\nThe discovery came courtesy of the\u00a0W. M. Keck Observatory in Hawaii \u2013 which is\u00a0the most powerful telescope on Earth \u2013 and we were able to see it thanks to the gravitational lensing phenomenon popularly associated with Einstein.\"Keck Observatory's telescopes are simply the best in the world for this work,\"\u00a0explained one of the research team, Maru\u0161a Brada\u010d, from the University of California, Davis (UC Davis). \"Their power, paired with the gravitational force of a massive cluster of galaxies, allows us to truly see where no human has seen before.\"For those who need a refresher, gravitational lensing is when an object is magnified by the gravity of another object, bending its light before it reaches any observers (in this case, the scientists in Hawaii).\u00a0And the object used to magnify the incredibly faint galaxy was a massive galaxy cluster officially known as\u00a0MACS2129.4-0741.\nIn fact,\u00a0MACS2129.4-0741\u00a0is\u00a0so big that it enabled astronomers to create three different images of the newly discovered galaxy, all thanks to gravitational lensing.\"If the light from this galaxy was not magnified by factors of 11, five, and two, we would not have been able to see it,\" said Kuang-Han Huang, also from UC Davis, and the lead researcher of the study.The discovery should give astronomers and astrophysicists some clues as to what caused hydrogen ionisation\u00a0\u2013 the process by which all those billions of years ago, one of the fundamental questions being asked in astronomy today, according to W. M. Keck Observatory staff astronomer Marc Kassis.During this mysterious period, large, dense clouds of hydrogen gas sat between galaxies, which has made it impossible for us to see the light from that time"
        ]
    },
    "4342": {
        "gold_standard": [
            "Scientists just found even more evidence that Europa - one of Jupiter's 67 known moons - might host alien life deep within its icy oceans.\u00a0The little moon has long been labelled by NASA as \"the most likely place to find life in our Solar System today\", thanks to the deep, salty oceans that are strongly suspected to be hidden beneath its frozen crust.\nAnd now a new study has shown that the chemical balance of those oceans would be very similar to the ones here on Earth, suggesting there'd be enough hydrogen and oxygen there for life to form - even without volcanic activity.\u00a0\"We're studying an alien ocean using methods developed to understand the movement of energy and nutrients in Earth's own systems,\" said lead researcher\u00a0Steve Vance, from NASA's Jet Propulsion Laboratory (JPL).\u00a0\"The cycling of oxygen and hydrogen in Europa's ocean will be a major driver for Europa's ocean chemistry and any life there, just as it is on Earth.\"To understand how that might work, the team compared Europa's potential for producing hydrogen and oxygen to that of Earth.For the purposes of this study, they only looked at processes that didn't\u00a0involve volcanism - volcanic activity is thought of as a kickstart for the formation of life, but the team wanted to see if passive processes on the moon could do the same thing.\nAnd, to their surprise, they calculated that they could. Published in Geophysical Research Letters, the study showed that the amounts of both hydrogen and oxygen would be comparable in scale, and on both worlds, oxygen production is about 10 times higher than hydrogen production.On Earth, our oceans make hydrogen through something called serpentinisation. That's where salty seawater soaks into cracks in Earth's crust and reacts with the minerals there to produce hydrogen and heat - two important ingredients for life.The potential for this to happen on Europa was the first thing the researchers focussed on, and based on how the moon has cooled down since its formation, they calculated that it might have fractures in its rocky interior as deep as 25 kilometres (15 miles) - roughly five times deeper than the cracks here on Earth.In other words, plenty of room for hydrogen to be formed as the ocean water percolates into those cracks"
        ]
    },
    "4355": {
        "gold_standard": [
            "The film The Man Who Knew Infinity tells the gripping story of Srinivasa Ramanujan, an exceptionally talented, self-taught Indian mathematician. While in India, he was able to develop his own ideas on summing geometric and arithmetic series without any formal training.\nEventually, his raw talent was recognised and he got a post at the University of Cambridge. There, he worked with G.H. Hardy until his untimely death at the age of 32 in 1920.\u00a0Despite his short life, Ramanujan made substantial contributions to number theory, elliptic functions, infinite series, and continued fractions.The story seems to suggest that mathematical ability is something at least partly innate. But what does the evidence say?From language to spatial thinkingThere are many different theories about what mathematical ability is. One is that it is closely tied to the capacity for understanding and building language. Just over a decade ago, a study examined members of an Amazonian tribe whose counting system comprised words only for 'one', 'two' and 'many'.The researchers found that the tribe were exceptionally poor at performing numerical thinking with quantities greater than three. They argued this suggests language is a prerequisite for mathematical ability.\nBut does that mean that a mathematical genius should be better at language than the average person? There is some evidence for this. In 2007, researchers scanned the brains of 25 adult students while they were solving multiplication problems.The study found that individuals with higher mathematical competence appeared to rely more strongly on language-mediated processes, associated with brain circuits in the parietal lobe.Srinivasa Ramanujan. wikimediaHowever, recent findings have challenged this. One study looked at the brain scans of participants, including professional mathematicians, while they evaluated mathematical and non-mathematical statements.\nThey found that instead of the left hemisphere regions of the brain typically involved during language processing and verbal semantics, high-level mathematical reasoning was linked with activation of a bilateral network of brain circuits associated with processing numbers and space.In fact, the brain activation in professional mathematicians in particular showed minimal use of language areas. The researchers argue their results support previous studies that have found that knowledge of numbers and space during early childhood can predict mathematical achievement.For example, a recent study of 77 eight-to-10-year-old children demonstrates that visuo-spatial skills (the capacity to identify visual and spatial relationships among objects) have an important role in mathematical achievement.As part of the study, they took part in a 'number line estimation task', in which they had to position a series of numbers at appropriate places on a line where only the start and end numbers of a scale (such as 0 and 10) were given.\nThe study also looked at the children's overall mathematical ability, visuospatial skills, and visuomotor integration (for example, copying increasingly complex images using pencil and paper). It found that children's scores on visuospatial skill and visuomotor integration strongly predicted how well they would do on number line estimation and mathematics.Hidden structures and genesAn alternative definition of mathematical ability is that it represents the capacity to recognise and exploit hidden structures in data. This may account for an observed overlap between mathematical and musical ability. Similarly, it could also explain why training in chess can benefit children's ability to solve mathematical problems.Albert Einstein famously claimed that images, feelings and musical structures formed the basis of his reasoning rather than logical symbols or mathematical equations.Albert Einstein playing the violin. E. O. HoppeHowever, the extent to which mathematical ability relies on innate or environmental factors remains controversial. A recent large-scale twin and genome-wide analysis of 12-year-old children found that genetics could explain around half of the observed correlation between mathematical and reading ability"
        ]
    },
    "4362": {
        "gold_standard": [
            "If you think there are aliens in Area 51 or the shooting of JFK was an inside job, then it could be because you're overly stressed, a new study suggests. While the evidence isn't clear cut, the researchers think there's a link here, which could explain why some people are more likely to believe in conspiracies than others.\nA team of UK researchers recuited 420 volunteers and asked them about various conspiracy theories. They were also asked to rate their anxiety levels and social status, and make a note of any stressful life events that had occurred in the last six months.The team from\u00a0Anglia Ruskin University\u00a0found that\u00a0a stronger belief in conspiracy theories was matched to individuals with both a greater perceived level of stress and a greater number of stressful life events in the recent past.Of course, there's no shortage of well-known conspiracy theories to talk about: the idea that the Apollo Moon landings were faked, or that Martin Luther King Jr was assassinated by the US government were two examples included in the study.As Ars Technica's Cathleen O'Grady reports, the tricky part with the research is proving causality: in other words, that higher stress levels actually cause the stronger belief in conspiracy theories, rather than the other way around. After all, conspiracy theories aren't exactly likely to make anyone feel more calm and reassured than they were before!\nEven so, the team behind the new study thinks there's a connection. \"Stressful situations increase the tendency to think less analytically.\u00a0An individual experiencing a stressful life event may begin to engage in a particular way of thinking, such as seeing patterns that don't exist,\"\u00a0said lead researcher, social psychologist Viren Swami.\"Therefore stressful life events may sometimes lead to a tendency to adopt a conspiracist mind-set,\" she added.\u00a0\"Once this worldview has become entrenched, other conspiracy theories are more easily taken on board.\"An alternative hypothesis put forward by the team is that distressing events could prompt us to try and take more control over our lives, and seeking out conspiracy theories is an extension of that.The study shows younger people are more likely to have conspiracist tendencies than older people, but there was no significant difference between men and women, or people of different social statuses.\nStress levels are unlikely to tell the whole story, though. Earlier studies have found links between believing in conspiracy theories and lower-than-average intelligence, political beliefs, a lack of trust in authority, low levels of self-esteem, and feelings of powerlessness \u2013 that's quite a mix of psychological factors. Of course, with the modern-day web, it's much easier to find like-minded people to share your opinions with too.There's also research looking into just how implausible conspiracy theories are, based on the maths involved \u2013 but who's to say these conspiracy debunks aren't just another conspiracy, hmm?\u00a0The findings are\u00a0published in Personality and Individual Difference"
        ]
    },
    "4373": {
        "gold_standard": [
            "Part of the difficulty in tackling viruses like Ebola and Zika is that they're all so different, and each one can regularly mutate to create different strains within the same virus.\nTo address this, scientists have been busy looking at common characteristics of viruses that could be used to develop an all-powerful vaccine capable of fighting off any infection, and researchers over at IBM say they're getting close.It's exciting stuff: a macromolecule \u2013 a giant molecule made up of smaller units \u2013 has now been developed that could have the potential to block multiple types of viruses, despite the many variations involved. It's still early days yet, but the results could lead to drugs that aren't tricked by mutating virus strains.The scientists, from tech giant IBM and the Institute of Bioengineering and Nanotechnology in Singapore,\u00a0ignored the RNA and DNA of the viruses they used for testing \u2013 these would traditionally be the areas to target, as they give the viruses their characteristics, but they also tend to vary from virus to virus and mutation to mutation.Instead the team looked at glycoproteins\u00a0\u2013\u00a0large molecules attached to the outside of all viruses and capable of latching onto cells in the body - the process that actually makes us sick. The macromolecule that's now been developed attracts viruses and then hitches a ride on these glycoproteins, neutralising their acidity levels and making them less able to replicate in the process.\nThe macromolecule has another method of attack too \u2013 a sugar called mannose, which attaches itself to healthy immune cells and draws them closer to the virus, speeding up the fight against the infection.Based on the tests already carried out by the team on viruses such as Ebola and dengue, the macromolecule works as intended. It binds itself to the glycoproteins, disabling viral ability to infect healthy cells, while the mannose was also found to be effective in stopping viruses from infecting immune cells.In the short term, the researchers think the macromolecules could be used in antiviral wipes or detergents, Gizmag's Chris Wood reports. With further study, we could see vaccinations that are capable of protecting us against a whole range of viruses.\"It's almost a daunting task to design any kind of therapeutic for a virus,\" lead researcher James Hedrick of IBM Research explained to Samantha Olson at Medical Daily. \"[The glycoprotein is] kind of like honey. It's kind of sticky. We can now competitively go after this cell faster than the virus can go after your immune cell. And once we block those receptors, we prevent infection.\"The group's findings have been published in the journal Macromolecules"
        ]
    },
    "4453": {
        "gold_standard": [
            "For many of us born in the last 30 years, it's hard to imagine life without a smartphone,\u00a0but these gadgets are still relatively new, and scientists are continuing to gathering data on their long-term mental and physical effects.\nNow the results of a new Australian study shows no correlation whatsoever between cellphone use and cases of cancer.\u00a0The researchers behind the study looked at three decades of data, gathered between 1982 and 2013, and mapped phone use against brain cancer rates.It will take more than a single study to settle the question of how healthy or unhealthy smartphones are, of course, but it's a significant piece of evidence to consider.As Chris Mills from Gizmodo reports, a\u00a0slight increase in cancer rates in males was noted in the study, but there was no noticeable difference in females, and overall the data matches up with an earlier study on the same issue carried out in Scandinavia.What makes the Australian report even more useful is that all diagnosed cases of cancer in the country have to be recorded by law.\n\"We found no increase in brain cancer incidence compatible with the steep increase in mobile phone use,\" reported the researchers in Cancer Epidemiology.While a rise in cancer rates was noted in those aged 70 to 84 over the time period in question, it began before mobile phones were in use, and the researchers think the jump is down to better diagnosis and cancer detection techniques in recent years.In total, the records of some 19,858 men and 14,222 women were examined. If you're interested in the rise of the smartphone \u2013 or just raw statistics in general \u2013 you might like to know that cellphone use in Australia started in 1987 and has risen to over 90 percent in the last 29 years.As lead researcher Simon Chapman notes at The Conversation, the long time period covered means we can be more confident that there isn't a 'lag period' between an increase in smartphone usage and an increase in cancer rates \u2013 if there was, we'd already be starting to see signs of it.\nBut with so many variables and influences on our lifestyles to consider, more research is needed to fully understand what these little gadgets are doing to our bodies and our minds.Chapman and his colleagues also tested their data against two separate studies (from 2011 and 2015) that had pointed to links between smartphone use and an increased risk of cancer. In neither case did the predicted rise in cancer rates proposed by those two studies show up in the data collected in Australia over three decades.So it seems we're safe for the time being \u2013 though there's no harm in going hands-free when you can, just in case"
        ]
    },
    "4483": {
        "gold_standard": [
            "In the same way that Microsoft's HoloLens device\u00a0could one day see you walking around a 3D projection of Minecraft in your living room, scientists have developed new holographic technology that allows them to 'peer' inside a molecule to figure out the exact arrangement of atoms inside.\nThis is the first time that anyone has been able to clearly see inside molecular structures with this degree of accuracy, and it's hoped that the technology will lead to a better understanding of the unique properties of different kinds of molecules, whether in biological systems, or crazy new materials.As Lisa Zyga from Phys.org explains, scientists have struggled to see inside small molecules ever since we knew they existed,\u00a0with the best and most reliable imaging techniques limited to scanning their surfaces. For anything more, indirect investigation methods or theoretical predictions had to be made.It's expected that the new system, developed by physicist Tobias L\u00fchr from the Technical University of Dortmund in Germany and his team, will offer far more accuracy.As Kate Baggaley from Popular Science\u00a0explains, the new method works by shooting high-energy electrons at the molecule under investigation. The electrons scatter as they hit the molecule, bouncing off in distinct patterns based on the layout of individual atoms, and through these patterns, researchers are able to build up a hologram of the whole molecule.\nThis not the first time holographic technology has been used to image molecular structures, but the new method reduces the marks and imperfections that previous techniques left on the resulting images, and can distinguish between different types of atoms.\u00a0And unlike previous technologies, the new technique can also handle more than 10 atoms at a time - a rather serious limitation that's held back the research up to this point.\u00a0Key to the improvements in the technology is the use of more energy behind the electron waves, to the tune of several thousand volts. This in turn leads to clearer pictures, because the waves can be more easily constrained and don't spread out as much. Pyrite - aka Fool's Gold, or FeS2 - was used as the test substance.\"In order to understand the physical and chemical properties of advanced materials, functional molecular adsorbates, and protein structures, a detailed knowledge of the atomic arrangement is essential,\" writes the team in the journal Nano Letters. \"We present a general reconstruction\u00a0algorithm that leads to high-quality atomic images showing thousands of atoms.\"The next step is to figure out all of the ways the new holographic technology can be used in further research - and there are likely to be a lot of them. If there's one thing we don't know nearly enough about, it's the tiny building blocks that make up every single thing we see around us. We'd better get on that"
        ]
    },
    "4487": {
        "gold_standard": [
            "It's estimated that nine out of 10 women suffer from period pain each month, and an unfortunate 10 percent of those will get it so bad, they could be incapacitated for up to three days.\nOther than using contraceptives to skip their period altogether (just like astronauts do), menstruating women have precious few options to beat this thing and get on with their lives. Some over-the-counter pain-killers and a strategically placed hot water bottle is about it.But there's another option behind secret door #3, and early reports are saying this thing actually works. Dubbed Livia, this new medical device claims to be an \"off switch for menstrual pain\".Okay, so first thing's first: how does this supposed 'miracle cure' actually work?\u00a0As the Livia website explains, the device comes with two electrodes, which you need to place on the painful areas on your abdomen. Switch the device on, and these electrodes will start delivering imperceptible electric pulses to your nerves, which will settle the pain.\nIf it sounds too good to be true, I'm right there with you. But this thing has been getting some serious hype, according to Julia Belluz at Vox:\n\"Livia has received rave reviews in international women's magazines like Cosmopolitan and Glamour, and more than 3,000 crowdfunders from around the world have put upward of $284,000 into Livia's Indiegogo campaign.\"\nWhile founder and CEO of Livia, Chen Nachum, insists that they've so far tested the device on 163 women in two different trials, with more than 80 percent of them reporting pain-relieving effects, we're yet to see the results for ourselves in a peer-reviewed study, so there's still a whole lot we don't know about this particular device.But what we do know is that the technology Livia is based on isn't new, and doctors have been prescribing it for years.\nKnown as TENS (transcutaneous electrical nerve stimulation), electronic nerve stimulators have been used to treat all kinds of pain in the past, from neck and back aches to labour pain. It basically works by 'confusing' your body's nervous system, so it can't figure out what to do with the pain signals it's supposed to be delivering to your brain.\"The idea is the nerve system cannot work with two types of signals at the same time,\" Nachum explained to Belluz, \"so what Livia does is transmit frequency to the nerve system that it is very similar to the body's frequency, but it's not something the body knows.\"Because the signals from the device reach the brain faster than the pain signals from the nerves, the brain doesn't have time to register your menstrual cramps, says Nachum.What Nachum is describing might sound really simple (and makes our nervous system seem kinda gullible), it's actually rooted in a whole lot of science, Belluz reports:\n\"Jen Gunter, an OB-GYN and pain medicine specialist, noted that the idea of using TENS for menstrual pain is actually very sound. In fact, there's enough research that the Cochrane Collaboration was able to put together a review of the evidence. Its conclusion: 'High-frequency nerve stimulation may help relieve painful menstrual cramps.'\"\nGunter told Vox she's been prescribing high-frequency TENS for period pain for more than 15 years, and while the technique doesn't necessary work for everyone, it really helps some women. \"Prescribed one this morning, in fact,\" she said.\nRight now, you're able to preorder a Livia device for US$85 and wait six months for it to ship, and Nacham says they're in the middle of another study, this time with 60 participants, to get a better idea of how effective it is.\u00a0And while we certainly don't recommend that you invest in one until we see the actual study results, it'll be interesting to see if Livia's application to the US Food and Drug Administration (FDA) as a menstrual pain reliever will be approved.Gunter told Vox that her main concern with the device is that it might not provide frequencies that are high enough to be effective, and Nacham has refused to comment on the device's exact frequency, perhaps for competition reasons.\u00a0If you're really curious, head to your GP now and get them to fill you in on TENS. Even if it turns out that Livia doesn't actually live up to the hype, you've got a whole lot of science on your side if you want to try the generic version"
        ]
    },
    "4506": {
        "gold_standard": [
            "This article was written by Jane Chalmers from Western Sydney University and was originally published by The Conversation.It is perhaps one of the most controversial debates in sexual function: is there or isn't there a G-spot? And if there is, how do we find it?\nThe G-spot is a purported highly erogenous area of the vagina that, when stimulated, may lead to strong sexual arousal and orgasm. Although the concept of vaginal orgasms has been around since the 17th century, the term G-spot wasn't coined until the 1980s. The G-spot is named after Eric Grafenberg, a German gynaecologist, whose 1940s research documented this sensitive region within the vagina in some women.The controversy surrounding the G-spot comes about because there is no consensus over just what the G-spot is, and while some women can orgasm through stimulation of the G-spot, others find it incredibly uncomfortable.Where is the G-spot?The G-spot lies on the anterior wall of the vagina, about 5 to 8 cm above the opening to the vagina. It is easiest to locate if a woman lies on her back and has someone else insert one or two fingers into the vagina with the palm up. Using a 'come here' motion, the tissue surrounding the urethra, called the urethral sponge, will begin to swell.\nThis swelling area is the G-spot. At first, this touch may make the woman feel as though she needs to urinate, but after a few seconds may turn into a pleasurable sensation. For some women, however, this stimulation remains uncomfortable, no matter how long the stimulation continues.Allure MedicThe G-spot orgasm and female ejaculationPhysiological responses from a G-spot orgasm differ to those responses seen in clitoral orgasms. During clitoral orgasms, the end of the vagina (near the opening) balloons out; however, in G-spot orgasms, the cervix pushes down into the vagina.Up to 50 percent of women expel various kinds of fluid from their urethra during sexual arousal or sexual intercourse. Studies have shown there are generally three types of fluid that are produced: urine, a dilute form of urine (known as 'squirting'), and female ejaculate.\nWhile some women may expel these fluids during arousal or sex, they are most commonly expelled during orgasm, and particularly through G-spot orgasm. So what is the difference between these fluids?The release of urine during penetrative sex is usually as a result of stress urinary incontinence. Some women experience no other symptoms of stress urinary incontinence, such as leakage when sneezing, coughing, or laughing, but will leak during sex.'Squirting' is the leakage of a urine-like substance during orgasm. It is thought to occur because of strong muscle contractions surrounding the bladder during female orgasm.Female ejaculate, most commonly reported with G-spot orgasm, is a much different substance: women describe the fluid as looking like watered-down fat-free milk and report producing about a teaspoon in volume during orgasm. The contents of female ejaculate have been chemically analysed and found that it closely resembles secretions from the male prostate. This has led to many suspecting that glands known as the female prostate (formerly Skene's glands) produce this ejaculate.\nWhat could the G-spot be?The G-spot is not a single, distinct entity. Much debate exists in the research field as to just what the G-spot is, and how it can produce orgasm.The G-spot is located in the clitourethrovaginal complex \u2013 the area where the clitoris, urethra, and vagina all meet up. There are several structures in this complex that could produce pleasurable sensations when stimulated \u2013 the G-spot might reflect the stimulation of just one structure, or multiple structures at once. Two structures in particular have been hotly debated and stand out as likely candidates for producing G-spot orgasms: the female prostate and the clitoris.The female prostate lies within the urethral sponge, a cushion of tissue surrounding the urethra. The urethral sponge and female prostate are highly innervated, which may explain their sensitivity when stimulated.\nThe clitoris is more than meets the eye: we now know this organ extends far beyond what is visible externally. Apart from where the urethra and vagina touch, the clitoris somewhat encircles the urethra. Mechanical stimulation of the G-spot may in fact be stimulating the internal portion of the clitoris.So, is the G-spot fact or fiction?The G-spot certainly exists in some women. However, not all women will find the stimulation of the G-spot pleasurable.Just because a woman is not aroused when the G-area is stimulated, this does not mean she is in any way sexually dysfunctional. Sexuality and arousal have clear physiological and psychological links. But, as human beings, we are all made slightly anatomically and physiologically different.In the same way that what I consider 'blue' may not be the exact same 'blue' you perceive, an orgasm in one woman is not the same as an orgasm in any other woman. It is a unique experience. And although you and I both see blue through our eyes, the complexities of human sexuality and the female reproductive organs mean women may achieve orgasm in multiple ways.\nSome women are unable to orgasm in the presence of a partner, but have no difficulty with orgasm with masturbation. Some women can orgasm only with clitoral stimulation, while others can orgasm through vaginal stimulation alone. There are reports of women who experience orgasm through the stimulation of the foot, and Grafenberg detailed in his report women who experienced arousal through ear penile penetration (but these reports are yet to be replicated!).You are not abnormal or strange or dysfunctional if you cannot find your G-spot. Similarly, you are not abnormal or strange or dysfunctional if you expel fluid during arousal or sex. Sexual arousal, desire, and pleasure are individual: if you are unable to find your G-area, work on finding something that does fulfil your sexual needs.Harry Potter star, feminist, and all-round superstar Emma Watson supports a great website for women wanting to explore their sexuality further. It's called OMGYes and is a great place to explore the ways in which different women experience sexual pleasur"
        ]
    },
    "4509": {
        "gold_standard": [
            "Back in the mid-1900's, Portugese neurosurgeon Antonio Egas Moniz\u00a0'perfected' the lobotomy - a medical procedure that involved driving a stake into a patient's prefrontal cortex to 'cure' various mental illnesses. Most of the time, these surgeries were carried out with an ice pick-like device without anaesthesia, leaving most patients brain-dead.\nWhile lobotomies are unfortunately still fresh in our collective consciousness, the act of drilling a hole into someone's skull isn't new. In fact, based on a number of 6,000-year-old fossils\u00a0recently uncovered in Russia, skull surgery might have been used in ritualistic practices long before humans even knew what mental illness was.Researchers from the German Archaeological Institute have just released a report on the 13 skulls unearthed in southwestern Russia, describing the large holes drilled into the back of them.It's thought they got there through a process known as trepanation\u00a0-\u00a0the surgical opening of the skull for religious or medical purposes.\u00a0Now isolated to\u00a0parts of Africa, South America, and Melanesia,\u00a0trepanation was once a go-to practice for many ancient societies around the world.The German archaeologists suggest that the Russian skulls once belonged to\u00a010-year-old children, who were likely involved in some kind of spiritual rite of passage into adulthood - though the skull-drilling technique is thought to have been performed to treat everything from\u00a0headaches to tumours.\nEven more shocking than the discovery of the holes themselves in the skulls of children, the team also reports that 11 of these skulls show signs of healing, which means the victims likely lived through the ordeal.According to Bruce Bower from\u00a0ScienceNews, this type of surgery was extremely risky, because it required the surgeon to scrape away just enough bone to expose the brain without allowing it to drain or get too heavily damaged.Plus, it's super-easy for a patient to bleed out if any veins in their neck get accidentally cut in the process. Ancient surgeons likely had solutions to all of these hurdles, though archaeologists are yet to figure out what they are.One of the skull holes. Credit: German Archaeological InstituteAfter analysing them with X-rays and CT scans, the researchers found no evidence to suggest that the surgeries were performed to treat any sort of medical condition, which is furthered by the location of the hole"
        ]
    },
    "4522": {
        "gold_standard": [
            "Journal of the American Chemical Society Catching diseases early is often crucial to effectively fighting them off, but there are many parts of the world where seeing a doctor or getting access to hospital equipment is a real challenge. That's why cheap home testing kits are so important.\nAnd now a new and potentially life-saving test is being developed by scientists in the US: simple, inexpensive paper strips that could help detect diseases such as cancer and malaria in remote areas.The idea is they would be almost as easy to use as a simple home pregnancy test - place a small drop of blood on the paper at home, then mail it off to a professional laboratory. If the result comes back positive, an appointment can be arranged; if not, you've got nothing to worry about.\"We want to empower people,\" said chemist Abraham Badu-Tawiah\u00a0from Ohio State University, who came up with the idea for the strips. \"If you care at all about your health and you have reason to worry about a condition, then you don't want to wait until you get sick to go to the hospital. You could test yourself as often as you want.\"The strips were originally conceived as a way of testing for malaria, but Badu-Tawiah says they could work for any disease that the body produces antibodies for \u2013 and that includes ovarian cancer and cancer of the large intestine.\nMade from sheets of white paper, stuck together with adhesive tape and run through a typical inkjet printer, the strips are covered in wax ink that creates channels and reservoirs to capture the blood sample. Each strip is about the size of a postage stamp.Small, synthetic\u00a0'ionic' probes in the paper, which carry a positive charge, allow for mass spectrometer readings, and keep the blood sample protected against light, temperature, and humidity, until the strip arrives safely at the lab.The probes have been specially designed to tag specific antibodies carrying signs of disease, and the samples the strips carry are good for at least 30 days. The team is also working to make the tests more sensitive, so saliva or urine could be used in place of blood.Badu-Tawiah says the strips could help provide invaluable medical care for those in rural or remote communities, including in developed nations, as well as assisting anyone who struggles to attend or pay for regular health check-ups. The strips currently cost around 50 US cents each, but that price should go down further if they're mass-produced.\nThe researchers have successfully used the strips in testing to detect biomarkers for both ovarian cancer and malaria - a disease that killed around 438,000 people last year. Now they're hoping to license the technology to a medical diagnostics company, with intentions to carry out clinical tests within three years.It's still early days for these strips, but there's an awful lot of potential here. Let's hope they live up to it and make a whole lot of lives easier.The findings are reported in the Journal of the American Chemical Societ"
        ]
    },
    "4563": {
        "gold_standard": [
            "On the Monday after the Orlando mass shooting, 12 specially-trained golden retrievers arrived in Florida City to do what they do best: provide comfort.The dogs are part of the\u00a0K-9 Comfort Dog Team, a program run by the\u00a0Lutheran Church Charities\u00a0that now has 130 dogs in 23 states across the country.\nThe dogs - all golden retrievers - deploy as part of the organisation's disaster response team. Each one was picked as a puppy because of its calm demeanour, and each one was specially trained to be gentle, comforting, and affectionate.\u00a0All do this without barking, jumping, or getting distracted by events and noises around them.In Orlando last week, the animals visited hospitals and churches, attended vigils and memorial services, and\u00a0met with the staff of Pulse\u00a0(the nightclub where the shooting occurred), reports\u00a0The New York Times.These same dogs were in Boston after the marathon bombing and in Sandy Hook after the elementary school shooting. When there is no national crisis, the dogs work six days a week making the rounds at schools, hospitals, and nursing homes.How the dogs helpNumerous studies have shown that dogs are special in their ability to affect human emotions, moods, and stress.\nResearch even suggests that they have biological effects on us by elevating the levels of the hormone oxytocin, sometimes referred to as 'the love hormone', which\u00a0plays an important role\u00a0in attachment forming and bonding.\"Dogs have an incredible bond with people,\" Brian Hare, professor of cognitive neuroscience at Duke University and author of The Genius of Dogs, told Business Insider. \"Just by making eye contact with dogs, we have an increase in oxytocin. This makes dogs incredibly valuable for people under any kind of stress, or recovering from trauma.\"LCCOxytocin has been\u00a0shown to improve trust, the ability to interpret facial expressions, the overcoming of paranoia, and other pro-social effects, Smithsonian reports.\nStudies have also shown that\u00a0petting dogs can help lower people's heart rates, as well as reduce\u00a0stress and anxiety. The\u00a0Americans with Disabilities Act\u00a0does not necessarily consider comfort dogs (or emotional support dogs) to be service dogs.Still, psychologists, psychiatrists, and doctors have used and continue to use dogs with patients because evidence shows canines can help\u00a0reduce feelings of depression, as well as symptoms of post-traumatic stress disorder in veterans and survivors of childhood abuse.These dogs also help people open up and talk about their experiences, Tim Hetzner, president of the Lutheran Church Charities, told Business Insider.\"It is very important that people in a crisis or disaster situation talk about the situation and what they have gone through. That's part of the healing process,\" he explained. \"Dogs are safe [so] they will talk to the dog, rather than a person, since dogs are great listeners. They are confidential, they don't keep records of rights and wrongs. They are non-judgmental. They are the perfect choice."
        ]
    },
    "4582": {
        "gold_standard": [
            "It's no secret that condoms aren't everyone's favourite thing. But a new study has shown that, for straight men, the decision to have safe sex during a casual fling might depend more on how 'hot' they find their partner, rather than their fear of sexually transmitted infections (STIs).\nYep, that's right, the small study suggests that, the more attractive a guy finds his hook-up buddy, the less interested he is in having protected sex. Even if that partner has a higher risk of having an STI.To be clear, the researchers only surveyed 51 heterosexual men aged between 19 and 61, so it's a very small, not diverse sample size, and we're limited in exactly how much we can take from the results.But the findings back up what several other studies have already found - how babe-ing people find their sex partners is one of the key factors in both men and women's decisions on whether to have safe sex (or sex at all, for that matter). Really deep guys, really deep.\u00a0The purpose of the study was to investigate what drives people to use or not use condoms during casual sex, and hopefully use the results to improve sexual education.\u00a0With STIs such as chlamydia and gonorrhoea on the rise in countries such as the US, the\u00a0UK, and Australia, it's clear there's room for improvement.\nResearchers from the University of Southampton and University of Bristol in the UK asked 51 straight men about all aspects of their sex lives, such as when their first sexual encounter was (on average, 18) and how many sexual partners they'd had (anywhere from 0 to 60, with the average falling at nine).The participants were then shown black-and-white pictures of 20 women's faces and asked the following:\u00a0Please rate the attractiveness of the following woman.\nIf you were single, how likely would you be to have sex with this woman should the opportunity arise?\nIf you were single and you were to have sex with this woman, how likely is it that you would use a condom?\nHow likely is this woman to have an STI?\nThe results showed that the more attractive the men found the women in questions, the less likely they were to want to use a condom.But neither attractiveness nor interest in safe sex really matched up with how likely the men thought the women were to have STIs, as Beth Mole reports for ArsTechnica.\"In fact, some men were most attracted to women they thought had a high risk of STIs, while others were highly attracted to ladies who they perceived would have a low risk of those infections,\" she explains.\nRegardless of their preference when it came to women who were perceived to be\u00a0'risky' or 'safe'\u00a0in the STI department, overall the men in the study seemed to have their condom choices influenced by hotness.\"Men who are more attracted to 'riskier' women are just as disinclined to wear a condom when they have sex with these women as men who are more attracted to 'safer' women,\" the researchers report in the journal BMJ Open.As we mentioned earlier, this is a very small study, and a lot more research is still needed to verify and confirm these findings. Plus, researchers will then need to find out exactly how perceived attractiveness affects men's condom choices.But all of these insights will hopefully help scientists get a better understanding of exactly what's going on in people's heads when they do or don't choose to use a condom during casual sex - and that could help them find better ways to encourage safe sex, says the University of Southampton team.And if that fails, at least scientists are still working on developing a condom that actually feels\u00a0better\u00a0than nothing at all\u00a0- because if the promise of better sex can't convince people to use condoms, then, let's face it, maybe nothing can"
        ]
    },
    "4596": {
        "gold_standard": [
            "Dartmouth College has just announced that it had more women than men graduate from its engineering course this year - an accomplishment they're claiming is a first for any research university in the US.\nWhile more and more women have been enrolling in engineering courses over the past decade, this is reportedly the first time graduating females have outweighed males anywhere in the country - suggesting that we might finally be approaching the tipping point for the male domination of the field.Although this is crazy exciting news, there are a couple of things to mention here. First, we're taking Dartmouth's word on the whole \"first research college in the US\" thing for now - it hasn't been independently verified as yet.Secondly, while Dartmouth is an ivy league school, it's also relatively small, and it doesn't break its engineering courses\u00a0into majors, such as civil or chemical engineering, like\u00a0most other colleges do, so its degrees aren't entirely comparable.But keeping that in mind, this is still a big deal - on average, only 19.9 percent of undergraduate engineering degrees in the US are awarded to women, and just 10 years ago, only a quarter of Dartmouth's engineering graduates\u00a0were\u00a0females.\nThis year, on the other hand, the college handed out 54 percent of its engineering degrees to females. Can someone give us a \"Yasss\"?\"We all recognise this as important,\" Joseph Helble, dean of the Thayer School of Engineering at Dartmouth, told David Brooks from the Concord Monitor. \"This\u00a0has been an issue in engineering education for decades. Diversity is something that we talk about frequently, part of the issue of national competitiveness.\"Helble claims the gender shift is due to the college purposefully hiring female role models in engineering, and also changing the way it structures its course, so students aren't broken up into specialities.\u00a0He says this works because certain engineering majors, such as mechanical and electrical engineering, are heavily male-dominated, and that can put women off further study - research has shown that being an obvious minority group in something can discourage people from continuing to participate.\nAlso, by teaching engineering as one stream, they allow students to combine applied science with some of the more theoretical work, which shows them the potential of their research.\"We've been able to attract more students, and especially women,\u00a0by letting them use engineering to solve real-world challenges,\" said Helble. \"They quickly learn how their creativity and engineering skills can make a real difference.\"According to Randy Atkins, director of communications at the US National Academy of Engineering, that perception is slowly shifting across the country.\u00a0\"We're\u00a0changing the image of engineering\u00a0to a creative profession, a problem-solving profession \u2026 That is resonating with more women, helping them see engineering in a new way,\" Atkins told Brooks.\u00a0Whatever they're doing, let's hope the progress continues, and a 50/50 split in engineering becomes the new normal.After all, we've come a long way from the days of female computer programmers being confused with promotional models, but we've still got work to do before the ideas and research of both men and women get equal attention in the field.\"Now\u00a0we've hit 50 percent, you'd better believe I'm going to talk about it with colleagues from other institutions,\" said Helbl"
        ]
    },
    "4599": {
        "gold_standard": [
            "The ocean's a noisy place, but under the regular din of marine life and ship traffic, scientists have detected a strange, much louder sound coming from the Caribbean Sea.It's too low to be heard by human ears, but the whistle-like noise is so powerful that researchers have been able to pick up its signature from space - and it's like nothing they've ever heard before.\nThe sound was detected while researchers were analysing the sea level and pressure in the region over the past 60 years, in an attempt to predict what could happen in the future. Their interest comes from the fact that the Caribbean Sea is an incredibly important part of the global circulation belt, responsible for forming currents that feed into the Gulf Stream. And if we want to understand how our climate's going to change in the future, we need to better understand how hot and cold water moves around the planet.So scientists from the University of Liverpool in the UK were looking at four different models of ocean activity to try and figure out some of the ocean dynamics in the region.But pretty quickly, they realised something strange was going on - their models kept showing pressure oscillations across the Caribbean basin that just didn't seem to add up.\n\"We were looking at ocean pressure through models for quite different reasons, and this region just didn't work,\" one of the researchers, Chris Hughes, told Gizmodo. \"It felt like a sore thumb.\"To see if the strange phenomenon was actually real, they checked water levels and pressure readings taken from the bottom of the Caribbean Sea between 1958 and 2013, and also looked at readings from tide gauges and satellite measurements of gravity in the area.It turns out the strange pressure oscillations were happening in real life, as well as in the models, producing a low noise that can best be described as a 'whistle'.You can hear a pitched up version of it below: width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\">It might not sound like much, but it's so powerful, the effects can be measured in space, through oscillations in Earth's gravity field.\nSo what's going on here?The sound is being caused by a large wave, known as the Rossby wave, which travels westwards across the ocean, and has been seen to disappear when it hits the west of the Caribbean basin, before appearing 120 days later on its eastern edge.That disappearance was picked up a few years ago, and labelled the Rossby wormhole. But now the researchers have discovered that the wave is still interacting profoundly with the seafloor in the sea, causing it to whistle.\"We can compare the ocean activity in the Caribbean Sea to that of a whistle,\" explains Hughes. \"When you blow into a whistle, the jet of air becomes unstable and excites the resonant sound wave which fits into the whistle cavity. Because the whistle is open, the sound radiates out so you can hear it.\"\"Similarly, an ocean current flowing through the Caribbean Sea becomes unstable and excites a resonance of a rather strange kind of ocean wave called a Rossby wave. Because the Caribbean Sea is partly open, this causes an exchange of water with the rest of the ocean which allows us to 'hear' the resonance using gravity measurements,\" he added.\nBut because the Caribbean Sea is so much bigger than a regular whistle, it causes the sound to be much lower than we can hear.As Stone explains for Gizmodo: \"It takes 120 days for waves to propagate east to west in the basin, yielding an A-flat tone that's roughly 30 octaves below the bottom of a piano.\"The researchers have now labelled the phenomenon the Rossby whistle, and have published their results in Geophysical Research Letters. Understanding how it works is pretty important to figuring out how the oceans in that part of the world will respond to climate variations in the future. \"This phenomenon can vary sea level by as much as 10 cm along the Colombian and Venezuelan coast, so understanding it can help predict the likelihood of coastal flooding,\" said Hughes.The researchers also predict that the Rossby whistle might have an impact on the entire North Atlantic, by regulating the flow in the Caribbean Current, which is the precursor to the Gulf Stream. They're now planning to investigate the phenomenon further to better understand how it affects ocean dynamics"
        ]
    },
    "4620": {
        "gold_standard": [
            "Scientists have broken the world\u00a0record for optical data transfer, beaming what's called 'twisted light' over a distance of 143 kilometres (almost 90 miles).If you're scratching your head over what twisted light is, it's actually exactly what it sounds like: a beam of light where the particles aren't all travelling forward in a linear block, but are twisting as they go, like a corkscrew through the air.\nThe new milestone represents\u00a0a 50-fold improvement\u00a0on the previous record, according to researchers from the University of Vienna in Austria, and while they're not ready for real-world applications yet, these twisted beams of light could one day be used to send large volumes of data at blisteringly high speeds.Also called an\u00a0optical vortex, twisted light could improve current fibre optic technology because it allows more data to be sent simultaneously - separate channels of information could be broadcast at the same time, using different amounts of twist.Scientists are still figuring out the practicalities of how such a system would work, because right now, one problem is beaming an optical vortex without the light (and therefore the data) being scrambled along the way.One of the\u00a0ways\u00a0we could\u00a0get around this is by using\u00a0neural networks that can help to filter out transmission errors. With this kind of system, the team was able to transmit light through the air between the islands of La Palma and Tenerife in the Canary Islands, Spain, for a total distance of 143 kilometres (89 miles).\nThey even encoded a message in the corkscrew beam: \"Hello, world.\" Aw.Credit: University of ViennaHaving been trained using data from beams distorted by turbulence, their computer-powered neural network was able to successfully decode messages about 80 percent of the time.That figure \u2013 and the overall distance \u2013 should get higher over time, as the technology and methods are further refined. The team used a green laser beam at the sending station in La Palmer, with the resulting magnified light collected on the wall of the Observatorio del Teide in Tenerife.The experiment took 10 days in total, which means\u00a0there's clearly room for improvement, seeing as that's about as fast as a smoke signal. Still, in science, you've gotta start somewhere.\nIn the future, this kind of technology could eventually allow for high-speed data transmission between satellites and Earth's surface, the scientists say.\"We don't consider this method as real communication, but merely the demonstration of the transmission quality of modes,\" write the researchers. \"However, the application of state-of-the-art adaptive optics such as those used in simple and efficient intensity-based methods could further improve the link quality.\"A paper detailing the research has been\u00a0published on pre-print website arXiv.org,\u00a0is currently awaiting\u00a0peer-revie"
        ]
    },
    "4641": {
        "gold_standard": [
            "The secret of what causes volcanic lightning - a strange and violent form of lightning that only happens inside the ash clouds of erupting volcanoes - has finally been cracked.\nNot only have researchers in Germany figured out where volcanic lightning comes from, they might\u00a0have also found a new way to measure how much ash a volcano is spewing out in real time, which will help us to\u00a0predict air quality during and after eruptions.Before we dive headfirst into volcanic lightning, we need to understand some basics about normal lightning. Lightning forms inside a cloud when a mix of warm and cold air causes a static electrical charge to build, with the top of the cloud having a positive charge and the bottom having a negative one.\"In the early stages of development, air acts as an insulator between the positive and negative charges in the cloud and between the cloud and the ground,\" explains the National Severe Storms Laboratory (NSSL).\"When the opposite charges builds up enough, this insulating capacity of the air breaks down and there is a rapid discharge of electricity that we know as lightning. The flash of lightning temporarily equalises the charged regions in the atmosphere until the opposite charges build up again.\"\nA similar thing happens in volcanic lightning, with an electrical charge building up, but there are some big differences, too. Volcanic lightning, for example, forms closer to the ground, and doesn't always move downward in the same way that normal lightning does.And, most importantly, volcanic lightning happens inside plumes of ash, rather than regular water vapour clouds, making them a mysterious force that researchers have figuring out for some time.Now, a team from Ludwig-Maximillian University has observed these awesome bolts of lightning form in Japan's Mount Sakurajima, one of the most active volcanoes on the planet, using high-speed video footage and acoustic analyses.After meticulously scrutinising the data they collected, the team found that volcanic lightning typically occurs in the lower section of the ash cloud.\nThis, they say, is because the churning magma inside the rim of the volcano causes the ash cloud right above it to become electrified. Eventually, this charge builds up similar to the way it does in a normal cloud, producing a lightning strike.\"These data lead us to infer that although volcanic and thundercloud lightning share many common physical characteristics, the conditions presaging the occurrence of electrical discharges at explosive eruptions result from the complex charge distribution within the developing plume,\" the team reports.While analysing their findings, the team noticed that that the frequency of the lightning strikes increased with the size of the ash plume.This correlation, they hope, will offer a new way to gauge how large an eruption is and how much ash is thrown into the air without putting researchers in danger. After all, lightning flashes are pretty easy to count even from far away.\n\"This is a parameter that can be measured - from a distance of several kilometres away and under conditions of poor visibility,\" one of the team, Corrado Cimarelli, told Maddie Stone at\u00a0Gizmodo.While we might now know how volcanic lightning comes to life, there's likely a lot more to learn about them - like this 2015 discovery, where\u00a0researchers from the University of Alabama found that volcanic lightning actually creates\u00a0perfectly round balls of glas"
        ]
    },
    "4652": {
        "gold_standard": [
            "If you were to wind the clock back, say, 4 billion years or so, our Solar System would look a little bit like this protoplanetary disc surrounding the baby star TW Hydrae.This is the closest planet-forming disc of its kind that we know about, and now, scientists have discovered something floating within the gas that could be essential to life: the organic molecule methyl alcohol (methanol). This is the first time this compound has been found in a protoplanetary disc.\nAn international team of researchers detected the fingerprint of this gaseous methanol located some 170 light-years away by using the Atacama Large Millimeter/Submillimeter Array (ALMA) in Chile, an array of radio telescopes specifically designed to study light emissions from some of the coldest objects in the Universe.That capability is what enabled the team to identify methanol around TW Hydrae, as the compound forms solely in the ice phase via surface reactions. In this case, the methanol was detected on minuscule dust grains that make up the protoplanetary disc. The researchers think it's released from the grains in its gaseous form.\"Finding methanol in a protoplanetary disc shows the unique capability of ALMA to probe the complex organic ice reservoir in discs and so, for the first time, allows us to look back in time to the origin of chemical complexity in a planet nursery around a young Sun-like star,\" said astronomer Catherine Walsh from the Leiden Observatory in the Netherlands.Because methanol is an essential building block for other compounds that make up organic life, such as amino acids, finding it in a protoplanetary disk is a major discovery \u2013 as it could help us to learn about how organic molecules and maybe even life itself end up finding a home on the planets that emerge from these cosmic nurseries.\n\"Methanol in gaseous form in the disc is an unambiguous indicator of rich organic chemical processes at an early stage of star and planet formation,\" said one of the team, Ryan A. Loomis. \"This result has an impact on our understanding of how organic matter accumulates in very young planetary systems.\"Methyl alcohol isn't the kind of alcohol most of us are familiar with, although strangely enough the drinkable sort, ethyl alcohol, is also found in space. Neither of which should be confused with space whiskey, either.In addition to detecting methanol, the team found that the distribution of the gas within the disc creates a ring-like pattern in the cloud of matter (which you can see in the images on this page). The scientists hypothesise that this ring is formed when larger dust grains in the icy mass decouple from the gas, and begin to drift inward to TW Hydrae, thanks to the star's gravitational pull.The methanol discovery follows fast on the heels of another important molecular find in space, with researchers this week announcing the first detection of chiral molecules in interstellar space \u2013 a key property of the organic molecules that make up all the living things on Earth.Artist's impression of the protoplanetary disc surrounding the young star TW Hydrae. Credit: ESO/M. KornmesserWhile neither of these findings are obviously on the level of actually finding alien life itself, they're the next best thing, adding weight to the case that life's building blocks exist outside our Solar System \u2013 and demonstrating the epic reach of today's best telescopes.\"The successful detection of cold gas-phase methanol in a protoplanetary disk implies that the products of ice chemistry can be explored in disks,\" the authors write in their paper, \"opening a window into studying complex organic chemistry during planetary system formation"
        ]
    },
    "4654": {
        "gold_standard": [
            "Physicists have just published a new paper that suggests the controversial EM drive - or electromagnetic drive - could actually work, and doesn't defy Newton's third law after all.\nIn case you've missed the hype, here's a quick catch-up: a lot of space lovers are freaking out about the EM drive because of claims it could get humans to Mars in just 10 weeks, but just as many are sick of hearing about it, because, on paper at least, it doesn't work within the laws of physics.Despite that not-insignificant setback, the EM drive shows no signs of quitting, and test after test - including trials by NASA scientists at the Eagleworks lab, and an independent researcher in Germany - has conceded that the propulsion system, somehow, does produce thrust.\u00a0Why is that so surprising? That's because of how the EM drive is supposed to work, in theory at least. First designed by British scientist Roger Shawyer back in 1999, the EM drive uses electromagnetic waves as fuel, and creates thrust by bouncing those microwaves back and forth within a metal cavity to trigger motion.According to Shawyer's calculations, that could produce enough thrust to blast humans to Mars in just 70 days, and potentially even help us reach the next star system, Alpha Centauri, in just\u00a092 years, all without the need for heavy, expensive rocket fuel.\nThat sounds pretty incredible, right? But there's one big problem - according to Newton's third law, everything must have an equal and opposite reaction, which means that something needs to be pushed out the back of propulsion system for it to move forwards. And, you pretty quickly see the dilemma - the EM drive doesn't use any fuel propellants, and so it doesn't have an exhaust, and so\u2026 it\u00a0can't\u00a0produce thrust. Even though it does.Now that we've taken that round-trip right back to the dilemma we started with, let's present you with a potential solution, from physicists at the COMSOL company, the University of Helsinki, and the University of Jyv\u00e4skyl\u00e4 in Finland.According to their new peer-reviewed study published in AIP Advances, the EM drive doesn't actually defy Newton's third law, because it\u00a0does\u00a0produce exhaust.*Cue scream face emoji*\nAccording to the researchers, the exhaust being blasted out is actually light, or more specifically, photons that have become paired up with another out-of-phase photon in order to shoot out of the metal cavity and produce thrust.\u00a0So if that's the case, why hasn't anyone detected it before?The researchers predict that's because photons need to become paired up in order to escape the fuel cavity, so that the two photons in those pairs are out of phase, which means they completely cancel each other out and have no net electromagnetic field. If you think of it like waves of water, if the crest of one wave occurs at the exact same time as the trough of another, they'll cancel each other out and produce a flat patch of water - despite the fact that two waves are still passing through it.\u00a0That's what's happening with the photons, so, in other words, the exhaust photons become invisible from an electromagnetic point of view because they're being masked by their out-of-sync partner.\n\"The\u00a0EM drive operates by the same principle, for example, as a jet engine, where\u00a0the high speed exhaust gases backwards (opposite reaction)\u00a0push the airplane forwards,\" one of the researchers Arto Annila, told ScienceAlert over email. \u00a0\"Light at microwave lengths is the fuel that's being fed into the cavity \u2026 and the EM drive\u00a0exhausts backwards paired\u00a0photons,\" he says. \"When two photons travel together, but having opposite phases, then the pair has no net electromagnetic field, and hence it will not reflect back from the metal walls, but goes through.\"And those escaping photons are the equal and opposite reaction that's producing the EM drive's thrust.To be clear, this is just a hypothesis based on theoretical calculations. But it's not the first time photons have been used to propel spacecraft forward - it's also the idea that Bill Nye's solar sail is based o"
        ]
    },
    "4683": {
        "gold_standard": [
            "The Astrophysical Journal Located about 3,700 light-years away, in the direction of the Cygnus constellation, lies a distant planet called Kepler\u20131647b, which at approximately 4.4 billion years of age is roughly as old as Earth.\nBut that's about where the similarities end, because Kepler\u20131647b turns out to hold a pretty sensational point of difference: this newly identified world is the largest planet ever discovered that orbits two stars. Known as circumbinary planets, these strange cosmic phenomena are often called 'Tatooine' planets, after Luke Skywalker's dusty desert home.An international team of astronomers led by NASA's Goddard Space Flight Centre just announced the discovery of Kepler\u20131647b, which has a mass and radius that are nearly identical to Jupiter's. But just because this circumbinary planet might be the largest of its kind that we currently know about, that didn't make locating it any easier.\"[F]inding circumbinary planets is much harder than finding planets around single stars,\" said astronomer William Welsh from San Diego State University (SDSU). \"The transits are not regularly spaced in time and they can vary in duration and even depth.\"The team identified the planet using data recorded by the Kepler space observatory, and adding to the challenge was Kepler\u20131647b's other remarkable feature \u2013 the immense length of its orbital period. At 1,107 days, this is the longest of any confirmed transiting exoplanet astronomers have yet found.Artist's impression. Credit: Lynette CookThis means it takes over three years for Kepler\u20131647b to orbit its host stars - both of which are similar in size to our Sun, with one being slightly smaller, and the other being slightly larger.\nThat epic orbital period is the result of Kepler\u20131647b being located further away from its host stars than other circumbinary planets, which usually hold relatively tight orbits. In the image below, you can see just how much wider Kepler\u20131647b's orbit (in red) is compared to its circumbinary counterparts (in grey), with Earth's orbit (in blue) added in for reference.\"It's a bit curious that this biggest planet took so long to confirm, since it is easier to find big planets than small ones,\" said SDSU astronomer Jerome Orosz. \"But it is because its orbital period is so long.\"Comparison of the relative sizes of several Kepler circumbinary planets. Credit: Lynette CookEvidence for Kepler\u20131647b's existence was first found back in 2011, when one of the team, Laurance Doyle from the SETI Institute, spotted the planet transit in front of one of its stars. But it took several extra years of analysis and observations \u2013 supported by amateur astronomers using the Kilodegree Extremely Little Telescopes in the US and South Africa \u2013 before the researchers confirmed that Kepler\u20131647b was a circumbinary planet.\nWhile Kepler\u20131647b's distance from its stars is greater than usual for a circumbinary planet, it's actually within the habitable zone \u2013 the distance from a star at which liquid water could exist on a planet's surface, not being so far away that it would freeze, nor so close that it would evaporate.But, in this case, since Kepler\u20131647b is a gas giant like Jupiter, the researchers think it's unlikely to host life \u2013 although there's a possibility any as-yet-undiscovered moons orbiting the planet could provide a suitable environment for it. Sadly, this means there's probably nobody looking up to see a beautiful two-star sunset like the one Luke Skywalker watches in Star Wars.Comparison of the orbits of the Kepler circumbinary planets. Kepler\u20131647 b's orbit is shown in red. Other planets are shown in grey. For comparison, the Earth's orbit is shown in blue. Credits: B. QuarlesBut just because we probably won't find alien life on Kepler\u20131647b doesn't mean the planet isn't a major find. In addition to its record-breaking size and orbital length, the scientists think this Tatooine-esque planet could herald the discovery of a new generation of similar worlds that have eluded us until now.\nWhen you consider that the first such planet \u2013 Kepler\u201316b \u2013 was only discovered five years ago, it becomes clear why this is such an exciting time for astronomy. Kepler\u20131647b is the 11th confirmed circumbinary planet discovered by the Kepler telescope since then.\"Habitability aside, Kepler\u20131647b is important because it is the tip of the iceberg of a theoretically predicted population of large, long-period circumbinary planets,\" said Welsh.The findings have been accepted for publication in The Astrophysical Journa"
        ]
    },
    "4689": {
        "gold_standard": [
            "The new comprehensive World Atlas of Artificial Night Sky Brightness has just appeared in Science Advances. Written by a group of distinguished scientists lead by Italian Fabio Falchi, it is a noteworthy accomplishment. The first atlas appeared in 2001\u00a0but was based on a less precise satellite measurement system. This latest atlas provides far more clarity.\nThe atlas measures what is called artificial sky glow - reflected light scatter in the atmosphere from the electric lighting below - across the world. Sky glow results from light pollution, or the excess of electric light during the night. But 'light pollution' is not like 'water pollution' which is pollution of water. It's actually 'night pollution by electric light'.So what is the magnitude of the problem?As one measure of how far we have come in obliterating the night sky, Falchi and colleagues estimate that, thanks to sky glow, the Milky Way is no longer visible to one-third of humanity, with the most heavily industrialised regions suffering the greatest loss: 60 percent of Europeans and 80 percent of North Americans can no longer see the Milky Way at night.But the problem with light pollution isn't just about stargazing. As Falchi and his colleagues point out, it also has effects on environmental and public health. As an epidemiologist who has been studying the possible impact of electric lighting on health for decades, I am greatly concerned about this.\nHow do we measure artificial light pollution?The atlas uses light measurements taken by the Suomi National Polar-orbiting Partnership satellite, which orbits 800 kilometres (497 miles) above Earth and takes pictures of the ground below at night. The satellite can sense the intensity of any light source it detects and plot its location. These measurements are then converted by some sophisticated modelling to produce colourful maps of each region of the world that show the level of sky glow over cities, towns, and adjacent countrysides.Falchi et al., Science Advances (2016)While the maps are rather pretty and appealing to view, the underlying message is ominous. The more sky glow, the more obscure the night sky is. For instance, in Times Square in the heart of New York City, at midnight you might be able to count only a dozen stars in the sky, if that. In those areas of the map that show red, the authors tell us, people don't experience true night because of an artificial twilight from sky glow.\nIn fact, as Falchi and colleagues note, \"\u2026the most light-polluted country is Singapore, where the entire population lives under skies so bright that the eye cannot fully dark-adapt to night vision\".In the most affected regions of the megacities in Europe, the Americas and Asia, the local light levels outside on the street are at times enough to prevent or delay transition to our normal nighttime physiology which should begin at about sunset. The health effects of these local light sources at night, and the sky glow they cause, are the subject of intense research, and have not yet been fully calculated.Developing societies are also embracing electric lighting of the night, and light pollution is expanding its domain at an epidemic rate. I must emphasise that this represents a huge change in the environment.Sky glow isn't just a problem in megacities and urban areas. As the authors note, Death Valley gets sky glow from Las Vegas and Los Angeles, and thereby experiences light pollution.\nWhat does sky glow mean for you?Humans, like most other life forms on the planet, have what is called an endogenous circadian rhythmicity. This is a built-in cycle for sleep and wake patterns, hunger, activity, hormone production, body temperature and a vast array of other physiological processes. The cycle lasts roughly 24 hours, and light, especially sunlight, and darkness are important signals to keep it on track.The sky glow reported in the atlas is, by itself, probably below the threshold for directly affecting our circadian rhythms, as measured by suppression of the circadian hormone melatonin.But the sky glow the atlas measures is the atmospheric reflection of electric lights in the immediate human environment. Those local light sources are in many, if not most, cases sufficient to cause circadian disruption. These include the lighting inside homes and commercial buildings as well as some forms of street lighting.\nSo the maps also indicate those places where light at night, in all its forms, can most disrupt our normal circadian rhythms, both inside buildings and for those who are outside at night.This circadian physiology has developed over billions of years. Humans have been living with electricity only since the late 19th century, and with widespread access in industrialised countries only since the 20th century. While that sounds like a long time, it's tiny drop in the evolutionary bucket. We are only beginning to understand the health consequences artificial light has on our circadian physiology.The increasing illumination of night has converged with our growing understanding of circadian physiology, and how light at night can disrupt that physiology. The suspicion has emerged recently that some serious maladies could result from circadian disruption such as poor sleep, obesity, diabetes, certain cancers and mood disorders. The most potent environmental exposure that can cause circadian disruption is ill-timed electric lighting, particularly at night.There are also some severe ecological consequences of light pollution that include mortality events on migrating birds and sea mammals.Dave Z/FlickrTurn off the lights\nJust as technology has created the problem of light pollution by invention of the electric light bulb, the technology of biological science is showing us what forms of light and at what times of day are most, or least, harmful to our circadian health.This knowledge is now being exploited to produce light sources that are appropriate for time of day. At the most basic, best is bright light with high blue content (e.g., compact fluorescent) in the morning and dim light with low blue content (e.g., low wattage incandescent) beginning at dusk. And turn off the bright blue screens of tablets and smartphones; read an actual book in the evening.One of many implications of this work is the engineering of street lighting. The wholesale conversion to 'white' LED street lighting by many communities such as Los Angeles and New York is coming under increasing scrutiny because that lighting produces the blue wavelengths that are least friendly to our nighttime physiology and circadian health.Maybe it's time rethink street lighting. Energy efficiency is an important consideration, but so too is health of the planet.Richard G. 'Bugs' Stevens, Professor, School of Medicine, University of Connecticut.This article was originally published by\u00a0The Conversation. Read the\u00a0original articl"
        ]
    },
    "4704": {
        "gold_standard": [
            "The Astrophysical Journal A likely new planet that might be one of our galaxy's youngest could also turn out to be unique, say astronomers, but that uniqueness appears to come at a price.Called PTFO8\u20138695 b, this newly discovered planet candidate orbits a star 1,100 light-years from Earth, but the newborn's proximity to its host star puts it in a dangerous situation. With an extremely close orbit that only takes 11 hours to complete, this 'hot Jupiter' \u2013 a term for hot planets with large masses and short orbital periods \u2013 looks to be engaged in a drawn-out death spiral.\nResearchers think PTFO8\u20138695 b is slowly losing its outer layers, which are being ripped away over time by the gravity pull of its nearby star.\"A handful of known planets are in similarly small orbits, but because this star is only 2 million years old, this is one of the most extreme examples,\" said astronomer Christopher Johns-Krull from Rice University.While the object's status as a planet has yet to be scientifically confirmed, the relative youth of PTFO8\u20138695 b, along with its unfortunate predicament, suggests that we're looking at something special. At least for as long as PTFO8\u20138695 b manages to hold out.Artist's impression. Credit: A. Passwaters/Rice University\"We don't yet have absolute proof this is a planet because we don't yet have a firm measure of the planet's mass, but our observations go a long way toward verifying this really is a planet,\" said Johns-Krull. \"We compared our evidence against every other scenario we could imagine, and the weight of the evidence suggests this is one of the youngest planets yet observed.\"\nAnd that list of planets observed is growing all the time. Scientists have currently discovered some 3,432 exoplanets (planets outside our Solar System), with that number receiving a massive bump last month, when NASA officially announced the discovery of 1,284 new alien worlds.The majority of these exoplanets orbit comparatively middle-aged stars \u2013 like our Sun, which is thought to be 4.5 billion years old. In contrast, PTFO8\u20138695's 2 million years or so make it something of a cosmic infant. But while young stars and their planets offer a valuable research subject for scientists, they're not always easy to study \u2013 or even find.According to Johns-Krull, there aren't many young stars that we know about that shine brightly enough for us to observe in detail with today's telescopes. And because young stars are also relatively active \u2013 with strong magnetic fields, and producing frequent visual outbursts and dimmings \u2013 it makes it harder for researchers to accurately gauge whether they're orbited by planets.PTFO8\u20138695 b was identified in 2012 by an international survey called the Palomar Transit Factory, but even though we've only known about it for a very short time, the jury's out on how long exactly this baby (maybe) planet has left.\"We don't know the ultimate fate of this planet,\" said Johns-Krull. \"It likely formed farther away from the star and has migrated in to a point where it's being destroyed. We know there are close-orbiting planets around middle-aged stars that are presumably in stable orbits. What we don't know is how quickly this young planet is going to lose its mass and whether it will lose too much to survive.\"The findings have been accepted for publication in The Astrophysical Journa"
        ]
    },
    "4754": {
        "gold_standard": [
            "There's a lot we still don't know about dark matter \u2013 we're not even 100 percent sure it exists \u2013 but for years, scientists have hypothesised that a huge disc of the mysterious stuff is slicing right through our very own Milky Way. Now, thanks to new calculations, that hypothesis is getting a whole lot more attention.\nA new study suggests that scientists have overlooked one important clue in their calculations: that this hypothetical dark matter disc could make room for itself\u00a0within our galaxy. If this disc can pinch in other types of matter \u2013 stars, gas, and dust \u2013 like the researchers suggest, then a dark matter disc begins to look more likely.Physicist Lisa Randall of Harvard University first proposed her version of the dark disc theory in 2013.\u00a0Dutch astronomer Jan Oort first floated the idea in 1932, after observing the irregular movement of the stars in our galaxy, and Randall has brought it out of obscurity. But, as Natalie Wolchover reports for\u00a0Wired, it's a controversial idea that has more detractors than supporters.Randall's new paper, written with Harvard graduate student Eric Kramer, is online at pre-press site, arXiv.org and has been accepted for publication in The Astrophysical Journal.The pair explains that the total visible mass of the Milky Way is typically estimated by extrapolating outwards from the density of its midplane \u2013 the central line passing through the galaxy.\u00a0If a dark disc exists and can pinch matter towards it \u2013 at the midplane \u2013 then our previous calculations are inaccurate.\nThat means the presence of a disc becomes possible, and perhaps even slightly probable, depending on the type of analysis used, they argue.\u00a0The fact that no one was looking for a disc that could interfere with matter in this way is why a lot of previous studies haven't seen evidence for it, Kramer told Wolchover.Other experts who've run the numbers say there's not enough room for error to leave the chance of a dark matter disc existing. \"It's more strongly constrained than Lisa Randall pretends,\" astrophysicist Jo Bovy of the University of Toronto in Canada, told her.Bovy, who wasn't involved in the new research, but has carried out his own measurements, thinks that even with a pinching effect in place, a disc could only account for 2 percent of the dark matter estimated to exist in the galaxy. That leaves a lot of unexplained dark matter.Thanks to the Gaia space observatory, we might soon know one way or the other: it's currently carrying out a new inventory of the Milky Way, which will give us a more accurate account of the position and velocity of 1 billion star"
        ]
    },
    "5210": {
        "gold_standard": [
            "For nearly nine decades, science's favourite explanation for the origin of life has been the 'primordial soup'. This is the idea that life began from a series of chemical reactions in a warm pond on Earth's surface, triggered by an external energy source such as lightning strike or ultraviolet (UV) light.\nBut recent research adds weight to an alternative idea, that life arose deep in the ocean within warm, rocky structures called hydrothermal vents.A study published last month in Nature Microbiology suggests the last common ancestor of all living cells fed on hydrogen gas in a hot iron-rich environment, much like that within the vents.\u00a0Advocates of the conventional hypothesis\u00a0have been sceptical that these findings should change our view of the origins of life.But the hydrothermal vent hypothesis, which is often described as exotic and controversial, explains how living cells evolved the ability to obtain energy, in a way that just wouldn't have been possible in a primordial soup.Under the conventional hypothesis, life supposedly began when lightning or UV rays caused simple molecules to join together into more complex compounds.\u00a0This culminated in the creation of information-storing molecules similar to our own DNA, housed within the protective bubbles of primitive cells.\nLaboratory experiments confirm that trace amounts of molecular building blocks that make up proteins and information-storing molecules can indeed be created under these conditions. For many, the primordial soup has become the most plausible environment for the origin of first living cells.But life isn't just about replicating information stored within DNA. All living things have to reproduce in order to survive, but replicating the DNA, assembling new proteins and building cells from scratch require tremendous amounts of energy.At the core of life are the mechanisms of obtaining energy from the environment, storing and continuously channelling it into cells' key metabolic reactions.Where this energy comes from and how it gets there can tell us a whole lot about the universal principles governing life's evolution and origin. Recent studies increasingly suggest that the primordial soup was not the right kind of environment to drive the energetics of the first living cells.\nIt's classic textbook knowledge that all life on Earth is powered by energy supplied by the sun and captured by plants, or extracted from simple compounds such as hydrogen or methane. Far less known is the fact that all life harnesses this energy in the same and quite peculiar way.This process works a bit like a hydroelectric dam. Instead of directly powering their core metabolic reactions, cells use energy from food to pump protons (positively charged hydrogen atoms) into a reservoir behind a biological membrane. This creates what is known as a 'concentration gradient' with a higher concentration of protons on one side of the membrane than other.The protons then flow back through molecular turbines embedded within the membrane, like water flowing through a dam. This generates high-energy compounds that are then used to power the rest of cell's activities.Life could have evolved to exploit any of the countless energy sources available on Earth, from heat or electrical discharges to naturally radioactive ores. Instead, all life forms are driven by proton concentration differences across cells' membranes.\nThis suggests that the earliest living cells harvested energy in a similar way and that life itself arose in an environment in which proton gradients were the most accessible power source.Vent hypothesisRecent studies based on sets of genes that were likely to have been present within the first living cells trace the origin of life back to deep-sea hydrothermal vents. These are porous geological structures produced by chemical reactions between solid rock and water.Alkaline fluids from the Earth's crust flow up the vent towards the more acidic ocean water, creating natural proton concentration differences remarkably similar to those powering all living cells.The studies suggest that in the earliest stages of life's evolution, chemical reactions in primitive cells were likely driven by these non-biological proton gradients. Cells then later learned how to produce their own gradients and escaped the vents to colonise the rest of the ocean and eventually the planet"
        ]
    },
    "4758": {
        "gold_standard": [
            "When it comes to casinos, it's no secret that the house always wins. And while roulette might be one of the most popular of the Vegas games,\u00a0it's also got some of the worst odds.\u00a0Unless you have an uncanny knowledge of physics, that is.\nBack in the '70s, a mathematician called J. Doyne Farmer famously built a machine that allowed him to skew the odds of roulette so significantly in his favour that he's since been banned from all the casinos in Nevada. And now\u00a0a colleague has just told the internet how it works.Before we get started, let's make it very clear that we're not endorsing gambling (or using science to do anything illegal).\u00a0But there's some pretty bad-ass physics and statistics to be learned here.The new insight into the roulette-beating machine was revealed over on Quora this week, when someone asked the world wide web \"What do physicists know that lets them win at casinos?\"The top-voted answer came from Richard Muller, a professor of physics at the University of California, Berkeley, who admitted that a colleague of his once built a device that allowed him to beat the roulette table.\nAs Muller explains:\n\"It worked as follows: to encourage people to bet at roulette, it has been traditional to allow bets to be made\u00a0after\u00a0the wheel is spun and the ball is flung, but only\u00a0before\u00a0it begins to drop. In that second or two, there is enough information to allow a measurement and computation that will, for example, double your odds of winning.\nIf the computation simply rules out half of the wheel as unlikely, then the odds jump up highly in your favour. Whereas before, your odds of winning might be 98:100 (so you lose), if you exclude half of the numbers, your odds become 196:100; you win big!\nYou don't have to predict the number where it will fall. You only have to increase your odds by 3 percent to go from losing on average to winning on average.\"\nWith that in mind, Muller explains that the machine worked by attaching a switch to the player's toes. The player would tap one switch each time the ball completed a full spin, and the other switch each time the wheel spun.From that data, a small pocket computer could calculate the odds and let him know, via a tap on the leg, where he should place his bet. All in the small window of time before the ball stops spinning.\nOf course, to figure this out, he first had to calibrate his device using a real casino roulette wheel, which he did by buying his own wheel and testing it in his garage before hitting the tables.\"The casinos don't have the right to search you, so how can they guard against devices such as that?\" writes Muller. \"To do that, they have lobbied to make a law that they can exclude any person without cause. They choose to do that only when they see someone consistently beating the odds. They can't get their money back, but they can stop losing \u2026\u00a0Indeed, my friend (who was then a gradate student at Berkeley) was put on the list.\"To be clear, Muller doesn't specify that he's talking about Farmer in his answer, but the story definitely matches up with Farmer's famous casino scam.And for all the doubters out there, this isn't just a science urban legend. Back in 2012, researchers Michael Small from the University of Western Australia, and Chi Kong Tse from Hong Kong Polytechnic University, published a paper that showed for the first time in a peer-reviewed journal how this process works.\nThe team was able to demonstrate that simply knowing the rate at which the wheel and ball are spinning - before the ball starts bouncing and everything gets random - is enough to skew the odds.In fact, by using a system similar to Farmer's where they recorded each time the ball or wheel passed a certain point, they showed that they could win on average 18 percent of the time - well above the negative 2.7 percent currently expected from a random bet.\u00a0\"Knowing the initial conditions allows you to beat the odds,\" said Small at the time. \"In some cases you can beat them quite significantly.\"The release of that publication actually prompted the first public response from Farmer about his machine, and he admitted that their technique was very similar to the one he'd used in his device - except that Small and Kong Tse had assumed that the main force slowing the ball down was friction with the rim, whereas he'd calculated that it was air resistance.So does using physics to outsmart the house pay off? It can\u2026 until the casino figures out what you're up to and bans you for life, as was the case with Farmer, who definitely didn't get rich off his scheme.\u00a0\"He says he\u00a0almost\u00a0made enough money to pay for the roulette wheel he had purchased to perfect his instrument at home before going out 'into the field',\" recalls Muller. Damn"
        ]
    },
    "4774": {
        "gold_standard": [
            "The Astrophysical Journal Letters Scientists have broken a new astronomical record, detecting the faint signal of hydrogen in an extremely distant galaxy located some 5 billion light-years away.The team made the find using the Very Large Array of the National Radio Astronomy Observatory in New Mexico, which just had a substantial upgrade to the antennae, allowing them to pick up on hydrogen signals from almost double the distance of the previous record.\n\"Due to the upgrade of the Very Large Array, this is the first time we've been able to directly measure atomic hydrogen in a galaxy this far from Earth,\" said one of the researchers, Ximena Fernandez from Rutgers University in New Jersey. \"These signals would have begun their journey before our planet even existed, and after 5 billion years of travelling through space without hitting anything, they've fallen into the telescope and allowed us to see this distant galaxy for the very first time.\"The researchers say the galaxy would once have contained billions of young, massive stars, created from the fuel of surrounding neutral hydrogen (HI) gas.Hubble Space Telescope image of the galaxy with overlay of the hydrogen emission that was recently discovered. Credit: Fernandez et al, NRAO/AUI/NSF, NASA\"Hydrogen is the basic element in the universe. That's where everything had to start,\" astronomer Attila Popping from the University of Western Australia told Garrett Mundy at the ABC. \"It's the first building block of gas and stars and galaxies. So with the survey we tried to understand the evolution of HI. How it evolves over time.\"\nThe team says the ability to peer so far across the Universe \u2013 and so far back in time as a result \u2013 is crucial to learning more about galaxy formation, and finding how the process has changed across galaxies over billions of years.\"This is precisely the goal of the project, to study how gas in galaxies has changed through history,\" said Fernandez. \"A question we hope to answer is whether galaxies in the past had more gas being turned into stars than galaxies today. Our record-breaking find is a galaxy with an unusually large amount of hydrogen.\"Artist's impression of the gas cloud and galaxy. Credit: ICRAR/Peter RyanBut the snapshot the researchers have taken \u2013 seen in a composite image above, along with an artist's impression underneath it \u2013 is not the way the galaxy would look like now, with billions of years of stellar activity likely to have radically altered the composition of the star system.\"The hydrogen has probably been turned into stars,\" Popping told the ABC. \"It's been eaten by the galaxy and become a supernova explosion and expelled again. The gas itself is probably in a different state now than as we can see it.\"The findings are reported in The Astrophysical Journal Letter"
        ]
    },
    "4778": {
        "gold_standard": [
            "Science is not quite sure why, but new calculations show the Universe is expanding faster than expected, possibly the result of something we only suspect exists \u2013 dark radiation.\nThe latest research on star movements found the Universe is expanding between 5 percent and 9 percent faster than early in its life. One consequence of this could be that the universe ends up ripping itself apart.\"A funny universe just got funnier,\" says lead Australian researcher and ANU astrophysicist Brad Tucker.\"It could be a new force similar to dark energy, or a new particle, or it could be that dark energy itself has changed over time,\" he added. \"We thought we were close to understanding dark energy, but now we know we don't know the answer at all. There's a lot of work to do.\"Stars, planets, and gas make up only 5 percent of the Universe. The rest is 25 percent dark matter and 70 percent dark energy, both of which are invisible and have never been directly detected.\nPrecise values of the Universe's expansion from 13.7 billion years ago have been calculated from observations of the cosmic microwave background, the very faint afterglow of the big bang.The research was led by Nobel Laureate Adam Riess of the Space Telescope Science Institute and the Johns Hopkins University in the US.The Hubble Space telescope was used to look at variable stars, called Cepheids, and Type Ia supernovae, which both have well known brightness which enables their distance to be precisely determined.The team measured the movements of about 2,400 Cepheid stars and about 300 Type Ia supernovae over two and a half years.From these measurements they calculated the Universe's expansion rate, known as the Hubble constant, to be 73.2 kilometres per second per megaparsec (a megaparsec equals 3.26 million light-years).\nThe new value means the distance between cosmic objects will double in another 9.8 billion years.The research is published in The\u00a0Astrophysical Journal.The team has a number of theories for the Universe's excessive speed. One possibility is that dark energy may be shoving galaxies away from each other with growing strength, termed phantom dark energy.Another idea is that the cosmos contained a new subatomic particle in its early history that travelled close to the speed of light and affected the expansion rate. Such speedy particles are collectively referred to as dark radiation and include previously known particles such as neutrinos.The boost in acceleration could also mean that dark matter possesses some weird, unexpected characteristics. Or the speedier Universe may be telling astronomers that Einstein's theory of gravity is incomplet"
        ]
    },
    "4797": {
        "gold_standard": [
            "If you're the kind of person who worries about how accurate (or perhaps not) your creaky bathroom scales might be, spare a thought for astrophysicist Gwendolyn Eadie. It's her job \u2013 or, rather, area of study \u2013 to figure out the mass of the whole galaxy.\nNo easy gig, to be sure, but according to Eadie's latest estimates, we now have a new measurement for the mass of the Milky Way, and it's a biggie. She calculates that the Milky Way has a mass equal to 7 x 1011solar masses. To put it another way, the galaxy has the same mass as 700 billion Suns. \"And our galaxy isn't even the biggest galaxy,\" Eadie says.To drill down a little further, the Sun has about 330,000 times the mass of Earth, or 2 nonillion kilograms (that's a 2 followed by 30 zeroes).Yep, these are some pretty crazy numbers, but astronomical mass estimations like this are an important part of figuring out how the Milky Way came to be \u2013 and where it's headed.\"Understanding our galaxy's mass puts it into a better cosmological context,\" Eadie, a PhD student from McMaster University in Canada, told Michelle Z. Donahue at National Geographic. \"People who study the evolution of galaxies look at how the mass relates to its evolution. If we have a better handle on what the mass of the Milky Way is, we can understand how it and other galaxies form and evolve.\"\nThere's a lot to take stock of in these kinds of calculations. The mass of a galaxy includes all its stars, planets, and moons, plus gases, dust, and other cosmic material. And that's just the visible matter \u2013 let's not forget dark matter, something we still know very little about, but which scientists think exerts a gravitational force on all the non- dark matter around it.To make matters worse, getting a handle on the visible objects we can actually see is complicated by the fact that we're located amidst all the matter we're trying to measure.\"The fact that we sit inside the galaxy does introduce some difficulties,\" Eadie told Tim Radford at The Guardian. \"We have a heliocentric perspective: we see everything from the perspective of our Sun's position (and movement) through the galaxy. It's important that we take the movement and position of the Sun into account when we measure the motions and positions of other objects in the Milky Way.\"Together with fellow researcher and supervisor William Harris, Eadie devised a new way for calculating the movement and velocity of globular clusters \u2013 spherical groups of stars that act like satellites, orbiting the galactic core.\nThe new technique, which helps fill in the gaps on what we don't know about some globular cluster velocities, provides what the researchers think is the most accurate estimation yet of the total galactic mass. Prior to the 700 billion Suns calculation, estimates varied between the mass of 100 billion Suns to 1 trillion.\"We can also compare the total mass estimate to the amount of visible matter that we see in the Milky Way and then get a prediction for the amount of dark matter,\" Eadie told The Guardian. \"With our estimate, it seems that dark matter makes up about 88 percent of the Milky Way's mass.\"The findings were presented at the annual meeting of the Canadian Astronomical Society this week and have been submitted to The Astrophysical Journal.The research hasn't been accepted for publication yet, so we'll have to wait for it to be peer-reviewed before we can start adding it to textbooks and the like, but it's already drawing praise from some within the astrophysics community.\"Figuring out how fast, and in what direction, globular clusters are moving is pretty hard. Combining all of these data together in a consistent model for the Milky Way is a real challenge,\" Alan McConnachie from Canada's Herzberg Institute for Astrophysics, who wasn't involved with the study, told National Geographic. \"This work is a big step toward being able to claim with confidence that we know how massive our home actually is."
        ]
    },
    "4827": {
        "gold_standard": [
            "An international team of astronomers working with the Gran Telescopio Canarias in Spain say they have witnessed the same superluminous supernova explode twice.The supernova went from bright to dim two times \u2013 instead of just once, which was what the researchers expected.\nThe team says this double-whammy explosion is likely the result of a magnetar \u2013 a rapidly rotating neutron star that forms after a gigantic stars collapses.Their findings shed new light on these superluminous supernovae, or SLSNs, pushing astronomers closer to a complete model of how they operate.\"From our data, we have tried to determine if this is a characteristic unique to this object, or whether it is a common feature of all superluminous supernovae, but has not been observed before, which is perfectly possible given their unpredictable nature,\" team leader Mathew Smith, from the University of Southampton in the UK, said in a statement.SLSN are much bigger than the other types of supernovae that researchers typically observe, which are categorised by how much light they give off.\nFor example, one of the most commonly seen types is called Ia, which form within binary systems and usually appear very bright for a few weeks before burning out completely. SLSN, on the other hand, are even brighter and can stay bright for up to six months.This isn't the first time researchers have been shocked by SLSNs, though.\u00a0Back in January, a team of astronomers working with the Las Campanas Observatory in Chile witnessed one of the biggest SLSNs ever recorded, which they said was over 200 times more powerful than any on record.Despite the amazing show they put on in the night sky, researchers have only witnessed about 12 of them, meaning there isn't a lot of data about how they work.The new study is the first to observe a SLSN from the moment it exploded to the moment it died out, allowing researchers to witness every detail.\n\"Superluminous supernovae are up to a hundred times more energetic than type 1a supernovae because they can remain bright for up to six months before fading, rather than just a few weeks,\" Smith said.\"What we have managed to observe, which is completely new, is that before the major explosion, there is a shorter, less luminous outburst, which we can pick out because it is followed by a dip in the light curve, and which lasts just a few days.\"The celestial object the team studied is known to astronomers as DES14X3taz, which lies 6,400 light-years away and was originally discovered by astronomers working with the Dark Energy Survey back in December 2014.After that team pegged the object as a possible SLSN, the current team used the GTC to monitor its activity on 26 January 2015 and again on 6 February 2015, witnessing a strange dip in brightness that makes it appear that the supernova happened twice, an event that researchers previously thought couldn't occur.\n\"From our data, we have tried to determine if this is a characteristic unique to this object, or whether it is a common feature of all superluminous supernovae, but has not been observed before, which is perfectly possible given their unpredictable nature,\" Smith said.To study the weird phenomenon, the team analyses the data they collected with computer models to see if any lined up with what they saw. In the end, they concluded that the double rise in brightness was likely caused by the formation of a magnetar, an awesomely named neutron star that rotates very quickly, becoming bright as it grows in size. As Smith explains:\n\"We think that a very massive star, some 200 times the mass of the Sun, collapses to form a magnetar. In the process, the first explosion occurs, which expels into space a quantity of matter equivalent to the mass of our sun, and this gives rise to the first peak of the graph.\nThe second peak occurs when the star collapses to form the magnetar, which is a very dense object rotating rapidly on its axis, and which heats up the matter expelled from the first explosion. This heating is what generates the second peak in the luminosity.\"\nThe team's findings shed new light on how SLSNs form and die out, providing possible data for future studies that will \u2013 hopefully \u2013 lead to a complete model of the strange supernovae.The new findings were recently published in the journal The Astrophysical Journal Letters"
        ]
    },
    "4845": {
        "gold_standard": [
            "The frozen plains of northern Siberia's tundra have been pretty weird over the past couple of years - scientists have spotted giant holes appearing seemingly out of nowhere, and a giant chasm opened up that locals call the \"gateway to the underworld\".\nBut now local media has reported that the land has literally started bubbling beneath people's feet on Siberia's remote Belyy Island.A video just released by the\u00a0Siberian Times\u00a0shows a researcher stepping on what looks to be a normal patch of grass - until it starts bizarrely wobbling like jelly >According to the Siberian Times, 15 of the patches have been discovered on the island so far, averaging around 1 metre in diameter.Environmental researchers Alexander Sokolov and Dorothee Ehrich first spotted the bubbles last year.\u00a0They've been working on the island in the Kara Sea for years, as it's a popular place to monitor climate change thanks to its large polar bear population But they stumbled across the blister-like bubbles purely by accident, and were surprised to find them there again this year.On their latest expedition, they've stripped the grass and dirt from one of these bubbles and recorded the escaping air, showing that it contains around 200 times more methane than normal air, and 20 times more carbon dioxide.\u00a0So what's going on here? More research needs to be done, but one hypothesis is that Europe's recent heatwave caused the tundra's permafrost to thaw, releasing methane gas just below the surface.\u00a0\"It is likely that that 10 days of extraordinary heat could have started some mechanisms, [and the] higher level of permafrost could have thawed and released a huge amount of gases,\" Sokolov told the Siberian Times.\u00a0\"Geologists suppose that there might be some gas leaking from the underground but it's unlikely. There is solid permafrost under the bubbles.\"\nAlthough we have no research to back that hypothesis up just yet, it's not too out there - leaky methane released by melting permafrost has already been linked to strange sinkholes and craters appearing across Siberia, like this one discovered in 2014:Vasiliy BogoyavlenskyWhat's more worrying is that there's\u00a0concern that all this newly released methane will actually exacerbate global warming further, with one study estimating that by 2100, up to 205 billion tonnes of carbon emissions will be released by permafrost if climate change continues to intensify, as Sarah Emerson reports for Motherboard. \u00a0This bubbling on Belyy Island could be a sign of this happening, and seeing as the planet has just come out of its 14th hottest month on record in a row, that's not unlikely"
        ]
    },
    "4873": {
        "gold_standard": [
            "A leading medical researcher has looked over the research and concluded that drinking alcohol \u2013 even in small amounts \u2013 doesn't just cause liver cancer, but can also lead to six other types of cancer.\nAccording to Jennie Connor, from the University of Otago in New Zealand, the evidence suggests that booze causes cancer of the mouth and throat, larynx, oesophagus, liver, colon, bowel, and breast.The research still isn't clear about how or why alcohol causes the mutations needed for cancer to form, but Connor says the findings indicate more than a casual association.\"There is strong evidence that alcohol causes cancer at seven sites in the body and probably others,\" said Connor.\"Even without complete knowledge of biological mechanisms, the epidemiological evidence can support the judgment that alcohol causes cancer of the oropharynx, larynx, oesophagus, liver, colon, rectum and breast.\"To come to this conclusion, Connor analysed many of the major alcohol-based cancer studies from the last decade to pull all of the data together and examine the links between them.\nIn the end, she concluded that alcohol has a dose-response relationship to cancer formation, meaning that the more a person drinks, the more likely they will be to develop certain cancers.\"The highest risks are associated with the heaviest drinking, but a considerable burden is experienced by drinkers with low to moderate consumption, due to the distribution of drinking in the population,\" Connor told\u00a0Denis Campbell from The Guardian.The strongest of these links was between drinking and mouth cancer. According to Connor, drinking 50 grams of alcohol per day can increase a person's risks of mouth cancer up to seven times that of a non-drinker.To put that into perspective because 'grams of alcohol' isn't really the best unit to understand, the National Institute on Alcohol Abuse and Alcoholism says that an average drink \u2013 something like a run-of-the-mill beer or a normal wine \u2013 has roughly 14 grams of alcohol in them.\nWhich means to get to that risk factor, a person would have to drink four drinks per day, though Connor says that even drinking less still raises the risk.According to health officials in the UK, no level of regular alcohol consumption is safe.In fact, back in January \u2013 long before the current study was published, the UK changed their drinking recommendations for men from 21 units (grams) per week to 14 units, making them the same level as their previous recommendation for women.They also publicly stated that women who drink five units per day are 40 percent more likely to develop breast cancer than non-drinkers, reports The Telegraph.To be clear, this research isn't in itself new, and it's only the conclusion of one scientists. But other researchers are also in agreeance with Connor, too.\nFor example, Susannah Brown, the science program manager for the World Cancer Fund, told New Scientist:\n\"We see the risk increasing as the amount of alcohol consumed increases, and we agree that there is solid evidence to conclude that alcohol consumption directly causes cancer.\"\n\"For cancer prevention, we have long recommended that people should not drink alcohol at all, but we understand that this can be easier said than done.\"\nDespite these results, no one truly understands why the link between cancer and alcohol exists.One of the popular hypotheses is that alcohol might damage DNA, leading to mutations that cause cancer cells to form, but until further research is done, no one really knows.While these new findings will certainly put a downer on our next happy hour foray, it's important to note that without knowing the true cause as to why alcohol causes cancer \u2013 and seeing it happen firsthand \u2013 it's really hard to come up with proper recommendations.\nFor example, coffee was long thought to be carcinogenic, but a recent review by researchers at the World Health Organisation (WHO) found that the real cause of cancer was extremely hot beverages that burn a drinker's throat, leading to mutations in cell growth.Though coffee and alcohol are completely different beverages on many levels, the June study shows how new knowledge can really sway findings.Until that happens we have to accept that one of the oldest beverages in existence \u2013 one that might have even sparked the agricultural revolution \u2013 might be negatively impacting our health in very serious ways.The commentary was recently published in the journal Addiction.Update 26 July 2016:\u00a0In an earlier version of the story we incorrectly stated that Connor's article was a meta-analysis, which is incorrect - it's just personal commentary. This has been updated"
        ]
    },
    "4913": {
        "gold_standard": [
            "When it comes to texting, the period, full stop, point \u2013 whatever you call it \u2013 has been getting a lot of attention.People have begun noticing slight changes to the way our smallest punctuation mark is deployed, from declarations that it's going out of style to claims that it's becoming angry.\nWhat they're actually noticing is written language becoming more flexible, with texting possessing its own set of stylistic norms (sometimes informally called \"textspeak\" or \"textese\").The period is merely one example of this shift, a change that has opened up new possibilities for communicating with written language. Just as we have different styles of speaking in different situations, so do we have context-dependent styles of writing.Reading between the periodsThough periods can still signal the end of a sentence in a text message, many users will omit them (especially if the message is only one sentence long). This tendency now subtly influences how we interpret them.Because text messaging is a conversation that involves a lot of back-and-forth, people add fillers as a way to mimic spoken language. We see this with the increased use of ellipses, which can invite the recipient to continue the conversation.\nThe period is the opposite of that \u2013 a definitive stop that signals, as linguistics professor Mark Liberman has explained, \"This is final, this is the end of the discussion.\"For some, this can appear angry or standoffish.Earlier this year, psychologist Danielle Gunraj tested how people perceived one-sentence text messages that used a period at the end of the sentence. Participants thought these text messages were more insincere than those that didn't have a period.But when the researchers then tested the same messages in handwritten notes, they found that the use of a period didn't influence how the messages were perceived.In a 2007 study by linguists Naomi Baron and Rich Ling, multi-sentence text messages often had punctuation to indicate where the sentences stopped, but only 29 percent of these texts had punctuation at the very end of the message. The reason, Baron and Ling explain, is that \"the act of sending a message coincides with sentence-final punctuation\".\nSituational switchesBut of all the things to feel when seeing a period at the end of a text message \u2013 why\u00a0insincerity?The answer could have something to do with a term used by linguist John J. Gumperz: \"situational code-switching\",\u00a0which is when we change how we talk depending on where we are, who we're talking to or how we're communicating.A common example is the way we talk in a job interview versus at a bar with friends. Typically, a speaker will use much more formal language in an interview than when hanging out with peers.If you talked to your friends the same way you talked during a job interview, it would probably give a stilted, distant feeling to the conversation.Scholars originally investigated situational code-switching in spoken language because spoken language was used in both casual and formal settings. In the past, written language was almost always tinged with a level of formality because it was associated with permanence in books and written documents.\nHowever, now that text messaging and social media have given their users an outlet for casual written language, differences between writing styles can be seen.The use of the period is one example of situational code-switching: When using one in a text message, it's perceived as overly formal. So when you end your text with a period, it can come across as insincere or awkward, just like using formal spoken language in a casual setting like a bar.A different form of sincerityAnother example of language change in casual written forms is the repetition of letters. Communication scholar Erika Darics has observed that the repetition of letters or punctuation marks adds intensity to messages (\"stopppp!!!\"). She writes that this creates \"a display of informality through using a relaxed writing style\".\nLinguist Deborah Tannen described a similar phenomenon, noting that repeated exclamation points in a message can convey a sincere tone, like in the following text message:\nJACKIE I AM SO SO SO SORRY! I thought you were behind us in the cab and then I saw you weren't!!!!! I feel soooooooo bad! Catch another cab and ill pay for it for youuuuu\nNote that this message does not contain a message-final period, since that may convey insincerity that would contradict the apology being presented. Instead, the sender uses the non-standard long vowels in \"soooooooo\"\u00a0and \"youuuuu\"\u00a0as well as five exclamation points at the end of one sentence.Compare this to a standardised version of the text message:\nJackie, I am so sorry. I thought you were behind us in the cab and then I saw you weren't. I feel so bad! Catch another cab and I'll pay for it for you.\nThis more formal version, according to the arguments made by Tannen and Darics, reads more like a work email sent to a colleague than one to a friend sincerely and fervently apologising for a transportation mishap.\nIt's a bit counterintuitive, but using formal language may undermine the sincerity of the apology; in order to convey the 'right' message, it's important to know the proper protocols. This may explain why some people's text messages seem stilted or awkward: they're used to writing with a formal style that doesn't translate to the casual medium.Will texting erode our writing skills?In the media, there's been a fair amount of debate about whether texting \u2013 or using overly casual language \u2013 can 'ruin' someone's writing ability. (Examples include the LA Times, the BBC, and The Daily Mail, to name a few.)However, past research into situational code-switching in spoken language has shown that a person's ability to code-switch can signal social competency, can affirm one's sense of identity or membership\u00a0in a community and may be an indicator of high intellectual ability in children.Studies like the recent work of psychologists\u00a0Gene Ouellette and Melissa Michaud have shown that the use of text messaging and \"textese\" has little relationship to how someone will score on spelling, reading and vocabulary tests. Meanwhile, a study out of California State University found little use of \"textisms\" in formal letter writing assignments completed by students. This observation supports work like a study by psychologist Beverly Plester and colleagues, who found that an increased use of textese was correlated with higher scores on verbal reasoning ability tests",
            "When it comes to texting, the period, full stop, point \u2013 whatever you call it \u2013 has been getting a lot of attention.People have begun noticing slight changes to the way our smallest punctuation mark is deployed, from declarations that it's going out of style to claims that it's becoming angry.\nWhat they're actually noticing is written language becoming more flexible, with texting possessing its own set of stylistic norms (sometimes informally called \"textspeak\" or \"textese\").The period is merely one example of this shift, a change that has opened up new possibilities for communicating with written language. Just as we have different styles of speaking in different situations, so do we have context-dependent styles of writing.Reading between the periodsThough periods can still signal the end of a sentence in a text message, many users will omit them (especially if the message is only one sentence long). This tendency now subtly influences how we interpret them.Because text messaging is a conversation that involves a lot of back-and-forth, people add fillers as a way to mimic spoken language. We see this with the increased use of ellipses, which can invite the recipient to continue the conversation.\nThe period is the opposite of that \u2013 a definitive stop that signals, as linguistics professor Mark Liberman has explained, \"This is final, this is the end of the discussion.\"For some, this can appear angry or standoffish.Earlier this year, psychologist Danielle Gunraj tested how people perceived one-sentence text messages that used a period at the end of the sentence. Participants thought these text messages were more insincere than those that didn't have a period.But when the researchers then tested the same messages in handwritten notes, they found that the use of a period didn't influence how the messages were perceived.In a 2007 study by linguists Naomi Baron and Rich Ling, multi-sentence text messages often had punctuation to indicate where the sentences stopped, but only 29 percent of these texts had punctuation at the very end of the message. The reason, Baron and Ling explain, is that \"the act of sending a message coincides with sentence-final punctuation\".\nSituational switchesBut of all the things to feel when seeing a period at the end of a text message \u2013 why\u00a0insincerity?The answer could have something to do with a term used by linguist John J. Gumperz: \"situational code-switching\",\u00a0which is when we change how we talk depending on where we are, who we're talking to or how we're communicating.A common example is the way we talk in a job interview versus at a bar with friends. Typically, a speaker will use much more formal language in an interview than when hanging out with peers.If you talked to your friends the same way you talked during a job interview, it would probably give a stilted, distant feeling to the conversation.Scholars originally investigated situational code-switching in spoken language because spoken language was used in both casual and formal settings. In the past, written language was almost always tinged with a level of formality because it was associated with permanence in books and written documents.\nHowever, now that text messaging and social media have given their users an outlet for casual written language, differences between writing styles can be seen.The use of the period is one example of situational code-switching: When using one in a text message, it's perceived as overly formal. So when you end your text with a period, it can come across as insincere or awkward, just like using formal spoken language in a casual setting like a bar.A different form of sincerityAnother example of language change in casual written forms is the repetition of letters. Communication scholar Erika Darics has observed that the repetition of letters or punctuation marks adds intensity to messages (\"stopppp!!!\"). She writes that this creates \"a display of informality through using a relaxed writing style\".\nLinguist Deborah Tannen described a similar phenomenon, noting that repeated exclamation points in a message can convey a sincere tone, like in the following text message:\nJACKIE I AM SO SO SO SORRY! I thought you were behind us in the cab and then I saw you weren't!!!!! I feel soooooooo bad! Catch another cab and ill pay for it for youuuuu\nNote that this message does not contain a message-final period, since that may convey insincerity that would contradict the apology being presented. Instead, the sender uses the non-standard long vowels in \"soooooooo\"\u00a0and \"youuuuu\"\u00a0as well as five exclamation points at the end of one sentence.Compare this to a standardised version of the text message:\nJackie, I am so sorry. I thought you were behind us in the cab and then I saw you weren't. I feel so bad! Catch another cab and I'll pay for it for you.\nThis more formal version, according to the arguments made by Tannen and Darics, reads more like a work email sent to a colleague than one to a friend sincerely and fervently apologising for a transportation mishap.\nIt's a bit counterintuitive, but using formal language may undermine the sincerity of the apology; in order to convey the 'right' message, it's important to know the proper protocols. This may explain why some people's text messages seem stilted or awkward: they're used to writing with a formal style that doesn't translate to the casual medium.Will texting erode our writing skills?In the media, there's been a fair amount of debate about whether texting \u2013 or using overly casual language \u2013 can 'ruin' someone's writing ability. (Examples include the LA Times, the BBC, and The Daily Mail, to name a few.)However, past research into situational code-switching in spoken language has shown that a person's ability to code-switch can signal social competency, can affirm one's sense of identity or membership\u00a0in a community and may be an indicator of high intellectual ability in childre",
            "When it comes to texting, the period, full stop, point \u2013 whatever you call it \u2013 has been getting a lot of attention.People have begun noticing slight changes to the way our smallest punctuation mark is deployed, from declarations that it's going out of style to claims that it's becoming angry.\nWhat they're actually noticing is written language becoming more flexible, with texting possessing its own set of stylistic norms (sometimes informally called \"textspeak\" or \"textese\").The period is merely one example of this shift, a change that has opened up new possibilities for communicating with written language. Just as we have different styles of speaking in different situations, so do we have context-dependent styles of writing.Reading between the periodsThough periods can still signal the end of a sentence in a text message, many users will omit them (especially if the message is only one sentence long). This tendency now subtly influences how we interpret them.Because text messaging is a conversation that involves a lot of back-and-forth, people add fillers as a way to mimic spoken language. We see this with the increased use of ellipses, which can invite the recipient to continue the conversation.\nThe period is the opposite of that \u2013 a definitive stop that signals, as linguistics professor Mark Liberman has explained, \"This is final, this is the end of the discussion.\"For some, this can appear angry or standoffish.Earlier this year, psychologist Danielle Gunraj tested how people perceived one-sentence text messages that used a period at the end of the sentence. Participants thought these text messages were more insincere than those that didn't have a period.But when the researchers then tested the same messages in handwritten notes, they found that the use of a period didn't influence how the messages were perceived.In a 2007 study by linguists Naomi Baron and Rich Ling, multi-sentence text messages often had punctuation to indicate where the sentences stopped, but only 29 percent of these texts had punctuation at the very end of the message. The reason, Baron and Ling explain, is that \"the act of sending a message coincides with sentence-final punctuation\".\nSituational switchesBut of all the things to feel when seeing a period at the end of a text message \u2013 why\u00a0insincerity?The answer could have something to do with a term used by linguist John J. Gumperz: \"situational code-switching\",\u00a0which is when we change how we talk depending on where we are, who we're talking to or how we're communicating.A common example is the way we talk in a job interview versus at a bar with friends. Typically, a speaker will use much more formal language in an interview than when hanging out with peers.If you talked to your friends the same way you talked during a job interview, it would probably give a stilted, distant feeling to the conversation.Scholars originally investigated situational code-switching in spoken language because spoken language was used in both casual and formal settings. In the past, written language was almost always tinged with a level of formality because it was associated with permanence in books and written documents.\nHowever, now that text messaging and social media have given their users an outlet for casual written language, differences between writing styles can be seen.The use of the period is one example of situational code-switching: When using one in a text message, it's perceived as overly formal. So when you end your text with a period, it can come across as insincere or awkward, just like using formal spoken language in a casual setting like a bar.A different form of sincerityAnother example of language change in casual written forms is the repetition of letters. Communication scholar Erika Darics has observed that the repetition of letters or punctuation marks adds intensity to messages (\"stopppp!!!\"). She writes that this creates \"a display of informality through using a relaxed writing style\".\nLinguist Deborah Tannen described a similar phenomenon, noting that repeated exclamation points in a message can convey a sincere tone, like in the following text message:\nJACKIE I AM SO SO SO SORRY! I thought you were behind us in the cab and then I saw you weren't!!!!! I feel soooooooo bad! Catch another cab and ill pay for it for youuuuu\nNote that this message does not contain a message-final period, since that may convey insincerity that would contradict the apology being presented. Instead, the sender uses the non-standard long vowels in \"soooooooo\"\u00a0and \"youuuuu\"\u00a0as well as five exclamation points at the end of one sentence.Compare this to a standardised version of the text message:\nJackie, I am so sorry. I thought you were behind us in the cab and then I saw you weren't. I feel so bad! Catch another cab and I'll pay for it for you.\nThis more formal version, according to the arguments made by Tannen and Darics, reads more like a work email sent to a colleague than one to a friend sincerely and fervently apologising for a transportation mishap.\nIt's a bit counterintuitive, but using formal language may undermine the sincerity of the apology; in order to convey the 'right' message, it's important to know the proper protocols. This may explain why some people's text messages seem stilted or awkward: they're used to writing with a formal style that doesn't translate to the casual medium.Will texting erode our writing skills?In the media, there's been a fair amount of debate about whether texting \u2013 or using overly casual language \u2013 can 'ruin' someone's writing ability. (Examples include the LA Times, the BBC, and The Daily Mail, to name a few.)However, past research into situational code-switching in spoken language has shown that a person's ability to code-switch can signal social competency, can affirm one's sense of identity or membership\u00a0in a community and may be an indicator of high intellectual ability in children"
        ]
    },
    "4945": {
        "gold_standard": [
            "Geophysical Research Letters Italian researchers say that a thought-to-be-extinct volcano named Colli Albani, which lies 30 kilometres (19 miles) from the centre of Rome, is actually still alive and active.\nWhile this certainly sounds scary, the volcano isn't expected to erupt for another 1,000 or so years, giving researchers and citizens a chance to prepare \u2013 though the team does state that the pending eruption has the potential to be\u00a0as devastating as that of Mount Vesuvius.According to the team \u2013 led by Fabrizio Marra from the National Institute of Geophysics and Volcanology in Rome \u2013 the volcano was believed extinct because it erupts so infrequently. Based on their analysis, the volcano's last eruption took place 36,000 years ago.Now, after a series of earthquakes in the 1990s and the formation of a steam vent, the team says Colli Albani - also known as the Alban Hills - is inflating, causing the surrounding area to rise about 2 millimetres (0.08 inches) every year.In fact, over the last 200,000 years, the team says the region has risen about 50 metres (164 feet) in total, suggesting that magma is pooling beneath the volcano, reports Stephanie Pappas for Live Science.\nThe team was able to come to this conclusion after analysing ground-based data collected during the earthquakes in the region and the formation of steam vents in conjunction with satellite data and rock samples.Now, the team says that all of Colli Albani's recent activity is likely due to a fracture that split apart beneath the volcano about 2,000 years ago. Over the years, this fracture has allowed more and more magma to rise into the volcano, making it expand, which also raises the ground above it, creates steam vents, and causes earthquakes.They also conclude that the volcano is likely on a 31,000-year eruption cycle, meaning that \u2013 since it's been 36,000 years from its last eruption \u2013 it's definitely due, and the team says the next eruption will likely happen in about 1,000 years.\"Although Rome and its suburbs are not in any immediate danger, previous research shows that in past eruptive cycles the volcano unleashed both low blasts of hot ash and lava that rolled down the volcano's slopes at tremendous speeds,\"\u00a0reports Elizabeth Deatrick from the American Geophysical Union (AGU).\nWhile it's easy to hear this news and imagine the plot of a disaster film, there's likely nothing for Romans to be that worried about. As Erik Klemetti \u2013 a Wired blogger and assistant professor of Geosciences at Denison University \u2013 sums up elegantly:\n\"Since 69,000 years ago, much of the activity has been small explosive eruptions. Those might impact people/property right around the Colli Albani, but likely won't\u00a0be a direct hazard for Rome. There is the potential for ash disruptions from such eruptions and people living in the area directly surrounding the eruption might be displaced for years (or forever). However, unless something has changed at the Colli Albani, the vigour in the activity has been in decline over the last half a million years.\"\nIn other words, an eruption of Colli Albani most likely wouldn't terribly impact those living within Rome, though those on the outskirts \u2013 and definitely those at the base of the volcano \u2013 might lose their homes or experience other types of property damage.Either way, the team's findings indicate that the Colli Albani should be monitored rather closely, especially because of its proximity to a major city.\nColli Albani isn't the only volcano making headlines recently. Back in February, researchers witnessed Big Ben \u2013 a sub-Antarctic volcano \u2013 erupting on Heard Island, one of the most remote places on Earth. You can watch the team's video of the eruption here.It will be exciting to see how much data researchers can collect while studying Colli Albani, which will hopefully lead to a better way of detecting and analysing volcanic activity in the future.The new findings were recently published in the journal Geophysical Research Letter"
        ]
    },
    "4950": {
        "gold_standard": [
            "Australian researchers have developed a new eye test that could detect glaucoma, which is a leading cause of blindness, four years earlier than current techniques.Glaucoma is a group of eye diseases which damage the optic nerve, causing vision loss. The disease is hard to catch though, as peripheral vision - which isn't usually tested by doctors - is the first to go, and there's no pain to alert the patient that something could be wrong.\nBut now researchers from the University of New South Wales (UNSW) in Australia, have created a new diagnostic test, where patients are asked to look at small dots of light at specific size and intensity. If the patients can't see them, it shows blind spots on the eye and loss of peripheral vision \u2013 a precursor to glaucoma.\"Glaucoma is one of the leading causes of irreversible blindness in the world, and in the early stages patients usually have no symptoms and are not aware they are developing permanent vision loss,\" said one of the researchers, Michael Kalloniatis.\"The cause of the disease is unknown and there is no cure, but its progression can be slowed with eye drops or surgery to lower pressure in the eye. So, early detection and early treatment is vital for prolonging sight.\"Right now, doctors rely on tests such as eye pressure and visual field testing to make sure their patients' eye sight is working okay. And although this can reveal glaucoma in its later stages, it's often too late to prevent it from doing damage.\nThe UNSW researchers have just published a study that assessed 13 patients with early glaucoma or optic nerve damage, and 42 people without eye disease, using their tests as well as currently available methods.The new test detected greater vision loss in all patients compared to current techniques.\"The current method of visual field testing, which uses just one dot size, is good but not ideal. Our test appears to be much more sensitive at detecting disease in an early stage. On average, we expect we will be able to detect glaucoma four years earlier than at present,\"\u00a0said Kalloniatis.The team is currently using the same eye test to assess 30 more patients, and hope to conduct a much larger clinical trial to determine exact effectiveness of the new test in the coming months. \u00a0\"We hope our new approach will eventually be introduced around the world, and treatment can begin earlier to slow down vision loss in glaucoma,\" he said.\nThe new diagnostic technique has already been patented in the US and European Union.The study was published in Ophthalmic and Physiological Optics earlier this year. UNSW Science is a sponsor of ScienceAlert. Find out more about their world-leading research"
        ]
    },
    "4965": {
        "gold_standard": [
            "An international team of scientists has observed matter wobbling in a gravitational vortex around a black hole for the first time.The discovery could help settle a long-standing debate about an astronomical phenomenon called quasi-periodic oscillation, as well as help scientists to understand more about how matter behaves in the intense gravitational forces near black holes \u2013 and, to that extent, test Einstein's general relativity.\nWhen matter gets sucked into a black hole, it begins to heat up, reaching millions of degrees, at which point it starts to beam X-rays into space.Back in the 1980s, scientists observed that these X-rays flicker, with the rate of their flickering changing over time. The X-rays dim and then brighten, at first taking 10 seconds to complete a single oscillation, but eventually speeding up as matter gets closer to the black hole, until 10 oscillations occur every second. This phenomenon is called quasi-periodic oscillation (QPO).\"It was immediately recognised to be something fascinating because it is coming from something very close to a black hole,\" says one of the researchers, Adam Ingram from the University of Amsterdam in the Netherlands.Astronomers later thought QPOs might be related to the gravitational effect predicted by Einstein's general relativity \u2013 basically, that a spinning object could create a kind of gravitational vortex.\n\"It is a bit like twisting a spoon in honey. Imagine that the honey is space and anything embedded in the honey will be 'dragged' around by the twisting spoon,\" explains Ingram. \"In reality, this means that anything orbiting a spinning object will have its motion affected.\"This effect is called Lense\u2013Thirring precession, and the effect would become so fast around black holes, that scientists began to think it could be linked to the flickering of QPOs.In 2009, Ingram published a paper suggesting that QPOs are driven by Lense-Thirring precession. The hypothesis was that the flat disc of matter surrounding a black hole \u2013 called an accretion disc \u2013 turns into hot plasma (called the inner flow) as it is sucked into the black hole.To test if this was actually occurring, Ingram and fellow researchers used two orbital telescopes \u2013 the European Space Agency's XMM-Newton and NASA's NuSTAR \u2013 to observe the QPO around a black hole called H 1743\u2013322"
        ]
    },
    "4967": {
        "gold_standard": [
            "Jet lag is terrible no matter where you're going. But regular travellers will know that your body clock seems to take way longer to recover when you're flying east, rather than heading west.\nNow physicists have finally been able to explain why this could be happening, using a mathematical model to show that our brain cells respond differently depending on which direction we're travelling.Jet lag occurs when the brain cells that regulate our circadian rhythm, called neuronal oscillator cells, can't adjust to our new time zone fast enough, messing up our metabolism, sleep pattern, and pretty much everything else on the first few days of our vacation.Up until now, the general advice has been to give yourself one day of recovery for every time zone crossed. But the new research, led by physicists from the University of Maryland, suggests that might not be enough if you're flying east.That's because our neuronal oscillator cells - the pacemakers for the rest of our brain - don't follow a perfect 24-hour schedule.\nStudies have shown that without any external cues, their activity follows a slightly longer cycle - around 24.5 hours. And that means it's easier for someone to extend the length of their day - for example, by flying westward across time zones - than shorten their day by flying east.To figure this out, the physicists took this 24.5-hour rhythm and applied it to a mathematical model that calculates how long it takes someone to recover from jet lag - and they showed that it's not just the amount of time zones crossed that impacts recovery time, but also the direction someone's travelling.\u00a0Their model showed that someone who crosses three time zones heading westward can adjust fully in a little less than four days. And for six time zones, recovery takes around six days - much as you'd expect based on the \"one day per time zone crossed\" principle.But when people are travelling east, the model predicts that it'll take more than four days to recover from a flight that crosses three time zones, and a whopping eight days to recover from crossing six time zones (which is why it feels so hellish to fly from New York to Paris)",
            "Jet lag is terrible no matter where you're going. But regular travellers will know that your body clock seems to take way longer to recover when you're flying east, rather than heading west.\nNow physicists have finally been able to explain why this could be happening, using a mathematical model to show that our brain cells respond differently depending on which direction we're travelling.Jet lag occurs when the brain cells that regulate our circadian rhythm, called neuronal oscillator cells, can't adjust to our new time zone fast enough, messing up our metabolism, sleep pattern, and pretty much everything else on the first few days of our vacation.Up until now, the general advice has been to give yourself one day of recovery for every time zone crossed. But the new research, led by physicists from the University of Maryland, suggests that might not be enough if you're flying east.That's because our neuronal oscillator cells - the pacemakers for the rest of our brain - don't follow a perfect 24-hour schedule.\nStudies have shown that without any external cues, their activity follows a slightly longer cycle - around 24.5 hours. And that means it's easier for someone to extend the length of their day - for example, by flying westward across time zones - than shorten their day by flying east.To figure this out, the physicists took this 24.5-hour rhythm and applied it to a mathematical model that calculates how long it takes someone to recover from jet lag - and they showed that it's not just the amount of time zones crossed that impacts recovery time, but also the direction someone's travelling.\u00a0Their model showed that someone who crosses three time zones heading westward can adjust fully in a little less than four days. And for six time zones, recovery takes around six days - much as you'd expect based on the \"one day per time zone crossed\" principle.But when people are travelling east, the model predicts that it'll take more than four days to recover from a flight that crosses three time zones, and a whopping eight days to recover from crossing six time zones (which is why it feels so hellish to fly from New York to Paris).\nThe model also explains why some people can cope with jet lag so much better than others - they likely have slight variations in their natural brain cell cycle.\"Some people may have a natural circadian rhythm with a period of 24.5 hours, while others may have longer or shorter natural rhythms,\" said lead researcher Michelle Girvan, from the University of Maryland. \"Our model suggests that the difference between a person's natural period and 24 hours controls how they experience jet lag.\"The research has been published in the journal Chaos, but it's important to note that none of this has been tested experimentally as yet - the researchers made their predictions by factoring in everything they know about how the human brain adjusts to new time zones, and let maths do the rest.Further research is now needed to back up these predictions, but the researchers' ultimate goal is to help people better manage their expectations when they travel, and will \"serve as a guide for developing more in-depth qualitative approaches, as well as strategies to combat circadian rhythm disruptions due to rapid cross-time-zone travel, shift work, or blindness,\" said Girvan"
        ]
    },
    "5019": {
        "gold_standard": [
            ">Spending time outdoors is awesome for your mental and physical health - unless, that is, you happen to come in contact with some poison ivy while you're out there, and end up with an itchy, painful rash all over your body.\nBut as retired biomedical scientist Jim Brauker explains in the video above, if you understand the science of how the plant works, it's actually possible to get poison ivy all over you, and not get a rash.And best of all, the technique doesn't require any special products or treatments, just a good old-fashioned wash cloth and elbow grease.For those of you lucky enough to not have experienced a poison ivy rash before, it happens after coming in contact with the plant's toxic sap, either through its leaves or vine.Unfortunately, poison ivy is found in forests and woods pretty much all over North America, as well as in parts of Asia, and its relatives, the poison oak and sumac, also have the same effect, so it's not the easiest thing to avoid.The resulting contact rash is lumpy and itchy, and although it doesn't usually require medical attention, it can be incredibly uncomfortable and last up to three weeks. See below if you require photographic evidence:Adam Rosenberg/FlickrSo how do you avoid this fate if you want to spend time in the woods this summer?\nAccording to Brauker, who's spent 25 years studying skin inflammation, it's not actually coming in contact with poison ivy that gets you in trouble, it's an oily molecule known as urushiol\u00a0-\u00a0which is found in the sap of poision ivy, poison oak, and sumac - that does the damage.And the good news is, it takes a while to soak in. Braumer has found that\u00a0if you wash urushiol off within 3 to 4 hours of being exposed to it in most parts of the body, you can avoid a serious poision ivy rash altogether.But (of course there's a but) getting urushiol off you isn't as easy as it sounds, which is where the trick comes in.The molecule is pretty similar to engine grease - it's oily, sticky, and hard to get off, even after you've washed thoroughly with a range of special poison ivy products, as Brauker demonstrates in the video above"
        ]
    },
    "5032": {
        "gold_standard": [
            "While it has its fair share of critics, the Turing test has become one of the most well-known ways of measuring artificial intelligence. The test, originally developed in 1950, states that if a human being can't tell the difference between an AI and a real human over a chat program, the AI has passed.\nBut now scientists have discovered a loophole of sorts in the Turing test, and it involves one of the oldest tricks in the book: simply staying silent.It turns out that silence on the part of the AI can help skew the perception of the person on the other end of the conversation, who is left wondering whether he or she is dealing with a shy (or offended) human being or a broken AI-powered bot.Scientists from Coventry University in the UK looked at six transcripts from earlier Turing tests and found that when the machines stopped speaking, it put doubt in the minds of the judges. Often the silence wasn't any intentional coyness on the part of the AI, and was simply due to technical problems.\"The technical issues entailed the failure of the computer programs to relay messages or responses to the judge's questions,\" one of the researchers, Huma Shah, told Dyllan Furness at\u00a0Digital Trends. \"The judges were unaware of the situation and hence in some cases they classified their hidden interlocutor as 'unsure'.\"\nIf the judge is unsure, the AI has succeeded.As Shah and fellow researcher Kevin Warwick note in their study, there's still plenty of controversy over the 'rules' of the Turing test, and plenty of ambiguity about what exactly its creator Alan Turing intended the challenge to actually measure.The interpretation used in this case is the basic \"imitation game\" described by Turing: the AI has to be able to pretend to be human to a reasonably convincing level.Leaving aside the debate over the conditions of the Turing test itself, the study considers the various repercussions of a bot effectively pleading\u00a0the Fifth Amendment (staying quiet).If a machine can fool humans by being tight-lipped, argue the researchers, then passing the test doesn't prove the machine can think \u2013 just that it can clam up (and by that reckoning, a stone could pass just as easily). If the human judge is unsure, that means the AI has won: and how can any certain judgement be made if the machine says nothing?\nThe team suggests that clever bots could keep quiet to avoid giving themselves away with a stupid answer, and that future Turing tests could be tweaked so silence automatically disqualifies a contestant, whether they're artificial or human.According to Shah, Turing designed his test to encourage the development of \"elaborate machines to respond in a satisfactory and sustained manner\", not just bots that are trying to fool their judges by staying schtum. In other words, it's not really playing fair or in the intended nature of the test, even if it's effective.Perhaps we need a new Turing test for the 21st century \u2013 after all, computing has come a long way since 1950. Or maybe the test is no longer as relevant as it once was, given the staggering advances AI has made in the past several decades.\u00a0Microsoft CEO Satya Nadella recently predicted\u00a0that\u00a0the future of AI is \"not going to be about human vs. machine\", but rather about how intelligent systems can help augment and enhance what we already do best. It's something these researchers tend to agree with.\"The role of AI is to augment human performance with intelligent agents,\" Shah told Digital Trends. \"For example, a human educator using an AI to score student assignments and exam questions leaving the teacher time to innovate learning, inspiring students, encouraging more into STEM, including females, for a better life or world of cooperation.\"The findings have been published in the Journal of Experimental & Theoretical Artificial Intelligence"
        ]
    },
    "5086": {
        "gold_standard": [
            "It wouldn't fly now, but back in 1975, it was a whole different story, because a cat named F.D.C. Willard was the co-author of a peer-reviewed physics paper called \"Two-, Three-, and Four-Atom Exchange Effects in bcc 3He.\"Published in the journal Physical Review Letters, the paper describes the results of an experiment exploring the behaviour of the helium-3 isotope at various temperatures.Conducted by Jack H. Hetherington, a professor of physics at Michigan State University, the experiment yielded important insights that are still being referenced today, but when Hetherington tried to submit it for publication, there was a problem.\"I had submitted the paper \u2026 and was rather proud of the work, considering it suitable for rapid publication in Physical Review Letters,\" Hetherington told author R. L. Weber for his 1985 book, More Random Walks in Science.\n\"Before I submitted it, I asked a colleague to read it over and he said, 'It's a fine paper, but they'll send it right back.'\"Why? Hetherington had opted to use the royal \"we\" in his paper rather than \"I\", and the journal had a specific rule that prohibited the use of \"we\" unless the paper had multiple authors.\u00a0\"Changing the paper to the impersonal seemed too difficult now, and it was all written and typed; therefore, after an evening's thought, I simply asked the secretary to change the title page to include the name of the family cat, a Siamese called Chester,\" Hetherington explains.Chester, the son of a cat named Willard, who Hetherington describes as \"one of the few unfixed male Siamese cats in Aspen, Colorado\", was given the pen name of F.D.C. Willard, which stands for Felis Domesticus Chester Willard.\nAs you can see here, the paper was accepted, and F.D.C. Willard from the Michigan State University physics department was an officially published cat.As nice as it must have been for Chester to suddenly be an expert on particle physics, surely it would have made more sense for Hetherington to just find an actual colleague in the physics department and throw their name on the paper instead?Well, there's actually a whole lot more method to this madness than you might think, because Hetherington wasn't particularly interested in sharing the spotlight with someone else when he did all the work.\u00a0He told Weber that he was conscious of the fact that researchers' pay and reputation is partly based on their research output, and didn't want that diluted. He also suspected that if everyone found out the co-author was a cat, well, that's just free publicity.\n\"In any case, I went ahead and did it, and have generally not been sorry,\" he said. \"Most people are amused by the concept, only editors, for some reason, seem to find little humour in the story.\"Ten lucky friends of Hetherington's got signed copies of the paper, and F.D.C. Willard was happy to lend a paw print, but the identity of the mysterious co-author was only made known to the public after someone asked to speak to this Willard character at Michigan State.\"[A] visitor asked to talk to me, and since I was unavailable, asked to talk with Willard. Everyone laughed and soon the cat was out of the bag,\"\u00a0Hetherington told the Today I Found Out website.More Random Walks in Science, R. L. WeberF.D.C. Willard went on to publish another article on helium-3\u00a0in the\u00a0French science magazine, La Recherche -\u00a0and this time as the sole author - before fading into obscurity once more.\nBut far be it from physicists to forget their feline compatriot. On 1 April 2014, the American Physical Society (APS) announced that all cat-authored papers would be available as open-access documents:\n\"APS is proud to announce a new open access initiative designed to further extend the benefits of open access to a broader set of authors. The new policy, effective today, makes all papers authored by cats freely available. \u2026\u00a0Not since Schr\u00f6dinger has there been an opportunity like this for cats in physics.\"\nIf both\u00a0NASA and cats are on the open-access train, you know it's good. We salute you, Felis Domesticus Chester Willar"
        ]
    },
    "5134": {
        "gold_standard": [
            "Imagine that years of drought have forced you to graze your cattle on sparse grass in an open desert landscape, far from permanent settlements. The nearest small shop is 40 kilometres (25 miles away), a journey normally made by donkey.\nNow imagine your one donkey is being mauled to death by a pride of lions, only metres from the flimsy tent that is your shelter.This was the scene I encountered in November 2015, while travelling through Purros Conservancy in north-west Namibia's Kunene region with two elderly Khoe-speaking people \u2013 Michael Ganaseb and Christophine Tauros \u2013 in the course of oral history research in the area.Both had grown up in this desert landscape. Our small party stopped at a remote Herero cattle-post close to Tauros' grandfather's grave. Khoe and Herero-speaking peoples both have long histories of dwelling in north-west Namibia, with sometimes different perspectives on living with indigenous fauna in the area.At this time, drought was causing Herero-speaking herders to disperse with their livestock to wherever they could find a few remnant tufts of perennial grasses.In a drought, Herero herders move their cattle to remote areas like this in Purros Conservancy. Sian Sullivan, Author providedSheltered only by a made-in-China tent, the lone herdsman we met here was angry. The previous night a group of lions had killed his donkey. He had poisoned the donkey's flesh in retaliation for the attack.\nWe related this incident to the dedicated founder of the\u00a0Desert Lion Conservation Project, Philip Stander, who tracks the movement of Namibia's special desert-adapted lions.He suggested that a group of five brothers named the 'Musketeers' \u2013 stars of the 2015 National Geographic film\u00a0Vanishing Kings: Lions of the Namib\u00a0\u2013 may have been responsible.This donkey met the Musketeers. Sian Sullivan, Author providedA few days later I encountered the Musketeers, close to Namibia's spectacular Skeleton Coast, while recording memories of places previously inhabited by Ganaseb's brother Noag, and their cousin Franz ||H\u00f6eb (the two lines signify a 'click consonant' in Khoe-languages).\nThey claimed that in the past people did not have problems with \"wild animals\" \u2013 they would simply ask them nicely to move, so that the people could be on their way.Some elderly Khoe-speaking people continue to practice these rituals, asking both known ancestors and anonymous spirits of the dead to protect them from lions. Whimsical perhaps, but these narratives illustrate variety in local experiences of lions.Less than a year later, on 9 August 2016, three of the Musketeers were killed in Purros Conservancy by poison set by cattle farmers. These lions had been troubling people for some time. The radio collars that tracked their movements were burnt. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Tragically, only days earlier Namibia's Ministry of Environment and Tourism had approved the transport of these three lions and their remaining brother to a national park where they would be kept apart from farmers and their livestock.\nBut as the three lions returned from unreachable mountainous areas they encountered a cattle-post, where they slaughtered a donkey and whose poisoned flesh later killed them. The ministry is seeking criminal charges.Although one of the worst cases, this is only the latest in a series of recent conflicts between humans and lions in the area. In June 2016, a lioness was shot dead after a bull was killed by a pride of lions near the settlement of Otjindakui.Earlier that month, the first Musketeer to be killed died from a bullet wound near a temporary cattle-post in the region.Conflict is inevitableThese incidents reflect recent expansion in lion distribution in Namibia's Kunene region. A result is economic damage, borne disproportionately by unlucky farmers.Compensation, when received, may not cover the cost of a lost cow or bull. As such, increasing lion numbers cause tour guides to celebrate while locals are dismayed.\nClashes between humans and lions in a region celebrated by tourists and conservationists have encouraged significant investment in addressing human-wildlife conflict.Community game guards were established in the early 1980s, beginning a widely praised model of \"community-based natural resources management\"\u00a0financed by donors including the WWF and the US and UK international aid departments.The kraal and tent of a lone Herero herder whose donkey was killed by lions. Sian Sullivan, Author providedSince 1996 indigenous Namibians have been able to legally derive incomes from wildlife in recognised territories managed as \"conservancies\".The vision is that this income will increase the value of indigenous fauna and flora as economically-productive resources, countering the costs to other livelihood activities of sharing land with wildlife whilst offering routes towards rural development.\nThe success of these conservancies, combined until recently with favourable wetter climatic conditions since the mid-1990s, has led to increasing lion populations.Efforts to smooth over resulting tensions with local people include a compensation scheme for herders paid for by safari operators; a community 'lion task force' and 'lion rangers'\u00a0who monitor lion movements and advise herders when to move away; lion proof kraals (cattle pens); and bright lights, ultra-sound, and fireworks to discourage lions from approaching settlements.These initiatives do much to mitigate the conflict. But current drought is causing herders to overlap with lion, the former seeking dispersed grazing, the latter dispersed prey animals.Expanding tourism has encouraged lions to become more confident around humans. And prey animals like zebra and antelope already affected by drought may be reduced further by shoot-to-sell policies, whereby conservancies sell rights to outside contractors to shoot animals to supply butcheries elsewhere.Different strokes for different folks?Human-lion conflicts can also act as a flash-point for other frustrations. Livestock herders in communal areas are experiencing punitive measures for trying to protect their animals in a context of historical land appropriation that squeezed indigenous Namibians into less productive landscapes.Namibia's commercial (and still largely white-owned) farming areas sometimes experience lion attacks but benefited historically from significant clearance of major predators. One celebrated former warden of Etosha National Park killed 75 lions to help farmers protect their cattle, before being employed in conservation in 1958.Today, wealthy visitors from afar hunt 'game' animals as trophies, including the occasional lion. Many conservancies are financed significantly by trophy-hunting and tourism, and some local people succeed as hunting and tourism professionals.But these benefits aren't evenly distributed, and can cause distrust over new inequalities linked with conservancy management and private sector investments.All these factors contribute to the intractable nature of the human-lion conflict. This problem is not about to disappear. At the same time, local people with different histories have different ideas about how to live with lions.Learning more about positive stories of how people lived with predators in the past may yet help people and lions to live alongside each other into the future.Sian Sullivan, Professor of Environment and Culture, Bath Spa UniversityThis article was originally published by\u00a0The Conversation. Read the original article",
            "Imagine that years of drought have forced you to graze your cattle on sparse grass in an open desert landscape, far from permanent settlements. The nearest small shop is 40 kilometres (25 miles away), a journey normally made by donkey.\nNow imagine your one donkey is being mauled to death by a pride of lions, only metres from the flimsy tent that is your shelter.This was the scene I encountered in November 2015, while travelling through Purros Conservancy in north-west Namibia's Kunene region with two elderly Khoe-speaking people \u2013 Michael Ganaseb and Christophine Tauros \u2013 in the course of oral history research in the area.Both had grown up in this desert landscape. Our small party stopped at a remote Herero cattle-post close to Tauros' grandfather's grave. Khoe and Herero-speaking peoples both have long histories of dwelling in north-west Namibia, with sometimes different perspectives on living with indigenous fauna in the area.At this time, drought was causing Herero-speaking herders to disperse with their livestock to wherever they could find a few remnant tufts of perennial grasses.In a drought, Herero herders move their cattle to remote areas like this in Purros Conservancy. Sian Sullivan, Author providedSheltered only by a made-in-China tent, the lone herdsman we met here was angry. The previous night a group of lions had killed his donkey. He had poisoned the donkey's flesh in retaliation for the attack.\nWe related this incident to the dedicated founder of the\u00a0Desert Lion Conservation Project, Philip Stander, who tracks the movement of Namibia's special desert-adapted lions.He suggested that a group of five brothers named the 'Musketeers' \u2013 stars of the 2015 National Geographic film\u00a0Vanishing Kings: Lions of the Namib\u00a0\u2013 may have been responsible.This donkey met the Musketeers. Sian Sullivan, Author providedA few days later I encountered the Musketeers, close to Namibia's spectacular Skeleton Coast, while recording memories of places previously inhabited by Ganaseb's brother Noag, and their cousin Franz ||H\u00f6eb (the two lines signify a 'click consonant' in Khoe-languages).\nThey claimed that in the past people did not have problems with \"wild animals\" \u2013 they would simply ask them nicely to move, so that the people could be on their way.Some elderly Khoe-speaking people continue to practice these rituals, asking both known ancestors and anonymous spirits of the dead to protect them from lions. Whimsical perhaps, but these narratives illustrate variety in local experiences of lions.Less than a year later, on 9 August 2016, three of the Musketeers were killed in Purros Conservancy by poison set by cattle farmers. These lions had been troubling people for some time. The radio collars that tracked their movements were burnt. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Tragically, only days earlier Namibia's Ministry of Environment and Tourism had approved the transport of these three lions and their remaining brother to a national park where they would be kept apart from farmers and their livestock.\nBut as the three lions returned from unreachable mountainous areas they encountered a cattle-post, where they slaughtered a donkey and whose poisoned flesh later killed them. The ministry is seeking criminal charges.Although one of the worst cases, this is only the latest in a series of recent conflicts between humans and lions in the area. In June 2016, a lioness was shot dead after a bull was killed by a pride of lions near the settlement of Otjindakui.Earlier that month, the first Musketeer to be killed died from a bullet wound near a temporary cattle-post in the region.Conflict is inevitableThese incidents reflect recent expansion in lion distribution in Namibia's Kunene region. A result is economic damage, borne disproportionately by unlucky farmers.Compensation, when received, may not cover the cost of a lost cow or bull. As such, increasing lion numbers cause tour guides to celebrate while locals are dismayed.\nClashes between humans and lions in a region celebrated by tourists and conservationists have encouraged significant investment in addressing human-wildlife conflict.Community game guards were established in the early 1980s, beginning a widely praised model of \"community-based natural resources management\"\u00a0financed by donors including the WWF and the US and UK international aid departments.The kraal and tent of a lone Herero herder whose donkey was killed by lions. Sian Sullivan, Author providedSince 1996 indigenous Namibians have been able to legally derive incomes from wildlife in recognised territories managed as \"conservancies\".The vision is that this income will increase the value of indigenous fauna and flora as economically-productive resources, countering the costs to other livelihood activities of sharing land with wildlife whilst offering routes towards rural development.\nThe success of these conservancies, combined until recently with favourable wetter climatic conditions since the mid-1990s, has led to increasing lion populations.Efforts to smooth over resulting tensions with local people include a compensation scheme for herders paid for by safari operators; a community 'lion task force' and 'lion rangers'\u00a0who monitor lion movements and advise herders when to move away; lion proof kraals (cattle pens); and bright lights, ultra-sound, and fireworks to discourage lions from approaching settlements.These initiatives do much to mitigate the conflict. But current drought is causing herders to overlap with lion, the former seeking dispersed grazing, the latter dispersed prey animals.Expanding tourism has encouraged lions to become more confident around humans. And prey animals like zebra and antelope already affected by drought may be reduced further by shoot-to-sell policies, whereby conservancies sell rights to outside contractors to shoot animals to supply butcheries elsewhere.Different strokes for different folks?Human-lion conflicts can also act as a flash-point for other frustrations. Livestock herders in communal areas are experiencing punitive measures for trying to protect their animals in a context of historical land appropriation that squeezed indigenous Namibians into less productive landscapes.Namibia's commercial (and still largely white-owned) farming areas sometimes experience lion attacks but benefited historically from significant clearance of major predators. One celebrated former warden of Etosha National Park killed 75 lions to help farmers protect their cattle, before being employed in conservation in 1958.Today, wealthy visitors from afar hunt 'game' animals as trophies, including the occasional lion. Many conservancies are financed significantly by trophy-hunting and tourism, and some local people succeed as hunting and tourism professionals.But these benefits aren't evenly distributed, and can cause distrust over new inequalities linked with conservancy management and private sector investments.All these factors contribute to the intractable nature of the human-lion conflict. This problem is not about to disappear. At the same time, local people with different histories have different ideas about how to live with lions.Learning more about positive stories of how people lived with predators in the past may yet help people and lions to live alongside each other into the future.Sian Sullivan, Professor of Environment and Culture, Bath Spa UniversityThis article was originally published by\u00a0The Conversation. Read the original article"
        ]
    },
    "5168": {
        "gold_standard": [
            "Scientists have confirmed that thousands of pristine blue lakes have appeared on the ice sheets of East Antarctica, and it's got them very worried.The problem? They've seen this kind of thing happen before. Greenland's ice sheet has been disintegrating rapidly, losing a whopping 1 trillion tonnes of ice between 2011 and 2014, and research suggests it's because of these lakes.\nA team of UK researchers has analysed hundreds of satellite images and meteorological data taken of the Langhovde Glacier in East Antarctica, and found for the first time that between 2000 and 2013, nearly 8,000 of these lakes had formed.Some of these formations, known as supraglacial - or meltwater - lakes, appear to be draining into the floating ice below, which could have serious consequences for the stability of the entire ice shelf.Ice shelves are thick, floating slabs of ice that form where a glacier or masses of ice flow down a coastline, whereas an ice sheet is\u00a0a massive chunk of glacier ice covering an area of land greater than 50,000 square kilometres (20,000 square miles).What's strange about this news is the fact that researchers had assumed that East Antarctica was fairly impervious to rising climate and ocean temperatures, and have instead been focussing their efforts on investigating the Antarctic Peninsula.\nThe Antarctic Peninsula is the northernmost part of the mainland of Antarctica, and has shown signs of rapid atmospheric and ocean warming in recent years.The disintegration of the East Antarctic ice sheet, on the other hand, has been more subtle, and now researchers are concerned that our lack of knowledge on how supraglacial lakes are affecting it will impact our ability to predict the consequences.\"[East Antarctic is] the part of the continent where people have for quite a long time assumed that it's relatively stable,\" one of the team, glaciologist Stewart Jamieson from Durham University, told Chris Mooney at The Washington Post.\"There's not a huge amount of change, it's very, very cold, and so, it's only very recently that the first supraglacial lakes, on top of the ice, were identified.\"\nAs Mooney explains, as the air temperatures rise during the summer months, these supraglacial lakes form on the surface of the ice sheets, and on the slender glaciers that stretch out into the ocean.These lakes don't last long - they either disappear through refreezing (the best option), drain vertically through the floating ice, or overflow into rivers on the surface that drain into the ice below.\u00a0These last two options have been shown in Greenland's case to eat away at and weaken the structure of the ice sheets and ice shelves, hastening their own disintegration.\"Sometimes, researchers have even been able to document fresh water flowing outward directly into the sea from the base of a glacier,\" Mooney says.\"That injection of cold fresh water into salty water can then create tornado-like underwater flow patterns at the submerged glacier front that cause further ice loss"
        ]
    },
    "5175": {
        "gold_standard": [
            "An international team of researchers has found that one of the four coronaviruses responsible for the common cold \u2013 a virus known as HCoV-229E \u2013 originated in camels before being transmitted to humans.\nThe result comes as a surprise, because researchers didn't realise viruses could spread between the two species until 2012, when the Middle East respiratory syndrome (MERS) coronavirus made the jump from camels to people.Now, the new study suggests that camels might be the cause of a whole lot of other infections \u2013 in addition to rhinoviruses and the three other coronaviruses, HCoV-229E is one of the main pathogens that causes the common cold you suffer from every winter.\"In our MERS investigations we examined about 1,000 camels for coronaviruses and were surprised to find pathogens that are related to 'HCoV-229E', the human common cold virus, in almost 6 percent of the cases,\" said lead researcher Christian Drosten, from the University Hospital of Bonn in Germany.To figure out whether this was just a case of the virus being similar across all animals, the team performed a molecular comparison on the common cold virus in camels, humans, and bats, which are already known to be able to transmit disease to people.\nTheir result suggests that the cold virus wasn't just similar in humans and camels - it had actually jumped from camels to humans at some point in history.They then took things a step further and isolated\u00a0live camel-based common cold viruses, and witnessed the viruses entering the human cells through the same receptor used by HCoV-229E.While a better understanding of where the common cold came from is important in itself, this research is even more crucial in trying to predict how MERS virus \u2013 which causes severe, often fatal, respiratory tract infections \u2013 spread from camels to humans, and how we can stop it in future.The good news is that the team found that the human body is pretty good at defending itself against the camel common cold virus, which suggests a healthy immune system should also be able to fight off MERS.\nThe team also found evidence that camel HCoV-229E had changed significantly to be able to transmit from human to human. The same evolution doesn't seem to have happened in the MERS virus as yet.\u00a0\"The MERS virus is a strange pathogen: smaller, regionally restricted outbreaks, for example in hospitals, keep occurring. Fortunately, the virus has not adapted well enough to humans, and has consequently been unable to spread globally up to now,\"\u00a0said Drosten.But the bad news is that, if the common cold virus eventually evolved to spread between humans, then MERS will most likely able to as well at some point, which means it's something researchers need to keep a close eye on.\"Our current study gives us a warning sign regarding the risk of a MERS pandemic \u2013 because MERS could perhaps do what HCoV-229E did,\"\u00a0Drosten added.A MERS vaccine is scheduled for clinical trials starting next year. Hopefully, as researchers gain a better understanding of MERS and systems at work behind it, they will find new ways of treating those infected and better ways to stop its spread.The team's work was published in Proceedings of the National Academy of Sciences"
        ]
    },
    "5198": {
        "gold_standard": [
            "Wood is a strong and versatile building material, but it rots, gets eaten by bugs, and blocks light.\u00a0Plain sheets of glass aren't much better. They shatter easily and let a lot of energy leak into or out of a building.\nBut engineers have recently figured out how to find the best of both worlds by making see-through wood.The team, led by materials scientist Liangbing Hu at the University of Maryland, developed a patented process to turn wood translucent, make it more durable, and lend it incredible strength.We first wrote about this\u00a0wild-looking material\u00a0in May 2016, but the same scientists recently published\u00a0a detailed study about its properties\u00a0in the journal Advanced Energy Materials.How strong is it? The engineers write in the study that it has \"high impact energy absorption that eliminates the safety issues often presented by glass\".Because seeing is believing, watch them whack this stuff with a hammer as hard as they can. You can see a regular piece of (thoroughly shattered) glass at left that did not fare so well with the same test:The recipe to make translucent wood like this is a secret for now, but\u00a0Martha Heil, a University of Maryland Nanocentre spokesperson,\u00a0told Business Insider in May that\u00a0the process uses bleach, epoxy, and - of course - wood.\nFirst the researchers soak the wood in lye, also known as sodium hydroxide. The chemical removes lignin, a compound in wood that normally makes wood brown, strong, and resistant to the munching of pests.Heil said\u00a0it takes about 10 minutes to bleach a very thing piece of wood and up to 24 hours to bleach a small log.Next the wood is soaked in a \"clear liquid\" to clear it up. At this stage the wood is \"very friable, or as one researcher put it, 'crunchy'\", said Heil.It looks like this if you don't bleach the wood long enough - note the lignin-packed rings of the wood:Fully processed, clarified wood gets soaked in a glue-like epoxy that makes it very hard and clear.\nThis turns the porous tubes of cellulose in wood - which normally suck water up toward leaves and pull sugars down toward roots - into highly efficient light diffusers.\"You have a uniform consistent indoor lighting, which is \u2026 independent of where the Sun is,\" materials scientist Tian Li said in a\u00a0YouTube video released by the university, so even light from a glancing angle will illuminate the see-through wood.And because this 'glass' is made of wood, it's also a better insulator against heat.\"Our transparent wood also has a much lower thermal conductivity compared with glass, making it a better thermally insulating building material with a lower carbon footprint,\" the team wrote in the new study.The researchers hope their creation will reinvent wood as the next big thing in renewable building materials, but they have yet to scale up their bench-top work to a manufacturing level - and perfect a process that relies on less harmful chemicals"
        ]
    },
    "5206": {
        "gold_standard": [
            "At this point, you're probably fully aware of how hot it is. But in case you're unaware: It's really, really hot.In fact,\u00a02016 is likely to be the hottest year on record, increasing 2.3 degrees Fahrenheit (1.3 degrees Celsius) above pre-industrial averages.\nThat brings us dangerously close to the 2.7-degree-Fahrenheit (1.5-degree-Celsius)\u00a0limit set by international policymakers\u00a0for global warming.\"There's no stopping global warming,\"\u00a0Gavin Schmidt, a climate scientist who is the director of NASA's Goddard Institute of Space Studies, told Business Insider. \"Everything that's happened so far is baked into the system.\"That means that even if carbon emissions dropped to zero tomorrow, we'd still be watching human-driven climate change play out for centuries. And, as we all know, emissions aren't going to stop tomorrow. So the key thing now, Schmidt said, is slowing climate change down enough to make sure we can adapt to it as painlessly as possible.This is what Earth could look like within 100 years if we do, barring huge leaps in renewable energy or carbon-capture technology.\n\"I think the 1.5-degree [2.7-degree F] target is out of reach as a long-term goal,\" Schmidt said. He estimated that we will blow past that by about 2030.Stephane Mahe/ReutersBut Schmidt is more optimistic about staying at or under 3.6 degrees Fahrenheit, or 2 degrees Celsius, above preindustrial levels \u2013 the level of temperature rise the UN hopes to avoid.Thomson ReutersLet's assume we land between those two targets. At the end of this century, we're already looking at a world that is on average 3 degrees or so Fahrenheit above where we are now.NASABut average surface temperature alone doesn't fully capture climate change. Temperature anomalies \u2013 or how much the temperature of a given area is deviating from what would be 'normal' in that region \u2013 will swing wildly.Oli Scarff/GettySource:\u00a0Tech Insider\nFor example, the temperature in the Arctic Circle last winter soared above freezing for one day. It was still cold for Florida, but it was extraordinarily hot for the arctic. That's abnormal, and it will start happening a lot more.Bob Strong/RetuersSource:\u00a0The Washington PostThat means years like this one, which had the lowest sea-ice extent on record, will become common. Summers in Greenland could become ice-free by 2050.NASA Goddard FlickrSource:\u00a0Journal of Advances in Modeling Earth Systems\nEven 2015 was nothing compared with 2012, when 97 percent of the Greenland Ice Sheet's surface started to melt in the summer. It's typically a once-in-a-century occurrence, but we could see this kind of extreme surface melt every six years by end of the century.Ville Miettinen/FlickrSource:\u00a0Climate Central,\u00a0National Snow & Ice Data CentreOn the bright side, ice in Antarctica will remain relatively stable, making minimal contributions to sea-level rise.Andreas Kambanis/FlickrSource:\u00a0Nature\nBut in our best-case scenarios, oceans are on track to rise 2 to 3 feet (0.6 to 0.9 metres) by 2100. Even a sea-level rise below 3 feet (0.9 metres) could displace up to 4 million people.Thomas ReutersSource:\u00a0NASA, TimeOceans not only will have less ice at the poles, but they will also continue to acidify in the tropics. Oceans absorb about a third of all carbon dioxide in the atmosphere, causing them to warm and become more acidic.Brandi Mueller for Argunners MagazineSource:\u00a0International Geosphere-Biosphere Program\nIf climate change continues unabated, nearly all coral reef habitats could be devastated. Under our best-case scenario, half of all tropical coral reefs are still threatened.Matt Kieffer/FlickrSource:\u00a0International Geosphere-Biosphere ProgramBut the oceans aren't the only place heating up. Even if we curb emissions, summers in the tropics could increase their extreme-heat days by half after 2050. Farther north, 10\u00a0percent\u00a0to 20\u00a0percent\u00a0of the days in a year will be hotter.Lionel Cironneau/APSource:\u00a0Environmental Research LettersBut compare that with the business-as-usual scenario, in which the tropics will stay at unusually hot temperatures all summer long. In the temperate zones, 30\u00a0percent or more of the days will be what is now unusual.Matt York/AP PhotoSource:\u00a0Environmental Research LettersEven a little bit of warming will strain water resources. In a 2013 paper, scientists used models to estimate that the world could see more severe droughts more frequently \u2013 about a 10 percent increase. If unchecked, climate change could cause severe drought across 40\u00a0percent of all land, double what it is today.ReutersSource:\u00a0PNASAnd then there's the weather. If the extreme El Ni\u00f1o event of 2015 to 2016 was any indication, we're in for much more dramatic natural disasters. More extreme storm surges, wildfires, and heat waves are on the menu for 2070 and beyond.Reuters/Max WhittakerSource:\u00a0Environment360Right now, humanity is standing on a precipice. We can ignore the warning signs and pollute ourselves into what Schmidt envisions as a \"vastly different planet\" \u2013 roughly as different as our current climate is from the most recent ice age.ReutersOr we can innovate solutions. Many of the scenarios laid out here assume we're reaching negative emissions by 2100 \u2013 that is, absorbing more than we're emitting through carbon-capture technology.Reuters/Aly SongSource:\u00a0The GuardianSchmidt says we are likely to reach 2100 with a planet somewhere between \"a little bit warmer than today and a lot warmer than today\".Heinz-Peter Bader/ReutersBut the difference between 'a little' and 'a lot' on the scale of Earth is one of millions of lives saved, or not.Benoit Tessier/ ReutersThis article was originally published by Business Inside"
        ]
    },
    "5212": {
        "gold_standard": [
            "(Peter Wardrop et al.) Scientists have found worrying evidence that fish are becoming toxic, as their environments are being polluted with billions of microbeads \u2013 the tiny plastic particles commonly found in face scrubs, body wash,\u00a0and other cosmetics.\nSeveral governments, including the US\u00a0and Australia, are in the process of phasing microbeads out, but based on their findings, researchers are pushing for an immediate ban.We've known for a while now\u00a0that microbeads act like tiny magnets for pollutants, capable of concentrating these substances up to 1 million times. And that's pretty worrying, seeing as 8 trillion of these tiny plastic beads are entering the waterways of the US alone, every single day.But even though it's long been suspected, this is the first study to show that the toxins attached to microbeads can contaminate fish directly, with a team from\u00a0RMIT University in Australia finding\u00a0that fish can absorb up to 12.5 percent of the pollution from microbeads.\"We know generally that if someone eats a fish, they risk eating any pollution that may be in the fish,\" said lead investigator Bradley Clarke.\n\"Our next step is to determine the implications of our findings on microbeads for public health,\u00a0working out the significance of this exposure pathway and precisely measuring how much pollution could be entering this human food chain.\"While you probably never give them a second thought, microbeads are in a huge amount of different cosmetic products, from facial scrubs to toothpastes. They're those ultra-tiny plastic balls that feel rough when you use them. Since we don't ingest them, most people had assumed these tiny plastic beads were harmless.But all of that changes when the microbeads are washed down our sinks and into the ocean, where fish can't help but to consume them, because they're so small.\u00a0These microbeads then end up sitting in the stomach of fish, and, just like any plastic, they attract and concentrate toxic chemicals \u2013 including a\u00a0class of pollutants called polybrominated diphenyl ethers (PBDEs), which are known to cause neurological problems, decreased immune function, and even fertility problems.\nTo figure this out, Clarke and his team fed Murray River rainbow fish microbeads that had been spiked with PBDEs, in levels that mimic the real-world environment.They then tested the amount of PBDE present in the fish tissue after 21 days, and compared it to a control group that hadn't eaten microbeads.The results showed that\u00a0up to 12.5 percent of the PBDEs on the microbeads had leached into the tissue of the fish \u2013 which is a problem, because that's\u00a0what\u00a0we end up eating.\"Our research shows for the first time that persistent organic pollutants accumulate in the tissue of fish that eat microbeads,\" said Clarke.The researchers have yet to prove that these pollutants can leech into the human system from fish tissue we eat, and they still need to replicate this result across more than one fish species.\nBut considering the potential health problems involved in ingesting chemicals such as PBDE, the researchers say it's not worth the risk of keeping microbeads on the shelves.Basically, we are what we eat, and that isn't always a good thing when the healthy-looking fish we had for dinner was full of pollutants.\"It would be nice to see an immediate ban, and the companies investing money into remediation costs. Microbeads should never have been in products in the first place,\"\u00a0Clarke told\u00a0The Sydney Morning Herald.\"We shouldn't have to wait one or two years for these products to be banned, because in that time, billions more microbeads will be released into the environment.\"Earlier this year, the US put in place a law\u00a0banning cosmetic companies from using microbeads after July 2017, and the sale of products containing them will be banned the following year.\u00a0The Australian government is talking about phasing microbeads out in 2018.\nLet's hope research such as this study help to speed up that process"
        ]
    },
    "5225": {
        "gold_standard": [
            "Researchers have successfully levitated a 50-mm (2-inch) solid polystyrene ball using nothing but high frequency sound waves.Although scientists have been able to acoustically levitate small objects such as water droplets for years, this is one of the largest spheres that's ever been floated in mid-air using the power of sound.\nAcoustic levitation works by using opposing beams of sound waves to create a standing waves. These standing waves have peaks that oscillate between high and low pressure, and can be used to bounce and jostle an object up against the force of gravity.Usually this is done with two opposing sound waves, and water droplets or tiny polystyrene balls smaller than the acoustic wavelength.The traditional technique is to trap the object in the pressure node - the sweet spot where the pressure of the standing wave doesn't change at all - so that the standing wave below the object works like a ping pong paddle, constantly hitting the object upwards.But this is the first time acoustic levitation has been done with a sphere that's 3.6 times larger than the acoustic wavelength, and has a mass of around 1.5 grams.Andrade et al./AIP PublishingUsing the traditional technique, it was thought that the maximum sized object that could be levitated using ultrasound waves, which have a frequency about 20 kHz and a wavelength of 14 mm, was around 4 mm in diameter.\n\"In our paper, we demonstrate that we can combine multiple ultrasonic transducers\u00a0to levitate an object significantly larger than the acoustic wavelength,\" one of the researchers, Marco Andrade from the University of S\u00e3o Paulo in Brazil, told Lisa Zyga over at Phys.org.\"We could increase the maximum object size from one quarter of the wavelength to 50 mm, which is approximately 3.6 times the acoustic wavelength.\"To pull this off, the team used a tripod structure of ultrasound transducers.Instead of trapping the object at the pressure node - the ping pong bat method isn't powerful enough to levitate something this large - the team generated a standing wave between the transducers and the object. This meant the sphere was being buffered on three sides by sounds waves to hold it in place.\nUsing this technique, they were able to levitate the sphere to a height of around 7 mm, which is approximately half the wavelength of acoustic waves.But the researchers hope that by tweaking their technique, they'll be able to get objects higher - and also levitate larger objects at different angles.\"At the moment, we can only levitate the object at a fixed position in space,\" Andrade told Phys.org. \"In future work, we would like to develop new devices capable of levitating and manipulating large objects in air.\"Acoustic levitation could play an important role in the future to analyse and control liquid in space, as well as helping researchers handle extremely hot or caustic materials here on Earth.It could also help researchers to one day generate Star Trek-style\u00a0tractor beam devices, that can pull an object towards them.\nMore importantly for now, it just looks really, really cool. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">For even more acoustic levitation on the small scale, check this out: width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">The research has been\u00a0published in\u00a0Applied Physics Letter"
        ]
    },
    "5238": {
        "gold_standard": [
            "Palaeontology An ancient shark that lived 300 million years ago was likely the most dangerous predator in its marine environment, and it looks like its fearsomeness wasn't just reserved for prey from other species.\nA new study suggests that Orthacanthus sharks turned to cannibalism when food became scarce, with evidence of baby shark teeth being found in poop fossils unearthed from an old Canadian coalfield.\"There is already evidence from fossilised stomach contents that ancient sharks like Orthacanthus preyed on amphibians and other fish, but this is the first evidence that these sharks also ate the young of their own species,\" said palaeontologist Aodh\u00e1n \u00d3 Gog\u00e1in from Trinity College Dublin in Ireland.Finding juvenile teeth in ancient shark poop wouldn't have been enough on its own to suggest that Orthacanthus resorted to cannibalism when other food sources ran low. After all, it's possible that some other carnivorous marine species was feeding on the baby sharks, and excreted the undigested teeth in their droppings.But what most likely settles the identification issue is the shape of the fossil poop that the researchers found.\nOrthacanthus was a 3-metre-long shark with a dorsal spine, an eel-like body, and what's known as tricuspid teeth \u2013 a crown with three cusps.It also had a distinctive corkscrew-shaped rectum, and the coprolites (fossil poop) that the researchers discovered were indeed spiral-shaped \u2013 making it hard to avoid the grisly conclusion that these sharks ate their own young (a practice known as filial cannibalism).Aodh\u00e1n \u00d3 Gog\u00e1in/Trinity College DublinIn the image above, you can see a thin section of the Orthacanthus poop fossil the researchers found in the Minto Coalfield of New Brunswick, Canada, with the black box highlighting the juvenile shark teeth in the coprolite.\n\"We don't know why Orthacanthus resorted to eating its own young. However, the Carboniferous Period [roughly 360 to 300 million years ago] was a time when marine fishes were starting to colonise freshwater swamps in large numbers,\" said one of the researchers, Howard Falcon-Lang from Royal Holloway, University of London in the UK.\"It's possible that Orthacanthus used inland waterways as protected nurseries to rear its babies, but then consumed them as food when other resources became scarce,\" he added.In any case, eating your own young is a relatively rare event in the animal world, for obvious enough reasons.\"There's cannibalism and then there's specifically filial cannibalism. And that is relatively unusual,\" Falcon-Lang told Jonathan Webb at BBC News. \"We generally find it in rather stressed ecosystems, where for whatever reason, food is running scarce. Obviously, it's evolutionarily a bad move to eat your own young unless you absolutely have to.\"\nScientists think that Orthacanthus sharks hunted in a range of shallow waters toward the end of the Carboniferous Period, so long ago that Europe and North America lay on the equator. Back then, the species was equally at home in the ocean and the swamps of the steamy jungle environments, called 'Coal Forests' \u2013 as the remnants have now become compacted into coal seams over millennia.\"Orthacanthus was probably a bit like the modern day bull shark, in that it was able to migrate backwards and forwards between coastal swamps and shallow seas,\" said \u00d3 Gog\u00e1in in a press release. \"This unusual ecological adaptation may have played an important role in the colonisation of inland freshwater environments.\"The findings are reported in Palaeontolog"
        ]
    },
    "5253": {
        "gold_standard": [
            "A\u00a0new paper\u00a0published in the Royal Society of Open Science names just one man as the culprit behind\u00a0one of the biggest scientific crimes ever committed.It all started in 1912, when Charles Dawson, a professional lawyer and amateur fossil hunter, discovered\u00a0fragments of a human-like skull, an apelike jawbone with two worn molar teeth, some stone tools, and fragments of animal fossils in a gravel pit in the UK. All of the fossils were stained a dark reddish-brown.\nDawson brought his discoveries to palaeontologist Arthur Smith Woodward. When the two announced their find, it sparked major excitement in the scientific community.The skull, which scientists decided came from a creature nicknamed\u00a0Piltdown Man\u00a0who walked the earth up to 500,000 years ago, was hailed as the missing evolutionary link between apes and humans.A few more fossil fragments were later excavated from the site, and one year before Dawson's death in 1915, he claimed that he had found fragments from another skull at a second site a few miles from the first one.But something was a bit off about the findings.One of the most famous scientific cons of all timeIn the 1950s, scientists reexamined the bones using new technologies and found something odd: The bones were not all the same age.\nThe upper skull was only 50,000 years old and the jawbone, which scientists now think came from an orangutan, was only a few decades old. Further evidence suggested that the perpetrator had stained the fossils with a chemical to give them\u00a0a reddish-brown appearance.The Piltdown Man hoax quickly became known as one of the most famous scientific cons of all time.Dawson was the obvious prime suspect, but did he act alone? Many suspected that Dawson had some help,\u00a0as Jennifer Ouellette outlines\u00a0in Gizmodo.Woodward seems like a tempting choice for Dawson's accomplice, except that he had spent the remainder of his life continuing the hunt for more of these fossils.Some argued that French priest Pierre Teilhard de Chardin, who was there when a canine tooth was found at the site, may have sneakily planted it there. Even Sir Arthur Conan Doyle, the legendary creator of Sherlock Holmes, was eyed as a suspect.\nBut the new paper clears all of the other suspects of any guilt, naming Dawson as the sole perpetrator in the case of the planted fossils. The paper points out that every specimen ever uncovered was found in Dawson's presence, and the sites suspiciously dried up after Dawson's death.Dawson knew that the British scientists would expect to see \"a large brain, ape-like face and jaws, and heavily fossilised materials that indicated great antiquity\" - so he gave them exactly what they were looking for.And lead author Isabelle de Groote, a palaeoanthropologist at Liverpool John Moores University, told Gizmodo that\u00a0at least 38 other fake finds\u00a0have been attributed to Dawson, including a stone ax, a\u00a0fraudulent flint mine\u00a0at the Lavant Caves, and what he claimed was one of the first bronze statuettes linked to Roman times.\"He clearly had been doing this for a very long time,\" she\u00a0said.\nA cautionary taleFor the new paper, the\u00a0researchers used modern scanning technology and DNA analysis to investigate the fossils. They were able to conclude that the jawbone and teeth came from one orangutan, which they suspect might have come from a curiosities shop.Another strange observation De Groote made about the fossils was that there was an off-white putty on the surface of the bones.\"This putty had been\u00a0painted over and stained, and in some cases was used to fill in cracks and gaps that the forger accidentally created,\" Michael Price\u00a0wrote in Science magazine.\"Inside the crania and teeth, she found tiny pebbles stuffed inside hollow chambers sealed over with the same putty.\"The paper was published on the 100th anniversary of\u00a0Dawson's death. And the hoax leaves us with a valuable lesson.\n\"Piltdown Man sets a good example of the need for us to take a step back and look at the evidence for what it is and not for whether it conforms to our preconceived ideas,\" De Groote\u00a0told Science magazine.This article was originally published by Business Insider.\nMore from Business Insider:Ukrainian President Zelenskyy delivered historic speech to Congress at a crucial moment in Ukraine war: 'Ukraine is alive'The US is finally sending Patriot air defenses to Ukraine, but officials warn that it's not 'a silver bullet'Alex Jones said he was 'so stressed out' during his January 6 examination that he was unable to spell his own middle name correctlyA Ukrainian military captain asked Zelenskyy to give Biden a medal he had won for his service: 'Give it to a very brave president'Ukraine's heavy artillery, not high-tech anti-tank missiles, is what stopped Russia's rush to Kyiv, experts sa"
        ]
    },
    "5254": {
        "gold_standard": [
            "Geophysical Research Letters Other than Earth, Saturn's largest moon Titan is the only other planetary body in our entire Solar System known to have naturally occurring liquid on its surface.But unlike our practically perfect planet, Titan's liquid isn't exactly inviting - it's made of super-cold methane, and for the first time, NASA's Cassini spacecraft has spotted deep gorges and complex river systems flooded with the stuff.\nIf you're not that familiar with Titan, let me paint a picture for you. This icy, desolate moon has a thick, highly pressurised nitrogen and methane atmosphere, and is shrouded in enormous clouds of cyanide.\u00a0Its air temperature is about 200 degrees Celsius cooler than Earth's, and on its rocky surface near the north pole, there are three large seas of methane hydrocarbon - Kraken Mare, Punga Mare, and Ligeia Mare. Dozens of smaller lakes surround these three vast oceans.Besides having very little atmospheric oxygen and no water - and, you know, the whole cyanide thing - Titan is of great interest to astronomers because it's kind of like a bizarro Earth.\u00a0It's got land and sea, and in the past, scientists have gone so far as to simulate a cell membrane that doesn't need oxygen to survive or reproduce. Yep, it's theoretically possible for a completely different kind of life to exist on Titan.\nNASA's Cassini spacecraft has spent almost two decades investigating Saturn and its peripheries, and the data it's sent back to headquarters has shown indications that its second-largest sea, Ligeia Mare, branches off into flooded rivers and canyons in a Nile River-like formation.The channels Cassini has spotted - in particular, a complex, 400 km-long network of them called Vid Flumina - appear to be formed from eight extremely narrow canyons that are slightly less than 1 km wide, but an intimidating 240 to 570 metres (790 to 1,870 feet) deep.Researchers have known about these formations for some time, and thought that maybe the strange dark material inside them could be liquid rather than icy debris, but until now, they've had no way of testing it.That's where Cassini's radar - and some extremely clever science - come into play.\nAs NASA explains, the researchers observed the way Cassini's radar signal reflected off the bottoms of the canyon features. The radar observed a \"glint\", which signals that the canyons have a very smooth surface, likely formed by a liquid, just like in Titan's methane seabeds.The team also figured out the depths of these canyons by looking at the timing of the radar echoes as they bounced off their edges and floors, which you can see in the gif at the top of the page.So how did these rivers and canyons form? That part is less clear, but the researchers say there are a couple of possibilities.\"The presence of such deep cuts in the landscape indicates that whatever process created them was active for a long time or eroded down much faster than other areas on Titan's surface,\" a NASA statement explains, adding that this could have involved either tectonic shifts or changes in sea level, or maybe even both.\nThe team modelled the likely scenarios for how these channels formed, using similar scenarios here on Earth as a comparison.\u00a0As David Lumb explains for Engadget, upward movements in the terrain caused by earthquakes could send liquid from Ligeia Mare punching deeply down, like it did in our own Grand Canyon.\u00a0Or, variations in the sea level could have increased the rivers' rate of erosion, like it did in the formation of Lake Powell, which runs off of the Colorado River.\"It's likely that a combination of these forces contributed to the formation of the deep canyons, but at present it's not clear to what degree each was involved,\" says one of the team, Valerio Poggiali from the University of Rome, Italy.\"What is clear is that any description of Titan's geological evolution needs to be able to explain how the canyons got there.\"Cassini will complete its 20-year mission some time next year, but hopefully before then, it will recieve more information from the canyons area. Because Titan is just weird enough that we really don't know what we could find.The study has been published in Geophysical Research Letter"
        ]
    },
    "5259": {
        "gold_standard": [
            "The Astrophysical Journal For the first time, astronomers have witnessed a small dwarf galaxy forming an even tinier galaxy, confirming the idea that galaxies of any mass can accrete \u2013 or bring together \u2013 smaller galaxies.\n\"In other words, not only massive bodies cannibalise smaller ones that happen to lie in their surroundings, but the same appetite and digestion capabilities can be found in the smaller ones,\" says team member Monica Tosi, from the Italian National Institute of Astrophysics (INAF).Understanding how these ultra-tiny galaxies form and then combine into larger galaxies will hopefully enable researchers to better understand how our galaxy \u2013 and the Universe as a whole\u00a0\u2013 came to look the way it does.To make their observation, the team used the Large Binocular Telescope (LBT) in Arizona to study a dwarf galaxy known as DDO 68 that measures only 100 million solar masses, which is only one-thousandth the mass of the Milky Way.While examining DDO 68, the team found that there were actually a bunch of super-small galaxies forming around it via the process of accretion.\nThis happens when matter \u2013 dust and other space debris \u2013 gets pulled together by the gravity of a galaxy, causing a new, smaller galaxy to form. As the new galaxy gets larger, it will likely be 'eaten' by the galaxy that accreted it.Lead researcher Francesca Annibali says\u00a0what they saw reminded them of a quote by Jonathan Swift:\n\"'So, naturalists observe, a flea has smaller fleas that on him prey; and these have smaller still to bite 'em; and so proceed ad infinitum.' It turns out that even the smallest of galaxies feed on companions that are even smaller, and so our paper bears that quote in its title.\"\nOver time, dwarf galaxies will consume enough smaller 'flea' galaxies to become full-fledged galaxies like the Milky Way.This process has been predicted by computer models for some time. Now, the team was finally able to verify the model by observing it happening in the night sky.\n\"It is very interesting to discover that a system whose gravitational potential is too low to retain ejecta from supernovae is still capable of attracting and accreting smaller galaxies,\" Tosi said.\"Specific dynamical and hydrodynamical studies are necessary to understand what main mechanisms are at play here.\"Guys, we've got another astronomical mystery on our hands here.The team's findings have been published in The Astrophysical Journa"
        ]
    },
    "5557": {
        "gold_standard": [
            "Researchers have once again debunked the 5-second rule, where food is apparently 'safe' to eat if dropped on the floor and picked up within 5 seconds.By testing various foods on different surfaces to see how fast bacteria transfers to it, they\u00a0found that bacteria can jump on our dropped snacks in under 1 second, which of course is\u00a0bad news for clumsy eaters everywhere.\n\"The popular notion of the '5-second rule' is that food dropped on the floor, but picked up quickly, is safe to eat, because bacteria need time to transfer,\"\u00a0said team member Donald Schaffner\u00a0from Rutgers University.\"We decided to look into this because the practice is so widespread. The topic might appear 'light', but we wanted our results backed by solid science.\"The team chose four different types of surface - stainless steel, ceramic tile, wood, and carpet - and selected a number of different foods to drop on them, including watermelon, dry bread, buttered bread, and gummy candies.They grew Enterobacter aerogenes\u00a0- a safe, non-pathogenic relative of Salmonella\u00a0- in the lab, and covered their test surfaces in it.Each piece of food was then dropped\u00a0on each bacteria-covered surface, and left there for various amounts of time: 1 second, 5 seconds, 30 seconds, and 300 seconds.\nA total of 128 different scenarios trials\u00a0were completed and replicated 20 times, adding up to\u00a02,560 individual measurements that\u00a0were used to\u00a0analyse the amount of contamination on each food item. The team found that the biggest factor\u00a0when it came to bacteria transfer was\u00a0the amount of moisture present in the food, followed by\u00a0the type of surface it's being dropped onto. And\u00a0while bacteria didn't hesitate to transfer over, the longer food was left, the more bacteria found its way over.\"Transfer of bacteria from surfaces to food appears to be affected most by moisture,\"\u00a0Schaffner said.\u00a0\"Bacteria don't have legs, they move with the moisture, and the wetter the food, the higher the risk of transfer. Also, longer food contact times usually result in the transfer of more bacteria from each surface to food.\"The team says that even though they found that longer contact times did lead to higher levels of contamination, picking up food in less than 5 seconds is still enough time for bacteria to transfer - especially if the food is wet or sticky like watermelon or candy, which had the highest levels of\u00a0contamination across the tests.\n\"The 5-second rule is a significant oversimplification of what actually happens when bacteria transfer from a surface to food,\"\u00a0Schaffner says.\u00a0\"Bacteria can contaminate instantaneously.\"There were some surprising finds, too. You might think that carpet - with its tendency to catch crumbs and get dirty rather quickly -\u00a0would be the\u00a0worst thing\u00a0to eat off of, but the researchers found that it's\u00a0actually the best, because its structure minimises the amount of contact it has with the food.\u00a0The Rutgers team isn't the first to debunk the 5-second rule - there have been other peer-reviewed studies about it and TV shows have tackled it, too. But they hope that their concrete analysis of different types of foods and surfaces will help people to understand how the popular piece of advice is not something you\u00a0want to base your hygiene practices around.The team's work was published in Applied and Environmental Microbiology"
        ]
    },
    "5570": {
        "gold_standard": [
            "Pediatric Dermatology Scientists have analysed the effectiveness of over-the-counter head lice treatment over the past 30 years, and let's just say it's not looking good. In fact, two of the most used type of over-the-counter medications for head lice, permethrin and synergized pyrethrins, have had a 75 percent drop in effectiveness since 1985.\n\"Recent clinical studies from across the United States have found that permethrin effectiveness has declined to 25 percent, even with nit combing, a level described as being no better than placebo,\" the researchers, from John Hopkins Medicine in Maryland, conclude.Check out this table, showing the single treatment effectiveness across the US, and just watch those percentages drop:The treatment formula has barely changed over the years, so how the hell does this happen? Well, bacteria aren't the only things that can gain resistance to particular forms of chemicals through subtle genetic changes over time. Head lice can become resistant to toxic chemicals too, like \u2013 you know \u2013 head lice treatments.\nIn this case, genetic testing has shown that gene changes called knockdown resistance mutations can reduce sensitivity in the nervous system, and help keep the lice alive. Just in case you were wondering, the frequency of these mutations in US head lice is currently at 99.6 percent. \"Our findings indicate that over-the-counter treatments for head louse infestations are no longer likely to be effective,\" said one of the researchers, Terri Meinking. Now, we've all heard of those home remedies for nits, such as essential oils, mayonnaise, or petroleum jelly, but don't go slathering them on your head just yet. The report also advised that these home remedies are ineffective, and with no studies evaluating their safety, it's probably best to steer clear. \"These therapies may transiently suppress louse metabolic activity, giving the false impression of death, only to have them awaken shortly thereafter - the so-called 'resurrection effect',\" the researchers say.\nThankfully, there are still some head lice treatments that do work, and won't require you to shave your whole head (or cover it in mayonnaise). The researchers singled out malathion, benzyl alcohol, spinosad, and topical ivermectin, as the active ingredients to look out for. However, these are mostly prescription products in the US, so you'll have to go to a doctor to get your hands on one. Although these are all likely going to be lifesavers if you do find yourself with head lice, the lead author of the study, Ellen Koch, warns that even these products aren't safe from overuse.\u00a0 \"The lesson we should learn is that those products that do remain effective, which are available by prescription, should be used judiciously so that they do not suffer the fate that has befallen the pyrethroids,\" she says.Basically, make sure you get rid of all the head lice - nit combing and all - otherwise we might be looking at a superbug head lice situation that nobody wants.The research has been published in Pediatric Dermatolog",
            "Scientists have analysed the effectiveness of over-the-counter head lice treatment over the past 30 years, and let's just say it's not looking good. In fact, two of the most used type of over-the-counter medications for head lice, permethrin and synergized pyrethrins, have had a 75 percent drop in effectiveness since 1985.\n\"Recent clinical studies from across the United States have found that permethrin effectiveness has declined to 25 percent, even with nit combing, a level described as being no better than placebo,\" the researchers, from John Hopkins Medicine in Maryland, conclude.Check out this table, showing the single treatment effectiveness across the US, and just watch those percentages drop:The treatment formula has barely changed over the years, so how the hell does this happen? Well, bacteria aren't the only things that can gain resistance to particular forms of chemicals through subtle genetic changes over time. Head lice can become resistant to toxic chemicals too, like \u2013 you know \u2013 head lice treatments.\nIn this case, genetic testing has shown that gene changes called knockdown resistance mutations can reduce sensitivity in the nervous system, and help keep the lice alive. Just in case you were wondering, the frequency of these mutations in US head lice is currently at 99.6 percent. \"Our findings indicate that over-the-counter treatments for head louse infestations are no longer likely to be effective,\" said one of the researchers, Terri Meinking. Now, we've all heard of those home remedies for nits, such as essential oils, mayonnaise, or petroleum jelly, but don't go slathering them on your head just yet. The report also advised that these home remedies are ineffective, and with no studies evaluating their safety, it's probably best to steer clear. \"These therapies may transiently suppress louse metabolic activity, giving the false impression of death, only to have them awaken shortly thereafter - the so-called 'resurrection effect',\" the researchers say"
        ]
    },
    "5639": {
        "gold_standard": [
            "An international team of researchers has found that Saturn's largest moon Titan has deep canyons filled with liquid hydrocarbons, making the alien moon look a lot like Earth, but with rivers of methane instead of water.\n\"Earth is warm and rocky, with rivers of water, while Titan is cold and icy, with rivers of methane. And yet it's remarkable that we find such similar features on both worlds,\" said team member Alex Hayes, from Cornell University.The team says these channels and canyons form a river network they're calling Vid Flumina. Each of these canyons are about 0.8 kilometres (0.5 miles) wide and somewhere between 244 metres (800 feet) and 579 metres (1,900 feet) deep.All of these rivers appear to flow into the moon's largest sea, Ligeia Mare, which is full of liquid methane hydrocarbons, but further research is needed to understand the flow and current of the rivers.The team was able to make these observations thanks to data collected by NASA's Cassini spacecraft back in 2013 that measured Titan's topography, but the funny thing is that \u2013 despite having all of these new data to work off \u2013 the canyons are still quite a mystery.\n\"The canyons found in Titan's north are even more surprising, as we have no idea how they formed. Their narrow width and depth imply rapid erosion, as sea levels rise and fall in the nearby sea,\" said Hayes.\"This brings up a host of questions, such as where did all the eroded material go?\"On Earth, canyon formation is a simple, yet lengthy process that involves rivers slowly carving into the Earth's surface, carrying away layer after layer of river bed until canyons eventually form. The sediment that is scraped off the riverbed simply washes downstream to larger bodies of water like lakes or oceans.On Titan, though, it remains unclear how these canyons came to be. Did they form thanks to erosion like Earth's? Or did they form from impacts or geological activities beneath the surface?\n\"It's likely that a combination of \u2026 forces contributed to the formation of the deep canyons, but at present, it's not clear,\" said team leader Valerio Poggiali, from the Sapienza University of Rome.\"What is clear is that any description of Titan's geological evolution needs to be able to explain how the canyons got there.\"While understanding how methane rivers work on Titan will give us a better understanding of how this moon of Saturn formed, other scientists say that Titan could be home to microorganisms that thrive in methane-based atmospheres.In fact, Titan is such a promising place for potential alien life, NASA is planning on sending an autonomous submarine there to explore these rivers and seas after Cassini finishes its mission.So far, the Cassini mission \u2013 which is about to celebrate its 20th birthday \u2013 has provided researchers with unique pictures and observations of Titan and Saturn that have led to a plethora of scientific discoveries.The mission will continue to run for another 10 months, with the hope that it will shine a light on the possibility of life at some point in its history, though there's still a long road ahead.The team's work was published in Geophysical Research Letters"
        ]
    },
    "5769": {
        "gold_standard": [
            "The human body begins adapting to high-elevation environments as quickly as overnight, and these biological changes can last for months - even after the person has returned to lower elevations.\nFor the first time ever, scientists comparing the blood of mountain hikers have observed how multiple changes affect the red blood cells' ability to retain oxygen in low-oxygen environments - and it happens within hours.The find contradicts an assumption that's lasted for half a century suggesting that humans in high-altitude environments start producing new red blood cells that are more capable of supplying oxygen to their muscles and organs than the average human's blood.That means in places like the Mount Everest Base Camp in Nepal - where the atmosphere contains just 53 percent as much oxygen as the air at sea level - scientists thought humans gradually replaced their red blood cells with new, high-functioning versions that are better able to deal with oxygen transport and delivery.\"That's been the story for 50 years,\" Robert Roach, lead investigator and director of the Altitude Research Centre at the University of Colorado, told Richard A. Lovett at Science.\nBut there's one big problem with that assumption. While it might make sense for populations that spend their entire lives in high-altitude, low-oxygen environments - such as the mountain-dwelling Tibetans and the Andean highlanders - it doesn't really gel with the experiences of mountain climbers and skiers.\u00a0Because while your body produces about 2 million new red cells every second, it takes weeks for all the red cells to be replaced, so how can hikers survive up there if it takes weeks to adapt?As Lovett points out, \"even ordinary people can adapt within days\".To investigate what's actually going on, Roach and his colleagues have been working with volunteers taking part in a project called AltitudeOmics, which is an ongoing study run by the Altitude Research Centre to figure out the basic biological changes that occur in humans as they acclimatise to high-altitude environments.\nThey sent 21 healthy volunteers (12 males and nine females, 19 to 23 years old) to a camp near the top of Bolivia's Mount Chacaltaya - at an altitude of 5,260 metres (17,257 feet).Their blood was monitored before they headed up the mountain, at several intervals on the mountain - including during a 3.2-km (2-mile) hike - and then after they had descended to 1,525 metres for a period of seven days.After their week's rest, the volunteers were sent back up the mountain again to attempt their 3.2-km hike once more.Interestingly, the volunteers reported finding the second trip up the mountain as being significantly easier than the first time, and they fared much better the second time they attempted the hike.This suggests that the volunteers had not only adapted during the first trip up the mountain, but had managed to retain the changes even after they'd returned to lower-elevation environments.\nWhen the researchers analysed the results from the blood tests, they realised that the red blood cells weren't being replaced - they were changing, and as rapidly as a few hours after exposure on Day 1.The team also found that the multitude of changes related to the red blood cells' ability to transport and deliver oxygen to muscles and vital organs were far more complex than they were expecting.This is the first ever evidence outside the lab of red blood cells undergoing biological changes in response to high-altitude environments, and as Lovett points out, because red blood cells live for about 120 days, the changes are expected to last as long as the cells do.\"We provide for the first time supportive evidence of red blood cell metabolic\u00a0adaptations that ensue within hours from exposure to high altitude\u00a0hypoxia,\" the team concludes.\nThat insight is exciting, because it means that even if you're not born with the genetic variations that ensure the survival of approximately 140 million people living permanently in the high altitudes\u00a0(more than 2,500 metres) of East Africa, Asia, and North, Central and South America, your body can still undergo changes to meet the challenges of low-oxygen environments.\u00a0The find could also inform how we treat injuries resulting in serious blood-loss in the future.\"Low oxygen is also a problem when trauma - from car accidents to gunshot wounds - causes blood loss,\" says Lovett. \"Finding ways to kick the blood's oxygen-carrying capacity into high gear in such an emergency \u2026 could save lives in both the civilian sector and on the battlefield.\"The research has been published in the Journal of Proteome Research"
        ]
    },
    "5599": {
        "gold_standard": [
            "Toxic nanoparticles from air pollution have been found embedded in people's brain tissue for the first time, and research has tentatively linked these particles to a higher risk of Alzheimer's disease.\nThe particles were already known to be present in our brains, but researchers had assumed our bodies naturally produced them. Now a small study by UK researchers has found that they're the direct result of polluted air.\"This is a discovery finding, and now what should start is a whole new examination of this as a potentially very important environmental risk factor for Alzheimer's disease,\" one of the team, Barbara Maher from Lancaster University, told Damian Carrington at The Guardian.\"Now there is a reason to go on and do the epidemiology and the toxicity testing, because these particles are so prolific and people are exposed to them.\"Maher and her team examined brain tissue from 37 people in Manchester, England, and Mexico City, aged between 3 years old and 92. Each of them contained particles of a type of iron oxide called magnetite, and not just traces of them - they were abundant.\n\"You are talking about millions of magnetite particles per gram of freeze-dried brain tissue - it is extraordinary,\" says Maher.The next step was to figure out where these particles were coming from. When the team looked at the particles in the front regions of the brains of six of the volunteers, they found two types of magnetite in the tissue - round particles of magnetite and angular magnetite crystals, and the round ones outnumbered the crystals by about 100 to one.\"Crystal forms are more likely to have a natural source - such as iron that has come out of the body's cells,\" Clare Wilson explains for New Scientist. \"But round particles normally come from melting iron at high temperatures, which happens when fuel is burned.\"A couple of caveats here - the evidence is circumstantial, and the only way to really prove that these particles are sourced from air pollution is to actually trace them all the way from the atmosphere to the brain tissue.\nBut Maher says they also found particles of metals such as platinum that are very rarely found naturally in the body, but are found in many car engines.\u00a0The second big limitation here is that the sample size is tiny, and while the result of abundant round magnetite particles was found in 100 percent of the participants, it's far too early to extrapolate meaning from that for the wider population.But if larger studies do end up finding similar results in a wider, more diverse group of participants, what are the implications?\"Magnetite in the brain is not something you want to have, because it is particularly toxic there,\" Maher told The Guardian, adding that they can produce reactive oxygen molecules called free radicals, which have been linked to ageing and neurological disease.\"Oxidative cell damage is one of the hallmark features of Alzheimer's disease, and this is why the presence of magnetite is so potentially significant, because it is so bioreactive,\" she says.\nPrevious research looking at cells grown in the lab has found that iron oxide could be present in the amyloid plaques that have been linked to the development of Alzheimer's disease, and a study from earlier in the year also linked the presence of magnetite to damage in the brains of Alzheimer's patients.\u00a0We're still very much in the early stages of figuring out what's going on here, but even if the Alzheimer's evidence is yet to be confirmed, what we do know is that air pollution is seriously bad for all of us.As a study from 2015 found, air pollution is likely contributing to the premature deaths of some 3.3 million people around the world every year, and that figure could double by 2050, so whatever pollution is doing to us, one thing's for sure - it's nothing good.Maher and her team's research has been published in\u00a0Proceedings of the National Academy of Sciences"
        ]
    },
    "5614": {
        "gold_standard": [
            "The US Food and Drug Administration\u00a0banned antibacterial soaps\u00a0on Friday because they're not better, cleaner, or safer than regular soap.\"Consumers may think antibacterial washes are more effective at preventing the spread of germs, but we have no scientific evidence that they are any better than plain soap and water,\" said Janet Woodcock, director of the FDA's Centre for Drug Evaluation and Research said in the\u00a0agency's press release.\n\"In fact, some data suggest that antibacterial ingredients may do more harm than good over the long-term,\" she added.The ban applies to products with 19 active ingredients, including triclosan and triclocarban - two widely used antibacterial agents.There's \"extensive literature suggesting that triclosan does not provide a benefit when used in a 'real world' setting compared to plain soap\", Allison Aiello, an epidemiologist from the University of North Carolina who has\u00a0published a review on several studies of triclosan tests,\u00a0told Chemistry World.One study,\u00a0published in the Journal of Antimicrobial Chemotherapy in September 2015, compared soap containing triclosan with regular soap both in lab tests and on people's hands.The researchers exposed people to a type of common bacteria than can infect those with weakened immune systems, then had them wash their hands with triclosan and regular soap.\nThey found no difference between the two soaps.In lab tests, the researchers also exposed 20 different kinds of bacteria to triclosan soap to see if it could do any damage there. It took nine hours to show any antibacterial effects.While that was in test tubes, not on actual humans, that's much longer than the\u00a020 seconds\u00a0the US Centres for Disease Control and Prevention recommends you take to wash your hands.Multiple other studies have found\u00a0that handwashing with antibacterial soap does not remove more bacteria or prevent more illnesses than washing with regular soap. They just work a little differently.While\u00a0regular soap works by mechanically removing germs\u00a0from your hands, antibacterial soap contains chemicals that can kill bacteria or inhibit their growth. And apparently that old wash-off-the-germs method works just as well as kill-them-on-contact.\nMore harm than goodThe US Food and Drug Administration first\u00a0registered triclosan in 1969, and the chemical has been added to countless\u00a0soaps, cosmetics and cleaning products\u00a0since then.But it turns out that triclosan soap is not just an equally effective replacement for ordinary soap - it may actually be worse than non-antibacterial varieties.Studies have found that triclosan can\u00a0increase bacterial antibiotic resistance,\u00a0affect hormone regulation in animals\u00a0and\u00a0kill algae.Triclosan is now in so many products that research has found it was washing down drains and\u00a0building up in lakes and streams. That's part of what prompted Minnesota\u00a0to become the first state to ban the ingredient in 2014.While more research is needed to determine triclosan's safety in small doses, studies so far have shown that there's no real advantage",
            "The US Food and Drug Administration\u00a0banned antibacterial soaps\u00a0on Friday because they're not better, cleaner, or safer than regular soap.\"Consumers may think antibacterial washes are more effective at preventing the spread of germs, but we have no scientific evidence that they are any better than plain soap and water,\" said Janet Woodcock, director of the FDA's Centre for Drug Evaluation and Research said in the\u00a0agency's press release.\n\"In fact, some data suggest that antibacterial ingredients may do more harm than good over the long-term,\" she added.The ban applies to products with 19 active ingredients, including triclosan and triclocarban - two widely used antibacterial agents.There's \"extensive literature suggesting that triclosan does not provide a benefit when used in a 'real world' setting compared to plain soap\", Allison Aiello, an epidemiologist from the University of North Carolina who has\u00a0published a review on several studies of triclosan tests,\u00a0told Chemistry World.One study,\u00a0published in the Journal of Antimicrobial Chemotherapy in September 2015, compared soap containing triclosan with regular soap both in lab tests and on people's hands.The researchers exposed people to a type of common bacteria than can infect those with weakened immune systems, then had them wash their hands with triclosan and regular soap.\nThey found no difference between the two soaps.In lab tests, the researchers also exposed 20 different kinds of bacteria to triclosan soap to see if it could do any damage there. It took nine hours to show any antibacterial effects.While that was in test tubes, not on actual humans, that's much longer than the\u00a020 seconds\u00a0the US Centres for Disease Control and Prevention recommends you take to wash your hands.Multiple other studies have found\u00a0that handwashing with antibacterial soap does not remove more bacteria or prevent more illnesses than washing with regular soap. They just work a little differently.While\u00a0regular soap works by mechanically removing germs\u00a0from your hands, antibacterial soap contains chemicals that can kill bacteria or inhibit their growth. And apparently that old wash-off-the-germs method works just as well as kill-them-on-contact.\nMore harm than goodThe US Food and Drug Administration first\u00a0registered triclosan in 1969, and the chemical has been added to countless\u00a0soaps, cosmetics and cleaning products\u00a0since then.But it turns out that triclosan soap is not just an equally effective replacement for ordinary soap - it may actually be worse than non-antibacterial varieties.Studies have found that triclosan can\u00a0increase bacterial antibiotic resistance,\u00a0affect hormone regulation in animals\u00a0and\u00a0kill algae.Triclosan is now in so many products that research has found it was washing down drains and\u00a0building up in lakes and streams. That's part of what prompted Minnesota\u00a0to become the first state to ban the ingredient in 2014.While more research is needed to determine triclosan's safety in small doses, studies so far have shown that there's no real advantag"
        ]
    },
    "5662": {
        "gold_standard": [
            "If you were to get up close and personal with \u00d6tzi the Iceman \u2013 the 5,000-year-old mummy of a tattooed, deep-voiced man who died and was frozen in the Alps \u2013 you'd notice that his skin is flecked with tiny bits of blue.\nAt first, it would appear that these oddly bluish crystal formations embedded in his skin are from freezing to death or some other sort of trauma, but it's actually a mineral called vivianite\u00a0(or blue ironstone) and it happens to form quite often on corpses left in iron-rich environments.For \u00d6tzi, the patches of vivianite are from him resting near rocks with flecks of iron in them, but other cases are way more severe.According to Chris Drudge at Atlas Obscura, a man named John White was buried in a cast iron coffin back in 1861. During those days, coffins often had a window for grieving family members to peer inside even if the lid was closed during the funeral.Sometime after he was buried, that window broke, allowing groundwater to come inside the iron coffin and interact with his body.\nOver a century later, White was exhumed because of land developments in the area. To the shock of everyone around, they found his body completely blue with large blue vivianite crystals forming all over him and inside the coffin. Here's what vivianite looks like on a piece of bone that was buried in sand:Terry O'Connor/BoneCommonsVivianite has also been found on the remains of American soldiers who died in a plane crash in Vietnam. Researchers were able to tell by the presence of the mineral that the soldiers were likely buried in wet soil alongside pieces of their plane, allowing vivianite to form.These are just a few examples out of many others where archaeologists have witnessed the odd mineral creeping up on exhumed corpses.\nSo what's going on here?Well, it all has to do with how phosphate interacts with iron and water.\u00a0While our bodies are composed of many different molecules, the most important for vivianite is phosphate, and luckily it's found all around our bodies.\"Phosphate is present in the hard bits of bones and teeth (as part of the mineral hydroxylapatite), helps hold together strands of DNA and RNA, and is used by cells to store and move energy around as well as to organise their many protein-driven activities,\"\u00a0explains Drudge.So, when a person dies and starts decomposing, all this phosphate leaks out into the environment around the corpse.If this environment happens to be wet and filled with iron \u2013 like that of White's coffin or \u00d6tzi's glacial tomb \u2013 the phosphate interacts with these other molecules to form the mineral vivianite"
        ]
    },
    "5686": {
        "gold_standard": [
            "For decades, scientists have been talking about quantum computers \u2013 a new generation of computers that would be exponentially more powerful than today's best supercomputers, and would revolutionise the way we process data.\nBut despite regular headlines on new advances in the field, it feels like we're still so far away from seeing a true, working version. That's why researchers have just published a paper describing a 'roadmap' of what needs to be done to build the first practical quantum computer.The study, led by scientists at the University of Technology Sydney (UTS) in Australia, in collaboration with MIT, looked specifically at research on photon-based quantum computer chips, which use particles of light to code for information, and are a frontrunner for getting quantum computers off the ground. But let's start with the basics. A regular computer solves problems using bits that can be either a 0 or a 1 \u2013 meaning it can process only one thing at a time.Quantum computers, on the other hand, use quantum bits (or qubits), which can be 0, 1, or in a \u00a0superposition of both at the same time - think Schrodinger's cat and being dead and alive in a box all at once.\nThis means that instead of being able to solve just one problem at a time, a quantum computer could theoretically solve many calculations at once. Google has already created what it calls a quantum computer, but many experts say it's not anywhere near as powerful as a 'real' quantum computer would be, because it only enacts a special type of quantum computing called quantum annealing.So what's standing in our way of building a proper quantum computer? While scientists have managed to capture and hold onto particles that are small enough to be qubits \u2013 and they've successfully demonstrated entanglement of multiple photons \u2013 they're still struggling to make these devices practical.Nevertheless, photon-based quantum computers are a solid bet, because not only can particles of light work as qubits, they can also transport the information afterwards, creating the foundation of a functioning computer system.\nPlus light travels fast and emitters can be efficiently packaged onto a small chip \u2013 just think of laser beams and laser pointers.\"Photonic technologies are becoming increasingly prevalent in our daily lives. After decades of rapid advances, light sources \u2013 especially lasers and light-emitting diodes (LEDs) \u2013 have become high-performance, yet low-cost and reliable components, driving the internet and lighting cities,\" the team from UTS writes.According to this new paper, the next step is the development of a perfect solid state non-classical light source, known as a single photon source. These sources of light produce streams of photons with controllable quantum relationships and act as qubits. They should emit identical photons, in terms of intensity and colour, and be triggered electrically.\nPlus researchers need to find and engineer the perfect material for the job. Among the many contenders are diamond and an emerging platform, identified by the researchers, called hexagonal boron nitride. \u00a0\"There is still no 'ideal' on-demand single-photon emitter, but a plethora of promising material systems have been developed, and several have transitioned from proof-of-concept to engineering efforts with steadily improving performance,\" the researchers write. \u00a0In the new paper, the team summarises some of the requirements for these future single-photon emitters. Here are the highlights: The team says that the emitters must be bright, easy to engineer, and scalable. The improvement we've already seen in the past few years is equivalent to the six-decade transformation of television \u2013 from cathode ray tube to brand new LED flat screen"
        ]
    },
    "5687": {
        "gold_standard": [
            "Most of us hardly notice our wisdom teeth coming through, but at some point in between middle school and university, many people living in the US or Australia are told we need to get them taken out.\nDepending on whether the teeth are impacted - meaning they're trapped under the gum line - the surgery can involve general anaesthetic, stitches, and a week or two of bed rest and pudding. For a lot of us, it can be a pretty brutal introduction to adulthood.But more and more experts are beginning to question whether the majority of these surgeries are even necessary. And a growing body of research indicates that we might be putting people through the risk of expensive tooth removal for no reason.To be clear, not all wisdom teeth removals are unnecessary. Wisdom teeth can become infected, cause tooth decay or cysts, damage neighbouring teeth, and cause a huge amount of pain if left in people's jaws.In these cases, the evidence is clear that it's far better for a patient to have these 'third molars' - the official name for wisdom teeth - removed.\nBut it's the other cases that researchers are beginning to question - the cases where wisdom teeth are impacted but are otherwise healthy, or don't have any symptoms at all.The UK gave up on routinely removing wisdom teeth without solid evidence back in 1998, after a study at the University of York concluded that there was no scientific evidence to support it.That same year, the Royal College of Physicians of Edinburgh said that for patients who don't have a condition related to third molars,\u00a0removal is \"not advisable\".Still, in many countries, including the US and Australia, routine wisdom teeth removal remains the standard procedure. The reason given is that leaving them in is simply putting off the inevitable, because patients with wisdom teeth will face infection or complications later on.\nBased on that logic,\u00a0in 2011,\u00a010 million wisdom teeth were removed from Americans' mouths, and a 2015 study estimated that seven times more people are hospitalised for the removal of impacted wisdom teeth in Australia than in the UK.\u00a0But new research suggests that it might be overkill.\"Everybody is at risk for appendicitis, but do you take out everyone's appendix?\" Greg J. Huang, chairman of orthodontics at the University of Washington in Seattle\u00a0told Rony Carin Rabin over at\u00a0The New York Times.\"I'm not against removing wisdom teeth, but you should do an assessment and have a good clinical reason.\"So what does the research say? The more recent evidence to support getting wisdom teeth out \"just in case\" comes from a 2014 review that looked at seven papers examining what happened when young adults left their wisdom teeth in. And while, overall, the study showed that leaving wisdom teeth in\u00a0did\u00a0lead to an increased risk of complications later on, that wasn't the full story.\n\"The review concluded that the risk of having to undergo removal appeared to increase as subjects aged,\" Rob Wile explains for Fusion.\"But at least one of the studies in the [review] concluded no such thing. Rather,\u00a0the British study\u00a0found that 83.13 percent of patients survived the one-year study period symptom-free, and just 5 percent had to have teeth removed.\"Rabin over at The New York Times also notes that while several studies have linked keeping wisdom teeth in with ongoing problems, \"There does not appear to be a single randomised clinical trial - the gold standard for scientific proof - comparing similar patients who have and have not undergone prophylactic wisdom teeth removal.\"On the other hand, there's\u00a0a solid and growing body of research showing the opposite - that a lot of wisdom teeth removal is unnecessar"
        ]
    },
    "5704": {
        "gold_standard": [
            "Researchers in Spain have discovered an extremely rare two-headed shark embryo growing in their lab.As far as they're aware, this is the first time the trait has ever been spotted in an egg-laying shark. There have been reports of two-headed sharks before, but they've all belonged to species that give birth to live animals.\nThe researchers are now trying to learn more about the individual, and the discovery will hopefully provide some insight into exactly what cases the mysterious two-headed mutation - officially known as dicephaly.The shark was a\u00a0near-threatened\u00a0Atlantic sawtail catshark\u00a0(Galeus atlanticus)\u00a0embryo, which had been collected by researchers at the University of Malaga in Spain as part of a study on cardiovascular systems.Out of the 797 embryos they collected, one was different to the rest - it had two heads.\"Each head had a mouth, two eyes, a brain, a notochord [like a spinal cord], and five gill openings on each side,\" the authors write in the\u00a0Journal of Fish Biology.The body also had two hearts, two stomachs, and two livers, but it shared just one intestine and a single set of kidneys and reproductive organs.Journal of Fish BiologyThis isn't the first time a two-headed shark has been seen - two-headed bullsharks have been spotted in the past, and there are seven other reports in the scientific literature of sharks with two heads.\nBut all of those species gave birth to live animals, whereas the catshark is the first truly egg-laying shark species to display dicephaly - and that could be the key to figuring out the underlying cause.This particular specimen was euthanised and preserved so the researchers could study it further. In nature, the condition is very rarely encountered, and it's unclear if that's because it's so rare to begin with, or if the creatures simply don't survive long enough to be discovered.There have been reports of\u00a0two-headed snakes,\u00a0cats, and\u00a0humans\u00a0in the past.\"Survival after birth may occur, but would likely be very brief,\" Michelle Heupel, a researcher at the Australian Institute of Marine Science, told David Shiffman over at Hakai magazine.\u00a0\"It is unclear whether the two heads will preclude swimming and prey capture, and whether joined internal organs will function adequatel"
        ]
    },
    "5744": {
        "gold_standard": [
            "ChemistrySelect. If scientists can figure out how to convert atmospheric carbon dioxide into fuel - and do it at an industrial scale - it would, quite literally, change the world. Last month, we hit the highest levels of atmospheric CO2 in 4 million years, and it's now permanent, meaning we'll never be able to drop to 'safe' levels again.\nBut if we can turn CO2 into a fuel source, we can at least slow things down a bit, and now\u00a0researchers have developed a process that can achieve this with a single catalyst.\"We discovered somewhat by accident that this material worked,\" said one of the team, Adam Rondinone, from the US Department of Energy's Oak Ridge National Laboratory.\"We were trying to study the first step of a proposed reaction when we realised that the catalyst was doing the entire reaction on its own.\"Rondinone and his colleagues had put together a catalyst using carbon, copper, and nitrogen, by embedding copper nanoparticles into nitrogen-laced carbon spikes measuring just 50-80 nanometres tall. (1 nanometre = one-millionth of a millimetre.)When they applied an electric current of just 1.2 volts, the catalyst converted a solution of CO2 dissolved in water into ethanol, with a yield of 63 percent.\nThis result was surprising for a couple of reasons: firstly, because it's effectively reversing the combustion process using a very modest amount of electricity, and secondly, it was able to do this while achieving a relatively high yield of ethanol - they were expecting to end up with the significantly less desirable chemical, methanol.As Colin Jeffrey explains for New Atlas, this type of electrochemical reaction usually results in a mix of several different products in small amounts, such as methane, ethylene, and carbon monoxide - none of which are in particularly high demand.Instead, the team got usable amounts of ethanol, which the US needs billions of gallons of each year to add to gasoline.\"We're taking carbon dioxide, a waste product of combustion, and we're pushing that combustion reaction backwards with very high selectivity to a useful fuel,\" Rondinone said in a press statement.\n\"Ethanol was a surprise - it's extremely difficult to go straight from carbon dioxide to ethanol with a single catalyst.\"This certainly isn't the first attempt to convert CO2 pollution into something we can actually use - researchers around the world have been figuring out ways to turn it into things like methanol, formate, and hydrocarbon fuel.This one team working in Iceland wants to turn it all into solid rock so we can just bury it and forget about it.But all of these methods, while promising, are dishing up an end product that the world doesn't really need right now. Sure, we could adjust our cars and energy plants to run on hydrocarbon fuel if it was cheap and efficient enough to produce from CO2, but we're certainly not there yet.Ethanol, on the other hand - well, the US is already blending most of its gasoline with 10 to 15 percent ethanol content.\nThe researchers explain that they were able to achieve such high yields because the nanostructure of the catalyst was easy to manipulate and adjust to get the desired results.\"By using common materials, but arranging them with nanotechnology, we figured out how to limit the side reactions and end up with the one thing that we want,\" said Rondinone. \"They are like 50-nanometre lightning rods that concentrate electrochemical reactivity at the tip of the spike.\"The team says that since the catalyst is made from inexpensive materials, and can operate at room temperature with modest electrical requirements, it could be scaled up for industrial level use.\u00a0But with so many CO2 conversion projects in the works right now\u00a0that are aiming to do the same thing, we'll have to remain cautiously optimistic until they can show real results in the field.\nLet's hope someone ultimately figures it out, because with a drastically expanding population, we're only going to be needing more energy, and we're only going to be pumping more pollution into the atmosphere. A 'two birds with one stone' solution would change everything - particularly if we can integrate it with solar and wind farms.\"A process like this would allow you to consume extra electricity when it's available to make and store as ethanol,\" Rondinone said. \"This could help to balance a grid supplied by intermittent renewable sources.\"The results have been published in\u00a0ChemistrySelec"
        ]
    },
    "5891": {
        "gold_standard": [
            "Historical Biology Scientists have discovered the remains of a mysterious, car-sized shark, which swam the coastlines of the Atlantic and Pacific oceans around 20 million years ago.The newly discovered species is a relative of the super-predator megalodon\u00a0(pictured above), and an ancient ancestor of today's great white sharks - but there's a 45-million-year gap in the fossil record before this new species appeared, leaving a lot of unanswered questions about how the shark evolved, and how long it survived.\n\"The fact that such a large \u2026 shark with such a wide geographic distribution had evaded recognition until now indicates just how little we still know about the Earth's ancient marine ecosystem,\" lead researcher Kenshu Shimada from DePaul University in Chicago told Laura Geggel from Live Science.The new species has been named\u00a0Megalolamna paradoxodon - putting it in a brand new genus of its own. The species name paradoxodon\u00a0refers to the fact that the shark emerged so suddenly in the geological record, after appearing to have split from its closest relative,\u00a0Otodus, around 45 million years earlier.So far, only five of the species' 5-cm-long (2-inch) teeth have been found in California, North Carolina, Japan, and Peru - covering most coastlines of the Pacific and Atlantic oceans.Based on these remains, the researchers estimate that the shark grew to around 3.7 metres (12 feet) long, making it significantly smaller than its relative, megalodon, which is thought to have reached a humungous 18 metres (59 feet) in length, and lived from\u00a023 to\u00a02.6 million years ago.\nBut\u00a0Megalolamna paradoxodon\u00a0was still large enough to have feasted on medium-sized fish, and would have been just slightly smaller than today's great white sharks, according to the researchers.You can see its distribution and the teeth remains below:Kenshu ShimadaWhat sets the new species apart are these strange teeth, which look similar to the teeth of modern sharks - belonging to the genus\u00a0Lamna -\u00a0with a few key differences.\"At first glance, teeth of\u00a0Megalolamna paradoxodon\u00a0look like gigantic teeth of the genus\u00a0Lamna, that includes the modern porbeagle and salmon sharks,\" Shimada told Live Science.\n\"However, the fossil teeth are too robust for\u00a0Lamna - it shows a mosaic of dental features reminiscent of the genus\u00a0Otodus. So, we determined it to be a species new to science\u00a0that belongs to the family Otodontidae with no direct relationship with\u00a0Lamna.\"These teeth would have been perfect for grabbing and slicing prey, Shimada adds.More importantly, the discovery impacts our understanding of the shark family tree. In the past, megalodon had been (somewhat contentiously) classified as belongning to the genus\u00a0Carcharocles,\u00a0which is part of the extinct Otodontidae family.But seeing as megalodon and\u00a0Megalolamna paradoxodon are so closely related, the researchers argue that megalodon should actually be put into the genus\u00a0Otodus, to reflect its true place in the evolutionary oath of sharks.\n\"The idea that megalodon and its close allies should be placed in\u00a0Otodus\u00a0is not new, but our study is the first of its kind that logically demonstrates the taxonomic proposition,\" Shimada said in a press release. \"Thus it should be referred to as\u00a0Otodus megalodon\u00a0from now on,\" he added.Further research is now needed to confirm this new classification of megalodon - the shark with a bite more powerful than\u00a0Tyrannosaurus rex's -\u00a0but it's fascinating to know that there was a close relative of the giant mega-predator swimming across most of the globe around 20 million years ago.\u00a0We're looking forward to finding out more about the elusive\u00a0Megalolamna paradoxodon,\u00a0including when and how it disappeared, as more remains are discovered.The research has been published in\u00a0Historical Biolog"
        ]
    },
    "5928": {
        "gold_standard": [
            "Last year, a massive 583-square-kilometre (225-square-mile) chunk of the Pine Island Glacier - a vast section of ice that holds the West Antarctic ice sheet together - broke free, heading out into the ocean to eventually melt and raise sea levels across the world.\nNow, new evidence from satellite imagery suggests that this break was caused by a rupture in the shelf 32 kilometres (20 miles) inland, indicating that the glacier is actually breaking apart from the inside, and not the periphery, as scientists had long suspected. And even worse - a second inland rift is now reportedly forming.You can see another of these inland rifts in the image at the top of the page. This new rift has formed in the centre of the Pine Island Glacier over the past few months, indicating a worrying trend.Researchers are now faced with predicting how massive shedding events like this will affect global\u00a0sea levels in the future, which is crucial, when you consider that roughly half of the world's population lives near a coastline.\"It's generally accepted that it's no longer a question of whether the West Antarctic ice sheet will melt, it's a question of when,\"\u00a0says researcher Ian Howat\u00a0from Ohio State University.\n\"This kind of rifting behaviour provides another mechanism for rapid retreat of these glaciers, adding to the probability that we may see significant collapse of West Antarctica in our lifetimes.\"So how does an ice shelf form a rift so far inland?Well, it's quite simple: warm ocean water seeps into a crevasse inside the ice shelf, heating it up from underneath. Over time, this warm water cuts away more and more ice, working its way up into the hidden crevasse until it cuts a huge chunk of the sheet free.\"Rifts usually form at the margins of an ice shelf, where the ice is thin and subject to shearing that rips it apart.\u00a0However, this latest event in the Pine Island Glacier was due to a rift that originated from the centre of the ice shelf and propagated out to the margins,\" Howat explains.\n\"This implies that something weakened the centre of the ice shelf, with the most likely explanation being a crevasse melted out at the bedrock level by a warming ocean.\"This hypothesis is backed up by the fact that Howat's team found that the rift opened up inside one of the sheet's valleys.These valleys, which are dips where parts of the ice sheet lie lower than sea level, allow warm water to reach further inland underneath it, causing indentations to form on the surface as ice melts below.\"The really troubling thing is that there are many of these valleys further up-glacier,\" Howat said. \"If they are actually sites of weakness that are prone to rifting, we could potentially see more accelerated ice loss in Antarctica.\"The team was able to come to their conclusions thanks to data collected by the Landsat 8 satellite\u00a0-\u00a0a joint project between NASA and the US Geological Survey, launched in 2013 to monitor changes on Earth's surface.\nUsing this data, they were able to look for signs of the break that happened in 2015 - before the event occurred - coming across the rift formation in the process.The team's discovery is crucial to our understanding of how the world's ice sheets are melting as our planet gets warmer and warmer.According to the team, about half of the world's fresh water is locked in Antarctica and the Pine Island Glacier.Along with its 'twin' - the Thwaites Glacier - these two glaciers are vital to keeping all this water trapped, because they block ice streams from the outer ocean.This means that if both - or really, just one - gives way, a bunch of that trapped ice will drift out into warmer ocean waters where it will melt.You can picture this by imagining a cup of water with a big ice cube on top of it - big enough to touch the water inside but too large to actually fit inside the glass's rim.\nIf this ice should melt, the water it releases will enter the glass, causing the water level to rise. This process happens a whole lot faster if the ice is broken up before it drops down, helping it to melt even quicker.In real life, if that Antarctic 'ice cube' melts into our oceans, sea levels would rise an expected 3 metres (10 feet) across the globe, endangering many coastal cities like New York and Miami.\"We need to understand exactly how these valleys and rifts form, and what they mean for\u00a0ice shelf\u00a0stability,\" Howat explains.\u00a0\"We're limited in what information we can get from space, so this will mean targeting air and field campaigns to collect more detailed observations.\"If the melting of the West Antarctic ice sheet really is an inevitability, we'll just have to hope that we can manage the consequences for life on Earth.\u00a0The team's work was published in Geophysical Research Letters"
        ]
    },
    "5970": {
        "gold_standard": [
            "Clinical Implant Dentistry and Related Research Researchers in Italy have found a 400-year-old dental prosthesis that consists of five teeth from different individuals \u2013 set in the wrong order \u2013 held together with gold.\nWhile that sounds pretty disturbing \u2013 after all, who wants someone else's teeth in their mouth? \u2013 the false teeth were remarkably advanced for the time, employing gold band technology to hold the wonky set together for the duration of the owner's life.Even though early sketches of similar types of dentures have been found dating as far back as the 7th century BC, this is one of the oldest and most complete set of false teeth researchers have ever found.The teeth were found inside the monastery of San Francesco in Lucca, Italy, which houses two large stone tombs that hold the remains of the Guinigis family \u2013 an extremely powerful and influential family who ruled the city in the early-1400s.Since the tomb contains roughly 100 sets of human remains, the team was unable to find which jaw the false teeth belonged to, making it difficult to accurately date the artefact.\nBut based on rock layer analysis, they think the false teeth were created and worn sometime in the 1600s.Many of the people buried in the tomb, who reportedly lived over the ripe old age of 40, had dental issues that, in today's world, would warrant tooth extraction and false teeth.\"Among the aristocratic Guinigis, the presence of cavities, periodontitis, and missing teeth was more than double compared to the Tuscan rural population,\" team leader Simona Minozzi from the University of Pisa\u00a0told Rossella Lorenzi at Discovery News.So, how did 17th-century dentists even make such a devise? Well, step one is finding some spare teeth.But besides knowing that the teeth came from different individuals, no one is quite sure how they were harvested.The prosthesis consisted of three central incisors and two lateral canines, which all had their root apex cut off, removing the part that actually grow of the jaw, leaving only the visible part of the tooth for the device.\n\"The teeth were then aligned and a subtle golden lamina was inserted into the fissure,\" the team writes.\u00a0\"Micro-CT scan revealed the presence of two small golden pins inserted into each tooth crossing the root and fixing the teeth to the internal gold band.\"Simona MinozziOnce inserted into the wearer's mouth, the device was held in place by two S-shaped tips and string that firmly kept the teeth from constantly falling out.Though the device seems extremely primitive given the dental technology employed today, it's the only device found from the time period that uses a gold band to keep everything together, something that, before now, researchers only found written evidence of.\n\"Although there are descriptions of similar objects in texts from the period, there is no known archaeological evidence,\" they write.\"The dentures found in the tomb are the first example of dentures from this historical period, and as such are a valuable addition to the history of dentistry.\"The team also found that the teeth and gold band had calculus deposits \u2013 better known as tartar \u2013 on them, suggesting that the person who used them had them for quite a long time.The find shows just how far dentistry has come over the last couple of hundred years, and while a remarkable number of us still fear getting even routine procedures done, we should all be thankful that we know we're never going to leave the dentist office with someone else's teeth in our mouths.The team's work was published in Clinical Implant Dentistry and Related Researc"
        ]
    },
    "5998": {
        "gold_standard": [
            "The International Journal of Nautical Archaeology You're probably familiar with the legend of\u00a0Atlantis\u00a0-\u00a0the allegorical city dreamt up by Plato that was lost to the sea - but have you heard of the very real British town of\u00a0Dunwich?\nYep, there's a submerged city off the coast of the UK, which has been sinking since the 1200s. In some areas, the town of Dunwich has sunk up to 10 metres under the North Sea.So how did this happen? The story of Dunwich has to do with\u00a0coastal erosion\u00a0-\u00a0a natural process where waves slowly eat away at dune sediment, eventually creating a new shoreline.If you were to hop into a time machine and teleport back, you'd find Dunwich to be the booming\u00a0capital of East Anglia\u00a0with a harbour that rivalled London's in traffic. It also had a coastline\u00a02,000 metres\u00a0(6,562 feet) further out than if you were to visit the area today.The coast first started eroding\u00a0on New Year's Eve\u00a0back in 1286,\u00a0when a series of storms hit the town, blocking off the mouth of the nearby Dunwich River with sediment, and creating a perpetual flood.\nOver time, the water continued to rise, eventually putting the entire town under 3 to 10 metres (9.8 to 33 feet) of water. Nowadays, the remaining town contains only a handful of streets, a museum, and a pub. The rest is hidden under the waves.David Barrie/FlickrDespite the medieval section of the town lying under a just few metres of water, researchers have had a tough time studying it, thanks to low visibility.But the good news is that,\u00a0back in 2013, a team of researchers from Southampton University were able to make an accurate map of the lost town using acoustic mapping.\"Visibility under the water at Dunwich is very poor due to the muddy water. This has limited the exploration of the site,\"\u00a0said team leader David Sear.\n\"We have now dived on the site using high-resolution DIDSON acoustic imaging to examine the ruins on the seabed - a first use of this technology for non-wreck marine archaeology. DIDSON technology is rather like shining a torch onto the seabed, only using sound instead of light.\"Using this technology, the team was able to come up with a detailed map, which shows how the city would have looked in its prime:Southampton UniversityWhile it's awesome to learn more about the archaeology of lost towns, Dunwich in particular reveals coastal change has affected humanity long before modern day global warming.\"Global climate change has made coastal erosion a topical issue in the 21st century, but Dunwich demonstrates that it has happened before,\" Sear explains.\n\"The severe storms of the 13th and 14th centuries coincided with a period of climate change, turning the warmer medieval climatic optimum into what we call the Little Ice Age.\"Understanding how this happens is vitally important, especially given that today's rising oceans affect nearly\u00a0half of the world's population\u00a0living on or near coasts.It also offers a chance to see how the citizens would have\u00a0coped with the changes over time.\u00a0For Dunwich in particular, it seems that the events triggered a series of economic decisions that eventually led to people abandoning the city.As Sear puts it:\n\"Our coastlines have always been changing, and communities have struggled to live with this change. Dunwich reminds us that it is not only the big storms and their frequency - coming one after another, that drives erosion and flooding, but also the social and economic decisions communities make at the coast.\nIn the end, with the harbour silting up, the town partly destroyed, and falling market incomes, many people simply gave up on Dunwich.\"\nHopefully, as researchers like Sear and his time continue to explore, map, and study towns like Dunwich, we will learn more about the populations that used to live there, giving us a better understanding of how to handle similar situations in modern times.The Southampton University team's work was published in\u00a0The International Journal of Nautical Archaeolog"
        ]
    },
    "6039": {
        "gold_standard": [
            "There's thought to be at least 1 million tonnes' worth of chemical weapons littering the ocean floor \u2013 the buried legacy of two World Wars \u2013 and scientists have warned it's likely to pose a \"significant threat\" to marine life.\nThe risk is due to the metal on these dumped munitions rusting away, releasing the chemicals they contain, and poisoning underwater ecosystems. Of course, that's going to affect anyone who relies on these ecosystems, which means pretty much all of us.Scientists from across Europe, supported by NATO's Science for Peace and Security (SPS) program, have worked for three years to set up monitoring equipment and collect data in the Baltic Sea.Their research \u2013 called the Monitoring of Dumped Munitions (MODUM) project\u00a0\u2013 is\u00a0intended to work out just how dangerous these chemical spillages could be, using a combination of Autonomous Underwater Vehicles (AUVs) and\u00a0Remotely Operated Underwater Vehicles (ROVs).With the data already collected, the researchers will evaluate the status of habitats in the region, conduct studies of fish health, and run computer modelling on possible threats to nearby areas.\nPart of the challenge is we're not sure where a lot these chemicals actually are. Many were dumped into the ocean at the end of World War II in bomb casings, artillery shells, and barrels, but nobody made detailed records of what went where, and it was often done in secret.And while some countries specifically looked for the deepest water they could find, with US chemicals despatched in areas with a minimum depth of 1,800 metres (5,906 feet),\u00a0others weren't so careful: the Soviets unloaded around 15,000 tonnes of material in the Baltic Sea, which has a maximum depth of only 459 metres (1,506 feet).In total, the NATO experts think that\u00a0there are about 50,000 tonnes of chemical weapons in the Baltic, and they say if just a sixth of that leaks, the underwater habitat in the area could be ruined for a century.Right now, scientists aren't sure exactly how these chemicals will leak, or the ultimate effects they'll have.\nBut previous studies published in Environmental Science & Technology in 2010 and Clinical Toxicology in 2015 both concluded that the risk to marine life and humans is real and needs a lot more\u00a0investigation, which is what MODUM hopes to provide.While we wait on more findings, the danger is already starting to surface, with reports of mustard gas washing up off the coast of Delaware in recent years.Then there's the scary tale of a group of Polish fishermen in 1997. As described by Andrew Curry at Hakai magazine,\u00a0after pulling a chunk of frozen mustard gas from the water, four of the crew had to be hospitalised with burns and blisters.Disposing of these kinds of harmful chemicals in the ocean has been illegal\u00a0since 1972,\u00a0thanks to the London Convention, but the MODUM team have their work cut out for them in addressing the dumping that took place in the decades before.Let's hope their research can come up with solutions before more people, animals, and ecosystems are put at serious risk.\"It's a global problem,\" Terrance Long, chair of the International Dialogue on Underwater Munitions (IDUM), told\u00a0Hakai. \"It's not regional, and it's not isolated."
        ]
    },
    "6066": {
        "gold_standard": [
            "Life is a series of addictions and without them we die.\"\u00a0This is my favourite quote in academic addiction literature and was made back in 1990 in the British Journal of Addiction, by Isaac Marks.\nThis deliberately provocative and controversial statement was made to stimulate debate about whether excessive and potentially problematic activities such as gambling, sex and work really can be classed as genuine addictions.Many of us might say to ourselves that we are 'addicted'\u00a0to tea, coffee, work or chocolate, or know others who we might describe as being 'hooked'\u00a0on television or using pornography. But do these assumptions have any basis in fact?The issue all comes down to how addiction is defined in the first place \u2013 as many of us in the field disagree on what the core components of addiction actually are. Many would argue that the words \"addiction\" and \"addictive\" are used so much in everyday circumstances that they have become meaningless.For instance, saying that a book is an \"addictive read\" or that a specific television series is \"addictive viewing\" renders the word useless in a clinical setting. Here, the word \"addictive\" is arguably used in a positive way and as such it devalues its real meaning.\nHealthy enthusiasm \u2026 or real problem?The question I get asked most \u2013 particularly by the broadcast media \u2013 is what is the difference between a healthy excessive enthusiasm and an addiction?My response is simple: a healthy excessive enthusiasm adds to life, whereas an addiction takes away from it.I also believe that to be classed as an addiction, any such behaviour should comprise a number of key components, including overriding preoccupation with the behaviour, conflict with other activities and relationships, withdrawal symptoms when unable to engage in the activity, an increase in the behaviour over time (tolerance), and use of the behaviour to alter mood state.Other consequences, such as feeling out of control with the behaviour and cravings for the behaviour are often present.If all these signs and symptoms are present then I would call the behaviour a true addiction. But that hasn't stopped others accusing me of watering down the concept of addiction.\nThe science of addictionA few years ago, Steve Sussman, Nadra Lisha and I published a review examining the relationship between 11 potentially addictive behaviours reported in the academic literature: smoking tobacco, drinking alcohol, taking illicit drugs, eating, gambling, internet use, love, sex, exercise, work and shopping.We examined the data from 83 large-scale studies and reported a prevalence of an addiction among US adults ranged from as low as 15 percent to as high as 61 percent in a 12-month period.We also reported it plausible that 47 percent of the US adult population suffers from maladaptive signs of an addictive disorder over a 12-month period and that it may be useful to think of addictions as due to problems of lifestyle as well as to person-level factors.In short \u2013 and with many caveats \u2013 our paper argued that at any one time almost half the US population is addicted to one or more behaviours.\nThere is a lot of scientific literature showing that having one addiction increases the propensity to have other addictions.For instance, in my own research, I have come across alcoholic pathological gamblers \u2013 and we can all probably think of people we might describe as caffeine-addicted workaholics.It is also common for people who give up one addiction to replace it with another (which we psychologists call \"reciprocity\").This is easily understandable as when a person gives up one addiction it leaves a void in the person's life and often the only activities that can fill the void and give similar experiences are other potentially addictive behaviours.This has led many people to describe such people as having an \"addictive personality\".Addictive personalities?While there are many pre-disposing factors for addictive behaviour, including genes and personality traits, such as high neuroticism (anxious, unhappy, prone to negative emotions) and low conscientiousness (impulsive, careless, disorganised), addictive personality is a myt"
        ]
    },
    "6068": {
        "gold_standard": [
            "Scientists have discovered that the Australian continent is shifting back and forth several millimetres every year, because of changes to Earth's centre of mass.In fact, this centre of mass is changing every single season, which means the entire Australian continent is moving its position slightly twice a year.\nEarlier this year, researchers confirmed that Australia had moved 1.5 metres north over the past 22 years due to tectonic shifts, and the government will be officially updating the country's latitude and longitude to reflect the change.But the new study shows that, in addition to this gradual northward drift, the continent is regularly wiggling back and forth throughout the year, because of changes to Earth's centre of mass.The centre of mass is the average position of the mass of an object, and for Earth, it lies roughly at the centre of the planet's molten core - around 6,000 kilometres (3,700 miles) below the surface.But it's not always in the same place - as the distribution of water changes across Earth's surface from summer to winter, the planet's centre of mass also shifts a few millimetres in different direction.\nThat slight shift in centre of mass affects all continents very slightly, but because of its position between Europe and the South Pacific Ocean, Australia moves the most, the team explains.\u00a0\"[Water] migrates every season,\" said lead researcher Shin-Chan Han, from the University of Newcastle in Australia. \"That motion causes quite a detectable, sizeable deformation in Australia.\"To figure out how much the continent was moving, Han and his team monitored changes in the locations of 14 land-based GPS stations across Australia, which can pick up changes in land position of less than 1 millimetre.They then compared their results with satellite data on Earth's gravitational pull throughout the year, which allowed them to measure where water was across the planet.What the team found was that every Northern Hemisphere winter (Australian summer) - when snowpack in the Northern Hemisphere is at its peaks - the weight of all that frozen water is strong enough to move Earth's centre of mass a few millimetres closer to Europe.\nThat causes the Australian\u00a0continent to move northwest by about 1 millimetre, and its northwestern edge to tilt downwards by 2 to 3 millimetres, while the southeastern edge lifts up the same amount.During Northern Hemisphere summer (Australian winter), the opposite occurs as all that ice returns to the atmosphere through evaporation.Shin-Chan HanThe shift is too subtle to be felt - this is all pretty minuscule stuff over the scale of an entire continent.But it's a significant enough change to affect satellite measurements, and the team suggests that GPS measurements are likely a millimetre or two off in Australia already.\nThat might not sound like a big deal, but is when we rely on GPS measurements to track things like rising sea levels, or self-driving cars.The team is now hoping they can use their research to make GPS more accurate.\u00a0\"If our [GPS] station has some systematic distortion - deformation - it will impact our precise positioning calculation,\" said Han. \"So we need to know any systematic bias in our station to better understand our position.\"The results have been published in\u00a0The Journal of Geophysical Research, and need to be replicated by independent teams before we make any major changes to GPS.But other researchers are already excited about the new approach, which can be used to double check other planetary measurements - and should also work on other continents.\"This new way of determining the Earth's [centre of mass] \u2026 is a new and novel approach and will be taken up by others,\" said Richard Gross, a researcher at NASA's Jet Propulsion Laboratory in Pasadena, California, who wasn't involved with the stud"
        ]
    },
    "6111": {
        "gold_standard": [
            "Researchers have finally confirmed a decades-old set of rules that describes strange shifts in space and time, known as continuous phase transitions.These aren't the traditional phase transitions we learnt about in high school, where solids transform into liquids, or liquids to gas. In continuous phase transitions, tiny, quantum defects are formed, where some matter is stuck between regions in distinct states. And now, for the first time, physicists can actually explain how that works.\nThat's important, because even though we can't see these continuous phase transitions happening around us, they play a huge role in the shifts and evolution of physical systems.One of the best examples of a continuous phase transition is the spontaneous symmetry breaking in the early Universe - when many of the unique properties of our Universe, such as time and matter, arose.Without that continuous phase transition, which occurred across both space and time, we wouldn't be here today.But understanding the principles of these continuous phase transitions won't just help us better understand how the Universe first formed, it will also help us understand the behaviour of materials on the quantum level - because this new research confirms for the first time that both processes are controlled by the same set of rules.\nThose rules are the Kibble-Zurek mechanism\u00a0(KZM), which was first proposed in 1976, but has never been demonstrated until now.The reason those rules are so important is because the defects formed by these continuous phase transitions are crucial cosmological phenomena such as domain walls, cosmic strings, and textures. The KZM predicts how these defects will form in space and time when a physical system goes through a continuous phase transition.And now we finally know that it works.\"We study phase transitions because it is one of the most fundamental questions that puzzle us,\" said one of the researchers, Cheng Chin, from the University of Chicago.\"What is the origin of the complex structure of the Universe, how do imperfections emerge and how do identical materials develop distinct properties over time?\"\nChin and his team were able to provide the first clear demonstration of the KZM by observing a continuous phase transition in gaseous caesium atoms cooled down to temperatures near absolute zero.Using a laser, the researchers created an optical lattice that lined up the atoms in patterns. They then used sound waves to shake the optical lattice and drive the atoms across a continuous, ferromagnetic quantum phase transition.This caused each atom to divide into different domains with either positive or negative momentum, and the faster the structure was shaken, the smaller the domains were.Impressively, the team found that the resulting structure was consistent with what the KSM would have predicted all the way back in 1976.This suggests that these KSM 'rules' for how matter will behave across space time during a continuous phase transition will be applicable to all physical systems - whether that's caesium gas atoms or the early Univers"
        ]
    },
    "6145": {
        "gold_standard": [
            "Humans arrived in the arid interior of Australia some 10,000 years earlier than we thought, archaeologists suggest, with the discovery of ancient artefacts in a South Australian cave that have been dated to as far back as 49,000 years ago.\nThat means once humans first set foot on the Australian coastline, it took a mere 1,000 years for them to expand out into its dry interior - further evidence of the ingenuity of what now stands as the oldest continuous civilisation on Earth.The site, which is a newly discovered cave in the Flinders Ranges, about 550 km north of Adelaide, is known as the Warratyi rock-shelter.\u00a0Archaeologist Giles Hamm from La Trobe University in Melbourne led the excavations at the cave, finding what appear to be some of the oldest bone and quartz tools ever found in Australia, plus the earliest known use of the pigment ochre in the country's history.\u00a0Artefacts that have been found so far include burnt eggshells, sharpened stone and bone tools, red ochre and gypsum pigments, and the team says this is evidence that these early technologies were developed locally.\n\"The old idea is that people might have come from the East, from the Levant, out of Africa, and these modern humans may have come with a package of innovative technologies,\" Hamm told Nicola Davis at The Guardian.\u00a0\"But the development of these fine stone tools, the bone technology, we think that happened as a local innovation, due to a local cultural evolution.\"That's significant, adds one of the team, Gavin Prideaux from Flinders University in Adelaide, because it challenges certain assumptions that Indigenous Australians were not as innovative as similar populations elsewhere in on the globe.\"There is a Eurocentric view that material culture in Australia is quite simplistic and backward, but this helps rewrite that story,\" he told ABC News.Until now, the oldest human tool found in Australia's vast, arid interior has been a tiny axe fragment found earlier this year in the Carpenter's Gap rock-shelter of the Kimberley region of northwest Australia.\nWhile the Carpenter's Gap site is not far from the northwest coast of Australia - thought to be one of the earliest settled parts of Australia - the Warratyi rock-shelter sits more than 2,000 km from the early settlement of Lake Mungo in southeasten New South Wales, making it a much more difficult trek.The tools have been dated based on a couple of estimates - quartz grains from the site have been dated to 44,000 years ago, but radiocarbon dating of the burnt eggshells, which are thought to be evidence of human cooking, revealed them to be between 45,000 and 49,000 years old.The shells are thought to have come from emus and a large, extinct flightless bird from the Genyornis genus. Together with discovery of bones of a huge, extinct wombat-like species, Diprotodon optatum, this suggests that early humans were actually interacting with Australia's legendary megafauna.Diprotodon reconstruction. Credit: Dmitry Bogdanov/WikimediaThis doesn't necessarily mean they were hunting them, but they were at least living in close enough quarters that they could find bones and eggs and bring them back to the cave.\n\"One good thing about this study \u2026 is there's no doubt there are megafauna remains in the form of Diprotodon and a giant bird in that rock shelter in a well-dated, well-stratified context sometime between 45,000 and 50,000 years ago,\" Prideaux told the ABC.\"The only way those bones and shells got there is because people brought them there \u2026 in terms of megafauna that's the really significant finding.\"The find is, of course, controversial, because that tiny axe fragment we mentioned earlier has been dated to around the same time period - 44,000 to 49,000 years ago. The problem is these estimates are all fairly rough, and still up for interpretation - Hamm's team, for example, insists that the axe is no more than 48,000 years old.\"[E]veryone is keen to make their site sound older,\"\u00a0Sue O'Connor from the Australian National University, who was not involved in either find, told Marcus Strom at The Sydney Morning Herald.\u00a0But she did add that\u00a0\"the Hamm discovery was likely older\""
        ]
    },
    "6180": {
        "gold_standard": [
            "A lot of people will have already made up their mind about whether humans need dairy in their diet and will be thinking that the answer is obviously \"yes\" or obviously \"no\". But nutrition is based on science not opinion \u2013 so, here's the latest research on the matter.\nMilk is an interesting foodstuff. The sugar in it is called lactose and lactose requires a chemical or enzyme called lactase to allow it to pass across the walls of the gut into the blood stream.When we are babies, we all produce plenty of the lactase enzyme which allows us to absorb our mother's milk.In populations where milk consumption has been historically low, such as Japan and China, most children will have stopped producing lactase soon after weaning and \u2013 producing almost entire populations that may be unable to absorb the lactose in milk \u2013 this we call \"lactose intolerance\".In populations where milk consumption has always been high, such as in Europe, most adults continue to produce lactase for their whole lives and can digest milk quite happily with only around 5 percent of the population being lactose intolerant.\nContinuing to produce lactase into adulthood is actually an inherited genetic variation which has become so common because being able to tolerate milk has a selective advantage.Milk is a useful source of protein, energy, calcium, phosphate, B vitamins and iodine, meaning that those with the mutation were generally healthier and produced more children than those who couldn't tolerate milk, and so the presence of the mutation increased.The symptoms of lactose intolerance include wind, bloating and diarrhoea so if you don't experience any of those after drinking milk or eating ice cream then you're fine.FermentingKefir 'grains' after straining.\u00a0A. Kniesel/WikipediaThere is good evidence that milk has been part of the human diet in Northern Europe for more than 8,000 years which is when people there first moved from being nomadic to having a more structured way of life.\nBecause 8,000 years ago most people didn't tolerate milk well, they quickly realised that if the milk was fermented and became cheese or yogurt it could be better tolerated.This is because these processes encourage bacteria to use up most of the carbohydrate - the lactose - in the milk so people who didn't produce the lactase enzyme could still benefit from the nutrients in the milk.Today people with lactose intolerance can drink kefir, a fermented milk drink made with a yeast starter, which some suggest also has probiotic benefits for the gut as well as many other health benefits.So dairy has been pivotal to nutrition and important to the survival of many populations in the world and most Europeans and North Americans are well adapted to digest it.So if you have been told that humans aren't adapted to have dairy in their diet, that isn't correct. Similarly, it isn't true to say that dairy promotes inflammation or acidity.\nCalciumNutritional scientists and dietitians have often assumed that because milk is rich in calcium, it is therefore good for maintaining the calcium levels in our bones.However, a couple of recent big studies have brought this into question. A further systematic review of the evidence concluded that actually, it doesn't seem to matter how much calcium you get from your diet, your risk of fracturing your bones remains the same.That said, we have seen that in cultures, where dairy plays a very minimal part in the traditional diet such as in China and Japan, the incidence of hip fracture \u2013 a common outcome of poor bone mineral density \u2013 is 150 percent higher than that of white American or European populations.One thing to remember about these studies is that they are looking at calcium intake in adulthood. However, we know that the strength of our bones is actually determined by our diet as children and teenager"
        ]
    },
    "6206": {
        "gold_standard": [
            "Proceedings of the National Academy of Sciences Global cheetah (Acinonyx jubatus) populations have crashed, putting the world's fastest land animal on the brink of extinction, according to an international team of researchers.\nThe team found that a mere 7,100 cheetah are left in the wild, with the species being driven out of 91 percent of its historic habitat. Populations in Asia have suffered the most, leaving only a small pocket of 50 cheetahs left in Iran, while the\u00a0majority of the global population is now spread across six countries in southern Africa.\"Our findings show that the large space requirements for cheetah, coupled with the complex range of threats faced by the species in the wild, mean that it is likely to be much more vulnerable to extinction than was previously thought,\"\u00a0said lead author Sarah Durant\u00a0from the Zoological Society of London (ZSL).The team, led by researchers from the Zoological Society of London (ZSL), the Wildlife Conservation Society (WCS), and big cat research organisation Panthera, says the animals will face extinction if further conservation efforts are not taken.It's hoped that their study will prompt the International Union for Conservation of Nature (IUCN) to upgrade the cheetah conservation status from \"vulnerable\" to \"endangered\".\n\"This study represents the most comprehensive analysis of cheetah status to date,\"\u00a0said Durant.\u00a0\"Given the secretive nature of this elusive cat, it has been difficult to gather hard information on the species, leading to its plight being overlooked.\"What makes cheetah so hard to protect is its range - being the fastest land animal, cheetahs maintain a very wide range for hunting prey.According to the team, roughly 77 percent of a cheetah's habitat would be outside the world's protected zones, making it difficult to keep them safe from poachers and other dangers.It also makes it a lot harder to monitor how well the species is doing. With such a large range, population studies have been few and far between, which is why the dramatic population decline is only just coming to light.\nThis problem is further compounded by the fact that human pressures have also led to a steep decline in cheetah prey.\u00a0The researchers say that's how Zimbabwe's cheetah population dropped from 1,200 animals to just 170 over the course of 16 years - an 85 percent loss.\"In many areas, there's overhunting, which leads to a loss of prey - and if there's no prey, there can be no cheetah,\"\u00a0Durant told Ed Yong at The Atlantic.\"If there are no alternatives, cheetah occasionally take livestock, leading to retaliation. There's a live trade in cheetah in the Horn of Africa, with captive animals heading towards the Gulf States.\"So, how did the team come up with these figures?They started by gathering existing data from protected parks and other areas around the world.\u00a0This data is incomplete because it's only from protected areas - and\u00a0cheetahs typically extend much further than these reserves - so the team also analysed data from unprotected regions.\nWith this information, they pieced together how the species' population has changed over the years, finding that cheetahs now only live in just 9 percent of their historical habitats.One of the most abundant cheetah zones stretches through six countries in southern Africa, with nearly half of the world's population -\u00a0about 4,000 adults and adolescents.The rest, reports Yong, are found in small pockets around the world, such as one in Iran, where there are just 50 individuals in total.The team also developed a computer model, which estimated that if the world's population of cheetah\u00a0declined by 10 percent per year, over 50 percent of the total cheetah population would likely be gone by 15 years.Based on these findings, the team is calling for action, asking governments and the IUCN to up the status of the species from \"vulnerable\" to \"endangered\" to allow for more comprehensive conservation efforts.\n\"We've just hit the reset button in our understanding of how close cheetahs are to extinction. The takeaway from this pinnacle study is that securing protected areas alone is not enough,\"\u00a0said Kim Young-Overton\u00a0from Panthera.\"We must think bigger, conserving across the mosaic of protected and unprotected landscapes that these far-ranging cats inhabit, if we are to avert the otherwise certain loss of the\u00a0cheetah\u00a0forever.\"The team notes that their methods will allow for the study of other threatened species that have been overlooked because of their long range, such as African wild dogs.Hopefully, the new report will help spur more rigorous conservation efforts for cheetahs before we lose even more of the dwindling population, but only time will tell.The research was published in Proceedings of the National Academy of Science"
        ]
    },
    "6210": {
        "gold_standard": [
            "Advanced Materials Inspired by the comic book character Wolverine, scientists have developed a self-healing, highly stretchable, transparent material that can be used to power artificial muscles.\nThe end product is a soft, rubber-like material that's easy to produce at low cost. It can stretch to 50 times its original length, and can heal itself from a scissor cut in the space of 24 hours at room temperature.Just 5 minutes after being cut, the material can stretch to two times its original length again \u2013 not a bad power for a comic book superhero to have.The material is also an ionic conductor - capable of conducting electricity through the flow of ions - and this is the first time scientists have combined self-healing properties in an ionic conductor.The team from the University of California, Riverside and the University of Colorado says it could ultimately be used in robotics, electronic devices, batteries, and biosensors.\"Creating a material with all these properties has been a puzzle for years,\" says researcher and lifelong Wolverine fan, Chao Wang\u00a0from UC Riverside.\n\"We did that and now are just beginning to explore the applications.\"Wang says his love for Wolverine helped inspire his interest in self-healing materials, which mimic materials seen in nature, and can help extend the lifetime and lower the cost of man-made materials and devices.UC RiversideWhile transparent and stretchable ionic conductors have been developed before, adding self-healing properties has proved tricky \u2013 to get a material to self-heal, you usually need non-covalent bonds between the individual molecules, which can't share electrons.Passing electricity through these bonds degrades them, which is a problem if you're trying to keep your self-healing material capable of self-healing.\nTo find a solution, Wang used ion-dipole interactions to hold the molecules together, which combine charged ions with polar molecules \u2013 where one end of the molecule has a positive charge and the other a negative.The small electrical imbalance in both these types of molecule creates an electrostatic attraction between them.So by mixing a high-ionic-strength salt to a stretchable polar polymer, Wang and his colleagues were able to produce a material with the properties they needed.The researchers used two layers of the new material, with a transparent membrane in between, to create an artificial muscle prototype. It could move in response to electrical signals, in the same way a human muscle moves in response to a signal from the brain.It's still early days for the material, but its unique combination of properties could make next-generation electronic devices and robots more resilient than ever, even if it's too late to get it fitted to Hugh Jackman's knuckles.\nThe research has been published in Advanced Material"
        ]
    },
    "6227": {
        "gold_standard": [
            "Advanced Materials Technologies Scientists have developed a bacteria-powered battery on a single piece of paper, which they say could be a cheap and easily manufactured power source for medical sensors in remote and developing areas.\nThe paper battery, which is foldable, is the latest example of what are known as bio-batteries, which store power generated by organic compounds. In this case, the power is generated by common bacteria found in wastewater.The paper-based design is part of a new field of research called papertronics, which like the name suggests, is a fusion of paper and electronics.The simple components needed to make these kinds of paper-based electronics should be easy to come by in remote parts of the world, which could make them a reliable backup in places where grid electricity or conventional batteries aren't available.Seokheun \"Sean\" Choi\"Papertronics have recently emerged as a simple and low-cost way to power disposable point-of-care diagnostic sensors,\" says engineer Seokheun \"Sean\" Choi from Binghamton University.\nTo make their battery, the researchers laid a ribbon of silver nitrate on a piece of chromatography paper. On top of this, they placed a thin layer of wax to create a cathode \u2013 the battery's positive electrode.On the other side of the paper, the team made a reservoir out of a conductive polymer, which acts an anode (negative electrode), once filled with a few drops of the bacteria-containing wastewater liquid.When the paper is folded so that the cathode and anode come into contact, the battery is powered by the bacterial metabolism, also known as cellular respiration.It's not the first time researchers have experimented with malleable or unconventional battery designs.Last year, a team from the US and China showed off an origami-style lithium-ion battery that incorporated 'soft creases' so that it can stretch and retract.\nMonths later, researchers in Sweden developed something called \"power paper\" \u2013 a sheet made of cellulose and polymer that's able to store energy.And just last month, scientists in the UK unveiled a battery design inspired by the human intestine.Their lithium-sulphur battery emulates the finger-like protrusions in the human gut called villi, to resist degradation by catching sulphur fragments that break off over time.In terms of the new paper battery, the amount of power output depends on how much paper you have and how it's stacked and folded. As you can see in the image above, each foldable sheet of paper contains a number of the small, square-shaped batteries laid out in a grid.In the researchers' testing, they were able to generate 31.51 microwatts at 125.53 microamps with six batteries (three batteries in a row, folded onto another three), and 44.85 microwatts at 105.89 microamps in (six batteries, folded onto another three).\nThe researchers acknowledge that performance is variable depending on any misalignment of, or gaps between, the paper layers, and say a lot more work needs to be done to get more current out of the device.Right now, it would take millions of the paper batteries to generate enough power for a 40-watt light bulb, so this kind of technology probably isn't going to be a solution for powering conventional electronics any time soon. \u00a0But as it stands, the researchers say the battery is already powerful enough to run simple biosensors for things like monitoring glucose levels in diabetes patients or detecting pathogens in patients, which could help bring urgent medical aid to people who need assistance in places without electric power.\"Among many flexible and integrative paper-based batteries with a large upside, paper-based microbial fuel cell technology is arguably the most underdeveloped,\" says Choi.\"We are excited about this because microorganisms can harvest electrical power from any type of biodegradable source, like wastewater, that is readily available. I believe this type of paper bio-battery can be a future power source for papertronics.\"The findings are reported in Advanced Materials Technologie"
        ]
    },
    "6636": {
        "gold_standard": [
            "If you're after a DIY project to tackle this weekend, what about making your own sonic tractor beam, and controlling objects through the power of sound waves?Thanks to instructions put together by computer scientist Asier Marzo, you can do just that, as long as you're prepared to do a little bit of soldering, screwing, and sawing along the way.\nMarzo, a research assistant at the University of Bristol in the UK, was part of the team that invented the first working single-sided sonic tractor beam in 2015: a hand-held device able to move objects around in the air with no physical contact.Now he's put together a simplified version that anyone can have a go at making. It's not expensive or difficult to do either, as long as you've got access to a 3D printer and some electronic components.\"Previously we developed a tractor beam, but it was very complicated and pricey because it required a phase array, which is a complex electronic system,\" says Marzo. \"[Now we've] made a simple, static tractor beam that only requires a static piece of matter.\"Moving objects imprecisely with sound isn't difficult, as you'll know if you've ever stood next to a very loud speaker: sound moves as a series of vibrations through air or some other physical medium.\nBut what makes a tractor beam special is it surrounds points of low acoustic pressure with high-intensity sound that's too high-pitched for the human ear to hear, trapping objects in a kind of sound cage.Originally the stuff of science fiction, tractor beams are now being looked at for everything from 3D displays to new kinds of medical procedures \u2013 such as moving a kidney stone without making an incision.Scientists have also tried moving objects with waves of light as well as sound, but for the time being the first real-life tractor beams are working at very small scales.This new version of the sonic tractor beam uses the internal shape of a 3D-printed cone and its inner tubes to shape the sound waves. In fact, getting the device into a form simple enough for a 3D printer to cope with was one of the biggest challenges for the team.\n\"We needed to engineer the tubes very well to allow them to be 3D-printed with a normal 3D printer,\" Marzo says. \"A normal 3D printer has a lot of limitations.\"As well as access to a 3D printer, you're also going to need an Arduino Nano, a mesh of 30 transducers, and various bits of electronics to make this happen at home, but Marzo says you can source all the materials for less than \u00a350 (about US$60).The tweaks made to the design mean the homemade version isn't as versatile in terms of the type of sonic traps it creates, and it can only move objects up and down. Still it's a fantastic achievement to cut down the device's complexity and cost, and Marzo is keen to see more science projects opened up like this.\"We would like to continue this trend of making our research open access and releasing step-by-step videos of how to reproduce it,\" Marzo told Maarten Rikken at ResearchGate.\n\"We think there is great value in making science accessible so that everyone can take part in it.\"There's a YouTube video, step-by-step instructions and an open access paper published in Applied Physics Letters if you want to have a go at this awesome projec"
        ]
    },
    "6597": {
        "gold_standard": [
            "The intense gravitational forces at the heart of supermassive black holes generate intense light shows that are among the brightest things ever seen in the Universe \u2013 but that doesn't necessarily mean we can always see them, even when they're close to home.\nNew research has confirmed the existence of two supermassive black holes in nearby galaxies, previously hidden by clouds of gas and dust that obscured the high-energy fireworks resulting from cosmic matter being drawn into their voids.\"These black holes are relatively close to the Milky Way, but they have remained hidden from us until now,\" says researcher Ady Annuar from Durham University in the UK, one of a team that investigated a black hole at the centre of a galaxy called NGC 1448.\"They're like monsters hiding under your bed.\"Supermassive black holes are actually invisible to us, because they emit no light, but as matter falls over their event horizon boundary, it heats up and produces radiation that can be observed across the electromagnetic spectrum.IC 3639. Credit: NASA/JPL-Caltech/ESO/STScIThis process, which occurs at what's called the active galactic nucleus \u2013 the core of a galaxy containing a supermassive black hole \u2013 puts on a brilliant display that can be detected from billions of light-years away, but only if the conditions are favourable.The problem is that most active nuclei are thought to be surrounded by a doughnut-shaped cloud of thick gas and dust that blocks much of the light emissions from getting out. If you've got a vantage point to look into the hole of the doughnut, you'll see an incredible light show \u2013 but when viewed from the side, you might not catch anything at all.\n\"Just as we can't see the Sun on a cloudy day, we can't directly see how bright these active galactic nuclei really are because of all of the gas and dust surrounding the central engine,\" says Peter Boorman from the University of Southampton in the UK, who led a separate study of a black hole in a galaxy called IC 3639.\"As the level of obscuration increases, only the highest energy X-rays can escape to be observed by us,\" he adds.The new findings were made possible by NASA's NuSTAR (Nuclear Spectroscopic Telescope Array) \u2013 a space-based X-ray telescope.Using NuSTAR, Boorman's team measured high-energy X-ray emissions coming from IC 3639 \u2013 a galaxy some 170 million light-years from Earth, but which is relatively close, considering the Universe is thought to measure approximately 45 billion light-years across.\nIC 3639 has previously been observed by NASA's Chandra X-ray Observatory and Japan's Suzaku satellite, but the new NuSTAR data are the first to confirm that the galaxy actually contains an active galactic nucleus.\"The black hole [in IC 3639] is so hidden, that it requires highly sensitive observations in the highest energy X-rays to classify it as obscured,\" says Boorman, whose findings were published in The Astrophysical Journal.\"IC 3639 turns out to be glowing extremely bright due to emission from hot Iron atoms whose origin is not fully understood.\"In a separate study, Annuar's team also used NuSTAR to examine a supermassive black hole that's even closer to Earth, at a distance of 38 million light-years away \u2013 which is still about 360 trillion kilometres (223 trillion miles) from us, so there's no need to panic.\nThe study has been published on pre-print website arXiv.org ahead of peer-review, and was presented at the American Astronomical Society meeting in Texas last week.The discoveries help us to understand more about supermassive black holes and the composition of the matter that surrounds them \u2013 which is important to stuff to know, especially since that material can also hide them from our view.Boorman's team now intends to a begin new NuSTAR survey to help determine the distribution of obscured active galactic nuclei across the Universe \u2013 meaning there could be some new surprises in our cosmic backyard before long.\"[These] recent discoveries certainly call out the question of how many other supermassive black holes we are still missing,\" says Annuar, \"even in our nearby Universe"
        ]
    },
    "6626": {
        "gold_standard": [
            "Advanced Materials After five years of work, scientists in the UK have found a way to create synthetic spider silk that's loaded with antibiotic properties, and could help deliver drugs and close open wounds with a decreased risk of infection.\nThe new material takes silk, which is synthesised from E. coli bacteria, and adheres molecules to its structure, infusing it with different substances that make for a better bandage.\"Our technique allows the rapid generation of biocompatible, mono or multi-functionalised silk structures for use in a wide range of applications,\"\u00a0said corresponding author Neil Thomas, from the University of Nottingham.\"These will be particularly useful in the fields of tissue engineering and biomedicine.\"While it might seem odd, spider silk is actually a pretty incredible material when it comes to first aid. It's biocompatible, biodegradable, protein-based, and it isn't known to cause any sort of immune, inflammatory or allergic reactions.The team says that using spider silk as wound dressing goes all the way back to the time of the ancient Greeks and Romans, who used the material to dress the wounds of soldiers to stop bleeding.\nThis process usually involved soldiers using a honey-vinegar mixture as an antiseptic to keep the wound clean, and then wrapping it in wads of spider silk to keep it safe.The team basically took this idea and modernised it with new technology. Instead of using real spider silk, they made their own by synthesising strands from E. coli bacteria in the lab.Once they had that procedure down pat, they discovered that they could 'decorate' the silk by covering it with antibiotic levofloxacin, a drug commonly used for treating bacterial infections.To pull that off, the molecules are 'clicked' into place inside a solution of synthesised spider silk before the proteins are turned into the actual strands.The best way to envision this is to think of a ball of yarn. Before it's individual strands, yarn is just a bunch of fibres. In that phase, before it is spun into strands, you can add extra materials or dyes. Then, when that's all done, you can make it into actual yarn with those added properties.\nThe team is doing the exact same thing but on a much smaller, more scientific level by binding antibiotics to the raw materials needed to spin synthetic spider silk, creating an infusion of silk and antibiotics.The funny thing is that the team came together by chance. Five years ago, the team's leaders \u2013 Neil Thomas and Sara Goodacre, both from the University of Nottingham \u2013 met at an event when Goodacre prompted an audience to help her make spider silk.\"At the end of the session Neil came up to me and said 'I think my group could make that',\"\u00a0Goodacre recounts.\"He also suggested that there might be more interesting 'tweaks' one could make so that the silk could be 'decorated' with different, useful, compounds either permanently or which could be released over time due to a change in the acidity of the environment.\"\nFrom that moment on, the team worked together to come up with ways to make the spider silk and the potential bandage of the future, eventually coming to the antibiotic-laced version of the material that they have today.\"It is likely that this paper is just the start of a very exciting range of studies using the new\u00a0spider silk\u00a0material,\"\u00a0Goodacre said.The team's work has been published in Advanced Material"
        ]
    },
    "6883": {
        "gold_standard": [
            "(Heinrich Frank) Researchers have found several colossal burrows in South America that are so huge and neatly constructed, you'd be forgiven for thinking humans dug them as a passageway through the forest.\nTurns out, they're far more ancient than they look, estimated to be at least 8,000 to 10,000 years old, and no known geologic process can explain them. But then there's the massive claw marks that line the walls and ceilings - it's now thought that an extinct species of giant ground sloth is behind at least some of these so-called palaeoburrows.\"I didn't know there was such a thing as palaeoburrows,\" lead researcher behind the latest study, Heinrich Frank from the Federal University of Rio Grande do Sul in Brazil,\u00a0told Andrew Jenner at Discover.\u00a0\"I'm a geologist, a professor, and I'd never even heard of them.\"Researchers have known about these tunnels since at least the 1930s, but back then, they were considered to be some kind of archaeological structure - remains of caves carved out by our ancient ancestors, perhaps.\nFast-forward to 2010, when geologist Amilcar Adamy from the Brazilian Geological Survey decided to investigate rumours of a peculiar cave in the state of Rondonia, to the north-west of the country.Amilcar AdamyThe structure was huge, and according to Jenner, it's still the largest known palaeoburrow in the Amazon, and is twice the size of the second largest palaeburrow in Brazil.\u00a0Adamy had gone to investigate the tunnel, determined to attribute it to some kind of geologic process, but once he saw it with his own eyes, he couldn't think of any natural process that would create such a deliberate-looking structure.\n\"I'd never seen anything like it before,\"\u00a0Adamy told Jenner. \"It really grabbed my attention. It didn't look natural.\"A few years later, Frank found his own strange cave, thousands of kilometres away in the\u00a0town of Novo Hamburgo. Once he knew what to look for, he found hundreds of them scattered across the Brazilian landscape.\u00a0There are now more than 1,500 known palaeoburrows that have been found in southern and southeastern Brazil alone, and there appear to be two different types: the smaller ones, that reach up to 1.5 metres in diameter; and the bigger ones, that can stretch up to 2 metres in height and 4 metres in width.It wasn't until Frank started climbing inside them that he realised the extent of these tunnels, which can extend for up to 100 metres,\u00a0and occasionally branch off into separate chambers.\nWhen he looked up at the ceiling, he got his first big clue about what could be behind their construction - distinctive grooves in the weathered granite, basalt, and sandstone surfaces, which he's identified as the claw marks of a massive, ancient creature.\"Most consist of long, shallow grooves parallel to each other, grouped and apparently produced by two or three claws,\" Frank and his team explained in a 2016 paper.\"These grooves are mostly smooth, but some irregular ones may have been produced by broken claws.\"Heinrich Frank\u00a0The discovery seemed to answer one of the long-standing questions in palaeontology regarding the ancient megafauna that roamed the planet during the Pleistocene epoch, from about 2.5 million years ago to 11,700 years ago: Where were all the burrows?As Frank and his colleagues explain, it's estimated that about half of the mammalian species on Earth right now are classified as semi-fossorial - meaning they spend some time inside burrows, but have to go outside to feed.\nAround 3.5 percent of living species are completely fossorial, which means they spend all their lives underground.Considering all the world's species have evolved from more ancient versions of themselves, it stands to reason that similar proportions of fossorial and semi-fossorial species would have existed around the time of the Pleistocene megafauna.But despite the abundance of fossilised remains proving the existence of these creatures, for centuries, researchers could not identify any evidence of burrows - something that was likely a combination of burrows collapsing over thousands of years, and researchers not knowing what to look for.Based on the size of the structures and the claw marks left in their walls, researchers are now confident that they've found the megafauna burrows, and have narrowed down the owners to giant ground sloths and giant armadillos.\n\"There's no geological process in the world that produces long tunnels with a circular or elliptical cross-section, which branch and rise and fall, with claw marks on the walls,\" Frank told Discover. \"I've [also] seen dozens of caves that have inorganic origins, and in these cases, it's very clear that digging animals had no role in their creation.\"Below is a summary of how the various tunnel diameters match up to known species of ancient armadillos and sloths:Renato Pereira Lopes et. al.The researchers suspect that the biggest palaeoburrows were dug by humungous South American ground sloths from the extinct Lestodon genus.But despite these creatures stretching up to 4.6 metres (15 feet) and weighing roughly 2,590 kg (5,709 pounds), a single ground sloth would have spent much of its lifespan dedicated entirely to constructing tunnels as large and extensive as the palaeoburrows are.\u00a0And why bother? Frank and his team aren't sure if the extensive caverns were used to escape the climate, predators, or humidity, but told Jenner at Discover\u00a0that all of these explanations seem unlikely, as a much smaller burrow would have suited those purposes just fine.It could be that several individuals inherited the burrows over generations, and kept adding to the structure to make it enormous, but that's something the researchers will need to confirm with further observations.With so many questions left to answer, let's just appreciate the fact that the sheer scale of things so 10,000 years ago was ridiculous, and we really just want a time machine so we can curl up with a giant sloth in its Narnia-esque\u00a0mansion.\u00a0The paper has been published in Ichno"
        ]
    },
    "6898": {
        "gold_standard": [
            "The relationship between mind, brain, and body has kept philosophers and scientists busy for centuries. Some of the first interesting \u2013 albeit gruesome \u2013 experiments on the role of the body in human consciousness considered life after decapitation. In 1905, French physician Gabriel Beaurieux believed he had communicated with prisoner Henri Languille after his head had been severed from his body.\nWriting of the experience, Beaurieux said:\n\"I called in a strong, sharp voice: 'Languille!' I saw the eyelids slowly lift up, without any spasmodic contractions \u2013 I insist advisedly on this peculiarity \u2013 but with an even movement, quite distinct and normal, such as happens in everyday life, with people awakened or torn from their thoughts.\"\nAlmost two decades later, Soviet scientist Sergei Brukhonenko reportedly kept a dog's severed head alive for nearly six months using a primitive heart-lung machine.Video footage allegedly shows the head responding to light, sound and citric acid stimuli.But while Brukhonenko's research may have been an important in the development of cardiac surgery \u2013 it is more often regarded as faked Soviet-era propaganda. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Consciousness and non-physical properties\nInvestigations into human consciousness have moved on since these initial observations \u2013 though we haven't got away from decapitation just yet. More recently, however, neuroscientists have questioned just how it is that physical matter comes together to make the mind.In 1995, Francis Crick wrote in\u00a0The Astonishing Hypothesis that we are nothing more than an \"immensely complex collection of neurons\".This hypothesis is a form of reductive physicalism \u2013 a philosophical position to which modern neuroscience typically subscribes \u2013 that everything in existence is no more than its physical properties.Again using animal decapitation, though this time with rats, neuroscientists have explored the question of how long brain activity is observed after death \u2013 a step forward from just consciousness.\nIn a 2011 experiment, it was reported that decapitated rats' time to unconsciousness \u2013 defined by a decrease in cognitive activity of 50 percent \u2013 was 4 seconds.The researchers also observed a very large and much later slow wave in brain activity. This was interpreted as what they called a \"wave of death\" \u2013 when all the brain's neurons died at the same time \u2013 and perhaps, the ultimate border between life and death.But some believe that the mind is more than just the sum of its physical brain cells. A contrasting position to physicalism is the dualist assumption that the physical and the mental are fundamentally different substances.Furthermore, some philosophers and scientists have suggested that \"information may be the key to consciousness\".Consistent with this idea is integrated information theory, which accepts the existence of consciousness, but controversially implies that anything at all may be conscious \u2013 even a smartphone \u2013 if it possesses a sufficiently high \"phi\": a measure of information in a system which cannot be reduced to that specified by its parts.\nFrom psychological moments to mortalityWhile I have left out many important details in this fascinating discussion, better understanding the link between mind, brain and body has been the focus of my own research, in recent years through looking at the functions of the vagus nerve.Higher vagus nerve function (measured and indexed by heart rate variability) supports a person's capacity for emotion regulation, social engagement and cognitive function.By contrast, impaired vagal function \u2013 and lower heart rate variability \u2013 may play a role in the onset of depression.But the vagus nerve doesn't just affect the mind. Higher levels of vagal function may lead to improved glucose regulation, reduced inflammation, and reduced risk of disease and death.Vagal function is also known to play an important role in brain cognition. It helps to suppress irrelevant and interfering stimuli.\nStudies have also suggested that the vagus nerve might play an important regulatory role over inflammatory processes, contributing to diabetes, obesity and cardiovascular disease \u2013 all of which also impact on cognitive function.However, little research has been done which looks at how the vagus nerve affects body and mind together.That's why I teamed up with colleagues to question whether previously reported relationships between vagal function and cognitive performance could be explained through a single neurological-psychological-physiological pathway.Supporting this possibility, we observed that impairment in vagal function appears to increase insulin resistance, which contributes to a thickening of the carotid arteries, which in turn adversely impacts on cognitive function.This means that low vagal function initiates a cascade of adverse downstream effects which subsequently lead to cognitive impairmen",
            "The relationship between mind, brain, and body has kept philosophers and scientists busy for centuries. Some of the first interesting \u2013 albeit gruesome \u2013 experiments on the role of the body in human consciousness considered life after decapitation. In 1905, French physician Gabriel Beaurieux believed he had communicated with prisoner Henri Languille after his head had been severed from his body.\nWriting of the experience, Beaurieux said:\n\"I called in a strong, sharp voice: 'Languille!' I saw the eyelids slowly lift up, without any spasmodic contractions \u2013 I insist advisedly on this peculiarity \u2013 but with an even movement, quite distinct and normal, such as happens in everyday life, with people awakened or torn from their thoughts.\"\nAlmost two decades later, Soviet scientist Sergei Brukhonenko reportedly kept a dog's severed head alive for nearly six months using a primitive heart-lung machine.Video footage allegedly shows the head responding to light, sound and citric acid stimuli.But while Brukhonenko's research may have been an important in the development of cardiac surgery \u2013 it is more often regarded as faked Soviet-era propaganda. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Consciousness and non-physical properties\nInvestigations into human consciousness have moved on since these initial observations \u2013 though we haven't got away from decapitation just yet. More recently, however, neuroscientists have questioned just how it is that physical matter comes together to make the mind.In 1995, Francis Crick wrote in\u00a0The Astonishing Hypothesis that we are nothing more than an \"immensely complex collection of neurons\".This hypothesis is a form of reductive physicalism \u2013 a philosophical position to which modern neuroscience typically subscribes \u2013 that everything in existence is no more than its physical properties.Again using animal decapitation, though this time with rats, neuroscientists have explored the question of how long brain activity is observed after death \u2013 a step forward from just consciousness.\nIn a 2011 experiment, it was reported that decapitated rats' time to unconsciousness \u2013 defined by a decrease in cognitive activity of 50 percent \u2013 was 4 seconds.The researchers also observed a very large and much later slow wave in brain activity. This was interpreted as what they called a \"wave of death\" \u2013 when all the brain's neurons died at the same time \u2013 and perhaps, the ultimate border between life and death.But some believe that the mind is more than just the sum of its physical brain cells. A contrasting position to physicalism is the dualist assumption that the physical and the mental are fundamentally different substances.Furthermore, some philosophers and scientists have suggested that \"information may be the key to consciousness\".Consistent with this idea is integrated information theory, which accepts the existence of consciousness, but controversially implies that anything at all may be conscious \u2013 even a smartphone \u2013 if it possesses a sufficiently high \"phi\": a measure of information in a system which cannot be reduced to that specified by its parts.\nFrom psychological moments to mortalityWhile I have left out many important details in this fascinating discussion, better understanding the link between mind, brain and body has been the focus of my own research, in recent years through looking at the functions of the vagus nerve.Higher vagus nerve function (measured and indexed by heart rate variability) supports a person's capacity for emotion regulation, social engagement and cognitive function.By contrast, impaired vagal function \u2013 and lower heart rate variability \u2013 may play a role in the onset of depression.But the vagus nerve doesn't just affect the mind. Higher levels of vagal function may lead to improved glucose regulation, reduced inflammation, and reduced risk of disease and death.Vagal function is also known to play an important role in brain cognition. It helps to suppress irrelevant and interfering stimuli"
        ]
    },
    "7053": {
        "gold_standard": [
            "Alexander Graham Bell made his name as the inventor of the world's first practical telephone, but his genius wasn't just limited to revolutionary inventions. He not only predicted today's looming energy crisis - he also offered up a solution complete with solar panels and biofuel.\nTurns out, in a 1917 article written for National Geographic magazine, Bell made an eerily accurate prediction about our unbridled use of fossil fuels, and later speculated that Earth would become a \"hot-house\".According to a biography co-written by Bell's great-grandson, Edwin S. Grosvenor, a handful of scientists were discussing the potential global effects of air pollution more than a century ago, and Bell bucked the trend with his \"hot-house\" predictions.\"The few scientists who thought about [air pollution in 1917] were convinced that dirtier air would mean that the climate would cool as the Sun's warming rays were blocked. Bell reasoned differently,\" Grosvenor and co-author Morgan Wessen wrote in 1977.\"While we would lose some of the Sun's heat,\" Bell is quoted as saying, \"we could gain some of Earth's heat, which is normally radiated into space.\"\n\"I am inclined to think we would have some kind of greenhouse effect. \u2026 The net result is that the greenhouse becomes a hot-house.\"Bell's been credited as having coined the phrase \"greenhouse effect\", but it appears to have been used almost a decade before these musings, by English physicist John Henry Poynting.In 1909, he refers to the \"blanketing effect\" of air pollution as \"'greenhouse effect' of the atmosphere\", and while his scientific musings were quickly dismissed, the phrase caught on, appearing in several journal articles in the early 1900s.Fast-forward to 1917, and Bell was asked to address to the graduating class of the McKinley Manual Training School in Washington, DC, where he took the opportunity to air a multitude of problems facing the world at that moment, such as how to take a warm bath at 2am, and \"Could postage stamps be used in transportation of persons?\"\nThe speech was revised for an edition of\u00a0National Geographic magazine later that year, and in it, he also considered the challenges faced by a world that progressed \"from candles to electricity in one lifetime\", predicting that we would not stop using coal and oil until the supplies literally dried up.\"Coal and oil are going up and are strictly limited in quantity. We can take coal out of a mine, but we can never put it back. We can draw oil from subterranean reservoirs, but we can never refill them again,\" he said.\"In relation to coal and oil, the world's annual consumption has become so enormous that we are now actually within measurable distance of the end of the supply. What shall we do when we have no more coal or oil!\"One of the OG proponents of renewables, Bell touts tidal and wave power, \"which we have not yet learned to utilise\", and \"the employment of the Sun's rays directly as a source of power\""
        ]
    },
    "7494": {
        "gold_standard": [
            "Don't let the fact that the objects known as Prince Rupert's drops are made out of glass fool you \u2013 the pretty, tear-drop shaped baubles can withstand some pretty harsh punishment. Until you gently snap their tail, at least.\nNew research has literally shed a light on the drops' odd balance of incredible strength and fragility, revealing it all comes down to a thin skin of glass held under incredible tension.A team of researchers led by scientists from the US and UK used a beam of polarised light to measure the internal properties of the glass drops to show how a tough outer skin and the channelling of cracks make for a paradoxical object that is as tough as it is brittle.Prince Rupert's drops are relatively simple to make; they're little more than molten glass dropped into cold water, creating a solid blob with a long, thin tail.Smacking the fat end with a hammer, pressing it with up to\u00a020 tons of force, or even shooting it\u00a0with a gun\u00a0won't do it a lot of damage.To break it, however, you only need to tap its tail, which will cause the entire object to disintegrate into a shower of tiny shards.\nThere aren't any records on the drops' origins, but sometime around 1660 Prince Rupert of the Rhine reportedly gave a number of 'glass bubbles' to King Charles II of England as gifts, who passed them on to the Royal Society of London to conduct a few studies of their own.The drops' remarkable properties were put down to the rapid cooling of the outer surface of the glass, forming a hard shell that allowed the insides to cool and then contract a little slower.It was this difference in layers \u2013 the 'squeezing' (or compressive forces) of the outer layer and the 'pulling' (or tensile forces) of the core \u2013 that was thought to explain both its toughness and fragile tail.New toys in the laboratory have allowed physicists over time to find new ways to test Prince Rupert's drops, and in 1994 materials scientists Srinivasan Chandrasekar from Purdue University and M. Munawar Chaudhri from the University of Cambridge in the UK did what any of us would do with a high speed camera and a glass object \u2013 watch it shatter.\nTheir research added more detail to the traditional explanation \u2013 breaking the tail appears to send a line of cracks running down the length of the drop at speeds of up to 1,900 m/s (6,200ft/s), with the crack-front slowing down as it enters the surface layer.They also measured the toughness and size of the surface layer, finding it extended about 15 percent of the way into their experiment's drops and had a compressive stress of 90 to 170 MPa (about 13,000 to 25,000 psi).In this latest experiment, the researchers put the drop under a different set of tests and recalculated their previous estimates, discovering in the process that the secret to Prince Rupert's drop lies in more than just the toughness of its extraordinary skin.This time the scientists lowered a drop into a liquid with the same refractive index as the glass.\nShining a polarised beam of red light through the liquid and the drop caused the light's rays to distort slightly inside the glass, revealing even more details about its characteristics.The process showed much higher compressive stresses in the surface of the glass drops, of\u00a0around 525 MPa (76,000 psi) in the head and a whopping 700 MPa (102,000 psi) in the tail.They also determined the surface layer to be about 10 percent of the diameter of the drop's head.This high compressive stress in the thin outer layer of the glass drops goes some way to explain why they can withstand such enormous forces, however there's one more piece of the puzzle.Based on their past experiments and their investigation using polarised light, the team found that any cracks that did form in the surface layer tended to run parallel to the core.\n\"In order for a PRD [Prince Rupert's drop] to disintegrate catastrophically, it is necessary for any cracks, induced by the compression process, to enter the tension zone in the head of the PRD,\" the researchers explained in their report.That's why they're so easy to break at the tail end. Once a crack gets through the compressed skin into the zone that's held under tension, it's game over.If only the curious mob of Royal Society scholars had such fancy equipment sitting around 400 years ago, they might have nailed the secrets behind Prince Rupert's Drops much sooner.\"I believe we have now solved most of the main aspects of this area. However, new questions may emerge unexpectedly,\" Chaudhri told Lisa Zyga at Phys.org.Let's hope so \u2013 future scientists could use an excuse to break a few glass baubles themselves"
        ]
    },
    "7514": {
        "gold_standard": [
            "Pharmaceutical giant Johnson & Johnson has been ordered to pay out the largest amount yet in a series of lawsuits brought against it for not adequately warning against potential risks associated with the use of talcum powder.\nWhile the scientific consensus behind the claim is still undecided, a state court jury in St. Louis, Missouri, determined that there was enough evidence to find the global company was liable for a 62-year-old American woman's development of ovarian cancer.Lois Slemp was awarded a payout of $US5.4 million in compensation, with Johnson & Johnson being slugged with a further $US105 million in punitive damages.The manufacturer of the talc considered to have caused the cancer, Imerys Talc, was found to also hold a percentage of responsibility and ordered to pay $US50,000.Slemp's case has made headlines for its sizeable sum, but hers is just the latest in a series of cases against the company based on the allegation that Johnson & Johnson failed to warn people that using talcum powder near their genitals could cause ovarian cancer.\nIn early 2016, several months after plaintiff Jacqueline Fox passed away from ovarian cancer, Johnson & Johnson were required to pay $US72 million in punitive and actual damages to the Fox family.More than 3,000 cases against the company have been filed across the US by people who believe not only that toiletry products based on talcum powder raise the risk of women developing ovarian cancer, but that Johnson & Johnson know it.Not all of the plaintiff's cases have been successful, with Johnson & Johnson persuading a New Jersey court in 2016 to throw out two cases based on a lack of scientific evidence.\"The court's decision today appropriately reflects the science and facts at issue in this litigation,\" a spokeswoman for Johnson & Johnson, Carol Goodrich, said in a statement at the time.\n\"Science, research, clinical evidence and decades of studies by medical experts around the world continue to support the safety of cosmetic talc.\"While a number of juries might be convinced that Johnson & Johnson aren't behaving as ethically as it should, the research on the matter hasn't made a convincing case for the scientific community.Talc is a mineral made mostly of magnesium and silicates, often found underground in deposits mixed with small amounts of asbestos.While this sounds bad, ever since 1973, the asbestos is required to be removed long before it makes its way into plastic bottles to sprinkle on the parts of your (or your baby's) body you want to keep dry.Back in the early 1970s, tissue from patients with ovarian and cervical tumours was found to contain particles of talc, leading to speculation that there was a link between the use of the powder and the cancers.\nNearly half a century later - not to mention numerous studies\u00a0-\u00a0research on the matter both shows\u00a0and don't show a relationship between cancer and use of talcum powder.While the World Health Organisation's International Agency for Research on Cancer identifies talc that contains asbestos as carcinogenic, its official position on the asbestos-free product is \"not classifiable as to its carcinogenicity in humans\" if inhaled or dusted on your skin.On the other hand, they do concede that\u00a0if used on your 'undercarriage',\u00a0there is a possibility of it being carcinogenic based on their interpretation of the evidence.So where does that leave us? For day-to-day use, groups like the American Cancer Society say that if you're concerned, stop using it, but otherwise there really isn't much of a reason to believe it will significantly increase the risk of developing cancer"
        ]
    },
    "7521": {
        "gold_standard": [
            "Biology is really one big horror story. You don't need to look much further than the various types of parasites that drive their hosts into the mouths of hungry predators.If you're keeping track of these tiny monsters, you should know that there's a species of flatworm that parks itself inside the eyeball of a fish, and controls when its host hides from birds or exposes itself to be eaten - all to benefit its very complicated (and creepy) life cycle.\nA team led by the Severtsov Institute of Ecology and Evolution in Moscow, Russia found that a common parasite called an eye fluke, Diplostomum pseudospathaceum, evolved this rather gruesome way of navigating its way through its somewhat complex life cycle.The fluke relies on three different animals to develop from egg to adult:It mates in a bird's digestive tract, where the eggs pass into the water with the bird's faeces\nLarvae hatch from the eggs and seek out a freshwater snail to burrow into, where they mature and reproduce asexually\nThe next stage of larvae, free-swimming forms of the parasite called cercariae, leave the snail and then dig their way through a fish's hide for their final journey, which ends in the lens of the animal's eyeball in a stage called metacercariae\nA bird eats the fish, infected eyeballs and all, and the fun begins all over again.\nStudies had shown that the parasite can affect the host's vision, which was suspected to help the fluke by making it harder for the fish to detect predators.Researchers conducting this new study weren't convinced that there was a lot of evidence for this, so in 2015 they set out to study the behaviours of infected rainbow trout (Oncorhynchus mykiss) by dosing around 25 fish with immature flukes.While the trout usually swam less vigorously, a researcher tasked with catching them with a dip net \u2013 unaware of which fish were infected and which weren't \u2013 found the infected fish a little harder to catch.\nBoth of these behaviours would help the trout avoid being spotted and nabbed by a bird before the flukes had a chance to grow into sexually mature adults.While the host's behaviour clearly changed, it didn't seem to be due to any induced blindness.\"In our study, manipulations of the host behaviour arose when metacercariae were small and host vision impairment due to cataract formation was unlikely,\" they wrote in their 2015 paper.If the parasite was pulling any strings, it was through chemistry rather than simply blocking out the light inside their eyeball.Now, in their most recent study, the team noticed there were in fact two distinct forms of behaviour, most likely differentiated by changes in the maturity of the flukes.Once they'd moved through whatever the fluke equivalent of puberty is, it was game on - the researchers noticed that the trout became more active and moved closer to the surface.\nThey also found that while both infected and non-infected fish would freeze as the silhouette of a bird passed overhead, the infected ones started moving sooner.The evidence suggests that the fish are being manipulated by their tiny hitchhikers to avoid being eaten while young, and then head for the bird's gut when old enough to reproduce sexually.\"Our findings suggest that immature larvae of D. pseudospathaceum induce changes in host behaviour that can protect them from predation,\" the researchers wrote in their 2015 study.They now\u00a0add in this new paper that the more mature \"metacercariae can change rainbow trout's behavior predisposing them to avian predation\".Of course, eye flukes aren't the only nightmare fuel parasites out there.Toxoplasmosis gondii is a well-known single-celled parasite that infects rodents and turns them into suicidal cat-lovers, even long after the parasites have cleared out"
        ]
    },
    "7600": {
        "gold_standard": [
            "The Tropics are defined as the area of Earth where the Sun is directly overhead at least once a year - the zone between the Tropics of Cancer and Capricorn.However, tropical climates occur within a larger area about 30 degrees either side of the Equator. Earth's dry subtropical zones lie adjacent to this broad region. It is here that we find the great warm deserts of the world.\nEarth's bulging waistlineEarth's tropical atmosphere is growing in all directions, leading one commentator to cleverly call this Earth's \"bulging waistline\".Since 1979, the planet's waistline been expanding poleward by 56 kilometres to 111 kilometres per decade in both hemispheres.Future climate projections suggest this expansion is likely to continue, driven largely by human activities \u2013 most notably emissions of greenhouse gases and black carbon, as well as warming in the lower atmosphere and the oceans.If the current rate continues, by 2100 the edge of the new dry subtropical zone would extend from roughly Sydney to Perth.As these dry subtropical zones shift, droughts will worsen and overall less rain will fall in most warm temperate regions.Poleward shifts in the average tracks of tropical and extratropical cyclones are already happening. This is likely to continue as the tropics expand further.\nAs extratropical cyclones move, they shift rain away from temperate regions that historically rely upon winter rainfalls for their agriculture and water security.Researchers have observed that, as climate zones change, animals and plants migrate to keep up. But as biodiversity and ecosystem services are threatened, species that can't adjust to rapidly changing conditions face extinction.In some biodiversity hotspots \u2013 such as the far southwest of Australia \u2013 there are no suitable land areas (only oceans) for ecosystems and species to move into to keep pace with warming and drying trends.We are already witnessing an expansion of pests and diseases into regions that were previously climatically unsuitable. This suggests that they will attempt to follow any future poleward shifts in climate zones.I recently drew attention to the anticipated impacts of an expanding tropics for Africa. So what might this might mean for Australia?IPCCAustralia is vulnerable\nAustralia's geographical location makes it highly vulnerable to an expanding tropics. About 60 percent of the continent lies north of 30\u00b0S.As the edge of the dry subtropical zone continues to creep south, more of southern Australia will be subject to its drying effects.Meanwhile, the fringes of the north of the continent may experience rainfall and temperature conditions that are more typical of our northern neighbours.The effects of the expanding tropics are already being felt in southern Australia in the form of declining winter rainfall. This is especially the case in the southwest and - to a lesser extent - the continental southeast.Future climate change projections for Australia include increasing air and ocean temperatures, rising sea levels, more hot days (over 35\u2103), declining rainfall in the southern continental areas, and more extreme fire weather events"
        ]
    },
    "7640": {
        "gold_standard": [
            "ACS Nano Whether it's balancing on a blade of grass or taking on the appearance of frozen smoke, aerogels have been blowing us away with their amazing properties in recent years. And just when you thought they couldn't get any freakier, researchers have created a graphene aerogel that can support over 6,000 times its own weight.\nAlong with being super strong, the new aerographene is bendy, conductive, and mimics the structure of a plant stem. The unique properties of the material could make it an ideal component in flexible electronics such as smart windows, curved TV screens, and printable solar panels.Speaking with ScienceAlert, Hao Bai, a materials engineer from Zhejiang University, says the graphene aerogel is unique from other aerogels available.\u00a0\"Learning from nature always offers new insights for developing new materials and technology,\" says Bai. \"Our graphene aerogel is different from current aerogels in both microstructures and properties.\"Weighing a minuscule 0.16 milligrams per cubic centimetre, graphene aerogel is 7.5 times lighter than air and about 1000 times less dense than water. This stuff is so light that you can balance it on a fluffy dandelion head or on the stamen of a flower. Out of all the aerogels, graphene aerogel is the least dense and considered one of the lightest solid materials on Earth.\nApart from blowing our minds, aerogels are already proving useful for a wide variety of applications, from cleaning up oil spills to creating high-energy batteries. Researchers have even managed to convert sunlight into water vapour at room temperature using graphene aerogel, which makes it possible to turn wastewater into drinkable water.But when it comes to moving machine parts, flexible sensors, and bendable energy storage devices, researchers have struggled to create aerogels that have both the strength and resilience required for these applications.\"Strength and resilience are usually mutually exclusive in regular aerogels,\" Bai explains. \"There is a high demand for strong and resilient aerogels in many important fields, but it is very difficult to achieve both of these properties.\"In recent years, we've seen several attempts to achieve these properties in graphene aerogels, including through the use of 3D printing and freeze-drying. The problem with these processes is that they only produce graphene aerogels with a random architectural structure, which doesn't provide robust strength and resilience.\nLooking at the natural world, the secret to the strength and bendiness of porous materials like plant stems comes down to how the material is arranged at the nanoscale. Even if the material itself is weak and porous, the highly organised arrangement of the material makes it strong and flexible.\"Many natural materials have developed unprecedented properties by building complex multiscale architectures,\" Bai says. \"We wondered whether we could mimic these features to create an aerogel that is both strong and resilient.\"\u00a0To find out, Bai and his team turned to the powdery alligator-flag (Thalia dealbata), a hardy aquatic plant native to South America and Mexico. Even though the stem of this plant is slender and porous, it can withstand frequent wild winds thanks to its grid-like layered microstructure.Taking cues from the plant's complex structure, the team used bidirectional freezing to mimic its architecture in graphene aerogel.\nFirst, graphene oxide particles are dispersed in water, which form sheets as the liquid freezes.Once completely frozen, the graphene oxide sheets form a three-dimensional network similar to the structure of ice crystals.Finally, thermal reduction and sublimation produced graphene aerogel that mirrored the bridged layers of the powdery alligator-flag stem.Next, the team put the aerogel through a series of compression tests to see whether its architecture produced strength and resilience. After 1,000 compressive cycles the researchers discovered that the graphene aerogel was capable of supporting over 6,000 times its own weight and spring back to its original state. The material also retained 85 per cent of its strength before compression was applied.This is a significant jump from aerogels with a random architecture, which tend to retain just 45 per cent of their original strength after only 10 compressive cycles.\nAlthough the enormous strength and resilience of the aerogel is amazing all on its own, the researchers also wanted to know whether the material was conductive under compression.The team placed the aerogel in a circuit with an LED, and applied different compression strains. Sure enough, they found that the aerogel remained conductive even when compressed, indicating that it could play a role in flexible electronics and sensors.Now that the researchers have finally created a graphene aerogel that is strong, resilient and conductive, the next step is figuring out whether nature can be used as a reference for developing other kinds of aerogels, such as cellulose-based or polymer-silica composites.\"Learning from natural models will definitely help to develop new materials,\" Bao told ScienceAlert. \"The challenges still remain in how much we can discover and understand nature's secrets, and if we can really mimic nature with synthetic approaches.\"We can only dream of what nature will help us design next.The research was published in ACS Nan"
        ]
    },
    "7144": {
        "gold_standard": [
            "A new editorial denying the role of saturated fats in heart disease has sparked controversy and an angry backlash from experts in the field.The editorial states that a widely held belief that saturated fats clog up arteries, leading to coronary heart disease, is just \"plain wrong\".\nThe reason we're advised to avoid saturated fats is to do with blood cholesterol, the waxy stuff that can build up in your arteries. All cholesterol is not the same, though - there's a distinction between 'good' high-density lipoprotein (HDL) and 'bad' low-density lipoprotein (LDL) cholesterol.Standard advice goes\u00a0that if your diet has too much saturated fat - think junk food, cakes, processed foods, chips - LDL cholesterol can build up and increase your risk of heart disease.Now a hotly debated editorial is saying we should forget all that, and instead focus on exercising and eating \"real foods\".\"Decades of emphasis on the primacy of lowering plasma cholesterol, as if this was an end in itself and driving a market of 'proven to lower cholesterol' and 'low-fat' foods and medications, has been misguided,\" a team of three cardiologists writes in the latest issue of the British Journal of Sports Medicine.\nThe lead author of the editorial is controversial British cardiologist Aseem Malhotra, who has an established media profile in the UK as a proponent of high fat diets.In fact, just last year another report co-authored by Malhotra sparked outrage, as it gave people dietary recommendations in conflict with evidence-based guidelines put forward by other public health organisations.The report was authored on behalf of the UK's National Obesity Forum, and four members of the organisation resigned in the fallout, stating they had not been consulted before the report was released.\"Eat fat to get slim. Don't fear fat. Fat is your friend. It's now truly time to bring back the fat,\" Malhotra told the Press Association last year.Now his latest article is once again perpetuating that message, citing a \"landmark systematic review and meta-analysis of observational studies\", which showed no association between saturated fat intake and heart disease.\nBut it must be noted that observational studies are not really the most reliable type of evidence, as they don't establish causation, and it's hard to weed out possible bias.There is so much research on dietary fat and heart disease that it would be easy to cherry-pick the studies that support your particular conclusion.We do have solid evidence from clinical trials that cutting back on saturated fats in your diet reduces 'cardiovascular risk', such as heart disease and stroke.And even though it's false to think that saturated fats directly clog the arteries, experts say that's not even what health authorities are claiming.\"Where the article is most misleading is the description of the current paradigm,\" says cardiologist Garry Jennings, chief medical advisor of Australia's National Heart Foundation.\nJennings adds that the authors of the editorial present \"a mixture of truths, half-truths, and misconceptions\".\"There are a number of poor and discredited studies quoted to support the arguments presented and confusion between high total fat in the diet and high saturated fats,\" he says.Malhotra and colleagues conclude that evidence shows regular brisk walking is a good preventative measure of heart disease, and that it's important to address inflammation of the arteries instead of watching out for saturated fat which leads to high LDL cholesterol.\"People with high LDL cholesterol have more heart attacks,\" says Jennings. \"There is more to it than this but leaving LDL cholesterol out of the story is misleading.\"Physician David Sullivan from Royal Prince Alfred Hospital is also critical"
        ]
    },
    "7160": {
        "gold_standard": [
            "ACS Biomaterials Science and Engineering A new cartilage-like hydrogel material could make the job of repairing knees much easier, say scientists, as it's 3D printable and can be made as an exact fit for each individual knee.\nThe new research focuses on the two crucial shock absorbers inside the knee, known as the menisci, and replacing these parts of our bodies needs both the right material properties and the right shape.That's a challenge the scientists from Duke University have taken up, showing that a suitable hydrogel meniscus can be produced by a 3D printer costing US$300 in just a day.If that feat can be replicated on a larger scale, we're looking at simple and inexpensive knee repairs for what are usually complex and problematic injuries.\"We've made it very easy now for anyone to print something that is pretty close in its mechanical properties to cartilage, in a relatively simple and inexpensive process,\" says one of the researchers, Benjamin Wiley.Each of our knees has two ear-shaped menisci, sitting between the thigh and shin bones, and cushioning every step we take. If these supports get damaged, walking becomes painful and the risk of arthritis increases.\nWhen we reach adulthood, these menisci can't really heal themselves, and broken ones often have to be replaced by surgeons. The trouble is, today's implants aren't as strong or elastic as the real thing, or do nothing to aid healing around the knee.What's more, the meniscus is made up of two complementary layers \u2013 a stiff middle and a soft outer layer \u2013 which complicates attempts to develop something that can be 3D printed from just a single material.To get around this, scientists combined both a strong hydrogel and a stretchable hydrogel together to try and get a material as close to cartilage as possible. They also added a nanoparticle clay to make the substance runny under stress but quick to harden.\"The two networks are woven into each other,\" explains another of the team, Feichen Yang. \"And that makes the whole material extremely strong.\"\nScientists are warming up to the idea of using hydrogels like these as cartilage replacements, because they share certain properties: take a close look at either, and you'll see a web of long string-like molecules with water molecules wedged in between.Plus, as we know from other research, the beauty of 3D printing in medical health is that replacement body parts can be made to order, just the right size and shape for a patient, and that's particularly important here.\"Shape is a huge deal for the meniscus,\" says Wiley. \"This thing is under a lot of pressure, and if it doesn't fit you perfectly it could potentially slide out, or be debilitating or painful.\"3D printing process. Credit: Feichen YangThrough computer tomography (CT) or magnetic resonance imaging ( MRI) scans, doctors can work out how implants need to be designed and then feed that information into a 3D printer, as long as we have artificial materials that can do as good a job as natural ones.\nThe researchers admit it's early days for this \"young field\" of research, but the menisci demo shows the potential of hydrogels to simplify knee repairs.We now know it's possible to develop hydrogels with similar properties to cartilage that can also be manipulated with a budget 3D printer. With future study, printable materials even closer to human tissue could be developed.\"I hope that demonstrating the ease with which this can be done will help get a lot of other people interested in making more realistic printable hydrogels,\" says Wiley.The research has been printed in ACS Biomaterials Science and Engineerin"
        ]
    },
    "7390": {
        "gold_standard": [
            "Researchers have constructed the world's thinnest metallic nanowire, creating a stable string of the chemical element tellurium, that measures just one atom thick.The team behind the nanowire says the material is the most precisely configured 'one-dimensional' system yet, and the technique used to produce the one-atom-thick atomic chain could lead to new advances in materials science and electronics miniaturisation.\nWhile any structure based on elements from the periodic table actually occupies three dimensions in space, in the field of nano-scale materials such as nanowires, one-atom-thick structures are considered one-dimensional (1D) due to the arrangement of a single atom making up their height and width.To build their own one-dimensional nanowire, a team led by researchers from the University of Cambridge in the UK produced the tellurium string inside extremely thin carbon nanotubes, which are hollow cylinders made up of carbon atoms.According to the team, these nanotubes don't just provide a handy way of producing nanowires by confining the atomic string, but the enclosure provides a means of supporting the 1D structure inside them \u2013 and can also alter the tellurium's behaviour.One of the problems with creating 1D structures is they can be very unstable, as the atoms that make up the nanowire are in a state of constant vibration, which can see the string lose its form or disintegrate.\nBy encapsulating the chemical you're working with, you can get around this problem, as long as the constraining substance doesn't introduce any unwanted side-effects.\"When working with materials at very small scales such as this, the material of interest typically needs to be deposited onto a surface, but the problem is that these surfaces are normally very reactive,\" says one of the team, materials scientist Paulo Medeiros.\"But carbon nanotubes are chemically quite inert, so they help solve one of the problems when trying to create truly one-dimensional materials.\"Using carbon nanotubes with diameters ranging between 0.7 nanometres (nm) and 1.1 nm, the researchers were able to build tellurium nanowires approximately 10,000 times thinner than a human hair.They also discovered that the properties of the chemical changed depending on how tightly enclosed the tellurium was inside the nanotubes.\nTellurium is a metalloid, which means as far as chemical elements go, it exhibits both metal-like and non-metal-like properties.But when enclosed too tightly inside the nanotubes, it starts behaving more like a metal, and less like a semiconductor.Knowing that limit could help scientists to one day find 1D-thick materials that can be used as the basis for even smaller transistors than what's currently been achieved, and might even be able to keep Moore's Law alive \u2013 which predicts that the number of transistors on a microchip will double every two years.As for whether that will ultimately be possible, nobody knows for sure, but mastering the art of producing and manipulating 1D nanowires is likely to be our best shot at making it happen \u2013 although there's plenty of research to be done in the meantime.\"[W]e're just starting to understand the physics and chemistry of these systems,\" says Medeiros, \"there's still a lot of basic physics to be uncovered.\"The findings are reported in ACS Nano"
        ]
    },
    "7426": {
        "gold_standard": [
            "Scientists have discovered that being an only child doesn't just lead to behavioural differences that can set kids apart from those with siblings - it actually affects a child's brain development, too.\nA new study comparing brain scans of only children and others who grew up with siblings has revealed significant differences in the participants' grey matter volume, and researchers say it's the first neurological evidence in this area linking changes in brain structure to differing behaviours. \u00a0\u00a0To investigate if only children demonstrated neurological differences from their peers who grew up with brothers and sisters, researchers at Southwest University in China recruited 303 college-age students.The mix of young people in China offers a broad pool of candidates for this area of research, owing to the nation's long-lasting one-child policy, which limited many but not all families to only raising a single child in between 1979 and 2015.The common\u00a0stereotype\u00a0about being an only child is that growing up without siblings influences an individual's behaviour and personality traits, making them more selfish and less likely to share with their peers.\nPrevious research\u00a0has borne some of this conventional wisdom out - but also demonstrated that only children can receive\u00a0cognitive benefits\u00a0as a result of their solo upbringing.The participants in this latest study were approximately half only children (and half children with siblings), and were given cognitive tests designed to measure their intelligence, creativity, and personality, in addition to scanning their brains with MRI machines.Although the results didn't demonstrate any difference in terms of intelligence between the two groups, they did reveal that only children exhibited greater flexibility in their thinking - a key marker of creativity per the Torrance Tests of Creative Thinking.While only children showed greater flexibility, they also demonstrated less agreeableness in personality tests under what's called the Revised NEO Personality Inventory. Agreeableness is one of the five chief measures tested under the system, with the other four being extraversion, conscientiousness, neuroticism, and openness to experience.\nBut more importantly than the behavioural data - which have been the focus of many other studies - the MRI results actually demonstrated neurological differences in the participants' grey matter volume (GMV) as a result of their upbringing.In particular, the results showed that only children showed greater supramarginal gyrus volumes - a portion of the parietal lobe thought to be associated with language perception and processing, and which in the study correlated to the only children's greater flexibility.By contrast, the brains of only children revealed less volume in other areas, including the medial prefrontal cortex (mPFC) - associated with emotional regulation, such as personality and social behaviours - which the team found to be correlated with their lower scores on agreeableness.While the researchers aren't drawing firm conclusions on why only children exhibit these differences, they suggest it's possible that parents may foster greater creativity in only children by devoting more time to them - and possibly placing greater expectations on the"
        ]
    },
    "7452": {
        "gold_standard": [
            "Drone footage has captured something no one's ever seen before - wild narwhals using their bizarre tusks to hunt Arctic cod by hitting and stunning them, making them easier to consume.\nThe behaviour addresses a biological mystery that's spanned decades - why these rare and elusive whales have evolved an extra-long left canine tooth that bursts through the upper lip and protrudes from the head like the horn of a unicorn.The footage was captured by two drones in Tremblay Sound, Nunavat, in northeastern Canada, which were operated by Adam Ravetch from the World Wildlife Fund (WWF) Canada and researchers from Fisheries and Oceans Canada.\"This is an entirely new observation of how the tusk is used,\" Brandon Laforest, a senior specialist of Arctic species and ecosystems with WWF-Canada, told National Geographic.The mystery of these 'horns' - which can grow up to 2.7 metres (9 feet) long - has led scientists to pose a number of possible functions, including signals of testicle size, navigation, and territorial battles.\nBut there's been one obvious gap in the evidence - these things look a whole lot like weapons, so are they using them to hunt too?Turns out, they are, as you can see in the footage below: width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\"> width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\">Now that we've witnessed this behaviour for the first time, it's become clear that the narwhal tusk is a multipurpose appendage that really was worth the cost of evolving the most unusual tooth in nature.Late last year, researchers discovered that this tusk helps narwhals 'see' like no other species on Earth - when they measured the whales' echolocation skills, they found that they have the most directional sonar ever detected.\nLike dolphins and other whales, they're able to navigate dark, murky waters by producing clicking sounds at a rate of up to 1,000 clicks per second, and using the echoes to reconstruct their surroundings based on how the sound waves bounce off nearby prey or rock formations.\u00a0Previous research had found that the narwhal tooth had foregone the protection of hard, external enamel to make it sensitive to even the tiniest of stimuli - and this appears to have given them the edge over all other echolocating species.Scientists suspect that the tooth plays a role in echolocation by allowing seawater to enter it through pores in its tip. Bubbles then travel through the shaft and excite nerve endings at the base of the tooth near the head, sending signals to the brain about the narwhal's surroundings.This sensitivity suggests that the narwhal tusk isn't something to be used haphazardly - you'll notice in the footage above that those hunting taps are extremely gentle.\nIt also reveals the cost of narwhal territorial battles (as seen in the image at the top of the page), which involve bashing their most sensitive appendages against each other.We should note that the behaviour in the drone footage has not been published in a peer-reviewed journal at this stage, so any interpretations of what we're seeing will have to be independently verified.\u00a0But this is the first time we've ever seen the mysterious narwhal tusk being used for hunting, which could be the final piece of the puzzle for this bizarre oddity of evolution"
        ]
    },
    "7527": {
        "gold_standard": [
            "If you need that extra push to complete a cycle ride or gym workout, then you might want to let out an expletive or two, because a new study suggests swearing can make you that bit stronger.\nParticipants using an exercise bike or performing a hand grip test produced more power when they repeated a swear word aloud compared with a neutral word, researchers have found.A team from Keele University in the UK hasn't yet come up with an hypothesis for why this might be the case, but it's something to bear in mind the next time you're struggling to get through the home straight - as long as there are no young children around\u2026\"In the short period of time we looked at there are benefits from swearing,\" one of the researchers, psychologist Richard Stephens, told Ian Sample at The Guardian.Two experiments were carried out - in the first, 29 volunteers tested their anaerobic power during short, intense bursts on an exercise bike.Participants had to pick two words: a swear word they might use when accidentally hitting their head, and a neutral word they might use to describe a table (like \"wooden\" or \"brown\").\nOne bike run was completed with the swear words repeated in an even tone, and one with the neutral words. The peak power produced by the cyclists rose by 24 watts on average when foul language was used.Next, 52 different volunteers were asked to run through an isometric hand test. Again with their choice of curse word, and then their choice of neutral word.When swearing, people's strength was boosted by the equivalent of 2.1 kilograms (4.6 pounds) on average, the researchers said.\"Quite why it is that swearing has these effects on strength and pain tolerance remains to be discovered,\" says Stephens.We can probably rule out the swearing causing a fight-or-flight response, though - heart rates measured during the tests showed no significant changes whether people were swearing or not swearing.\nIt's important to bear in mind that the study used a relatively small sample size, and has yet to be peer-reviewed journal, so these findings are intriguing rather than conclusive for the time being.But the research does tie in with an earlier study carried out by Stephens and his colleagues, which found that throwing out expletives increases a person's pain threshold.The researchers admit that we have yet to fully understand the reactions that swearing kicks off in the body, but more and more, scientists are looking into it.A little boost of strength isn't the only thing swearing has going for it -\u00a0another study published earlier this year found that people who cursed more often were also more likely to be honest, based on tests run on 276 participants.\"Swearing is often inappropriate, but it can also be evidence that someone is telling you their honest opinion,\" explained one of the researchers,\u00a0David Stillwell from the University of Cambridge in the U"
        ]
    },
    "7547": {
        "gold_standard": [
            "Unless you have coeliac disease, where digested gluten irritates your small intestine, you might be putting subjecting yourself to unintended health risks by switching to a gluten-free diet, new research has found.\nGoing gluten-free has become a popular lifestyle choice among those who want to improve their health, but it won't reduce your risk of heart disease, and may limit the amount of beneficial whole grains you eat.\"Our findings show that gluten restriction has no benefit, at least in terms of heart health, for people without coeliac disease,\" says one of the researchers, Benjamin Lebwohl from the Columbia University Medical Centre.For those who do have coeliac disease, the irritation caused by the gluten protein (found in wheat, barley, and rye) can block the uptake of nutrients from the small intestine. Long-term, the problem can lead to heart disease, anaemia, and osteoporosis.This irritation and associated health issues can be avoided with a gluten-free diet, but if you don't have coeliac disease, cutting out gluten doesn't appear to have the same heart-healthy effects.\nLebwohl and his colleagues came to this conclusion by analysing survey responses from 110,017 non-coeliac people taken over the years 1986 to 2010.\u00a0The participants were split into five groups, based on the amount of gluten they ate.It turns out that the risk of a heart attack wasn't significantly different between the group that ate the most gluten and the group that ate the least.In fact, the researchers say the risk of heart disease could actually be greater with a gluten-free diet \u2013 not because of a lack of gluten, but because going gluten-free tends to reduce the number of whole grains you eat as well, which are known to boost heart health.So if you're determined to go gluten-free, don't expect a reduced risk of heart problems, and make sure you're not reducing the whole grains in your diet at the same time.\n\"Based on our data, recommending a low-gluten diet solely for the promotion of heart health does not appear warranted,\" says one of the researchers, Andrew Chan from the Harvard Medical School.This isn't the first study to question the benefits of going gluten-free for otherwise healthy people, and some experts say it has no benefits at all, despite popular perceptions.A study published earlier this year\u00a0found that going gluten-free can actually increase the risk of type 2 diabetes, based on surveys of almost 200,000 participants for up to four years.Again, the increased risk may have been because of a food linked to gluten, not gluten itself \u2013 in this case, cereal fibres, which are known to protect against this type of diabetes.So why are so many non-coeliac people swearing by their gluten-free diets?\nGluten consumption has been linked to the production a molecule called zonulin, which\u00a0can trigger inflammation in the gut, and many people report feeling better after giving it up.But\u00a0as we reported last year, whether the positive feelings are down to the gluten-free effect or just an all-round improved diet isn't clear,\u00a0and some experts think the benefits could be all in our heads rather than our stomachs.It's fair to say that we've still got plenty to learn about how gluten affects the body, and the knock-on effects that a gluten-free diet might have, whatever your opinion on the debate.Lebwohl and his team now want to look at gluten intake measured against cancer and autoimmune disease, among other health problems, to get more answers.\"Despite the relatively low prevalence of coeliac disease and non-coeliac gluten sensitivity, surveys suggest that about one-third of Americans are trying to cut down on gluten,\" says Lebwohl.\"This certainly benefits companies that sell gluten-free products. But does it benefit the public? That is the question we wanted to answer.\"The research has been published in the British Medical Journal"
        ]
    },
    "7553": {
        "gold_standard": [
            "Two species of fungus isolated from a highly toxic mine pit in Montana have been thrown together in the lab with unexpected results - the duo teamed up to synthesise a compound that kills four antibiotic-resistant strains of MRSA.\nThis never-before-seen compound resembles a known class of antibiotic, except for one major detail - the way it kills bacteria is unlike anything scientists have documented, and it's already proven effective against the bugs that cause anthrax and strep throat.The two fungal species were collected from the Berkeley Pit - an abandoned open pit copper mine in Montana that's more than 540 metres deep (1,780 feet), and contains water that's as acidic as lemon juice, and laced with arsenic.This stagnant pit of toxic waste is so dangerous, it's become known as a death trap for migrating snow geese - just a few months ago, thousands were forced to take refuge in the pit to get away from a snowstorm, only to perish in the metal-laden waters.Autopsies of the 342 geese found floating in the pit back in 1995 revealed that their insides were ravaged with burns and festering sores - symptoms of exposure to high concentrations of copper, cadmium, and arsenic.\nBut not everything falls victim to the Berkeley Pit death trap. An array of fungal and bacterial species have been found to thrive here, and for two decades now, University of Montana chemists Andrea A. Stierle and Donald B. Stierle have been analysing the unusual compounds produced by these hardy extremophiles.So far, they've identified a fungus with cancer-killing qualities called Taxomyces andreanae, plus organisms that can synthesise molecules with anti-inflammatory and anti-ageing qualities.This time, they decided to see what would happen if they cultured two species of Penicillium fungus together, and after six days, found that these bizarre lake inhabitants had cooperated to produce new compounds that neither could make on their own.The molecular structure of these compounds resembled a known class of antibiotics called macrolides, and when the researchers observed how one of these new compounds - called berkeleylactone A - attacked a number of harmful bacteria, the result was like nothing they'd seen before.\n\"Mode of action studies have shown that, unlike other macrolide antibiotics, berkeleylactone A does not inhibit protein synthesis nor target the ribosome, which suggests a novel mode of action for its antibiotic activity,\" the team reports.When they examined the structure of berkeleylactone A, they found that it lacked both sugars and a double bond, which sets it apart from similar antibiotic compounds.As Melissae Fellet explains for Chemical & Engineering News, those\u00a0two structural features are \"thought to be important to the antibiotic properties of other 16-member macrolides isolated from bacteria or fungi\".So without them, how did berkeleylactone A manage to extinguish four antibiotic-resistant strains of MRSA, plus\u00a0Bacillus anthracis\u00a0(the anthrax bacterium),\u00a0Streptococcus pyogenes\u00a0(strep throat),\u00a0Candida albicans, and\u00a0Candida glabrata\u00a0(pathogenic yeasts in humans)"
        ]
    },
    "7568": {
        "gold_standard": [
            "Back in February, physicists announced an outlandish plan to 're-freeze' the Arctic, by installing 10 million wind-powered pumps over the ice cap to replenish the dwindling sea ice.\nThe idea was so wild, no one actually thought it would happen, but researchers in Switzerland have just launched a trial that will see if they can sustain an entire glacier through summer using nothing but snow machines.If the team manages to successfully preserve a small, artificial glacier at the foot of the Diavolezzafirn glacier in the south-eastern part of Switzerland through the year's hottest months, it's hoped that they can apply the technique to the country's natural giant - the\u00a0Morteratsch glacier.One of the most massive glaciers in the eastern alps, this vast valley glacier has been retreating fast thanks to rising temperatures, and is currently losing 30 to 40 metres every year.It could be that the only hope for Switzerland's Morteratsch glacier is thousands of snow machines blasting it with artificial sleet.\nIf all of this sounds a little far-fetched to you, scientists have actually done the maths,\u00a0and it is technically feasible to use machines to rebuild glaciers and replenish vanishing sea ice.Earlier this year, a team led by Arizona State University physicist, Steven Desch, put out a report describing how millions of wind-powered pumps could blast 1.3 metres of water on the surface of the Arctic, adding 1 extra metre (3.2 feet) of sea ice.\u00a0While an extra metre doesn't sound like all that much, they calculated that it would be like pushing time back by 17 years.The only problem? How mind-bogglingly vast the Arctic region actually is.\u00a0The team calculated that covering just 10 percent of the Arctic would involve erecting millions of pumps, which together would have to spray 7.5 kg per of water (16.5 pounds) every second to achieve 1 extra metre in a year.\n\"The area of the Arctic Ocean is about 107\u00a0km2 [3.8 million miles2],\" the report stated.\"If the wind-powered pumps are to be distributed across 10 percent of that area, this would necessitate about 10 million wind-powered pumps; if distributed across the entire Arctic, about 100 million would be needed.\"In order to build a fleet of 100 million pumps to save the entire Arctic, you'd need more steel than the US produces in a entire year.All that considered, there was no way in hell the plan was ever going to be funded, but the much smaller version proposed for Switzerland could actually have some legs.Glacier expert Johannes Oerlemans of Utrecht University in the Netherlands calculated that around 4,000 snow machines could help the Morteratsch glacier not only stop retreating, but actually grow in the coming decades.\nThe basic idea is that the ice on the glacier is now being exposed to sunlight, but if they could cover the ice in thick, artificial snow, it could reflect the light away before it ever gets to the vulnerable ice layers below.Oerlemans presented his plan at the recent annual meeting of the European Geosciences Union in Vienna, Austria.\"Looking at previous work showing that natural snow can help glaciers grow, he concluded that the glacier could regain up to 800 metres of length within 20 years if it had a covering,\" Andy Coghlan reports for New Scientist.\"He worked out that just a few centimetres of artificial snow blown onto a 0.5-square-kilometre plateau high up the glacier each summer could be enough to protect the ice beneath.\"Of course, the plan isn't as colossal as the Arctic one, but it's still huge, and would require a lot of funding, but Oerlemans and his team are quietly confiden"
        ]
    },
    "7609": {
        "gold_standard": [
            "In a major discovery, astronomers have observed a pair of supermassive black holes orbiting each other, hundreds of millions of light years away.The discovery is the result of more than two decades of work, and an incredible feat considering the precise measurements required. Understanding the nature of such interactions will give us a greater understanding of how galaxies, and the universe, have evolved.\n\"For a long time, we've been looking into space to try and find a pair of these supermassive black holes orbiting as a result of two galaxies merging,\" says Greg Taylor, one of the researchers, from The University of New Mexico (UNM).\"Even though we've theorised that this should be happening, nobody had ever seen it until now.\"The team observed the pair of black holes in a galaxy, named 0402+379, roughly 750 million light years from Earth.VLBA map of radio galaxy 0402+379 at 15 GHz. Credit: UNMAccording to\u00a0Karishma\u00a0Bansal, the first author on the paper, also from UNM, the combined mass of these supermassive black holes is about 15 billion times that of our sun, and their orbital period is around 24,000 years.\nThis means that even though the team has been observing these black holes for over a decade, they haven't been able to detect even the slightest curvature in their orbit.\"If you imagine a snail on the recently-discovered Earth-like planet orbiting Proxima Centauri - 4.243 light years away - moving at 1cm [0.4 inches] a second, that's the angular motion we're resolving here,\" explains Roger W. Romani, one of the researchers from Stanford University.Black holes are notoriously difficult to study because they cannot be directly observed, but can only be detected from their effect on nearby matter.So, to find the orbit of these black holes, the UNM team used the Very Long Baseline Array (VLBA), which is composed of 10 radio telescopes. By measuring the various frequencies of radio signals emitted by the black holes, the team was then able to plot their trajectory.\n\"When Dr. Taylor gave me this data I was at the very beginning of learning how to image and understand it,\" says Bansal.\"And, as I learned there was data going back to 2003, we plotted it and determined they are orbiting one another. It's very exciting.\" The technical achievement of this discovery is a triumph and will vastly improve our understanding of these enigmatic objects.Ever since Einstein's theory of general relativity, astronomers have been fascinated by supermassive black holes. Recently, there have been several new discoveries about black holes, but there's still a lot about them that we don't know.Continuing to observe the orbit and interaction of these black holes will reveal a lot about where our galaxy came from, where it might be heading in the future and the role that black holes play in this process.\nCurrently, the Andromeda galaxy, which also contains a supermassive black hole, is projected to collide with our Milky Way - making the event that the UNM team is observing our galaxy's potential future in a few billion years.\"Supermassive black holes have a lot of influence on the stars around them and the growth and evolution of the galaxy,\" says Taylor.\"So, understanding more about them and what happens when they merge with one another could be important for our understanding for the universe.\"The UNM team will come back to these black holes in a few years time to confirm observations and improve their projections around orbits and trajectories.For now, we can enjoy the fact they've finally delivered a direct observation for the first time and no doubt will inspire other work to push forward amongst the wider scientific world.The paper was published in The Astrophysical Journal with a pre-print version available on arXi"
        ]
    },
    "7615": {
        "gold_standard": [
            "Like most animals adapted to urban living, the house finches in Mexico City make good use of what we humans commonly throw away.The tiny Carpodacus mexicanus birds take cigarette butts back to their nests, a habit that researchers are now confident is to keep ticks at bay, even if the toxins have a rather nasty side-effect on the growing chicks.\nA team of scientists from the National Autonomous University of Mexico followed up on a previous study conducted in 2012 that left them wondering if the finch's use of the cellulose fibres found in cigarette butts as nesting material was medicinal, or purely for warmth and structure.The nicotine in tobacco that stimulates a buzz in smokers has a far more overpowering effect on smaller animals like insects and other arthropods, making it useful as a pesticide.Just because the nicotine-stained garbage happened to be keeping the bities at bay didn't necessarily mean the finches were seeking it out as a parasite repellent.\"One possibility is that birds extract the cellulose fibres from discarded butts simply because they resemble feathers,\" the researchers write in their latest paper.To find more solid evidence, the scientists watched house finches build their nests on the university grounds, and then swapped the fluffy linings in their nests with clean pieces of felt once the chicks had hatched.\nThe exchange ensured that there were no parasites near the chicks, and the linings were free of cigarette fibres.On average, the old nest linings had contained around 70 ticks. Using this as a baseline, the researchers added 70 live ticks to 10 of the fresh nest linings.They then added 10 dead ticks to 10 other nests, and left a further 12 nests tick-free.To determine whether there was a relationship between parasite loads and the subsequent collection of cigarette fibres, the team then simply weighed the mass of butts in both the old and new linings.Based on the numbers, it appears as if the discarded butts are deliberately being used to kill parasites such as ticks, with up to 40 percent more cigarette material being added to the live parasite nests than to those containing dead ticks.Unfortunately repelling the blood-suckers comes at a cost.\nIn 2014, the researchers found the higher the amounts of nicotine the birds were putting into their nests, the greater the number of chromosomal abnormalities in the chicks.The lower parasite counts seemed to help more chicks hatch. They also had healthier immune systems, either by being sensitised by the cigarette fibres or simply because they weren't fighting off as many parasites.If the chromosomal damage failed to cause problems until the chicks had left the nest and reproduced, the scavenging behaviour would give them more of an advantage, at least in the short term.More research would be needed to get a clearer picture of the long term effects.Cigarette butts are among the most common forms of litter, with around two-thirds of the 6 trillion cigarettes smoked worldwide ending up being flicked to the ground, posing a potential hazard for many organisms.So while a few finches might appreciate it, claiming you're helping the wildlife still isn't going to be a valid excuse for not putting your butts in the bin.This research was published in the Journal of Avian Biology",
            "Like most animals adapted to urban living, the house finches in Mexico City make good use of what we humans commonly throw away.The tiny Carpodacus mexicanus birds take cigarette butts back to their nests, a habit that researchers are now confident is to keep ticks at bay, even if the toxins have a rather nasty side-effect on the growing chicks.\nA team of scientists from the National Autonomous University of Mexico followed up on a previous study conducted in 2012 that left them wondering if the finch's use of the cellulose fibres found in cigarette butts as nesting material was medicinal, or purely for warmth and structure.The nicotine in tobacco that stimulates a buzz in smokers has a far more overpowering effect on smaller animals like insects and other arthropods, making it useful as a pesticide.Just because the nicotine-stained garbage happened to be keeping the bities at bay didn't necessarily mean the finches were seeking it out as a parasite repellent.\"One possibility is that birds extract the cellulose fibres from discarded butts simply because they resemble feathers,\" the researchers write in their latest paper.To find more solid evidence, the scientists watched house finches build their nests on the university grounds, and then swapped the fluffy linings in their nests with clean pieces of felt once the chicks had hatched.\nThe exchange ensured that there were no parasites near the chicks, and the linings were free of cigarette fibres.On average, the old nest linings had contained around 70 ticks. Using this as a baseline, the researchers added 70 live ticks to 10 of the fresh nest linings.They then added 10 dead ticks to 10 other nests, and left a further 12 nests tick-free.To determine whether there was a relationship between parasite loads and the subsequent collection of cigarette fibres, the team then simply weighed the mass of butts in both the old and new linings.Based on the numbers, it appears as if the discarded butts are deliberately being used to kill parasites such as ticks, with up to 40 percent more cigarette material being added to the live parasite nests than to those containing dead ticks.Unfortunately repelling the blood-suckers comes at a cost"
        ]
    },
    "7629": {
        "gold_standard": [
            "As if a sensitivity to their spores wasn't enough of a problem for some people, new research has found the toxins produced by mould sprouting in the damp corners of your house can also become airborne.\nThe discovery could help explain what is referred to as \"sick building syndrome\", a broad collection of symptoms that appear to increase in severity the longer a person occupies a room or building.A team of French researchers has found evidence that particles shed by several species of fungi (that we'd commonly think of as mould) can contain chemicals called mycotoxins, and that the toxins themselves can also become airborne.For people with asthma and other allergies, the mould particles themselves can be a nightmare, inflaming the lungs and sinuses and causing anything from sneezing and itchy eyes to restricted airways and asthma attacks.This is usually caused by the body's immune system becoming sensitive to compounds in the spores and hyphae or to waste products called microbial volatile organic compounds, and not specifically the mycotoxins.\nUsually, mycotoxins are substances we'd associate with food contamination as they leach out of fungi growing on fruit or grains. Nobody is sure why fungi produce them, but consumed in high enough concentrations they can be deadly.While their effects on the body after being ingested have been studied extensively, less is known about the effect of breathing in mycotoxins, or whether it's even something to consider as a potential health concern for most of us.\"There is almost no data on toxicity of mycotoxins following inhalation,\" says researcher Jean-Denis Bailly from the National Veterinary School of Toulouse, France.Of the little data that does exist, most research has focused on the kinds of fungi found in agriculture. These numbers have contributed to what's called a concentration of no toxicologic concern (CoNTC), which is 30 nanograms per cubic metre for agricultural mycotoxins.\nBased on this, there's little evidence that airborne mycotoxins can reach high enough concentrations to cause health problems for most of us.But indoor environments could be different, and mycotoxins just might be playing a role in making those of us who spend a lot of times indoors sick.This new research looked at fungi such as Penicillium brevicompactum, Aspergillus versicolor, andStachybotrys chartarum. These are often found growing in the damp corners of bathrooms or poorly ventilated bedrooms, where their spores and bits of root-like threads called hyphae can drift about in the air.The study involved controlling the air movements around a piece of wallpaper that had been contaminated with the different moulds.The researchers then analysed the air that came off the wallpaper.Each species of fungus shed particles at different air speeds, most probably due to their unique structures and spore arrangements"
        ]
    },
    "7633": {
        "gold_standard": [
            "Autism Research Having a higher number of copies of genes has been shown to raise the risk of a child developing autism, as has early exposure to various pollutants in the mother's environment.\nResearchers have now shown that when these two factors are combined, an individual has 10 times the chance of developing the condition, demonstrating the importance of stepping beyond the question of nature versus nurture and looking at the bigger picture.The analysis by a team led by scientists from Pennsylvania State University is one of the first to examine genetic differences across the whole genome in conjunction with environmental factors surrounding an individual as it develops.Autism Spectrum Disorder ( ASD) covers a variety of behaviours involving social interactions and communications, presenting with degrees of severity.\"There are probably hundreds, if not thousands, of genes involved and up until now \u2013 with very few exceptions \u2013 these have been studied independently of the environmental contributors to autism, which are real,\" says Penn State researcher Scott B. Selleck.\nThose genes can affect numerous functions in the brain, potentially affecting a bunch of different neurological circuits that influence anything from social interactions to eye contact.The question on just how heritable autism is has long been debated, with some early twin studies estimating as much as 90 percent of the condition is the result of genes passed down from parents.Other researchers suggest the environment shares more of the blame, with the consensus now hovering around 50 percent genetics, 50 percent environment.This new study shows how complicated the story just might be when it comes to such complex neurological conditions.\"Our team of researchers represents a merger of people with genetic expertise and environmental epidemiologists, allowing us for the first time to answer questions about how genetic and environmental risk factors for autism interact,\" says Selleck.\nResearch involved 158 children with autism who were selected through a previous study, and 147 controls who were closely matched in age and demographic.The team examined a feature called copy-number variations (CNVs); sequences that have been duplicated at least once to form repeats through the genome.Previous research on individuals with ASD has already shown a higher tendency for their genomes to contain more CNVs than the rest of the population, and that the more of these repeats an individual has, the lower their measures of social and communication skills.In addition to the subjects' genetic variations, the team analysed their family's residential history, comparing the addresses with data on air quality from the US Environmental Protection Agency (EPA) Air Quality System.\"This allowed us to examine differences between cases of autism and typically developing controls in both their prenatal pollutant exposure and their total load of extra or deleted genetic material,\" says researcher Irva Hertz-Picciotto from University of California Davis.\nEach risk factor on its own \u2013 larger numbers of CNV and high amounts of particulate in the air \u2013 was found to elevate the risk of autism, in line with previous research.Once they started to combine the figures, one result in particular stood out.Ozone, as one of the pollutants examined, hasn't previously been considered a hugely significant risk factor for ASD.The gas, consisting of three oxygen atoms, is formed from other pollutants such as nitrogen oxides and volatile organic compounds, which react in the presence of sunlight. Those molecules are generally released in vehicle exhaust, industrial processes, and electrical utilities.The effect of ozone on those with high CVN numbers ramps up the chances of developing the condition, more than either would account for on their own.Compared with those the bottom quarter of CNV numbers, and the bottom quarter of ozone exposure, there is a ten-fold risk of developing autism for those in the top quarter for both measures.\n\"This increase in risk is striking, but given what we know about the complexity of diseases like autism, perhaps not surprising,\" says Selleck.While the study didn't analyse the cause, the researchers did speculate that ozone could increase the number of reactive oxygen species, such as peroxides, that are known to cause stress to cells and damage DNA.It's possible that having more variations of genes responsible for certain autism-related functions could open individuals to more oxidation damage.The researchers acknowledge their sample size was relatively small, and since ozone occurs in conjunction with numerous other pollutants, there could be confounding factors that need to be pulled apart. It also doesn't point at a single cause, instead hinting at one way a number of key genes could be affected by the environment.\nStill, given the complexities of the condition, the study does show how variables we've previously dismissed might be working in combination.\"It demonstrates how important it is to consider different types of risk factors for disease together, even those with small individual effects,\" says Selleck.This research was published in\u00a0Autism Researc"
        ]
    },
    "7643": {
        "gold_standard": [
            "Psychological Science Scientists have used an unconventional technique to increase the happiness of married couples: brain washing them with pictures of cute puppies.The team developed a procedure that could be used as part of marriage counselling to improve people's feelings about their partners. The intervention could be used to keep the spark alive in long-distance and challenging relationship situations, such as those experienced by members of the armed forces.\nKeeping a marriage healthy and happy is a challenging task \u2013 there's even a mathematical formula to keep the love alive. Happiness is a really important metric and previous research has shown that if happiness level of males is higher than their partner it's more likely to end in divorce.The team of psychologists wanted to find out whether it was possible to improve marital satisfaction by subtly brain washing the study participants, a process called evaluative conditioning. They designed an experiment to retrain the automatic responses of married people when they think about their partner.\"One ultimate source of our feelings about our relationships can be reduced to how we associate our partners with positive affect, and those associations can come from our partners but also from unrelated things, like puppies and bunnies,\" said James K McNulty, lead researcher from Florida State University.The study included 144 married couples who were all under 40 and married for less than 5 years. At the start of the experiment, couples completed a series of tests to measure their relationship satisfaction.\nThis included measuring their immediate, automatic attitudes toward their partner. Like a scary word association game that could lead to divorce.To improve the automatic reactions to their spouse subjects were asked to watch a short, happy montage of images once every three days for six weeks.For those in the experimental group, they were shown pictures of their spouse alongside positive stimuli, such as a puppy that makes you grit your teeth and die from happiness, or the word \"wonderful\". In the control group, the participants saw their partner's face with pictures of neutral stimuli such as a shirt button.Did the positive stimuli actually make them perceive their partner in a more positive light?To test the effect that the montage was having on the couple, every 2 weeks for 8 weeks each spouse was shown a series of faces, including their partners and were asked to indicate the emotional tone of the image as quickly as possible.\nSomething amazing happened to the participants.The simple act of associating their partners with positive stimuli increased the marital satisfaction over the course of the study.\"I was actually a little surprised that it worked,\" McNulty explained. \"All the theory I reviewed on evaluative conditioning suggested it should, but existing theories of relationships, and just the idea that something so simple and unrelated to marriage could affect how people feel about their marriage, made me skeptical.\"Of course, the research only measured one aspect of relationship happiness and the researchers were quick to point out that behaviour also plays a big part in determining happiness.Although this simple intervention focused on automatic attitudes, the researchers say it could be useful as one aspect of marriage counselling.\n\"The research was actually prompted by a grant from the Department of Defence \u2013 I was asked to conceptualise and test a brief way to help married couples cope with the stress of separation and deployment,\" McNulty said. \"We would really like to develop a procedure that could help soldiers and other people in situations that are challenging for relationships.\"As long as researchers keep coming up with more reasons to look at pictures of cute puppies we're not going to complain.The research was reported in Psychological Scienc"
        ]
    },
    "7651": {
        "gold_standard": [
            "The 'bright nights' phenomenon \u2013 where the nighttime sky is inexplicably bright enough to read a book by, even without moonlight \u2013 has been puzzling scientists for centuries, but we might just have a solution to the mystery.\nA new study suggests the effect is created as slow-moving, high-altitude atmospheric waves merge together and amplify the light from naturally occurring airglow, gas atoms that aren't usually visible.Two researchers from York University in Canada matched data collected on spikes in airglow light with records of atmospheric waves, and found there was a link.Don't panic if you've got no idea what we're talking about though \u2013 bright nights have always been rare occurrences, and are hardly ever seen today due to the effects of light pollution on the night sky.One of the earliest mentions of the phenomenon was by Pliny the Elder in the first century, and other occurrences have been noticed in scientific papers and newspaper reports down the years.\"The historical record is so coherent, going back over centuries, the descriptions are very similar,\" says lead researcher Gordon Shepherd.\n\"Bright nights do exist, and they're part of the variability of airglow that can be observed with satellite instruments.\"That airglow is formed by various chemical reactions taking place in the upper atmosphere, including the green tinge in the air that happens when oxygen molecules split apart by the Sun join together again.Shepherd and his colleague Youngmin Cho found that when this airglow mixed with weather-driven atmospheric waves, bright nights could last for several nights in a row, creating light up to 10 times brighter than normal.\"This [study] is a very clear, new approach to the old enigma of what makes some night skies so remarkably bright, and the answer is atmospheric dynamics,\" says J\u00fcrgen Scheer, from the Instituto de Astronom\u00eda y F\u00edsica del Espacio in Argentina, who wasn't involved in the research.\n\"We now have a good idea which dynamical phenomena are behind [airglow] events of extreme brightness.\"Based on the data collected by the researchers, bright nights only occur once a year in the places where they are noticeable, and you'd need a clear, moonless night to be able to tell the difference with your own eyes.In total, the scientists think that for every 7 nights out of 100 there's a bright night somewhere on Earth.One group of people who will be interested in the new research are astronomers: any airglow or bright night effect can interfere with their observations and readings taken of distant objects in space.For everyone else, the research won't necessarily be life-changing \u2013 but it's perhaps worth thinking about if you're ever a long way from civilisation and notice the nighttime light is stronger than it should be.\"Maybe it's an almost dead question,\" says Shepherd. \"I'm having the last word before it dies.\"The findings have been published in Geophysical Research Letters"
        ]
    },
    "7718": {
        "gold_standard": [
            "After more than a century of being buried by a volcanic eruption, New Zealand's long-lost pink and white terraces might have finally been rediscovered under layers of ash and mud.\nOnce hailed as a natural wonder of the world, and the largest silica deposits of their kind on Earth, it was feared that these terraces were destroyed by the 1886 eruption of Mount Tarawera. But now researchers say they've located where they were buried, and suspect some of them have been preserved this whole time.\"They became the greatest tourist attraction in the Southern Hemisphere and the British empire, and shiploads of tourists made the dangerous visit down from the UK, Europe, and America to see them,\" one of the team, Rex Bunn, told The Guardian.\"But they were never surveyed by the government of the time, so there was no record of their latitude or longitude.\"During the heyday, the pink and white terraces of New Zealand were thought to be the largest silica 'sinter' deposits on the planet. Sintering occurs when a mineral spring or geyser deposits enough sediment to form a crust, creating natural mounds, terraces, or cones around the water supply.\nThere was a 'white terrace', which sat on the north-east end of Lake Rotomahana in northern New Zealand, and the 'pink terrace', which sat on another shore nearby.It's thought that the pink hue found in some of the terraces was likely due to the presence of extensive colonies of a pigmented bacteria, such as Thermus ruber - relatives of the micro-organisms that inhabit the famously technicolour Morning Glory pool at Yellowstone.Bunn, an independent researcher, got his big break in 2016 when Sascha Nolden from the National Library of New Zealand shared with him an old field diary he'd discovered some years prior.The diary belonged to 19th century geologist Ferdinand von Hochstetter, who in 1859 was commissioned by the government of New Zealand to make a geological survey of the islands.\nIn his notes, von Hochstetter had recorded raw data from a compass survey of Lake Rotomahana, located 20 kilometres (12 miles) to the south-east of the city of Rotorua in northern New Zealand.Because this was almost three decades before the volcanic eruption, the pink and white terraces were plainly marked in the area.\u00a0So, case closed? Not quite, because that eruption didn't just bury one of the world's most spectacular natural wonders - it shifted the landscape around it so severely that even an 'X marks the spot' no longer applies today.Bunn and Nolden set about reconstructing von Hochstetter's lake map using a technique called forensic cartography, which involved comparing current topographic maps to the 1859 data, and matching up certain geological features until they'd narrowed down the most likely location of the terraces.\nThat might sound fairly simple, but the actual process was far from it.\"We would have put in 2,500 hours of research in the last 12 months,\" Bunn told Hannah Martin at Stuff.co.uk.\u00a0\"We're confident, to the best of our ability, we have identified the terrace locations. We're closer than anyone has ever been in the last 130 years.\"That last point is important - there have been several claims in recent years from other teams that they'd found the terraces, with some dispute over whether the landmark had been destroyed or partially preserved in the eruption.Based on their research, Bunn claims to have developed an algorithm that's pinpointed the location of the pink and white terraces with a margin of error of plus or minus 35 metres.He says when you're talking about a landmark that spans hundreds of metres, that's a close enough estimate to make digging them out a reality.\nThe decision to excavate the area has been given to the local Tuhourangi tribal authority, but Bunn expects that if they do decide to dig the terraces out, they will find some part of them still intact.It's too soon to know if Bunn's and Nolden's claims of locating the terraces, and their continued existence, will pan out, but it would be incredible if they did.As\u00a0Bunn told Martin,\u00a0\"The pink and white terraces may in some small way return, to delight visitors to Rotorua as they did in the 19th century.\"The research has been published in the Journal of the Royal Society of New Zealand"
        ]
    },
    "7719": {
        "gold_standard": [
            "A species of salamander known for only producing female offspring has been observed using genetic material stolen from males of other species in equal measures.This is the first time biologists have analysed the balance of genetic expression in a hybrid species of animal with more than two genomes, and they've discovered what has to be one of the most feminist acts of nature.\nA team led by researchers from the University of Iowa took a close look at the rather unusual genome of a population of mole salamander (Ambystoma)\u00a0to determine if it has a preference for a particular set of its genes.Humans - like many animals - tend to be what are called diploid organisms. In simple terms, that means most of our cells contain two sets of chromosomes, those long strings of DNA that contain sequences of genes.We typically get one set of chromosomes from each of our two parents, and while recent research has questioned whether all of our cells treat each parent's genes equally, in general it's accepted that our bodies don't play favourites.Some species of Ambystoma do things a little differently - they're part of a select group of vertebrates that happen to be polyploid, which means they possess more than two sets of chromosomes.\nSpecifically, many populations of all-female mole salamander range from triploid to pentaploid, having between three and five sets of chromosomes.These amphibians are also\u00a0parthenogenetic, which means their offspring are usually clones of the mother, inheriting the complete allotment of chromosomes directly from her.That's not to say they've done away with sex altogether - they still seek a male from another closely related species, have a quick dalliance, and use their sperm to kickstart the reproduction process.Usually the sperm are discarded after they've triggered the egg cells into dividing, but these amphibian Amazonians have another trick up their sleeve -sometimes they'll steal some of the sperm's genetic material, an act biologists call kleptogenesis.That means the triploid genome of unisex Ambystoma populations can include genetic material from different father lineages - one paternal lineage for each chromosome set.\nThe fathers in this study came from the three species:\u00a0Ambystoma laterale, Ambystoma texanum, and Ambystoma tigrinum.Since polyploid organisms - especially plants - often turn off genes they have multiple copies of, the researchers wondered if the unisex Ambystoma were particular about which lineage of genes they used.It turns out they weren't all that choosy.\"It's mostly balanced. The three genomes are mostly being expressed equally in this hybrid,\" said researcher Kyle McElroy.The team analysed just under 3,000 genes common to each chromosome and found that 72 percent of the genes were expressed equally by each set.It's likely that there's a good reason that the salamanders aren't prioritising any one genetic line.\"This balance might have been a prerequisite for the emergence and continued success of this particular hybrid lineage,\" said researcher Maurine Neiman.\nOne possibility is it allows the population to remain adaptable to its surroundings. While one set of genes might give it an advantage now, a relatively swift change in the environment might then spell doom.McElroy gave an analogy of a sporting team, where you don't lean too hard on one player's strategy.\"If you have a team that's unbalanced and loses a top player, you won't win,\" said McElroy.\u00a0\"But if every player is equal, then you don't lose as much.\"Keeping it simple and not using complicated processes to pick the best genes seems to have been a winning strategy for these gene thieving, promiscuous, all-female mole salamanders.This research was published in Genome Biology and Evolution"
        ]
    },
    "7649": {
        "gold_standard": [
            "Some people on very low-carb diets say they feel euphoric, have clear minds and lose their appetite.Going low-carb might even mimic the effects of GHB \u2013 the recreational drug better known as fantasy, liquid ecstasy or grievous bodily harm \u2013 on the brain.\nTo understand why we need to look at how the body processes a very low-carb diet, one that typically limits carbohydrates to no more than 50 grams a day. That's one cup of rice, two slices of bread or roughly 10 percent of your total daily energy needs.I've gone from low carb crash to low carb euphoria! Wtf body y didn't u tell me u were hiding this much energy #diet #crazy #oncrack\u2014 T. L. Shreffler (@catseyeauthor) April 15, 2014Your body thinks it's starvingA very low-carb diet flips your metabolic switch from burning more carbs than fat, to more fat than carbs. This usually takes a few days in a process known as ketosis.During this time, your body thinks it's starving. Once it uses up most of your glucose (carb) reserves, the body stimulates the breakdown of stored fat into fatty acids and releases them into the blood.\nWhen fatty acids reach the liver they're converted into acetoacetate, an excellent metabolic fuel that belongs to a family of chemicals called ketones. That's why very low-carb diets are sometimes called \"ketogenic\" diets.Acetoacetate decomposes to carbon dioxide and acetone, the smelly solvent best known for its ability to remove nail polish. This is why very low-carb dieters and people who are fasting often have sweet smelling breath.A healthy liver minimises the acetone lost via the lungs by converting most of the acetoacetate it produces to a more stable substance, called beta-hydroxybutyrate or BHB. And this is where those euphoric feelings could come from. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\">BHB is almost identical to GHB, the naturally occurring neurotransmitter, called gamma-hydroxybutyrate, that in synthetic form is used as a recreational drug.\nBHB and GHB have exactly the same chemical formula. Both consist of just 15 atoms, with the only difference being the position of one hydrogen and oxygen atom.It's not too surprising, therefore, the two molecules share the same carrier across the blood-brain-barrier, the impermeable tissue that protects the brain.During ketosis, BHB can reach high levels in the brain, where it can bind to the same anxiety-reducing receptors as GHB. They bind with sufficient affinity that they may have similar effects.There are no reports of BHB supplements or low-carb diets causing any of GHB's adverse effects, like loss of consciousness, seizures and death.So, apart from the similar-sounding name, what evidence is there that BHB produced by the liver by people on a very low-carb diet has euphoric, GHB-like effects in the brain?\nFasting for the original 'natural high'The first case of euphoria directly attributed to ketosis was reported by Walter Bloom, who pioneered therapeutic fasts for obesity in the 1950s. After several days without food, his patients lost their appetite, felt remarkably well, and experienced a mild intoxication: \"not dissimilar to the effects of ethanol\".Bloom speculated that acetoacetate had caused the inexplicable jubilation.Other people have observed similar effects, including three Scottish doctors whose patients fasted for up to 249 days in the 1960s. After several days without food, their appetites subsided and all patients felt an increased sense of well-being which: \"in some amounted to frank euphoria\".Unfortunately, no studies of the euphoria reported by low-carb dieters have been conducted, as far as we know.\nSo, researchers don't know the exact cause of these feelings. Acetoacetate, acetone and BHB, or any of their metabolites, may all be involved, as well as the effects of low blood sugar, which can cause euphoria and giddiness.A good place to start might be to image brain activity in people on a very low-carb diet and compare activity with people on a normal, non-calorie restricted diet. The aim would be to see if brain imaging of people on a very low-carb diet has similar effects on brain activity seen when people take GHB.And if you're thinking of going on a very low-carb diet to get that high, beware. Side effects include loss of calcium from bones, increased risk of kidney stones and growth retardation.Andrew Brown, Professor and Head, School of Biotechnology and Biomolecular Sciences, UNSW.This article was originally published by\u00a0The Conversation. Read the original article.UNSW Science is a sponsor of ScienceAlert. Find out more about their world-leading researc"
        ]
    },
    "7749": {
        "gold_standard": [
            "Alimentary Pharmacology & Therapeutics Excessive amounts of exercise are linked to a higher risk of acute or chronic gut issues, a new study has found, cautioning that over-exercising can trigger your intestinal cells to become injured and leaky, especially if you've got a gut-related medical problem already.\nResearchers say a moderately intense workout of 2 or more hours is enough to push the risk of damaging your gut higher, but add that people who already have bowel conditions should not be afraid to participate in \"low to moderate\" exercise.According to a new meta-review of previous studies on exercise and gut health, a team from Monash University and the University of Tasmania in Australia has found that too much exercise can trigger cells in the intestines to leak toxins.Those toxins then seep into the bloodstream, potentially causing a variety of health issues that can be\u00a0exacerbated if you're exercising in hot conditions.But the researchers have also found ways to limit the damage.The review looked at 62 previous studies from the last 20 years, covering activities such as running, cycling, and resistance exercise, and\u00a0identified the exact point in the exercise where gut damage started to take effect.\n\"Exercise stress of 2 or more hours at 60 percent VO2 max [the level of oxygen consumption] appeared to be the threshold whereby significant gut disturbances arise, irrespective of an individual's fitness status,\" the team writes in a press statement.Some prevention strategies did seem to limit the damage: staying hydrated, taking on carbohydrates during exercise, and avoiding anti-inflammatory drugs were all found to reduce some of the health risks in some cases.These counter-measures weren't particularly clear-cut though, and the team suggests further research to get a better idea of how they affect our bodies.Before you pack away the exercise bike, the scientists still reaffirm that exercise is incredibly good for you, but they do warn against overdoing it, especially if you've got a gut-related medical problem already.\n\"It is recommended that a full gut assessment during exercise should be undertaken by individuals with symptoms of gut disturbances during exercise, to ascertain what is causing the issue and to develop individually tailored management strategies,\" says one of the researchers, Ricardo Costa from Monash University.In short, the team advises tailoring your exercise regime to your own body, an idea that's\u00a0backed up by previous studies.More generally speaking, the dangers of overdoing it with exercise are well documented. A small 2015 study found that the mortality rate of people who overdid their jogging regime didn't differ too much from those who didn't do any jogging at all.Meanwhile, a study of mice in 2014 found that endurance exercise could interfere with the natural rhythm of the heart.\nBut what everyone agrees on is that the benefits of regular exercise\u00a0do outweigh the potential risks: it keeps your weight down, strengthens your bones and muscles, boosts your mood, increases your chances of living longer, and reduces the risk of many health problems, including heart disease, diabetes, and some cancers.Just make sure you know how much exercise is enough for your body.The findings have been published in Alimentary Pharmacology & Therapeutic"
        ]
    },
    "7769": {
        "gold_standard": [
            "Blood is thicker than water, but that doesn't mean our friendships should take a backseat to our family relationships as we grow up.A new study has found that friendships can have a much greater impact on our overall health and happiness as we age than our families, suggesting that it's worth our while to invest in those relationships now, so they're with us for the long-haul.\n\"Friendships become even more important as we age,\" says psychologist William Chopik from Michigan State University.\"Keeping a few really good friends around can make a world of difference for our health and well-being. So it's smart to invest in the friendships that make you happiest.\"That's not to say you should ditch your fam altogether and throw your entire lot in with your besties - we all know friendships can fall apart far easier than you can get an emancipation certificate or a new identity.But the evidence suggests that we need to keep in mind that the relationships we don't choose can have less of an impact on our lives as we age than those we do.To figure this out, Chopik analysed survey information about relationships and self-rated health and happiness from 271,053 participants across all age groups from nearly 100 countries around the world.\nHe then compared the results to a separate survey about relationship support, relationship strain, and chronic illness, involving 7,481 older adults (median age 68) in the US.The first survey revealed that, overall, those who valued both their family and friendship relationships enjoyed greater health and higher happiness.But among the older participants, valuing friendships became a stronger predictor of health and happiness than valuing family.Chopik, W. J.,Personal Relationships (2017)The second survey took this notion even further by revealing that friendships have a far greater influence on our physical and emotional state as we age than our family relationships.\nThis can be a good and a bad thing, because if your friendships are awesome and provide you with support, you're more likely to be happier and free from health concerns than if you get your support from your family members alone.But this goes the other way too, because if your friendships become a source of stress in older age, you're more likely to experience chronic illness, such as high blood pressure, diabetes, cancer, or coronary heart disease.Interestingly, family relationships with people other than spouses and immediate children were found to have little influence on an individual's health and well-being in older adulthood across both surveys.\u00a0\"Friendships were very influential - when friends were the source of strain, participants reported more chronic illnesses; when friends were the source of support, participants were happier,\" Chopik reports in his study.\n\"This finding is consistent with previous research showing that friendship quality often predicts health more so than the quality of other relationships.\"There are a number of important limitations in this study, such as self-reporting happiness, which is not an objective measure, and giving equal weight to the various chronic illnesses - having high blood pressure generally doesn't carry the same emotional weight as having cancer.But the results do reflect what many of us have likely already experienced, even before we hit 'old age' - we benefit from our friends because we get to choose the ones who make us feel happiest, whereas family can often come with inescapable baggage and stress.\u00a0The finding supports a similar study from 2005, which found that Australians aged 70 or older tended to live significantly longer if they had more strong friendships"
        ]
    },
    "7782": {
        "gold_standard": [
            "The warm evenings of summer are prime time for grilling. But this all-American ritual may also raise health risks - particularly if the grill is loaded up with hamburgers and hot dogs.\nWhen cooked at high temperatures or over open flames, according to accumulating evidence, compounds in red and processed meats undergo biochemical reactions that produce carcinogenic compounds capable of altering the eater's DNA.Most of the research has been conducted in lab dishes and in animals. But some emerging evidence is starting to connect the dots to human risks of cancer, too.Lest you feel that science threatens everything you enjoy in life, experts say it's not necessary to give up meat - or grilling - altogether. Grilled vegetables don't harbour the same risks. There are also ways to cook meat that produce fewer carcinogens.And while there's not enough evidence to say how much is too much, eating grilled meat in moderation is probably fine. In other words, don't get too freaked out by what you might find on the Internet.\n\"You can just Google and see all of these sensationalistic headlines that say eating bacon is like smoking a pack of cigarettes,\" but it's not the same, says Robert Turesky, a biochemical toxicologist at the University of Minnesota in Minneapolis.\"I still do enjoy barbecue. I just don't eat it as often.\"The case for meat as a cancer risk has been building for decades, with plenty of studies showing that people who report eating diets heavy in red and processed meats have higher risks of certain types of cancer, as well as heart disease and other chronic illnesses.Enough of those studies - together with lab work - have built up to make a convincing case that meat carries risks, according to a 2015\u00a0analysis\u00a0by the World Health Organisation's International Agency for Research on Cancer, which considered more than 800 studies conducted around the world.\nOverall, the IARC review found that the strongest evidence linked processed meats (such as hot dogs, beef jerky, bacon and ham) to colorectal cancer - with each hot-dog-size serving of processed meat eaten daily raising the risk by 18 percent over a lifetime.More than 34,000 cancer deaths are caused around the world each year by diets high in processed meat, according to data referenced in the IARC report.By comparison, tobacco causes about a million cancer deaths annually. Alcohol consumption causes 600,000. And air pollution is responsible for 200,000.The IARC review also found evidence for an association between unprocessed red meat (such as beef or pork) and colorectal cancer, along with some evidence that red meat might contribute to pancreatic and prostate cancers, too.Studies show several ways that meat might cause cancer, says Loic Le Marchand, an epidemiologist at the University of Hawaii Cancer Centre, who collaborated with more than 20 international scientists on the IARC report.\nOne line of evidence points to compounds called nitrates and nitrites, which are used during processing and also form in the colon when people digest meat and meat products, even those labelled 'nitrate-free'.Cooking methods make a difference, according to studies that have zeroed in on two groups of chemicals that appear in particularly large quantities when meat, fish or poultry is cooked under high heat by grilling, barbecuing, broiling or even pan-frying.One group, called HAAs (heterocyclic aromatic amines), form during high-temperature reactions between substances in muscle tissue. PAHs (polycyclic aromatic hydrocarbons), which form when meat is smoked, charred or cooked over an open flame, are also found in tobacco smoke.In general, Turesky says, higher temperatures and longer cooking times lead to higher levels of HAAs and PAHs.\nEnzymes in our bodies then change these chemicals into compounds that can damage DNA. Numerous studies have illustrated that kind of damaging potential in cell cultures and animals, including rodents and primates.But does meat actually cause cancer in people?Turesky is beginning to turn up evidence that it might. In a\u00a0study\u00a0published last year, he and colleagues studied biopsies of prostate tumours and found that DNA in the cancer cells had been damaged by HAAs.\"This is the first unequivocal proof that, once you eat the cooked meat mutagens, some of them find their way to the prostate and damage the prostate,\" Turesky says.The study doesn't prove that meat caused the cancer, he adds. \"It could just be an association. Now we have to show that the mutations are attributed to the chemicals in cooked meat."
        ]
    },
    "7822": {
        "gold_standard": [
            "Recreational marijuana use is now legal in eight states plus the District of Columbia, giving public health researchers more leeway than ever to investigate some of the foundational underpinnings of cannabis culture:\u00a0How much weed is in a joint?\u00a0What happens to your brain when you get high?\nAnd now: Are\u00a0chronic marijuana users really more relaxed than everyone else?\u00a0You might be surprised to learn that the research to date on this question is mixed.One recent study found that while low doses of THC (the active chemical compound in pot) helped people cope with stressful situations, moderate to higher doses\u00a0actually made people stress out\u00a0even more.\u00a0\u00a0But that particular study simply measured the effects of a single dose of THC - what about the effects of repeated\u00a0heavy cannabis use?Enter\u00a0new research from Washington State University, recently published in the journal Psychopharmacology.The study recruited two groups of 40 people: One group had used marijuana nearly every day for at least a year, and the other comprised people\u00a0who\u00a0weren't marijuana users.Half of each group, users and nonusers, was subject to a particularly anxiety-inducing laboratory test commonly used to measure stress responses:\nThey had to dunk their hands in a container of cold water for anywhere from 45 to 90 seconds, and then count backward from 2,043 by 17, getting reprimanded by lab workers whenever they got a number wrong.As if that weren't bad enough, they\u00a0were also shown a live video feed of their faces as they attempted to count.The other half of each group was subject to a non-stressful \"control\" scenario: Dip a hand in warm water, count from 1 to 25, no reprimands, no video.The meat of this study comes from comparing the stress responses of the cannabis users and the nonusers.To assess\u00a0this, the researchers measured the amounts of cortisol, the body's\u00a0primary stress hormone, in the subjects' saliva immediately after they took the stress tests.\"Despite abstaining from cannabis use on the day of testing,\" the researchers found, \"cannabis users exhibited\u00a0no increase\u00a0in salivary cortisol concentration in response to the stress manipulation compared to non-users\" [emphasis added].\nFor a sanity check, the researchers also had the subjects self-evaluate their perceived levels of stress. Same finding: Nonusers rated themselves as more stressed out than the chronic marijuana users.The heavy users, in other words, reacted to a stressful situation with equanimity and chill even though they weren't stoned at the time of the test.There's an outside chance that some of this effect could be due to self-selection: Perhaps naturally relaxed people are more inclined to become frequent cannabis users?But the effects were observed in a controlled laboratory experiment, making the causal link much stronger than it would have been if the researchers had just relied on, say, pre-existing survey data.This is somewhat unsurprising:\u00a0Surveys show that \"relaxation\"\u00a0is the No. 1 reason cited by marijuana users for why pot is their drug of choice.\nThis research confirms that they're probably not just deluding themselves and that over the long term, marijuana use does perhaps lead to a somewhat more relaxed outlook on life.But, as the researchers note, this can be a double-edged sword. Stress is an adaptive response to potentially dangerous or harmful situations.Dampening that response in otherwise healthy individuals may have unintended consequences: Prior research has shown links between unbalanced\u00a0cortisol levels and\u00a0PTSD\u00a0and\u00a0depression, for instance.On the other hand, stress\u00a0and anxiety can be debilitating conditions in and of themselves. For certain individuals, self-medicating with pot may provide an optimal level of stress relief without risk of some of the\u00a0nastier side effects of prescription medications, for instance"
        ]
    },
    "7831": {
        "gold_standard": [
            "Body organs such as kidneys, livers and hearts are incredibly complex tissues. Each is made up of many different cell types, plus other components that give the organs their structure and allow them to function as we need them to.\nFor 3D printed organs to work, they must mimic what happens naturally \u2013 both in terms of arrangement and serving a biological need. For example, a kidney must process and excrete waste in the form of urine.Our latest paper shows a new technique for 3D printing of cells and other biological materials as part of a single production process. It's another step towards being able to print complex, living structures.But it's not organ transplants we see as the most important possible consequence of this work.There is already evidence that 3D cell printing is a technology useful in drug development, something that may reduce the burden on animals for testing and bring new treatments to market more quickly and safely.How we 3D bioprint3D printing was first developed for rapid fabrication of industrial parts using methods known as sterolithography and fuse deposition modelling.\nAdd \"biology\" (that is, cells) to the printing technique and it becomes an entirely new process: 3D bioprinting.3D bioprinting requires sterile conditions to avoid contamination of the bioprinted sample, and an appropriate temperature and humidity so the cells don't die. Also, the plastic materials traditionally used in 3D printing cannot be used in bioprinting, as they require high temperatures or toxic solvents.We and other researchers around the world are developing materials that can be manipulated in a 3D printer while causing minimal harm to the cells.However, each cell type that makes up the different tissues of the human anatomy requires a unique mechanical environment. Each requires unique structural supports to function normally.As an example, bones are a resistant and brittle material, muscles of the heart are elastic, tough materials, and internal organs such as the liver are soft and compressible.\nIn a recent publication, we and our colleagues show that new materials extracted from marine algae can be used to 3D bioprint human stem cells in distinct environments, and without harming the cells. We believe that these findings pave the way toward the printing of complex tissue structures.Steffen HarrHoping for new organsCurrently, patients needing replacement organs must wait for availability (from living or deceased donors) and are then required to be on immunosuppressive drugs for most of the rest of their lives, causing side effects and creating a tremendous cost for the healthcare system.The development of 3D-printed biological tissues for organ replacement hopes to offer a new solution for the 1,500 patients on the organ receiver waiting list every year in Australia.\nBut printing of entire organs is an incredibly complex process, one that takes weeks of time that a patient may not have up his or her sleeve.Also, while this process is somewhat advanced for relatively simple tissues such as skin, the next phase of the technology requires incorporation of nerves, blood vessels and lymphatic vessels that would integrate with the host system to create transplantable whole organs such as kidneys, lungs, hearts or livers.Steffen HarrWe're probably many many years and millions of dollars away from being able to bioprint whole, functional human organs.But there's another way bioprinted cells can be used: for testing new drugs in the laboratory.\nBioprinted cells for drug testingUsing current methods, bringing a new drug to market has been estimated to cost US$2.5 billion, and can take more than ten years from start to finish.Even if you manage to identify a new candidate drug, the likelihood of regulatory approval is low: in 2016, less than 10\u00a0percent\u00a0were approved.When starting human clinical trials, the probability of a drug to make it to the market is between 10 and 15 percent depending on the type of molecule , with illness or even death for participants.We know that these drugs mainly fail due to poor efficacy in humans despite promising results in animals. This disconnect is due to the different physiology between species: rodents and other trial animals are very different from humans in many key ways.3D printing technology allows us to print more complex 3D models that reproduce aspects of the liver, kidneys or heart muscles that are suitable to test and identify novel pharmaceutical molecules. These models are already starting to be used by multinational pharmaceutical companies.\nWhile the use of animals in research is still inevitable, the regulatory agency the Food and Drug Administration and its new director have already started to consider integrating alternatives for drug safety and efficacy assessment.The idea that bioprinted tissues have promise for drug development is already recognised, with funding agencies here in Australia and globally supporting projects.Steffen HarrToward the end of the animal testing?In 2013 the European Union passed a new law prohibiting the use of animal testing for cosmetic development on its territory, and of retailing products tested abroad on animals.This regulation has accelerated the development of human-based 3D models of skin for the testing of new cosmetic formulations. These resolutions were accepted because the technology was available and has enabled a reduction in the number of research animals.This is about to be translated in Australia as well.The changes operated in other industries combined with the exciting technological advances let us have a glance at how 3D bioprinting may be able to contribute to faster and cheaper ways to create effective new drugs.Aurelien Forget, Associate Lecturer in Macromolecular Chemistry, Queensland University of Technology and Tim Dargaville, ARC Future Fellow, A/Prof Polymer Chemistry, Queensland University of TechnologyThis article was originally published by\u00a0The Conversation. Read the original article.Queensland University of Technology is a sponsor of ScienceAlert"
        ]
    },
    "7834": {
        "gold_standard": [
            "There's a new checkmark in the 'drinking isn't all bad for you' column.According to\u00a0a new study that looked at more than 70,000 Danish people, those who drink small to moderate amounts of alcohol on a frequent basis are less likely to develop diabetes than people who don't drink at all.\nTo be clear, these results shouldn't be seen as licence or encouragement to drink freely as a health-promoting exercise.But they do provide further evidence that, for some reason, people who drink moderately are less likely to suffer from certain illnesses, including\u00a0some cardiovascular diseases\u00a0and type-2 diabetes.For the new study, researchers wanted to see how much alcohol consumption was associated with the lowest diabetes risk, and determine whether the type of alcohol or the frequency that people drank mattered.Using data from the Danish Health Examination Survey, they looked at the drinking habits of 28,704 men and 41,847 women, and tracked whether those people developed diabetes within approximately five years.The researchers excluded anyone who already had diabetes, was pregnant at the start of the study, and didn't provide information on their alcohol consumption.\nThe results showed that the study participants least likely to develop diabetes drank 3-4 days a week. For men, those who drank 14 drinks per week had the lowest risk, as the chart on the left shows below.For women, those who drank nine drinks per week had the lowest risk, as the right-hand chart shows.Diabetologia, 2017As the U-shaped risk curve shows, study participants who didn't drink at all seemed to have a higher risk of developing diabetes. People who drank moderately had a lower risk, up to a certain point - after that, risk started to rise again.Even heavy drinkers (up to 40 drinks per week for men and 28 drinks per week for women), however, still had a lower risk of developing diabetes than teetotalers.\nThe lowest risk was associated with drinking that was spread out throughout the week, rather than occurring in the same day or two.The type of alcohol mattered too. Men and women who drank wine had the lowest diabetes risk. For men, beer was also associated with a lower risk.Spirits didn't seem to affect risk for men, but women who drank seven or more drinks of spirits a week had an increased risk of developing diabetes.A brief but important aside on\u00a0diabetes: The design of this study didn't allow researchers to say whether drinkers had a lower risk of developing type-2 diabetes or type 1.Type 2 is generally caused by lifestyle factors and prevents the body from using insulin, whereas type 1 cannot be prevented since the body simply doesn't produce enough insulin.The researchers say their study should refer to type-2 diabetes, since their results held true even if they eliminated anyone under 40 (by which point the vast majority of people with type-1 diabetes already have it"
        ]
    },
    "7835": {
        "gold_standard": [
            "Scientists at Columbia University discovered during a study\u00a0published in the journal\u00a0Hippocampus\u00a0that the memories of mice with Alzheimer's disease can be recovered optogenetically - meaning with the use of lights.\nThis could shift our understanding of the disease from the idea that it destroys memories to the concept that it simply disrupts\u00a0recall mechanisms.The results were garnered by comparing healthy mice with mice given a disease similar to human Alzheimer's.First, parts of mice's brains were engineered to glow yellow during memory storage and red during memory recall.Then, the mice were exposed to the smell of lemon followed by an electric shock - associating the two memories.A week later, they were given the smell of lemon again: the healthy mice's red and yellow glows overlapped and they expressed fear, showing they were accessing the right memories.However, the Alzheimer's brains glowed in different areas, and the diseased mice were indifferent, showing they were recalling from the wrong sections of the brain.\nThe team, lead by\u00a0Christine A. Denny, then used a fibre optic cable to shine a blue laser into the mice's brains. This successfully \"reactivated\" the lemon and electric shock memory and caused the mice to freeze when they smelt it.The research could possibly revolutionise Alzheimer's research and treatment, helping the\u00a05 million Americans\u00a0who are suffering from\u00a0the disease.\u00a0Ralph Martins\u00a0at Edith Cowan University in Australia\u00a0told New Scientist\u00a0that \"it has the potential to lead to novel drug development to help with regaining memories.\"However, the crucial question is whether mice brains and the artificial Alzheimer's disease that the team exposed them to are sufficiently similar to the human variant for the results to be medically significant.In particular, humans lose more neurons than mice during the course of Alzheimer's, and it would be extremely difficult to target specific memories because our brains are far more complicated.\nWhile further studies must be done, these\u00a0findings are one of many promising avenues that are currently being developed in Alzheimer's research.\u00a0 Artificial intelligence is being\u00a0applied to the condition\u00a0and has successfully predicted who will develop Alzheimer's 10 years out, the leukemia drug nilotinib\u00a0has been shown to help\u00a0combat the condition - and finally, a \"metabolic enhancement for neurodegeneration\" treatment has also reversed some of its symptoms.This article was originally published by Futurism. Read the original articl"
        ]
    },
    "7837": {
        "gold_standard": [
            "Astronomers have now discovered plenty of exoplanets \u2013 planets outside our Solar System orbiting suns like our own \u2013 but the hunt for smaller exomoons around these planets goes on. Now astronomers think they might have found the very first.\nThe potential exomoon has been revealed thanks to the magnifying power of NASA's Kepler telescope, and could eventually have a lot to teach us about the formation of planets, moons, and star systems.So far this potential exomoon has passed its first set of tests, apparently causing three dips in starlight that we've measured \u2013 one of the tell-tale signs that something significant is out there. It also has a name: Kepler-1625b I.\"We're excited about it,\" one of the team, David Kipping from Columbia University, told the BBC. \"Statistically, formally, it's a very high probability. But do we really trust the statistics? That's something unquantifiable.\"This find is part of a larger project called The Hunt for Exomoons with Kepler (HEK), an attempt to make a systematic search of the galaxies outside the Milky Way using Kepler's capabilities \u2013 the orbiting space observatory can track the brightness of more than 145,000 stars in its fixed field of view.\nThe new exomoon candidate has been observed around a star some 4,000 light-years away from Earth, and is believed to be around the size of Neptune (inspiring team members to give it the nickname Nep-moon).As for the planet it could be circling, Kepler-1625b, that looks to be the size of Jupiter. The current hypothesis is that the vast gravitational pull of Kepler-1625b pulled the moon Kepler-1625 I into orbit at some point in time.The next stage is to take further readings using the Hubble telescope in October, which should help confirm whether or not we're looking at an exomoon.This is about more than just ticking an exomoon box: as we've seen with Saturn's moons in our own Solar System, these rocky objects could well have conditions that are more habitable than the planets they're orbiting. Our next stop as humankind could be a moon rather than a planet.\nDespite that statistical \"high probability\" we mentioned earlier, the researchers say they're still 50-50 on whether this will turn out to be an exomoon. Their work has yet to be published in a peer-reviewed journal as well, so other astronomers haven't yet had a chance to analyse the findings.And we've been here before. Another candidate was identified back in 2014, but scientists still have no way of proving whether it really is an exomoon or not.We shouldn't get too excited then \u2013 but there's a real chance that our long hunt to find an exomoon is nearly over.\"I'd say it's the best [candidate] we've had,\" Kipping told Paul Rincon at the BBC.\"Almost every time we hit a candidate, and it passes our tests, we invent more tests until it finally dies \u2013 until it fails one of the tests\u2026 in this case we've applied everything we've ever done and it's passed all of those tests. On the other hand, we only have three events.\"The findings have yet to be peer-reviewed but you can read them on the pre-print website arXiv.or"
        ]
    },
    "7841": {
        "gold_standard": [
            "g One in 8 couples has\u00a0difficulty getting pregnant or carrying a baby to term, leading more than 11\u00a0percent of women in the United States to\u00a0use fertility services.\u00a0In my private nutrition practice, I'm seeing more and more clients in their 30s and 40s who are trying to get pregnant and want to make sure their eating habits help their chances of conception and support a healthy pregnancy.\nMost of what we know about the effect of nutrition on fertility is courtesy of a study based on data from the\u00a0landmark Nurses' Health Study. The \"fertility diet\" study followed nearly 18,000 women who were trying to conceive, and tracked their nutrition and lifestyle habits over eight years.Participants followed a diet including plenty of plant-based foods such as vegetables, fruit, whole grains and beans, as well as protein-rich foods, healthy fats and a bit of full-fat dairy.The researchers observed that a specific eating pattern was linked to having a 66\u00a0percent lower risk of ovulatory infertility and a 27\u00a0percent lower risk of infertility from other causes.While this study doesn't show cause and effect, it does provide us with some valuable insights into nutrition and fertility.\nThe 'fertility zone'If you're over- or underweight, getting to a healthy weight range is one of the most important steps you can take to boost your fertility.There appears to be a \"fertility zone\" for weight. To get your BMI, or body mass index, visit the National Institutes of Health website and use its\u00a0BMI calculator. If you're overweight, losing 5 to 10\u00a0percent of that weight can positively fertility.About 75\u00a0percent of overweight women who struggle with fertility have\u00a0polycystic ovary syndrome (PCOS), so it's important to get checked by your doctor to have any health issues resolved and/or managed.This emphasis on weight doesn't mean it's time to crash diet. Food scarcity (a.k.a. dieting) negatively influences your fertility.It makes sense from a biological perspective: Your body needs to know the food supply is reliable and nutritious before bringing a baby on board.\nA recent systematic review found that a balanced eating plan that promotes\u00a0gradual weight loss is better for fertility than drastically cutting calories.Men also need to follow a healthy eating plan and get to a healthy weight to boost fertility. Being overweight can have a negative impact on testosterone levels,\u00a0sperm count\u00a0and motility.Low-carb or slow carb?There has been some headline-grabbing buzz that\u00a0low-carb diets\u00a0increase fertility. A\u00a0recent review\u00a0of low-carb diets and fertility found that of the interventions that have been done, the definition of a low-carb diet varies greatly and often is combined with other interventions.As a result, we don't know enough about the effect of these diets to recommend them during the pre-conception period. Further, overdoing it on animal protein probably isn't helpful.\nThe \"fertility diet\" study found that ovulatory infertility was almost 40\u00a0percent more likely in women who ate the most animal protein.According to Hillary Wright, a dietitian and director of nutritional counseling for the Domar Center for Mind/Body Health at Boston IVF, \"The body uses nutrients in plant-based foods to neutralise the effects of toxic exposure, inflammation and more, so it makes sense to emphasise these foods during pre-conception and beyond.\"The researchers looking at the fertility diet found that the more women ate fast-absorbing carbs such as white bread, white rice, potatoes, soda and candy, the higher their risk for ovulatory infertility.They also observed that eating slow-absorbing carbs such as vegetables, whole grains, beans and lentils can provide a fertility boost. As an added bonus, a high-fibre diet reduces the risk of gestational diabetes.\nWright advises clients to get their carbohydrates from whole foods and to spread them throughout the day in smaller portions. She recommends making half your plate at each meal non-starchy vegetables, a quarter protein-rich foods and a quarter fibre-rich carbohydrates with some healthy fat.Getting more vegetables, legumes, whole grains, fruit, nuts and seeds means more fibre and phytochemicals in your diet,\u00a0helping to manage weight, improve health and boost fertility.Taking in plenty of antioxidants from produce also seems to be beneficial for male fertility.Should you switch to whole milk?In the \"fertility diet\" study, consuming one to two servings of full-fat dairy products a day was linked to increased fertility, while low-fat versions showed the opposite trend. It seems that having some whole milk or higher-fat yogurt could positively affect ovulation and conception, because the cream component of milk influences its balance of sex hormones.\nBefore you start putting cheese on everything and finishing every meal with a bowl of ice cream, note that it's one or two servings a day, and it's best to choose nutrient-rich options.Wright advises her clients to use their saturated fat \"budget\" wisely. If you're going to have some higher-fat yogurt, put skim milk in your oatmeal.You also don't want to get your fat from processed foods, as hydrogenated oils negatively impact fertility.Although the\u00a0Food and Drug Administration has banned the use of artificial trans fats\u00a0in processed foods, this doesn't come into effect until June 2018.\u00a0Until then, read your ingredients lists and limit anything that has partially hydrogenated oils.Better yet, eat whole foods rather than packaged ones. That's great advice for anyone to follow.2017 \u00a9\u00a0The Washington PostThis article was originally published by\u00a0The Washington Pos"
        ]
    },
    "7846": {
        "gold_standard": [
            "Scientists have created an ultrathin energy harvesting device that generates electricity from human motion.\u00a0The material could be placed in the fabric of clothing to charge your smartphone, fitness tracker and other personal electronics while you go about your daily life.\n\"In the future, I expect that we will all become charging depots for our personal devices by pulling energy directly from our motions and the environment,\" said researcher Cary Pint\u00a0from Vanderbilt University in the US.A lot of research has been conducted into the harvesting of so called ambient energy sources, such as energy from vibrations and deformations, temperature variations, or energy from light, radio waves and biochemical reactions. Recently, we have even witnessed the invention of a smart phone that used ambient radio waves to power itself.But one valuable energy source has gone untapped \u2013 excess energy from human motion.Lots of devices have been proposed to capture the energy from low frequency human motion but often the materials work best when the movements happen over 100 times per second \u2013 missing out on the energy from the majority of human movements.\nThis new device is 1/5000th the thickness of a human hair and able to extract even the subtlest of human movements.\"Compared to the other approaches designed to harvest energy from human motion, our method has two fundamental advantages,\" said Pint.\"The materials are atomically thin and small enough to be impregnated into textiles without affecting the fabric's look or feel and it can extract energy from movements that are slower than 10 Hertz \u2013 10 cycles per second \u2013 over the whole low-frequency window of movements corresponding to human motion.\"In this new study, the scientists use a film of black phosphorus, a material that has nanotechnologists excited by its electrical, optical and electrochemical properties. Until now, graphene\u00a0has been the most exciting material in this space, and it seems the two could actually work well together.\nThe team created their energy harvester by sandwiching an electrolyte between two identical black phosphorus electrodes.\u00a0The electrodes are made by using a chemical process that involves laying thin layers of black phosphorus onto graphene.Working together, the 2D wonder materials bend and flex to create energy.The team found that their prototype designs can produce energy from movements lower than 10 Hertz (10 movements per second) and even as low as 0.01 hertz, or, one movement every 100 seconds \u2013 it would be harder to avoid moving that often than not.Lining your favourite jacket with these devices is all well and good, but we wouldn't want to go up in flames like the recent batch of batteries for some smartphones. So, are these devices safe?\nPint is confident that we won't seeing any tech-triggered immolation from his device.\"One of the peer reviewers for our paper raised the question of safety,\" said Pint. \"That isn't a problem here. Batteries usually catch on fire when the positive and negative electrodes are shorted, which ignites the electrolyte.\"\"Because our harvester has two identical electrodes, shorting it will do nothing more than inhibit the device from harvesting energy. It is true that our prototype will catch on fire if you put it under a blowtorch but we can eliminate even this concern by using a solid-state electrolyte.\"At the moment, the devices are limited by the voltage produced from movements \u2013 it's only in the millivolt range. However, this is next on the agenda for the research team and Pint believes there are potential applications for their device beyond power systems"
        ]
    },
    "7866": {
        "gold_standard": [
            "While the planet is working on cutting emissions to curb climate change, some scientists are saying we can also help our planet out by directly messing with our atmosphere.Collectively known as geoengineering, these technology-based climate hacks could be our ticket to actively cooling down the planet, but they are untested and potentially dangerous, and therefore have remained controversial for decades. And yet scientists keep bringing them u Now an international team of researchers has run the numbers on how we might stabilise global temperatures by using a 'cocktail' of solar geoengineering tools intended for deflecting solar radiation away from the planet.The scientists modelled what would happen if we used sulphate particles to scatter the sun's rays in the atmosphere and simultaneously thinned out sunlight-reflecting clouds to reduce warming.\"As far as I know, this is the first study to try to model using two different geoengineering approaches simultaneously to try to improve the overall fit of the technology,\" says one of the team, Ken Caldeira from Carnegie Institution, US.The simulations showed that this cocktail could decrease temperatures back to pre-industrial levels without dramatically increasing rainfall. But there are caveats - the team worked under the assumption that the methods would work as predicted, without unexpected drama.\n\"A thorough investigation of these potential side effects is .. beyond our scope,\" they write in the study.There's actually been a flurry of talk about solar geoengineering lately. In fact, one of the strategies suggested for this 'cocktail' was discussed just last week in Science.Ulrike Lohmann and Bla\u017e Gasparini from the Swiss Institute of Atmospheric and Climate Science explained how exactly we can thin out the wispy high-atmosphere cirrus clouds that don't reflect much solar radiation, but still manage to trap quite a lot of heat.They propose 'seeding' these clouds - planting large particles such as desert dust or pollen that essentially help break up the cirrus formations, thinning them out and decreasing their heat-trapping potential.G. Grullon / Science (2017)Meanwhile Ulrike Niemeier from Max Planck Institute in Germany and Simone Tilmes from US National Center for Atmospheric Research suggested that if we reach a point when drastic interventions are necessary to prevent the worst effects of climate change, we could consider mimicking a volcanic eruption to cool things down.\nThis technique relies on continuously injecting sulphur into the stratosphere, which creates dense clouds better capable of reflecting solar radiation. We would need loads of sulphur though. The team calculates it would take 6,700 flights per day to deliver the sulphur to the stratosphere, costing about US$20 billion per year.And that's not all. Earlier this month a team from the University of Washington proposed an early-stage test for 'marine cloud brightening'.This involves spraying saltwater in the sky above a coastal area of the Pacific Ocean to produce large, long-lived bright white clouds good at reflecting the sun's light away from the planet's surface.That sounds pretty nuts, but if we hear them out, turns out such a test (they are currently seeking funding for this caper) could also answer a vitally important question that's been bothering climate scientists.\nWhen it comes to modelling climate change, clouds are actually some of the biggest spanners thrown in the works, because there's a lot of uncertainty over how human-produced aerosols affect them.\"To overcome these challenges, it would be extremely valuable to explore aerosol influences on clouds in situations where meteorological and source variability do not introduce confusion,\" the University of Washington researchers write in the paper.By controlling every aspect of the particles injected into the marine clouds, not only could we potentially brighten them and reflect some sunlight, but also produce a 'controlled experiment'. The team proposes it could be an unprecedented source of data for climate models.\"Testing out marine cloud brightening would actually have some major benefits for addressing both questions,\" says lead researcher Rob Wood"
        ]
    },
    "7890": {
        "gold_standard": [
            "A prototype vaccine, decades in the making, that could prevent type 1 diabetes in children is ready to start clinical trials in 2018.It's not a cure, and it won't eliminate the disease altogether, but the vaccine is expected to provide immunity against a virus that has been found to trigger the body's defences into attacking itself, potentially reducing the number of new diabetes cases each year.\nOver two decades of research led by the University of Tampere in Finland has already provided solid evidence linking a type of virus called coxsackievirus B1 with an autoimmune reaction that causes the body to destroy cells in its own pancreas.The type 1 form of diabetes \u2013 not to be confused with the more prevalent type 2 variety that tends to affect individuals later in life \u2013 is a decreased ability to produce the insulin used by the body's cells to absorb glucose out of the blood.This loss of insulin is the result of pancreatic tissue called beta cells being destroyed by the body's own immune system, often within the first few years of life.It's something of a mystery as to why the body identifies beta cells as foreign, though there could be a genetic link producing variations of human leukocyte markers, which act as the cell's 'ID tags'.\nNo doubt it's complex, and there are numerous ways this process can be triggered. One example established by virologist Heikki Hy\u00f6ty from the University of Tampere is an infection by a type of enterovirus.Enteroviruses are nasty pieces of work; you might be most familiar with polio, but they can also cause hand, foot and mouth disease, meningitis and myocarditis. There has been suspicion of a link between this group of pathogens and diabetes for a number of years, but it took time to nail down the prime suspects.In 2014, Hy\u00f6ty and his team used a pair of studies on Finnish children with type 1 diabetes to show that at least one of the six viruses in the B group of coxsackieviruses was associated with the condition.Enteroviruses are surprisingly common in newborns, with the Centres for Disease Control and Prevention (CDC) finding that around a quarter of the 444 known enterovirus infections in the US in 2007 were caused by coxsackievirus B1 (CVB1).\nAnd for some of those children, it could have been the start of a life-long, incurable condition.\"One can estimate from the generated data that less than 5 percent of CVB1-infected children go on to develop type 1 diabetes,\" the researchers wrote in their 2014 study.That might not seem like a lot, but it does suggest each year hundreds of infants around the globe develop type 1 diabetes. If the other members of the CVB group also contribute to beta cell autoimmunity \u2013 which they might \u2013 the numbers could be higher.If all goes well, this newly developed vaccine could put a stop to that.\"Already now it is known that the vaccine is effective and safe on mice,\" says Hy\u00f6ty.\"The developing process has now taken a significant leap forward as the next phase is to study the vaccine in humans.\"\nPre-clinical trials are of course just the first step. The next phase will involve testing on healthy adult humans, just to map out any complications.As a bonus, the vaccine could help reduce other enterovirus infections.\"Additionally, the vaccine would protect from infections caused by enteroviruses such as the common cold, myocarditis, meningitis and ear infections,\" says Hy\u00f6ty.It could be another eight years before we see whether the vaccine does what it's supposed to do, so we shouldn't be expecting anything revolutionary too soon.Meanwhile, groups like the Juvenile Diabetes Research Foundation (JDRF) are continuing to fund research into finding better ways to prevent and treat type 1 diabetes by improving technology that mimics the function of the pancreas or by identifying ways to regenerate insulin-producing cells.\nEarlier this year, researchers identified an immature cell in the pancreas which can potentially be encouraged to take up the job of lost mature beta cells.There will be no single cure, treatment, or prevention which will gives us a diabetes-free world.Between 20 and 40 million people worldwide live with type 1 diabetes. A vaccine like this might not end the disease, but if it works it's certainly going to be a big step forwar"
        ]
    },
    "7924": {
        "gold_standard": [
            "Scans taken of fluids moving through rock have shown engineers have had it wrong when it comes to substances flowing through porous materials.For the past century, the movement of gases and liquids through rocks has been modelled using a law that assumes they flow in a stable pattern. Under the microscope, it turns out this was the wrong assumption to make.\nThe discovery made by researchers from Imperial College London might not seem all that ground-breaking, but any future technology that aims to capture carbon dioxide and store it in underground reservoirs would need their models on how gases move to be as accurate as possible.By scanning a block of sandstone with X-rays produced by a synchrotron called the Diamond Light Source, the engineers created high-speed videos of nitrogen gas and liquid salt-water seeping through microscopic channels, giving them the most detailed moving images of the process to date.Previously X-ray scans took single captures over a number of hours. Using the synchrotron's bursts allowed them to snap the same images in as little as 45 seconds to create a more accurate animation.Until now it was thought that the two different phases of fluid would stick to their own channel, flowing in a static, if still complex manner.\nThis was all thanks to a 19th century French engineer named Henry Darcy, who came up with a hydraulics law to describe how fluids moved through porous materials.His law was later extended to mathematically describe the relative permeability of a porous material, one that depended on the phase of fluid pushing through it.Darcy's extended law didn't take into account interactions between different fluids moving through their own channels, which although an assumption, has been a useful way to describe most hydraulic phenomena.The images produced by the Imperial College researchers shows that far from being stable, the pathways taken by the two fluids stutter and shift, lasting no more than tens of seconds before taking a new direction.Take a look at the short clip below to get a better idea of their findings.\nwidth=\"700\u2033 height=\"414\u2033 style=\"display: block; margin-left: auto; margin-right: auto;\" allowfullscreen=\"allowfullscreen\">The researchers liken it to a tiny road-network with traffic lights.\"The flow of cars through the network can be stopped by a red traffic light, blocking a junction for a short time. When the light turns green \u2013 when the local energy balance\u00a0favours movement again \u2013 the flow continues down the same road,\" the researchers write.Since the sudden shifts in 'traffic' take just a split moment, the researchers hope to eventually capture images on the scale of 100ths of a second, something currently impossible with existing X-ray technology.They have called this process dynamic connectivity, and it could have significant applications in a variety of contexts.\n\"Trying to model how fluids flow through rock at large scales has proven to be a major scientific and engineering challenge,\" says lead researcher Catriona Reynolds.\"Engineers have long suspected that there were some major gaps in our understanding of the underlying physics of fluid flow. Our new observations in this study will force engineers to re-evaluate their modelling techniques, increasing their accuracy.\"Carbon capture and storage (CCS) is one engineering feat that requires sound understanding of how gases and liquids move through a porous substance.In simple terms, the practice would see emissions from industrial fossil fuel combustion pumped into stable subterranean reservoirs, such as deleted oil and gas fields or deep saline aquifers.There are various proposed solutions, including dissolving CO2 in water and pumping it into basalt where it could mineralise, trapping the carbon as a solid.\nSuch diverse technologies would all have their pros and cons, and pose clear risks and benefits. But most would benefit from knowing what's happening to the fluids at a microscopic level.The modifications to the existing models could also have applications in understanding how freshwater moves into aquifers deep underground, or how seawater flows through the bedrock, providing a more accurate insight into the crust's volatility.Controversially, it might also help improve processes that extract fossil fuels from underground, providing safer, more efficient fracking processes.No doubt Mr Darcy would be quite pleased to find it was time his old law was given a good tweak.This research was published in PNA"
        ]
    },
    "7953": {
        "gold_standard": [
            "Scientists have 3D-printed a soft, artificial heart made of silicone that beats almost like a human heart, putting us another step closer to replacing damaged human hearts without the need for a transplant.\nWith about 26 million people worldwide suffering from heart failure, and a global shortage of donors, being able to custom-make artificial hearts would be an invaluable solution to a perennial, long-term problem.The team behind the artificial heart, from ETH Zurich in Switzerland, says its prototype heart can beat in a very natural way for about half an hour before the materials break down, and the researchers are working hard to improve their new invention.\"[Our] goal is to develop an artificial heart that is roughly the same size as the patient's own one and which imitates the human heart as closely as possible in form and function,\" says one of the team, Nicholas Cohrs.The silicone heart features left and right ventricles or chambers, just like a human heart, as well as an additional chamber that acts as the heart's engine by driving the external pump.Credit: ETH ZurichThe idea is that pressurised air inflates and deflates this third chamber, which would drive blood through the ventricles \u2013 for the purposes of this study, a liquid with the same viscosity of blood was used.\nWeighing in at 390 grams (13.8 ounces) and with a volume of 679 cubic centimetres (41 cubic inches), it's slightly heavier but about the same size as a normal human heart. it's hoped this artificial version can eventually replace mechanical pumps, which are always at risk of failure or causing complications in the body.Right now these mechanical pumps are used while people recover from heart failure or wait for a donated heart to become available.With each silicone heart only lasting for around 3,000 beats, the strength of the material and the performance of the heart need to be significantly increased \u2013 but having a soft, 3D-printed heart beating like a human one is a fantastic start.\"This was simply a feasibility test,\" says Cohrs. \"Our goal was not to present a heart ready for implantation, but to think about a new direction for the development of artificial hearts.\"\nIf we can't replace this most crucial of organs with a 3D-printed version then perhaps there's hope in regenerating damaged heart tissue. Last month scientists explained how gene programming in a sea anemone could unlock a way of teaching human stem cells to replace heart tissue.Meanwhile, earlier this year a team from Worcester Polytechnic Institute (WPI) used spinach leaves to generate functioning heart tissue, complete with veins that could transport blood.We're still a long way off being able to replace or regrow the human heart \u2013 but it's exciting to think we're getting closer all the time.The research has been published in Artificial Organs"
        ]
    },
    "7966": {
        "gold_standard": [
            "Evidence gathered over 60 years about adding fluoride to drinking water has failed to convince some people this major public health initiative is not only safe but helps to prevent tooth decay.\nMyths about fluoridated water persist. These include fluoride isn't natural, adding it to our water supplies doesn't prevent tooth decay, and it causes conditions ranging from cancer to Down syndrome.The Australian National Health and Medical Research Council (NHMRC) is in the process of updating its evidence on the impact of fluoridated water on human health since it last issued a statement on the topic in 2007.Its draft findings and recommendations are clear cut:\nNHMRC strongly recommends community water fluoridation as a safe, effective and ethical way to help reduce tooth decay across the population.\nIt came to its conclusion after analysing the evidence and issuing a technical report for those wanting more detail.Here are four common myths the evidence says are wrong.1. Fluoride isn't natural\nFluoride is a naturally occurring substance found in rocks that leaches into groundwater; it's also found in surface water. The natural level of fluoride in the water varies depending on the type of water (groundwater or surface) and the type of rocks and minerals it's in contact with.Fluoride is found in all natural water supplies at some concentration. Ocean water contains fluoride at around 1 part per million, about the same as levels of fluoridated drinking water in Australia.There are many places in Australia where fluoride occurs naturally in the water supply at optimum levels to maintain good dental health. For example, both Portland and Port Fairy in Victoria have naturally occurring fluoride in their water at 0.7-1.0 parts per million.What is the Difference Between Natural Fluoride and the Kind That is Artificially Added to Our Water Supply? |... https://t.co/yK7azTPIsd\u2014 sunflowerdance (@paramofsunflowe) June 22, 2017The type of fluoride commonly found in many rocks and the source of the naturally occurring fluoride ion in water supplies is calcium fluoride.\nThe three main fluoride compounds generally used to fluoridate water are: sodium fluoride, hydrofluorosilicic acid (hexafluorosilicic acid) and sodium silicofluoride. All these fully mix (dissociate) in water, resulting in the availability of fluoride ions to prevent tooth decay.So regardless of the original compound source, the end result is the same \u2013 fluoride ions in the water.2. Fluoridated water doesn't workWhat doesn't work to improve oral health? Fluoridated water. What's the solution? More fluoridated water. http://t.co/NesFAAfLv8\u2014 fluoridefreeAUS (@FluorideFreeAus) January 30, 2014Evidence for water fluoridation dates back to US studies in the 1940s, where dental researchers noticed lower levels of tooth decay in areas with naturally occurring fluoride in the water supply.\nThis prompted a study involving the artificial fluoridation of water supplies to a large community, and comparing the tooth decay rates to a neighbouring community with no fluoride.The trial had to be discontinued after six years because the benefits to the children in the fluoridated community were so obvious it was deemed unethical to not provide the benefits to all the children, and so the control community water supply was also fluoridated.Since then, consistently we see lower levels of tooth decay associated with water fluoridation, and the most recent evidence, from Australia and overseas, supports this.The NHMRC review found children and teenagers who had lived in areas with water fluoridation had 26-44 percent fewer teeth or surfaces affected by decay, and adults had 27 percent less tooth decay.\nA number of factors are likely to influence the variation across populations and countries, including diet, access to dental care, and the amount of tap water people drink.3. Fluoridated water causes cancer and other health problemsDespite widespread belief in fluoride's safety, activists north of Boston push to eliminate it from water supplies http://t.co/gZxLVkL9BI\u2014 Scuba Happy (@scubahappy97459) February 8, 2015The NHMRC found, there was reliable evidence to suggest water fluoridation at current levels in Australia of 0.6-1.1 parts per million is not associated with: cancer, Down syndrome, cognitive problems, lowered intelligence, hip fracture, chronic kidney disease, kidney stones, hardening of the arteries, high blood pressure, low birth weight, premature death from any cause, musculoskeletal pain, osteoporosis, skeletal fluorosis (extra bone fluoride), thyroid problems, or other self-reported complaints.\nThis confirms previous statements from the NHMRC on the safety of water fluoridation, and statements from international bodies such as the World Health Organisation, the World Dental Federation, the Australian Dental Association and the US Centers for Disease Control and Prevention.Most studies that claim to show adverse health effects report on areas where there are high levels of fluoride occurring naturally in the water supply. This is often more than 2-10 parts per million or more, up to 10 times levels found in Australian water.These studies are also often not of the highest quality, for example with small sample sizes and not taking into account other factors that may affect adverse health outcomes.There is, however, evidence that fluoridated water is linked to both the amount and severity of dental fluorosis. This is caused by being exposed to excess fluoride (from any source) while the teeth are forming, affecting how the tooth enamel mineralises.Most dental fluorosis in Australia is very mild or mild, and does not affect the either the function or appearance of the teeth. When you can see it, there are fine white flecks or lines on the teeth. Moderate dental fluorosis is very uncommon, and tends to include brown patches on the tooth surface. Severe dental fluorosis is rare in Australia.4. Fluoridated water is not safe for infant formulaSome people are concerned about using fluoridated water to make up infant formula.Mothers\u2014please do not use tap water for your baby formula. It is not safe because of the fluoride in the water.\u2014 John James (@JohnJames1526) April 20, 2017However, all infant formula sold in Australia has very low levels of fluoride, below the threshold amount of 17 micrograms of fluoride/100 kilojules (before reconstitution), which would require a warning label.Therefore, making up infant formula with fluoridated tap water at levels found in Australian (0.6-1.1 parts per million) is safe, and does not pose a risk for dental fluorosis. Indeed, Australian research shows there is no association between infant formula use and dental fluorosis.A consistent messageAdding fluoride to tap water to prevent tooth decay is one of our greatest public health achievements, with evidence gathered over more than 60 years showing it works and is safe. This latest review, tailored to Australia, adds to that evidence.Matthew Hopcraft, Clinical Associate Professor, Melbourne Dental School, University of Melbourne.This article was originally published on The Conversation. Read the original articl"
        ]
    },
    "7969": {
        "gold_standard": [
            "potential sea level surface melt ponds One of the largest icebergs ever recorded has just broken away from the Larsen C Ice Shelf in Antarctica. Over the past few years I've led a team that has been studying this ice shelf and monitoring change.\nWe spent many weeks camped on the ice investigating melt ponds and their impact \u2013 and struggling to avoid sunburn thanks to the thin ozone layer. Our main approach, however, is to use satellites to keep an eye on things.We've been surprised by the level of interest in what may simply be a rare but natural occurrence. Because, despite the media and public fascination, the Larsen C rift and iceberg \"calving\" is not a warning of imminent sea level rise, and any link to climate change is far from straightforward.This event is, however, a spectacular episode in the recent history of Antarctica's ice shelves, involving forces beyond the human scale, in a place where few of us have been, and one which will fundamentally change the geography of this region.Adrian Luckman / MIDASIce shelves are found where glaciers meet the ocean and the climate is cold enough to sustain the ice as it goes afloat. Located mostly around Antarctica, these floating platforms of ice a few hundred meters thick form natural barriers which slow the flow of glaciers into the ocean and thereby regulate sea level rise.\nIn a warming world, ice shelves are of particular scientific interest because they are susceptible both to atmospheric warming from above and ocean warming from below.The ice shelves of the Antarctic peninsula. AJ Cook & DG Vaughan, 2014, CC BY-SABack in the 1890s, a Norwegian explorer named Carl Anton Larsen sailed south down the Antarctic Peninsula, a 1,000km long branch of the continent that points towards South America. Along the east coast he discovered the huge ice shelf which took his name.For the following century, the shelf, or what we now know to be a set of distinct shelves \u2013 Larsen A, B, C and D \u2013 remained fairly stable.However the sudden disintegrations of Larsen A and B in 1995 and 2002 respectively, and the ongoing speed-up of glaciers which fed them, focused scientific interest on their much larger neighbour, Larsen C, the fourth biggest ice shelf in Antarctica.\nThis is why colleagues and I set out in 2014 to study the role of surface melt on the stability of this ice shelf. Not long into the project, the discovery by our colleague, Daniela Jansen, of a rift growing rapidly through Larsen C, immediately gave us something equally significant to investigate.Nature at workThe development of rifts and the calving of icebergs is part of the natural cycle of an ice shelf. What makes this iceberg unusual is its size \u2013 at around 5,800 square kilometres (2,240 square miles) it's the size of a small US state.There is also the concern that what remains of Larsen C will be susceptible to the same fate as Larsen B, and collapse almost entirely.Our work has highlighted significant similarities between the previous behaviour of Larsen B and current developments at Larsen C, and we have shown that stability may be compromised. Others, however, are confident that Larsen C will remain stable.\nWhat is not disputed by scientists is that it will take many years to know what will happen to the remainder of Larsen C as it begins to adapt to its new shape, and as the iceberg gradually drifts away and breaks up. There will certainly be no imminent collapse, and unquestionably no direct effect on sea level because the iceberg is already afloat and displacing its own weight in seawater.Some great aerial footage from @BAS_News of the rift on Larsen C! pic.twitter.com/aXyCx9QTzX\u2014 Project MIDAS (@MIDASOnIce) February 21, 2017This means that, despite much speculation, we would have to look years into the future for ice from Larsen C to contribute significantly to sea level rise.In 1995 Larsen B underwent a similar calving event. However, it took a further seven years of gradual erosion of the ice-front before the ice shelf became unstable enough to collapse, and glaciers held back by it were able to speed up, and even then the collapse process may have depended on the presence of surface melt ponds.Updated #Sentinel1 InSAR sequence shows final branching at the rift tip as it reaches within 4.5 km (2.8 miles) of breaking through to calve pic.twitter.com/6F1Bs8Zmkv\u2014 Adrian Luckman (@adrian_luckman) July 6, 2017Even if the remaining part of Larsen C were to eventually collapse, many years into the future, the potential sea level rise is quite modest. Taking into account only the catchments of glaciers flowing into Larsen C, the total, even after decades, will probably be less than a centimetre.\nIs this a climate change signal?This event has also been widely but over-simplistically linked to climate change"
        ]
    },
    "7982": {
        "gold_standard": [
            "A new study on decision-making in people with autism spectrum conditions has found that they are more consistent in their choices when evaluating product options.Consumers are constantly bombarded with endless choices, often tailored specifically to influence their buying decisions. But now it looks like having traits on the autism spectrum can actually protect you from some marketing tricks.\nWhen it comes to processing information and performing various cognitive tasks, people with autism spectrum conditions (ASC) are known to be better at tuning out distracting stimuli or irrelevant context.\"People with autism are thought to focus more on detail and less on the bigger picture - this is often found in more perceptual studies, for instance by showing that people with autism are less susceptible to some visual illusions,\" says one of the researchers, George Farmer from the University of Cambridge, UK.\"We wanted to know if this tendency would apply to higher-level decision-making tasks.\"The team recruited 90 people with diagnosed ASC and 212 neurotypical people without any conditions. Both groups were repeatedly presented with a series of ten product pairs across different categories, including things like cell phones, orange juice, USB drives and others.\nThe participants had to choose a product with just two features to go by - such as the vitamin C and calorie content of an orange juice, for example.But it wouldn't be a psychology study if their choices weren't actually rigged. Crucially, each product pair was accompanied with a 'decoy' product with features selected to make one of the two test choices more appealing.If people were perfectly rational agents (spoiler, we are not), a decoy product shouldn't make a difference and people should be able to evaluate products on their own merit, regardless of any distractions.\"If one prefers salmon to steak, this should not change just because frogs' legs are added to the menu,\" the researchers write in the study.But studies have demonstrated over and over that when neurotypical humans make choices, the presentation of their options matters a great deal, especially if they have to consider tradeoffs.\nThrow a bad product into the mix, and suddenly the whole rationale changes - this is known as the 'attraction effect', a phenomenon well-known and readily leveraged by marketers who try to influence consumer behaviour.By using specific decoys in their study design, the team was able to see whether people switched their product selection when the decoy was swapped, suddenly making the other product in the pair more attractiv The researchers note that their findings have \"practical implications for the socioeconomic functioning of people with ASC,\" because the attraction effect influences more than just which toothpaste you might get at the supermarket. It can also have an effect on policy decisions, legal judgements and even election choices.The team emphasises that people with ASC are not entirely impervious to decoys, but they are significantly less influenced by them than the general population.\"[C]hoice consistency is regarded as normative in conventional economic theory, so reduced context sensitivity would provide a new demonstration that autism is not in all respects a 'disability',\" the researchers write in the paper.But they also note that there could be a price to pay - sometimes using context to make an optimum choice is a handy strategy, especially if you're not being swindled by an advertising executiv",
            "A new study on decision-making in people with autism spectrum conditions has found that they are more consistent in their choices when evaluating product options.Consumers are constantly bombarded with endless choices, often tailored specifically to influence their buying decisions. But now it looks like having traits on the autism spectrum can actually protect you from some marketing tricks.\nWhen it comes to processing information and performing various cognitive tasks, people with autism spectrum conditions (ASC) are known to be better at tuning out distracting stimuli or irrelevant context.\"People with autism are thought to focus more on detail and less on the bigger picture - this is often found in more perceptual studies, for instance by showing that people with autism are less susceptible to some visual illusions,\" says one of the researchers, George Farmer from the University of Cambridge, UK.\"We wanted to know if this tendency would apply to higher-level decision-making tasks.\"The team recruited 90 people with diagnosed ASC and 212 neurotypical people without any conditions. Both groups were repeatedly presented with a series of ten product pairs across different categories, including things like cell phones, orange juice, USB drives and others.\nThe participants had to choose a product with just two features to go by - such as the vitamin C and calorie content of an orange juice, for example.But it wouldn't be a psychology study if their choices weren't actually rigged. Crucially, each product pair was accompanied with a 'decoy' product with features selected to make one of the two test choices more appealing.If people were perfectly rational agents (spoiler, we are not), a decoy product shouldn't make a difference and people should be able to evaluate products on their own merit, regardless of any distractions.\"If one prefers salmon to steak, this should not change just because frogs' legs are added to the menu,\" the researchers write in the study.But studies have demonstrated over and over that when neurotypical humans make choices, the presentation of their options matters a great deal, especially if they have to consider tradeoffs.\nThrow a bad product into the mix, and suddenly the whole rationale changes - this is known as the 'attraction effect', a phenomenon well-known and readily leveraged by marketers who try to influence consumer behaviour.By using specific decoys in their study design, the team was able to see whether people switched their product selection when the decoy was swapped, suddenly making the other product in the pair more attractive without changing any of the core product features.As it turns out, participants with ASC really did make more consistent choices and were less swayed by the decoys as opposed to neurotypical participants.\"From an economic perspective, this suggests that people with autism are more rational and less likely to be influenced by the way choices are presented,\" says Farmer"
        ]
    },
    "7990": {
        "gold_standard": [
            "Having a sense of purpose in life can lower the risk of sleep problems and improve sleep quality, a new study has found, which could give doctors new options for treating the tens of millions of people who can't get a good night's sleep.\nProblems such as sleep apnea (shallow breathing) and restless legs syndrome (physical restlessness) were among those covered by the study, and the findings give scientists new data on how our state of mind could affect how easily we nod off in the evening.It's the first study to examine this connection over a longer period \u2013 a year in this case \u2013 according to the researchers from Northwestern University, as previous similar studies focussed on one particular point in life.\"Helping people cultivate a purpose in life could be an effective drug-free strategy to improve sleep quality, particularly for a population that is facing more insomnia,\" says lead researcher Jason Ong.\"Purpose in life is something that can be cultivated and enhanced through mindfulness therapies.\"The study asked 823 adults, aged between 60 to 100 years old, 32 questions about their sleep habits and outlook on life, including their response to a series of statements.\nThe statements included \"I feel good when I think of what I've done in the past and what I hope to do in the future\" and \"some people wander aimlessly through life, but I am not one of them\", and were designed to tease out an outlook on life.Those who said their lives had most meaning were 63 percent less likely to have sleep apnea and 52 percent less likely to have restless legs syndrome, as well as having moderately better sleep quality overall, the study found.The sleep quality measured in the study can involve trouble falling asleep, staying asleep through the night, and feeling sleepy during the day, so we're talking about a whole host of issues related to not getting enough shut-eye.And while the age range is relatively old, the researchers are confident the same connection could apply to the broader population. They also note that older people are more likely to have issues with sleeping as they age.\nHaving a purpose in life might be an indicator of better physical and mental health, the researchers suggest, which would in turn lead to better sleep. It's also true that those with goals to hit spend more time exercising, which again helps to improve sleep quality.In other words there could be several factors at play here, and now the researchers want to try several mindfulness therapies to see if they can improve sleep quality.They also note some limitations to the study, including that it was based on a self-reporting method that might not always be reliable, and it looked at a section of the population with better-than-average education and access to healthcare.Even with those caveats though, it's an interesting take on how our mental perspective could be affecting our health around the clock \u2013 if you're finding your sleep is less than satisfactory, maybe you need to head out and find your calling in life.\"Collectively, the emerging data indicates the benefits of positive psychology on sleep health,\" conclude the researchers.The findings have been published in Sleep Science and Practice"
        ]
    },
    "7995": {
        "gold_standard": [
            "The Wilson Journal of Ornithology The elevated posture and folded front legs of the praying mantis might lead you to believe that this cunning predator is a seemingly benign, upstanding member of the insect kingdom \u2013 but don't be fooled.\nIf we needed any further proof that this voracious carnivore is a threat to animals and insects alike, we now have it \u2013 with a new study by zoologists finding that praying mantises have been documented killing birds and devouring their brains across the globe.If that makes it sound like mantises have been infected by some kind of zombie contagion compelling them to hunt down and consume our feathery friends, don't worry \u2013 that hasn't happened (at least as far as we're aware). The truth is this is just an amazing natural behaviour.But while it has been known that mantises infrequently prey upon small vertebrates \u2013 also including frogs, lizards, and snakes \u2013 in addition to their regular fare of arthropods, up until now scientists weren't clued in on how universal the bird buffet was.\"The fact that eating of birds is so widespread in praying mantises, both taxonomically as well as geographically speaking, is a spectacular discovery,\" says lead researcher Martin Nyffeler from the University of Basel in Switzerland.Tom VaughanNyffeler's team reviewed all the available scientific literature and other accounts on bird predation by mantises and found that the phenomenon has been documented in 13 different countries, on all continents except Antarctica \u2013 with mantises preying on some 24 different species of bird.\nAll up, the researchers found 147 cases of the behaviour that have been reported since the first documented instance back in 1864, with the majority of cases involving attacks on hummingbirds in the US, where the birds are often ambushed at hummingbird feeders in house gardens.According to at least one of the included observations, the act is pretty gruesome, especially since mantises are known to sometimes consume their prey while they're still alive:\n\"The modus operandi of the mantis seems to be to approach the bird, which is always hanging downwards, and then enter the cranial cavity via one of the eyes, feeding on the brain tissues.\"\nThe attack, which may end on a flourish with a complete decapitation, is made possible by the mantis's powerful front legs \u2013 sometimes described as forearms \u2013 which enable it to capture and pretty much just incapacitate the victim.Megan Ralph, Dryad Ranch\"They just hold [their prey], and they eat them while they are still alive, slowly and slowly until there is nothing left,\" retired forensic ecologist Dietrich Mebs from the University of Frankfurt in Germany, who wasn't involved with the study, told Newsweek.\n\"It's really impressive.\"That's certainly one word for it, but while the behaviour may definitely make some bird lovers and watchers a bit squeamish, it could also potentially represent a risk to bird numbers \u2013 especially hummingbirds in the US.\"Our study shows the threat mantises pose to some bird populations,\" says Nyffeler.\"Thus, great caution is advised when releasing mantises for pest control\", something that has\u00a0been practised in the past.While the widespread nature of this bird hunting may come as something of a surprise to scientists, Indiana-based author and bird-watcher Kenn Kaufman says that in light of the overall scarcity of accounts recorded so far, we probably don't have to be too worried about hummingbirds on that score.Chris McCarthy\"As weird/gruesome as the behaviour seems, I don't think it represents a threat to the survival of any hummingbird species, because it doesn't happen very often relative to the total population,\" Kaufman told Sarah Emerson at Motherboard.\"So I'd say it's an interesting phenomenon but not a conservation concern.\"The findings are reported in The Wilson Journal of Ornitholog"
        ]
    },
    "8008": {
        "gold_standard": [
            "The Anatomical Record The humble frog has been hiding a secret \u2013 like most birds, mammals, and a handful of reptiles, it has a kneecap.This newly discovered piece of amphibian anatomy is barely a tiny blob of squishy cartilage, so nothing fancy, but the discovery could roll back our best guess on when kneecaps evolved.\nA small team of Argentinian researchers were inspired by relatively recent discoveries of structures called sesamoids in species thought to be lacking in bony joint covers.Sesamoids are bony material embedded in connective tissue such as the tendons over a joint. Knee caps, in other words.They analysed the skeletons of 20 species of frog and found rudimentary structures that weren't quite sesamoids, but weren't like the surrounding connective tissue.The kneecap, or\u00a0patella, comes in all manner of shapes and sizes in different animals to suit slightly different forms of locomotion.Have you ever wondered why we don't have an elbowcap?Protecting a forward-facing joint could explain part of it, but the bony protrusion could also provide some mechanical benefit to what is essentially a lever required to swing a fairly heavy load as quickly and efficiently as possible.\nJust recently researchers in the UK explored the purpose of the odd double-kneecap that seems to be exclusive to ostriches.\"We speculate that this might mean ostriches are able to extend their knees relatively faster than they would with one kneecap,\" says the study's lead researcher Sophie Regnault.These benefits to walking mean before now, the evolution of the knee's sesamoid bone was presumed to coincide with the first tetrapods ambling about on dry land.If amphibians like frogs and toads have a similar structure over their knees, it's possible the kneecap evolved out of something the first land animals brought with them.\"Until now it was thought that the evolution of kneecaps coincided with the arrival of tetrapods that lay eggs on land or retain fertilised eggs in the body,\" lead researcher Virginia Abdala of Argentina's Institute of Neotropical Biodiversity told Andy Coghlan at New Scientist.\n\"This investigation shows that the process really started with fibrocartilage in frogs,\" she says.This fibrocartilage is hard to see, even under a microscope, which helps to explain why centuries of frog dissections haven't stumbled across them before.Although small, it's thought to help absorb the strain of a bent leg as the frog sits, rather than provide any mechanical advantage.\"The resting position in frogs is analogous to the jumping position in humans, so the knees of frogs are under constant stress, and the fibrocartilaginous kneecap might alleviate this,\" says Abdala.The discovery is an interesting one, but we probably shouldn't get too hasty about rewriting any text books yet. After all, what makes a kneecap a kneecap? Fibrocartilage pads to relieve strain aren't the same as bony blocks to help the leg swing.\nOther animals also have squishy bits around their joints called patelloids.There is also a leap in assuming 8 frog species represent thousands.While biologists wrestle with those questions, it's interesting to consider that as the first tetrapods were creeping up onto muddy banks, there were structures that could evolve to help make moving their legs easier.More frog dissections will provide more evidence on the matter. At least we've had plenty of practice by now.This research was published in The Anatomical Recor",
            "The humble frog has been hiding a secret \u2013 like most birds, mammals, and a handful of reptiles, it has a kneecap.This newly discovered piece of amphibian anatomy is barely a tiny blob of squishy cartilage, so nothing fancy, but the discovery could roll back our best guess on when kneecaps evolved.\nA small team of Argentinian researchers were inspired by relatively recent discoveries of structures called sesamoids in species thought to be lacking in bony joint covers.Sesamoids are bony material embedded in connective tissue such as the tendons over a joint. Knee caps, in other words.They analysed the skeletons of 20 species of frog and found rudimentary structures that weren't quite sesamoids, but weren't like the surrounding connective tissue.The kneecap, or\u00a0patella, comes in all manner of shapes and sizes in different animals to suit slightly different forms of locomotion.Have you ever wondered why we don't have an elbowcap?Protecting a forward-facing joint could explain part of it, but the bony protrusion could also provide some mechanical benefit to what is essentially a lever required to swing a fairly heavy load as quickly and efficiently as possible.\nJust recently researchers in the UK explored the purpose of the odd double-kneecap that seems to be exclusive to ostriches.\"We speculate that this might mean ostriches are able to extend their knees relatively faster than they would with one kneecap,\" says the study's lead researcher Sophie Regnault.These benefits to walking mean before now, the evolution of the knee's sesamoid bone was presumed to coincide with the first tetrapods ambling about on dry land.If amphibians like frogs and toads have a similar structure over their knees, it's possible the kneecap evolved out of something the first land animals brought with them.\"Until now it was thought that the evolution of kneecaps coincided with the arrival of tetrapods that lay eggs on land or retain fertilised eggs in the body,\" lead researcher Virginia Abdala of Argentina's Institute of Neotropical Biodiversity told Andy Coghlan at New Scientist.\n\"This investigation shows that the process really started with fibrocartilage in frogs,\" she says.This fibrocartilage is hard to see, even under a microscope, which helps to explain why centuries of frog dissections haven't stumbled across them before.Although small, it's thought to help absorb the strain of a bent leg as the frog sits, rather than provide any mechanical advantage.\"The resting position in frogs is analogous to the jumping position in humans, so the knees of frogs are under constant stres stress, and the fibrocartilaginous kneecap might alleviate this,\" says Abdala.The discovery is an interesting one, but we probably shouldn't get too hasty about rewriting any text books yet. After all, what makes a kneecap a kneecap? Fibrocartilage pads to relieve strain aren't the same as bony blocks to help the leg swing.\nOther animals also have squishy bits around their joints called patelloid"
        ]
    },
    "8014": {
        "gold_standard": [
            "Scientists have created an inexpensive material that removes a highly toxic industrial pollutant from water.The filtration material is made by turning a naturally occurring sugar molecule into a polymer and it performs much better than our current filtration technology at dealing with one big contamination problem.\nIndustrial pollutants cause major issues for communities near industrial sites. In the US, Hoosick Falls, New York, and Bennington, Vermont, declared states of emergency because of chemical contamination of drinking water\u00a0in 2016.The main culprit? Perfluorooctanoic acid \u2013 which can be shortened to the acronym PFOA.PFOA is a molecule that has been used historically in the production of our non-stick friend, TEFLON, and as a water and oil repellent for carpets, food wrapping and even dental floss.But there's a serious price to pay for our stain free and non-stick existence.PFOA is toxic to living things and, once released into the environment, it will never break down. This means removing PFOA from the contaminated waterways is the only course of action we have to improve the water quality.\nScientists have created a new polymer material constructed from a simple sugar molecule, beta-cyclodextrin. The material is ten times more efficient at removing PFOA from water than commonly used filtration materials such as activated carbon (the same stuff now used in fart absorbing underwear).\"Our material fully extracts the pollutant out of water. The polymer contains sites that bind PFOA strongly, which strips this pollutant out of water even when present at extremely low concentrations\" said lead researcher William Dichtel from Northwestern University, Illinois.Beta-cyclodextrin\u00a0is a naturally occurring bio-renewable sugar molecule derived from cornstarch. The cyclodextrin is transformed into a polymer by connecting the molecules together with another molecule \u2013 known as cross linking. Perfecting the ratio of beta-cyclodextrin to cross-linker was the key to maximising the filtration efficiency.As the name suggests, cyclodextrins are made up of sugar molecules bound together in a ring. The ring-like nature of beta-cyclodextrin creates a molecular bucket that's the perfect size for capturing and holding on to the PFOA molecules.Credit: American Chemical SocietyTargeting for other pollutants can be programmed into the material by changing the cyclodextrin for one with bigger or smaller cavities.\n\"Our findings demonstrate the selectivity of this type of polymer can be tailored to target pollutants of interest, in this case PFOA,\"\u00a0said Dichtel.Even very small amounts of the beta-cyclodextrin polymer can reduce the levels of PFOA to below the environmental protection agency's advised limit of 70 parts per trillion, which is equal to one teaspoon of PFOA in 14 Olympic-sized swimming pools.In the study, the scientists were able to take contaminated water with PFOA from a concentration of one milligram per litre (similar to that of contaminated water resources) to concentrations as low as 10 nanograms per litre \u2013 far below the Environmental Protection Agency's advised limits.The best performing polymers made could remove up to 95 percent of the PFOA within 13.5 hours.To make the polymer even better, it was able to be used multiple times by simply washing it with methanol at room temperature. Importantly, it was also resilient to humic acid, a component of natural organic matter which is commonly found in waterways and stops activated carbon filters from working.The scientists are hoping to turn this material into a commercial product very soon and have founded a start-up to manufacture and distribute the material.\u00a0The findings were published in the\u00a0Journal of the American Chemical Societ"
        ]
    },
    "8032": {
        "gold_standard": [
            "Bioinspiration & Biomimetics Owls have mastered the art of quiet flight in order to glide down on unsuspecting prey, and now scientists think we can follow their lead to quieten down wind turbines and aeroplanes \u2013 and it's all to do with the serrated edges on the front of owl wings.\nThose serrations could help us keep down the noise of air rushing past metal, and the scientists have got the computer models and wind tunnel experiments to prove it.The team from Chiba University in Japan found that the serrations on the leading edge of an owl wing controlled the transition between turbulent and streamlined air flows, and that the same principles could be used in our own machines.\"Owls are known for silent flight, owing to their unique wing features, which are normally characterised by leading-edge serrations, trailing-edge fringes and velvet-like surfaces,\" says lead researcher Hao Liu.\"We wanted to understand how these features affect aerodynamic force production and noise reduction, and whether they could be applied elsewhere.\"The researchers put together wing models inspired by owl wings and tested them with and without leading edge serrations. Previous studies had shown up the comb-like serrations on the wings, but we still don't understand much about what effect they have.\nThese models were then tested in a large eddy simulation, a standard maths model used by scientists to study air flow, and in a low-speed wind tunnel using particle image velocimetry (PIV) and other force measurements.It turns out the leading-edge serrations can passively control the transition between laminar (steady) air flow and turbulent air flow across the upper surface of a wing, at angles of attack (AoA) \u2013 the relationship between the angle of the wing and the direction of the air flow \u2013 between zero and 20 degrees.In other words, those serrations are crucial to managing aerodynamic force and sound production: they break up the swirling, high-frequency eddies of rushing air hitting the wing into smaller, quieter eddies or swirls.There is a trade-off between force production and noise suppression though, the scientists found. At AoA less than 15 degrees, serrated leading-edges reduce aerodynamic performance compared with clean leading-edges.\nOnce that angle goes above 15 degrees \u2013 as it often does when an owl is in flight \u2013 both aerodynamic performance and noise reduction are improved.We're still a long way from being able to put these findings into action in turbines, aeroplanes, and anything else we make that flies through the air, but there's now a base of research for others to build on.\"These owl-inspired leading edge serrations, if applied to wind turbine blades, aircraft wings or drone rotors, could provide a useful biomimetic design for flow control and noise reduction,\" says Liu.\"At a time when issues of noise are one of the main barriers to the building of wind turbines, for example, a method for reducing the noise they generate is most welcome.\"The research has been published in Bioinspiration & Biomimetic"
        ]
    },
    "8034": {
        "gold_standard": [
            "Why do cats purr? Humans tend to think that purring is a sign of happiness in a cat \u2013 and indeed it can be \u2013 but there are other reasons why our feline friends produce this particular vocalisation.\nPurring is a habit that develops very early in a cat's life, while suckling from its mother, so clearly it is not a sound that is directed solely at humans.Cat owners will be well aware that a cat can produce more than one kind of purr, just as they have a whole repertoire of meows, chirps, growls, spits and other sounds.The purr that is produced during suckling, is quite different in quality to the purr that you will hear when your cat is sprawling across your lap being stroked.Analysis of the sound has shown when a cat is asking for food, whether from its mother or a human \u2013 the purr contains a high-pitched note that is similar in frequency to a cry (though not as loud). It may have something of the effect of the cry of a newborn, which affects the hormonal state of female mammals and elicits a care-giving response.\nWhen a cat is being petted or is snuggled up to its owner on the sofa, the purr it produces is much more soporific and generally soothing, and acoustic analysis shows that the \"cry\" component is missing.Adult cats will often purr when they are close to or in physical contact with another cat, engaging in grooming for example. They will also do it when they play with an inanimate object, or while eating, which can be at a time when they are alone.However, the most usual time for purring is in company, and it can be the care soliciting sound, asking to be fed or stroked, or an indication of social pleasure.The darker sideStrangely, vets also report that cats will purr when they are in great pain or just before death. This seems to be illogical if it is a sound relating to pleasure, but in fact, it could be that the cat is asking for help.\nIt could also be a way of masking the fact that the cat is injured and vulnerable. If you are a small animal, even a carnivore, it is not good to show weakness as this could encourage larger predators to come along and eat you.The purr may be the cat equivalent of \"everything's fine, I'm on top of the world. Nothing to see here, move along please\".Can big cats purr too?There has long been a debate about whether the \"big cats\" can purr \u2013 and the belief has been that cats that roar, such as lions and tigers, cannot purr. Although there is no conclusive evidence on this subject, it seems that even cats that roar purr as cubs while suckling.All mammals have a bone or series of bones in the throat called the hyoid apparatus, which supports the larynx and tongue",
            "Why do cats purr? Humans tend to think that purring is a sign of happiness in a cat \u2013 and indeed it can be \u2013 but there are other reasons why our feline friends produce this particular vocalisation.\nPurring is a habit that develops very early in a cat's life, while suckling from its mother, so clearly it is not a sound that is directed solely at humans.Cat owners will be well aware that a cat can produce more than one kind of purr, just as they have a whole repertoire of meows, chirps, growls, spits and other sounds.The purr that is produced during suckling, is quite different in quality to the purr that you will hear when your cat is sprawling across your lap being stroked.Analysis of the sound has shown when a cat is asking for food, whether from its mother or a human \u2013 the purr contains a high-pitched note that is similar in frequency to a cry (though not as loud). It may have something of the effect of the cry of a newborn, which affects the hormonal state of female mammals and elicits a care-giving response.\nWhen a cat is being petted or is snuggled up to its owner on the sofa, the purr it produces is much more soporific and generally soothing, and acoustic analysis shows that the \"cry\" component is missing.Adult cats will often purr when they are close to or in physical contact with another cat, engaging in grooming for example. They will also do it when they play with an inanimate object, or while eating, which can be at a time when they are alone.However, the most usual time for purring is in company, and it can be the care soliciting sound, asking to be fed or stroked, or an indication of social pleasure.The darker sideStrangely, vets also report that cats will purr when they are in great pain or just before death. This seems to be illogical if it is a sound relating to pleasure, but in fact, it could be that the cat is asking for help.\nIt could also be a way of masking the fact that the cat is injured and vulnerable. If you are a small animal, even a carnivore, it is not good to show weakness as this could encourage larger predators to come along and eat you.The purr may be the cat equivalent of \"everything's fine, I'm on top of the world. Nothing to see here, move along please\".Can big cats purr too?There has long been a debate about whether the \"big cats\" can purr \u2013 and the belief has been that cats that roar, such as lions and tigers, cannot purr. Although there is no conclusive evidence on this subject, it seems that even cats that roar purr as cubs while suckling.All mammals have a bone or series of bones in the throat called the hyoid apparatus, which supports the larynx and tongue. In cat species that roar the hyoid apparatus is not entirely made of bone but retains some parts as cartilage, while cat species that purr have a hyoid that is completely bon"
        ]
    },
    "8039": {
        "gold_standard": [
            "A review of the research on combining therapy with the psychoactive component from magic mushrooms has concluded it's not only a safe and effective way to treat conditions related to anxiety, depression, and addiction, it could be better than many existing forms of treatment.\nThe findings reinforce the need to explore the full impact of the psychedelic compound called psilocybin, a drug that is showing increasing promise in its ability dramatically improve the lives of those who suffer debilitating psychiatric disorders.Psychedelics such as lysergic acid diethylamide ( LSD) and psilocybin have a reputation more as a party drug than as forms of therapeutic medication.But their similarity to neurotransmitters such as serotonin and their ability to affect our perception and mess with our state of consciousness has made them attractive candidates for treating various psychiatric conditions.Studies have found patients with severe depression have improved after taking small amounts of psilocybin alongside supportive therapy sessions, with evidence that their brains have strengthened links across previously disconnected regions.\nThese kinds of results demand attention, demonstrating great potential for using serotonin agonists such as psilocybin to block problematic networks in the brain while therapy can be used to create more functional ones.A review by researchers in California has shown such studies aren't outliers, prompting a need to step forward with testing.Their analysis of seven clinical trials conducted over the past decade testing the effects of psilocybin-assisted therapy on anxiety, depressive disorders, addiction, and obsessive-compulsive disorder has shown the drug.\"Psilocybin-assisted therapy has been shown to be safe in several studies across a variety of patient populations,\" researcher Kelan Thomas of Touro University California explained to Eric W. Dolan of PsyPost.Compared with other forms of treatment on validated psychiatric rating scales, therapy with psilocybin has resulted in a larger effect, suggesting it could be a better option for many patients, especially those who have failed to respond to other medications or procedures.\n\"One important distinction from these other session-based treatments would be that the benefits of psilocybin-assisted therapy may only require a few dosing sessions and the effects appear to persist longer than other treatment options,\" the researchers write in their report.This isn't to say the drug can be beneficial independently as a form of medication \u2013 research on the therapeutic impact of psychoactive drugs is pretty thin on the ground due to ethical constraints, but that also means there's no strong evidence supporting use of psilocybin without the support of therapy sessions.It is a good reason to now conduct larger trials with more powerful statistical tools to aim for getting the US Food and Drug Administration's big tick of approval.\"The clinical trials summarised were Phase 2 studies investigating safety and efficacy endpoints, but some of the studies were open-label and lacked statistical analysis,\" says Thomas"
        ]
    },
    "8040": {
        "gold_standard": [
            "A femur discovered in a cave in southwestern Germany has provided researchers with firm evidence that a small population of humans left Africa and then vanished, long before the big migration that saw humans populate the globe.\nSigns of this mysterious early migration remained in the DNA of the Neanderthal who left the leg bone behind, revealing not only a previous tryst between the two hominin populations, but a sign that Neanderthals were far more diverse than we thought.A team of scientists led by the Max Planck Institute for the Science of Human History and the University of T\u00fcbingen in Germany used the DNA from the femur's mitochondria to determine its relationship with other Neanderthals and modern humans.Neanderthal and human history is a little complicated. So stick with us.Neanderthals and huma'ns are regarded as close cousins, either under the same species of Homo sapiens or a closely related species Homo neanderthalis.Mitochondria \u2013 our cells batteries \u2013 contain a set of genes separate from the DNA bunched up inside our nucleus. Since mitochondrial DNA mutates in a fairly predictable, conserved fashion, we can measure and map its mutations to get a good idea of when two populations last shared them.\nDifferences between our mitochondrial genes suggest we last shared a common ancestor a little over 400,000 years ago, though previous studies on nuclear DNA had estimated a split as far back as nearly 800,000 years ago.Another group of human cousins dubbed the Denisovans also split off from a group of Neanderthals roughly 400,000 to 450,000 years ago before they went wandering the Earth.The thing to note is Denisovans have nuclear DNA that matches Neanderthals' DNA more than our own. Which makes sense, since Denisovans probably split off from a Neanderthal population.But Neanderthals and modern humans have more similar mitochondria. Why the difference?Neanderthal bones found in a Spanish cave have been dated to 430,000 years ago, suggesting their ancestors left Africa nearly half a million years ago and ventured across Europe as far as southern Siberia before dying out only a few tens of thousands of years ago.\nOur own ancestors migrated out of Africa some time roughly 50,000 years ago, before establishing ourselves across the globe.DNA taken from modern humans with non-African lineage reveals we have genes that had evolved in Neanderthals and Denisovans, suggesting there was a bit of an on-again/off-again relationship with our cousins over the millennia since we first parted ways.Considering the populations had a chance to mingle in Europe over a span of a few thousand years, some sort of casual affair isn't all that surprising.But this new discovery is a bit of a shock.The specimen, coded HST after the site of its discovery in Hohlenstein-Stadel cave, couldn't be carbon-dated. But its mitochondrial DNA put it at about 124,000 years old.\"The bone, which shows evidence of being gnawed on by a large carnivore, provided mitochondrial genetic data that showed it belongs to the Neanderthal branch,\" says lead researcher Cosimo Posth of the Max Planck Institute for the Science of Human History.\nJust to throw another twist into the story, this Neanderthal's mitochondria didn't come from the same group as those belonging to other previously analysed Neanderthal bones. Instead, it came from a lineage dating back at least 220,000 years.Not only does this suggest modern humans might have been stepping tentatively into Europe and getting friendly with Neanderthals long before the wave of migration that led to today's population, it shows Neanderthals were more diverse than we thought.Taken altogether, this evidence helps flesh out the complex relationship between Neanderthals, Denisovans, and modern humans.Around 450,000 years ago, an ancestor of the Neanderthals and Denisovans split off and headed for Europe and Asia. Those who ventured further east eventually became the Denisovans; in the west, they were the Neanderthals"
        ]
    },
    "8048": {
        "gold_standard": [
            "Advanced Functional Materials If there's one thing that's standing between us and the dream of safe long-haul space travel, it's the threat of radiation in space\u00a0\u2013 which can seriously endanger astronauts' health once they pass outside of Earth's protective magnetosphere for any extended period.\nWhile fixing that problem won't be easy, a new invention from\u00a0scientists in Australia could indicate a new avenue for mitigating at least some of the radiation in space, thanks to a nano-material that can alternate between reflecting and transmitting light.Led by physicists Yuri Kivshar and Lei Xu from Australian National University (ANU), the team says their metasurface is so small that hundreds of layers of it could fit on the tip of a needle, meaning the material could readily be applied to any surface or structure, including spacesuits.\"Our invention has a lot of potential applications,\" says Mohsen Rahmani, one of the researchers, \"such as protecting astronauts or satellites with an ultra-thin film that can be adjusted to reflect various dangerous ultraviolet or infrared radiation in different environments.\"It's worth pointing out that the nano-material at present can't shield all the harmful effects of cosmic radiation, as it only blocks light \u2013 not the harmful, massive particles that make up cosmic rays. But it's a promising way to curb harmful light that could also be dangerous to space travellers.\nThe key to the nano-material's protective powers is temperature. When the device is heated or cooled, the surface \u2013 composed of a 2D lattice of nanoparticles \u2013 can be reversibly tuned to either reflect or conduct light waves, including visible light.ANUWhat that means is that, in addition to shielding astronauts from cosmic rays, the technology could also be implemented back on Earth for somewhat less dramatic purposes, where the tuning mechanism could be used to transform surfaces between opaque and transparent states.\"For instance, you could have a window that can turn into a mirror in a bathroom on demand,\" says another member of the team, Andrey Miroshnichenko, \"or control the amount of light passing through your house windows in different seasons.\"\nThe researchers think that these kinds of applications could lead to new directions in architecture, with reversible mirror/windows that change as needed during the day, potentially cutting down on energy costs by facilitating natural lighting and heating in place of electric substitutes.Of course, you'd still need to heat or cool the nano-material to trigger the transition in the metasurface, but the team says doing so is relatively easy.\"Much like your car has a series of parallel resistive wires on the back windscreen to defog the rear view, a similar arrangement could be used with our invention to confine the temperature control to a precise location,\" says Lei Xu.ANUThe device builds on previous research by the team that used similar principles to develop nano-crystals capable of converting invisible light into visible light \u2013 which could one day lead to an ultra-thin coating on regular glasses that could effectively turn people's glasses into night vision goggles.\nAs Fiona MacDonald reported for us late last year:\n\"In addition to helping build the next-generation of night-vision glasses, the crystal could be used to twist light in all kinds of useful ways.\nFor example, those holograms on bank notes that prove they're not counterfeit could be created from these light-bending crystals. And they could also produce powerful new holograms.\"\nAt present, the nano-material layer has only been demonstrated in the lab, but the team says with the right investment, it might only be two to three years before their metasurface could be in production \u2013 which could revolutionise space travel (and the humble window) as we know it.You can find out more about the nano-material in the video below"
        ]
    },
    "8065": {
        "gold_standard": [
            "For new mothers, eating their own (and child's) placenta has become a popular trend in the US and other western societies. And while it may seem unnecessarily gross, advocates of the practice \u2013 called placentophagy \u2013 claim a wide range of benefits, from protecting against postpartum depression to increasing milk production.\nBut just as the practice is becoming more common, the Centers for Disease Control and Prevention (CDC) is warning new mothers that placentophagy may put newborns at risk of infectious bacteria.In theory, eating placenta makes sense. Placenta is chock-a-block full of essential vitamins, minerals, nutrients and postpartum hormones. But that doesn't necessarily mean that consuming it is beneficial.Proponents often cite how common placentophagy is among other mammals, but practically no studies have explored the effects of this practice on humans. And the few studies that do exist provide no conclusive evidence that eating your own placenta is beneficial. \u00a0 \u00a0For instance, a study last year found that consuming placenta does not significantly improve the iron levels of new mothers, at least no more than other iron-rich foods, such as beef.\nSo, if eating your own placenta may or may not be beneficial, why not still give it a go?Well, turns out it could risk the health of your newborn.A new case report published by the CDC warns mothers their placenta supplements may be contaminated with infectious pathogens. \u00a0The report follows a mother in Oregon, who gave birth to a healthy baby in September of last year. A couple of days later, the infant was rushed to the neonatal intensive care unit and was successfully treated for a life-threatening blood infection called late-onset group B Streptococcus agalactiae (GBS) bacteremia.\u00a0Flash-forward five days, and the infant is back in hospital with a second case of GBS\u00a0\u2013\u00a0a recurring infection.The doctors were stumped. That is, until they discovered the mother was taking placenta pills that were packed not only with placenta powder, but also with GBS.\nGBS doesn't usually cause infections in adults, but in a newborn's undeveloped immune system it can be treacherous.The strain that the researchers found in the Oregon case was particularly virulent, allowing it to flood the baby's intestines, bloodstream, and potentially their blood brain barrier.After running some labs, the researchers found the GBS strains in the pill were genetically identical to the GBS infection in the newborn.This suggests the placenta capsules may have elevated the mother's GBS colony in her own intestine and/or skin, making it easier for the infection to then spread to the infant. \u00a0Currently, there are no existing standards for processing placenta for consumption.\u00a0 And the researchers of the CDC report believe this may be why the mother's placenta pills were contaminated.\nThe company that the mother had hired to make her placenta pills \u2013 unnamed by the CDC\u00a0\u2013 had dehydrated her placenta at 46 \u2013 71\u00b0C (115 \u2013 160\u00b0F), before placing the powder into a couple hundred gelatin capsules.\u00a0The researchers theorise that this company's dehydration process may not heat the placenta long enough or at a high enough temperature to kill all pathogens present.\"The placenta encapsulation process does not per se eradicate infectious pathogens; thus, placenta capsule ingestion should be avoided,\" the researchers conclude.\"Clinicians should inquire about a history of placenta ingestion in cases of late-onset GBS infection and educate mothers interested in placenta encapsulation about the potential risks.\"Until further research is conducted and more stringent standards for processing placenta are put into place, this is a practice that should probably be avoided"
        ]
    },
    "8084": {
        "gold_standard": [
            "Like a puddle under hot sunshine, the world's largest inland body of water is shrinking in the face of heat \u2013 in this case, a scorching climate the modern world has never before seen.\nThe Caspian Sea, which lies between Europe and Asia, has been slowly evaporating over the past two decades due to rising temperatures associated with climate change, a new study shows.According to an analysis led by researchers from the University of Texas at Austin, the Caspian Sea is dropping almost 7 centimetres (2.8 inches) in its water level each year, and has been ever since 1996.If that descent continues, it won't take too long before this landlocked mega lake \u2013 bordered by Russia, Kazakhstan, Iran, Azerbaijan, and Turkmenistan \u2013 falls below its historic low set in the 1970s.Scott Kelly/NASA-JSCThe researchers say that hotter surface air temperatures over the Caspian Sea \u2013 a total rise of about 1 degree Celsius (1.8 degrees Fahrenheit) since 1979 \u2013 have resulted in increased evaporation, and the most likely culprit behind all this is climate change.\nWhile the overall water level in the Caspian has fluctuated for several hundred years, steepened changes in the last century suggest evaporation caused by warmer temperatures is the greatest influence on the body of water.\"The real control that causes it to go up and down over long periods of time is really most likely the evaporation, which is almost completely dominated by temperature,\" says one of the researchers, geophysicist Clark Wilson.The team began their study by chance, after being involved in research to help calibrate satellite data for the GRACE gravity field mission launched in 2002.While reconciling GRACE data with Earth-based measurements including readings of the Caspian Sea, they noticed just how much the water levels were fluctuating.Jianli Chen/Geophysical Research Letters/AGU\"That got us going on the current question, which is trying to understand what the reason is for these multi-metre variations in the sea level,\" says Wilson.\n\"It's an interesting place, and it's been studied for a long time, but it wasn't really clear.\"Digging into the satellite data along with records of precipitation and drainage into the sea from rivers, the team found the effects of evaporation were greater than any other influences on water level.In other words, evaporation has more of an impact than gains made from rainfall or water flowing into the Caspian from rivers surrounding the sea.\"If the temperature in the Caspian Sea region continues to increase, the evaporation rate is also expected to increase,\" explains space geodesist Anny Cazenave from France's space agency CNES, who wasn't involved with the study.\"Unless river discharge increases accordingly or precipitation in the Caspian drainage basin increases accordingly, the imbalance is likely to continue.\"Jianli Chen/Geophysical Research Letters/AGUThe team says that under current climate models, the evaporation could even see the northern waters of the Caspian vanish within 75 years.\nThe northern part of the sea is its shallowest region, where much of the water is less than 5 metres (16 feet) deep \u2013 not much left to lose, in other words.The current study wasn't focussed on providing specific estimates of how a grand evaporation like that would play out, but such a grave analysis could soon be on the cards for scientists studying the Caspian.It wouldn't be the first time a world's surface water was lost to vast changes in atmospheric conditions \u2013 and it might not be the last.\u00a0\"If you're going to take this to the next step, it would be to take a suite of climate models or look at some sort of ensemble predictions of future temperatures to get some idea of what those scenarios might be for the Caspian Sea,\" Wilson says.\"You can imagine if you had a continued decline in sea level that led to several metres of loss, you've considerably diminished the size of the sea.\"The findings are reported in Geophysical Research Letter"
        ]
    },
    "8085": {
        "gold_standard": [
            "The 4th International Conference on Quantum Technologies held in Moscow last month was supposed to put the spotlight on Google, who were preparing to give a lecture on a 49-qubit quantum computer they have in the works.\nA morning talk presented by Harvard University's Mikhail Lukin, however, upstaged that evening's event with a small announcement of his own \u2013 his team of American and Russian researchers had successfully tested a 51-qubit device, setting a landmark in the race for quantum supremacy.Quantum computers are considered to be part of the next generation in revolutionary technology; devices that make use of the odd 'in-between' states of quantum particles to accelerate the processing power of digital machines.The truth is both fascinating and disappointing. It's unlikely we'll be playing Grand Theft Auto VR8K-3000 on a quantum-souped Playstation 7 any time soon. Sorry, folks.Quantum computing isn't all about swapping one kind of chip for a faster one.What it does do is give us a third kind of bit where typical computers have only two. In quantum computing, we apply quantum superposition \u2013 that odd cloud of 'maybes' that a particle occupies before we observe its existence cemented as one of two different states \u2013 to solving highly complex computational problems.\nWhile those kinds of problems are a long, tedious process that tax even our best supercomputers, a quantum computer's \"qubit\" mix of 1s, 0s, and that extra space in between can make exercises such as simulating quantum systems in molecules or factorising prime numbers vastly easier to crunch.That's not to say quantum computing could never be a useful addition for your home desktop. But to even begin dreaming of the possibilities, there are a whole number of problems to solve first.One of them is to ramp up a measly handful of qubits from less than 20 to something that can begin to rival our best classical supercomputers on those trickier tasks.That number? About 50-odd, a figure that's often referred to in rather rapturous terms as quantum supremacy.The Harvard device was based on an array of super-cooled atoms of rubidium held in a trap of magnets and laser 'tweezers' that were then excited in a fashion that allowed their quantum states to be used as a single system.\nThe researchers were able to control 51 of these trapped atoms in such a way that they could model some pretty complex quantum mechanics, something well out of reach of your everyday desktop computer.While the modelling was mostly used to test the limits of this kind of set-up, the researchers gained useful insights into the quantum dynamics associated with what's called many-body phenomena. Fortunately they were still able to test their relatively simpler discoveries using classical computers, finding their technique was right on the money.The research is currently on the pre-publish website arXiv.com, awaiting peer review. But the announcement certainly has the quantum computing community talking about the possibilities and consequences of achieving such limits.The magical number of 50 qubits is more like a relative horizon than a true landmark. Not much has changed in the world of quantum computing with the Harvard announcement, and we still have a long way to go before this kind of technology will be useful in making any significant discoveries.\nGoogle's own plan for a 49-qubit device uses a completely different process to Lukin's, relying on multiple-qubit quantum chips that employ a solid-state superconducting structure called a Josephson junction.They've proven their technology with a simpler 9-qubit version, and plan to gradually step up to their goal.Without going into detail, each of the technologies has its pros and cons when it comes to scaling and reliability.A significant problem with quantum computing will be how to make the system as reliable and error-free as possible. While classical computing can duplicate processes to reduce the risk of mistakes, the probabilistic nature of qubits makes this impossible for quantum calculations.There's also the question on how to connect a number of units together to form ever larger processors.\nWhich methods will address these concerns best in the long run is anybody's guess. \"There are several platforms that are very promising, and they are all entering the regime where it is getting interesting, you know, system sizes you cannot simulate with classical computers,\" Lukin said to Himanshu Goenka from International Business Times.\"But I think it is way premature to pick a winner among them. Moreover, if we are thinking about truly large scales, hundreds of thousands of qubits, systems which will be needed for some algorithms, to be honest, I don't think anyone knows how to go there.\"It's a small step on the road to a hundred thousand qubits, but it doesn't make passing this milestone any less significant.\u00a0Happy 51, Harvar"
        ]
    },
    "8087": {
        "gold_standard": [
            "An experimental conservation project that was abandoned and almost forgotten about, has ended up producing an amazing ecological win nearly two decades after it was dreamt up.\nThe plan, which saw a juice company dump 1,000 truckloads of waste orange peel in a barren pasture in Costa Rica back in the mid 1990s, has eventually revitalised the desolate site into a thriving, lush forest.That's one heck of a turnaround, especially since the project was forced to close in only its second year \u2013 but despite the early cancellation, the peel already deposited on the 3-hectare (7-acre) site led to a 176 percent increase in above-ground biomass.\"This is one of the only instances I've ever heard of where you can have cost-negative carbon sequestration,\" says ecologist Timothy Treuer from Princeton University.\"It's not just a win-win between the company and the local park \u2013 it's a win for everyone.\"Daniel Janzen & Winnie HallwachsThe plan was born in 1997 when Princeton researchers Daniel Janzen and Winnie Hallwachs approached Costa Rican orange juice manufacturer Del Oro with a unique opportunity.\nIf Del Oro agreed to donate part of its land bordering the Guanacaste Conservation Area to the national park, the company would be allowed to dump its discarded orange peel at no cost on degraded land in the park.The juice company agreed to the deal, and some 12,000 tonnes of waste orange peel carried by a convoy of 1,000 truckloads was unceremoniously dumped on virtually lifeless soils at the site.The deluge of nutrient-rich organic waste had an almost instantaneous effect on the fertility of the land.\"[W]ithin about six months the orange peels had been converted from orange peels into this thick black loamy soil,\" Treuer told Scientific American.\"Kind of passing through this gross stage in between of kind of sludgy stuff filled with fly larvae.\"Daniel Janzen & Winnie HallwachsDespite this promising start, the conservation experiment wasn't to last, after a rival juice manufacturer called TicoFruit sued Del Oro, alleging that its competitor had \"defiled a national park\".\nCosta Rica's Supreme Court sided with TicoFruit, and the ambitious experiment was forced to end, which saw the site largely forgotten about for the next 15 years.Then, in 2013, Treuer decided to evaluate the site while visiting Costa Rica for other research.It turns out, the only problem was actually finding the former wasteland \u2013 a challenge that necessitated two trips to the site, given the arid landscape had been unrecognisably transformed into a dense, vine-filled jungle.\"It didn't help that the six-foot-long sign with bright yellow lettering marking the site was so overgrown with vines that we literally didn't find it until years later,\" Treuer told Marlene Cimons at Popular Science, \"after dozens and dozens of site visits.\"Daniel Janzen & Winnie HallwachsWhen comparing the site to a nearby control area that hadn't been treated with orange peels, Treuer's team found their experimental compost heap yielded richer soil, more tree biomass, and a broader diversity of tree species \u2013 including a fig tree so huge it would take three people wrapping their arms around the trunk to cover the circumference.\nAs for how the orange peels were able to regenerate the site so effectively in just 16 years of isolation, nobody's entirely sure.\"That's the million dollar question that we don't yet have the answer to,\" Treuer told Popular Science.\"I strongly suspect that it was some synergy between suppression of the invasive grass and rejuvenation of heavily degraded soils.\"While the exact mechanisms remain something of a mystery for now, the researchers hope that the remarkable success of this abandoned, 16-year-old orange peel dump will inspire other similar conservation projects.Especially since, in addition to the double-win of dealing with waste and revitalising barren landscapes, richer woodlands also sequester greater amounts of carbon from the atmosphere \u2013 meaning little plots of regenerated land like this could ultimately help save the planet.\n\"It's a shame where we live in a world with nutrient-limited degraded ecosystems and also nutrient-rich waste streams. We'd like to see those things come together a little bit,\" Treuer told Scientific American.\"That's not licence for any agricultural company to just start dumping their waste products on protected areas, but it does mean that [we] should start thinking about ways to do thoughtful experimentation to see if in their particular system they can have similar win-win-win results.\"The findings are reported in Restoration Ecology"
        ]
    },
    "8104": {
        "gold_standard": [
            "Drug overdoses in the US are feared to have caused more than 60,000 deaths in 2016, but new vaccines that make the brain immune to mind-altering chemicals could be the key to ending the opioid crisis.\nA combination vaccine that offers protection from the effects of both heroin and the synthetic opioid fentanyl is under development by researchers in the US, which could one day help curb addiction and even possibly prevent fatal overdoses.The findings, presented last week at a meeting of the American Chemical Society (ACS) in Washington, DC, are the latest developments in a long-researched and controversial approach to treating addiction \u2013 using vaccines to effectively neuter drugs' effects.But while such investigations date as far back as the 1970s, researchers say the recent rise of synthetic opioids means vaccines to counter drugs' powers could be more important than ever.\"There is an urgent need to discover effective medications to treat substance use disorders,\" says chemist Kim D. Janda from the Scripps Research Institute in California.\n\"Increasingly, drug users are turning to opioids and powerful synthetic versions of these drugs that can sometimes be as much as 100 times more potent than heroin. Moreover, many patients [are] receiving treatment relapse.\"The problems posed by these synthetic substitutes and supplements are various. Not only are they cheaper to manufacture, but they can be produced far more quickly than conventional drugs like heroin.Worse still, they can be incredibly powerful \u2013 with reports of black market opiates that are up to 10,000 times more powerful than morphine.In the case of fentanyl \u2013 which is up to 100 times more powerful than morphine \u2013 it's a dangerously cheap and accessible substitute that ends up getting cut with heroin.\"It's an economics thing,\" Janda told Dave Roos at Seeker.\n\"They start putting in things like fentanyl, because it's much more potent and inexpensive. We'll see more problems going forward, simply because it takes a couple of months to grow poppies, but it only takes a couple of days to make the synthetic opioid.\"One of the difficulties with developing vaccines to counter these kinds of drugs is that the opioids are made up of tiny molecules that the body's immune system doesn't recognise, and so doesn't do anything to fight against them.To encourage that defensive reaction, Janda's team designed small molecules called haptens that resemble the opioid molecules, but with proteins attached called epitopes that act as a binding site for antibodies produced by the immune system.Once an immune system is trained up with a series of vaccination shots, it will learn to recognise molecular structures that look like opioids thanks to exposure to these beckoning proxies \u2013 and will send out antibodies that cling to the drugs, preventing them from crossing the blood-brain barrier for up to eight months.\n\"The antibody binds to the drug so the drug can't get to the target,\" Janda explained.The new research has so far been conducted on mice and monkeys and hasn't been peer-reviewed yet \u2013 so we should bear that in mind, until more is known about how effective this approach could ultimately be in vaccinating humans against heroin and opioids.But the results build upon former work by the team separately vaccinating rhesus monkeys against heroin and mice against fentanyl, and the researchers hope the combined approach could one day help protect humans from the effects of these dangerous opioids.Better still, because the same receptors in the brain that signal pleasure in response to opioids are the ones that can depress breathing in high doses of drugs, it's possible the vaccine could reduce deaths from overdoses \u2013 a result the animal research suggests.\nTo that end, the team hopes to begin clinical trials investigating how their molecule works in humans.If they're successful, it could one day be a huge assist to psychology-based interventions treating addiction \u2013 provided people truly want to give up their habit, that is.\"Vaccines are meant to be used by people who want to quit taking drugs,\" Janda explained to Philip Ball at The Guardian.\"If you don't want to stop then nothing will help. The idea is that if they have a moment of weakness, they won't relapse and can continue with their therap"
        ]
    },
    "8109": {
        "gold_standard": [
            "You know what sounds pretty great? Finding out that you've won the US$700 million\u00a0Powerball jackpot.The lump sum minus taxes yields about US$293 million to play with, depending on where you live. Divide that by two or three to account for multiple winners, and it's still a ton of money.\nBuying a ticket\u00a0may not be a financially rational decision, but you'd still have to imagine that winning even a chunk of that money would make you super happy\u2026right?If you're not happy already, winning the lottery actually might not make a difference in the long term.The psychology of rolling in piles in cashThere's some fascinating research on the psychology of lotteries. Studies have shown that people are compelled to buy tickets because\u00a0we have a hard time processing just how unlikely\u00a0a win is and we give ourselves reasons to think we could somehow win.Some research\u00a0has also suggested that the desire to play the lotto may be stronger among people with lower incomes who hope to escape difficult financial circumstances.But perhaps most interestingly, research indicates that winning the lotto doesn't make people happier long-term. Contrary to popular myth, however, it\u00a0doesn't seem to make people\u00a0more likely to go on spending sprees that leave them broken and unhappy, either.\nWinners mostly report ending up about as happy as they were before winning.A classic\u00a01978 study\u00a0on this compared 22 lotto winners to 22 control-group members (who didn't win any money) and to 29 people who were paralysed in accidents.In general, the lottery winners reported that they were happier than the paraplegics and quadriplegics - a 4 out of 5 instead of a 2.96 out of 5.The control group averaged 3.82 out of 5, not significantly different from lotto winners. However, lotto winners reported getting the least enjoyment from what researchers called \"mundane pleasures\" - enjoyable aspects of everyday life like eating breakfast or talking with a friend.Researchers were surprised that lotto winners didn't report being significantly happier than non-winners, and that accident victims reported being above the scale's mid-point (2.5).\nOverall, winning the lottery didn't increase happiness as much as others thought it would, and a catastrophic accident didn't make people as unhappy as one might expect.As\u00a0Melissa Dahl noted in Science of Us, this is how the authors described the way winning might make it harder to enjoy everyday life:\n\"Eventually, the thrill of winning the lottery will itself wear off. If all things are judged by the extent to which they depart from a baseline of past experience, gradually even the most positive events will cease to have impact as they themselves are absorbed into the new baseline against which further events are judged.\nThus, as lottery winners become accustomed to the additional pleasures made possible by their new wealth, these pleasures should be experienced as less intense and should no longer contribute very much to their general level of happiness.\"\nHedonic adaptation\nAlthough 1978 analysis was a small study, a\u00a02008 study of Dutch lottery winners\u00a0reported similar findings.Those authors found that people who earned more money reported being happier (something psychologists have found is\u00a0true only up to a certain income threshold), but \"lottery winnings do not make households happier.\"The concept at play here is called \"hedonic adaptation.\" People have been shown to return to a kind of \"set point\" of happiness after events that we assume will have a big impact on how we feel.\"Some of us have our thermostat set to happy. Some are set to depressed. Meanwhile, others are somewhere in between,\" psychologist Robert Puff\u00a0wrote in Psychology Today.\"When we experience a major event, say winning the lottery or becoming paralysed, our thermostat may temporarily swing up or down. But over time, it returns to its usual setting.\"\nThere are things that we can do to\u00a0influence our own happiness, however, including cultivating strong relationships, spending time and money on fun experiences, and exercising.Perhaps a lucky lotto winner could devote their newfound wealth to those sorts of goals. But winning itself doesn't seem to be enough to boost happiness long-term.Still, it's pretty fun to imagine what that money could be used for - a mental state some psychologists say is\u00a0perhaps the best reason\u00a0to play the lotto in the first place.This article was originally published by Business Insider"
        ]
    },
    "8137": {
        "gold_standard": [
            "Researchers have shown how astronaut urine, poop and even exhaled breath could be turned into 3D-printed plastics and nutrients, the kind of smart waste recycling we're going to need if humans are to make the long trip to Mars \u2013 and beyond.\nThe trick is in a yeast called Yarrowia lipolytica, which scientists have found can feed on the carbon from our breath and the nitrogen in our pee to produce everything from vitamin supplements to polyesters, perfect for the production of space tools.Due to time and weight restrictions, we can't just take everything we're going to need on Mars up in a rocket, which is why the recycling system put together by a team from Clemson University could be vital for future missions to the Red Planet.\"If astronauts are going to make journeys that span several years, we'll need to find a way to reuse and recycle everything they bring with them,\" says one of the researchers, Mark A. Blenner. \"Atom economy will become really important.\"Right now, the carbon and nitrogen-eating yeast can only provide small amounts of polyesters and nutrients, but the team is working on increasing its output.\nOne of the developed yeast strains was engineered to produce omega-3 fatty acids, which help heart, eye, and brain health. The supplements we buy here on Earth have a shelf life of just a couple of years, so astronauts will need a way of making their own.Another strain was developed to produce polyester polymers, the type of plastic you can find in clothes and which could eventually be repurposed to feed a 3D printer \u2013 the hope is that astronauts could repair and replace tools while out in space.If that wasn't enough, the yeast investigations might help in fish farming and human nutrition on our own planet, through its ability to produce omega-3.\"We're learning that Y. lipolytica is quite a bit different than other yeast in their genetics and biochemical nature,\" says Blenner. \"Every new organism has some amount of quirkiness that you have to focus on and understand better.\"\nAs well as boosting the output of the yeast, there are other challenges to overcome: right now the yeast needs an extra ingredient added by the scientists to properly convert carbon, while the polymers are proving tricky to harvest from the yeast (which hangs on to them tightly as a potential food source).Even with the limitations of the system as it stands though, it shows a promising way of developing the sort of deep space waste recycling we'll need for long space journeys.The experiments have been funded with a grant NASA awarded in 2015 to look into this kind of biological processing, and to build on the human waste recycling systems we already have on board the ISS \u2013 urine and sweat can already be converted back into drinking water, for example.\"Having a biological system that astronauts can awaken from a dormant state to start producing what they need, when they need it, is the motivation for our project,\" says Blenner"
        ]
    },
    "8140": {
        "gold_standard": [
            "Changes to the Turkish secondary school science curriculum that has been expected to take effect by 2019 will be in place next month, according to recent updates on the controversial measure.\nWhile the government sees this as the foundation for a simpler, \"values-based\" education system, for many in the politically-charged nation it's a troubling sign of religious influences.Earlier this year drafts of the new Turkish education curriculum were discovered to no longer contain any mention of the word 'evolution', inspiring a call-to-arms from science advocacy groups such as the Ecology and Evolutionary Biology Society.The chair of Turkey's Board of Education, Alpaslan Durmu\u015f, has since outlined on the board's website the specific changes to the nation's primary and secondary curriculum, one of which is the removal of the grade 9 topic \"Origin of Life and Evolution\".\"We have excluded controversial subjects for students at an age unable yet to understand the issues' scientific background,\" Durmu\u015f claimed, stating it would instead be delayed until the students attended undergraduate studies.\nThe Education Minister Ismet Yilmaz echoed the chair's justifications, telling reporters, \"It's a theory that requires a higher philosophical understanding than schoolchildren have.Come September, those grade 9 students \u2013 made up mostly of 14-year-old children \u2013 will be reading from science textbooks that no longer mention evolution.As can be imagined, the changes have sparked a firestorm of debate not just in Turkey but around the world, with comparisons made with various attempts in the US to expunge similar 'controversial' topics from the syllabus.Turkish parents and academics have since voiced their concerns that without an adequate grounding in something as fundamental as an understanding of how and why life evolves, future generations of scientists will be significantly affected.\n\"I'm worried, but I hope it changes by the time my grandchildren are in high school,\" retired chemical engineer Emel Ishakoglu told NPR. \"Otherwise our kids will be left behind compared to other countries when it comes to science education.\"Behind it all there are deeper worries that the changes aren't so grounded in sound pedagogy, as much as politics.Despite its Muslim majority, as far as its constitution goes Turkey has been a secular nation for much of the 20th century. This is largely due to the revolutionary influences of the founder of the Republic of Turkey, Mustafa Kemal Atat\u00fcrk, about a century ago.\u00a0Other changes made to the curriculum in recent years have reduced the amount of time spent learning about Atat\u00fcrk while also making other changes to religious tuition, making some classes optional while adding modern concepts such as exploring the notion of jihad to others.\nSold as a \"simplification\" of the curriculum, the changes are being interpreted by some groups as a sign of an ongoing political shift in empowering the nation's religious groups.The current government, a conservative party led by President Recep Tayyip Erdo\u011fan since 2014, has implemented various changes to religious freedoms since coming into power, including the removal of a ban on the wearing of head-scarves and increasing the number of religious schools.For some, this is just one more sign of Turkey's eroding secularism. \"The last crumbs of secular scientific education have been removed,\" head of a secular-teachers union, Feray Aytekin Aydogan, told Patrick Kingsley at the New York Times. Turkey's politics and religious culture have influenced the teaching of evolution\u00a0and the inclusion of creationism in the curriculum for decades, making this change less unusual than first appears. It's yet to be seen how teachers will react to the changes, and how students will be affected given there is far more to the classroom than what's demanded by a syllabus.\u00a0But if the international response to the changes is any indication, Turkey's new curriculum reflects growing fears that science is increasingly being treated as a political position and not as a necessary part of a strong and productive futur"
        ]
    },
    "8142": {
        "gold_standard": [
            "Gut Microbes There's no shortage of evidence linking brain function\u00a0to the composition of our gut bacteria, but just how that relationship works is still something of a mystery.Now, a team has uncovered what looks like a communication channel between gut microbes and the brain, and they're theorising that the operation of this pathway may ultimately help explain how autism develops.\nThe researchers have specifically found that cortisol \u2013 often called the 'stress hormone' \u2013 could act as a messenger to chemicals in our heads.\u00a0These chemicals \u2013 called brain metabolites or neurometabolites \u2013 are crucial for helping the brain to function and grow.\"Changes in neurometabolites during infancy can have profound effects on brain development,\" explains neuroscientist Austin Mudd from the University of Illinois at Urbana-Champaign, \"and it is possible that the microbiome \u2013 or collection of bacteria, fungi, and viruses inhabiting our gut \u2013 plays a role in this process.\"To examine any potential associations between gut bacteria and compounds in the blood and brain, Mudd and fellow researchers studied 24 one-month-old piglets, which bear strong similarities to human infants in terms of gut and brain development.Using magnetic resonance spectroscopy to identify concentrations of neurometabolites, the aim was to find any associations with the pigs' gut bacteria.\n\"[We] wanted to see if we could find bacteria in the faeces of piglets that might predict concentrations of compounds in the blood and brain,\" Mudd says, \"both of which are more difficult to characterise in [human] infants.\"The analysis turned up a number of links. The genera Bacteroides and Clostridium predicted higher concentrations of a brain chemical called myo-inositol, while Butyricimonas predicted one called n-acetylaspartate (NAA).Bacteroides also predicted higher levels of creatine, but an abundant presence of Ruminococcus bacteria was associated with lower NAA concentrations.That's important, because while these compounds are involved in a number of chemical processes related to metabolism, they've previously been identified as a significant factor in autism research.\n\"These brain metabolites have been found in altered states in individuals diagnosed with autism spectrum disorder ( ASD),\" Mudd says, \"yet no previous studies have identified specific links between bacterial genera and these particular metabolites.\"Using a statistical method called mediation analysis to examine the ties between the bacteria Ruminococcus and the molecule NAA in particular, the researchers found that cortisol indirectly influences and enables the relationship.What this means is, in effect, the bacteria uses the steroid hormone to communicate with and make changes to the brain \u2013 at least in terms of the NAA metabolite.\"This mediation finding is interesting, in that it gives us insight into one way that the gut microbiota may be communicating with the brain,\" one of the team, Ryan Dilger, explains.\n\"It can be used as a framework for developing future intervention studies which further support this proposed mechanism.\"The researchers are cautious not to overstate their hypothesis, especially since this research is based in a statistical analysis focussed on piglets \u2013meaning this can't be taken as a clinical demonstration that the same mediation process is happening in people.But nonetheless, this kind of pathway may ultimately help explain how bacteria has been associated with any number of conditions \u2013 including strokes, Parkinson's disease, irritable bowel syndrome, chronic fatigue syndrome, and more.That list also includes autism \u2013 which researchers have previously hypothesised could be linked to bacteria.We may not know more with greater certainty until future clinical trials can replicate these findings \u2013 but the researchers, for all their caution, think they've definitely found something here.\n\"Initially, we set out to characterise relationships between the gut microbiota, blood biomarkers, and brain metabolites,\" says Mudd.\"But once we looked at the relationships identified in our study, they kept leading us to independently reported findings in the autism literature.\"The findings are reported in Gut Microbe"
        ]
    },
    "8145": {
        "gold_standard": [
            "I watched the solar eclipse on my parents' farm in Wisconsin and got a front row seat to wacky animal behaviour during the celestial event of the century.At the eclipse's peak, when the moon was covering about 83 percent of the sun, chipmunks popped their heads out of their burrows, and a pheasant started squawking incessantly. (My dog also briefly ran away, but I think that was mostly due to a scary garbage truck.)\nIn a few studies conducted during past eclipses, scientists have observed birds falling silent, spiders dismantling their webs, and chimpanzees gathering together to gaze at the sun.Most of the evidence we have of animals behaving differently during an eclipse is anecdotal, however. Yesterday, zoos, national parks, and science centres across the US encouraged people to report their observations of animals to get more information.On the iNaturalist app created by the California Academy of Sciences, people reported that at totality, fireflies emerged, crickets chirped, and cows mooed. But most of the observations submitted noted that animals didn't do much of anything.Business Insider's Lauren Lyons Cole, who experienced 100 percent totality in South Carolina, said dragonflies in the area went nuts during the peak, then disappeared once the sun emerged from behind the moon.\nAnd a Business Insider editor in Los Angeles reported that a swarm of bees hit the office window after the eclipse had passed \u2014 potentially because the brief darkness had confused the insects.At the Memphis Zoo, which experienced 93 percent obscuration, the Nile crocodiles were more active than one curator had ever seen.Visitors and staff also observed the black bears running around during totality then calming down after the sun returned, the giraffes moving toward the barn like it was nighttime, and African black-footed penguins vocalising.At the Jamaica Bay Wildlife Refuge in New York, which experienced 72 percent coverage, an \"eerie\" quiet fell over the National Recreation Area, Fox 5 reported.The crabs came to the edge of the water, probably thinking it was nighttime and that there wouldn't be any birds around to eat them there.\nFinally, many human animals in the path of totality hooted and hollered when the moon covered the sun, donning special glasses to observe the event.Hopefully the contributions of citizen scientists and the connections researchers were able to make using new technology will yield more reliable results. If so, we'll know more about what animals do during eclipses when the next one rolls around.This article was originally published by Business Insider.\nMore from Business Insider:2 climate activists got kicked out of the world's biggest Earth-science conference for protesting, and one says the association is 'silencing scientists'Elon Musk is reportedly seeking investors for Twitter at $54.20 a share \u2014 the same price he paid for itFEC asks Congress to take action on 'scam PACs' that raise millions for campaigns but only enrich their foundersThe 2022 World Cup Final will feature Argentina facing off against France \u2014 here's how to livestream the championship'1923' is the latest prequel to 'Yellowstone' \u2014 here's how to watch the new Western starring Harrison Ford and Helen Mirre",
            "I watched the solar eclipse on my parents' farm in Wisconsin and got a front row seat to wacky animal behaviour during the celestial event of the century.At the eclipse's peak, when the moon was covering about 83 percent of the sun, chipmunks popped their heads out of their burrows, and a pheasant started squawking incessantly. (My dog also briefly ran away, but I think that was mostly due to a scary garbage truck.)\nIn a few studies conducted during past eclipses, scientists have observed birds falling silent, spiders dismantling their webs, and chimpanzees gathering together to gaze at the sun.Most of the evidence we have of animals behaving differently during an eclipse is anecdotal, however. Yesterday, zoos, national parks, and science centres across the US encouraged people to report their observations of animals to get more information.On the iNaturalist app created by the California Academy of Sciences, people reported that at totality, fireflies emerged, crickets chirped, and cows mooed. But most of the observations submitted noted that animals didn't do much of anything.Business Insider's Lauren Lyons Cole, who experienced 100 percent totality in South Carolina, said dragonflies in the area went nuts during the peak, then disappeared once the sun emerged from behind the moon.\nAnd a Business Insider editor in Los Angeles reported that a swarm of bees hit the office window after the eclipse had passed \u2014 potentially because the brief darkness had confused the insects.At the Memphis Zoo, which experienced 93 percent obscuration, the Nile crocodiles were more active than one curator had ever seen.Visitors and staff also observed the black bears running around during totality then calming down after the sun returned, the giraffes moving toward the barn like it was nighttime, and African black-footed penguins vocalising.At the Jamaica Bay Wildlife Refuge in New York, which experienced 72 percent coverage, an \"eerie\" quiet fell over the National Recreation Area, Fox 5 reported.The crabs came to the edge of the water, probably thinking it was nighttime and that there wouldn't be any birds around to eat them there.\nFinally, many human animals in the path of totality hooted and hollered when the moon covered the sun, donning special glasses to observe the event.Hopefully the contributions of citizen scientists and the connections researchers were able to make using new technology will yield more reliable results. If so, we'll know more about what animals do during eclipses when the next one rolls around.This article was originally published by Business Insider.\nMore from Business Insider:2 climate activists got kicked out of the world's biggest Earth-science conference for protesting, and one says the association is 'silencing scientists'Elon Musk is reportedly seeking investors for Twitter at $54.20 a share \u2014 the same price he paid for itFEC asks Congress to take action on 'scam PACs' that raise millions for campaigns but only enrich their foundersThe 2022 World Cup Final will feature Argentina facing off against France \u2014 here's how to livestream the championship'1923' is the latest prequel to 'Yellowstone' \u2014 here's how to watch the new Western starring Harrison Ford and Helen Mirre"
        ]
    },
    "8150": {
        "gold_standard": [
            "Infectious Diseases The looming threat of antibiotic resistance means we desperately need new remedies to counter deadly superbugs, and researchers could have just found one in the most natural food source of all: breast milk.\nScientists have long known that, in addition to general sustenance, breast milk offers babies vital nutrients to build up their immune systems. Now, researchers have discovered a new mechanism behind this antibacterial boost \u2013 in breast milk sugars.Contrary to the understanding that antibacterial defences are passed from mothers to their babies solely through proteins in breast milk, a team from Vanderbilt University says sugars \u2013 or carbohydrates \u2013 also demonstrate properties that can protect against bacterial infections.\"This is the first example of generalised, antimicrobial activity on the part of the carbohydrates in human milk,\" says chemist Steven Townsend.\"One of the remarkable properties of these compounds is that they are clearly non-toxic, unlike most antibiotics.\" width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\">The most prominent infection that affects newborns is called Group B Streptococcus\u00a0(GBS), which can lead to babies developing sepsis or pneumonia before their immune systems are strong enough to fight off the bug.\nLuckily, while GBS can be deadly for babies, most newborns don't get infected by it, and the team wanted to investigate whether those infants might be getting protection courtesy of their mothers' milk.\"We wondered whether [GBS's] common host, pregnant women, produces compounds that can either weaken or kill strep, which is a leading cause of infections in newborns worldwide,\" Townsend explains.To find out, the researchers took human breast milk carbohydrates from five human donors and isolated complex sugars from them (called oligosaccharides), before introducing the oligosaccharides to strep cultures in the lab.Analysing the interaction under microscope, the team found the carbohydrate could both kill the bacteria as well as weaken its natural defences \u2013 by preventing it from forming a protective biofilm to fend off threats.Steven Townsend/VanderbiltIn the image above, that biofilm can be seen on the left \u2013 but it's prevented from forming in the presence of the carbohydrates (on the right).\n\"When bacteria want to harm us, they produce this gooey protective substance,\" Townsend explains, \"which allows them to thwart our defence mechanisms.\"In one sample, the sugars killed the strep entirely. In another, they were moderately effective at killing the strep, while in the remaining three samples the carbohydrates weren't very effective.To help explain what's going on here, the team is currently conducting another set of tests.In new research not yet published but presented this week at a meeting of the American Chemical Society in Washington, DC, Townsend's group again found a mix of results.These included two cases where breast milk sugars broke down the biofilm and killed the bacteria; four where the biofilm was broken but the bacteria survived; and two where the bacteria died, but the biofilm persisted.\nIt's early days, and it's clear that more research will be needed to figure out the spectrum of these outcomes.But if the team can solve the puzzle, it could lead to the beginnings of a new class of antibiotics, now that we know how these carbohydrates function in the presence of bacteria.\"[T]hese sugars have a one-two punch,\" says Townsend.\"First, they sensitise the target bacteria and then they kill them. Biologists sometimes call this 'synthetic lethality' and there is a major push to develop new antimicrobial drugs with this capability.\"In addition, the team says its preliminary, still-in-progress data indicates that milk sugars can make bacteria more susceptible to common antibiotics \u2013 such as penicillin and erythromycin.We shouldn't get too carried away until the team has more to show, but if those results pan out, it's possible that the carbohydrates might be able to one day lessen our reliance on these kinds of common antibiotics, and in doing so help to unravel a big part of the resistance problem.\nWe won't know more until the latest research is complete, but it's a hugely promising direction to investigate further \u2013 and one that, one day, could reap benefits for everybody.\"If you can figure out how the sugars are acting, then you can justify attempting to make large-scale amounts of them,\" Townsend says, \"and then putting them in humans.\"The findings are reported in Infectious Disease"
        ]
    },
    "8156": {
        "gold_standard": [
            "Is our non-stop photo-taking pulling us out of the moments that matter and causing us to forget what we've seen? Maybe not, according to new research looking at the relationship between snapping pictures and forming memories.\nDuring the study, 294 volunteers were asked to tour a museum exhibit listening to an audio guide \u2013 those in one group were encouraged to take photos, while those in another had to leave their phones and cameras behind.When questioned afterwards, the photo takers could remember more about what they'd seen and less about what they'd heard. The result suggests the act of taking pictures and seeking out worthy frames to capture helps fix memories in our minds, according to the researchers.\"Our research is novel because it shows that photo-taking itself improves memory for visual aspects of an experience but can hurt memory for non-visual aspects, like auditory details,\" said the team, from New York University, University of Southern California, University of Pennsylvania and Yale University, in a statement.The findings could help scientists understand more about how smartphone use and constant photo-taking is affecting our memories and the way we process information.\nWhile there is some evidence that our brains are using smartphone snaps and the internet as replacements for our long-term memories, that might not apply when we're taking photos of people and places that we really don't want to forget.this is my new favorite photo of all time pic.twitter.com/v8Qs6TeXZf\u2014 Wayne Dahlberg (@waynedahlberg) September 26, 2015\"People take photos specifically to remember these experiences, whether it's a fun dinner with friends, a sightseeing tour, or something else,\" say the researchers.The museum test was backed up with a follow-up experiment using a virtual art gallery app on a smartphone. Some volunteers could take screenshots and some couldn't, and the same pattern was repeated \u2013 those who grabbed digital memories remembered more of what they'd seen, but less of what they'd heard from an audio commentary.\nThe positive effect on visual memory was greater than the negative effect on auditory memory, the researchers found.Even when participants were only asked to take a mental photo, the same boost to memory was noticed, though the difference wasn't as significant. What's more, in both experiments those who could snap photos were also more likely to remember objects they hadn't specifically taken pictures of as well as ones they had.\"These findings suggest that having a camera changes how people approach an experience in a fundamental way,\" says the team.\"Even when people don't take a photo of a particular object, like a sculpture, but have a camera with them and the intention to take photos, they remember that sculpture better than people who did not have a camera with them.\"What's also interesting is that the study participants weren't allowed to review their photos before taking memory tests, which mimics what we tend to do in real life \u2013 taking a pile of photos of everything we see before never looking at them again.\nIt's almost as if the potential to take photos makes us more aware of our surroundings.Remember that human beings have only been able to capture moments in time in the form of photographs for less than 200 years, and the researchers suggest we've still got a lot to learn about the effects of photography on human behaviour.With the rise of digital photography and then smartphones, taking pictures and sharing them with millions of other people is now instant and effortless \u2013 and we still don't know exactly how that's affecting our take on life.\"Given the increasing centrality of photography in people's lives, addressing these open questions will be both theoretically interesting and relevant to people's lives,\" conclude the researchers in their published paper.The research has been published in Psychological Science"
        ]
    },
    "8160": {
        "gold_standard": [
            "The United States will see a\u00a0total solar eclipse\u00a0on August 21 for the first time in decades.\u00a0Some people are travelling\u00a0hundreds of miles to cities in the line of totality, like Nashville, Tennessee and Salem, Oregon.\nBut there is one thing that could put a damper on the event: clouds.Esri, an international supplier of geographic information system (GIS) software, has created a cloud-cover prediction map for the time of the eclipse in every state.\u00a0Michael Zeiler, a geographer at Esri, is producing new maps every day leading up to the eclipse.As you can see in the map below, clouds could obscure the eclipse in most states in its path of totality.Michael Zeiler/GreatAmericanEclipse.com; ArcGIS/EsriA total\u00a0solar eclipse\u00a0is an astronomical phenomenon that occurs when the moon passes between Earth and the sun, and appears to cover the latter. The two other types of eclipses are annular and partial, when the moon doesn't completely mask the sun.\nSolar eclipses\u00a0look different depending on the location. On August 21, the total solar eclipse will only cut through a 70-mile-wide band of the country, stretching from the northwest to the southeast US.Everyone in the US - from Maine to Alaska - will be able to experience at least a partial eclipse, weather permitting.For most of the US, the eclipse will happen\u00a0around lunchtime.\"This is the subject of intense interest for millions of people interested in going to see the eclipse,\" Cameron Lowe, a spokesperson for Esri, told Business Insider in an email. \"Weather will be a huge factor.\"This article was originally published by Business Inside"
        ]
    },
    "8171": {
        "gold_standard": [
            "Scientists have developed a packaging-free, instantly dissolvable milk capsule that you can drop straight into your hot beverage, making them easier to use than the conventional little cartons we're all used to, and reducing waste along the way.\nThey're essentially like sugar cubes but for milk, and the team behind them says they're produced along similar lines, with a crystalline layer keeping the milk contained until you're ready to dunk it.When you weigh up just how many tiny milk containers get used in hotels and elsewhere \u2013 and how fiddly they can be to break into \u2013 the new capsules produced by researchers from the Martin Luther University of Halle-Wittenberg in Germany look like they could be a significant improvement.\"For example, the capsules could replace the small, extremely unpractical coffee creamer packaging that is used in great quantities at conferences or on airplanes,\" says one of the team, Joachim Ulrich.The researchers were able to encapsulate liquid milk inside two\u00a0crystallised\u00a0substances: sucrose for a high level of sweetness, and erythritol for a medium level of sweetness.\nFor the time being, if you don't want any sugar in your drink alongside the milk, then you're out of luck \u2013 but the team is working on it.The way it works is milk and the chosen substance are mixed together and fitted into a mould. As the solution cools, the added sugar moves to the edge of the mould, forming crystals that then keep the milk in place until it's needed in your tea or coffee.The little pods stay sealed at room temperature and can keep for at least three weeks, making them ideal for hotels, aeroplanes, conference centres, and so on. They can even be made in a variety of shapes.As soon as the capsules are dunked into something hot, the crystallised\u00a0outer layer dissolves and you've got your milk and your sweetener in one package, with no extra cartons to get rid of.We couldn't find statistics for the number of tiny milk containers produced a year \u2013 maybe no one has gone to the trouble of counting them \u2013 but with around 8 million tonnes of plastic getting dumped into the ocean every year, anything we can do to try and cut down on the waste we're producing has got to be good news.\nIt's not clear when we'll be able to start using these sugary capsules though: as with anything that's going to be eaten or drunk, there are a host of health and safety requirements to be met first, and more work needs to be done on scaling up the process of producing the pods.But when they are ready, we'll be ready to use them. As an added bonus, the team behind the new dissolving milk pods says the process can be adapted for other drinks as well.\"Our processes can also be used for other liquids. For example, we can also encapsulate fruit juice concentrate,\" says one of the researchers, Martha Wellner.Details of the research have been published in Chemical Engineering & Technology"
        ]
    },
    "8183": {
        "gold_standard": [
            "President Donald Trump's vow to hit North Korea with 'fire and fury like the world has never seen' is an unveiled threat to unleash America's most potent weapons of mass destruction onto the Korean peninsula.\nAccording to many defence analysts, the risk of nuclear confrontation over Europe and the Indian subcontinent has also increased in recent years.In a more hopeful turn of events, 122 countries voted in June to adopt the United Nations Treaty on the prohibition of nuclear weapons in New York. The \"ban treaty\" will make nuclear weapons illegal for ratifying countries, and many see it as an opportunity to kick start a renewed effort towards multilateral disarmament.Supporters of the treaty argue that even a limited, regional nuclear war would produce a catastrophic and global humanitarian crisis.\u00a0Equally, other analysts suggest that the reality is not as severe as is often depicted.In March this year, Matthias Eken, a researcher of attitudes towards nuclear weapons, wrote in The Conversation that their destructive power \"has been vastly exaggerated\" and that one should avoid overusing \"doomsday scenarios and apocalyptic language\".\nEken argued that nuclear weapons are not as powerful as often described, on the basis that a 9 megaton thermonuclear warhead dropped over the state of Arkansas would only destroy 0.2 percent of the state's surface area.He also observed that more than 2,000 nuclear detonations have been made on the planet without having ended human civilisation, and argued that if we want to mitigate the risk posed by nuclear weapons, we must not exaggerate those risks.Eken's sanguine approach towards nuclear weapons stands in contrast to the more dramatic rhetoric of global humanitarian catastrophe and existential threats to humanity. So what is the basis for the latter?Nuclear war is also a war on the environmentThe greatest concern derives from relatively new research which has modelled the indirect effects of nuclear detonations on the environment and climate. The most-studied scenario is a limited regional nuclear war between India and Pakistan, involving 100 Hiroshima-sized warheads (small by modern standards) detonated mostly over urban areas.\nMany analysts suggest that this is a plausible scenario in the event of an all-out war between the two states, whose combined arsenals amount to more than 220 nuclear warheads.In this event, an estimated 20m people could die within a week from the direct effects of the explosions, fire, and local radiation. That alone is catastrophic \u2013 more deaths than in the entire of World War I.But nuclear explosions are also extremely likely to ignite fires over a large area, which coalesce and inject large volumes of soot and debris into the stratosphere.In the India-Pakistan scenario, up to 6.5m tonnes of soot could be thrown up into the upper atmosphere, blocking out the sun and causing a significant drop in average surface temperature and precipitation across the globe, with effects that could last for more than a decade.\nThis ecological disruption would, in turn, badly affect global food production.According to one study, maize production in the US (the world's largest producer) would decline by an average by 12 percent over ten years in our given scenario.\u00a0In China, middle season rice would fall by 17 percent over a decade, maize by 16 percent, and winter wheat by 31 percent.With total world grain reserves amounting to less than 100 days of global consumption, such effects would place an estimated 2 billion people at risk of famine.Although a nuclear conflict involving North Korea and the US would be smaller, given Pyongyang's limited arsenal, many people would still die and ecological damage would severely affect global public health for years.Additionally, any nuclear conflict between the US and North Korea is likely to increase the risk of nuclear confrontation involving other states and other regions of the world"
        ]
    },
    "8198": {
        "gold_standard": [
            "Geophysical Research Letters The historic 1987 treaty to fight the hole in the ozone layer wasn't just an international success story \u2013 it was a stunning environmental victory that's still saving the planet in unexpected ways some 30 years later.\nThe Montreal Protocol successfully outlawed harmful chemicals that deplete ozone in the atmosphere, but new research shows the ban had an amazing, unforeseen side effect: drastically slashing greenhouse gas emissions in the US.A new analysis led by the Cooperative Institute for Research in Environmental Sciences (CIRES) is the first study using atmospheric observations to quantify the impact of the Montreal Protocol on US greenhouse gas emissions.The results show that banning the use of ozone-depleting substances such as chlorofluorocarbons (CFCs) and hydrochlorofluorocarbons (HCFCs) had ramifications far beyond the intended aim of restoring ozone levels in the atmosphere and plugging the hole in the ozone layer.Between 2008 and 2014, the prohibition on these environmentally harmful chemicals actually eliminated the equivalent of 170 million tonnes of carbon dioxide (CO2) emissions each year.NOAA/CIRES\"We were surprised by the size of the decline, especially compared with other greenhouse gases,\" says lead researcher Lei Hu.\nIt's a staggering result \u2013 equivalent to about half the reductions achieved in the US for CO2 and other greenhouse gases in the same period \u2013 and one that was never anticipated by the Montreal Protocol's framers back in the 1980s, before the true extent of today's global warming predicament was known throughout the science world.Previous research had already demonstrated this beneficial side effect of the ozone-depleting chemicals ban in an international context, but the new study is the first to look at how the thermal changes play out in North America's atmosphere.The researchers predict that by reducing the volume of CFCs and HCFCs in the air \u2013 potent gases that can trap heat up to 10,000 times greater than CO2, in addition to harming ozone \u2013 the Montreal Protocol will produce even greater atmospheric benefits in the future.Specifically, by 2025, the team estimates the Montreal Protocol will effectively reduce US greenhouse gas emissions by the equivalent of 500 million tonnes of CO2 annually compared with 2005 levels.\nNot bad at all for a treaty moonlighting on its day job, given this equates to approximately 25\u201330 percent of the US target originally committed to at the UN's Paris climate deal, COP 21.\"Most of these reductions will be in addition to what is achieved by COP21 because ozone-depleting substances are not included in COP21 targets,\" Hu explains.Of course, the Montreal Protocol hasn't just solved everything in relation to the ozone layer. Another unintended side effect of the treaty \u2013 and this time, not a positive one \u2013 was the introduction of hydrofluorocarbons (HFCs).This alternative chemical was developed to take the place of CFCs and HCFCs in things like refrigerators and air conditioners where it's used as a coolant, but while HFCs don't hurt ozone, they're still devastatingly effective at trapping heat \u2013 so not something we want just hanging around in our atmosphere.\nFortunately, an amendment to the Montreal Protocol last year will phase out these dangerous substitutes too \u2013 a move that then US Secretary of State John Kerry applauded as \"likely the single most important step we could take at this moment to limit the warming of our planet and limit the warming for generations to come\".We still don't know how for sure how impactful that amendment will turn out to be \u2013 but if it's anything like its protocol parent, we're hoping for great things.We may still have a long way to go in fixing Earth's ozone problems for good, but it's undeniable that the Montreal Protocol has been a great thing for the planet (HFCs notwithstanding).It's helped ozone, it's hindered climate change.And it serves as a great example of how, 30 years ago, the world united as one to avert a towering environmental catastrophe \u2013 an invaluable, inspiring piece of history we can never forget.The findings are reported in Geophysical Research Letter"
        ]
    },
    "8202": {
        "gold_standard": [
            "For nearly 60 years scientists have known the chemical responsible for magic mushrooms' psychedelic reputation is a compound called psilocybin. What we haven't known is the biochemical pathway behind this famous hallucinogen.\nFeel free to now tick that one off your chemistry bucket-list. German researchers have identified four key enzymes involved in making the chemical, potentially setting the stage for mass production of a promising pharmaceutical. Psilocybin was first identified by the Swiss scientist Albert Hofmann way back in 1959, but has only recently re-entered the spotlight as a safe way to treat conditions related to anxiety, depression, and addiction.As the evidence mounts, there could be a need for an efficient way to synthesise the compound for experimentation and mass production.So a small team of researchers from Friedrich Schiller University Jena in Germany sequenced the genomes of the magic mushroom species Psilocybe cubensis and Psilocybe cyanescens to hunt for the biochemical components responsible for constructing this mind-bending molecule.\nThey had their suspicions, as early work on the molecule's biosynthesis using radioactive tags had already revealed the order of the steps required to turn a molecule of tryptophan\u00a0- an essential amino acid - into a series of chemicals, ending up with psilocybin.While the order is a little different than it first appeared, it turns out four enzymes are responsible for the entire process.Knowing what these enzymes are as well as the genes that encode them is a boon for any future pharmacologist who might want to churn out buckets of the stuff, or tweak the secret recipe to suit their needs.\"Our findings set the stage for heterologous production of [psilocybin] in a controlled place for pharmaceutical purposes, using engineered microbial hosts, should the re-discovered pharmaceutical value lead to increased demands,\" the researchers write in their report.\nUnfortunately since the mid 1960s, the production of psilocybin from mushrooms has been heavily regulated, with a reputation as a mind-altering drug for party-goers rather than a potential therapeutic for mental illnesses.That not only made it harder to study, its baggage as an illicit substance has dissuaded researchers from looking deeper into any potential benefits.After four decades of virtually ignoring the science of psychedelics, researchers tentatively returned to investigating how substances such as lysergic acid diethylamide ( LSD) and psilocybin behaved in the brain.Since then researchers have found evidence that psychedelics can reduce the clinical symptoms of mood and affective disorders, addiction, and even help painful conditions such as cluster headaches.More recently, it's been found that small doses of psilocybin can be used in conjunction with therapy to help 'reset' brains as they're going through counselling.\nAs far as risks go, the biggest problems consumers of magic mushrooms currently face stem from mistaking their mycology and picking a toxic dead ringer in the wild, finding specimens that have too little (or too much) active compounds for their liking, or behaving in dangerous ways under the drug's influence.\"Magic mushrooms are one of the safest drugs in the world,\" consultant addiction psychiatrist Adam Winstock recently told Olivia Solon at The Guardian.Compared with other illicit substances such as LSD, cocaine, and MDMA, risk of harm from taking psilocybin is at least five times lower.For all of its promise, even the most advanced clinical trials won't bear fruit for a number of years.If, or when, psilocybin gets the big tick of approval as a safe and effective form of medication, it's nice to know the groundwork has been set for a cheap and effective production process.This research was published in Angewandte Chemie"
        ]
    },
    "8212": {
        "gold_standard": [
            "The intriguing, yet somewhat malodorous, topic of poo transplants is in the news. A study published today found poo transplants are better at treating a particular type of diarrhoea than an antibiotic or placebo (a fake or dummy treatment).\nThe study collated and analysed the results from earlier studies in how effective poo transplants were in treating diarrhoea caused by the bacterium Clostridium difficile.Researchers have been interested in alternative treatments for this condition due to the rise in resistance to standard treatments (including antibiotics). So this type of diarrhoea has quickly developed into a more life-threatening disease.The study findings are in line with recent European advice strongly encouraging setting up centres specialising in poo transplants to treat C. difficile diarrhoea.Despite the apparent success of poo transplants for this particular condition, there is still much we don't know about this therapy. It's important to figure out how long the effects last, and which bugs in the poo transplant help us cure disease and which don't t.\nHow do poo transplants work?Poo transplants (or \"faecal microbiota transplantation\") involve transferring poo from a healthy donor to a sick recipient. The collective community of bugs and compounds (the gut microbiota) in the donor's poo is then believed to establish itself in the recipient's gut.The scientific consensus is poo transplants work if the recipient's gut microbiota is \"restored\". The most consistent measure of this has been an increase in the diversity of the community of organisms in the recipient's gut.By encouraging a more diverse and beneficial community of organisms in the gut, the idea is that this allows the recipient to resist being overwhelmed by the \"bad\" bugs. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\">Before donating their poo, donors' poo and their blood is screened for many infectious agents such as C. difficile, HIV and viral hepatitis (A, B and C). This is to make sure a donation doesn't transfer pathogens (disease causing microorganisms) by accident.\nThe screened donor poo is then delivered to the recipient in a number of ways.Delivery methods from above involve recipients swallowing a poo capsule (or \"crapsule\") containing frozen poo. Alternatively, a diluted sample can be delivered through a plastic tube inserted into the nose down to the stomach or small bowel (nasogastric intubation).Samples can also be delivered from below via colonoscopy, where a tube is inserted into the rectum and goes deep into the gut to the caecum (just above the appendix). Or recipients can have an enema, where fluid is infused through the rectum.What works?Poo transplants made their way into the medical literature a long time ago with the first successful result in 1958. Interest in poo transplants was ignited in 1989, in Australia, when various conditions including irritable bowel syndrome responded to therapy.\nHowever, it was not until 2013 that the first controlled trial for C. difficile diarrhoea was carried out, which showed the treatment was better than antibiotics and placebo.The trial was stopped early as the ethics committee considered it unethical to withhold this therapy from the control group. The research out today backs these findings.There is also evidence that poo transplants may be beneficial for patients suffering from the gut conditions colitis and Crohn's disease, a range of infectious or inflammatory liver conditions, and in eliminating antibiotic-resistant bacteria from recipients' guts.Preliminary studies also suggest benefit for coeliac disease (in a single person), irritable bowel syndrome (in mice), and for bowel and behavioural symptoms in children with autism spectrum disorders (this was a small study"
        ]
    },
    "8230": {
        "gold_standard": [
            "Can having a pet improve your health? It's a question that's fascinated scientists and pet owners for years, but the latest research seems to suggest that no, maybe it can't.\nThe study showed that children in households who had cats and dogs were healthier overall in a number of ways \u2013 but after accounting for controlling factors, it also showed that the cats and dogs were unlikely to be the reason why.The findings are a counter argument to many other studies that have found a link between pets and healthiness, but members of the team from the RAND Corporation, a research nonprofit, say they were surprised by the results too.\"We could not find evidence that children from families with dogs or cats are better off either in terms of their mental wellbeing or their physical health,\" says one of the researchers, statistician Layla Parast.\"Everyone on the research team was surprised \u2013 we all have or grew up with dogs and cats. We had essentially assumed from our own personal experiences that there was a connection.\"\nOne of the reasons this new study is worth taking note of is that the sample size is so large: it looked at 5,191 households in total, using data from the California Health Interview Survey collected in 2003. That's bigger than many other pet and health studies.What also sets this research apart are the advanced statistical calculations used to control for multiple factors that could also boost a child's wellbeing, including being in a higher income family, living in a wealthier area, or the type of family housing.As expected, the kids with pets were doing better overall: they tended to have better health in general and slightly higher weights, and were more likely to be physically active. They were even noted as being more obedient.But when the findings were adjusted to account for a bunch of other variables that can influence wellbeing, the health differences between the pet-owning households and the non-pet-owning households almost completely disappeared.\nThose results will seem strange to anyone who's felt the happiness of owning a pet, including the RAND researchers themselves.\"I've talked to a lot of friends of mine whose reaction was like yours and mine: No!,\" Parast told James Hamblin at The Atlantic. \"This can't be true. What kind of 'science' are you doing?\"One possibility is that owning a pet signifies better health rather than causing it, but there's some hope for those of us who are still sure that pets really can be good for us.To begin with, the data in this research only looks at a snapshot of children's health at one particular point in time, rather than over months or years.And the team behind the analysis says further studies would be required to get a definitive answer on whether pets are responsible for better health, with some participants given pets and others not, and wellbeing tracked over 10 years or more.\n\"We're not completely ruling out that pet ownership leads to good health,\" Parast told The Atlantic. \"We're just saying you need to step back and see that people who own pets are different from people who don't in a whole lot of ways.\"What's more, Parast says owning a pet brings the joy of companionship and a host of other benefits that aren't necessarily recorded in standard measurements of health like BMI and the time we spend being active.So there's hope yet for the hypothesis that owning a cat or a dog can improve your health \u2013 we just need more evidence for it.\"It would be great to have a reason to hand out cuddly puppies to everyone who needs better health,\" Parast told The Atlantic.\"I would be completely in favour of that. But there's no scientific evidence right now that shows that.\"The research has been published in Anthrozoos"
        ]
    },
    "8236": {
        "gold_standard": [
            "To play any game, you need to have a basic grasp of the rules. But the way we learn and process those rules is a fascinating process in itself - one that scientists can use to investigate learning in animals.\nNow scientists have demonstrated that chimpanzees (Pan troglodytes) can learn the relationship between the three hand signals we use to play rock-paper-scissors, and become as adept at it as four-year-old people.The team, led by researchers from Kyoto University in Japan, employed seven chimps of both sexes and various ages, all residents of the university's Primate Research Institute. All were already familiar with computer-controlled tasks.Even though chimps have more sophisticated hands than we do, they weren't actually taught to make the hand signals we use to play the game, but instead were presented with pictures of these signals on a screen, portrayed with both chimp and human hands.Each picture showed two of the three hand signals, and the chimps had to indicate the preferred one - paper over rock, scissors over paper, and rock over scissors.\nThen the learning process began. Sitting in a cosy experimental booth, the animals would tap on the pictures on the screen and either be rewarded with a piece of apple and a chime sound, or an error buzzer and no food.Gao et al. (2017)This went on for 48 trials per session, three times a day, and the different signals were progressively mixed in complexity as the chimps learnt the relationships between them.Eventually five of the seven chimps completed the entire training program with pictures of both chimp hands and - once they'd mastered those - of human hands as well. It took them an average of 307 training sessions.\nTo see how their learning ability compared to human kids, the researchers then experimented with teaching this same set of game rules to 38 preschool children, ranging in age from about three to six years.The set-up was similar, except the experiments were conducted at a kindergarten and the kids were not rewarded with a piece of apple when choosing correctly - it was just a chime sound and a picture of happy chimps\u2026 and a small reward for showing up.\"After the experiment, the children received cartoon stickers as a reward for their participation, regardless of their performance,\" the researchers note in the study.In comparison to the chimps, most of the kids grasped the rules pretty quickly, averaging just five sessions of 12 trials. But their success was strongly correlated with age - anyone under four years old was hopeless, scoring no better than chance at selecting the right hand signals.\n\"[T]his circular problem is highly difficult for children below the critical age of approximately 4 years,\" the team concluded, noting that it's also possible older kids might be more familiar with the game already.Overall, after crunching the data, researchers concluded that once chimps have learned the basics, their mastery of rock-paper-scissors was as good as that of tiny people.\"The chimpanzees' performance during the mixed-pair sessions was similar to that of four-year-old children,\" says lead researcher Jie Gao.The team's results build on previous studies that investigate how animals other than ourselves can learn circular relationships, and they hope they have laid ground for further investigations on the subject.And we like to imagine that somewhere in the outdoor compounds of the institute in Kyoto a bunch of chimps are currently playing rock-paper-scissors to determine who wins the juiciest fruit for lunch.You can read the full study in Primate"
        ]
    },
    "8262": {
        "gold_standard": [
            "Scientists have discovered a new difference between the sexes: women's brains seem to be more active than men's brains, in terms of blood flow through specific regions.It doesn't mean women can be labelled smarter or deeper thinkers, but it could give us clues to treating brain diseases like Alzheimer's and Parkinson's, and adapting those treatments based on gender.\nA team from Amen Clinics in California looked at 46,034 brain scans carried out through SPECT (Single-Photon Emission Computed Tomography) technology, specifically designed to track blood flow through the brain.\"This is a very important study to help understand gender-based brain differences,\" says lead researcher Daniel Amen, a renowned psychiatrist with a somewhat controversial reputation.\"The quantifiable differences we identified between men and women are important for understanding gender-based risk for brain disorders such as Alzheimer's disease.\"Increased blood flow in women's brains is shown in red. Credit: Amen ClinicsAs well as 119 healthy volunteers, the scans covered 26,683 patients with psychiatric conditions, both while the brain was at rest and while it was focussed on a certain task.\nAreas where women's brains were found to be significantly more active in terms of blood flow were the prefrontal cortex, which helps with controlling impulses and maintaining focus, and the limbic or emotional parts of the brain, which handle mood and anxiety.The researchers suggest this could explain why women are often considered more empathetic and intuitive than men (although the extent of this effect varies), for example, and also at a greater risk of developing problems with anxiety.Women have significantly higher rates of depression and anxiety disorders, while men are more at risk of Attention Deficit Hyperactivity Disorder ( ADHD) and much more likely to end up in prison. The SPECT scans might explain some of those differences.While there was more blood flow in women's brains overall, male brains had more blood flow in certain areas, including the visual and coordination centres of the brain.\nThese variations could eventually help us understand why the risk of Alzheimer's and Parkinson's is different between men and women. Part of the reason seems to be that some of the brain's deepest structures age more quickly in the male brain.Exactly what this higher activity means isn't fully clear to scientists, and likely depends on the region of the brain in question.\"These results do not mean that women's brains are more active, or that women use more of their brains,\" the neuroscience blogger Neuroskeptic explains over at\u00a0Discover Magazine.\"All we know is that more blood flows through blood vessels in the female brain. There could be many possible explanations for this.\"It is thought that increased blood flow, and the extra oxygen that goes along with it, leads to better brain function \u2013 without it, the brain dies \u2013 but in the case of this particular study the scientists are focussing on how the findings might help us understand malfunctioning brains.\"Using functional neuroimaging tools, such as SPECT, are essential to developing precision medicine brain treatments in the future,\" says Amen.The findings have been published in the Journal of Alzheimer's Disease"
        ]
    },
    "8289": {
        "gold_standard": [
            "Advanced Materials Interfaces Scientists have created a material that can switch between repelling and absorbing water droplets at the flick of a switch.The copper based material can go from super hydrophobic (water hating) to super hydrophilic (water loving) in a matter of seconds and could be used for water filtration, biomedical devices, liquid lenses and smart self-cleaning surfaces.\nSuper hydrophobicity is something that's incredibly satisfying to watch. We've seen hydrophobic knives slice through water with ease, cause water to bounce off surfaces like tennis balls and you'd be lying if you said that watching super hydrophobic materials on YouTube didn't fill a hole in your life you didn't know existed.And on the other side of the coin, super hydrophilicity is used to pull drinking water straight from the air and used to create self-cleaning glass.But what about a material that can switch between both of these properties?In the past, scientist have attempted to make these type of materials with heat treatment or bombarding the copper with UV and X-rays but the treatment takes hours or days and severely limits the applications.This new study creates a material that can switch properties in seconds \u2013 instead of hours \u2013\u00a0and it'll surprise you with how simple it turned out to be.\nThe scientists used a copper based surface which changes from water loving to water hating by simply changing the voltage applied across the surface. The voltage required to change the properties of the surface is as low as 1.5 volts \u2013\u00a0lower than that found in a normal household battery.\"When tiny voltages are applied to the surface, water droplets that initially roll off stick to it more and more tightly,\" says Ben Zahiri, one of the researchers, from the\u00a0University of British Columbia (UBC).\"By changing the magnitude of the voltage and how long it is applied, we can easily control the angle that each droplet forms with the surface and how quickly this happens.\"The copper is deposited on a surface by a process called electrodeposition, which\u00a0causes the copper to grow like an array of Christmas trees\nThis this what the surface looks like:UBCThe material works by changing the oxidation state of the copper surface; as copper loses electrons, it becomes less attracted to water.At zero volts, the water sits on top of the Christmas trees and as soon as the voltage is applied the water seeps into the Christmas tree surface.Things got stranger when they changed the voltage while the droplet remained on the surface.When the scientists switched the material from super hydrophobic to super hydrophilic it acted as an electric sponge that held onto and released liquids at the press of a button \u2013 something really useful for dealing with hazardous material spills.\nThe team from chose copper because it is cheap and abundant and is one of the most commonly used metals in the world.Zahiri believes that the electrochemical manipulation of other metals, metal oxides, and mixed oxides may yield similarly promising results.Although they didn't test it directly, the scientists say the material could be used to manipulate any conducting liquid, which includes blood.\"These findings could open up a new area of exploration for smart surfaces,\" says lead researcher Walter M\u00e9rida.We can't wait to waste hours watching these new materials on YouTube.\u00a0This study was published in Advanced Materials Interface"
        ]
    },
    "8322": {
        "gold_standard": [
            "Tonga was once at the centre of a vast trading empire stretching 500,000 square kilometres (193,000 square miles) across the Pacific.Stone tools imported during the last 1,000 years from Fiji, Samoa, and the Society Islands reveal that the maritime empire of Tonga served as a hub through which prehistoric people exchanged products and political ideas, according to a study.\nFrom about 1200 AD, the state of Tonga integrated the archipelago under a centralised authority and emerged as a unique maritime empire which engaged in long distance economic and political commerce.Seeking to establish the extent of Tonga's maritime polity, Geoffrey Clark of the Australian National University and colleagues geochemically analysed stone tools excavated from places central to the Tongan seat of power.They focussed on artefacts associated with stone-faced chiefly tombs.The analysis revealed that about two-thirds of the tools were imports from Fiji, Samoa and the Society Islands, and that exotic stone artifacts likely represented an important source of political capital to Tongan elites.The stone tools found in Tonga came from Fiji, Samoa, and Tahiti, 2,500 km (1,553 miles) away.\nModern Tonga\u00a0is a constitutional monarchy, a Polynesian state made up of 176 islands.The study, \"Stone tools from the ancient Tongan state reveal prehistoric interaction centers in the Central Pacific\", is published in the journal PNAS.This article was originally published by Business Insider.\nMore from Business Insider:Trump did not plead the Fifth when deposed in 'Electric Avenue' copyright suit, Eddy Grant's lawyers saySam Bankman-Fried is reportedly willing to be extradited to the USIncoming GOP congressman accused of lying about his employment history and where he went to college defends himself with a false Winston Churchill quoteDeSantis' latest education plan targets teachers' unions by ending automatic dues in favor of monthly mailed-in checksI'm a 41-year-old Airbnb host whose revenue fell nearly 10% this year, and I plan to keep dropping my nightly rates as competition from other hosts heats up in 202"
        ]
    },
    "8335": {
        "gold_standard": [
            "Among the possible pest infestations you could get, bed bugs are definitely one of the worst. They'll nest inside your mattress and feast on your flesh at night, and they develop resistance to pesticides really quickly.\nSo once you have them, getting them gone is really tricky and requires professional help.And there has been a resurgence around the world in the last decade, possibly exacerbated by the accessibility of low-cost travel options.Bed bugs, or Cimex lectularius, are small, can't fly, and prefer living in holes in their host's sleeping area, yet infestations are common around the world in travel accommodations.The likeliest explanation is that they're hitchhiking rides in travellers' luggage.There are steps you can take to minimise the risk of that happening to you, according to researchers from the University of Sheffield in the UK.Namely, taking care of your dirty laundry - because it turns out that C. lectularius likes your clothes when they're grubby.To get to that point, first the team thought about mosquitoes, another insect that feeds on the blood of mammals.\nMosquitoes are attracted to carbon dioxide, which is present in mammalian exhalation. However, in the presence of the smell of a human body, the mosquito will preference that over CO2.It's possible that bed bugs have similar instincts, so the team set up two identical, temperature controlled rooms to figure out if that was the case.Containers of 10 bed bugs, 5 male and 5 female, were placed in the rooms. One room had elevated CO2 to simulate the presence of a human in the vicinity, the other did not. Into each room, the researchers placed four tote bags of laundry, two dirty and two clean.Interestingly, while the CO2 seemed to initiate more host-seeking behaviour, it didn't seem to make much difference to where the bed bugs went after they had emerged from their container. Similar, as the researchers thought, to mosquitoe"
        ]
    },
    "8346": {
        "gold_standard": [
            "Australia was once home to a giant prehistoric Ice Age marsupial related to wombats and koalas, and that followed an annual seasonal migration.The three-tonne beast, up to 1.8 metres (6 ft) tall and 3.5 metres (11.5 ft) long, was the only known marsupial to follow a migration pattern, according to our research published in the journal Proceedings of the Royal Society of London B.\nFor many years, palaeontologists have marvelled at the fossil deposits of southeast Queensland's Darling Downs, describing it as a \"vast graveyard\" of the enormous herbivorous and carnivorous animals of the Pleistocene (from about 1.6 million to 10,000 years ago).These giant, now extinct animals are commonly dubbed the megafauna and comprised a suite of oversized marsupials, reptiles and birds.The diversity of the Darling Downs' Ice Age wildlife was incredible and included some heavy-hitting record breakers:Megalania (Varanus priscus), the biggest venomous lizard ever to exist, the Marsupial \"Lion\" (Thylacoleo carnifex), the largest known pouched predator, and the ruler of the Pleistocene, the 3,000kg wombat-like Diprotodon (Diprotodon optatum), famous for being the bulkiest marsupial ever to walk the planet.\nBut what was life like on the Darling Downs during the Ice Age? Our new study focused on reconstructing the palaeobiology and palaeoecology of Diprotodon in an effort to reveal the secrets of \"Australia's Serengeti\".A giant among giantsDiprotodon is one of the first Australian animals described on the basis of fossils, but very little is actually known about it. Its fossil record tells us that it was the most widespread species of megafauna and also one of the last surviving.Our study concentrated on Diprotodon's teeth. These can reveal a remarkable amount of information about extinct animals such as their diet and relationships to other species.Gilbert PriceWe selected an upper incisor and drilled numerous samples from the tough, crystalline outer enamel for a geochemical study. (You can see it in 3D detail here.)\nThe old saying \"you are what you eat\" is absolutely true, for the chemical signature of the foods that an organism eats becomes fixed into its teeth when they form.But it's also true that \"you are where you ate\", especially if you are a plant eater. The geochemistry of the soils where plants grow also becomes incorporated into a herbivore's teeth.If that particular geochemical signal varies within a given tooth, it would imply that the individual fed across different geological regions when alive.Like elephant tusks, Diprotodon's front incisors never stopped growing throughout its life. Thus, our sampling revealed not only seasonal changes in food and water intake of the Diprotodon, but also the various geological provinces where the individual once travelled.Migrating megafauna\nOur data clearly show that Diprotodon was a seasonal migrant. It tracked its preferred food source year after year across vast geological regions of the Darling Downs.It would move roughly north to south and back again, up to 200km (125 miles) per year in massive round-trip journeys, just like many of East Africa's mammals do today.And like those East African cousins, Diprotodon moved in herds or mobs.To date, no other marsupial living or extinct is known to undertake such journeys.This is all the more remarkable considering that Diprotodon's closest relatives, the metatherians (a mammal group that includes all living marsupials but not placental or egg-laying mammals), have been around for more than 160 million years.Our data suggest that such migration is an ecological phenomenon that has been extinct in Australia since the Pleistocen"
        ]
    },
    "8405": {
        "gold_standard": [
            "Fast radio bursts are quite the ongoing space mystery. We don't know what they are, and only a couple of dozen sources have ever been detected by radio telescopes.But they may not be as rare as we think - they could be firing off as frequently as once a second over the entire observable universe.\n\"If we are right about such a high rate of FRBs happening at any given time, you can imagine the sky is filled with flashes like paparazzi taking photos of a celebrity,\" said lead researcher Anastasia Fialkov of the Harvard-Smithsonian Center for Astrophysics.\"Instead of the light we can see with our eyes, these flashes come in radio waves.\"Most fast radio burst sources are only detected once. They are extremely powerful radio bursts that last just milliseconds. They can't be predicted, and because they are so short and unrepeating, tracking them to their source or trying to figure out what causes them is all but impossible.However, there's one notable exception. FRB 121102, which was first detected in 2002. It has fired an incredible 34 bursts over the years, which has allowed researchers to pin down its location to a galaxy 3 billion light-years away.\nIn August this year, researchers from the University of California, Berkeley announced that they had detected a massive 15 FRBs in just five hours from FRB 121102.We still don't know what that means, but Fialkov and her co-researcher Avi Loeb wondered: What if FRB 121102 is not an outlier at all, but representative of all FRBs?According to their model, low-frequency telescopes could detect FRBs between 50MHz and 3.5GHz once a second per sky, especially accounting for future telescopes.The Australian Square Kilometre Array Pathfinder, for instance, was only switched on this year, and has already detected three of the mysterious signals operating at a quarter of its capacity.The Square Kilometre Array, being built across Australia, New Zealand and South Africa, will be much more powerful, and will also include a low-frequency aperture array that will be able to detect the very low frequency signals between 50 and 350MHz.\n\"In the time it takes you to drink a cup of coffee, hundreds of FRBs may have gone off somewhere in the Universe,\" Loeb said. \"If we can study even a fraction of those well enough, we should be able to unravel their origin.\"There are several theories as to what causes FRBs. Black holes or neutron stars, for instance. They could be pulsars, but pulsars are typically regular, as far as we know. Or they could be caused by magnetars, a type of neutron star with a very powerful magnetic field, known to emit giant flares.Some researchers have even hypothesised that they could be alien spaceships.Whatever they are, they could, the researchers say, help unveil clues as to the origin of the universe and the Epoch of Reonisation, wherein the interstellar medium, primarily hydrogen, became ionised in the very early universe. We still don't know how that happened, either.\"FRBs are like incredibly powerful flashlights that we think can penetrate this fog [of the interstellar medium] and be seen over vast distances,\" said Fialkov. \"This could allow us to study the 'dawn' of the universe in a new way.\"The research has been published in the peer-review journal The Astrophysical Journal Letters. and is available on Arxiv her"
        ]
    },
    "8409": {
        "gold_standard": [
            "New research into Neolithic stone circles on the Scottish islands of Orkney has revealed they were the party hotspots of the end of the Stone Age \u2013 places where people met to find partners, celebrate the summer and winter solstices, and pay tribute to the dead.\nThe study has also revealed how the area was a melting pot of different social groups and communities, a mix that eventually caused enough political tension for the groups to go their separate ways.Part of a broader investigation into Neolithic living called The Times of their Lives, led by Historic England, the new analysis examines more than 600 radiocarbon dates, giving researchers a clearer view of the timing and duration of events between 3200 BC and 2500 BC on the islands.\"This study shows that new statistical analysis of the large numbers of radiocarbon dates that are now available in British archaeology really changes what we can know about our pasts,\" lead researcher Alex Bayliss, from Historic England, told the BBC.\"People in the Neolithic made choices, just like us, about all sorts of things \u2013 where to live, how to bury their dead, how to farm, where and when to gather together \u2013 and those choices are just beginning to come into view through archaeology.\"The Standing Stones of Stenness. Credit: stevekeiretsu/FlickrA number of well-known sites were covered by the study, including the Standing Stones of Stenness circles, granted UNESCO World Heritage Status in 1999, and the Skara Brae settlement.\nThe research also looked at the Maeshowe passage grave, and the 104-metre (341-foot) diameter Ring of Brodgar, originally thought to feature up to 60 stones, of which 27 are still standing.The researchers have now managed to figure out that Orkney was probably first colonised in 3600 BC, with settlement peaking around 3100-2900 BC.And even after communities had settled elsewhere, they still returned to these sites for celebrations, Bayliss told Loulla-Mae Eleftheriou-Smith at The Independent.\"It's not a village \u2013 it's a gathering place,\" says Bayliss. \"Each stone in the Ring of Brodgar is from a different stone or area of the island, so it's almost like each village brought its own stone there.\"The relatively rapid changes in the stone monuments identified by the researchers seem to show a conflict of ideas about certain rituals, including how to bury the dead.\nThese tribes would appear to have been able to put aside their differences for the occasional bit of revelry though, at least for a while, and people might have settled here from as far away as Belgium.That's hinted at by the Orkney voles that don't live in Britain and can't have lived through the last ice age \u2013 it's possible that they were brought over from Belgium before 3000 BC.Whether or not it was the Orkney nightlife that tempted them over remains to be seen.\"Visitors come from all over the world to admire the wonderfully preserved archaeological remains of Orkney, in what may seem a timeless setting,\" senior researcher Alasdair Whittle, from Cardiff University in the UK, told the BBC.\"Our study underlines that the Neolithic past was often rapidly changing, and that what may appear to us to be enduring monuments were in fact part of a dynamic historical context.\"The research has been published in Antiquit"
        ]
    },
    "8436": {
        "gold_standard": [
            "Alcheringa So many new species aren't discovered straight out of the ground, but after having been under our noses for decades. Such is the case with Arminisaurus schuberti, a newly discovered 'sea monster' that swam the Jurassic oceans 190 million years ago.\nPoor Arminisaurus had a dreadful journey. The fossilised bones were originally discovered in a clay pit near Bielefeld in Germany, all the way back in the early 1980s. But before it was found, the intact and complete skeleton was broken up by mining machinery. Only 40 percent of the bones could be recovered.It spent some time languishing in disarray. It was only salvaged by the intervention of avid amateur palaeontologist Siegfried Schubert, who painstakingly and thoroughly cleaned the bones and sent them to the Naturkunde-Museum Bielefeld in 2015.The plesiosaur was named in honour of Schubert, and of the Germanic chieftain Arminius.\"Plesiosaurs were amongst the most successful marine predators from the Age of Dinosaurs,\" said researcher Sven Sachs.\"Some, such as the famous Liopleurodon, were colossal predators up to 15 metres (50 feet) long. They were the equivalent of white sharks and killer whales in the oceans today.\"Joschua Kn\u00fcppe/Uppsala UniversityArminius was just a little fellow, around 3-4 metres (10-13 feet), and probably hunted small prey such as fish and squid. However, an almost complete scapula bone shares a feature called the scapular shelf in common with plesiosaurs from the Cretaceous period that followed the Jurassic.\nThis discovery could help palaeontologists better understand the evolutionary radiation of plesiosaurs.\"Arminisaurus is significant because it dates from a timeframe early in the Jurassic, during which we have very few identifiable plesiosaur fossils,\" said researcher Benjamin Kear of the Museum of Evolution at Uppsala University.\"Only two other plesiosaur fossils have ever been named from this mysterious interval in plesiosaurian evolution, making Arminisaurus a very important new addition for the global record of the group.\"The research was published in marine paleontology journal Alchering"
        ]
    },
    "8444": {
        "gold_standard": [
            "How animals evolved on Earth is somewhat murky. We know that most major animal phyla we see today appeared during the Cambrian explosion 541 million years ago - but before that, the fossil record is patchy.\nBut that doesn't mean it's nonexistent. Before the Cambrian explosion, there lived a group of strange lifeforms known collectively as the Ediacaran biota. But exactly what those lifeforms were and how they fit in with the tree of life has long remained a mystery. Now, we might finally have some answers.A team of researchers from Cambridge, Oxford, Bristol, and the British Geological Survey\u00a0has confirmed that one of the strangest and most iconic of the Ediacaran biota, a creature known as\u00a0Dickinsonia,\u00a0was officially an animal.That suggests animals were around\u00a0before\u00a0the Cambrian explosion.\"'Dickinsonia\u00a0belongs to the Ediacaran biota - a collection of mostly soft-bodied organisms that lived in the global oceans between roughly 580 and 540 million years ago,\"\u00a0said lead researcher Renee Hoekzema of Oxford.\n\"They are mysterious because despite there being around 200 different species, very few of them resemble any living or extinct organism, and therefore what they were, and how they relate to modern organisms, has been a long-standing palaeontological mystery.\"The Ediacaran biota is so puzzling because there's nothing else like them.Initially, the Ediacaran biota were thought to be complex multicellular animals, or\u00a0metazoans, and a growing body of research is returning to that idea.But they're not easy to tie down, with algae, protozoans, lichens, and colonies of bacteria all being floated as possibilities at various times.But none of these explanations have ever fully fit, because of how strange the creatures were - particularly Dickinsonia, which looks strangely like a ribbed oval.\nDickinsonia was first described in 1947, at which time it was categorised as a jellyfish. It has also been thought to be a worm, a polyp, or even a mushroom.It has so few features in common with modern organisms that the approach to categorising has mostly been throwing ideas at the wall to see what sticks.This new classification of it as an animal is based on how the creature grows.\"We took the approach of looking at populations of this organism, including assumed juvenile and adult individuals, to assess how it grew and to try to work out how to classify it from a developmental perspective,\" said researcher Alex Liu from Cambridge.As you can see in the image above, Dickinsonia's body is divided into segments. The researchers counted and measured these segments, and plotted them against the age of the organism to create a computer model that could replicate how the creature grew as it age"
        ]
    },
    "8447": {
        "gold_standard": [
            "Do you ever have trouble telling right from left? For example you're taking a driving lesson and the instructor asks you to take a left turn and you pause, struggling to think of which way is left.\nIf so, you're not on your own \u2013 a significant proportion of our population has difficulty in telling right from left.Left-right discrimination is a complex neuro-psychological process involving several higher neurological functions such as the ability to integrate sensory and visual information, language function and memory.For some it is second nature but for others a considerable challenge. You can take a test here to see how well you do.One further problem facing the health profession is that when a doctor or nurse faces a patient, their right-side is on the patient's left-side.So correctly distinguishing right from left in a patient also involves the visuo-spatial function of mentally rotating images.Wrong turns to avoidable errorsIt's hardly the end of the world if you take the wrong direction on a journey, but there are many situations where confusing right from left can have devastating consequences.\nSome of the most tragic errors in medicine have been when surgery was performed on the wrong side of a patient: removing the wrong kidney or amputating the wrong leg.While there are systems, checks and balances in place to anticipate and minimise these kinds of mistakes, when they do occur, human error is often at the root of the cause.Error is an inherent characteristic of human behaviour \u2013 sometimes we just get things wrong \u2013 but left-right ones may be more than a one-off accident.Evidence would suggest that right-left confusion is more common in women. The literature would appear to suggest that men demonstrate a greater degree of visuo-spatial function.The 'distraction effect'Distinguishing right from left also never occurs in isolation. Hospitals and other health settings are busy and complex places to work in.\nDoctors are often subject to distractions while working; receiving telephone calls, cardiac monitors bleeping, taking questions from colleagues, patients and their relatives \u2013 the clinical environment can be very challenging.In research we published in Medical Education, we explored the impact of such interruptions on medical students' ability to correctly discriminate right from left.While objectively measuring 234 medical students' ability to distinguish right from left, we subjected them to the typical ambient noise of a ward environment and interrupted them with clinical questions.Our findings were startling. Even the background noise of a ward environment was enough to throw some medical students off when making right-left judgements.Asking them a series of questions while they were trying to distinguish right from left had an even greater impact. The \"distraction effect\" was greater for older and female students.\nAn individual's ability to self-determine how well they could distinguish right from left was also often imprecise. So many students thought they were good at distinguishing right from left when, objectively measured, they weren't.Counter techniquesThose who have difficulty in telling right from left often develop their own techniques \u2013 for example placing their left thumb at right angles to their index finger to make an \"L\" representation for their \"left\" side.It appears however that these techniques remain fallible and fail to combat this issue in all cases.In healthcare, training \u2013 starting at an undergraduate level \u2013 needs to make students mindful of the challenges of making right-left decisions and the impact that distractions can have on such critical decisions.We need to develop strategies to reduce such error-provoking situations and to raise student and teacher awareness of the fact that some individuals are more prone to right-left confusion",
            "Do you ever have trouble telling right from left? For example you're taking a driving lesson and the instructor asks you to take a left turn and you pause, struggling to think of which way is left.\nIf so, you're not on your own \u2013 a significant proportion of our population has difficulty in telling right from left.Left-right discrimination is a complex neuro-psychological process involving several higher neurological functions such as the ability to integrate sensory and visual information, language function and memory.For some it is second nature but for others a considerable challenge. You can take a test here to see how well you do.One further problem facing the health profession is that when a doctor or nurse faces a patient, their right-side is on the patient's left-side.So correctly distinguishing right from left in a patient also involves the visuo-spatial function of mentally rotating images.Wrong turns to avoidable errorsIt's hardly the end of the world if you take the wrong direction on a journey, but there are many situations where confusing right from left can have devastating consequences.\nSome of the most tragic errors in medicine have been when surgery was performed on the wrong side of a patient: removing the wrong kidney or amputating the wrong leg.While there are systems, checks and balances in place to anticipate and minimise these kinds of mistakes, when they do occur, human error is often at the root of the cause.Error is an inherent characteristic of human behaviour \u2013 sometimes we just get things wrong \u2013 but left-right ones may be more than a one-off accident.Evidence would suggest that right-left confusion is more common in women. The literature would appear to suggest that men demonstrate a greater degree of visuo-spatial function.The 'distraction effect'Distinguishing right from left also never occurs in isolation. Hospitals and other health settings are busy and complex places to work in.\nDoctors are often subject to distractions while working; receiving telephone calls, cardiac monitors bleeping, taking questions from colleagues, patients and their relatives \u2013 the clinical environment can be very challenging.In research we published in Medical Education, we explored the impact of such interruptions on medical students' ability to correctly discriminate right from left.While objectively measuring 234 medical students' ability to distinguish right from left, we subjected them to the typical ambient noise of a ward environment and interrupted them with clinical questions.Our findings were startling. Even the background noise of a ward environment was enough to throw some medical students off when making right-left judgements.Asking them a series of questions while they were trying to distinguish right from left had an even greater impact. The \"distraction effect\" was greater for older and female students"
        ]
    },
    "8508": {
        "gold_standard": [
            "(2017) Scientists have discovered a new type of 'hell ant' - a species with terrifying spiky mouthparts reinforced with metal and used for drinking the blood of its enemies.Thankfully, these insects have been extinct for a while, but a 98-million-year-old amber specimen has now revealed stunning detail of the prehistoric species, including a curious metal component in its jaws.\nThe newly described Linguamyrmex vladi belongs to a group known as 'hell ants' or haidomyrmecines, an extinct bunch that lived in the Cretaceous period and characterised by strange, vertically moving mouthparts.Hell ants aren't actually the ancestors of the tiny critters we see today, and instead belong to a stem-group which went extinct before the common ancestor of all modern ants appeared on the scene to start its lineage.And given how scary some of those hell ant features sound, we're almost grateful that the worst we have to deal with these days are \"just\" bullet ants and fire ants.Instead of plain old downward-facing mandibles, L. vladi sported giant blade-like scythes that pointed upward - a feature you won't find in any ant living today.For comparison, here are the mandibles of a typical modern ant:Chandan Kumar / Flickr / CC BY-NC-ND 2.0And here's a close-up of the jaws of this newly discovered hell ant:Barden et al., Syst Entomol (2017)It appears that these spiky jaws were surrounded by trigger hairs which are similar to those used by trap-jaw ants today - the same ones that help an ant's jaws to snap shut at a horrifying speed.\nThis ant also had a reinforced horn-like appendage or 'paddle' on top of its jaws, and it's possible it used that to clamp down on its prey once it thrusted the upward-facing mandibles into the prey's body.The researchers, led by Phillip Barden from New Jersey Institute of Technology, also discovered a tube-like channel between the mandibles, and think the ants probably sucked on their food rather than chewed it, since the weird jaws wouldn't really accommodate for chewing action.\"The mandibles and paddle of Linguamyrmex may have functioned to puncture soft-bodied prey and feed on the haemolymph,\" the team writes in the study.Helpfully, the specimen was found in its ambery grave next to a large larva of a beetle, which would have been perfect soft-bodied prey for a liquid-sucking predator such as this one.Barden et al., Syst Entomol (2017) / ScienceAlertThe diagram above shows the placement of the two specimens (the red circle shows the location of the paddle horn). The jaws of the ant weren't actually embedded in the larva, but the researchers note that its placement is \"consistent with this being prey.\"\nAnd if you haven't had enough of these gruesome details, here comes perhaps the weirdest part - an X-ray scan of the amber specimen revealed that the underside of that paddle horn on its head is reinforced with metal particles.Now, the bug didn't actually fashion a little war helmet for itself - instead, it appears to have had the awesome ability to collect trace metals from its diet into parts of the body that needed reinforcement.\"Insects are known to sequester metals \u2013 in particular, calcium, manganese, zinc, and iron \u2013 in ovipositors and mandibles, to increase strength and reduce wear,\" the team writes in the study.Having a metal-infused spike would have allowed the hell ant to withstand the wriggling of its prey if it missed a hit with its jaws, or perhaps made it easier to jam its spikes into the soft-bodied food, the researchers think.\n\"Until we find a specimen with the prey item trapped, which is probably a matter of time, we're left to speculate,\" Barden told Josh Gabbatiss at New Scientist.As the amber specimen came from a rich excavation area in Myanmar, it might just be a matter of time until we find more horror spike bugs\u2026 er, hell ants.The new species was described in Systematic Entomolog"
        ]
    },
    "8512": {
        "gold_standard": [
            "Just weeks after Hurricane Harvey caused destruction in Texas, Irma has made landfall in Florida - and there are still almost 12 weeks left of Atlantic hurricane season. It raises the question - where are all of these storms coming from?\nResearch has shown that most of the monster storms that hit the US and Canada start out as a distinct weather pattern in the atmosphere over western Africa, specifically a spot off the coast of the African Cape Verde\u00a0islands.In fact, a 2015 study published in Geophysical Research Letters\u00a0showed that by closely watching these tropical disturbances off the coast of western Africa, researchers could better predict which of them would turn into serious hurricanes a few weeks later.Google Maps\"85 percent of the most intense hurricanes affecting the US and Canada start off as disturbances in the atmosphere over western Africa,\" said lead researcher Colin Price from Tel Aviv University in Israel at the time.\n\"We found that the larger the area covered by the disturbances, the higher the chance they would develop into hurricanes only one to two weeks later.\"Interestingly, these hurricanes are directly linked to one of the driest places on Earth - the Sahara desert.The interaction between the hot dry air of the Sahara and the cooler, more humid air from the Gulf of Guinea to its South forms what's known as the African easterly jet, which blows from east to west across Africa.\u00a0Within this jet, atmospheric disturbances or bands of thunderstorm activity known as tropical waves can form. As they blow off the west coast of Africa past Cape Verde, the 2015 study showed that the amount of cloud coverage at that point can predict whether or not these tropical waves will become hurricanes a week or two later.\nHow does that happen? Tropical waves interact with the warm equatorial water of the Atlantic as they head west, triggering columns of warm moist air to rise from the ocean.That provides two of the three ingredients required for tropical storms to turn into full-blown hurricanes: moist air; Earth's rotation; and warm ocean temperatures. When the swirling winds reach speeds of 74 mph (119 km/h), the storm is classified as a Category 1 hurricane.Irma was first spotted as a tropical disturbance off the Cape Verde Islands in late August, before becoming a hurricane over the Atlantic as it made its way towards the Caribbean and US.According to Price, only 10 percent of the 60 disturbances originating in Africa every year turn into hurricanes - but the ones that do have the opportunity to gather energy as they cross the Atlantic, which makes them so powerful that they're more likely to hit the US and even Canada.\n\"Not all hurricanes tha"
        ]
    },
    "8520": {
        "gold_standard": [
            "Heroic Scandinavian women standing shoulder to shoulder with ranks of masculine warriors in Viking combat are the stuff of legends, but debate has raged over the years on whether it's also the stuff of reality.\nA new discovery has confirmed that in at least one specific case, remains found buried in a warrior's grave were genetically female, supporting the view that the mythical 'shield-maiden' female fighters might have its roots in actual historical events.Researchers from Uppsala University and Stockholm University conducted genetic and isotope analyses on bones taken from a 10th century grave near the Swedish Viking\u00a0town of Birka, just outside of Stockholm.The grave, coded Bj 581, consisted of no ordinary burial. Excavated and mapped well over a century ago, it was found to contain an axe, sword, spear, armour-piercing arrows, a battle knife, a pair of shields, pieces for a table-top war game, and the bones of a mare and a stallion.Illustration by Evald Hansen based on the original plan by excavator Hjalmar Stolpe (1889).Based on these goods, and the fact most such high ranking warriors of the period were considered to be men, the skeleton was readily assumed to belong to a male.\nBut the bones didn't seem all that masculine, and a full osteological inspection of Bj 581's skeleton suggested the esteemed official was in fact a woman of at least 30 years in age.The size and shapes of bones can provide a strong suggestion on the specific sex of a set of remains, but variation within sexes and between populations means it's not without its problems.DNA can provide a more solid grounding for a conclusion, when it can be successfully extracted.In this case, the researchers amplified DNA taken from one of the Birka warrior's teeth and arm bones and determined there was sufficient genetic data to conclude it was of only X chromosome origin, without any sign of DNA from a Y chromosome. \"This is the first formal and genetic confirmation of a female Viking warrior,\" says researcher Mattias Jakobsson from Uppsala University.\nAn evaluation of the isotopes in her bones showed she was well travelled, adding further evidence to her being a respected leader among her people.\"The gaming set indicates that she was an officer, someone who worked with tactics and strategy and could lead troops in battle,\" says lead researcher Charlotte Hedenstierna-Jonson from Stockholm University. Ancient Scandinavian legends, or sagas as they're often called, often contain depictions of female fighters.One of the more well known, The Saga of Herv\u00f6r and Heidrek from the 13th century, features a heroic female fighter who took on her father's quest to find a mythical sword named Tyrfing.Such powerful tales have resonated through the ages, influencing numerous writers and poets, the most renowned of which being Lord of the Rings author, JRR Tolkien.\nSeparating myth from historical accounts has required a lot of detective work, however. And even with this discovery, it's important not to get too worked up in the romance.\"What we have studied was not a Valkyrie from the sagas but a real life military leader, that happens to have been a woman,\" says Hedenstierna-Jonson, referring to mythical warrior spirits who oversee battles in ancient stories.A study published in 2011 based on osteology (the physiological study of bones) claimed women made up as much as half of the remains among Norse migrants, a report that sparked an enthusiastic, if somewhat overhyped interpretation that envisioned this Viking diaspora as armed raiders. \u00a0\u00a0\u00a0\u00a0Still, while one discovery can't tell us how common female combatants are, having DNA evidence confirming at least one instance of a prominent warrior-class woman is a sign that the stories weren't all fantasy.\"Written sources mention female warriors occasionally, but this is the first time that we've really found convincing archaeological evidence for their existence,\" says researcher Neil Price from Uppsala University.\u00a0This research was published in the American Journal of Physical Anthropolog"
        ]
    },
    "8524": {
        "gold_standard": [
            "Pluto's geography now has officially approved names, so if you get lost on the way to the ice plains, you'll be able to ask for accurate directions.Actually, the naming of planetary features is very serious business. Only the International Astronomical Union's Working Group for Planetary System Nomenclature has the authority to approve them, and they usually follow certain conventions.\nNames take a bit of time to formalise, which is why we have the first official 14 names two years after probe New Horizons flew by Pluto in July 2015. It's not a contentious process, though - some are the names the New Horizons team has been using since the beginning, others are suggestions made by members of the public.\"We're very excited to approve names recognising people of significance to Pluto and the pursuit of exploration as well as the mythology of the underworld. These names highlight the importance of pushing to the frontiers of discovery,\" said the IAU's Rita Schulz.\"We appreciate the contribution of the general public in the form of their naming suggestions and the New Horizons team for proposing these names to us.\"Naming these features will allow researchers in the future to accurately pinpoint and describe locations, but they also help honour the contributions of scientists and other Pluto pioneers.\nClyde Tombaugh, the astronomer who discovered the dwarf planet, and Venetia Burney, the 11-year-old girl who proposed the name Pluto, have both been honoured.\"The approved designations honour many people and space missions who paved the way for the historic exploration of Pluto and the Kuiper Belt, the most distant worlds ever explored,\" said New Horizons principal investigator Alan Stern.More features will be named on Pluto and its moons in the future, and life isn't over for New Horizons, either, which is expected to make a flyby of Kuiper Belt object 2014 MU69 in January 2019.International Astronomical UnionHere's the full list of names,\u00a0according to the IAU website:\nTombaugh Regio honours Clyde Tombaugh (1906\u20131997), the U.S. astronomer who discovered Pluto in 1930 from Lowell Observatory in Arizona.\nBurney crater honours Venetia Burney (1918\u20132009), who as an 11-year-old schoolgirl suggested the name \"Pluto\" for Clyde Tombaugh's newly discovered planet. Later in life she taught mathematics and economics.\nSputnik Planitia is a large plain named after Sputnik 1, the first space satellite, launched by the Soviet Union in 1957.\nTenzing Montes and Hillary Montes are mountain ranges honouring Tenzing Norgay (1914\u20131986) and Sir Edmund Hillary (1919\u20132008), the Indian/Nepali Sherpa and New Zealand mountaineer who were the first to reach the summit of Mount Everest and return safely.\nAl-Idrisi Montes honours Ash-Sharif al-Idrisi (1100\u20131165/66), a noted Arab mapmaker and geographer whose landmark work of medieval geography is sometimes translated as \"The Pleasure of Him Who Longs to Cross the Horizons.\"\nDjanggawul Fossae defines a network of long, narrow depressions named for the Djanggawuls, three ancestral beings in indigenous Australian mythology who travelled between the island of the dead and Australia, creating the landscape and filling it with vegetatio"
        ]
    },
    "8528": {
        "gold_standard": [
            "Atheists are much fairer to Christians than Christians are to atheists, according to a new study that has analysed interactions between the two groups.But if you're an atheist, don't get too excited about your moral superiority yet. The study suggests that atheists are nicer in an attempt to compensate for the stereotype that atheists are immoral.\nResearchers at Ohio University were seeking to study in-group bias and prosocial behaviour, or the tendency groups have to favour their own members.\"We often see that negative stereotypes about a group can lead members of that group to behave in compensatory ways that ostensibly seek to disconfirm that stereotype, such as when American immigrants strive to emphasise their American identity when it is threatened,\" researcher Colleen Cowgill told Psypost.\"This was the rationale behind my hypotheses stating that atheists' behaviour toward Christians in economic games might be different from Christians' behaviour toward atheists in economic games.\"The study was divided into three parts. The first part was conducted using 297 subjects, 150 Christians and 147 atheists. These participants were tasked to play a game based on the Dictator Game, in which one player gives the other player an amount of money.\nIt was designed to test how self-interested people are, with the general prediction that very few people will choose to give their partner money when there are no consequences involved.The researchers modified the game, however, so that participants were led to believe that several rounds of the game would be played, and that the other player would give them a reputation score that other people could see.They were told that the other person knew that they were Christian or atheist. They were then told whether they were paired with a fictional Christian or atheist. Each of them was then told they had the task of dividing up the money they had been given.The second part of the study, involving 233 different participants, 151 Christians and 82 atheists, was almost exactly the same, except for some key differences. The second group didn't know that they weren't partnered with real people, and they had to complete a survey afterwards that evaluated the morality of their partner.\nWhat these parts both found was that Christians gave more money to Christians than they gave to atheists, but that atheists gave the same amount to everyone, regardless of religious status.However, the third part of the study, involving 524 participants, 140 atheists and 384 Christians, showed that this discrepancy isn't purely motivated by altruism. These participants were divided into two groups. The first was told that the other person would not be informed of their religious status. The second was told that they would.When atheists thought that Christians would not know of their atheism, they showed as much in-group bias as Christians did, giving more money to fellow atheists than Christians.\"Our results show that atheists are uniquely concerned about outgroup members seeing them as immoral by virtue of their lack of religiosity, and that these concerns are at least partially responsible for atheists' behaviour toward their Christian partners in economic games,\" the researchers wrote in the study.\nInterplay between the two groups is of ongoing interest to the research team. Researchers Ain Simpson and Kimberly Rios published a study last year that found that they don't understand each other - and that atheists speak more negatively about Christians than the other way round.\"I think it is quite telling that atheists are perhaps so acutely aware of negative stereotypes about themselves that there are observable differences in their behaviour as compared with Christians in even this small, low-stakes type of interaction,\" Cowgill said.\"Research like this in the aggregate begins to build a case that there may be these kinds of hidden costs to the prevalent, unchallenged negative stereotyping in our society.\"The team's paper has been published in the Journal of Experimental Social Psycholog"
        ]
    },
    "8545": {
        "gold_standard": [
            "Researchers have uncovered what they say is a new class of ultra-low-density ice, which crystallises amid extreme negative pressure on water molecules.While many of us are only familiar with the kind of frozen water that keeps our drinks nice and chilled, regular ice on Earth is just one of around 20 known phases of ice \u2013 and the new forms discovered by researchers in Japan appear to have the lowest density of all known ice crystals.\nThe new ice is called aeroice, and its discovery by researchers at Okayama University is part of an emerging wave of research into how water freezes.A lot of previous studies have seen huge amounts of pressure applied to water molecules to create kinds of ultra-dense ice that don't naturally occur on Earth under ordinary atmospheric conditions, but here the team was focussed on the opposite cause and effect \u2013 the absence of pressure to make ice that isn't dense.\"Our research, which surveys an entire negative-pressure region for the first time, provides a significant stepping stone in exploring this vast and intricate territory on the phase diagram,\" says lead researcher Masakazu Matsumoto.As it stands, there are 17 recognised solid crystalline phases of water that can form all different kinds of ice. Of these, only two occur naturally on Earth, hexagonal ice and cubic ice.\nIt's the former, known as Ice Ih, that makes up almost all the ice on our planet, but another type called Ice Ic can form in Earth's upper atmosphere.All the other kinds of ice phases are what happens when water molecules are frozen in extreme conditions \u2013 often involving severe variations in pressure to replicate how ice might form in exotic or far-flung environments, such as when icy planetary bodies collide in space.Anyway, of the 17 known ice phases \u2013 which are named in order of their discovery \u2013 only two have lower density than normal ice. These are the latest additions to the lineup, called Ice XVI and Ice XVII.Ice XVI was discovered in 2014 by researchers who found ice could form in a kind of 3D crystalline cage called a zeolite structure.In the right conditions, this frozen cage could take shape around a guest molecule \u2013 in this case, neon atoms \u2013 which could then be extracted from the structure, resulting in what became the lowest density phase of ice yet discovered.Masakazu MatsumotoAbove, you can see an example of zeolitic ice on the left, with the molecular structure of one of the types of aeroice on the right.\nNot to be outdone by Ice XVI, simulations by another team of researchers surpassed the milestone in 2016 with Ice XVII, using a similar molecule trapping-and-extracting technique, that theoretically results in ice with 25 percent less density than Ice XVI.The new discovery by Matsumoto's team, aeroice, again stems from molecular rearrangements conducted at negative pressure, but this time involving silica (aka silicon dioxide, SiO2).In simulations, the team removed the two oxygen atoms from SiO2 molecular structure and then swapped out each molecule's single silicon atom for a single oxygen atom, before adding hydrogen atoms.The end result produces a kind of ice with a density about half that of liquid water (~0.5 g/cm3), but despite that extreme low-density, the researchers say aeroices are more stable than any other kinds of zeolite ice that have been engineered to date.\nAdditional simulations suggest aeroices could become even less dense \u2013 between 0 and 0.5 grams per cubic centimetre \u2013 with additional tampering.By adding polyhedral building blocks (structures with six planes or more), the molecules could maintain their crystalline stability while making the overall structure sparser, which would lower the density \u2013 meaning any number of aeroices could ultimately be possible.\"Ices with lower density than normal ice are also found to be manifold,\" says Matsumoto.\"These new structures are the aeroices, and they can be more stable than any zeolitic ice at certain thermodynamic conditions under negative pressure.\"While the findings may be largely of academic interest right now, the potential applications of discoveries like this are huge, ranging from understanding how water behaves in nanotubes and nanopores, to discovering how ice might behave for off-world colonists exploring the far reaches of the Solar System.That's a lot to think about, sure, and it'd probably go down better with a cool beverage in your hand.The findings are reported in The Journal of Chemical Physics"
        ]
    },
    "8567": {
        "gold_standard": [
            "The most poisonous animal in the world is difficult to quantify, but one of the most deadly is, without question, the golden poison frog (Phyllobates terribilis), native to Colombia. But how does it avoid killing itself with its toxins?\nThey look adorable, but within their skin glands, they store an alkaloid toxin called batrachotoxin. Enough of it, on average, to kill 10 human beings \u2014 if the poison enters your bloodstream, you'll likely be dead in under 10 minutes.There's only one known species that is resistant to it (a snake), and there is no known antidote.The frogs don't create the toxin themselves. When removed from their natural environment and bred in captivity, they are completely harmless, which has led to the accepted theory that, like poisonous puffer fish, the frogs synthesise the toxin from their diet.So why don't they die of it themselves? To figure it out, researchers from the State University of New York\u00a0(SUNY) turned to rats.Batrachotoxin works by irreversibly opening the sodium channels of nerve cells, which permanently blocks the transmission of nerve signals to the muscles, while preventing the muscles from being able to relax. The heart is particularly susceptible, and the end result is cardiac failure.\nPuffer fish tetrodotoxin also works on the sodium channel, although the mechanism is slightly different. But they have a single amino acid mutation that modifies their sodium channels so that they are immune to their own poison.The researchers, Sho-Ya Wang and Ging Kuo Wang, looked to amino acids for the frogs' immunity.Using rat muscle, they tested five naturally occurring amino acid substitutions that had been found within P. terribilis muscle. When all five of the rat amino acids were replaced with the frog mutations, the rat muscle was completely resistant to batrachotoxin.The next step was to try the substitutions one by one. All but one still showed a high sensitivity to the toxin. The one substitution that remained resistant is called N1584T. For this mutation, the amino acid asparagine is replaced with the amino acid threonine.\nPrevious research conducted by a Harvard team suggested there were multiple origins for the frogs' resistance to their own toxin, but the SUNY team's research suggests that, like the puffer fish, the frogs' resistance comes mainly from a single genetic mutation.\u00a0This doesn't mean we'll be able to find an antidote, though. There is still no known antidote for puffer fish toxin. The purpose of the study was to find the mutation that makes the endangered frogs immune to their own toxin.\u00a0\"Our results strongly support the conclusion that batrachotoxin autoresistance in P. terribilis\u00a0muscle sodium channels is primarily due to an equivalent rNav1.4- N1584T substitution, which eliminates nearly all batrachotoxin actions,\" the study's conclusion reads.\"Whether a reverse mutant remains partially batrachotoxin-resistant as predicted by stepwise increases of toxin autoresistance in poison frogs during evolution merits additional studies.\"The research has been published in the journal PNAS",
            "The most poisonous animal in the world is difficult to quantify, but one of the most deadly is, without question, the golden poison frog (Phyllobates terribilis), native to Colombia. But how does it avoid killing itself with its toxins?\nThey look adorable, but within their skin glands, they store an alkaloid toxin called batrachotoxin. Enough of it, on average, to kill 10 human beings \u2014 if the poison enters your bloodstream, you'll likely be dead in under 10 minutes.There's only one known species that is resistant to it (a snake), and there is no known antidote.The frogs don't create the toxin themselves. When removed from their natural environment and bred in captivity, they are completely harmless, which has led to the accepted theory that, like poisonous puffer fish, the frogs synthesise the toxin from their diet.So why don't they die of it themselves? To figure it out, researchers from the State University of New York\u00a0(SUNY) turned to rats.Batrachotoxin works by irreversibly opening the sodium channels of nerve cells, which permanently blocks the transmission of nerve signals to the muscles, while preventing the muscles from being able to relax. The heart is particularly susceptible, and the end result is cardiac failure.\nPuffer fish tetrodotoxin also works on the sodium channel, although the mechanism is slightly different. But they have a single amino acid mutation that modifies their sodium channels so that they are immune to their own poison.The researchers, Sho-Ya Wang and Ging Kuo Wang, looked to amino acids for the frogs' immunity.Using rat muscle, they tested five naturally occurring amino acid substitutions that had been found within P. terribilis muscle. When all five of the rat amino acids were replaced with the frog mutations, the rat muscle was completely resistant to batrachotoxin.The next step was to try the substitutions one by one. All but one still showed a high sensitivity to the toxin. The one substitution that remained resistant is called N1584T. For this mutation, the amino acid asparagine is replaced with the amino acid threonin"
        ]
    },
    "8584": {
        "gold_standard": [
            "Environmental Science & Technology Our increased use of antidepressants is having a knock-on effect on nature: scientists have found evidence of these drugs in the brain tissue of 10 different species of fish in the Great Lakes region.\nNot only does it threaten the biodiversity of the lakes, the researchers say, it can also cause harmful changes to the behaviour of the fish.The international team of researchers says there's no danger to humans from eating these fish, but that more needs to be done to get these antidepressant chemicals out of our wastewater before they have a chance to damage marine life beyond repair.\"These active ingredients from antidepressants, which are coming out from wastewater treatment plants, are accumulating in fish brains,\" says lead researcher Diana Aga from the University of Buffalo. \"It is a threat to biodiversity, and we should be very concerned.\"\"These drugs could affect fish behaviour. We didn't look at behaviour in our study, but other research teams have shown that antidepressants can affect the feeding behaviour of fish or their survival instincts.\"\nThat previous research suggests, for example, that some fish become less aware of predators when hit with antidepressant chemicals, although the reaction to the drugs varies between species.The team looked at ten different species of fish in the Niagara River, a crucial channel connecting Lake Erie to Lake Ontario.In all of the species \u2013 smallmouth bass, largemouth bass, rudd, rock bass, white bass, white perch, walleye, bowfin, steelhead, and yellow perch \u2013 they found evidence of antidepressants.The highest concentration of drugs was found in a rock bass: 400 nanograms of norsertraline per gram of brain tissue. Norsertraline is produced in the body by sertraline, the active ingredient in Zoloft.These chemical levels aren't as high as the ones artificially generated in marine species for related research, but they're still very worrying for scientists.\nWhat's more, the concentrations of drugs in the brains of the fish were significantly higher than the concentrations in the river water, suggesting the fish are picking up more and more of the chemicals over time.For the researchers, it's important that wastewater plants do more to filter out chemicals like those from antidepressants, which appear in the urine of the people taking them.These plants generally concentrate on killing bacteria and removing solids and faeces, but need to address drugs that are often being ignored, says the team behind the study.\"These plants are focused on removing nitrogen, phosphorus, and dissolved organic carbon but there are so many other chemicals that are not prioritised that impact our environment,\" says Aga.\"As a result, wildlife is exposed to all of these chemicals. Fish are receiving this cocktail of drugs 24 hours a day, and we are now finding these drugs in their brains.\"\nAs for exactly how these chemicals might damage fish or change their behaviour, or what the knock-on effect might be to the broader ecosystem, scientists just don't have enough information to go off yet \u2013 but their concerns are very real.With antidepressant use rising steadily in the US and other countries, the problem needs to be addressed before more damage is done. Let's hope people can get the help they need and our rivers and lakes can be kept free of the chemical fall-out.\"The risk that the drugs pose to biodiversity is real, and scientists are just beginning to understand what the consequences might be,\" says one of the team, Randolph Singh from the University of Buffalo.The research has been published in Environmental Science & Technolog"
        ]
    },
    "8655": {
        "gold_standard": [
            "facilitate creative problem solving Unable to stay focused? Frequently going away with the fairies? It may be because you have so much brain capacity that it needs to find ways to keep itself occupied, according to new research.\nA team of psychologists has found a positive correlation between a person's tendency to daydream and their levels of intelligence and creativity.\"People tend to think of mind wandering as something that is bad. You try to pay attention and you can't,\" said one of the team, Eric Schumacher\u00a0from Georgia Institute of Technology.\"Our data are consistent with the idea that this isn't always true. Some people have more efficient brains.\"The researchers examined the brain patterns of 112 study participants as they lay in an fMRI machine not doing anything in particular and just staring at a fixed point for five minutes.This is known as a resting state scan, and the team used this data to figure out which parts of the participants' brains worked together in unison in what's called the default mode network.\nThese participants also completed a questionnaire about daydreaming, and, once the researchers figured out how their brains worked, tests of executive function, fluid intelligence and creativity.There were several correlations. Those participants who self-reported higher rates of daydreaming had a higher rate of default mode network connectivity in the brain, as well as a higher rate of control between the default mode network and the frontoparietal control network of the brain.Those participants also performed better on the fluid intelligence and creativity tests than the participants who weren't daydreamers.The perils of daydreaming have been well documented. Previous research has found that a wandering mind can have a detrimental effect on tasks such as reading comprehension and academic tests, and it can reduce the brain's cortical analysis of external events",
            "cortical analysis of external events Unable to stay focused? Frequently going away with the fairies? It may be because you have so much brain capacity that it needs to find ways to keep itself occupied, according to new research.\nA team of psychologists has found a positive correlation between a person's tendency to daydream and their levels of intelligence and creativity.\"People tend to think of mind wandering as something that is bad. You try to pay attention and you can't,\" said one of the team, Eric Schumacher\u00a0from Georgia Institute of Technology.\"Our data are consistent with the idea that this isn't always true. Some people have more efficient brains.\"The researchers examined the brain patterns of 112 study participants as they lay in an fMRI machine not doing anything in particular and just staring at a fixed point for five minutes.This is known as a resting state scan, and the team used this data to figure out which parts of the participants' brains worked together in unison in what's called the default mode network.\nThese participants also completed a questionnaire about daydreaming, and, once the researchers figured out how their brains worked, tests of executive function, fluid intelligence and creativity.There were several correlations. Those participants who self-reported higher rates of daydreaming had a higher rate of default mode network connectivity in the brain, as well as a higher rate of control between the default mode network and the frontoparietal control network of the brain.Those participants also performed better on the fluid intelligence and creativity tests than the participants who weren't daydreamers.The perils of daydreaming have been well documented. Previous research has found that a wandering mind can have a detrimental effect on tasks such as reading comprehension and academic tests, and it can reduce the brain's cortical analysis of external event"
        ]
    },
    "8687": {
        "gold_standard": [
            "Some people see happiness as the feeling in a small moment - a chat between old friends, a warm meal. Some see it as deeply profound, a kind of enlightenment.Scientists tend to view it another way, namely, as an ongoing state of being that ebbs and flows - but can be controlled based on how people live their lives.\nSome of the biggest findings about the science of happiness contradict many people's understandings of how to find joy.Here are just a handful of those misconceptions.1. More money does increase happiness - but only to a point.A higher salary is always nice, but it won't necessarily increase your happiness, a wide body of research suggests. Some early behavioural economics studies found that a salary of roughly US$75,000 a year was the point at which happiness began to plateau.Follow-up research has found similar plateaus based on the cost-of-living in your particular area. Someone in Atlanta, for example, will hit peak happiness by making roughly US$42,000 a year, while a New Yorker will need to pull in US$105,000.2. Happiness comes from giving gifts, not receiving them.Unwrapping presents on a holiday or birthday is undeniably fun, but science suggests the person who bought and wrapped those gifts is gaining more happiness than you are.Robert F. Bukaty/APA 2008 study found that people's reported levels of happiness jumped when they spent money on others instead of on themselves. A follow-up study in 2013 showed that the finding applied to people in 136 countries, not just those in North America.\nAnd earlier this year, a study showed a neural link between generosity and happiness, further cementing humans as fundamentally social animals.3. Having too much freedom of choice can reduce happiness.It's better to have some choice instead of no choice, psychologist Barry Schwartz has said. But it doesn't hold that more choice is always better.If humans are presented with too many options, their decision-making abilities kind of shut down, Schwartz's research has found. Some neuroscience research has also shown that making choices is exhausting and can hurt cognitive abilities in other areas.These findings have led Northwestern University neuroscientist Moran Cerf to adopt a surprising habit: He always picks the second menu item on a list of specials to free up his brain for more important choices in the day.\n4. Longer vacations aren't always worth it.The psychologist Daniel Kahneman has written that human beings are actually composed of two distinct selves: the experiencing self and the remembering self. The experiencing self lives in the moment, while the remembering self savours life in hindsight.Vacations are the ultimate ticket to happiness for many people, but Kahneman suggests that from the point of view of the remembering self, two-week vacations aren't twice as good as one-week trips.Unless you spend each day differently, the memories will all mix together and you won't be any happier for it.5. No one should try to be happy all the time.A big misconception about happiness is that it's something to attain, and keep, forever. Science encourages people to reject that mindset and instead view happiness as multi-faceted.\nIt's possible to have multiple kinds of happiness that contradict each other, such as when you need to turn down dinner invitations because you've committed yourself to working on a new book, or some other long-term goal.In order to maximise happiness, humans seem to need to know what the bad moments look like - suffering is something to practice, scientists have found.6. Grudges really do prevent people from being happy.Confronting negative emotions is difficult, and something a lot of people want to avoid. But a wealth of research has discovered that forgiving others (and oneself) for past misdeeds can go a long way to reducing long-term stress and improving psychological well-being.A 2015 study also found that letting go of a grudge can lead to improved physical ability. Participants who reflected on a time they forgave someone then jumped into the air reached greater heights than the people who reflected on a time they kept a grudge before jumping.This article was originally published by Business Inside"
        ]
    },
    "8705": {
        "gold_standard": [
            "Journal of Psychopharmacology Take a quick tipple and you could find yourself speaking a second tongue more naturally, according to new research.The foreign language skills of participants in the study were found to be improved after a drink of alcohol, which suggests the way booze can put us at ease outweighs the negative effects on our brain \u2013 at least for the first drink, anyway.\nThe international team of researchers is warning against reading too much into their experiment, but it could reveal some interesting insights into the anxiety associated with speaking another language, and how alcohol can help us overcome it.\"Our study shows that acute alcohol consumption may have beneficial effects on the pronunciation of a foreign language in people who recently learned that language,\" says one of the team, Inge Kersbergen from the University of Liverpool in the UK.The study involved 50 native German speakers studying Dutch at a Dutch university, who had recently learned to speak, read, and write in the new language.Based on random selections, participants were either given alcohol or water as a control beverage. The amount of alcohol varied based on body size, but was the equivalent of just under a pint (460 millilitres) of 5 percent beer for a 70 kg (154 lb) male.\nThey then chatted to a researcher for five minutes, before an audio recording was assessed by two native Dutch speakers who weren't told whether alcohol had been consumed or not. The participants were also asked to rate their own Dutch language skills over the course of the chat.While the alcohol didn't affect how the students rated themselves, those people who had been given the alcoholic drink were given better ratings by the observers, especially for their pronunciation.So what's going on? We know that alcohol has a detrimental effect on our brain's executive functioning, including our memory, our attention, and our inhibitions. A lot of these functions are important for speaking a non-native language.At the same time, we know that booze also improves confidence and reduces social anxiety, which is also helpful when you're trying to talk in another tongue, especially if you've only just learned it.\n\"One possible mechanism could be the anxiety-reducing effect of alcohol,\" says one of the researchers, Jessica Werthmann from Maastricht University in the Netherlands. \"But more research is needed to test this.\"With only 50 people involved in the research, we should be wary of making too many generalisations on this study alone, but it's an interesting pointer towards how a little bit of drink could grease the wheels as far as talking in a foreign language is concerned.As pronunciation was particularly highlighted as being improved, perhaps a limited amount of booze encourages us to really go for those unfamiliar sounds and mouth movements and not hold back.\"It is important to point out that participants in this study consumed a low dose of alcohol,\" adds one of the team, Fritz Renner from Maastricht University. \"Higher levels of alcohol consumption might not have beneficial effects on the pronunciation of a foreign language.\"In other words, this effect probably doesn't get better if you just keep on drinking \u2013 eventually no one will be able to understand you at all.The research has been published in the Journal of Psychopharmacolog"
        ]
    },
    "8710": {
        "gold_standard": [
            "A new type of archaeological site has been discovered in the desert lava fields of western Saudi Arabia. Nearly 400 structures dating back thousands of years have been found, with many clustered in Harrat Khaybar.\nAnd it's partially thanks to the introduction and growing accessibility of aerial mapping technologies, which allow researchers to view areas they can't easily reach by land, or don't know are significant.The monuments have been called \"gates\", and are described in an upcoming paper by David Kennedy of the University of Western Australia, who in 1978 founded the Aerial Photographic Archive for Archaeology in the Middle East.They're not gates at all - they are so named because they look a bit like old-fashioned field gates from the air - two upright posts, with bars between them, as seen in the image below.D. Kennedy, Arabian Archaeology and EpigraphyThey were initially discovered by citizen science.\n\"This novel site type was first brought to a wider audience by a group of Saudi nationals - all non-archaeologists - who have been engaged in exploring the cultural heritage of their country,\" Kennedy wrote in his paper.\"In particular, Dr Al-Sa'eed, a medical doctor who, together with other members of what they have called the Desert Team, used Google Earth to examine parts of the landscape, visit some of the sites, and illustrate them on a website.\"In spite of the name, the structures are not gates. They are low, with rough-built walls, the majority measuring between 50 and 150 metres (164 to 492 feet), but of the 389 total gates found, 36 are over 200 metres (656 feet) and the longest one measures 518 metres (1,699 feet) in length.What they are and why they were built is yet unknown, but their presence suggests that the lava fields used to be much more habitable.\n\"The lava fields are often rich in archaeological remains, implying a moister past and more abundant vegetation, and recent fieldwork identifying larger settlement sites supports this notion,\" Kennedy wrote in the paper.\"As in the much better explored lava field of Jordan there are many thousands of stone-built structures which are collectively known to Bedouin as the 'works of the old men'.\"The gates aren't the only structures at the sites. Interspersed with and sometimes even overlapping the gates are what researchers estimate to be tens of thousands of stone cairns, sometimes ringed with a small stone wall so that they resemble a bullseye from the air.D. Kennedy, Arabian Archaeology and EpigrahyThere are also structures known as \"kites,\" seen in the image above intersecting with a gate, common across the desert fields of the Middle East, the function of which is unknown but which are thought to have perhaps been used to trap game.\nCairns are often burial monuments, but it's unlikely that these would be built intersecting with another structure, the paper notes. Fieldwork would be required to determine if there are human remains within these cairns - and that, in turn, might yield clues as to the purpose of the gates.A field team may also use optically stimulated luminescence to examine the monuments. This technique can determine the last time quartz crystal was exposed to light, thus providing an accurate construction date.Kennedy has another paper currently in press on a few other little-known or unknown site types in Saudi Arabia, found using aerial mapping and photography. Drones are also proving to be a powerful archaeology tool - in 2016, archaeologists found a massive monument in Petra using a drone to fly where they couldn't reach.\"The availability of high-resolution satellite imagery of Saudi Arabia on publicly available platforms such as Google Earth and Bing Maps has been transformational for archaeology,\" Kennedy wrote in the paper.\"Within just a few years tens of thousands of sites previously unrecorded and scarcely known to the academic world have been mapped.\"The paper has been accepted for publication in the journal Arabian Archaeology and Epigraphy"
        ]
    },
    "8713": {
        "gold_standard": [
            "Journal of Geophysical Research: Solid Earth The Lusi eruption has been steadily spewing out mud across the Indonesian Island of Java since May 2006 \u2013 and scientists think they've finally worked out what's behind it.\nNew research mapping the ground underneath Lusi has showed it's connected to magma chambers linked to a nearby volcanic system, baking the sediments under the eruption site and continuing to spurt mud, water, and rocks out into the air.Not only does it give us an answer to why Lusi has become the biggest mud eruption in recorded history, the research could also tell us more about how volcanoes evolve, says the international team of geoscientists.\"We clearly show the evidence that the two systems are connected at depth,\" says one of the researchers, Adriano Mazzini from the University of Oslo in Norway.\"What our new study shows is that the whole system was already existing there \u2013 everything was charged and ready to be triggered.\"Credit: Adriano Mazzini/The Lusi Lab ProjectPrevious research had found gases linked to magma in the Lusi eruptions, but before now no one had definitely proved a link to the Arjuno-Welirang volcanic complex.\nUsing seismometers to create a 3D map of the ground below Java, the team found a tunnel and a series of vents up to 6 kilometres (3.7 miles) underground, connecting a magma chamber in Arjuno-Welirang to the sedimentary basin directly underneath Lusi.That's enough to pump scorching magma and other hydrothermal fluids into the Lusi site, triggering explosive reactions caused by a high-pressure build-up of gas.\"It's just a matter of reactivating or opening these faults and whatever overpressure you have gathered in the subsurface will inevitably want to escape and come to the surface, and you have a manifestation on the surface, and that is Lusi,\" says Mazzini.A village buried by mud. Credit: Adriano Mazzini/The Lusi Lab ProjectAnd what an eruption. At its peak in September 2006, Lusi was churning out enough mud to fill 72 Olympic-sized swimming pools every single day \u2013 up to 180,000 cubic metres (6.4 million cubic feet).\nMuch of the mud has now hardened, but the eruption has covered an area twice the size of New York's Central Park, with nearly 60,000 Indonesians forced out of their homes to escape the tides of mud reaching as high as 40 metres (131 feet).Even in 2017 the site continues to cough up enough mud and other material to fill 32 Olympic-sized swimming pools every day, still nearly half of its peak output.As well as explaining continued activity at Lusi, the discovery could shed light on how other volcanic systems evolve underground, and even shift their location as underground pressures build up and get released.Unfortunately for the people of Java, it's unlikely that the flow of mud is going to stop anytime soon: the volcanic chambers are going to keep the site cooking for several years to come.\n\"So what it means to me is that Lusi's not going to stop anytime soon,\" says Stephen Miller, from the University of Neuch\u00e2tel in Switzerland, who wasn't involved in the study.The research has been published in the Journal of Geophysical Research: Solid Eart"
        ]
    },
    "8726": {
        "gold_standard": [
            "Waves rippling across a lake can also cause faint rumblings in Earth itself, according to scientists, giving us clues about the condition of a lake and its surrounding geology through the readings of a seismometer.\nFor instance, scientists could be able to tell whether a lake was frozen over without direct observations, just from the seismic readings in the surrounding area.These seismic shudders wouldn't be strong enough to feel if you were standing there on the ground. But with the right instruments they could allow us to map climate change and take other readings across wide areas, suggest the researchers from the University of Utah and Yunnan University in China.\"It's kind of a new phenomenon,\" says one of the researchers, Keith Koper from the University of Utah. \"We don't really know how it's created.\"Small bursts of seismic activity, called microseisms, are already known to form from ocean waves draggin the sea floor \u2013 they're part of the background seismic noise observed in coastal locations.\nStudying waves from lakes in this way is a newer idea, and the researchers used data from earlier studies alongside new readings from Yellowstone Lake in Wyoming as well as Dianchi Lake, Fuxian Lake, and Erhai Lake in China.\"The lakes span more than two orders of magnitude in size (areas from 210 km2 to 27,000 km2) and sample a range of climatic and tectonic regimes in Canada, the US, and China,\" the researchers write in their study.What they found was that by averaging seismic activity over longer periods, like six months or so, it's possible to create what the scientists call a \"CT scan of the Earth\".These small seismic waves travel through different geological materials at different speeds, enabling scientists to work out the composition of the ground around a lake \u2013 and without the need for an artificial shock like an explosion or vibrating plates.\n\"It would take quite a bit of effort and work to generate this level of energy [artificially],\" says Koper.The study found that these lake microseisms could act as accurate predictors of how an earthquake might affect an area, as well as picking up on whether or not a lake was frozen over, which affects the speed of the ripples.Rather than satellite readings or field trips, scientists could use autonomous seismometers to check the changes in seasonal temperatures around a lake. When the known freezing and thawing times for Yellowstone Lake were compared to interpretations of the seismic data, everything matched up.For remote lakes high above sea level, which are useful indicators of our changing climate, that sort of automatic monitoring could prove very helpful.The next step in the research is to understand exactly how ripples on a lake lead to ripples underground, and to do that more data and more instruments are going to be required.\"If we can record at the same time on land and underwater, we can get a better idea of how these things are generated,\" says Koper.The findings have been published in the Journal of Geophysical Research Solid Earth",
            "Waves rippling across a lake can also cause faint rumblings in Earth itself, according to scientists, giving us clues about the condition of a lake and its surrounding geology through the readings of a seismometer.\nFor instance, scientists could be able to tell whether a lake was frozen over without direct observations, just from the seismic readings in the surrounding area.These seismic shudders wouldn't be strong enough to feel if you were standing there on the ground. But with the right instruments they could allow us to map climate change and take other readings across wide areas, suggest the researchers from the University of Utah and Yunnan University in China.\"It's kind of a new phenomenon,\" says one of the researchers, Keith Koper from the University of Utah. \"We don't really know how it's created.\"Small bursts of seismic activity, called microseisms, are already known to form from ocean waves dragging across the sea floor \u2013 they're part of the background seismic noise observed in coastal locations.\nStudying waves from lakes in this way is a newer idea, and the researchers used data from earlier studies alongside new readings from Yellowstone Lake in Wyoming as well as Dianchi Lake, Fuxian Lake, and Erhai Lake in China.\"The lakes span more than two orders of magnitude in size (areas from 210 km2 to 27,000 km2) and sample a range of climatic and tectonic regimes in Canada, the US, and China,\" the researchers write in their study.What they found was that by averaging seismic activity over longer periods, like six months or so, it's possible to create what the scientists call a \"CT scan of the Earth\".These small seismic waves travel through different geological materials at different speeds, enabling scientists to work out the composition of the ground around a lake \u2013 and without the need for an artificial shock like an explosion or vibrating plate"
        ]
    },
    "8729": {
        "gold_standard": [
            "paper For the first time, researchers have documented the violent clash of predators from two very different worlds, discovering evidence of alligators feasting on sharks in the wild.\nWhile there have been anecdotal reports of this kind of thing happening before, it's never been comprehensively studied, since ordinarily the American alligator (Alligator mississippiensis) and sharks occupy very different bodies of water.But that's not always the case. In coastal areas where marine ecosystems meet with estuaries, sometimes sharks and stingrays will veer from their ocean habitat into the briny mix of fresh and saltwater near the shore.Evidently, it's not always a good idea to do this, because it can bring them into contact with a fearsome predator that can adapt to the salty conditions of these coastal waterways.Judy Cooke\"Alligators seek out fresh water in high-salinity environments,\" says ecologist James Nifong from Kansas State University.\n\"When it rains really hard, they can actually sip fresh water off the surface of the saltwater. That can prolong the time they can stay in a saltwater environment.\"For their research, Nifong and wildlife biologist Russell Lowers searched through scientific and historical literature and consulted experts for any accounts of alligators attacking elasmobranchii \u2013 a subclass of cartilaginous fish that includes sharks and rays.They found unreported evidence of four times where American alligators preyed on elasmobranchii, including attacks on a nurse shark (image at top), bonnethead shark (image above and below), lemon shark, and an Atlantic stingray.There might not be any great whites on that list, but it shows A. mississippiensis is happy to forage beyond its regular diet of crustaceans, snails, and fish when seafood specials feature on the menu.Judy Cooke\"Alligators are opportunistic,\" Nifong explained to New Scientist.\u00a0\"They're not going to pass up a big chunk of protein that's swimming by.\"\nWhile the known instances of this preying are few and far between, the researchers say the fact it happens at all means sharks and rays may constitute a more significant part of the alligator diet than scientists had previously realised.It's also food for thought when it comes to managing endangered marine animals \u2013 as one of the uncontemplated risks to their survival could be death by alligator.As for why this preying behaviour has gone mostly unnoticed for so long, it could be because both alligators and sharks are difficult animals to study and observe in coastal habitats \u2013 especially since some small sharks can be mistaken for fish.There's also the question of post-meal evidence \u2013 or the lack of it \u2013 when researchers pump alligator guts to analyse what they've been consuming.\n\"Most prey gators eat turn to mush pretty quickly within their stomachs,\" ecologist Adam Rosenblatt from the University of North Florida, who wasn't involved with the study, told National Geographic.\"It all turns into one big pile of indistinguishable stuff, except for certain body parts like hair and shells.\"But just in case you thought this was a one-way contest, guess again. In the course of their research, Nifong and Lowers also uncovered reports of a bizarre historical melee, when the tables were turned on alligators.\"[O]n 5 October 1877 the sports magazine The Fishing Gazette published an article entitled 'Alligator and Shark Fight', recounting the observations of an epic skirmish between American alligators and sharks (unknown species) in a tidal inlet near Jupiter, Florida,\" the authors write in their pape"
        ]
    },
    "8800": {
        "gold_standard": [
            "New research\u00a0published on Monday finds there is so much wind energy potential over oceans that it could\u00a0theoretically be used to generate 'civilisation scale power' - assuming, that is, that we are willing to cover enormous stretches of the sea with turbines, and can come up with ways to install and maintain them in often extreme ocean environments.\nIt's very unlikely that we would ever build out open ocean turbines on anything like that scale - indeed, doing so could\u00a0even alter the planet's climate, the research finds.\u00a0But the more modest message is that wind energy over the open oceans has\u00a0large potential - reinforcing the idea that floating wind farms, over very deep waters, could be the next major step for wind energy technology.\"I would look at this as kind of a greenlight for that industry from a geophysical point of view,\" said Ken Caldeira of the\u00a0Carnegie Institution for Science in Stanford, Calif.The study, in the Proceedings of the National Academy of Sciences, was led by Carnegie researcher Anna Possner, who worked in collaboration with Caldeira.The study takes, as its outset, prior research that has found that there's probably an upper\u00a0 limit to the amount of energy that can be generated by a wind farm that's located on land.\nThe limit arises both because natural and human structures on land create friction that slows down the wind speed, but also because each individual wind turbine extracts some of the energy of the wind and transforms it into power that we can use - leaving less wind energy for other turbines to collect.\"If each turbine removes something like half the energy flowing through it, by the time you get to the second row, you've only got a quarter of the energy, and so on,\" explained Caldeira.The ocean is different. First, wind speeds\u00a0can be as much as 70 percent higher than on land. But a bigger deal is what you might call wind replenishment.The new research found that over the mid-latitude oceans, storms regularly transfer powerful wind energy down to the surface from higher altitudes, meaning that the upper limit here for how much energy you can capture with turbines is considerably higher.\n\"Over land, the turbines are just sort of scraping the kinetic energy out of the lowest part of the atmosphere, whereas over the ocean, it's depleting the kinetic energy out of most of the troposphere, or the lower part of the atmosphere,\" said Caldeira.The study compares a theoretical wind farm of nearly 2 million square kilometres located either over the US (centered on Kansas) or in the open Atlantic.And it finds that covering much of the central US with wind farms would still be insufficient to power the US and China, which would require a generating capacity of some 7 terawatts annually (a terawatt is equivalent to a trillion watts).But the North Atlantic could theoretically power those two countries and then some. The potential energy that can be extracted over the ocean, given the same area, is \"at least three times as high\".\nIt would take an even larger, 3 million square kilometre wind installation over the ocean to provide\u00a0humanity's current power needs, or 18 terawatts, the study found. That's an area even larger than Greenland.Hence, the study concludes that \"on an annual mean basis, the wind power available in the North Atlantic could be sufficient to power the world\".But it's\u00a0critical to emphasize that these are purely theoretical calculations.They are thwarted by many practical factors, including the fact that the winds aren't equally strong in all seasons, and that the technologies to capture their energy at such a scale, much less transfer it to shore, do not currently exist.Oh, and then there's another large problem: Modelling simulations\u00a0performed in the study suggest that extracting this much wind energy from nature would have planetary-scale effects, including cooling down parts of the Arctic by as much as 13 degrees Celsius.\n\"Trying to get civilisation scale power out of wind is a bit asking for trouble,\"\u00a0Caldeira said.\u00a0But he said the climate effect would be smaller if the amount of energy being tapped was reduced down from these extremely high numbers, and if the wind farms were more spaced out across the globe.\"I think it lends itself to the idea that we're going to want to use a portfolio of technologies, and not rely on this only,\" said Caldeira.Energy gurus have\u00a0long said\u00a0that among renewable sources, solar energy has the greatest potential to scale up and generate terawatt-scale power, enough to satisfy large parts of human energy demand. Caldeira doesn't dispute that.But his study suggests that at least if open ocean wind becomes accessible someday, it may have considerable potential to"
        ]
    },
    "8879": {
        "gold_standard": [
            "One day last March I talked with Juliana and Elisa, a mother and daughter who farmed just outside the city of Hu\u00e1nuco, Peru.Although they had only one acre of land in this mountainous landscape, they grew dozens of local varieties of potatoes and corn, along with other crops. And they knew each of their varieties by a common name \u2013 mostly in their Quechua language.\nPotatoes are native to the Andes, and over 4,000 varieties are grown there now. They come in numerous shapes, sizes and colors \u2013 red, yellow, purple, striped and spotted. A colorful mound of them resembles the bold, burnished colors of locally woven shawls.This wide array of types is an example of agrobiodiversity \u2013 a genetic legacy created by natural selection interacting with cultural practices over thousands of years.Today, however, agrobiodiversity is declining in many countries.In Mexico farmers are cultivating only 20 percent of the corn types that were grown there in 1930. Chinese farmers are producing only 10 percent of 10,000 varieties of wheat that were recorded there in 1949.More than 95 percent of known apple varieties that existed in the United States in 1900 are no longer cultivated.\nAccording to Bioversity International, an international research and policy organisation, just three crops \u2013 rice, wheat and maize \u2013 provide more than half of plant-derived calories consumed worldwide.This is a problem because our diets are heavy in calories, sugar and saturated fat and low in fruits and vegetables.\u00a0But there also are bright spots, such as Andean potatoes.\u00a0In a recent article, Stef de Haan of the International Center for Tropical Agriculture and I call for a major effort to strengthen agrobiodiversity for the future.Consuming many different species and varieties provides a diet that offers many unique tastes and a wide selection of nutrients that humans need to thrive.It also can help ensure more stable food systems and the needed variety of desirable genetic traits, such as hardiness.\nWealthy nations have less-diverse dietsGenerally, agrobiodiversity is significantly lower in wealthy nations, where the industrial food system pushes toward genetic uniformity.For example, federal agriculture policy in the United States tends to favour raising large crops of corn and soybeans, which are big business. Crop subsidies, federal renewable fuel targets and many other factors reinforce this focus on a few commodity crops.In turn, this system drives production and consumption of inexpensive, low-quality food based on a simplified diet.The lack of diversity of fruit and vegetables in the American diet has contributed to a national public health crisis that is concentrated among socioeconomically disadvantaged groups.Low agrobiodiversity also makes US agriculture more vulnerable to pests, diseases and climate change.Agrobiodiversity is a set of genetic resources in food and agriculture. (FAO)To connect these conditions to agrobiodiversity, consider potatoes. Although the United States has 10 times more people than Peru, only about 150 varieties of potato are sold here.\nSix varieties account for three-quarters of our national potato harvest. They dominate because they produce high yields under optimal conditions and are easy to store, transport and process \u2013 especially into french fries and potato chips.Federal policies have helped these varieties become established by reducing the cost of irrigation.Ironically, rich agrobiodiversity in many low- and medium-income nations supports more standardised and genetically uniform breeding industries in wealthy nations.US and European scientists and seed companies have used the diversity of Andean potatoes and their relatives to create commercial varieties that are the roots of modern industrial agriculture.How change can promote agrobiodiversityTo protect and increase agrobiodiversity, we have to know how to value it in a rapidly changing world.\nIn the GeoSynthESES Lab that I lead at Penn State, we are developing an ambitious new framework to analyse whether and how agrobiodiversity can continue to be produced and consumed in the future.Thanks to our fieldwork in Peru and other countries, we're finding that certain global dynamics, such as urbanisation and migration, can be compatible with agrobiodiversity production and consumption.For example, Elisa and Juliana live within a few miles of the Hu\u00e1nuco urban area, and they both work jobs in the city. Their \"traditional\" farming and eating patterns blend with their part-time farming.Such changes can even support the innovative use of local food varieties, but only under the right conditions.Farmers must have sufficient land and water. They have to continue preferring these food flavours and tastes. Vibrant local markets for these foods make producing them economically viable.\nTogether with collaborators working in Hu\u00e1nuco, our lab is assessing ways in which global trends could undercut agrobiodiversity in Peru.One concern is local adoption of \"improved varieties\" of both potatoes and corn that are being created by national and international breeding programs and private seed companies.Under favourable conditions, these types provide high yields and potentially good sales income. But the seeds can be expensive by local standards, and growing them requires more inputs, such as fungicides and irrigation.Farmers who use them are less resilient if it's a bad growing year or if cash is low. For these reasons more than one-half of the potato and maize seed being grown by the Hu\u00e1nuco farmers still comes from local sources such as nearby markets, neighbours and family members.So far, farmers in Hu\u00e1nuco and elsewhere in Peru prefer to growth both their traditional crops and new ones if possible. But discussions of new initiatives to extend the reach of such \"improved varieties\" reflect how these challenges will continue to evolve.Shifting dietsWe also are analysing local impacts of the global spread of inexpensive, low-quality industrial foods.Juliana, Elisa and their Hu\u00e1nuco neighbours increasingly depend on staples such as rice and sugar and on heavy use of cooking oil. Many of them still grow high-agrobiodiversity crops, but on a smaller scale, and these crops play a shrinking role in their diets.It is important to counter this trend by revaluing these nutritious foods, both for human health and for the environmental benefits that agrobiodiversity brings.On the positive side, middle-class Peruvians are embracing agrobiodiverse foods sold through markets and food fairs, such as the huge annual Mistura food festival in Lima.Internationally renowned elite restaurants and celebrity chefs are potentially important, nontraditional allies. It is crucial to find ways in which Elisa, Juliana and other producers of agrobiodiverse foods can earn rewards from these new markets.There also is growing interest in agrobiodiversity in the United States. Potato farmers here in central Pennsylvania and across the Northeast are reviving more than 100 local varieties that until recently had been considered lost.In the Southwest, research groups recently uncovered evidence of the ancient 'Four Corners Potato', the first known wild potato in North America, which was used some 10,000 years ago. DNA from this species could provide genes to make modern potato strains more resistant to drought and disease.Global shifts of urbanisation, migration, markets and climate can potentially be compatible with agrobiodiversity, but other powerful forces are undermining it.The imperatives of producing food at lower cost and higher yield clash with efforts to raise high-quality food and protect the environment. The future of agrobiodiversity hangs in the balance.Karl Zimmerer, Professor of Geography, Pennsylvania State University.This article was originally published by The Conversation. Read the original articl"
        ]
    },
    "8902": {
        "gold_standard": [
            "Could 2,000 years of belief be wrong? Are we in fact living on a disc rather than a globe?One believer from the Flat Earth Society is determined to find out. \"Mad\" Mike Hughes is all set to build his own rocket to see for himself that Earth is flat.\nFor the last 50 years, we've been able to view pictures of Earth from space, which might seem like all the proof you need to see that our planet is in fact round.But the awareness of how easily images can be doctored and the growth of internet conspiracy theories appears to have fuelled a resurgence of belief in a flat Earth.At the same time, there's a lack of understanding of the science that has long been used to demonstrate that we live on a globe, without the need to leave it. I wish Hughes well with his endeavour, as he has at least been willing to try and prove his theory.Perhaps if more people really could see for themselves the evidence, we might be able to reverse this worrying trend. A good place to start would be by making sure children have the chance to try out simple experiments in school.\nOne of the best documented methods for determining Earth's roundness was first performed (to our knowledge) by the ancient Greeks.This was achieved by comparing the shadows of sticks in different locations. When the sun was directly overhead in one place, the stick there cast no shadow. At the same time in a city around 500 miles north, the stick there did cast a shadow.If Earth were flat then both sticks should show the same shadow (or lack of) because they would be positioned at the same angle towards the sun. The ancient Greeks found the shadows were different because Earth was curved and so the sticks were at different angles.They then used the difference in these angles to calculate the circumference of Earth. They managed to get it to within 10 percent of the true value \u2013 not bad for around 250 BCE.\nAnother piece of evidence for a globe is the difference between the night skies in the northern and southern hemispheres. The view is completely different because the Earth beneath you is pointing in a different direction.If Earth were flat, the view should be the same. This can be made even easier by simply comparing when it is night and day in each country.You can observe the planets as well. They all rotate, and watching over the course of a few days gives a clear picture they are spherical rather than flat. The chance that most of the planets are spherical but Earth is flat seems very unlikely.Fake scienceBut when science experiments are performed incorrectly they can appear to give the opposite result. If they are shared through social media, these false ideas can be spread quickly with no one to point out their flaws"
        ]
    },
    "8915": {
        "gold_standard": [
            "There seems to be significant confusion about what happened in the British parliament when MPs discussed a proposed amendment to the EU (Withdrawal) Bill to formally recognise animal sentience. But where science is concerned, animal sentience is in no doubt.\nThe definition of sentient is simply \"able to perceive or feel things\". Today most of us would probably also say that animals are able to feel emotion, form attachments and have distinct personalities. Yet for many decades the idea of animals feeling emotions or having personalities was dismissed by behavioural scientists.This strange view that arose from the 17th century philosopher Ren\u00e9 Descartes' alleged assertion that animals are without feelings, physical or emotional.Recent work has debunked this idea (whether or not Descartes actually said it). If any mammal appears to be free of emotions, apart perhaps from cynicism, it would be the goat. Yet scientists have been able to show that goats become emotionally aroused in response to various test situations, and whether these emotions are positive or negative.The researchers analysed the calls the goats made when they were expecting food, when they were frustrated because a food reward didn't arrive and when they were isolated from their herd mates.\nThey also used the goats' body language and heart rate to calibrate their assessment of the emotions expressed in the calls, as analysed using the frequency of the sounds.Horses are a bundle of emotions. This is not surprising, given that they are very social animals, with a close relationship with others in their herds and are also prey animals whose response to threat is to run away as fast as possible.In Canada, horse riding is reckoned to be one of the most dangerous sports, ahead of motor racing and skiing, and the emotional state of the horse is an important aspect of the safety or otherwise of the rider.Researchers in France looked at the level of emotion and the ability to learn shown by 184 horses from 22 different riding schools.The ability of a horse to be fairly calm in the face of a novel situation, and to learn quickly that a new object or situation is not threatening, is crucial when riding. So the researchers concentrated on these aspects of horse emotion.\nThey found that one of the most important influences on how emotional horses are is the way that they are housed. Horses that were kept outside in a field were likely to be less fearful of a new object and to respond with less excitement to being loose in an arena than horses that were housed individually in boxes.While the result is not surprising, the study emphasises the fact that horses are capable of emotions such as anxiety and fear.Another vexed question, in the early part of the 20th century at least, was whether or not animals have personalities. It is now generally accepted that they do, and that those personalities are capable of as much variation as human personalities.Perhaps the most surprising aspect of this area of study is that personality is discernible even in fish, which are often seen as being singularly lacking in emotional range. Scientists have found that the personality type of a fish may affect its likelihood of having certain parasites, or its ability to move past a barrier in a stream when on migration.\nWhy it mattersThe reason that all these studies and the many others into animal emotions, personality and ability to feel pain, fear and stress, are important is the huge implications for animal welfare.Whether or not the law recognises animals as being sentient, those animals will still feel afraid, fail to cope or suffer pain during transport and slaughter, as well as in everyday situations.It is difficult to reduce the fear and stress endured by animals going to slaughter, or being used in sport, entertainment or as companions. But it is likely to be even more difficult if the law does not recognise animals as sentient beings, to whose welfare we should pay full regard.Slaughter house personnel are perceived as being somewhat rough in handling the animals under their care, in spite of repeated training. Unless animal sentience continues to be recognised in law, it will be even more difficult to deal with people who compromise animal welfare.Jan Hoole, Lecturer in Biology, Keele UniversityThis article was originally published by The Conversation. Read the original article"
        ]
    },
    "8927": {
        "gold_standard": [
            "Environmental Science & Technology The oceans are full of plastic. We know it, and we know it's a big problem. What we don't know is precisely how big the problem is.A fluorescent dye could help scope out the tiniest pieces of garbage in our marine environments, allowing researchers to map oceanic waste in unprecedented detail and just maybe help us find solutions to this growing environmental crisis.\nWaste that accumulates in gyres, often described as Great Garbage Patches, often shocks us with its sheer scale.But it's the tiny bits we don't see that are as much of a concern, if not more so.Particles smaller than 5 millimetres (0.2 inches) known as microplastics can be found as tiny beads in cosmetics and cleaning products, fibres in garments, or form from larger plastics breaking down.As such, they are estimated to be far more abundant than the chunky bottles and floating bags we can see. Just how much more, nobody really knows.Research led by the University of Warwick in the UK has found a practical solution for detecting microplastics in field samples.Tiny pieces of plastic waste on the scale of tens of micrometres aren't exactly easy to distinguish from other pieces of natural flotsam, even with a decent microscope.\nAs tempting as it is to think of these miniscule shreds of rubbish as 'out of sight, out of mind', they're just a much of an issue for marine species as the turtle-choking plastic bags that larger animals mistaken for tasty jellyfish.Just recently, researchers found coral polyps didn't just swallow them up \u2013 they did so with relish, seeming to actually like the flavour.That's not to mention the variety of plastic materials that shed persistent, bioaccumulative, and toxic (PBT) compounds into the food chain.So getting a grip on the scale and distribution of microplastics is clearly a high priority.\"Current methods used to assess the amount of microplastics mostly consist in manually picking the microplastics out of samples one by one,\" says marine ecologist Gabriel Erni-Cassola.\nTo help make the plastics stand out from similar-looking bits of gunk, the researchers investigated the use of \"Nile red\", a fluorescent dye that lights up when it comes into contact with the right kinds of chemicals.Preliminary tests on different plastic polymers showed the dye was up to the job of making microplastics stand out.To make sure it didn't mark similar materials such as fatty substances or tiny wood fragments, they flushed samples with nitric acid, which proved efficient at digesting all kinds of biogenic matter.Out in the field, the team took samples of beach sand and trawled the surface water from the coast around the town of Plymouth and analysed them for microplastics using both traditional methods and their staining technique.They found a much larger amount of microplastics under 1 millimetre (0.04 inches) in size than they'd predicted, and significantly more than they'd have found using traditional methods alone.\nThe number one culprit for these hidden, smaller variety microplastics seems to be polypropylene \u2013 the stiff polymers we use in everything from ropes to banknotes to packaging.\"Using this method, a huge series of samples can be viewed and analysed very quickly, to obtain large amounts of data on the quantities of small microplastics in seawater or, effectively, in any environmental sample,\" says Erni-Cassola.Previous studies have determined that 99 percent of the plastic waste that we believe to be entering the ocean can't be detected, meaning it's either too small to see or is hiding inside the digestive systems of marine life.This new method seems to have spotted at least a portion of it.\"Have we found the lost 99 percent of missing plastic in surface oceans?\" asks Joseph A. Christie-Oleza, a microbiologist and a co-author on the study.\n\"Obviously this method needs to be implemented in future scientific surveys to confirm our preliminary findings.\"Tracking the fate of microplastics will certainly help inform future policies on waste management and industry regulations.Meanwhile, the challenge of weaning ourselves off our insatiable love of plastics and finding a way to deal with the waste remains.\u00a0This research was published in Environmental Science & Technolog"
        ]
    },
    "8942": {
        "gold_standard": [
            "The immense popularity of the bright, energy-saving electrical components called light-emitting diodes (LEDs) has been a boon for the environment. But researchers are also discovering it has come at a rather serious cost.\nThanks partially to solid-state lighting's bigger bang for your buck, the growing problem of light pollution is showing no sign of slowing, which is bad news for our ecosystems and our health.A big part of the problem is we just don't think of light in the same way we do noxious aerosols or toxic fluids.So when we invent new light-emitting technology, we're less likely to think of the potential cost to the environment\u00a0\u2013 we think of what annoying shadows we can blast away with a few extra bulbs.The result is as clear as daylight \u2013 our world has less darkness than ever before.Physicist Chris Kyba from the German Research Centre for Geosciences has led a study using satellite data to investigate how brighter our nights are becoming.And while he doesn't point the finger solely at LEDs, they do represent the problem.\n\"We'll light something that we didn't light before, like a bicycle path through a park or a section of highway leading outside of town that in the past wasn't lit,\" says Kyba.The researchers use the term 'rebound effect' to describe how a savings in energy leaves us with more money that we simply pour back into the product.We can see the same effect in our approach to buying cars \u2013 better fuel efficiency leads to more fuel to drive longer distances, rather than a reduction in overall power consumption.Light pollution isn't a new concern, especially among astronomers, ecologists, and insomniacs.Outdoor illumination grew at a rate of about 3 to 6 percent per year\u00a0in the second half of the 20th century, seeing an end to night as we knew it in many parts of the world. And we've needed to rely on statistical estimates and assumptions to get a grip on how bad it is.\nSufficiently calibrated satellite technology has only recently provided data that's accurate and reliable enough to monitor the problem in detail.The team used information gathered by a radiometer called the Visible/Infrared Imager Radiometer Suite (VIIRS), which was mounted on a National Oceanic and Atmospheric Administration (NOAA) satellite named Suomi NPP.Restricting themselves to data collected in October in order to avoid added illumination from holiday period festivities, the researchers analysed the growth in light pollution between 2012 and 2016.On average the amount of area illuminated at night increased by about 2.2 percent each year. Continuously lit areas were also about 2.2 percent brighter each year.Growth mostly occurred throughout South America, Africa, and Asia, while declines in lighting were noticed mostly in war-torn zones, such as Syria and Yemen. Illumination had stabilised in just a few countries, mostly those which were already brilliantly lit.\nIf this all sounds serious, the reality is likely to be slightly worse.\u00a0The satellite data couldn't directly detect the bluer wavelengths emitted by many LEDs.\"We can say with fairly high confidence even though we didn't measure in the satellite an increase in these countries, they are nearly certainly increasing in brightness in terms of how human beings would perceive the light,\" says Kyba.This end of the visible light spectrum more closely resembles daylight, so even if we were to assume the overall luminosity didn't increase in countries that were replacing old bulbs with LED technology, we'd still perceive night to feel more like day.It's well established that this flood of blue light has a serious impact on our health and wellbeing.It also messes with wildlife \u2013 you might not care much about a few moths getting dazed by the lights, but research shows LED lighting could have profound impacts on a range of plant and animal species.\nManipulating their spectrum and intensity according to certain times of the day could offer a small amount of respite, but there's a lot to be said for simply asking if we really need so much light.By 2020, LED lights are set to account for 61 percent of the global lighting market. That's a good thing where power consumption is concerned.It should also be a reminder to remember there's another kind of pollution we need to be concerned about when it comes to switching off that light.\u00a0This research was published in Science Advance"
        ]
    },
    "8949": {
        "gold_standard": [
            "Many humans have gone way too far in their need to have squeaky clean, completely germ-free hands at all times.And while alcohol-based hand sanitiser is the least problematic choice, now it turns out it could get you in trouble with law enforcement.\nResults from a small experimental study show that alcohol vapour from hand sanitiser used by the person administering a breath test can lead to false positives and produce error codes in the equipment - and this has real implications for how police use breathalysers in the US and many other countries around the world.Science is clear on the fact that you can't absorb enough hand-sanitising alcohol through your skin to make you appear drunk on a breath test.But it's a different situation if the person administering your test used sanitiser to be more hygienic.A pair of researchers from the Missouri Department of Health and Senior Services tested 65 stone-cold sober individuals in three groups, using one of three common breathalyzer machines on each group.The test operators would apply a standard amount of either gel- or foam-based alcohol hand sanitiser and rub their hands until dry. Then they proceeded with unwrapping the disposable mouthpiece and holding it while subjects performed the breath test.\nThe final results showed that 10 percent of initial tests yielded a positive breath alcohol result despite the subjects being completely sober.Furthermore, 31.5 percent of tests ended up with error codes, as the presence of alcohol vapour messed up the measurements.Additionally, a smaller test with just ten subjects showed that if the operator waited five minutes between hand rub application and administering the breath test, there were no false positives.These results fall in line with previous research that has indicated similar outcomes, although in those cases the breathalysers tested were not the same as ones routinely used by the police in the US.But taken together, these findings point to a need of adjusting common practices, so that people don't end up falsely accused of being intoxicated.\n\"[I]t would be advisable to train officers regarding this possibility and potentially update methodologies for the collection of breath alcohol test results,\" the researchers write in the study.Additionally, the scientists advise it might be prudent to review the habit of keeping alcohol-based hand sanitiser around fingerprinting devices in the law enforcement office.Not only does this practice often land them near the breathalyser machine, but apparently some non-alcohol based hand sanitisers can even improve the quality of fingerprint scans.Although given the antibiotic resistance crisis, maybe more people should just wash their hands with good old soap and water.The study was published in the Journal of Forensic Science"
        ]
    },
    "8969": {
        "gold_standard": [
            "In 2015, NASA announced that it had \"the best evidence yet\" for water flowing on the surface of Mars: Dark, apparently damp streaks spotted on the Red Planet contained salts associated with liquid water.\nThe news had NASA's head of planetary science, Jim Green, imagining future astronauts slurping up the salty sludge as they explored the Red Planet.\"Mark Watney could have taken advantage of this discovery,\" he told The Washington Post at the time, referring to the central character of the movie The Martian.Others suggested that the streaks might harbor microbial life.But then US Geological Survey scientists decided to take a look. In a study published Monday in the journal Nature Geoscience, the USGS says that those promising streaks are merely marks made by flowing sand or dust.\u00a0Recurring slope lineae up close (NASA/JPL/University of Arizona/USGS. Public domain)\"This new understanding \u2026 supports other evidence that shows that Mars today is very dry,\" lead author Colin Dundas said in a news release.\nThe finding is the latest disappointment for scientists who hoped that the streaks, technically called \"recurring slope lineae,\" might indicate that Mars isn't quite the desolate desert wasteland it's commonly made out to be.While the RSL weren't ever direct evidence of water, they seemed like a strong indicator.Scientists had noticed that the streaks grew and shrank in response to the seasons - almost as if salty water was being heated by the Sun and then flowing down ridges and hills.Not only that, but the streaks contained perchlorates - molecules that help water stay liquid over a broader range of temperatures.But when Dundas and his colleagues examined images of dozens of RSL at multiple sites, they found the \"streaks\" didn't behave like flowing water.For one thing, they existed only at the tops of very steep slopes. For another, the streaks all seemed to end when their slopes matched the dynamic \"angle of repose\" - the steepest angle at which a given material can be piled without slumping.\nIf you've ever tried to build a sand castle, you're familiar with this concept. It's why dry sand - which has a very shallow angle of repose - tends to slide out of shape, but wet sand - with a steeper angle of repose - can be piled into towers and turrets.\"The RSL don't flow onto shallower slopes, and the lengths of these are so closely correlated with the dynamic angle of repose, it can't be a coincidence,\" co-author Alfred McEwen of the University of Arizona, Tucson, told Phys.org.McEwen is the principle investigator for HiRISE, a camera on the Mars Reconnaissance Orbiter that was used to image the RSLs.The RSL aren't created by water, Dundas and McEwen concluded. Instead, they resemble the markings left by dry grains that slide down the sides of a sad, slumping sand castle.\nThis doesn't mean there's no water whatsoever in the RSL, they write. The tendency for these streaks to appear in warm seasons, along with the presence of perchlorates, suggest that water might help the streaks form.\"However, liquid water volumes may be small or zero,\" the authors say.That fits with a study published last year in the journal Geophysical Research Letters that found the streaks could contain no more than 3 percent liquid water - making them little more than mildly damp, slightly salty dirt.Mars's weird streaks probably couldn't keep an astronaut alive, and they probably aren't home to tiny alien organisms. But they're still worth studying, McEwen said.\"RSL probably form by some mechanism that is unique to the environment of Mars,\" he told Phys.org, \"so they represent an opportunity to learn about how Mars behaves, which is important for future surface exploratio"
        ]
    },
    "8973": {
        "gold_standard": [
            "saying their name compelled to make a compromise Whether it's getting your partner to do more housework or making your colleagues back your latest idea, we all end up spending a considerable amount of time trying to persuade or even manipulate others.\nSo can science offer any clever tricks to get people to do what we want, without resorting to bullying them? It's complicated, but some 30 years of psychological research suggest there might just be a few methods that are worth a try.Use a person's body against themGot a date coming up? Maybe you should consider taking them to see a horror movie. \"Misattribution of arousal\" is a popular theory in social psychology that suggests people sometimes mislabel feelings from their body.For example, you experience an elevated heart rate when you are anxious, but also when you are excited.Psychologists have therefore been experimenting on whether it is possible to use this idea to manipulate individuals into thinking they are experiencing particular emotions, such as believing they are attracted when they're actually scared This is because removing the \"you\" removes the accusatory element.Another linguistic trick is to use nouns rather than verbs when discussing an outcome you want to happen.In one study people were asked \"how important is it to you to be a voter in tomorrow's election?\" versus \"how important is it to you to vote in tomorrow's election?\" When people were asked about \"being a voter\", this primed their self-identity as a person who votes.The people who were asked about being a \"voter\" were 11 percent more likely to vote in a state election the next day, compared to those who were asked about \"voting\".There are also various other body and language tricks you can employ that have been shown to increase people's liking or trust in you, such as subtly mimicking people's body posture, looking people in the eye more frequently and saying their name more often Use rewards and punishments variablyDoes your loved one need some \"behaviour shaping\"? Maybe a bit more hanging up the bathmat, and a bit less using your toothbrush?We all know that you can increase the likelihood that someone will do something by rewarding it, and decrease it through punishment.But, operant conditioning psychology shows that for prolonged manipulation, it is better not to reward or punish every instance of the behaviour.So if you want someone to keep doing something (or to stop doing something), you can simply alter the schedule by which you dole out rewards or punishments to maximise their compliance.A variable reinforcement schedule like this works by the slightly creepy \"will they, won't they\" principle \u2013 where the uncertainty makes people learn faster and maintain a behaviour longer once the reward or punishment is removed.In the same way, not knowing how many more plays you need before you win is part of what makes gambling and the lottery so addictive.Ask for something you don't wantA large body of popular research suggests that if you are trying to get something, you may help your case by also asking for something you don't want.The \"foot-in-the-door method\" refers to the fact that, once a person has agreed to a very small request, they are more likely to agree to another, much larger request \u2013 significantly more so than if they were only posed with the large request.It was first suggested this must occur because people use their own behaviour as a cue to their internal attitudes.Since they were not pressured externally into agreeing, the person unconsciously infers their acquiescence is due to a positive attitude towards the asker or the issue.The effect seems to hold even when the second request is a completely different type, or when made by a different person.Given this, it was thought that perhaps the first \"yes\" changes the individual's own disposition towards saying yes to things in general (\"I am clearly such a yes man\").On the flip side, if you ask for something outrageously large that a person would never agree to, you actually raise your chances of agreement to a second smaller request.This may also be a form of reciprocity effect: the person being asked is compelled to make a compromise, in response to the asker making a concession.In sum, social psychology may not change your life \u2026 but it may just help you get the last biscuit.Harriet Dempsey-Jones, Postdoctoral Researcher in Cognitive Neurosciences, University of Oxford.This article was originally published by\u00a0The Conversation. Read the original article"
        ]
    },
    "9058": {
        "gold_standard": [
            "When the cosmos shoots pool, it plays for keeps. It sank a six-mile-wide rock in our pocket of the solar system 66 million years ago. The smack of the asteroid against Earth released energy on the order of billions of atomic bombs.\nDinosaurs were the cataclysm's most famous victims, joined by sea creatures, plants and microorganisms. All told, Earth's biodiversity shrank by 75 percent in what is known as the Cretaceous-Paleogene, or K-Pg, extinction (also known as the K-T extinction).A large asteroid strike happens only once every 100 million years. And a controversial new report suggests the K-Pg impact was an exceptionally unlikely shot.In a paper published Thursday in the journal Scientific Reports, a pair of researchers calculated the asteroid had little more than a 1-in-10 chance of triggering a mass extinction when it smacked into Earth.(We mammals should be glad it beat the odds: After the dinosaurs' swift exit, nocturnal furballs - our ancestors - scampered into the daylight and conquered the planet. And one branch of dinosaurs survived and persists as today's birds.)\nSoot was the impact's most lethal symptom, argued paleontologist Kunio Kaiho, of Tohoku University, and Naga Oshima, an atmospheric chemist at Japan's Meteorological Research Institute.The asteroid hit Earth near the Yucat\u00e1n Peninsula in Mexico. There, the researchers say, vast reservoirs of crude oil and hydrocarbons were tucked beneath a shallow sea, waiting to be set ablaze.Kaiho and Oshima's previous work, published in 2016, modelled what would happen if an asteroid turned lots of organic matter into soot - millions and millions of tons of it, injected into the stratosphere.In the scenario, Earth's temperature plunged beneath the soot cloud that blocked the sun's radiation. Plants, trapped in this carbon choke hold, wilted and died. Starving animals soon followed suit.Sixty-six million years ago, only 13 percent of Earth's surface contained enough organic material to generate this doomsday soot, the authors concluded in the new study.\nHad the asteroid hit the other 87 percent of Earth, Kaiho said, \"I think dinosaurs could be alive today.\"Timothy Bralower, a Pennsylvania State University paleoceanographer who was not involved with this work, applauded the researchers for their \"innovative way of thinking\". But Bralower said he doubted that a soot cloud alone could explain why the asteroid was so lethal.\"The 13 percent number they're quoting has a lot of assumptions based around it,\" said Sean Gulick, a geophysicist at the University of Texas at Austin.The asteroid churned up soot, he said, but soot was \"not the driver\" that killed the dinosaurs.The extinction asteroid theory, widely accepted as the most plausible explanation for the dinosaurs' disappearance, is the result of four decades of research.In the late 1970s, scientists Luis and Walter Alvarez, a father-son duo at the University of California at Berkeley, began to investigate rocks on the border between the Cretaceous and Paleogene geologic periods.\nThe Alvarez team discovered the element iridium, at levels found only in asteroids, in Italian clay that dated to the ancient divide. Cretaceous soot, too, was mixed in with the red clay.Iridium appeared in 66-million-year-old clay around the world, in locations as far apart as Tunisia and New Zealand. In 1990, scientists announced they'd found the entry wound. It was a giant pockmark in the Yucat\u00e1n Peninsula, the \"Crater of Doom,\" centered near a small Mexican town named Chicxulub.Kaiho and Oshima based their soot cloud calculations on geologic layers in Haiti, near the peninsula. In the late Cretaceous, these rocks were rich in hydrocarbons.That, they said, was the ammunition the asteroid needed. \"If the asteroid had hit a low-medium hydrocarbon area on Earth (occupying approximately 87 percent of the Earth's surface), mass extinction could not have occurred,\" Kaiho said.\nBut Gulick, part of a 2016 drilling project to explore the asteroid's crater, said there was little evidence for sufficient amounts of organic matter at the Chicxulub impact site.Scientists have found a diary of horrors burned into geologic layers at the time of impact. Hypothesised \"kill mechanisms\" include toxic heavy metals brought by the asteroid, acidic oceans (so corrosive that animal shells dissolved) and global firestorms.Red-hot asteroid bits, kicked up in the collision, would have rained down on forests and started wildfires across the planet. This might explain the soot found in the clay, Bralower said.The K-Pg extinction was not the result of one blow but a \"quadruple whammy,\" he said. \"I just don't think, with the diversity of life, one mechanism can explain all the mass extinction.\"\nAll the researchers agreed that the location, at Chicxulub, was crucial to its devastation. \"The authors of the study are correct in making the point that you couldn't have hit just anywhere,\" Gulick said.Both Bralower and Gulick pointed to a recent paper in Geophysical Research Letters - they are listed as participants or third-party scientists - which contends that the asteroid released killer amounts not of soot, but of gas.Carbon dioxide and sulphur gases blown extremely high into the atmosphere would have the opposite of a greenhouse effect: surface temperatures plummeting by more than 20 degrees Celsius, or about 40 degrees Fahrenheit.\"If you cool the planet by 26 degrees Celsius in five years you're going to cause a lot of extinction,\" Bralower said.To release these climate-altering gases, the asteroid needed to hit a shallow sea above sedimentary rock"
        ]
    },
    "9145": {
        "gold_standard": [
            "The remains of an ancient flying predator that ruled the skies some 70 million years ago have been discovered in Mongolia, and researchers say the species likely ranked among the largest of its kind.\nThe fossil discovered belongs to a kind of pterosaur \u2013 a group of flying reptiles that lived around the same time as dinosaurs. These animals were the first vertebrates known to evolve the power of flight, and are thought to be the largest flying animals ever seen on Earth.The pterosaur species unearthed in Mongolia has not yet been identified, but based on the size of the fragments of cervical vertebrae (neck bones) found, this sucker was huge.\"I immediately recognised that it might be a pterosaur and was astonished at its gigantic size,\" palaeontologist Takanobu Tsuihiji from the University of Tokyo told John Pickrell at\u00a0National Geographic.\"Straight away, we went back to the site and discovered the rest of the specimen.\"That site was a geological formation in the Gobi Desert called the Nemegt Formation, which has turned up numerous dinosaur finds dating back to around 70 million years ago.\nBut up until now, this fertile fossil patch has never produced a pterosaur \u2013 and the researchers say their find is indicative of just how widely distributed these ancient aerial predators once were during the late Cretaceous period.While it's hard to estimate the size of an extinct pterosaur solely from chunks of neck, the team thinks its footprint would have been comparable to the two largest species we know about: Quetzalcoatlus and Hatzegopteryx, which had wingspans up to approximately 11 metres (36 feet).That puts them, and potentially our Mongolian John Doe, on a par with a small plane \u2013 which, frankly, would have been terrifying if you were a small vertebrate being stalked and swooped by these things 70 million years ago.\"It's a really big vertebra, and the only thing comparable is some material from Romania,\" British palaeontologist and pterosaur expert Mark Witton from the University of Portsmouth, who wasn't involved with the discovery, told National Geographic.\n\"This is definitely up there with the largest pterosaurs, and there's nothing like it from Asia so far.\"It's possible, Witton thinks, given the scarcity of bones so far found, that this animal might have been smaller than its peers, and that the neck bones found were disproportionately larger in this species for some unknown evolutionary reason.Solving that mystery will require more fossils to be found, which could also help clear up just what these aerial giants once preyed upon.For his part, Witton suspects they weren't too discriminating.\"They seem to be feeding on things on the ground,\" he said, \"and are generalist in their ability to grab basically whatever they can fit in their beaks.\"The findings are reported in the Journal of Vertebrate Paleontology"
        ]
    },
    "9179": {
        "gold_standard": [
            "announced they'd actually observed the waves. the researchers wrote in their paper The phenomenon of \"bow waves\" has been long hypothesised, but proven quite elusive. Now, using sensors from 2,000 sites across the US, researchers have what they are claiming is the \"first unambiguous evidence\" of upper atmospheric bow waves in the wake of an eclipse Since the initial proposal in 1970, several attempts have been made to observe these waves. For starters,\u00a0a 1973 study was inconclusive.Microbarographs were used to observe a 1976 eclipse in Australia, and that study produced findings that were consistent with the eclipse bow wave hypothesis.\u00a0Then, data consistent with eclipse bow waves were observed in 1987\u00a0- but neither of these events produced conclusive results.In 2011, researchers from Taiwan announced they'd actually observed the waves. They used ground-based GPS satellite receivers to track a 2009 eclipse over Taiwan and Japan, looking for changes in electron content - a higher electron count means a higher level of ionisation as electrons get stripped from atoms, creating plasma.The gravity waves are essentially a higher concentration of plasma in the ionosphere, and can be ascertained by that spike in electron content.\nThe researchers observed both bow and stern waves, wavelengths between 36 and 120 kilometres\u00a0(22 and 75 miles), periods of three or five minutes, and travelling through the ionosphere at 100 metres (330 feet) per second.This is the same technique researchers used to track this year's eclipse - but they had a lot more land available across which to track the shadow, a lot more sensors, and therefore a lot more data.They observed the waves as electron changes across central and eastern US, with 300-400 kilometre wavelength, periods of around 25 minutes, and travelling at speeds of 280 metres per second - too quickly to be attributed to known gravity wave disturbances we get due to typical ionospheric processes.The researchers attribute the difference in findings to the limited field of view in a narrow band used by the researchers in the 2011 study.\n\"This study reveals complex interconnections between the Sun, Moon, and Earth's neutral atmosphere and ionosphere, and demonstrates persistent coupling processes between different components of the Earth's atmosphere, a topic of significant community interest,\" the researchers wrote in their paper.They added that their results \"present the most comprehensive set of eclipse-induced wave characteristics available to date, advance theoretical understanding, and address a long-standing controversy surrounding one of nature's most spectacular active events"
        ]
    },
    "9812": {
        "gold_standard": [
            "Thanks to a long-duration solar flare belched out by the Sun earlier this week, Earth is buckling down for a geomagnetic storm at the higher latitudes.On 12 February, a relatively mild C-class solar flare occurred, accompanied by a coronal mass ejection (CME), sending plasma and electromagnetic radiation out into space - some of it heading straight for Earth.\nIt may sound a bit scary, but it's not even remotely unusual. These coronal mass ejections are, in fact, amongst the things responsible for one of the most beautiful phenomena to grace the skies - the eerie light show we call the aurora.This happens when the charged particles from the CME collide with atoms and molecules in the atmosphere, causing the sky to light up.The solar wind can also cause auroras when it's particularly strong, but the auroras produced by the geomagnetic storms caused by CMEs are particularly clear and spectacular.According to an alert for the storm issued by the US National Oceanic and Atmospheric Administration, those in higher latitudes, such as Canada, Alaska and Siberia in the north, and Antarctica in the south, may be treated to a magnificent light show in the nights ahead.\nThis is because the charged particles from the Sun get caught up in Earth's magnetic field lines, which direct them towards the poles.Aurora isn't the only effect of a geomagnetic storm, though. High-frequency communication signals, which bounce of the ionosphere, can be affected, as can radio signals below 30 MHz at all latitudes.GPS signals can also be affected. This is because the disturbed atmosphere can disrupt the signals being sent between the ground-based transmitter and the orbital satellites.Thankfully, this storm is only a mild one, so the NOAA is only predicting very weak fluctuations in the power grid, caused by small surges of geomagnetically induced current - certainly not enough to knock the grid out entirely.So if you're above around 65 degrees latitude, relax, go get a chair, and prepare to enjoy something truly awe-inspiring"
        ]
    },
    "10259": {
        "gold_standard": [
            "It's not often you get chance to look at something that's several billion years old - we're totally amazed by these fossilised remains, found in rocks formed from microbial mats that settled in shallow pools some 1.6 billion years go.\nThe holes you see were formed by oxygen bubbles given off by tiny microbes, setting the foundations for life as our planet started to become increasingly hospitable.That's according to a new study on the mats carried out by researchers in Sweden and Denmark, who describe their findings as \"a signature for life\".\u00a0The billion-year-old material can teach us more about this distant period of history, say the researchers.(Stefan Bengtson)Mats like the ones that formed these fossils are typically produced at the intersection of different substances \u2013 such as ocean water and the ocean floor \u2013 and are made up of the simplest of microorganisms, including bacteria.\nIn this particular case, the mats mined from central India are thought to show oxygen bubbles created by cyanobacteria, a particular type of bacterium that produces energy through photosynthesis.As well as exhaling oxygen, cyanobacteria also excrete minerals, and this combination of oxygen and minerals would've been crucial in allowing other life on Earth to flourish.This extra oxygen supply would've been seized upon by more advanced organisms, plants, and eventually animals, according to the researchers.The tiny organisms produced even tinier bubbles: the ones you can see are only around 50-500 microns in size, so some are as small as the width of a human hair.Some bubbles have been partly compressed, suggesting a flexible original texture (Stefan Bengtson)But even at such a miniature size, these bubble fossils can help scientists understand more about how cyanobacteria worked and spread. They were taken from a thick sedimentary layer called the Vindhyan Supergroup, one of the most ancient records of early life we have.\n\"These evidences together point toward a shallow setting where primary production was dominated by cyanobacterial and algal photosynthesis,\" the team writes in their study.The research has to be taken in the context of other studies, but ultimately can reveal more about the beginnings of life.In particular, the way that a barren and rocky planet might have gradually evolved to become perfect for supporting life. Oxygen would have played a big part in that, and especially the Great Oxygenation Event that scientists reckon got underway around 2.45 billion years ago.While increased oxygen levels would've killed off some microbes that evolved without oxygen, others would have been allowed to develop and flourish, marking the transition from the sparsely inhabitated landscape of Earth's middle age to the lush world we're familiar with toda"
        ]
    },
    "10298": {
        "gold_standard": [
            "Advanced Energy Materials A novel approach to an energy storage device run on an aqueous electrolyte can go from flat to fully-charged in just 20 seconds, making it perfect for portable electronics that frequently need a quick boost.\nWhile the concept isn't new, previous attempts have resulted in devices that suffer from low power and short working lives.We ask a lot of power storage tech these days. Not only must it be compact, powerful, long-lasting, and quick to recharge, it also has to be environmentally friendly. Oh, and preferably not blow up if you happen to chew on it.For those and other reasons, aqueous storage devices \u2013 those that contain water-based solutions rather than a mush of toxic or flammable organic paste \u2013 have gained some serious attention as safe and reliable options.Although less flammable than modern lithium batteries and potentially a whole lot cheaper, the way the solution carries electrons introduces a serious problem.The cells that make up a battery work by transferring electrons between two materials. Aqueous solutions limit the voltage range between the two points more than other solutions, resulting in the anode being eaten away faster.\nThat makes for a poor life span and low amounts of power \u2013 not exactly great for reliably pushing your latest smart device through the day.So researchers at Korea Advanced Institute of Science and Technology (KAIST) have put a new spin on the system, modifying the way a device called an aqueous hybrid capacitor (AHC) is constructed.Hybrid capacitors such as these are essentially a mix of battery and capacitor \u2013 with electrodes that store their power electrochemically as an electrostatic charge. Adding an aqueous solution of ions inbetween can help carry the current.By using graphene-based polymers instead of more traditional metallic conductors on the anode, and making the cathode with a scattering of metaloxide nanoparticles, the researchers were able to overcome the shortfalls of previous AHCs.\nThe web of tiny carbon fibres on the anode turns out to be far more efficient at transferring electrons into the aqueous solution, allowing for batteries with more than 100 times the power density than previous devices while still sustaining capacity for over 100,000 charges.Better yet, the new anodes coupled with liquid electrolytes mean the whole thing can go from zero to 100 perfect with just 20 seconds of charging.All of this is at no cost to its safety or economics.\"This eco-friendly technology can be easily manufactured and is highly applicable,\" says chemist Jeung Ku Kang.\"In particular, its high capacity and high stability, compared to existing technologies, could contribute to the commercialization of aqueous capacitors.\"Since the power source doesn't need to be a strong one, its rapid rate of charging might see it couple up neatly with photovoltaic cells or other micro-generating power sources.\nIt'll be a while before we see these kinds of devices outcompete the likes of lithium ion batteries, but cheap cells that can handle extreme conditions without catching fire will no doubt find a place in future portable technology.The low charge time is just an added bonus, though we've been promised charge-while-you-wait batteries for years now.The wonder-material graphene is keeping our hopes alive, with Samsung exploring its potential in materials that might see a smart phone being fully loaded with power in about 12 minutes.Beefed up capacitors could provide an altogether different approach, allowing us to charge up in less time than it takes to say \"I'm on 1 percent I'll call you right back!\"Who knows where quick-charge aqueous batteries will fit among these kinds of storage technologies. But given the rate at which cheap, power-hungry smart devices are spreading, we're going to need more like them.This research was published in Advanced Energy Material"
        ]
    },
    "10370": {
        "gold_standard": [
            "If you are looking to make a bone dagger - and come on, who isn't - scientists have your back.In a slightly creepy study, they've examined the structural properties of several and determined that the creme de la creme are those made out of human thigh bones.\nBone daggers are a common tool among the people of the Pacific Island of Papua New Guinea. They are often carved with decorative patterns, and used for hunting, fighting, and ceremonial purposes - and as a symbol of status and masculine fighting ability.Usually, they are made of the thigh bone of the cassowary, a large (and very aggressive) flightless bird - but once upon a time, some were made from human bones.These, according to researchers led by Dartmouth College in the US, were made from the thigh bones of respected men, and carried with them a special layer of prestige.And, based on a study of 11 bone daggers - five human, made by the people of the Sepik region, six cassowary - the ones that used to be human thighs are stronger.(Nathaniel Dominy)\"We used computed tomography to examine the structural mechanics of 11 bone daggers, 10 of which are museum-accessioned objects of art,\" the researchers wrote in their paper.\n\"We found that human and cassowary bones have similar material properties and that the geometry of human bone daggers results in higher moments of inertia and a greater resistance to bending.\"Data from finite-element models corroborated the superior mechanical performance of human bone daggers, revealing greater resistance to larger loads with fewer failed elements.\"Although most of the daggers were owned by the college's Hood Museum of Art and therefore could not be put under mechanical stress, the team purchased a 1970s cassowary dagger from a private art dealer on which they could perform tests.To simulate what would happen when a cassowary dagger is inserted into a human joint, the researchers embedded 20 percent of its length in a urethane casting. They then use a machine to push down on it until it broke, using that amount of force to establish a failure point"
        ]
    },
    "10504": {
        "gold_standard": [
            "There's a weird type of 'ice' found in the ocean that burns when exposed to a flame - and scientists think they've finally solved the mystery of how this strange substance forms under the sea.\nGas hydrates, also known as 'flammable ice', are formed as gas gets trapped in lattices of water molecules - and it really does look a lot like strange, pockmarked ice.This flammable ice is widely found inside minerals packed into clay-rich ocean sediments. The things is, the saltiness and pore size inside those minerals shouldn't be conducive to the formation of gas hydrates - and that's been puzzling experts until now.Two researchers from the Korea Advanced Institute of Science and Technology (KAIST) have used a complex experimental electrical field setup to examine how water and clay interact, and how gas hydrates could start to form in those ocean sediments.Scientists polarised water molecules to examine interactions with clay. (KAIST)\"Through this research, we gained better insight into the origin of gas hydrates occurrence in clay-rich sedimentary deposits,\" says one of the researchers, Tae-Hyuk Kwon.\n\"In the near future, we will soon be able to commercially produce methane gas from natural gas hydrate deposits.\"The scientists found that the negatively charged surfaces of clay materials were crucial in causing this flammable ice to form. The energy seems to partially break the hydrogen-bonded water clusters, lowering the thermal energy of the water molecules.Part of the reason scientists have been so keen to solve this mystery is that gas hydrates are seen as a viable alternative energy source \u2013 last year a team in China managed to extract natural gas from underwater flammable ice for the first time.If the technique can be perfected and commercialised, we could be looking at an abundant new source for gas energy. Reserves could be greater than all other fossil fuels combined, according to estimates.A block of gas hydrate (Wusel007/Wikimedia)Because flammable ice relies on such a precise combination of temperature and pressure, trying to keep the substance stable enough to successfully extract is quite a challenge: but research like this latest study should help with that.\nThe new findings will also prove useful as engineers try and deal with the problem of hydrates clogging up drilling pipes.Future research building on this study will need to examine the optimum conditions for the formation of gas hydrates, particularly in terms of the water molecule polarisation strength at different distances from the clay sediment.However, we now know far more than we did before about how this amazing substance comes into being.\"An understanding of the association between gas hydrates and clay minerals is required as it is expected to play a significant role in the exploitation of methane production from hydrate deposits and CO2 storage in oceanic sediments,\" conclude the researchers"
        ]
    },
    "10507": {
        "gold_standard": [
            "ACS Applied Materials & Interfaces Sometimes our phones end up in the toilet bowl, or laptops end up covered in tea. It happens.But if they were coated with an 'omniphobic' material, like the one created by a team of University of Michigan\u00a0researchers, your devices would be a lot more likely to come out unscathed.\n\"I have a 2-year-old at home, so for me, this particular project was about more than just the science,\" said one of the researchers, materials scientist Anish Tuteja.\"We're excited about what this could do to make homes and daycares cleaner places, and we're looking at a variety of possible applications in industry as well.\"This everything-proof material works by combining fluorinated polyurethane and fluorodecyl polyhedral oligomeric silsesquioxane (F-POSS).F-POSS has an extremely low surface energy, which means that things don't stick to it.The coating developed by the team stands out from other similar materials because of the clever way these two ingredients work together, forming a more durable product.\"In the past, researchers might have taken a very durable substance and a very repellent substance and mixed them together,\" Tuteja said.\n\"But this doesn't necessarily yield a durable, repellent coating.\"But these two materials have combined so well, they ended up with a durable coating that can repeal everything - oil, water, or anything else the researchers threw at it.\"The repellent and binder mix together well enough to make a clear coating, but there's a very small amount of phase separation between them,\"\u00a0says materials scientist Mathew Boban.\"That separation allows the F-POSS to sort-of float to the surface and create a nice repellent layer.\"Although this all sounds amazing, this incredible coating won't be available quite yet \u2013 F-POSS is rare and expensive right now, although that is changing as manufacturers scale up the product, which should lower the cost.We can't wait to see the end product \u2013 our phones and laptops are counting on it!The research has been published in\u00a0ACS Applied Materials & Interface"
        ]
    },
    "10542": {
        "gold_standard": [
            "Whether it's James Damore at Google or an overconfident lab partner in biology class, women in science, technology, engineering and math (STEM) careers are told time and time again that they are not as smart as their male counterparts.\nNow, a new study suggests that men aren't better at science, they just think they are - and that makes all the difference.The study, which examined an undergraduate biology class, suggests that men overestimate their own intelligence, while underestimating the brainpower of their female colleagues.At the same time, the study suggests women are plagued by feelings of academic self-doubt, even when their grades reveal they are just as smart.\"This echoes what has been previously shown in the literature; a review of nearly 20 published papers on self-estimated intelligence concluded that men rate themselves higher than women on self-estimated intelligence,\" the study concludes.In the study's undergraduate biology class, the average grade was 3.3, which means that statistically half of the students should be above the average and half below it.\nHowever, when students were asked where they sat in comparison to the class, the average male student thought he was smarter than 66 percent of the class, and the average female student thought she was smarter than 54 percent of the class.The students were then asked to rate their academic abilities in comparison to their closest classmate. When comparing themselves to just one other person, men thought they were smarter 61 percent of the time, while women thought they were smarter only 33 percent of the time.These differences were observed by the researchers even when they controlled for prior academic ability, which has been found to impact academic self-confidence.It's not clear exactly why men tend to overestimate their scientific abilities, while women tend to judge their intelligence much more harshly, but there are a few theories.\n\"Really bright girls often don't feel like they know something unless they very much understand it, whereas boys are more comfortable saying they understand something without having an actual deeper understanding,\" Ilana Seidel Horn, a professor of mathematics at Vanderbilt University, told NBC.The problem may also be rooted in the way science is taught in the classroom. For instance, studies have shown that greater self-confidence leads to greater participation, which in turn leads to greater learning and motivation.In a self-fulfilling cycle, lower self-confidence may be holding women back from speaking up or taking leadership roles in science class.\"More and more of these studies are painting similar pictures,\" said co-author Sara Brownell.\"Females are not participating as much in science class. They are not raising their hands and answering questions"
        ]
    },
    "10593": {
        "gold_standard": [
            "For many people, the best way to melt off stress after a hard day is to soak in a hot bath.The Japanese macaques \u2013 commonly referred to as \"snow monkeys\" \u2013 that draw tourists to Jigokudani Monkey Park feel the same way.\nAnd as a relaxation or de-stressing technique, a hot bath really works, according to a study of the monkeys newly published in the journal Primates.The macaques use the springs to warm up in winter, according to the researchers behind the study. And when they bathe, their stress hormone levels drop.To figure this out, Rafaela Takeshita and colleagues from Kyoto University picked a troop with 12 adult female macaques.The monkeys are the non-human primates who live the furthest north in the entire world.They do grow longer and thicker fur in the winter, but at least some also indulge in baths at hot springs in the park.The first time researchers spotted this behaviour was in 1963, when a young female was spotted in a spring at a hotel.Observations revealed that other monkeys did the same, though they stopped bathing as the weather warmed up by the end of March, indicating they primarily did this to stay warm.\nThe park decided it'd be more hygienic for the monkeys to have their own hot spring than to share one with humans, so they built one just for the macaques.By 2003, they'd observed that 31 percent of females regularly made use of the hot water.But cold isn't just uncomfortable. Humans release stress hormones when exposed to cold temperatures; monkeys do the same.Since hot baths have have been shown to help lower stress hormone levels in humans, Takeshita and co-authors thought the same might be the case for the macaques.Studying snow monkeysThe scientists tracked the monkeys throughout a winter and spring, regularly collecting their faeces to measure hormone levels.They observed that in general, the dominant females got more access to the hot springs, indicating that they treat the baths as a limited resource.\nGenerally, those females had higher levels of stress hormones, associated with greater aggression. (Over time the researchers also observed that stress levels for these monkeys were unaffected by visits from tourists.)But during the times that the macaques would bathe, especially in winter and when it got cold outside, stress hormone levels would drop.\"This indicates that, as in humans, the hot spring has a stress-reducing effect in snow monkeys,\" Takeshita said in a news release.\"This unique habit of hot spring bathing by snow monkeys illustrates how behavioural flexibility can help counter cold-climate stress, with likely implications for reproduction and survival.\"Next time you're feeling stressed, take a cue from a macaque and try a hot soak.This article was originally published by Business Insider"
        ]
    },
    "10673": {
        "gold_standard": [
            "Ecology Spreading your genes through procreation is a biological imperative, and for most animals, this requires, well, staying alive to actually produce babies.Not so for the wily stick insect!\u00a0Scientists have now discovered that even if a stick insect is eaten by a bird, it still has a second chance at producing offspring post mortem.\nA team led by researchers from Kobe University found that when a stick insect is swallowed by a bird, the hard-shelled eggs nestled within the insect's body can travel through the bird's digestive tract and out the other end without damage.Warm and cosy within the bird excrement, the eggs may even be able to hatch, birthing a new stick insect far away from its relatives.(Kobe University)If this sounds familiar, it's because many plants do this with seeds. And now it turns out that stick insects don't just look like plants, they also travel like plants.Similar to stick insects, plants aren't known for their ability to traverse great distances, which means they have to rely on something else to distribute their seeds.\nFor many plants, this mean relying on animals, which eat the plant's fruit and then later poop the seeds out intact thanks to their hard shell casing.The stick insect's bizarre form of gene flow is made possible by another unusual characteristic. Female stick insects are parthenogenic, which means that they can produce viable eggs without the need for fertilisation.When researchers fed eggs from three species of stick insects to a brown-eared bulbul bird (a common predator), they found between 5 and 20 percent of the eggs were excreted unharmed. Afterwards, one of the insect eggs successfully hatched in the bird excrement.The researchers note that this may not be the most frequent way stick insects get their eggs to be dispersed, as only a small percentage of the fully developed eggs in a female's stomach would end up intact - but they say it's important for the species nonetheless.\nEven if it's not the dominant way for stick insects to spread their genes, it has allowed them to turn death into a remarkable opportunity.If stick insect eggs are hardy enough to survive a trip through a bird's digestive tract, if they are viable without fertilisation, and if the insect born from these eggs can fend for itself, theoretically, they can be dispersed as far as their predators can fly.The researchers hypothesise that being eaten by birds is one of the ways that stick insects have so successfully expanded their habitat.\u00a0By hitching a ride from their avian predators, stick insects have been able to hop across islands and spread to remote corners of the globe.In fact, stick insects are so ubiquitous, they are currently found on every continent except Antarctica.\"Our next step is analysing the genetic structure of stick insects,\" said one of the team, biologist Kenji Suetsugu.\n\"Based on this we'd like to investigate whether similar genetic structure of stick insects can be found along birds' migration flight paths, and whether there are genetic similarities between stick insects and plants that rely on birds for seed distribution.\"With this information, the researchers will be able to track how bird dispersal has impacted the distribution and gene flow of stick insects.The study has been published in the journal Ecolog"
        ]
    },
    "10680": {
        "gold_standard": [
            "Scientists say they have determined the most likely place to find traces of ancient microbial life on Mars in future missions to the Red Planet.In a new 'field guide' for discovering fossils on Mars, researchers say iron-rich rocks located near the sites of ancient lakes should be the priority for upcoming visits to the Martian surface, because they are acting like mineral sanctuaries that could preserve signs of life from billions of years ago.\n\"There are many interesting rock and mineral outcrops on Mars where we would like to search for fossils, but since we can't send rovers to all of them we have tried to prioritise the most promising deposits based on the best available information,\" explains astrobiologist Sean McMahon from the University of Edinburgh in Scotland.Narrowing the field of focus isn't such a bad idea.After all, in over 2,100 days of exploration, NASA's current Curiosity rover has covered just 18 kilometres (11 miles), and while the upcoming Mars 2020 mission will enjoy unprecedented manoeuvrability, knowing the optimal rock targets in advance gives us the best chance of hitting Martian pay-dirt.The Jezero Crater river delta on Mars (NASA/JPL-Caltech/MSSS/JHU-APL)To that end, McMahon and his team reviewed scientific literature of rocks on Mars and the potential of their environments to preserve the remains of microbial organisms that could have once lived in them \u2013 based on what we know about fossils on Earth, and previous experiments replicating Martian conditions.\nThe findings suggest sedimentary rocks that formed in lake beds from compacted mud or clay are the most likely to contain fossils, due to their high iron and silica content.\"The Martian surface is cold, dry, exposed to biologically harmful radiation and apparently barren today,\" the authors explain in their paper.\"Nevertheless, there is clear geological evidence for warmer, wetter intervals in the past that could have supported life at or near the surface.\"Specifically, the team thinks rocks that formed between the Noachian and Hesperian periods of the Red Planet's geological past \u2013 roughly 4 to 3 billion years ago \u2013 could have held onto the vestiges of Martian life that may have lived when the planet was wet.\"We recommend that iron-rich lacustrine mudstones, especially those rich in silica, should be prioritised for biosignature exploration,\" the researchers writ"
        ]
    },
    "10721": {
        "gold_standard": [
            "arXiv Pluto may not be categorised as a planet any more, but it still holds plenty of fascination. For instance, how did the dwarf planet form, and why is it so different from the planets? By examining its chemical composition, researchers have come up with a new idea: Pluto is made of comets.\nAccording to the currently accepted model, planets are formed by the gradual accretion of smaller objects - and Pluto, situated right next to the Kuiper Belt asteroid field, has long been thought to have formed the same way. So that part is nothing new.But there are similarities between Pluto and Comet 67P/Churyumov-Gerasimenko that scientists from the Southwest Research Institute (SwRI) believe may not be coincidental. In particular, the nitrogen-rich ice in Pluto's Sputnik Planitia.Thanks to the Pluto probe New Horizons and Rosetta, the space probe sent to study Comet 67P, we have a new and unprecedented wealth of data about both Pluto and comets.\"We've developed what we call 'the giant comet' cosmochemical model of Pluto formation,\" said geochemist Christopher Glein of the SwRI's Space Science and Engineering Division.\n\"We found an intriguing consistency between the estimated amount of nitrogen inside the glacier and the amount that would be expected if Pluto was formed by the agglomeration of roughly a billion comets or other Kuiper Belt objects similar in chemical composition to 67P, the comet explored by Rosetta.\"Nitrogen on Pluto is akin to methane on Titan, or water on Earth - the key volatile responsible for shaping the dwarf planet's surface. Because of its low viscosity at Pluto's surface temperatures, nitrogen is able to flow like glaciers on Earth - eroding the bedrock and changing the shape of the landscape.Earth's atmosphere is around 78 percent nitrogen (our temperatures don't get as cold as Pluto, so it remains gaseous), but Pluto's is about 98 percent. So between the nitrogen ice and the nitrogen atmosphere, the dwarf planet has an unusually high proportion of it.Previously, scientists thought that maybe the nitrogen came from comets that landed on Pluto - but that model would not account for the sheer amount of it.\nIn addition to the comet model, the researchers also investigated a model whereby Pluto formed from very cold ices with chemical compositions similar to that of the Sun. By examining these models, they hoped to get a better understanding of Pluto's leaky atmosphere, to figure out how much nitrogen is escaping into nearby space.They also needed to reconcile the amount of carbon monoxide in Pluto's atmosphere, and neither model was able to explain how little there was.\"Our research suggests that Pluto's initial chemical makeup, inherited from cometary building blocks, was chemically modified by liquid water, perhaps even in a subsurface ocean,\" Glein said.It's also possible, under the cometary model, that the missing carbon monoxide is trapped, frozen under Pluto's surface. Because there are more explanations for the missing carbon monoxide under the cometary model, it seems more likely than the solar model, the researchers said.\nOf course, this is hypothetical at this point and, as the researchers put it, leads to \"an appreciation of many subsequent questions that must be addressed\" in future analyses, such as whether the abundance of nitrogen on Comet 67P is representative of other comets, and what role liquid water has played in the evolution of volatiles on Pluto.\"This research builds upon the fantastic successes of the New Horizons and Rosetta missions to expand our understanding of the origin and evolution of Pluto,\" said Glein.\"Using chemistry as a detective's tool, we are able to trace certain features we see on Pluto today to formation processes from long ago. This leads to a new appreciation of the richness of Pluto's 'life story,' which we are only starting to grasp.\"The paper has been accepted for publishing in the journal Icarus, and can be read on arXi"
        ]
    },
    "10749": {
        "gold_standard": [
            "Proceedings of the National Academy of Sciences Humankind is pathetically lightweight in comparison to the mass of almost all other living things on Earth, but while our bodies (and thinking) may be tiny, our crushing footprint is not.\nThe most comprehensive study ever of the weight of all living biomass on the planet has discovered humans account for only about 0.01 percent of life on Earth \u2013 but despite our physical insignificance compared to the teeming masses around us, history shows there's no doubt over whose dominion this is.\"I would hope this gives people a perspective on the very dominant role that humanity now plays on Earth,\" biologist Ron Milo from the Weizmann Institute of Science in Israel told The Guardian.\"It is definitely striking, our disproportionate place on Earth.\"Milo and fellow researchers spent three years combing the existing scientific literature on the planet's biomass to provide the most up-to-date and comprehensive estimate on the mass of all the kingdoms of life.In terms of carbon content \u2013 which means we don't need to factor in the varying water masses of different kinds of animals, plants, and other life forms \u2013 the team's census suggests the total biomass of the planet amounts to approximately 550 gigatonnes of carbon (Gt C).\nOf this, approximately 450 Gt C, or 80 percent of the total biomass, is made up of plants, which far outweighs the mass of anything else living on the planet; bacteria\u00a0come in second, at about 70 Gt C (15 percent).Then we hit fungi. At about 12 Gt C, they're about six times more abundant than all animal life on the planet, which comes after archaea (7 Gt C) and protists (4 Gt C).In fact, animals only account for a mere 2 Gt C, and humans make up only an incredibly tiny fraction of that. And yet, the overall animal landscape has been irrevocably altered by human design.While the biomass of humans is only about 0.06 Gt C, we're almost 10 times more abundant than wild mammals, which represent only 0.007 Gt C.But there's a different kind of mammal, which \u2013 by uniquely serving human needs \u2013 has also come to dominate the rest of the animal kingdom: livestock.\nLivestock, mostly cattle and pigs, makes up about 60 percent of all mammals on Earth (at 0.1 Gt C).When it comes to bird life, the same picture emerges, with the biomass of domesticated poultry being about three times greater than that of wild birds.\"When I do a puzzle with my daughters, there is usually an elephant next to a giraffe next to a rhino,\" Milo told The Guardian.\"But if I was trying to give them a more realistic sense of the world, it would be a cow next to a cow next to a cow and then a chicken.\"It didn't use to be this way, of course.Prior to the domestication of livestock and the innovation of agriculture \u2013 and the Industrial Revolution on their heels \u2013 the natural landscape would have looked much different.The researchers acknowledge it is difficult to accurately estimate the pre-human biomass of animals, but their analysis suggests human civilisation has slashed the total biomass of wild mammals by as much as 85 per cent, and has cut plant biomass in half.\nThis inadvertent culling has had a massive effect on the overall biosphere, leading to a situation where scientists say we're now in the midst of a mass extinction event that is almost without precedent.While entirely regrettable, our actions also constitute a frighteningly outsized effort for a delicate species of bipeds that only makes up a hundredth of a percent of the world's living things.\"The fact that the biomass of fungi exceeds that of all animals sort of puts us in our place,\" evolutionary biologist James Hanken from Harvard University, who wasn't involved in the study, told AP.If only that were true.The findings are reported in Proceedings of the National Academy of Science"
        ]
    },
    "10839": {
        "gold_standard": [
            "Sometimes mushroom hunting can yield much more than you bargain for. In the case of a forest delver in Minnesota, the discovery was straight out of a twisted tale on mutant creatures - a deceased, two-headed deer fawn.\n\"It's amazing and extremely rare,\" says deer ecologist Gino D'Angelo of the University of Georgia, formerly of the Minnesota Department of Natural Resources, who studied the tiny carcass.\"We can't even estimate the rarity of this. Of the tens of millions of fawns born annually in the US, there are probably abnormalities happening in the wild we don't even know about.\"These fawns turned out to be conjoined twins - the first of their kind known to have been carried to term and birthed. All other examples of such conjoined twins have only ever been seen in utero.Conjoined twins are more common in domesticated animals, such as sheep and cows, and even kittens, occurring only rarely in wild animals. Of only 19 cases of conjoined twins in wildlife in scientific literature between 1671 and 2006, only 5 have been deer.\nIn white-tailed deer, only two other cases of conjoined twins have been reported, both fetuses that were not actually brought to term. The exact causes for conjoined twins are unknown.The white-tailed deer fawns were originally found two years ago, in May 2016, in the forest of southeastern Minnesota - clean, dry and only recently deceased. It was sent to the Minnesota Department of Natural Resources and frozen until it could be studied in detail.The research team conducted a full necropsy, MRI and CT scan of the body at the University of Minnesota's Veterinary Diagnostic Laboratory.(D'Angelo et al./The American Midland Naturalist)They found that the female fawns had one body, but the spine diverged at the thorax into two, so that there were two separate necks and two separate heads.\nThe lungs, when placed in water, sank straight to the bottom - confirming that they had never breathed air and were stillborn instead. And their anatomy shows that, sadly, they were never destined to make it, anyway.There were two separate gastrointestinal tracts, although only one was fully connected all the way to the anus. They also had two separate hearts inside a shared pericardial sac, and extra spleens. However, they only shared one liver, and it was malformed.\"Their anatomy indicates the fawns would never have been viable,\" D'Angelo said.\"Yet, they were found groomed and in a natural position, suggesting that the doe tried to care for them after delivery. The maternal instinct is very strong.\"If you want to see the fawns, and you're in the area, they will be on display at the Minnesota Department of Natural Resource's headquarters in St. Paul, Minnesota.The paper describing the find has been published in\u00a0The American Midland Naturalis"
        ]
    },
    "10891": {
        "gold_standard": [
            "The carbon footprint of tourism is about four times larger than previously thought, according to a world-first study published today in Nature Climate Change.Researchers from the University of Sydney, University of Queensland and National Cheng Kung University - including ourselves - worked together to assess the entire supply chain of tourism.\nThis includes transportation, accommodation, food and beverages, souvenirs, clothing, cosmetics and other goods.Put together, global tourism produces about 8 percent of global greenhouse gas emissions, much more than previous estimates.Adding it all upTourism is a trillion-dollar industry, and is growing faster than international trade.To determine the true emissions produced by tourism, we scanned over a billion supply chains of a range of commodities consumed by tourists. By combining a detailed international trade database with accounts tracking what goods and services tourists bought, we identified carbon flows between 160 countries from 2009 to 2013.Our results show that tourism-related emissions increased by around 15 percent over that period, from 3.9 gigatonnes (Gt) of carbon-dioxide equivalent (CO\u2082-e) to 4.5Gt.\nThis rise primarily came from tourist spending on transport, shopping and food.(Arunima Malik/Ya-Yen Sun)We estimate that our growing appetite for travel and a business-as-usual scenario would increase carbon emissions from global tourism to about 6.5Gt by 2025.This increase is largely driven by rising incomes, making tourism highly income-elastic and carbon-intensive.Whose responsibility is it?In the study, we compared two perspectives for allocating responsibility for these emissions: residence-based accounting and destination-based accounting. The former perspective allocates emissions to the country of residence of tourists, the latter to the country of destination.\nPut simply, are tourism-related carbon emissions the responsibility of travellers or tourist destinations?If responsibility lies with the travellers, then we should identify the countries that send the most tourists out into the world, and find ways to reduce the carbon footprint of their travel.On the other hand, destination-based accounting can offer insights into tourism spots (like popular islands) that would benefit most from technology improvements and regulations for reducing the carbon footprint of tourism.Tracking emissions under destination-based accounting over a specific period could help researchers and policymakers to answer questions about the success of incentive schemes and regulations, and to assess the speed of decarbonisation of tourism-related sectors.So how do countries rank under the two accounting perspectives?\nThe United States is responsible for the majority of tourism-related emissions under both perspectives - many people travel both from and to the US - followed by China, Germany and India.But on a per-capita basis, the situation looks rather different. Small island destinations have the highest per-capita destination-based footprints. Maldives tops the list \u2013 95% of the island's tourism-related emissions come from international visitors.Tourists are responsible for 30-80% of the national emissions of island economies. These findings bring up the question of the impact of tourism on small island states.Islands as tourist destinationsSmall islands depend on income from tourists. At the same time, these very tourists threaten the native biodiversity of the islands.Small island states typically do not have the capacity to embrace technology improvements due to their small economies of scale and isolated location"
        ]
    },
    "10892": {
        "gold_standard": [
            "If you ever get the feeling that we're going around in circles, you're right, but the cosmic holding pattern we're stuck in is probably a little bigger than what you had in mind.\nScientists have confirmed a longstanding hypothesis that Earth's orbit is warped by the gravitational pull of Jupiter and Venus in an epic cycle that repeats regularly every 405,000 years.\"It's an astonishing result because this long cycle, which had been predicted from planetary motions through about 50 million years ago, has been confirmed through at least 215 million years ago,\" says geomagnetics researcher Dennis V. Kent from Rutgers University.\"Scientists can now link changes in the climate, environment, dinosaurs, mammals, and fossils around the world to this 405,000-year cycle in a very precise way.\"For decades researchers have studied this phenomenon \u2013 an example of what's called a Milankovitch cycle \u2013 which makes our virtually circular orbit around the Sun shift to one that's about 5 percent elliptical, before resuming its circular trajectory.A fresh rock core (Columbia University)But, before now, evidence for how far back it extended into Earth and the Solar System's history was disputed.\nThanks to ancient rocks drilled from deep under Arizona's Petrified Forest National Park, though, we're getting a clearer picture.In 2013, Kent and his team began drilling rock cores in excess of 1,500 feet long (457 metres) from a butte in the park, analysing them for radioisotopes that indicated their age and evidence of reversals in the polarity of the Earth's magnetic field.When they compared them with sediment samples from the Newark basin \u2013 a former prehistoric lake that spanned most of New Jersey \u2013 they found that the 405,000-year cycle is the most regular astronomical pattern linked to the Earth's annual turn around the Sun, which dates as far back as 215 million years ago, to the Triassic period.\"There are other, shorter, orbital cycles, but when you look into the past, it's very difficult to know which one you're dealing with at any one time, because they change over time,\" says Kent, who is also affiliated with Columbia University.\n\"The beauty of this one is that it stands alone. It doesn't change. All the other ones move over it.\"By confirming that this steady, metronome-like 405,000-year cycle dates back to a time before even the reign of the dinosaurs, the findings have implications to innumerable fields of research \u2013 potentially affecting how we interpret fossils and trace the evolution of life forms, to understanding more about planetary movements.But perhaps the most topical area of science this could help us understand is pinning down how Jupiter and Venus \u2013 incredibly distant though they are \u2013affect Earth's climate, and how it inevitably undergoes heating and cooling changes over vast timeframes.Not that anybody should be pointing to this study and insisting our planet's current climate woes are due to anything but human activity, the authors point out, as the multi-millennial pace of this Milankovitch cycle's effects aren't something we could notice in our short lifetimes.\n\"It's pretty far down on the list of so many other things that can affect climate on times scales that matter to us,\" says Kent.\"On the other hand, all the CO2 we're pouring into the air right now is the obvious big enchilada. That's having an effect we can measure right now. The planetary cycle is a little more subtle.\"The findings are reported in PNAS"
        ]
    },
    "10950": {
        "gold_standard": [
            "An adorable family of great horned owls (Bubo virginianus) has become an internet sensation after they were discovered nesting on the window of an office building in Reno, Nevada.\n\"I heard this racket outside my window,\" recalled Jim Thomas, a hydrologist at the Desert Research Institute.Looking out onto the window ledge, Thomas saw a pair of great horned owls fighting off some ravens for the prime territory.Soon enough, the male and female owl couple became famous around the office. But then, something odd happened: another female owl showed up.The office watched in fascination as the two female owls began to lay eggs along the rocky window ledge.\u00a0While the females were nesting, the male owl would bring back tasty treats from his hunting expeditions, like mice and an old rabbit.The behavior from these owls isn't just unusual for an office environment, it's also completely unheard of in nature - mainly because great horned owls are monogamous.Christian Artuso, an ornithologist with Bird Studies Canada, told National Geographic that this is the first time polygyny - which is when one male mates with more than one female - has ever been observed in the species.\nThe behaviour is even more confusing when considering that most great horned owls are solitary creatures.\u00a0The species, which is quite territorial, doesn't usually flock together and they certainly don't nest near each other.Still, the behaviour isn't completely out of the question for other owl species. For instance, scientists have noted instances of polygyny in\u00a0barn owls and Eurasian eagle owls.But overall, the behaviour is still very rare among raptors. Because unless there is bountiful food, Artuso explained, a male will generally not be able to provide two females with enough sustenance.David Catalano, an ornithologist with the Nevada Department of Wildlife, agreed.\u00a0\"Very, very odd,\" he told National Geographic.Realising how important the discovery was, Thomas' office set up a webcam to broadcast live footage of the owls. The owl family has since become an internet sensation.\n\"It's been quite frankly amazing,\" said Thomas. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\">It gets even more amazing. The second female owl did not look after her eggs well enough, and they failed to hatch.So, when the first female's eggs hatched, the second female began caring for the two owlets, offering them shelter and food \u2013 despite the fact that she was not their biological mother.Catalano said this is likely a classic case of misdirected parenting. In other words, the second owl mistook the owlets for her own.Although, there is another explanation. The two female birds could also be related, maybe as sisters or as mother-daughter.\nThis could explain why the two birds generally get along well together. Like most family members, the two birds do get into \"some pretty good battles\" \u2013 although, according to Catalono, in general \"they've co-parented quite well.\"Still, without a genetic test, all of this is guesswork.Never mind the odd family set up, the owlets appear to be doing just fine.One of them has already flown out of the nest, landing safely below the ledge. The other owlet will soon follow.\"It could be any day now,\" Catalano said.And with that, the three adult owls will be empty nesters"
        ]
    },
    "10977": {
        "gold_standard": [
            "Geophysical Research Letters The Gulf of Oman plays host to the largest and thickest \"dead zone\" in the world, but scientists have struggled to study it intensively due to piracy and geopolitical tensions in the region.\nNow, thanks to an alleviation in regional conflict, scientists have finally been able to use remote-controlled submarines to reveal the full extent of the area's dead zone.The data has revealed that this particular dead zone is about the size of the US state of Florida, and it's still growing.Dead zones, or Oxygen Minimum Zones (OMZs), are areas largely devoid of oxygen, and in the ocean, they are naturally occurring between 200 and 800 meters deep.The new research has confirmed that the largest OMZ in the world is located in the Gulf of Oman \u2013 which is actually a strait, bordered by Iran, Pakistan, Oman, and the UAE \u2013 encompassing\u00a0almost the entire 165,000 square kilometres (63,700 square miles) that make up the ocean region.But this isn't all the study found.Using two submarines in combination with computer simulations, scientists have revealed that since the 1990s, the gulf's dead zone has experienced a \"dramatic increase\" in both size and severity.\nAccording to the recent data, the dead zone is now made up of entirely anoxic or suboxic conditions, which is when no oxygen or very low oxygen is present, respectively.\"Our research shows that the situation is actually worse than feared. The area of dead zone is vast and growing. The ocean is suffocating,\" lead researcher Bastien Queste said in a statement.\"All fish, marine plants, and other animals need oxygen, so they can't survive there. It's a real environmental problem, with dire consequences for humans, too, who rely on the oceans for food and employment.\"The growing OMZ also spells bad news for climate change.When oxygen is absent, the chemical cycling of nitrogen changes dramatically. This means that in OMZs, the underlying nitrogen cycle is altered so that it produces more nitrous oxide \u2013 a greenhouse gas that is\u00a0roughly 300 times more potent\u00a0than carbon dioxide.\nThe problem is made even worse by the fact that the growth of OMZs is strongly linked to climate change. The researchers predict that as the oceans grow warmer, their capacity to hold oxygen will slowly decrease, and these dead zones will continue to spread.\"There are a number of things that could have contributed to the shift\u2014the most major of which is very much tied to climate change,\" said Queste, a marine biogeochemist from the University of East Anglia's School of Environmental Sciences.\"The oxygen levels are determined by the balance of oxygen supply from the atmosphere, mixed in by waves, eddies, and just general energetic mixing near the surface, and oxygen loss, primarily the oxygen being 'breathed' by bacteria living on and eating sinking decomposing organic matter.\"The situation will only be exacerbated by fertiliser and sewage running off the land and into the seas.\n\"Increase in land use, larger cities, and increased pollution will also lead to more nutrients, such as nitrogen and phosphorus, entering the water, which promotes more algae that later sink and get consumed by the bacteria,\" said Queste.\"It's an incredibly intricate system with many moving parts,\" he added.Using computer simulations of ocean oxygen, the study predicts a decrease in oxygen over the next century and growing OMZs around the world.The next step for Queste and his team is to figure out whether this is due to the overall supply of oxygen decreasing, or an increased consumption of oxygen in the region.\"Another interesting question is now that the Gulf of Oman is clearly consuming oxygen faster than it is replenished, how much of that is exported to the Arabian Sea and making the wider Arabian Sea OMZ extend and grow even more?\" he asked.The study has been published in Geophysical Research Letter"
        ]
    },
    "3246": {
        "gold_standard": [
            "New touchscreen technology that has the potential to improve display transparency and sensitivity has been developed by researchers in Switzerland, thanks to a specialised microscopic 3D printing technique.\u00a0If these new nano-sized, gold and silver grid materials can be made to work commercially, the research could end up influencing future generations of smartphones, tablets, and wearables.\nThe new printing technique is called Nanodrip, and it uses a system similar to those in household inkjet printers to push out grids of electrohydrodynamic ink (ink that can be electrically charged). These nanowalls of electrodes are made with gold or silver rather than the traditional indium tin oxide to substantially improve the overall conductivity of the material, while making it more transparent.\u00a0The addition of the third dimension and the application of the 3D printing technique are key: gold and silver are not transparent, but by building up grids of nanowalls that are 80-500 nanometres thick, the team from the ETH Zurich University has\u00a0produced a material with the required level of conductive performance and transparency.\u00a0\"If you want to achieve both high conductivity and transparency in wires made from these metals, you have a conflict of objectives,\" said project leader Dimos Poulikakos. \"As the cross-sectional area of gold and silver wires grows, the conductivity increases, but the grid's transparency decreases.\"The droplets produced by the Nanodrip process are about 10 times smaller than the aperture itself, pushing out microscopic metal nanoparticles in a solvent mixture. As the solvent evaporates, the three-dimensional gold or silver structure remains. By balancing the composition of the metallic ink with the charge of the electromagnetic field used to draw it out of the printing device, the researchers were able to create incredibly small droplets.\n\"Imagine a water drop hanging from a tap that is turned off. And now imagine that another tiny droplet is hanging from this drop - we are only printing the tiny droplet,\" said Poulikakos.As you might expect, the next challenge is in proving that the process can be upscaled and applied on an industrial level. But the team is confident that the Nanodrip technology will eventually work out to be more cost-effective than current touchscreen manufacturing processes. It could also be useful in the production of solar cells and other scenarios where transparent electrodes are required.\u00a0The research has been published in the journal Advanced Functional Materials"
        ]
    },
    "5301": {
        "gold_standard": [
            "Researchers are trying to figure out why humpback whales keep going out of their way to save different creatures from becoming orca meals.In fact, some have witnessed humpbacks intervening in orca hunts to save other mammals so many times \u2013 115 to be exact \u2013 that they now suggest the protective behaviour could be ingrained in the whales, though no one is completely sure why.\n\"Anecdotes have been passed down for centuries about dolphins at sea coming to the aid of distressed conspecifics [members of the same species], as well as other species, including humans,\" an international team of researchers, led by Robert Pitman from the US National Marine Fisheries Service,\u00a0say in a new review of the humpback behaviour.\"However, more recent observations, including popular accounts and videos posted on the internet, suggest that a baleen whale \u2013 the humpback whale (Megaptera novaeangliae) \u2013 also approaches marine vertebrates in distress, most notably, when they are being attacked by killer whales (Orcinus orca).\"To understand how weird this is, we need to tell you one of the stories. According to Bryan Nelson from Mother Nature Network, one of the most ridiculous humpback rescues happened back in 2009, when a pod of orcas was hunting a seal trapped on\u00a0a sheet of ice near Antarctica.After the orcas managed to knock the seal off the ice, researchers were shocked to see a gigantic humpback whale rise up from under the seal, blocking the orcas.\nWhile this seems like it could just be a fluke (see what we did there?) the humpback actually turned over, lifting its belly above water, and placed the seal on top of it, protecting it from the predators.This example \u2013 while being just straight-up weird \u2013 is also\u00a0evidence that humpbacks know exactly what they're doing when they rescue these creatures,\u00a0says Pitman, who made the observation.Now researchers are wondering where this behaviour stems from. After all, it's not like humpbacks really gain anything by being the good guys of the sea.\"More often, though, humpbacks approached MEKWs (mammal-eating killer whales) that were attacking prey species that were clearly not humpbacks (e.g. a grey whale calf with its mother, a seal hauled out on an ice floe, a sunfish), and although the humpbacks faced little risk of serious injury, they also gained no obvious benefits for their time and energy spent,\"\u00a0the team writes in\u00a0Marine Mammal Science"
        ]
    },
    "5336": {
        "gold_standard": [
            "Jupiter's frozen moon Io is a pretty bleak place, with a toxic atmosphere and the most active volcanoes of any known body in the Solar System.But it's somehow managed to get\u00a0even more miserable, because scientists just watched its atmosphere collapse - something that apparently happens every single day as Jupiter eclipses it.\nAstronomers have long suspected that Io's already thin atmosphere deflates as the shadow of the gas giant passes over it daily, but no one had ever been able to see this happening until now.\"This research is the first time scientists have observed this remarkable phenomenon directly, improving our understanding of this geologically active moon,\" said lead researcher Constantine Tsang from the Southwest Research Institute in Colorado.The study shows that for 2 hours every day, Jupiter eclipses the moon with its giant shadow, causing the temperature to plummet and Io's sulphur dioxide-rich atmosphere to freeze and collapse to the surface.When the planet moves out of Jupiter's shadow, the Sun gradually heats Io's surface temperature up from about \u2013270 degrees Fahrenheit (\u2013168 degrees Celsius)\u00a0to \u2013235 degrees Fahrenheit (\u2013148 degrees Celsius), and the sulphur dioxide returns to the atmosphere as gas.\nBut then the whole cycle repeats again the next day, and seeing as a day on Io lasts around 1.7 Earth days, the atmosphere is deflating and reflating all the time.\"This confirms that Io's atmosphere is in a constant state of collapse and repair, and shows that a large fraction of the atmosphere is supported by sublimation of SO2\u00a0[sulphur dioxide]\u00a0ice,\" said one of the team, John Spencer. \"We've long suspected this, but can finally watch it happen.\"The team was able to figure this out using the Gemini North telescope in Hawaii, in addition to a long-range spectrograph, which was capable of monitoring the composition of the moon's atmosphere.Using this combination to measure the electromagnetic signatures coming off Io in real-time, the team could show that the sulphur dioxide content drops off daily during Jupiter's eclipse.\nThe findings have been published in the Journal of Geophysical Research.Perhaps the most exciting part of all is that\u00a0most of Jupiter's 67 known moons - and the punishment the gas giant unleashes on them - remain a mystery to us.But now that we have our own probe, Juno, in orbit around the planet, we'll hopefully get some more insight into the strange behaviour occurring in the neighbourhood.It's still early days for the mission, but we've already heard creepy AF sounds coming from around Jupiter, and have been sent this visible-light photo of the gas giant with Io, Europa, and Ganymede:NASAWe can't wait for more strangeness. Stay tune"
        ]
    },
    "5346": {
        "gold_standard": [
            "The Journal of Experimental Zoology The female orgasm has been shouldering its 'mysterious' reputation for centuries. The male orgasm is simple to understand - it quite literally facilitates human reproduction.\nWhy the female orgasm exists, and how it survived millions of years of evolution is a whole lot less clear, but a pair of evolutionary biologists think they might finally have the answer.It might not feel like it right now, as you slump over your computer screen and feel annoyed about your various aches and pains and why you're always tired, but your body represents the most effective version of the human species that has ever existed.Every part of you is there for a reason - your ears hear sounds, your kidneys process waste, and your body hair helps regulate your internal temperature.\u00a0Even the parts that don't play any discernible role other than taking up space - your wisdom teeth, appendix, and tailbone - are there for a reason. Not because we need them, but because they're not 'costly' enough to have been phased out by natural selection through the millennia of human evolution.\nUnlike wisdom teeth, the female orgasm still serves plenty of important roles, particularly in terms of strengthening intimate relationships, and at the most basic level, it's a source of free, healthy, good old-fashioned pleasure.But with all the parts that have to come together to achieve an awesome combination of muscle contractions, hormone release, and intense pleasure - which only occurs 69 percent of the time\u00a0in the average heterosexual encounter - it's a lot of work, evolutionarily speaking, for a bit of fun.\u00a0Now, evolutionary biologists Mihaela Pavli\u010dev from the Cincinnati Children's Hospital and G\u00fcnter Wagner from Yale University have come up with a new hypothesis that could explain\u00a0why the\u00a0female orgasm came to be\u00a0- it might once have been as psychologically vital to human reproduction as the male orgasm is now.\"It is important to stress that it didn't look like the human female orgasm looks like now,\" Pavli\u010dev told Nicola Davis at The Guardian. \"We think that [the hormonal surge] is the core that was maybe modified further in humans.\"\nPavli\u010dev and Wagner decided to look at the female orgasm in the context of other placental mammals. In rabbits and cats, hormonal surges also occur during sex, but instead of imparting pleasure, their role is to signal to the ovaries to release eggs - something known as male-induced ovulation.While rabbits and cats only release an egg during sex, in humans, our eggs are released spontaneously each month - and not because of a male-induced\u00a0hormone signal.\u00a0But in tracing the history of ovulation through the mammalian evolutionary tree, Pavli\u010dev and Wagner found that male-induced ovulation actually existed earlier than spontaneous ovulation, and pinpointed its origin in a common ancestor of primates and rodents that lived some 75 million years ago.\"That, they say, suggests that human female orgasm could have its roots in a mechanism for the release of eggs during sex - a mechanism that became redundant with the evolution of spontaneous ovulation, with female orgasm potentially going on to acquire other roles,\" says Davis.\nInterestingly, the position of the clitoris in women today supports this hypothesis, the researchers say, because when male-induced ovulation was the norm, the clitoris was located inside the vagina, and has since moved outside, as Carl Zimmer explains for The New York Times:\n\"When early mammals mated, the clitoris could send signals to the brain, triggering hormones that released an egg. Once the egg became fertilised, the hormones may have helped ensure it became implanted in the uterus.\"\nOnce spontaneous ovulation kicked in for humans, the clitoris moved away from this position, so as not to confuse the body with conflicting signals. \"You don't want to have the old signal sending noise at the wrong time,\" Wagner told Zimmer.Of course, this is just an hypothesis for now, and it will need to be debated by other scientists and supported by evidence before it can rise above the dozens of other hypotheses about the female orgasm that have failed to achieve consensus.\nAnd, as Sarah Emerson points out at Motherboard, this whole hypothesis is based on us trying to equate the function of the female orgasm with the function of the male orgasm, and that could be sending us down the wrong road entirely.Maybe it doesn't need to have an evolutionary purpose at all, as Elisabeth A. Lloyd, a philosopher at Indiana University argues.\u00a0Maybe like nipples, the female orgasm evolved alongside the male orgasm, one version ending up with a very strong evolutionary purpose, the other, not so much.\u00a0\"It all seems to be rather purposeless - except for the enjoyment, obviously,\" she told The Guardian. \"It doesn't mean it is not important, it just means it doesn't have an evolutionary purpose.\"The study has been published in\u00a0The Journal of Experimental Zoolog"
        ]
    },
    "5358": {
        "gold_standard": [
            "The beautiful gullies we see on Mars today probably aren't being formed by flowing water, NASA has announced.Until now, liquid water was one of the leading candidates thought to be carving out the distinctive channels along the Red Planet's surface, but researchers say the latest data rules out that possibility.\nIt's important to note that these gullies are distinctive from the 'recurring slope lineae' (or RSL) that were discovered on the surface of Mars last year.RSL look like dark streaks, and they form during the warmer months and fade away in winter. Scientists have found strong evidence - in the form of hydrated salt - that those are\u00a0caused by flowing water.\u00a0Gullies, on the other hand, occur between 30 and 50 degrees latitude in both the northern and southern hemispheres, and are more of a deep 'channel-like' structure.They\u00a0were first discovered back in 2000,\u00a0getting everyone excited about the presence of liquid water on Mars, because they looked a lot like gullies here on Earth - which we know are formed by liquid.But, back in 2014, NASA found evidence that these gullies were more likely formed by the seasonal freezing of carbon dioxide, not liquid water after all, and it was unlikely that there would be enough water on the surface of the Red Planet to carve something like them out.\nStill, scientists have remained divided on the issue, and seeing as no rovers have gotten close enough to analyse the minerals present at the sites, we haven't had any definitive evidence either way.But new data from the Mars Reconnaissance Orbiter (MRO) adds further\u00a0weight\u00a0to the hypothesis that these channels weren't carved out by water, as much as we\u00a0all love the idea of rivers flowing across the Red Planet.To figure this out, researchers from Johns Hopkins University examined high-resolution data on more than 100 gully sites across Mars.\u00a0That data came from the MRO's on-board spectrometer, known as CRISM, which is able to perform chemical analyses by measuring the wavelengths of electromagnetic radiation being emitted by a sample.They were looking for any trace of water or its by-products near the gully, but failed to find any - making it very unlikely that water played a role in making them.\n\"The findings showed no mineralogical evidence for abundant liquid water or its by-products, thus pointing to mechanisms other than the flow of water - such as the freeze and thaw of carbon dioxide frost - as being the major drivers of recent gully evolution,\" the team explains in a press release.But that doesn't mean water was never involved, simply that it hasn't been involved in recent history.\"On Earth and on Mars, we know that the presence of phyllosilicates - clays - or other hydrated minerals indicates formation in liquid water,\" said study leader Jorge N\u00fa\u00f1ez.\"In our study, we found no evidence for clays or other hydrated minerals in most of the gullies we studied, and when we did see them, they were erosional debris from ancient rocks, exposed and transported downslope, rather than altered in more recent flowing water.\"\n\"These gullies are carving into the terrain and exposing clays that likely formed billions of years ago when liquid water was more stable on the Martian surface,\" he added.So, we still can't say for sure what formed these gullies, but we've now ruled out one hypothesis. And hopefully as we get more data we'll have a better idea of the\u00a0current geological processes shaping the surface of Mars\u2026 especially seeing as we hope to live there one day.The research has been published in Geophysical Research Letters"
        ]
    },
    "5391": {
        "gold_standard": [
            "According to the latest figures, levels of atmospheric carbon have officially surpassed 400 parts per million (ppm), and there's little hope of returning them to safe levels - the situation is now permanent.\nWhat's the big deal about 400 ppm? Well, the 'safe' level of CO2 in the atmosphere is considered to be 350 ppm, and the last time Earth experienced levels that were consistently this high was roughly 4 million years ago. That means humans have literally never experienced CO2 like this before.According to researchers at the Scripps Institution of Oceanography, the CO2 value for September 2016 will definitely be above 400 ppm, and will likely be around 401 ppm. And here's the thing - September typically has the lowest atmospheric CO2 levels of the year.\"Is it possible that October 2016 will yield a lower monthly value than September and dip below 400 ppm? Almost impossible,\" Ralph Keeling, director of the Scripps CO2 Program, writes in a blog post.Keeling says that by November this year, we could be pushing towards new highs, and perhaps even breaking the 410 ppm barrier.\n\"[I]t already seems safe to conclude that we won't be seeing a monthly value below 400 ppm this year - or ever again for the indefinite future,\" he adds.Even if, by some miracle, we all stopped emitting carbon dioxide tomorrow, it would take decades to get us back below the 400 ppm threshold - and we all know that's never going to happen.\"At best (in that scenario), one might expect a balance in the near term, and so CO2 levels probably wouldn't change much - but would start to fall off in a decade or so,\" Gavin Schmidt, NASA's chief climate scientist, told Brian Kahn at Climate Central.\u00a0\"In my opinion, we won't ever see a month below 400 ppm.\"For years now, scientists have been predicting that we'd hit the 400 ppm threshold and eventually tip over. Back in 2013, the Mauna Loa Observatory in Hawaii - described as the world's \"gold standard\" carbon dioxide observatory - hit the 400 ppm mark, and gradually, all other observing stations followed suit.\nIn May 2016, the world collectively passed the 400 ppm threshold, with the South Pole Observatory in Antarctica being the last to clear 400 ppm.\u00a0And this September, which should have been our low point for the year, failed to deliver, and now we're stuck with this mess until we can figure out how to significantly decrease our emissions.So when was the last time the planet had CO2 levels like this? Analysis of carbon levels in ice cores can give us indications of atmospheric CO2 as far back as 800,000 years ago, and scientists have estimated that it's \"inconceivable\" that they would have been much above 300 ppm at that time.According to\u00a0David Etheridge, principal research scientist at Australia's CSIRO,\u00a0analysis of sea sediments can push our estimates of historic CO2 levels back to about 2 million years ago. Based on these values, scientists have created climate models that give us an idea of what conditions on Earth were like tens of millions of years ago.\nAs\u00a0Graham Readfearn reported for The Guardian earlier this year, a 2009 study in Science found the last time in Earth's history that atmospheric CO2 levels were this high for a sustained period was between 15 and 20 million years ago.\u00a0More recently,\u00a0a 2011 study in Paleoceanography found that atmospheric CO2 levels could have been comparable to today's levels much later than that - between 2 and 4.6 million years ago.Regardless of whether Earth has experienced these levels 15 or 4 million years ago, humans have never been around to experience them until now. And that means there's really no telling what's going to happen next.With July and August being the two hottest months on record EVER, let's hope Elon Musk's plans for Mars domination\u00a0can give humanity a Plan B soon"
        ]
    },
    "5454": {
        "gold_standard": [
            "Geophysical Research Letters NASA's Cassini spacecraft just spotted a mysterious ice cloud over Saturn's largest moon, Titan, and its appearance challenges everything we thought we knew about the moon's atmosphere.\nFirst spotted decades ago by NASA's Voyager 1 spacecraft, the cloud has reappeared for the second time, and it's somehow made up of compounds that barely exist in Titan's atmosphere. So where did it come from?\"The appearance of this ice cloud goes against everything we know about the way clouds form on Titan,\" said lead researcher Carrie Anderson from NASA's Goddard Space Flight Centre.Back when Voyager 1 first spotted this cloud in Titan's stratosphere during its 1980-81 Saturn flyby, scientists determined that it was formed from a compound of carbon and nitrogen called dicyanoacetylene (C4N2).C4N2 is a key compound for Titan, because it's part of a unique 'chemical cocktail' that gives the moon its hazy, burnt-orange atmosphere.\u00a0But there was a problem - up in the stratosphere where the C4N2 cloud had formed, scientists detected less than 1 percent of the C4N2 gas needed for the cloud to condense and form.\nIn other words, there simply isn't enough C4N2 in Titan's stratosphere to facilitate cloud formation, according to our current understanding of the laws of thermodynamics.Fast-forward to now, and NASA's Cassini spacecraft\u00a0has just sent back data from its latest Titan flyby to reveal that the same type of cloud is there, up in the giant moon's stratosphere, and it's still made from an 'impossible' amount of C4N2.Titan is one of the most exciting places in our Solar System, because it's basically like a frozen version of Earth, with mountain chains and rolling dunes on its surface, protected by a thick, smoggy atmosphere.\u00a0In fact, Titan is the only moon in the Solar System known to maintain such a dense, nitrogen-rich atmosphere, and it's the only celestial body other than Earth found to have stable pools of liquid on its surface.\n\"In many respects, Saturn's largest moon, Titan, is one of the most Earth-like worlds we have found to date,\" says NASA.\"With its thick atmosphere and organic-rich chemistry, Titan resembles a frozen version of Earth, several billion years ago, before life began pumping oxygen into our atmosphere.\"If you look at Titan, getting past all that orangey haze, you can see just how similar it looks to our own home planet:Composite image of Titan. Credit: NASAAnd researchers think processes here on Earth could be key to what's going on in Titan's atmosphere to form its mysterious cloud.On Earth, our clouds form thanks to a continuous cycle of evaporation and condensation of water. One of the many Earth-like characteristics of Titan is that the same kind of cycle takes place in Titan's troposphere - the lowest layer of the atmosphere, that sits just below the stratosphere - but with methane instead of water.\nEvidence suggests that things in Titan's troposphere follow the same rules as things in our own troposphere - and this is where its various weather patterns are thought to originate, just like on Earth. But a\u00a0different condensation process appears to be taking place in the stratosphere at Titan's north and south winter poles.As NASA explains, circulation patterns force warm gases to move downward at the pole, and this causes layers of gas to condense as they sink through cooler and cooler layers of the polar stratosphere.This means clouds can form up in Titan's stratosphere because\u00a0levels of air temperature and pressure at the poles are enough for this vapour to condense into ice and reach a kind of 'equilibrium'.\"For clouds that condense, this equilibrium is mandatory, like the law of gravity,\" says one of the researchers, Robert Samuelson, from NASA's Goddard Space Flight Centre.\nThis is all pretty straightforward, and Titan would be perfectly normal if it weren't for the fact that the cloud in its stratosphere is made from dicyanoacetylene (C4N2).\"[T]he numbers don't compute for the cloud made from dicyanoacetylene,\" says NASA. \"The scientists determined that they would need at least 100 times more vapour to form an ice cloud where the cloud top was observed by Cassini's CIRS [Composite Infrared Spectrometer].\"While nothing's been confirmed yet, the team's leading hypothesis for why this is the case is based on clouds that exist in Earth's atmosphere and damage our ozone layer.As Rachel Feltman explains for The Washington Post,\u00a0there are certain clouds above Earth that\u00a0forego condensation altogether, and form instead through a kind of 'solid-state' chemistry based on the interactions of ice particles.\nThis is how chlorine-based chemicals in pollution make their way up into Earth's stratosphere from the ground, and end up eating away at the ozone layer, and a similar process could be allowing for new supplies of C4N2 to be produced in Titan's stratosphere.As Feltman reports:\n\"[C]yanoacetylene, a more common compound containing hydrogen, carbon, and nitrogen, could become coated with hydrogen cyanide as it moved down the stratosphere in the form of icy crystals.\nIf ultraviolet rays from the Sun struck one of these dual-layer ice crystals, the resulting chemical reaction would release dicyanoacetylene and hydrogen.\u00a0Voila, a cloud!\"\nThe hypothesis will need to be confirmed through further Cassini observations, so until then, Titan's cloud remains a mystery.And with Cassini's mission coming to a close next year, time is running out. Let's hope the hardest working spaceprobe in the Solar System can give us some answers before then.The research has been published in\u00a0Geophysical Research Letter"
        ]
    },
    "5532": {
        "gold_standard": [
            "Have you ever experienced a migraine? If so, perhaps you recognise this:\"It feels as if there is hammering and pounding in the head. Sound or talking is unbearable, as is light or glare. The pain arises from hot, choleric fumes, together with windiness. And so one feels piercing, burning and ringing.\"\nSuch a precise explanation of the pain and disorientation experienced during a migraine might have been written yesterday.In fact, it comes from an encyclopedia, compiled by the Franciscan monk Bartholomaeus Anglicus (Bartholomew the Englishman), in the 13th century.There aren't many ailments that have maintained so clear a course over so many centuries. And what's more, looking at the history of migraines reveals that the ailment was actually taken more seriously in the past, something we can learn a lot from today.Hemicrania decipheredWe can pinpoint the beginning of the history of migraine as a named disorder to Galen (c. 129 to c. 216/17 CE), the most famous philosopher and physician in the Roman Empire.Galen set migraine, or hemicrania as he termed it, apart from other types of headache: as a painful disorder affecting only half the head, caused by the ascent of vapours from the stomach that were excessive, too hot, or too cold.\nThe 12th-century text of Causae et Curae, which scholars generally accept as the work of the the celebrated German abbess Hildegard of Bingen (1098-1179), gave a compelling explanation of why migraine seized only half the brain at a time.This was a bodily force so powerful, that if it seized the whole head, the pain would be unendurable.Although Galen's writings were lost with the fall of the Roman Empire, Galen's term, hemicrania, persisted, being adapted and adopted into various languages over the centuries.For example, in Middle English, we find emigranea and in medieval Wales the term migran. William Dunbar, writing in Middle Scots, used the term magryme in his poem describing the physical pain of migraine as being like an arrow piercing his brow, a pain so bad that he couldn't look at the light.\nDunbar also captured the migraine aftermath, the \"postdrome\" that came with the new morning, when he sat down to write but was unable to find any words. His head \"dulled in dullness\", his body was unrefreshed, his spirit asleep.Throughout the 16th and 17th centuries, a wealth of remedies in manuscript and printed recipe collections suggest a sophisticated general knowledge about this disorder.For example, Jane Jackson's recipe book, dating from 1642, gives six separate recipes for \"Migrim in the Head\", requiring various amounts of effort to produce.The simpler remedies could be made in a few minutes from common garden ingredients (mix houseleek and earthworms with flour, spread it on a cloth and bind to the forehead), but the most complex concoction required equipment, planning and financial outlay to produce a medicine that would last 20 years.\nAs well as taking migraine seriously, Jackson's recipe book suggests that people of the 17th century appreciated that migraine could occur on a spectrum, from the occasional acute attack to a chronic illness that could last for several days.Losing legitimacyThese historical descriptions of migraine reveal that we have lost something.In all of the sources from the medieval and early modern period that I have come across during the five years I have spent tracing the history of migraine, one thing is clear: these people took migraine seriously.This is important. Migraine is now accepted as a 'real' disorder which affects around one in seven people, two-thirds of whom are women, and is recognised by the WHO as the sixth highest cause worldwide of years lost due to disability (YLD).But despite this, it (along with other headache disorders) is nevertheless chronically under-funded, its sufferers often ignored, dismissed, or blamed, and their ailments under-diagnosed and under-treated",
            "Have you ever experienced a migraine? If so, perhaps you recognise this:\"It feels as if there is hammering and pounding in the head. Sound or talking is unbearable, as is light or glare. The pain arises from hot, choleric fumes, together with windiness. And so one feels piercing, burning and ringing.\"\nSuch a precise explanation of the pain and disorientation experienced during a migraine might have been written yesterday.In fact, it comes from an encyclopedia, compiled by the Franciscan monk Bartholomaeus Anglicus (Bartholomew the Englishman), in the 13th century.There aren't many ailments that have maintained so clear a course over so many centuries. And what's more, looking at the history of migraines reveals that the ailment was actually taken more seriously in the past, something we can learn a lot from today.Hemicrania decipheredWe can pinpoint the beginning of the history of migraine as a named disorder to Galen (c. 129 to c. 216/17 CE), the most famous philosopher and physician in the Roman Empire.Galen set migraine, or hemicrania as he termed it, apart from other types of headache: as a painful disorder affecting only half the head, caused by the ascent of vapours from the stomach that were excessive, too hot, or too cold.\nThe 12th-century text of Causae et Curae, which scholars generally accept as the work of the the celebrated German abbess Hildegard of Bingen (1098-1179), gave a compelling explanation of why migraine seized only half the brain at a time.This was a bodily force so powerful, that if it seized the whole head, the pain would be unendurable.Although Galen's writings were lost with the fall of the Roman Empire, Galen's term, hemicrania, persisted, being adapted and adopted into various languages over the centuries.For example, in Middle English, we find emigranea and in medieval Wales the term migran. William Dunbar, writing in Middle Scots, used the term magryme in his poem describing the physical pain of migraine as being like an arrow piercing his brow, a pain so bad that he couldn't look at the light.\nDunbar also captured the migraine aftermath, the \"postdrome\" that came with the new morning, when he sat down to write but was unable to find any words. His head \"dulled in dullness\", his body was unrefreshed, his spirit asleep.Throughout the 16th and 17th centuries, a wealth of remedies in manuscript and printed recipe collections suggest a sophisticated general knowledge about this disorder.For example, Jane Jackson's recipe book, dating from 1642, gives six separate recipes for \"Migrim in the Head\", requiring various amounts of effort to produce.The simpler remedies could be made in a few minutes from common garden ingredients (mix houseleek and earthworms with flour, spread it on a cloth and bind to the forehead), but the most complex concoction required equipment, planning and financial outlay to produce a medicine that would last 20 years.\nAs well as taking migraine seriously, Jackson's recipe book suggests that people of the 17th century appreciated that migraine could occur on a spectrum, from the occasional acute attack to a chronic illness that could last for several days.Losing legitimacyThese historical descriptions of migraine reveal that we have lost something.In all of the sources from the medieval and early modern period that I have come across during the five years I have spent tracing the history of migraine, one thing is clear: these people took migraine seriously.This is important. Migraine is now accepted as a 'real' disorder which affects around one in seven people, two-thirds of whom are women, and is recognised by the WHO as the sixth highest cause worldwide of years lost due to disability (YLD).But despite this, it (along with other headache disorders) is nevertheless chronically under-funded, its sufferers often ignored, dismissed, or blamed, and their ailments under-diagnosed and under-treated.\nIn her recent book Not Tonight, the sociologist Joanna Kempner has described this situation as migraine's \"legitimacy deficit\".So what has happened?Historical sources suggest that the question we need to ask is not how we can begin to give migraine the legitimacy it needs, but when and why we stopped taking it seriously in the first place.'La migraine', 1823.Over the course of the 18th century, something changed, as migraine became the stuff of ridicule.In May 1782, for instance, a flamboyant character graced the King's Theatre Masquerade in London, and introduced himself to the gathering as \"Le Sieur Francois de Migraine, Docteur en Medicine\""
        ]
    },
    "6235": {
        "gold_standard": [
            "An international team of scientists has found the brightest gamma-ray binary ever seen, and it's the first to be seen outside the Milky Way galaxy.The team combined data from NASA's Fermi Gamma-ray Space Telescope with those from other facilities and confirmed that what was once thought to be a high-mass X-ray binary (HMXB) was in fact, a gamma-ray binary system.\nTheir findings have been published in The Astrophysical Journal.The newly found gamma-ray binary, named LMC P3, was discovered in a small nearby galaxy called the Large Magellanic Cloud (LMC), located 163,000 light-years away. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Gamma-ray binaries are systems wherein there are two stars, one orbiting the other.One is usually a massive star and the other is either a black hole or a neutron star (an extremely magnetic star), and are very rare, with only five found in our galaxy to date.And so far, LMC P3 is the most luminous gamma-ray binary system ever found in terms of gamma rays, X-rays, radio waves, and visible light.\n\"Fermi has detected only five of these systems in our own galaxy, so finding one so luminous and distant is quite exciting,\" NASA Goddard Space Flight Centre lead researcher Robin Corbet says.\"Gamma-ray binaries are prized because the gamma-ray output changes significantly during each orbit and sometimes over longer time scales. This variation lets us study many of the emission processes common to other gamma-ray sources in unique detail.\"Cosmic death raysHaving two extremely high-energy bodies within a system undoubtedly causes immense energy to be unleashed.On a regular day, the ozone layer protects us from gamma rays beaming around from outer space.However, gamma-ray bursts can wipe out life in an entire planet, if that planet happens to be in its beam direction. And some postulate that such an event did just that to Earth 450 million years ago.Artist's concept of a 10-second gamma ray burst wiping out life on Earth. Credit: NASAIt is estimated that gamma-ray binaries emit between 0.1 to over 100 gigaelectron-volts (GeV) of energ"
        ]
    },
    "6395": {
        "gold_standard": [
            "Tardigrades don't need any help in the weird department - the tiny creatures, also known as water bears, are only a few hundred micrometres long, but are almost impossible to kill. They can survive in the vacuum of space, endure total desiccation, and can even bounce back from being frozen for decades at a time.\nNow we finally have footage of the strange creatures having sex, and researchers have shown it's even more complicated than expected (see below).When it comes to mating, researchers knew that the some water bear species were bisexual (something that's not that uncommon in the animal world), and it was suspected that fertilisation happened outside the body.But, on the whole, their sex lives have remained pretty mysterious.Now a team of researchers from the Senckenberg Museum of Natural History in G\u00f6rlitz, Germany,\u00a0have finally filmed the process, which you can see in part below, providing new insight into how the creatures reproduce.It might not look like much - this is the male ejecting his semen under the female's skin - but trust us, things get weird. frameborder=\"0\u2033 width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"true\">\"In the present study we provide new insights into the mating behaviour of a bisexual tardigrade,\u00a0Isohypsibius dastychi, revealing a process much more complex than expected,\" the team write in the Zoological Journal.\n\"Mating included mutual stimulation that preceded semen ejaculation and egg deposition.\"As the team describes in the paper, the first step of the mating process is the female laying her eggs.This happens during one of the animal's many moulting periods - when they shed their outer cuticle.The eggs are laid inside that outer layer of cuticle, and then a male approaches and gets into position around her, a process that can take several minutes.Once he's in the right spot, the water bears engage in mutual stimulation, until the male finally ejaculates his semen via an opening above his anus into the female's outer layer of skin - which is what you can see happening in the footage above.This confirms that fertilisation actually occurs outside the female's body - although the researchers still aren't entirely sure how the semen gets to her egg eggs.\nThe team also found that if no mating occurred, the females reabsorbed their eggs. And the temperature that the animals were on determined how quickly the offspring ended up becoming adults.\u00a0There's still a lot to learn, such as why the animals take part in this foreplay, and how exactly sperm is directed to the correct location.Hopefully further study of this creatures will reveal more insight into their reproduction mechanisms. And knowing water bears, we're sure there are more weird surprises in store.The research has been published in the\u00a0Zoological Journal, and you can see more footage of the act over at BBC Eart"
        ]
    },
    "7099": {
        "gold_standard": [
            "Movement Disorders Researchers have found yet another reason to think the symptoms of\u00a0Parkinson's disease\u00a0could be a consequence of the type of bacteria living in our gut.Such discoveries could help us use changes in our gut bacteria to not only diagnose the debilitating disorder earlier, but potentially create better targeted treatments.\nOnce referred to as 'the shaking palsy', Parkinson's disease is mostly characterised by tremors and a loss of fine motor control, later progressing into dementia, difficulty walking, and sometimes chronic depression.In most studies on the condition the brain has been the focus, with the blame for the disease primarily falling on the death of cells in a part of the brain called the substantia nigra \u2013 a lump of tissue responsible for movement and reward.In recent years, however, scientists studying the root cause of Parkinson's disease have shifted their attention from the nervous system onto the denizens of our gut, identifying significant differences in the types of bacteria living in the guts of those with the condition and those who don't.Now a team of scientists at the University of Alabama at Birmingham in the US have contributed yet another piece of evidence tying Parkinson's disease with our personal community of microorganisms \u2013 or microbiota.\n\"We know that a well-balanced gut microbiota is critical for maintaining general health, and alterations in the composition of gut microbiota have been linked to a range of disorders,\" said researcher Haydeh Payami.The researchers analysed samples of gut microbes from 197 patients with Parkinson's disease from Seattle, New York, and Atlanta \u2013 representing three distinct regions around the US \u2013 and compared their species and functions with samples taken from 130 individuals without the condition.Not only did the results show marked differences in the numbers and types of bacteria between the two groups, they also noticed a difference in the metabolism of various medications.In other words, either the various drugs taken by those with Parkinson's disease were also having a unique impact on the bacteria, or their microbiota was affecting how their bodies responded to pharmaceutical treatments.\nMicroorganisms in our digestive system have been found to play an important role in breaking down so-called xenobiotics \u2013 chemicals which aren't usually expected to be present inside an organism.This includes not only the medications used to treat conditions such as Parkinson's disease, but chemicals in their environment such as pesticides and herbicides.Given farmers seem to be more prone to Parkinson's disease than the general population, thanks possibly to the chemicals they use, it's possible that the bacteria in their guts could be their body's first casualties.\"It could be that, in some people, a drug alters the microbiome so that it causes additional health problems in the form of side effects,\" Payami said.\"Another consideration is that the natural variability in the microbiome could be a reason some people benefit from a given drug and others are unresponsive. The growing field of pharmacogenomics \u2013 tailoring drugs based on an individual's genetic makeup \u2013 may need to take the microbiome into consideration.\"\nOne of the early symptoms of Parkinson's disease is constipation, so correlations such as these shouldn't come as much of a surprise.As with many things in science, however, it's hard to tell if a difference in microbiota is a cause of Parkinson's disease or an effect. \u00a0Last year researchers at the Californian Institute of Technology found mice who had been engineered to be susceptible to Parkinson's disease developed less severe symptoms if they were raised in sterile conditions.Injecting microflora from the guts of human Parkinson's patients led to a rapid deterioration, suggesting the type of microbes could be at least partially responsible for the severity of the symptoms.However it's clear the relationship is a two-way street, making for a complex interaction which demands further study.We're only beginning to learn how important our body's tiny citizens are, but as we find more links like these, we open up new horizons to treating or even preventing diseases such as Parkinson's.This research was published in Movement Disorder"
        ]
    },
    "7454": {
        "gold_standard": [
            "Homo sapiens is a very moody species. Even though sadness and bad moods have always been part of the human experience, we now live in an age that ignores or devalues these feelings.\nIn our culture, normal human emotions like temporary sadness are often treated as disorders. Manipulative advertising, marketing and self-help industries claim happiness should be ours for the asking. Yet bad moods remain an essential part of the normal range of moods we regularly experience.Despite the near-universal cult of happiness and unprecedented material wealth, happiness and life satisfaction in Western societies has not improved for decades.It's time to re-assess the role of bad moods in our lives. We should recognise they are a normal, and even a useful and adaptive part of being human, helping us cope with many everyday situations and challenges.A short history of sadnessIn earlier historical times, short spells of feeling sad or moody (known as mild dysphoria) have always been accepted as a normal part of everyday life. In fact, many of the greatest achievements of the human spirit deal with evoking, rehearsing and even cultivating negative feelings.\nGreek tragedies exposed and trained audiences to accept and deal with inevitable misfortune as a normal part of human life. Shakespeare's tragedies are classics because they echo this theme. And the works of many great artists such as Beethoven and Chopin in music, or Chekhov and Ibsen in literature explore the landscape of sadness, a theme long recognised as instructive and valuable.Ancient philosophers have also believed accepting bad moods is essential to living a full life. Even hedonist philosophers like Epicurus recognised living well involves exercising wise judgement, restraint, self-control and accepting inevitable adversity.Other philosophers like the stoics also highlighted the importance of learning to anticipate and accept misfortunes, such as loss, sorrow or injustice.What is the point of sadness?\nPsychologists who study how our feelings and behaviours have evolved over time maintain all our affective states (such as moods and emotions) have a useful role: they alert us to states of the world we need to respond to.In fact, the range of human emotions includes many more negative than positive feelings. Negative emotions such as fear, anger, shame or disgust are helpful because they help us recognise, avoid and overcome threatening or dangerous situations.But what is the point of sadness, perhaps the most common negative emotion, and one most practising psychologists deal with?Intense and enduring sadness, such as depression, is obviously a serious and debilitating disorder. However, mild, temporary bad moods may serve an important and useful adaptive purpose, by helping us to cope with everyday challenges and difficult situations.\nThey also act as a social signal that communicates disengagement, withdrawal from competition and provides a protective cover. When we appear sad or in a bad mood, people often are concerned and are inclined to help.Some negative moods, such as melancholia and nostalgia (a longing for the past) may even be pleasant and seem to provide useful information to guide future plans and motivation.Sadness can also enhance empathy, compassion, connectedness and moral and aesthetic sensibility. And sadness has long been a trigger for artistic creativity.Recent scientific experiments document the benefits of mild bad moods, which often work as automatic, unconscious alarm signals, promoting a more attentive and detailed thinking style. In other words, bad moods help us to be more attentive and focused in difficult situations.\nIn contrast, positive mood (like feeling happy) typically serves as a signal indicating familiar and safe situations and results in a less detailed and attentive processing style.Psychological benefits of sadnessThere is now growing evidence that negative moods, like sadness, has psychological benefits.To demonstrate this, researchers first manipulate people's mood (by showing happy or sad films, for example), then measure changes in performance in various cognitive and behavioural tasks.Feeling sad or in a bad mood produces a number of benefits:\nbetter memory: In one study, a bad mood (caused by bad weather) resulted in people better remembering the details of a shop they just left. Bad mood can also improve eyewitness memories by reducing the effects of various distractions, like irrelevant, false or misleading information"
        ]
    },
    "7484": {
        "gold_standard": [
            "Even as the Trump administration weighs withdrawing the\u00a0United States from the Paris climate agreement, a\u00a0new scientific paper\u00a0has documented growing fluxes of greenhouse gases streaming into the air from the Alaskan tundra, a long-feared\u00a0occurrence that could worsen climate change.\nThe new study, published in the Proceedings of the National Academy of Sciences, suggests that frozen northern soils - often called permafrost - are unleashing\u00a0an increasing amount of carbon dioxide into the air as they thaw in summer or subsequently fail to refreeze as they once did, particularly in late fall and early winter.\"Over a large area, we're seeing a substantial increase in the amount of CO2 that's coming out in the fall,\" said\u00a0Roisin Commane, a Harvard atmospheric scientist who is the lead author of the study.\u00a0The research was published by 19 authors from a variety\u00a0of institutions, including NASA's Jet Propulsion Laboratory and the National Oceanic and Atmospheric Administration.The study, based on aircraft measurements of carbon dioxide and methane\u00a0and tower measurements from Barrow, Alaska, found that from 2012 through 2014, the state emitted the equivalent of 220 million tons of carbon dioxide gas into the atmosphere from biological sources (the figure\u00a0excludes fossil fuel burning and wildfires).\nThat's an amount comparable to\u00a0all the emissions\u00a0from the US commercial sector in a single\u00a0year.The chief reason for the greater CO2 release was that as Alaska\u00a0has warmed up, emissions from once frozen tundra in winter are increasing\u00a0- presumably because the ground is not refreezing as quickly.\"The soils are warmer deeper, and as they freeze in the fall, the temperature of every soil depth has to come to zero before they hard freeze,\" Commane said.\"The temperature has to come to zero and equilibrate, for the soils to freeze hard through. And through that whole period you have emissions because the microbe are active.\"In particular, the research\u00a0found that since 1975, there has been a 73.4 percent increase in the amount of carbon lost from the Alaskan tundra in the months of October through December\u00a0as the climate warmed steadily.\nThe new study is \"the first to show that a large region of the Arctic is a carbon source and that this change is driven by increased carbon emissions during the winter,\" said Sue Natali, a permafrost researcher with the Woods Hole Research Center, who was not involved in the study.\"Because the models aren't capturing these cold-season processes, we're very likely underestimating carbon losses from the Arctic under current and future climate scenarios.\"The fears about permafrost carbon losses are based on some simple chemistry.Unlike at warmer latitudes, where microorganisms in the soil constantly break down plant matter and return the carbon it contains to the atmosphere, Arctic soils have been cold enough to preserve the frozen remains of ancient plant life.\u00a0But as the planet warms, soil microbes become able to break down more and more of this carbon, sending it back into the atmosphere and worsening global warming in a troubling feedback loop.\nSome scientists, however, held out hope that there would be a key offsetting process: As the Arctic warms, it might also stow away more carbon as it becomes greener and supports the additional plant life, particularly in tundra regions.This 'Arctic greening'\u00a0is indeed occurring, but the new research suggests that the permafrost losses in early winter are more than enough to offset that.\"There is greening going on, but it seems like you run out of the sunlight so far north, so it doesn't matter how much greening there is, eventually, the plants just run out of light,\" Commane said.\"It appears now that the microbes are winning.\"The\u00a0new study contrasts with\u00a0a\u00a02016 study\u00a0by the US Geological Survey, which had found that Alaska was acting as a net carbon \"sink\" at the moment - removing more carbon from the air than it is emitting - and that this should continue and expand\u00a0over the course of the century\u00a0as plant growth increases.\nOne\u00a0of the lead authors of that research, Dave McGuire of the University of Alaska at Fairbanks and USGS, said the new study is \"not the final word, but it is a significant step forward.\"McGuire pointed out that the new study looks at the years 2012 to 2014, whereas the 2016 USGS study looked at earlier years and ended in 2009, making an 'apples to apples' comparison difficult.Alaska\u00a0is only one area\u00a0of the Arctic where permafrost soils could be emitting carbon dioxide into the atmosphere. Permafrost regions in Canada and Siberia are even vaster.But the new\u00a0study's lessons could also apply to those areas, researchers say.The study \"shows that the Alaska region, which may be representative of large swaths of boreal forest and Arctic tundra biomes elsewhere, appear to be releasing net carbon to the atmosphere, in particular with stimulated emissions in the fall/early winter period,\" said Ted Schuur, an ecologist at Northern Arizona University, who\u00a0was not involved in the research"
        ]
    },
    "7493": {
        "gold_standard": [
            "Journal of Applied Physics Researchers have developed a new kind of transistor laser that can switch between two stable energy states \u2013 electronic and photonic \u2013 which could one day enable data transfer 100 times faster than conventional digital devices.\nThe transistor prototype features what's called bistability \u2013 the capability for a single switch to alternate between optical and electrical signal output \u2013 and could help lead to the development of light-based computer systems where data is shuttled in between semiconductors by photons instead of simply electrons.\"Building a transistor with electrical and optical bistability into a computer chip will significantly increase processing speeds,\" says microelectronics engineer Milton Feng from the University of Illinois at Urbana-Champaign, \"because the devices can communicate without the interference that occurs when limited to electron-only transistors.\"In conventional electronic devices, microchips are made up of billions of tiny switches called transistors, which act as gateways to channel the flow of electrons across an integrated circuit.The problem with this model \u2013 which has worked pretty well for electronic devices for several decades up until now \u2013 is that as modern computer processors have become ever faster and more powerful, the number of transistors on them inevitably increases.\nThis tendency is what's called Moore's Law \u2013 the famous prediction by Intel co-founder Gordon Moore that the transistor count on an integrated circuit will double every two years.Moore's Law has actually held up pretty well since it was first forecast back in the 1960s, but a range of technical issues are currently threatening to derail its continuation \u2013 which could put a stop to processors getting faster, if we can't think of new ways to build them.Chiefly, transistors have gotten so incredibly small now that it's getting harder to physically shrink them any further, and there are also concerns about how energy-efficient electron-based transistors will be if Moore's Law does continue in the future.Besides those points, since light can travel significantly faster than electrons inside an integrated circuit, moving to photonics-based processors in place of solely electronic devices makes a lot of sense, which is why scientists are busy studying how we can develop light-based computers.\nTo that end, Feng and fellow researcher Nick Holonyak Jr first developed the concept of the transistor laser back in 2004 \u2013 a semiconductor device that incorporates both electrical and optical outputs.\"The fastest way for current to switch in a semiconductor material is for the electrons to jump between bands in the material in a process called tunnelling,\" Feng explained in 2016.\"Light photons help shuttle the electrons across, a process called intra-cavity photon-assisted tunnelling, making the device much faster.\"In their latest research, the same team has now described how the transistor laser can switch between the two signals \u2013 a crucial distinction for optical computing, since despite the allure of photonics, the researchers say we will still need to accommodate electrons in future chip designs.\n\"You cannot remove electronics entirely because you need to plug into a current and convert that into light,\" says Feng.\"That's the problem with the all-optical computer concept some people talk about. It just is not possible because there is no such thing as an all-optical system.\"In the new study, the researchers detail how they've got their bistable switch working at -50 degrees Celsius (-58 degrees Fahrenheit).The researchers further claim to have actually gotten the device working at room temperature \u2013 which is pretty important if we're ever going to use these transistors in actual devices \u2013 and will share details on how they accomplished that in an upcoming paper.As for when we'll see this kind of technology in our smartphones and notebooks, it's still not entirely clear.\nBut it's a sure bet that when our microchips include billions of tiny lasers in them, a whole new kind of computing will become possible.\"This is a single device that provides bistability for both electrical and optical functions with one switch,\" says Feng.\"It is totally new, and we are working hard to find more new applications for the device.\"The findings are reported in the Journal of Applied Physic"
        ]
    },
    "7561": {
        "gold_standard": [
            "Scientists are always on the lookout for new materials that can enable improved energy storage and quicker energy transfers, and a new study suggests what could be a dramatically simple approach for achieving those ends: just add water.\nBy adding atomically thin, nanoscale layers of water to an existing material, researchers found it was able to store and deliver energy more quickly than the same material without the water layers, which could lead to new ways of manufacturing better batteries and improved electric devices.\"This is a proof of concept, but the idea of using water or other solvents to 'tune' the transport of ions in a layered material is very exciting,\" says one of the team, materials scientist Veronica Augustyn from North Carolina State University.\"The fundamental idea is that this could allow an increased amount of energy to be stored per unit of volume, faster diffusion of ions through the material, and faster charge transfer.\"Augustyn's team compared two materials in their research: a crystalline tungsten oxide, and the same material in a layered from \u2013 called crystalline tungsten oxide hydrate \u2013 which was interspersed with extremely thin layers of water (seen as stripes in the image below):North Carolina State UniversityThe idea is to enable fast diffusion of ions in a solid-state structure, using water to speed up the transfer of energy throughout the medium, while still retaining the ability of the material to store as much energy as possible.\nResearch in this field \u2013 called pseudocapacitance \u2013 has gone on for decades, but researchers are now better able to explore their hypotheses thanks to advances in materials science and nanostructuring methods.\"The goal for many energy-storage researchers is to create technologies that have the high energy density of batteries and the high power of capacitors,\" says one of the researchers, James Mitchell.\"Pseudocapacitors like the one we discuss in the paper may allow us to develop technologies that bridge that gap.\"In testing with the hydrate material, the team found that it was able to store more energy than the regular tungsten oxide, but only when it was charged for short periods.After being charged for 12 seconds, the water layer oxide stored more energy, but when the charging cycle was extended to 10 minutes, the regular oxide stored more \u2013 although the hydrate stored energy more efficiently than the conventional material, by wasting less energy as heat"
        ]
    },
    "8347": {
        "gold_standard": [
            "Red makes the heart beat faster. You will frequently find\u00a0this and other claims\u00a0made for the effects of different colours on the human mind and body.But is there any scientific evidence and data to support such claims?\nThe physiological mechanisms that underpin human colour vision have been understood for the best part of a century, but it is only in the last couple of decades that we have discovered and begun to understand a separate pathway for\u00a0the non-visual effects of colour.Like the ear, which also provides us with our sense of balance, we now know that the eye performs two functions.Light sensitive cells known as cones in the retina at the back of the eye send electrochemical signals primarily to an area of the brain known as the\u00a0visual cortex, where the visual images we see are formed.However, we now know that some\u00a0retinal ganglion cells\u00a0respond to light by sending signals mainly to a central brain region called the hypothalamus which plays no part in forming visual images.Light but not vision\nThe\u00a0hypothalamus\u00a0is a key part of the brain responsible for the secretion of a number of hormones which control many aspects of the body's self-regulation, including temperature, sleep, hunger and circadian rhythms.\u00a0Exposure to light in the morning, and blue/green light in particular, prompts the release of the hormone cortisol which stimulates and wakes us, and inhibits the release of melatonin. In the late evening as the amount of blue light in sunlight is reduced, melatonin is released into the bloodstream and we become drowsy.The retinal cells that form the non-image-forming visual pathway between eye and hypothalamus are selectively sensitive to the short wavelengths (blue and green) of the visible spectrum.What this means is that there is clearly an established physiological mechanism through which colour and light can affect mood, heart rate, alertness, and impulsivity, to name but a few.\nFor example, this non-image-forming visual pathway to the hypothalmus is believed to be involved in\u00a0seasonal affective disorder, a mood disorder that affects some people during the darker winter months that can be successfully treated by exposure to light in the morning.Similarly, there is published data that show that exposure to bright, short-wavelength light a couple of hours prior to normal bedtime can increase alertness and subsequently\u00a0affect sleep quality.Poor quality sleep is becoming increasingly prevalent in modern society and is linked with increased risk factors for obesity,\u00a0diabetes\u00a0and\u00a0heart disease.There is some\u00a0concern\u00a0that the excessive use of smartphones and tablets in the late evening can affect sleep quality, because they emit substantial amounts of blue/green light at the wavelengths that inhibit the release of melatonin, and so prevent us from becoming drowsy.\nThat's one effect of blue/green light, but there is much more research to be done in order to back the many claims made for other colours.Experiencing colourI lead the Experience Design research group at the University of Leeds where we have a\u00a0lighting laboratory\u00a0especially designed to evaluate the effect of light on human behaviour and psychology.The lighting system is unique in the UK in that it can flood a room with coloured light of any specific wavelengths (other coloured lighting usually uses a crude mixture of red, green and blue light).Stephen WestlandRecent research by the group has found a small effect of coloured light on heart rate and blood pressure: red light does seem to raise heart rate, while blue light lowers it. The effect is small but has been corroborated in a 2015\u00a0paper\u00a0by a group in Australia"
        ]
    },
    "8364": {
        "gold_standard": [
            "A 4,000-year-old tomb in Jerusalem has yielded up a lovely surprise - a funerary vessel containing the tiny bones of at least nine toads, all of which had been decapitated prior to being placed inside.\nThe tomb was one of 67 human-made shaft tombs found in the Nahal Repha'im basin, not far from the Jerusalem Biblical Zoo. The area was populous during the Canaanite period, and archaeologists have uncovered two settlement sites, two temples and a number of cemeteries in the region.It dates to the Middle Bronze Age, and while funerary jars containing offerings of food to provide sustenance to the dead are common, finding toads inside is not.\"To the best of my knowledge, the only other place in Israel with a toad find was in Wadi Ara, and dates to the Late Bronze Age,\" dig co-director Shua Kisilevitz of the Israel Antiquities Authority told The Times of Israel.The jar of toad bones. Zohar Turgeman-Yaffe, Israel Antiquities AuthorityThe tomb had been intentionally sealed with a large rock. Inside was a single, poorly preserved human skeleton, surrounded by intact bowls and jars.\n\"For an archaeologist, finding tombs that were intentionally sealed in antiquity is a priceless treasure, because they are a time capsule that allows us to encounter objects almost just as they were originally left,\" said Kisilevitz and dig co-director Zohar Turgeman-Yaffe.Other tombs have revealed a variety of foodstuffs such as goat, oxen and gazelle left behind for the dead, as well as lamps, amulets such as scarabs, and toggle pins, the latter probably to secure the burial garment.The find indicates that toads were part of the local diet during the time of the burial.\"We understand that this was part of the food consumed while still alive,\" Kisilevitz said. This would explain why the heads were missing - they would have been taken off so that the skin could be removed in preparation for eating.The team will present their research on 18 October 2017 at the New Studies in the Archaeology of Jerusalem and its Region conference at the Hebrew University of Jerusalem"
        ]
    },
    "8386": {
        "gold_standard": [
            "Ever since the EM drive first made headlines, science lovers have puzzled over how the propulsion system seems to produce thrust, despite the fact it's 'impossible' according to one of the most fundamental laws of physics - Newton's third law of motion.\nNow a team of physicists have put forward an alternative explanation - it turns out the EM drive could actually work without breaking any scientific laws, if we factor in a weird and often overlooked idea in quantum physics - pilot wave theory.For those who need a refresher, the crux of the problem here is that the EM, or electromagnetic, drive appears to produce thrust without any fuel or propellant.That's awesome because it means we can get to space with way less pay load - it's proposed it could even get us to Mars within 72 days.But it's also perplexing, because, according to Newton's third law, every action must have an equal and opposite reaction. So without pushing any propellant out one end, the drive shouldn't be able to produce thrust in the opposite direction.Still, as a NASA peer-reviewed paper showed last year, the drive does produce thrust, at least as far as we can currently tell. And a relatively large amount of thrust at that. We just don't know how.\nSo either our understanding of physics isn't right, or we're missing a big piece of the puzzle when it comes to the EM drive.A new paper published in The Journal of Applied Physical Science International makes the argument that what we're missing is pilot wave theory - a slightly controversial alternative interpretation of quantum mechanics.Researchers Jos\u00e9 Croca and Paulo Castro from the Centre for Philosophy of Sciences of the University of Lisbon in Portugal suggest that not only could pilot wave theory explain the mysterious behaviour of the EM drive, it could help to make it even more powerful.\"We have found that applying a pilot wave theory to NASA's EM drive frustum [or cone], we could explain its thrust without involving any external action applied to the system, as Newton's third law would require,\" Castro told ScienceAlert via email.\nSo what is pilot wave theory? Currently, the majority of physicists subscribe to the Copenhagen interpretation of quantum mechanics, which states that particles do not have defined locations until they are observed.Pilot wave theory, on the other hand, suggests that particles do have precise positions at all times, but in order for this to be the case, the world must also be strange in other ways \u2013 which is why many physicists have dismissed the idea.But in recent years, the pilot wave theory has been increasing in popularity. The team has shown in its latest paper this theory could be tweaked slightly to apply to something bigger. Say, the EM drive. And it could explain the results we've been seeing.Basically, pilot wave theory says that an object radiates a wave field, and it is then pulled or attracted to regions of that field that have higher intensity or energy density. In that way, the wave field is actually 'piloting' the object, hence the name.\nThrough modelling, the team showed that a sufficiently strong and asymmetrical electromagnetic field could act as a pilot wave. And that's exactly what the EM drive generates.Because the cone, or frustum, of the EM drive is asymmetrical, it would also generate an asymmetrical wave field. As a result, the walls of the EM drive would move towards the areas of higher intensity, creating thrust.While that might sound pretty out there, this was also actually a possible solution put forward by the NASA Eagleworks researchers in their seminal paper last year where they first reported the thrust generated by their device:\n\"[The] supporting physics model used to derive a force based on operating conditions in the test article can be categorised as a nonlocal hidden-variable theory, or pilot-wave theory for short.\"\nTo be clear, the researchers from the University of Lisbon haven't tested their proposal in a real device as yet.\nThey've only shown that it's possible, from a modelling point of view, for a pilot wave to guide the EM drive. But they've also shown how the idea could actually be tested in future.\"At the moment the most stringent empirical evidence comes from the EM drive behaviour,\" Castro told ScienceAlert. \"However, we have also devised an experiment to detect and modulate subquantum waves.\"Importantly, if the hypothesis is confirmed, it would mean the EM drive would not have to break Newton's third law. And the team hopes this might result in the device being taken seriously and more widely tested.\"EM drive is the future of space propelling motors,\" they said. \"[Although] it will perhaps find its initial application in nano satellites or nano drones, at least before the effect can be scaled up to heavier machines.\"\nImportantly, if a pilot wave does explain the thrust behind the device, then it could also lead to a way to make the propulsion system even more powerful in future, and it's as simple as tweaking the shape.\"We have seen that the effect could be enhanced using a different shape for the frustum,\" said Castro. \"In fact a trumpet exponential form is expected to increase the thrust.\"The team is now considering building its own experimental set up to study the phenomena and has invited anyone interested in the project to get in touch.In the meantime, the NASA Eagleworks team continues to test out its device. And there are also groups looking to test the EM drive in space - or according to some rumours, already doing so - which would really show once and for all whether it works.There's a lot we have yet to learn about the mysterious EM drive and it's a topic that continues to divide the science world. But whether or not it ends up being the future of space travel, at least it's teaching us more about the physics that govern our world.The new research has been published in The Journal of Applied Physical Science International"
        ]
    },
    "8416": {
        "gold_standard": [
            "The Auk: Ornithological Advances In the world of ducks, there's a lot going on under the surface. But the biggest influence on what's down below seems to be the company they keep.Of the 10,000 or so known species of birds, ducks are in the rare minority that have actually retained their penises, which shrink and expand by as much as 10 times depending on the season \u2013 but it looks like their maximum potential hinges on sexual competition.\nResearchers investigated the effects of social pressures on duck penis morphology, and found that greater numbers of male sexual competitors can actually make duck penises grow longer and faster.\"This study illustrates how social forces can actually shape individual anatomy,\" says ornithologist Richard Prum from Yale University, \"but it also suggests how sexual conflict and sexual autonomy shape social behaviour.\"A ruddy drake and his appendage. Credit: P. BrennanPrum and fellow researcher Patricia Brennan from Mount Holyoke College compared the manhoods \u2013 duckhoods? \u2013 of two different species of duck, ruddy ducks (Oxyura jamaicensis) and lesser scaups (Aythya affinis).\nFor the purposes of the two-year experiment, both species were observed in two different kinds of sexualised scenario: single drakes paired with a single female, or multiple males housed with a single female \u2013 kind of like an all-duck reimagining of The Bachelorette.In the case of the lesser scaups, the rabble of quacking competitors seemingly spurred ducks to stand out from the crowd, growing longer penises on average than their single counterparts teamed up with a female.But the results weren't quite so linear for ruddy ducks.In this species, the Bachelorette contestants grew their penises faster than the single ruddy ducks, but hierarchical factors among the flock seemed to come into play.In the first year, only the largest drakes grew full-length penises, with some of the smaller ruddy ducks producing only small half-centimetre penis stubs in mating season.\nWhat's more, males grew their penises out of sync with each other, and didn't always maintain their maximum penis length for as long, lasting only weeks instead of months.The divergent effects of male crowding on ruddy ducks and lesser scaups could come down to the species' individual sexual habits.Compared to the more humbly proportioned and perhaps emotionally sensitive lesser scaup \u2013 which is monogamous throughout a mating season \u2013 ruddy drakes are combative and promiscuous, and bear exceptionally long penises that can grow longer than the ducks themselves.\"I can't imagine they could grow any longer,\" Brennan told Nature, adding that the ruddy drakes' performance issues could be more than just stage fright.\"Bullying may increase stress hormones, and those could counteract the effects of androgen hormones.\"\nOf course, these findings only pertain to two duck species so far, but the researchers think the findings suggest genital growth is responsive not just to long-term evolutionary factors, but also short-term variables that influence where, when, and how life-forms expend energy on swelling their nether regions.\"[E]volution must be acting on the ability to be plastic \u2013 the ability to invest only in what is needed in your current circumstance,\" Brennan told Nature.A fascinating hypothesis, but we'll let this lesser scaup have the last word for now:Ray Hennessy/Shutterstock.comThe findings are reported in The Auk: Ornithological Advance"
        ]
    },
    "8425": {
        "gold_standard": [
            "Geophysical Research Letters There's an increase in lightning storms at sea, and the culprit is the exhaust produced by diesel-powered cargo ships, a new study has found.Our oceans are criss-crossed with invisible lanes taken by cargo ships, and now it turns out those heavily trafficked areas have surprisingly different weather.\nDiesel fumes are some of the worst pollutants. We know that they're significantly worse for human health than petrol fumes, and a new study has just found that they're responsible for 5,000 premature deaths annually in Europe.And it turns out particles in that exhaust are also responsible for an increase in lightning, according to a team of researchers from the University of Washington.Using 12 years of lightning strike data from the\u00a0World Wide Lightning Location Network, the team found that lightning strikes were occurring nearly twice as often directly above two heavily trafficked shipping lanes, compared to adjacent areas of the ocean with similar climates.This difference over the shipping channels over the Indian Ocean and the South China Sea cannot solely be attributed to changes in weather, the researchers said.\n\"[We made] a map of where the lightning was enhanced and a map of where the ships are traveling and it was pretty obvious just from the co-location \u2026 that the ships were somehow involved in enhancing lightning,\" says lead researcher Joel Thornton.Clouds form when water vapour in the atmosphere clings to particles in the air. We know this can be induced, because scientists have been experimenting with a practice called \"cloud seeding\" for decades.This involves pumping particles into the air for the vapour to cling to, such as dry ice particles.This is what could be happening with the diesel exhaust. But the particles therein are more numerous than would be normally in the atmosphere, meaning the water vapour has more particles to collect around.This results in smaller and lighter cloud particles, which are lifted higher into the atmosphere, past the freezing line, where they form soft hail and ice crystals.\nThese then collide with each other, creating the electrical charge that results in lightning.The team studied 1.5 billion lightning strikes produced between 2005 and 2016, and believe their findings represent the first evidence that humans are influencing cloud formation on a continual basis, rather than periodically, such as after a wildfire.Cloud formation can also affect climate by changing how much sunlight is reflected back into space.\"It is the first time we have, literally, a smoking gun, showing over pristine ocean areas that the lightning amount is more than doubling,\" says atmospheric scientist Daniel Rosenfeld of Hebrew University of Jerusalem who didn't participate in the study.\"The study shows, highly unambiguously, the relationship between anthropogenic emissions - in this case, from diesel engines - on deep convective clouds.\"The research has been published in the journal Geophysical Research Letter"
        ]
    },
    "8434": {
        "gold_standard": [
            "Scientists have discovered the existence of a type of particle that's never previously been observed, which demonstrates unprecedented chemical stability for its kind.It's big news for chemists and physicists \u2013 but the achievement isn't just exciting for theoretical scientists, because, if researchers can figure out how to make it in the lab, it could also enable new kinds of consumer products, such as aluminium-ion batteries.\nThe new discovery is the modelling of what's called a tri-anion particle, so-called because they contain three more electrons than protons.While these have been found before, they've always been atomically unstable in the gas phase due to their surplus of electrons \u2013 that is, until now.Researchers at Virginia Commonwealth University used computer modelling to show that stable tri-anions are in fact possible \u2013 at least hypothetically \u2013 as long as you've got the right molecular ratios of the elements boron and beryllium paired with the chemical compound cyanogen.Tri-anion particles are usually unstable in the gas phase because their extra electrons means they dispel additional electrons due to strong electrostatic repulsion, which interrupts chemical reactions.But a team led by physicist Puru Jena used quantum mechanical calculations to show that a molecule called BeB11(CN)12 is actually chemically stable \u2013 so robust in fact, that they described it in their paper as exhibiting \"colossal stability\".\n\"This is very important in this field, nobody has ever found such a tri-anion,\" says Jena.\"Not only can it keep three electrons but the third electron is extremely stable.\"The researchers also had success substituting cyanogen for the chemical compounds thiocyanate (SCN) and borate (BO) .\"The implication of the extraordinary stability of the above tri-anions is that one can regard this class of clusters as super-pnictogens,\" the researchers write, \"analogous to super-halogens discovered more than 30 years ago.\"Pnictogens are a class of chemicals including nitrogen and phosphorus that have three unpaired electrons in their outermost electron shell, and which are known for their stability.These belong in group 15 of the Periodic Table, and the researchers say the newly discovered BeB11(CN)12 \u2013 and its thiocyanate and borate variants \u2013 mimic the chemistry and stability of the group"
        ]
    },
    "8586": {
        "gold_standard": [
            "(Jiming Bao, et al.) They're calling it laser streaming. No, it's not a new sport or some Netflix-like pastime. Instead it's a new observable phenomenon involving fluids and laser beams.Thanks to engineers from the\u00a0University of Houston (UH)\u00a0in Texas, we've now realised that it's possible for highly focused, beams of light\u00a0- aka lasers\u00a0- to transfer its momentum to create a stream of liquid.\n\"Transforming a laser beam into a mass flow has been a challenge both scientifically and technologically,\" the researchers, led by UH engineer Jiming Bao, wrote in\u00a0a study published online.Usually, light simply passes through water, unless forced to interact with another medium it could 'push' - like air.\"Here we report the discovery of a new optofluidics principle and demonstrate the generation of a steady-state water flow by a pulsed laser beam through a glass window.\"In short, they were able to use a laser beam to generate liquid streams inside a fluid.Jiming Bao, et al.Bao and his colleagues found that it's possible for a laser to push water if it contains gold nanoparticles. To demonstrate this rather unique phenomenon, they shine a pulsed green laser through a liquid container's glass wall.\nWithin minutes, it produces a current of liquid streaming along the direction of the laser beam.\"The flows appear as liquid analogues of laser beams and move in the same directions of the refracted beams as if they are directly driven by photons of laser beams,\"\u00a0they wrote. \"We call this phenomenon laser streaming.\"Nanoparticles can absorb green light because it resonates close to the frequency of the electrons these contain.The particles expand and contract as they heat up and cool down with each laser pulse, generating acoustic waves in the water\u00a0- a phenomenon long-known, called acoustic streaming.This discovery has significant applications, particularly for lab-on-a-chip experiments\u00a0where moving liquids at a microscopic scale can be crucial, as well is in nanofabrication and even laser propulsion.As Bao and his colleagues explained in their paper, \"Laser streaming will find applications in optically controlled or activated devices such as microfluidics, laser propulsion, laser surgery and cleaning, mass transport or mixing, to name just a few"
        ]
    },
    "8598": {
        "gold_standard": [
            "Changes in the flow of iron around Earth's outer core are thought to contribute to very small fluctuations in the length of our days.Now researchers say the sloshing of our planet's core could also be used for potential earthquake warnings, possibly even years ahead.\nYou've probably never noticed variations in the length of a day, as they're measured in milliseconds, but they represent very slight slowdowns in the speed that the world is spinning at.Two geophysicists have found a correlation between day length variations over the last 100 years and major magnitude 7 earthquakes. They think the same root cause could be behind both - that molten iron sloshing around in Earth's core.If the hypothesis holds up, we have a new earthquake predictor that could give us as much as five years of advance warning about the risk of increased tremors - way more warning than what we have right now.\"The Earth offers us a five-year heads up on future earthquakes, which is remarkable,\" suggests one of the researchers, Roger Bilham from the University of Colorado (CU) in Boulder.\n\"The correlation they've found is remarkable, and deserves investigation,\" Peter Molnar from CU, who wasn't involved in the study, told Paul Voosen at Science.No one's quite sure how this sloshing action works, though it also affects slight changes in Earth's magnetic field as well as day length, so we know it's happening.One idea is that part of the molten outer core sticks to the mantle above, changing the flow of liquid, and checking Earth's momentum - it's a bit like a loose cannon rolling across the deck of a ship, suggest the researchers.In a study published in August, Bilham and Rebecca Bendick from the University of Montana found clusters of serious earthquakes happening at roughly 32-year intervals. In their latest work, they've also matched those clusters with peaks in the fluctuation in day lengths - and so maybe also with activity deep within Earth.\nWith Earth spinning at some 465 metres (1,509 feet) per second, the researchers say some kind of sloshing action could plausibly trigger a season of earthquake activity.In fact, since 1900, more than 80 percent of all earthquakes measuring a magnitude 7 or above on the eastern Caribbean plate boundary have occurred within five years of one of these changes in Earth's speed and day length, including the 2010 Haiti earthquake.It's still early days for the hypothesis, but having five or six years advance warning of increased earthquake risk could make a big difference to preparations, and other experts are cautiously optimistic.\"I've worked on earthquakes triggered by seasonal variation, melting snow,\" Michael Manga of the University of California, Berkeley, told Science. \"[This] correlation is much better than what I'm used to seeing"
        ]
    },
    "8626": {
        "gold_standard": [
            "Regular marijuana users have about 20 percent more sex than abstainers, according to a new study from researchers at Stanford University.The study analysed data on 28,000 female and 23,000 male participants in the National Survey of Family Growth, a nationally representative CDC survey of Americans age 15 to 49.\nIt found that women who smoked marijuana daily had sex with a male partner an average of 7.1 times per month, compared to 6 times per month for nonsmoking women.Similarly, men who used marijuana daily reported having sex with a woman 6.9 times per month, compared to 5.6 times for nonusers.Those findings held true even after the researchers controlled for a number of demographic variables known to affect sex habits and marijuana use.\"The overall trend we saw applied to people of both sexes and all races, ages, education levels, income groups and religions, every health status, whether they were married or single and whether they had kids,\" author Michael Eisenberg said in a statement.\nFurther bolstering the findings, the study also found what researchers call a \"dose-dependent relationship\" between marijuana use and sex frequency: as respondents' marijuana use rates increased, so did their frequency of having sex.The study does not, however, necessarily indicate a causal relationship between marijuana use and sex. \"It doesn't say if you smoke more marijuana, you'll have more sex,\" Eisenberg said.For instance, people who are naturally inclined to have more frequent sex may be predisposed to marijuana use, rather than the other way around.Nevertheless, it does seem plausible that a causal effect could be at work here. Some qualitative research published in 2016, for instance, found that respondents generally said that stoned sex was more pleasurable than drunk or sober sex.\nA 2003 study also found that over half of marijuana users said the drug was a libido-booster, compared to 26 percent who said it inhibited their sex drive.\"In humans, sex is not only a means to procreation but serves as an important source of physical pleasure and expression of emotional intimacy,\" the Stanford authors write.As such, a fair amount of other research has found a link between the frequency of sex and overall physical and mental health. People who have more sex, on average, are happier and less stressed, they have lower blood pressure, and better cardiovascular health overall.This underscores a key point about drug use. We all know the risks associated with marijuana use - dependency, impaired driving, decreased academic performance, etc. But when discussing drug policy we rarely talk about the benefits of drug use"
        ]
    },
    "8632": {
        "gold_standard": [
            "Models used to estimate past ocean temperatures might be based on a flawed assumption, according to new research.If true, it would mean our ancient seas were far cooler than previously calculated, and our planet's current warming trend is even more extraordinary than we thought.\nA team of scientists from some of Europe's leading research institutes has taken a critical look at a chemical process that has served as a proxy for determining the temperatures of oceans millions of years in the past.Even the most solid of scientific models rests on fairly well-reasoned assumptions.In this case, the method for calculating temperature was based on the thought that temperatures were preserved perfectly inside tiny marine organisms called foraminifera.Specifically, the exact ratio of oxygen-18 to oxygen-16 in the calcite of the organisms' exoskeletons varies with the isotope concentrations in the environment \u2013 a factor that was determined by things like acidity and salinity \u2013 and the water's temperature.So if we determine the differences in the oxygen isotopes in fossils, we have a record of the temperatures as they were when they lived a little over 100 million years ago.\nThis tells us the temperature of the deeper parts of the ocean at the tropics were about 15 degrees Celsius warmer than today.Yet it turns out things might not be quite so straightforward.\"What appeared to be perfectly preserved fossils are in fact not,\" says Sylvain Bernard, a mineralogist from the French National Center for Scientific Research.Evidence now suggests the ratio of oxygen-18 to oxygen-16 in the buried marine life might not be quite as stable as thought.To test how the chemistry of the calcite in the foraminifera's shells might continue to change over time, the researchers placed a sample of the organisms in artificial sea water that contained just isotopes of oxygen-18.They then cranked the temperature to simulate the heat generated by being buried beneath a pile of sediment and used a device called a nanoscale secondary ion mass spectrometer (or NanoSIMS) to analyse changes in the calcite's oxygen ratios.\nSure enough, the equilibrium shifted, changing the ratios.\"This means that the paleotemperature estimates made up to now are incorrect,\" says Bernard.Taken at face value, it implies the waters probably weren't all that much warmer than today.\u00a0The discovery also helps resolve a paradox that has hinted at an inconsistency in the most favoured models.Using the oxygen isotope method, ocean temperatures in the tropics during the warm Cretaceous period weren't all that different to the surface temperatures at the poles.Unfortunately other models on climate and ocean currents don't gel with this shallow gradient, hinting at a problem.In addition, analysing magnesium isotopes in the foraminifera fossils instead of oxygen suggests the sea surface temperatures at higher latitudes were also colder than estimate",
            "Models used to estimate past ocean temperatures might be based on a flawed assumption, according to new research.If true, it would mean our ancient seas were far cooler than previously calculated, and our planet's current warming trend is even more extraordinary than we thought.\nA team of scientists from some of Europe's leading research institutes has taken a critical look at a chemical process that has served as a proxy for determining the temperatures of oceans millions of years in the past.Even the most solid of scientific models rests on fairly well-reasoned assumptions.In this case, the method for calculating temperature was based on the thought that temperatures were preserved perfectly inside tiny marine organisms called foraminifera.Specifically, the exact ratio of oxygen-18 to oxygen-16 in the calcite of the organisms' exoskeletons varies with the isotope concentrations in the environment \u2013 a factor that was determined by things like acidity and salinity \u2013 and the water's temperature.So if we determine the differences in the oxygen isotopes in fossils, we have a record of the temperatures as they were when they lived a little over 100 million years ago.\nThis tells us the temperature of the deeper parts of the ocean at the tropics were about 15 degrees Celsius warmer than today.Yet it turns out things might not be quite so straightforward.\"What appeared to be perfectly preserved fossils are in fact not,\" says Sylvain Bernard, a mineralogist from the French National Center for Scientific Research.Evidence now suggests the ratio of oxygen-18 to oxygen-16 in the buried marine life might not be quite as stable as thought.To test how the chemistry of the calcite in the foraminifera's shells might continue to change over time, the researchers placed a sample of the organisms in artificial sea water that contained just isotopes of oxygen-18.They then cranked the temperature to simulate the heat generated by being buried beneath a pile of sediment and used a device called a nanoscale secondary ion mass spectrometer (or NanoSIMS) to analyse changes in the calcite's oxygen ratios.\nSure enough, the equilibrium shifted, changing the ratios.\"This means that the paleotemperature estimates made up to now are incorrect,\" says Bernard.Taken at face value, it implies the waters probably weren't all that much warmer than today.\u00a0The discovery also helps resolve a paradox that has hinted at an inconsistency in the most favoured models.Using the oxygen isotope method, ocean temperatures in the tropics during the warm Cretaceous period weren't all that different to the surface temperatures at the poles.Unfortunately other models on climate and ocean currents don't gel with this shallow gradient, hinting at a problem.In addition, analysing magnesium isotopes in the foraminifera fossils instead of oxygen suggests the sea surface temperatures at higher latitudes were also colder than estimate"
        ]
    },
    "8644": {
        "gold_standard": [
            "A cool new study using virtual reality and ethical dilemmas has discovered that those with psychopathic traits will readily sacrifice the few for the good of the many.But in a scenario that simulated inevitable harm against another human being, participants with strong psychopathic traits also used greater physical force, so we still wouldn't really want to be friends with them.\nAccording to the Hare Psychopathy Checklist, to determine if someone has psychopathic traits, all we have to do is assess 20 traits with a strength of 0, 1 or 2, resulting in a maximum score of 40.The cut-off for psychopathy is 30 points in the US, 25 points in the UK (where this study was conducted) and sometimes 25 points for research purposes.These traits include impaired empathy, antisocial behaviour, callousness, impulsiveness, strong self-interest to the detriment of others, and a short attention span.To assess the level of psychopathy of the 40 participants of their study, researchers from the University of Plymouth put together an electronic questionnaire from four self-reporting tests, including the Levenson Self-Report Psychopathy Scale (which you can take here if, like us, you got curious) and the HEXACO Personality Inventory (which you can take here).\nThe participants were then presented with a moral dilemma, both in a questionnaire and with a simulated action component. The latter used a robotic system called vBOT to provide haptic feedback to realistically simulate the feeling of, say, the resistance that would occur if you needed to\u2026 stab someone.The moral dilemmas required the study participants to make the choice to physically kill someone for mercy or the greater good. For instance, sacrificing one person to save many, or mercy-killing an injured teammate who would otherwise be captured and tortured by the enemy.For the second part of the study, the researchers recruited 25 members of the public, rather than the university student volunteers used in the first half.These participants were presented with a full virtual reality version of the trolley dilemma that the researchers called the footbridge dilemm"
        ]
    },
    "8832": {
        "gold_standard": [
            "The recent popularity of \"designer\" dogs, cats, micro-pigs and other pets may seem to suggest that pet keeping is no more than a fad.Indeed, it is often assumed that pets are a Western affectation, a weird relic of the working animals kept by communities of the past.\nAbout half of the households in Britain alone include some kind of pet; roughly 10m of those are dogs while cats make up another 10m. Pets cost time and money, and nowadays bring little in the way of material benefits.But during the 2008 financial crisis, spending on pets remained almost unaffected, which suggests that for most owners pets are not a luxury but an integral and deeply loved part of the family.Some people are into pets, however, while others simply aren't interested. Why is this the case?It is highly probable that our desire for the company of animals actually goes back tens of thousands of years and has played an important part in our evolution.If so, then genetics might help explain why a love of animals is something some people just don't get.The health questionIn recent times, much attention has been devoted to the notion that keeping a dog (or possibly a cat) can benefit the owner's health in multiple ways \u2013 reducing the risk of heart disease, combating loneliness, and alleviating depression and the symptoms of depression and dementia.\nAs I explore in my new book, there are two problems with these claims.First, there are a similar number of studies that suggest that pets have no or even a slight negative impact on health.Second, pet owners don't live any longer than those who have never entertained the idea of having an animal about the house, which they should if the claims were true.And even if they were real, these supposed health benefits only apply to today's stressed urbanites, not their hunter-gatherer ancestors, so they cannot be considered as the reason that we began keeping pets in the first place.The urge to bring animals into our homes is so widespread that it's tempting to think of it as a universal feature of human nature, but not all societies have a tradition of pet-keeping.Even in the West there are plenty of people who feel no particular affinity for animals, whether pets or no.\nThe pet-keeping habit often runs in families: this was once ascribed to children coming to imitate their parents' lifestyles when they leave home, but recent research has suggested that it also has a genetic basis.Some people, whatever their upbringing, seem predisposed to seek out the company of animals, others less so.So the genes that promote pet-keeping may be unique to humans, but they are not universal, suggesting that in the past some societies or individuals \u2013 but not all \u2013 thrived due to an instinctive rapport with animals.Pet DNAThe DNA of today's domesticated animals reveals that each species separated from its wild counterpart between 15,000 and 5,000 years ago, in the late Palaeolithic and Neolithic periods. Yes, this was also when we started breeding livestock.But it is not easy to see how this could have been achieved if those first dogs, cats, cattle and pigs were treated as mere commodities.\nIf this were so, the technologies available would have been inadequate to prevent unwanted interbreeding of domestic and wild stock, which in the early stages would have had ready access to one another, endlessly diluting the genes for \"tameness\" and thus slowing further domestication to a crawl \u2013 or even reversing it.Also, periods of famine would also have encouraged the slaughter of the breeding stock, locally wiping out the \"tame\" genes entirely.But if at least some of these early domestic animals had been treated as pets, physical containment within human habitations would have prevented wild males from having their way with domesticated females; special social status, as afforded to some extant hunter-gatherer pets, would have inhibited their consumption as food.Kept isolated in these ways, the new semi-domesticated animals would have been able to evolve away from their ancestors' wild ways, and become the pliable beasts we know toda"
        ]
    },
    "8842": {
        "gold_standard": [
            "Journal of the American Chemical Society There's a lot we don't know about the actinides. On the periodic table, this series of heavy, radioactive elements hangs at the bottom, and includes a host of mysterious substances that don't naturally occur on Earth.\nAmong this cast of unknowns, berkelium looks to be even stranger than we realised. New experiments with this incredibly rare synthetic element have shown that its electrons don't behave the way they should, defying quantum mechanics.\"It's almost like being in an alternate universe because you're seeing chemistry you simply don't see in everyday elements,\" says chemist Thomas Albrecht-Schmitt from Florida State University.For years, Albrecht-Schmitt has studied the complex, radioactive world of actinides, including plutonium, californium, and berkelium.The latter, discovered in 1949, was named after the Berkeley scientists who first produced it, and one of the reasons it's so little understood, apart from its radioactivity, is because it's so difficult (and prohibitively expensive) to synthesise.\nIt's estimated that less than 1 gram of the element has been synthesised in the past 50 years. For his latest research, Albrecht-Schmitt was trusted with a whole 13 milligrams of the radioactive metal by the Department of Energy.That might not seem like much, sure, but it's about 1,000 times more than anyone else has given for major research studies, and it enabled the researchers to observe something they never expected to see.In a series of experiments over three years, the team engineered various compounds out of berkelium and observed that their electrons behaved unusually.At the top end of the periodic table, which is dominated by light elements, electrons line up in configurations that are explained by quantum theory.What Albrecht-Schmitt and fellow researchers discovered is that when it comes to berkelium, and other heavy elements, the principles of quantum mechanics can't actually explain what the electrons are doing.\nInstead, it looks like the electrons are governed by Einstein's theory of relativity, which predicts that as objects with mass move faster, they get heavier.In terms of the electrons in berkelium, the thinking goes that as the electrons begin to move at extremely fast speeds around each atom's highly charged nucleus \u2013 at up to significant fractions of the speed of light \u2013 this causes them to become heavy, and behave in ways that defy a quantum explanation of events.\"When you see this interesting phenomenon, you start asking yourself all these questions like how can you make it stronger or shut it down,\" says Albrecht-Schmitt.\"A few years ago, no one even thought you could make a berkelium compound.\"The work builds upon previous research involving berkelium compounds published last year by the same team, which also teased that berkelium was \"electronically different than what people expected\".\nAs this body of work builds, it's yet more evidence that berkelium, like the periodic table itself, is something that's almost impossible to pin down \u2013 and it remains to be seen just how far these mysterious actinides will make our best theories bend or break.\"What this really gives us is an understanding of how chemistry is changing late in the table,\" Albrecht-Schmitt explained last year.\"The purpose is to understand the underlying chemistry of the element. Even after having [berkelium] for almost 70 years, many of the basic chemical properties are still unknown.\"The findings are reported in the Journal of the American Chemical Societ"
        ]
    },
    "8857": {
        "gold_standard": [
            "Scientists have discovered a way to harvest electricity from the secretions produced by our eyes and several other parts of the body.It's all thanks to a protein called lysozyme, which generates electricity when it's put under pressure, and if we can harvest it effectively it could become a new fuel source for all kinds of implanted devices.\nLysozyme, which is present in tears, saliva, milk, mucus, and egg whites, is an enzyme that helps break down bacterial cell walls \u2013 but in its crystallised form, researchers from the University of Limerick in Ireland found it can also be manipulated to produce an electrical charge.By applying pressure to a film of lysozyme crystals squeezed between two glass slides, the team measured it producing a form of energy called piezoelectricity, where an electric charge accumulates in response to applied mechanical stress.Sean Curtin/True Media\"While piezoelectricity is used all around us, the capacity to generate electricity from this particular protein had not been explored,\"\u00a0explains\u00a0one of the researchers, physicist Aimee Stapleton.\n\"However, because it is a biological material, it is non-toxic so it could have many innovative applications such as electroactive anti-microbial coatings for medical implants.\"According to the team, the efficiency of lysozyme crystals rivals that of quartz crystals, which have long been known for their piezoelectric prowess, since being discovered by the French physicists Pierre and Jacques Curie in the late 19th century.But quartz of course is a non-biological material, so finding an equivalent that's compatible with the inner body could open the door to all kinds of new implantable piezoelectric devices, and it's the first time the potential has been observed in something as simple as protein.\"This is a new approach,\" says lead researcher, Tofail Syed, \"as scientists so far have tried to understand piezoelectricity in biology using complex hierarchical structures such as tissues, cells or polypeptides rather than investigating simpler fundamental building blocks.\"\nIf future research is able to take advantage of this discovery, the team anticipates a new era of flexible, energy-harvesting electronics could become possible.This could include new kinds of implants that release drugs in the body, controlled and powered by sensors that detect lysozyme under the skin.\"We also imagine that lysozyme may be employed as a biodegradable, piezoelectric, and antimicrobial additive/coating to conventional implants,\" the team explain in their paper.If this lysozyme-fuelled future eventuates, it won't be the first time this enzyme has contributed to scientific leaps.The protein was once investigated by Alexander Fleming as an antibiotic candidate before he discovered penicillin, and was one of the first proteins to ever be mapped in three dimensions back in 1965.\n\"In fact, it is the second protein structure and the first enzyme structure that was ever solved,\" says one of the team, structural biologist Tewfik Soulimane, \"but we are the first to use these crystals to show the evidence of piezoelectricity.\"So the next time your heart breaks and your eyes start welling up into quivering pools of hurt, don't just wipe those tears away: press them.The findings are reported in Applied Physics Letter"
        ]
    },
    "9028": {
        "gold_standard": [
            "A remote, protected world heritage area has been found to be the home of living stromatolites - the world's oldest evidence of lifeforms.They were found in freshwater spring mounds in the karstic wetlands of a wilderness area in Tasmania, Australia. These are wetlands with peaty soils over carbonate bedrock such as limestone, and waters that dissolve the bedrock into cave systems.\nIf you're looking for the oldest identifiable fossils on the planet, you're looking for stromatolites. Palaeontologists have found such fossils\u00a0dating back 3.7 billion years, a time when the first single-celled organisms appeared during the\u00a0Archaean Eon.The shape of stromatolites can vary, but they typically appear as rock structures. They are formed by single-celled photosynthesising microbes such as Cyanobacteria, which collectively form a layer called a biofilm.This biofilm is made of filaments composed of single-celled organisms, a bit like a felted mat. It traps sediment and minerals from the water and cements it in place, building up the stromatolite layer by painstaking layer.For this reason, stromatolites are an excellent tool for studying Earth's geological history.There are few places around the world where living stromatolites can be found today. They're usually found in hypersaline waters, because the salt deters animals from grazing. There are a few freshwater colonies too, such as Laguna Bacalar in Mexico and Salda G\u00f6l\u00fc in southern Turkey.\nThis new discovery marks the first time living stromatolites have been discovered in Tasmania, in a river catchment that's part of the\u00a0UNESCO-listed Tasmanian Wilderness World Heritage Area.\"The discovery reveals a unique and unexpected ecosystem in a remote valley in the state's south west,\" said lead author Bernadette Proemse, a geochemist at the University of Tasmania.\"The ecosystem has developed around spring mounds where mineral-rich groundwater is forced to the surface by geological structures in underlying limestone rocks. The find has proved doubly interesting, because closer examination revealed that these spring mounds were partly built of living stromatolites.\"The composition of the bacterial community, the paper said, is unique, consisting of Cyanobacteria, Alphaproteobacteria and an unusually high proportion of Chloroflexi, followed by Armatimonadetes and Planctomycetes.\nThe stromatolites are unusual too, rising several centimetres above the surface of the water, suggesting, the research team noted in the paper, a \"terrestrial\" variant.A cross section of the structure reveals alternating light and dark layers each about a millimetre thick. Spectroscopy confirms that they are made of calcium carbonate.Stromatolites in site (left) and the calcite layers (right). (Proemse et al./Scientific Reports)The waters in which the stromatolites grew are slightly alkaline and dominated by calcium bicarbonate, so this makes sense.Like hypersaline environments, alkaline waters are also inhospitable to other organisms - and it's possibly this factor that allows the stromatolites to thrive. The spring mounds, the researchers noticed, were littered with the shells of dead freshwater snails"
        ]
    },
    "2352": {
        "gold_standard": [
            "Your breath says more about you than you might think - not just how inebriated you are or what you had for breakfast.\u00a0A new type of sensor that can 'sniff out' traces of ovarian cancer in a patient's breath has been developed by researchers in Israel, offering a low-cost, and painless way to screen for the disease.\nWe've seen the idea of a breathalyser being used to detect different types of cancer\u00a0before, but what makes this new technology stand out is the amount of data that can be captured, as well as the compact size and low cost of the associated kit. On top of that, the researchers claim it's safer and more accurate than the detection methods that are currently in use.The sensors in the breathalyser are looking for volatile organic compounds (VOCs) in the breath samples: they use a flexible polymer substrate covered in gold nanoparticles to which the VOCs attach. By applying electrodes and a voltage to the resulting film, patterns can be identified, which are then matched up to various diseases.\"Changes in metabolism that accompany a specific illness cause changes in the composition and/or concentration of VOCs in the breath,\" lead researcher Nicole Kahn from the\u00a0Technion-Israel Institute of Technology told\u00a0Jordan Rosenfeld at\u00a0Mental Floss.Based on some initial testing, Kahn and her colleagues were able to correctly detect ovarian cancer in 82 percent of cases, which they say is a significant improvement on current detection methods, including special blood tests and transvaginal ultraound. The fact that having to give a breath sample is a non-invasive, safe, and easy often for patients means more women will hopefully be given the option to get screened. Right now, only high-risk patients are tested for ovarian cancer to reduce the chance of false positives,\u00a0and seeing as most women don't get symptoms until the disease is quite advanced, it means many cases go undetected until it's too late.\nWith further research, Kahn thinks the same technique could be used to test for different types of cancer, as well as other diseases such as Alzheimer's and Parkinson's. She also says there's still room for improvement in making the sensors smaller and more sensitive before they're ready for clinical use.Ovarian cancer currently accounts for around 3 percent of cancers among women, and with around 200,000 cases reported in the US each year, it's one of the rarer forms of the disease. However, it causes more deaths than any other cancer of the female reproductive system, and so new techniques to battle it would have a significant impact.The study has been published in the journal Nano Letters"
        ]
    },
    "9088": {
        "gold_standard": [
            "Proceedings of the National Academy of Sciences Volcanic eruptions inevitably call to mind the mental image of an incredibly hot, molten pool of magma, bursting forth from the ground in an orgy of fiery destruction.But you might be surprised to know that before the fireworks take place, that super-hot mass of molten rock isn't necessarily super-hot or molten at all \u2013 and could instead be trapped in a solidified form of 'cold storage', new research suggests.\n\"The older view is that there's a long period with a big tank of molten rock in the crust,\" says geoscientist Nathan Andersen from the University of Wisconsin-Madison.\"A new view is that magma is stored for a long period in a state that is locked, cool, crystalline, and unable to produce an eruption. That dormant system would need a huge infusion of heat to erupt.\"Such a huge infusion of heat is what's thought to have unleashed a violent supereruption in California some 765,000 years ago.This event, which produced the Long Valley Caldera in the east of the state, would have been beyond anything modern humans have seen in terms of volcanic eruptions, casting a layer of debris from the Pacific Ocean to Nebraska.\"It would have completely wiped out everything within 50 kilometres of the caldera,\" one of the researchers, geologist Brad Singer, told The New York Times.\n\"All the vegetation and biota in that area would have been extinguished.\"But as awesomely destructive as the supereruption was, lingering evidence from the aftermath can tell us about the magma conditions deep underground before the top blew so spectacularly.Specifically, an analysis of argon isotopes contained in crystals from the Bishop Tuff \u2013 the large rocky outcrop produced when the Long Valley Caldera was created \u2013 shows the magma from the supereruption was heated rapidly, not slowly simmered.Geologically speaking, that is \u2013 meaning the heating forces that produced the supereruption occurred over decades, or perhaps a couple of centuries. (A long time for people, sure, but a blink of an eye in the life-time of a supervolcano.)The reasoning is that argon quickly escapes from hot crystals, so it wouldn't have a chance to accumulate in the rock if the rock were super-heated for a long time.\nUsing a high-precision mass spectrometer, the team found argon isotopes spanning a 16,000-year range from the Bishop Tuff, which suggests argon remained from long before the supereruption took place, meaning the magma would have been cooler for longer, before heating suddenly.\"It must have cooled to the point that it was completely solid,\" Andersen explained to Newsweek.\"It had to be really a rock, at something more like 400 degrees [Celsius, 750 degrees Fahrenheit].\"Then, changing thermal conditions would have relatively quickly 'thawed' the rock preserved in cold storage, taking the magma to the necessary 700\u2013850 degree Celsius threshold required for an eruption, estimated to have produced something like 650 cubic kilometres of lava and ash.Unfortunately, while scientists are doing everything they can to read the signs of volcanic supereruptions \u2013 something NASA views as more dangerous than asteroid strikes \u2013 the reality is, the new findings don't bring us any closer to seeing the future.\"This does not point to prediction in any concrete way,\" Singer explains in a press statement, \"but it does point to the fact that we don't understand what is going on in these systems, in the period of 10 to 1,000 years that precedes a large eruption.\"The findings are reported in the Proceedings of the National Academy of Science"
        ]
    },
    "9101": {
        "gold_standard": [
            "The first American settlers may have arrived across a coastal \"kelp highway\" from northeast Asia, and arrived well before another culture that was previously thought to be first.\nThe Clovis culture that appeared in the Americas some 13,500 years ago is widely accepted to be the ancestor of most of the continents' indigenous cultures. However, with a growing body of evidence to back them up, anthropologists have declared the idea that the Clovis people were here first is now\u2026 dead.The Clovis people were so-named because artefacts of their culture were first found in Clovis, New Mexico in 1932. There are very few skeletal remains, but those of an infant boy named Anzick-1 from a Clovis burial site in Montana showed a genetic connection to modern Native American populations - and Siberia.It's thought that the Clovis people made their way to the Americas over land that used to span the Bering Sea during the last Ice Age, called the Bering Land Bridge, from Siberia.Not everyone agrees with the Siberian origin, since Anzick-1's genome showed genetic divergence from Siberian populations, but that the Clovis people existed is not under dispute.\nNow, according to a team of anthropologists from the US, more and more evidence points to earlier settlement - at a time when passage through the Bering Land Bridge would have been blocked by glaciers. Such arrivals would have had to travel a different route.\"In a dramatic intellectual turnabout, most archaeologists and other scholars now believe that the earliest Americans followed Pacific Rim shorelines from northeast Asia to Beringia and the Americas,\" the team writes in the latest study.\"According to the kelp highway hypothesis, deglaciation of the outer coast of North America's Pacific Northwest ~17,000 years ago created a possible dispersal corridor rich in aquatic and terrestrial resources along the Pacific Coast, with productive kelp forest and estuarine ecosystems at sea level and no major geographic barriers.\"Over the last few years, more and more evidence has suggested earlier settlements. A 2011 paper found stone tools in Texas that could date back 15,500 years, and petrified human faeces found in Oregon dates back 14,000 years.\nA mastodon skeleton was found with a piece of bone from another mastodon in its rib, indicating that humans had hunted it with bone spear points. It dates back 13,800 years. And just last year, a paper was released describing a butchered mastodon in Florida, dating back 14,550 years.\"There is a coalescence of data - genetic, archaeological, and geologic - that support a colonisation around 20,000\u201315,000 years ago,\" senior researcher Torben Rick from the US National Museum of Natural History told Seeker.\"This doesn't preclude earlier migrations, or suggest that we should not investigate earlier migrations, but a growing body of evidence is building on intensive research that supports the 20,000\u201315,000 years ago \u00a0timeframe, and evidence for earlier migrations is problematic and speculative.\"Sea levels have risen since that time, the ocean has eroded the shoreline, and the shorelines have migrated, so evidence of those early migrations is rare, the researchers said"
        ]
    }
}
