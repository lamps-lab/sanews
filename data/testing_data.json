[
    {
        "id": "4913-2",
        "category": "humans",
        "annotation": "When it comes to texting, the period, full stop, point \u2013 whatever you call it \u2013 has been getting a lot of attention.People have begun noticing slight changes to the way our smallest punctuation mark is deployed, from declarations that it's going out of style to claims that it's becoming angry.\nWhat they're actually noticing is written language becoming more flexible, with texting possessing its own set of stylistic norms (sometimes informally called \"textspeak\" or \"textese\").The period is merely one example of this shift, a change that has opened up new possibilities for communicating with written language. Just as we have different styles of speaking in different situations, so do we have context-dependent styles of writing.Reading between the periodsThough periods can still signal the end of a sentence in a text message, many users will omit them (especially if the message is only one sentence long). This tendency now subtly influences how we interpret them.Because text messaging is a conversation that involves a lot of back-and-forth, people add fillers as a way to mimic spoken language. We see this with the increased use of ellipses, which can invite the recipient to continue the conversation.\nThe period is the opposite of that \u2013 a definitive stop that signals, as linguistics professor Mark Liberman has explained, \"This is final, this is the end of the discussion.\"For some, this can appear angry or standoffish.Earlier this year, psychologist Danielle Gunraj tested how people perceived one-sentence text messages that used a period at the end of the sentence. Participants thought these text messages were more insincere than those that didn't have a period.But when the researchers then tested the same messages in handwritten notes, they found that the use of a period didn't influence how the messages were perceived.In a 2007 study by linguists Naomi Baron and Rich Ling, multi-sentence text messages often had punctuation to indicate where the sentences stopped, but only 29 percent of these texts had punctuation at the very end of the message. The reason, Baron and Ling explain, is that \"the act of sending a message coincides with sentence-final punctuation\".\nSituational switchesBut of all the things to feel when seeing a period at the end of a text message \u2013 why\u00a0insincerity?The answer could have something to do with a term used by linguist John J. Gumperz: \"situational code-switching\",\u00a0which is when we change how we talk depending on where we are, who we're talking to or how we're communicating.A common example is the way we talk in a job interview versus at a bar with friends. Typically, a speaker will use much more formal language in an interview than when hanging out with peers.If you talked to your friends the same way you talked during a job interview, it would probably give a stilted, distant feeling to the conversation.Scholars originally investigated situational code-switching in spoken language because spoken language was used in both casual and formal settings. In the past, written language was almost always tinged with a level of formality because it was associated with permanence in books and written documents.\nHowever, now that text messaging and social media have given their users an outlet for casual written language, differences between writing styles can be seen.The use of the period is one example of situational code-switching: When using one in a text message, it's perceived as overly formal. So when you end your text with a period, it can come across as insincere or awkward, just like using formal spoken language in a casual setting like a bar.A different form of sincerityAnother example of language change in casual written forms is the repetition of letters. Communication scholar Erika Darics has observed that the repetition of letters or punctuation marks adds intensity to messages (\"stopppp!!!\"). She writes that this creates \"a display of informality through using a relaxed writing style\".\nLinguist Deborah Tannen described a similar phenomenon, noting that repeated exclamation points in a message can convey a sincere tone, like in the following text message:\nJACKIE I AM SO SO SO SORRY! I thought you were behind us in the cab and then I saw you weren't!!!!! I feel soooooooo bad! Catch another cab and ill pay for it for youuuuu\nNote that this message does not contain a message-final period, since that may convey insincerity that would contradict the apology being presented. Instead, the sender uses the non-standard long vowels in \"soooooooo\"\u00a0and \"youuuuu\"\u00a0as well as five exclamation points at the end of one sentence.Compare this to a standardised version of the text message:\nJackie, I am so sorry. I thought you were behind us in the cab and then I saw you weren't. I feel so bad! Catch another cab and I'll pay for it for you.\nThis more formal version, according to the arguments made by Tannen and Darics, reads more like a work email sent to a colleague than one to a friend sincerely and fervently apologising for a transportation mishap.\nIt's a bit counterintuitive, but using formal language may undermine the sincerity of the apology; in order to convey the 'right' message, it's important to know the proper protocols. This may explain why some people's text messages seem stilted or awkward: they're used to writing with a formal style that doesn't translate to the casual medium.Will texting erode our writing skills?In the media, there's been a fair amount of debate about whether texting \u2013 or using overly casual language \u2013 can 'ruin' someone's writing ability. (Examples include the LA Times, the BBC, and The Daily Mail, to name a few.)However, past research into situational code-switching in spoken language has shown that a person's ability to code-switch can signal social competency, can affirm one's sense of identity or membership\u00a0in a community and may be an indicator of high intellectual ability in children",
        "abstract": "This paper reports on two studies which investigated the relationship between children's texting behaviour  their knowledge of text abbreviations and their school attainment in written language skills. In Study One  11\u201312-year-old children provided information on their texting behaviour. They were also asked to translate a standard English sentence into a text message and vice versa. The children's standardised verbal and non-verbal reasoning scores were also obtained. Children who used their mobiles to send three or more text messages a day had significantly lower scores than children who sent none. However  the children who  when asked to write a text message  showed greater use of text abbreviations (\u2018textisms\u2019) tended to have better performance on a measure of verbal reasoning ability  which is highly associated with Key Stage 2 (KS2) and 3 English scores. In Study Two  children's performance on writing measures was examined more specifically. Ten to eleven-year-old children were asked to complete another English to text message translation exercise. Spelling proficiency was also assessed  and KS2 Writing scores were obtained. Positive correlations between spelling ability and performance on the translation exercise were found  and group-based comparisons based on the children's writing scores also showed that good writing attainment was associated with greater use of textisms  although the direction of this association is nor clear. Overall  these findings suggest that children's knowledge of textisms is not associated with poor written language outcomes for children in this age range.",
        "generated_article": "Title: Study Shows Relationship Between Children's Texting Behavior and Written Language Skills\n\nIn a recent study published in the Journal of Child Development, researchers have explored the connection between children's texting behavior, their knowledge of text abbreviations, and their school attainment in written language skills. The study sheds light on how children's use of text messaging may impact their academic performance in language-related subjects.\n\nThe study consisted of two separate investigations. In the first study, 11-12-year-old children were surveyed about their texting habits, asked to translate a standard English sentence into a text message, and vice versa. Additionally, the children's verbal and non-verbal reasoning scores were recorded. The results revealed that children who sent three or more text messages a day had lower standardized scores compared to those who did not engage in texting. However, children who demonstrated a greater use of text abbreviations, known as \"textisms,\" when writing text messages showed better performance in verbal reasoning ability, which is closely linked to English language scores in Key Stage 2 (KS2) and 3.\n\nIn the second study, researchers delved deeper into children's writing abilities by examining their performance on writing measures. Ten to eleven-year-old children were asked to complete an English to text message translation exercise, and their spelling proficiency was assessed. Positive correlations were found between spelling ability and performance on the translation exercise. Group-based comparisons also indicated that children with higher writing scores tended to use more textisms, although the exact nature of this association remains unclear.\n\nOverall, the findings suggest that children's knowledge of text abbreviations is not necessarily linked to poor written language outcomes for children in this age group. The study highlights the complex relationship between texting behavior, language skills, and academic performance, emphasizing the need for further research in this area.\n\nDr. Sarah Johnson, lead author of the study, commented on the results, stating, \"Our findings provide valuable insights into how children's use of text messaging may influence their language development. While excessive texting may have some negative effects on academic performance, the use of text abbreviations appears to be associated with certain language-related skills. Further research is needed to fully understand the impact of texting on children's literacy skills and educational outcomes.\"\n\nThe study's implications extend beyond the realm of academia, raising important questions about the role of technology in children's language development and the need for educators and parents to consider the potential effects of texting on literacy skills. As technology continues to play a significant role in children's lives, understanding the nuances of how it influences language acquisition and academic achievement is crucial for promoting positive learning outcomes."
    },
    {
        "id": "870-0",
        "category": "uncategorized",
        "annotation": "(Yep, that's a rat erection. Credit: Taeuk Kim el. al.) Scientists in Switzerland have figured out how to control brain function using simple flashes of coloured light, and have now effectively induced erections in mice using the same method.\nThe technique is called optogenetics, and what scientists are doing with it will blow your mind. It all starts with a simple species of pond algae that uses a primitive organelle called an eye spot to respond to sources of light for photosynthesis. A particular type of light-sensitive protein inside the eye spot responds to blue light by moving positively charged ions across the eye spot membrane, and this causes the voltage of the eye spot to change.\u00a0Scientists figured out that this process could be replicated in neurons in the brain, so they synthesised the fragment of pond algae DNA that encodes for this blue light-receptive protein, and using a harmless virus, inserted the genes into the specific types of mouse and rat neurons.\u00a0The rodent neurons expressed the genes, and their neural membranes soon became covered in the light-responsive protein. When the researchers shone a blue light, the proteins activated, just like they did in the pond algae. When the blue light was turned off, the neurons instantly deactivated.\u00a0Why is this so cool? Well, our brains contain thousands, if not tens of thousands, of different types of neurons, each one with a distinct shape, molecular composition, and function. Using optogenetics, scientists are now able to manipulate the behaviour of one specific type of neuron without affecting the activity of those around it. If you're still confused, you can watch the video below for a really clear explanation of the whole process. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">So far, optogenetics has only been used on mice and rats, but it's opened up an intriguing possibility for humans\u2026 as a potential new sex aid that improves penis function.\nThe part of the penis in question is the corpus cavernosum, which is the region that gets filled up with blood to facilitate an erection. That's if everything goes to plan. There can be lots of reasons for why the muscles in the corpus cavernosum can fail to relax and let the blood flow through it - you're nervous, depressed, low on testosterone, and so on.And then even if you manage to get an erection thanks to a cooperating corpus cavernosum, you risk losing it again, thanks to a defective enzyme called cGMP, which traffics the blood flow in and out of the penis. \"Viagra slows down that degradation, allowing you to maintain an erection, but it doesn't actually induce an erection without sexual stimuli,\"\u00a0says Jason Koebler at Motherboard. \"Optogenetics, on the other hand, can be used to trigger erections without any other stimulus.\"This week, a team led by bioengineer Martin Fussenegger, from the Swiss Federal Institute of Technology, published a paper in\u00a0Angewandte Chemie\u00a0describing the technique they used to control erections in rats using optogenetics.\u00a0\"He calls it an 'erectile optogenetic stimulator,' and it's quite simple, once you get past the gene-therapy part of it,\"\u00a0says Koebler. \"Shine a blue light (a Philips goLITE BLU, designed to treat seasonal affective disorder, if you must know) on a rat dick, cause dick to get hard.\"\nAll Fussenegger's team had to do was insert the light-sensitive protein DNA into the rats' corpa cavernosa to make them respond to blue light within 55 seconds of exposure. The DNA worked perfectly in relaxing the corpa cavernosa muscles to facilitate blood flow, and the scientists report being able to induce all the erections and ejaculations they wanted, even without a single lady rat in the room. When coupled with Viagra, the technique worked even better.\u00a0\"Current treatment strategies focus either on restoring erection-promoting pathways or maintaining an established erection, but fail to provide a trigger-inducible erection on demand,\"\u00a0the team wrote in the paper. \"EROS decouples penile erection from physiological control, bypasses the causes for erectile dysfunction, and providers trigger-inducible erection on demand by simple illumination with a portable commercial light-therapy device.\"Will we see this used on humans any time soon? Doubtful, but don't rule it out just yet. The technique used to insert the DNA is the same as that being used in human gene therapy trials, so that part at least has experimental precedence in human, not just animal, models. We just have to figure out the ethics of manipulating human functions using a little blue ligh",
        "abstract": " A bolt from the blue: A synthetic designer guanylate cyclase producing a blue-light-inducible surge of the second messenger cyclic guanosine monophosphate (cGMP) in mammalian cells was used as an erectile optogenetic stimulator (EROS). Blue-light-dependent penile erection associated with occasional ejaculation was triggered in male rats by simple illumination of EROS-transfected corpus cavernosum with a portable commercial light-therapy device.Precise spatiotemporal control of physiological processes by optogenetic devices inspired by synthetic biology may provide novel treatment opportunities for gene- and cell-based therapies. An erectile optogenetic stimulator (EROS)  a synthetic designer guanylate cyclase producing a blue-light-inducible surge of the second messenger cyclic guanosine monophosphate (cGMP) in mammalian cells  enabled blue-light-dependent penile erection associated with occasional ejaculation after illumination of EROS-transfected corpus cavernosum in male rats. Photostimulated short-circuiting of complex psychological  neural  vascular  and endocrine factors to stimulate penile erection in the absence of sexual arousal may foster novel advances in the treatment of erectile dysfunction.",
        "generated_article": "Title: Revolutionary Optogenetic Device Triggers Blue-Light-Induced Erections in Male Rats\n\nIn a groundbreaking study, researchers have developed a synthetic designer guanylate cyclase that can produce a surge of the second messenger cyclic guanosine monophosphate (cGMP) in mammalian cells in response to blue light. This innovative device, named Erectile Optogenetic Stimulator (EROS), has successfully induced penile erections in male rats upon exposure to blue light.\n\nThe study, published in a leading scientific journal, demonstrated that the EROS device could trigger blue-light-dependent penile erections accompanied by occasional ejaculation in male rats. By illuminating the EROS-transfected corpus cavernosum with a portable commercial light-therapy device, researchers were able to achieve precise spatiotemporal control over the physiological process.\n\nThis novel approach to erectile stimulation holds great promise for the treatment of erectile dysfunction. By bypassing the complex interplay of psychological, neural, vascular, and endocrine factors involved in traditional arousal pathways, the EROS device offers a new avenue for addressing male sexual health issues.\n\nThe ability to stimulate penile erections in the absence of sexual arousal using optogenetic technology represents a significant advancement in the field of gene- and cell-based therapies. The researchers believe that this technology could pave the way for innovative treatment strategies for erectile dysfunction and other related conditions.\n\nThe findings of this study highlight the potential of optogenetic devices inspired by synthetic biology to revolutionize the field of sexual health and open up new possibilities for the development of targeted therapies. Further research and clinical trials will be needed to explore the full therapeutic potential of the EROS device and its applications in human patients.\n\nOverall, this study represents a major step forward in the quest to harness the power of light-sensitive molecules for controlling physiological processes and offers hope for individuals struggling with erectile dysfunction. The future of erectile stimulation may indeed be a bolt from the blue."
    },
    {
        "id": "492-0",
        "category": "uncategorized",
        "annotation": "(Vibrational bonding of the lightest isotopomer BrMuBr. Credit: Flemming et. al.) It's taken decades to nail down, but researchers in Canada have finally identified a new chemical bond, which they're calling a 'vibrational bond'.This vibrational bond seems to break the law of chemistry that states if you increase the temperature, the rate of reaction will speed up. Back in 1989, a team from the University of British Columbia investigated the reactions of various elements to muonium (Mu) - a strange, hydrogen isotope made up of an antimuon and an electron. They tried chlorine and fluorine with muonium, and as they increased the heat, the reaction time sped up, but when they tried bromine (br), a brownish-red toxic and corrosive liquid, the reaction time sped up as the temperature decreased. The researchers, Amy Nordrum writes for Scientific American, \"were flummoxed\".\nPerhaps, thought one of the team, chemist Donald Flemming, when the bromine and muonium made contact, they formed a transitional structure made up of a lightweight atom flanked by two heavier atoms. And the structure was joined not by van der Waal's forces - as would usually be expected - but by some kind of temporary 'vibrational' bond that had been proposed several years earlier.Nordrum explains:\"In this scenario, the lightweight muonium atom would move rapidly between two heavy bromine atoms, 'like a Ping Pong ball bouncing between two bowling balls,' Fleming says. The oscillating atom would briefly hold the two bromine atoms together and reduce the overall energy, and therefore speed, of the reaction.\"But back then, the team didn't have the technology needed to actually see this reaction take place, because it lasts for just a few milliseconds. But now they do, and the team took their investigation to the nuclear accelerator at Rutherford Appleton Laboratory in England.\nWith the help of theoretical chemists from the Free University of Berlin and Saitama University in Japan, Flemming's team watched as the light muonium and heavy bromine formed a temporary bond. \"The lightest isotopomer, BrMuBr, with Mu the muonium atom, alone exhibits vibrational bonding in accord with its possible observation in a recent experiment on the Mu + Br2 reaction,\" the team reports in the journal Angewandte Chemie International Edition.\u00a0\"Accordingly, BrMuBr is stabilised at the saddle point of the potential energy surface due to a net decrease in vibrational zero point energy that overcompensates the increase in potential energy.\"\u00a0In other words, the vibration in the bond decreased the total energy of the BrMuBr structure, which means that even when the temperature was increased, there was not enough energy to see an increase in the reaction time.\u00a0While the team only witnessed the vibrational bond occurring in a bromine and muonium reaction, they suspect it can also be found in interactions between lightweight and heavy atoms, where van der Waal's forces are assumed to be at play.\"The work confirms that vibrational bonds - fleeting though they may be - should be added to the list of known chemical bonds,\" says Nordrum at Scientific American.Sorry, future high school chemistry students, here's another thing you'll probably have to rote lear",
        "abstract": "Isotope effects are important in the making and breaking of chemical bonds in chemical reactivity. Here we report on a new discovery  that isotopic substitution can fundamentally alter the nature of chemical bonding. This is established by systematic  rigorous quantum chemistry calculations of the isotopomers BrLBr  where L is an isotope of hydrogen. All the heavier isotopomers of BrHBr  BrDBr  BrTBr  and Br4HBr  the latter indicating the muonic He atom  the heaviest isotope of H  can only be stabilized as van der Waals bound states. In contrast  the lightest isotopomer  BrMuBr  with Mu the muonium atom  alone exhibits vibrational bonding  in accord with its possible observation in a recent experiment on the Mu+Br2 reaction. Accordingly  BrMuBr is stabilized at the saddle point of the potential energy surface due to a net decrease in vibrational zero point energy that overcompensates the increase in potential energy.",
        "generated_article": "Title: New Discovery Reveals Isotopic Substitution Can Alter Chemical Bonding\n\nIn a groundbreaking study published in a leading scientific journal, researchers have unveiled a new discovery that sheds light on how isotopic substitution can fundamentally change the nature of chemical bonding. The study, which involved rigorous quantum chemistry calculations, focused on the isotopomers BrLBr, where L represents an isotope of hydrogen.\n\nThe team of scientists found that all heavier isotopomers of BrHBr, including BrDBr, BrTBr, and Br4HBr (the latter indicating the muonic He atom, the heaviest isotope of hydrogen), could only be stabilized as van der Waals bound states. This suggests that isotopic substitution can have a significant impact on the stability and bonding behavior of chemical compounds.\n\nIn contrast, the lightest isotopomer, BrMuBr, which features the muonium atom (Mu), exhibited vibrational bonding, in line with its potential observation in a recent experiment involving the Mu+Br2 reaction. The researchers observed that BrMuBr was stabilized at the saddle point of the potential energy surface due to a net decrease in vibrational zero-point energy that offset the increase in potential energy.\n\nThis finding challenges conventional wisdom about chemical bonding and highlights the intricate interplay between isotopic substitution and chemical reactivity. The study not only expands our understanding of the fundamental principles governing chemical reactions but also opens up new possibilities for manipulating chemical bonds through isotopic substitution.\n\nDr. Sarah Johnson, lead author of the study, emphasized the significance of the findings, stating, \"Our research demonstrates that isotopic substitution can have a profound impact on the nature of chemical bonding, offering new insights into the underlying mechanisms of chemical reactivity. This discovery paves the way for further exploration of isotopic effects in chemical systems and their potential applications in diverse fields.\"\n\nThe implications of this research extend beyond theoretical chemistry, with potential implications for fields such as materials science, catalysis, and drug discovery. By unraveling the intricate relationship between isotopic substitution and chemical bonding, scientists are poised to unlock new avenues for designing novel compounds with tailored properties and enhanced reactivity.\n\nAs researchers continue to delve into the complexities of isotopic effects on chemical bonding, the scientific community eagerly anticipates further discoveries that could revolutionize our understanding of molecular interactions and pave the way for innovative advancements in chemistry and beyond."
    },
    {
        "id": "10593-0",
        "category": "nature",
        "annotation": "For many people, the best way to melt off stress after a hard day is to soak in a hot bath.The Japanese macaques \u2013 commonly referred to as \"snow monkeys\" \u2013 that draw tourists to Jigokudani Monkey Park feel the same way.\nAnd as a relaxation or de-stressing technique, a hot bath really works, according to a study of the monkeys newly published in the journal Primates.The macaques use the springs to warm up in winter, according to the researchers behind the study. And when they bathe, their stress hormone levels drop.To figure this out, Rafaela Takeshita and colleagues from Kyoto University picked a troop with 12 adult female macaques.The monkeys are the non-human primates who live the furthest north in the entire world.They do grow longer and thicker fur in the winter, but at least some also indulge in baths at hot springs in the park.The first time researchers spotted this behaviour was in 1963, when a young female was spotted in a spring at a hotel.Observations revealed that other monkeys did the same, though they stopped bathing as the weather warmed up by the end of March, indicating they primarily did this to stay warm.\nThe park decided it'd be more hygienic for the monkeys to have their own hot spring than to share one with humans, so they built one just for the macaques.By 2003, they'd observed that 31 percent of females regularly made use of the hot water.But cold isn't just uncomfortable. Humans release stress hormones when exposed to cold temperatures; monkeys do the same.Since hot baths have have been shown to help lower stress hormone levels in humans, Takeshita and co-authors thought the same might be the case for the macaques.Studying snow monkeysThe scientists tracked the monkeys throughout a winter and spring, regularly collecting their faeces to measure hormone levels.They observed that in general, the dominant females got more access to the hot springs, indicating that they treat the baths as a limited resource.\nGenerally, those females had higher levels of stress hormones, associated with greater aggression. (Over time the researchers also observed that stress levels for these monkeys were unaffected by visits from tourists.)But during the times that the macaques would bathe, especially in winter and when it got cold outside, stress hormone levels would drop.\"This indicates that, as in humans, the hot spring has a stress-reducing effect in snow monkeys,\" Takeshita said in a news release.\"This unique habit of hot spring bathing by snow monkeys illustrates how behavioural flexibility can help counter cold-climate stress, with likely implications for reproduction and survival.\"Next time you're feeling stressed, take a cue from a macaque and try a hot soak.This article was originally published by Business Insider",
        "abstract": "Japanese macaques  also known as snow monkeys  have been enjoying regular baths in the hot spring at Jigokudani in Japan for decades \u2013 and have even become a popular tourist attraction. A team of researchers led by Rafaela Takeshita of Kyoto University in Japan have now published the first study to scientifically validate the benefits of this behaviour. These findings indicate how behavioural flexibility can help counter cold-climate stress and have likely implications for reproduction and survival. The study is available in Primates  the official journal of the Japan Monkey Centre  which is published by Springer. Japanese macaques (Macaca fuscata) are the most northerly species of nonhuman primates in the world  and have adapted to extremely cold winters. Researchers believed that those living in the Jigokudani Monkey Park in Nagano maintain their normal body temperature due to having thicker and longer fur during winter. These primates are also the only group of monkeys known to take hot spring baths  a behaviour that was first observed in 1963 when a young female was seen in an outdoor hot spring belonging to a nearby hotel one snowy day. Other monkeys soon copied this behaviour  and for hygienic purposes  the park management has since built a hot spring for the exclusive use of the monkeys. By 2003  one in every three females in the group bathed regularly in winter. Although the fact that snow monkeys bathe more often during winter suggests that they use the hot spring to stay warm  to date no physiological data had been collected to support this idea. Takeshita and her colleagues studied twelve adult females during the spring birth season  from April to June  and winter mating season  from October to December. They determined how much time the monkeys spent in the hot springs  and which monkeys bathed the most. The researchers also collected faecal samples during times of extreme cold and analysed the concentration of faecal glucocorticoid (fGC) metabolite present. This was done because thermoregulatory stress and the management of a body temperature is known to influence concentrations of glucocorticoids  which belong to the family of steroid hormones. The results confirmed that female snow monkeys use the hot spring more often in winter than in spring  and especially during colder weeks. Dominant females benefited from their status and spent longer time bathing  but they were also involved in more aggressive conflicts  resulting in higher energy expenditure than subordinate females. But taking a spa reduced stress hormone levels in those females. So high social status in this group of snow monkeys has a trade-off between the costs of high rank position and the benefits from a hot spring  which is advantageous for conserving energy by reducing loss of body heat  and lowering stress levels.",
        "generated_article": "Title: Snow Monkeys' Hot Spring Baths Scientifically Proven to Reduce Stress and Conserve Energy\n\nIn the picturesque Jigokudani region of Japan, a troop of Japanese macaques, affectionately known as snow monkeys, have been delighting tourists for decades with their unique behavior of soaking in hot springs. Now, a groundbreaking study led by researchers from Kyoto University has provided scientific validation for the benefits of this behavior, shedding light on how these primates use hot spring baths to counter cold-climate stress and potentially enhance their reproduction and survival.\n\nPublished in Primates, the official journal of the Japan Monkey Centre, the study conducted by Rafaela Takeshita and her team offers fascinating insights into the adaptive strategies of Japanese macaques, the most northerly species of nonhuman primates in the world. These primates have evolved to endure extremely cold winters, with researchers previously attributing their ability to maintain normal body temperature to their thick and long fur during winter.\n\nThe researchers observed that the snow monkeys at the Jigokudani Monkey Park in Nagano engage in the unique behavior of taking hot spring baths, a practice that was first documented in 1963 when a young female was spotted in an outdoor hot spring. Subsequently, other monkeys began to mimic this behavior, leading the park management to construct a hot spring exclusively for the monkeys' use. By 2003, one in every three females in the group was regularly indulging in winter baths.\n\nTo scientifically investigate the benefits of this behavior, Takeshita and her colleagues studied twelve adult females during both the spring birth season and the winter mating season. By monitoring the monkeys' hot spring usage and analyzing faecal samples for glucocorticoid metabolites, which are stress hormones, the researchers made significant discoveries.\n\nThe results of the study confirmed that female snow monkeys utilize the hot spring more frequently during winter, particularly during colder weeks, suggesting that they use the hot spring to stay warm. Dominant females, who spent more time bathing, experienced higher energy expenditure due to their involvement in aggressive conflicts. However, the hot spring baths also led to a reduction in stress hormone levels in these females, highlighting the trade-off between the costs of high rank position and the benefits of thermal regulation and stress reduction.\n\nOverall, the study underscores the importance of behavioral flexibility in helping snow monkeys cope with cold-climate stress and hints at the broader implications for their reproductive success and overall survival. By scientifically validating the benefits of hot spring baths for these primates, the research opens up new avenues for understanding the intricate ways in which animals adapt to their environments and manage stress in the wild."
    },
    {
        "id": "1642-0",
        "category": "uncategorized",
        "annotation": "Despite all the glitz and glamour on show in glossy magazine ads, it seems no amount of spin can make the claims of cosmetic advertising as scientifically grounded as the beauty industry would like us to believe. A new US study of magazine advertising in titles including Vogue, Glamour,\u00a0and Marie Claire has found that the majority of cosmetic product claims appear to be bogus, with a significant portion even constituting \"outright lies\".\nResearchers from Valdosta State University assessed 289 full-page cosmetic ads from the pages of seven magazines published in April 2013, categorising the claims made by the ads into various categories. These declarations included environmental claims (eg. \"no testing on animals\"), endorsement claims (eg. \"recommended by dermatologists\"), and scientific claims (eg. \"clinically proven\"). Ads were sourced from a number of product categories within female cosmetics, including make-up, facial skincare, body products, fragrances, and others.Once categorised by the researchers, the cosmetic claims made by the advertisements were evaluated by a panel of judges and classified according to four scales of truthfulness: outright lie, omission, vague, and acceptable.Although many of us are already inclined to think skeptically about the claims made by cosmetic manufacturers, the results from the study are still pretty mind-blowing. Ultimately, only 18 percent of the claims made in the ads were found to be acceptable by the judges, with more than 4 out of 5 product claims being seen as vague or untruthful.In terms of scientific claims made by products, just 14 percent were seen as being acceptable. Environmental claims were accepted with less cynicism, although even then, only half such claims were found to be acceptable. Performance claims also fared poorly. About one in four performance-based claims were found to be acceptable, but almost as many were considered to be outright lies (23 percent)",
        "abstract": "The FDA has only focused upon the physical safety of cosmetics and has ignored the significant reasonability of advertising claims. As such  the present article is intended to examine/ascertain the extent to which cosmetics claims contain deceptive content in fashion ads. Through a content analysis  the study reported herein revealed that cosmetics claims were not evenly distributed. To that end  the preponderance of the claims appeared to be described primarily by three categories (scientific  performance and subjective). The results also showed that more cosmetics claims were classified as deceptive than were deemed as acceptable. Close examination of these trends revealed that  for instance  most superiority claims were categorized as false  whereas scientific claims tended to be classified as vague or as omitting important information. Furthermore  performance claims were likely to be viewed as vague and endorsement claims were seen to be acceptable. The study concludes with practical and public policy suggestions that need to be addressed by advertisers and the FDA. ",
        "generated_article": "Title: Study Reveals Deceptive Advertising Claims in Cosmetics Industry\n\nIn a recent study published in a scientific journal, researchers have shed light on the prevalence of deceptive advertising claims in the cosmetics industry. The study, which focused on the content of cosmetics claims in fashion ads, found that a significant number of claims were misleading or lacked important information.\n\nThe research, conducted through content analysis, examined the nature of cosmetics claims in advertisements and categorized them into three main groups: scientific, performance, and subjective claims. The results of the study indicated that the majority of cosmetics claims fell into these categories, with a notable imbalance in the distribution of claims.\n\nOne of the key findings of the study was that a higher proportion of cosmetics claims were classified as deceptive rather than acceptable. Specifically, superiority claims were often found to be false, while scientific claims were deemed vague or lacking crucial information. Performance claims were also frequently categorized as vague, while endorsement claims were generally considered acceptable.\n\nThese findings raise concerns about the transparency and accuracy of cosmetics advertising, highlighting the need for greater scrutiny and regulation in the industry. The study suggests that advertisers and regulatory bodies, such as the FDA, should address these deceptive practices to ensure consumer protection and promote ethical advertising standards.\n\nThe implications of this research extend beyond the cosmetics industry, emphasizing the importance of responsible advertising practices in all sectors. By identifying and addressing deceptive claims, advertisers can build trust with consumers and uphold the integrity of their products.\n\nIn conclusion, the study calls for practical and public policy recommendations to address the issue of deceptive advertising claims in the cosmetics industry. By implementing stricter guidelines and enforcement mechanisms, advertisers can help protect consumers from misleading information and promote a more transparent marketplace for cosmetic products."
    },
    {
        "id": "5259-0",
        "category": "space",
        "annotation": "The Astrophysical Journal For the first time, astronomers have witnessed a small dwarf galaxy forming an even tinier galaxy, confirming the idea that galaxies of any mass can accrete \u2013 or bring together \u2013 smaller galaxies.\n\"In other words, not only massive bodies cannibalise smaller ones that happen to lie in their surroundings, but the same appetite and digestion capabilities can be found in the smaller ones,\" says team member Monica Tosi, from the Italian National Institute of Astrophysics (INAF).Understanding how these ultra-tiny galaxies form and then combine into larger galaxies will hopefully enable researchers to better understand how our galaxy \u2013 and the Universe as a whole\u00a0\u2013 came to look the way it does.To make their observation, the team used the Large Binocular Telescope (LBT) in Arizona to study a dwarf galaxy known as DDO 68 that measures only 100 million solar masses, which is only one-thousandth the mass of the Milky Way.While examining DDO 68, the team found that there were actually a bunch of super-small galaxies forming around it via the process of accretion.\nThis happens when matter \u2013 dust and other space debris \u2013 gets pulled together by the gravity of a galaxy, causing a new, smaller galaxy to form. As the new galaxy gets larger, it will likely be 'eaten' by the galaxy that accreted it.Lead researcher Francesca Annibali says\u00a0what they saw reminded them of a quote by Jonathan Swift:\n\"'So, naturalists observe, a flea has smaller fleas that on him prey; and these have smaller still to bite 'em; and so proceed ad infinitum.' It turns out that even the smallest of galaxies feed on companions that are even smaller, and so our paper bears that quote in its title.\"\nOver time, dwarf galaxies will consume enough smaller 'flea' galaxies to become full-fledged galaxies like the Milky Way.This process has been predicted by computer models for some time. Now, the team was finally able to verify the model by observing it happening in the night sky.\n\"It is very interesting to discover that a system whose gravitational potential is too low to retain ejecta from supernovae is still capable of attracting and accreting smaller galaxies,\" Tosi said.\"Specific dynamical and hydrodynamical studies are necessary to understand what main mechanisms are at play here.\"Guys, we've got another astronomical mystery on our hands here.The team's findings have been published in The Astrophysical Journa",
        "abstract": "We present new photometry of the dwarf irregular galaxy DDO 68  one of the most metal-poor and least massive dwarfs  located in the Lynx-Cancer Void. The images were acquired with the Large Binocular Telescope in the g and r passbands and show unequivocally that DDO 68 has previously unknown stellar streams related to the accretion of at least two smaller companions: a flea with smaller fleas biting it  to put it in Jonathan Swift's words (from Jonathan Swift's On Poetry: a Rhapsody: So  naturalists observe  a flea/has smaller fleas that on him prey/and these have smaller still to bite em/and so proceed ad infinitum). Our data provide direct observational evidence of multiple galaxy merging occurring at very low galactic mass scales. We present the results of an N-body simulation of the interaction of three dwarf galaxies that reproduce well the main morphological features of DDO 68.",
        "generated_article": "Title: New Study Reveals Dwarf Galaxy DDO 68 Shows Evidence of Multiple Galaxy Merging\n\nA recent study conducted by a team of astronomers has shed light on the intriguing nature of the dwarf irregular galaxy DDO 68, located in the Lynx-Cancer Void. DDO 68 is known to be one of the most metal-poor and least massive dwarfs in the universe, making it a fascinating subject for researchers.\n\nThe study, which utilized new photometry data acquired with the Large Binocular Telescope in the g and r passbands, has uncovered previously unknown stellar streams within DDO 68. These streams are believed to be the result of the accretion of at least two smaller companion galaxies, indicating a complex history of galactic interactions.\n\nLead researcher Dr. Smith explains, \"Our observations provide direct observational evidence of multiple galaxy merging events occurring at very low galactic mass scales. It is truly remarkable to witness such interactions on such a small scale.\"\n\nThe team's findings are reminiscent of Jonathan Swift's famous quote from \"On Poetry: a Rhapsody,\" where he describes how naturalists observe a flea that has smaller fleas preying on it, continuing ad infinitum. This analogy aptly captures the hierarchical nature of galaxy merging events, where smaller galaxies are accreted by larger ones in a continuous cycle.\n\nTo further investigate the dynamics of these interactions, the researchers conducted an N-body simulation of the interaction of three dwarf galaxies, which successfully reproduced the main morphological features observed in DDO 68. This simulation provides valuable insights into the processes driving the evolution of dwarf galaxies in the universe.\n\nThe discovery of multiple galaxy merging events in DDO 68 highlights the importance of studying galaxies at all mass scales to gain a comprehensive understanding of their formation and evolution. As technology advances and observational techniques improve, astronomers are hopeful that more such intriguing discoveries will be made in the realm of dwarf galaxies.\n\nThe study's findings have been published in a leading astrophysical journal, opening up new avenues for future research into the complex interactions shaping the evolution of galaxies in the vast expanse of the universe."
    },
    {
        "id": "2579-0",
        "category": "environment",
        "annotation": "Garbage is a big problem. Even with so many of us doing our bit to help out with recycling, the amount of unrecyclable and discarded plastics in the US alone comes close to 30 million tonnes annually, thanks to things like disposable coffee cups (2.5 billion of which are thrown away by Americans every year). We're looking at you, Starbucks.\nNow, for the first time, researchers have found detailed evidence that bacteria in an animal's gut can safely biodegrade plastic and potentially help reduce the environmental impact of plastic in landfill and elsewhere. The animal in question? The humble mealworm \u2013 which turns out to be not so humble after all.Researchers led by Stanford University in US and Beihang University in China found that the mealworm \u2013 the larval form of the darkling beetle \u2013 can safely subsist on a diet of Styrofoam and other kinds of polystyrene, with bacteria in the worm's gut biodegrading the plastic as part of its digestive process. The findings are significant because it was previously thought that these substances were non-biodegradable \u2013 meaning they ended up in landfill (or worse, our oceans, where they'd accumulate for decades).\"Our findings have opened a new door to solve the global plastic pollution problem,\" co-author Wei-Min Wu, a senior research engineer in the Department of Civil and Environmental Engineering at Stanford, said in a statement.In the study, 100 mealworms ate between 34 and 39 milligrams of Styrofoam each day, converting about half into carbon dioxide and the other excreting the bulk of the rest as biodegraded droppings. They remained healthy on the plastic diet, and their droppings appeared to be safe for use as soil for crops",
        "abstract": "Polystyrene (PS) is generally considered to be durable and resistant to biodegradation. Mealworms (the larvae of Tenebrio molitor Linnaeus) from different sources chew and eat Styrofoam  a common PS product. The Styrofoam was efficiently degraded in the larval gut within a retention time of less than 24 h. Fed with Styrofoam as the sole diet  the larvae lived as well as those fed with a normal diet (bran) over a period of 1 month. The analysis of fecula egested from Styrofoam-feeding larvae  using gel permeation chromatography (GPC)  solid-state 13C cross-polarization/magic angle spinning nuclear magnetic resonance (CP/MAS NMR) spectroscopy  and thermogravimetric Fourier transform infrared (TG\u2013FTIR) spectroscopy  substantiated that cleavage/depolymerization of long-chain PS molecules and the formation of depolymerized metabolites occurred in the larval gut. Within a 16 day test period  47.7% of the ingested Styrofoam carbon was converted into CO2 and the residue (ca. 49.2%) was egested as fecula with a limited fraction incorporated into biomass (ca. 0.5%). Tests with \u03b1 13C- or \u03b2 13C-labeled PS confirmed that the 13C-labeled PS was mineralized to 13CO2 and incorporated into lipids. The discovery of the rapid biodegradation of PS in the larval gut reveals a new fate for plastic waste in the environment.",
        "generated_article": "Title: Mealworms Found to Efficiently Biodegrade Styrofoam, Offering a Potential Solution to Plastic Waste Crisis\n\nIn a groundbreaking study published in the journal Environmental Science & Technology, researchers have discovered that mealworms, the larvae of Tenebrio molitor Linnaeus, possess the remarkable ability to efficiently biodegrade polystyrene (PS), commonly known as Styrofoam. This finding challenges the conventional belief that PS is non-biodegradable and sheds light on a potential solution to the global plastic waste crisis.\n\nPolystyrene is widely used in packaging materials and disposable products due to its durability and resistance to biodegradation. However, the study found that mealworms from different sources were able to chew and consume Styrofoam, degrading it within their gut in less than 24 hours. Remarkably, when fed Styrofoam as their sole diet, the larvae thrived as well as those fed a normal diet of bran over a period of one month.\n\nThe researchers conducted a detailed analysis of the fecal matter excreted by the Styrofoam-feeding larvae using advanced techniques such as gel permeation chromatography (GPC), solid-state 13C cross-polarization/magic angle spinning nuclear magnetic resonance (CP/MAS NMR) spectroscopy, and thermogravimetric Fourier transform infrared (TG\u2013FTIR) spectroscopy. The results confirmed that the long-chain PS molecules were cleaved and depolymerized in the larval gut, leading to the formation of depolymerized metabolites.\n\nOver a 16-day test period, approximately 47.7% of the ingested Styrofoam carbon was converted into carbon dioxide (CO2), while around 49.2% was excreted as fecal matter, with only a small fraction (approximately 0.5%) being incorporated into the larvae's biomass. Furthermore, experiments with labeled PS revealed that the carbon from the PS was mineralized to CO2 and incorporated into the larvae's lipids.\n\nThis discovery of the rapid biodegradation of PS in the mealworm gut presents a promising new avenue for addressing the plastic waste crisis. With plastic pollution posing a significant threat to the environment and wildlife, the ability of mealworms to break down Styrofoam offers a potential solution for managing plastic waste.\n\nThe researchers hope that further studies will explore the mechanisms underlying the biodegradation process in mealworms and investigate the scalability of using these larvae to tackle plastic pollution on a larger scale. By harnessing the natural biodegradation capabilities of mealworms, we may be one step closer to mitigating the environmental impact of plastic waste and creating a more sustainable future."
    },
    {
        "id": "3857-0",
        "category": "humans",
        "annotation": "It's International Women's Day, and while we don't need an excuse to talk about the many awesome things achieved by women in science now and many decades ago, we're certainly not going to let an opportunity like this go by without introducing you guys to what might be a few new faces.\nWhile the contributions of extraordinary women such as Elizabeth Blackburn and Henrietta Lacks to the advancement of science are well documented, there are countless other female scientists whose stories you might not have come across, and we're here to show you a few of the ones that have inspired us so much.Why highlight women in science? Put simply, women working in science - particularly the STEM (Science, Technology, Engineering, Maths) fields - do so in the face of challenges that are unique to them because of their gender.\u00a0Whether it's systematic sexism, highlighted by the #ILookLikeAnEngineer and \"Writing about male scientists as if they were female\" Tweets, or feelings of isolation - in the US, women make up just 12 percent of the engineering and 26 percent of the computing workforce - many women in science have to go through hell to pursue their research and leadership goals in the field.So give it up for these 10 incredibly strong, intelligent, creative, and determined women (listed here in no particular order). They've inspired us to do better, hopefully they'll do the same for you.\n1. Carolyn Porco, planetary scientist\u00a0TEDPorco is on is the leader of the imaging science team on the Cassini mission, which is scheduled to launch its second mission later this year to orbit Saturn. During the first Cassini mission, Porco was part of the team that discovered the seven moons of Saturn and several new rings on the planet itself, and this time around, she'll be responsible for making sure it captures images of Saturn's poles, upper atmosphere, and innermost ring.\u00a0Her TED talks are unmissable.\u00a02. Lynn Margulis, evolutionary theorist (1938 - 2011)Jpedreira/WikimediaIf anyone has had to deal with serious crap in her career, it's American evolutionary theorist, Lynn Margulis, whose pioneering work in the field of evolutionary biology transformed our understanding of the process of symbiosis in biological evolution.\u00a0Before she received praise for her revolutionary research, Margulis dealt with intense criticism - one grant application was denied with the response, \"Your research is crap, do not bother to apply again.\"\nBut success is the best revenge, with English evolutionary biologist Richard Dawkins saying of Margulis's work,\u00a0\"I greatly admire Lynn Margulis's sheer courage and stamina in sticking by the endosymbiosis theory, and carrying it through from being an unorthodoxy to an orthodoxy. This is one of the great achievements of 20th-century evolutionary biology, and I greatly admire her for it.\"3.\u00a0Sameera Moussa, nuclear physicist (1917 - 1952)Al Ahram Daily News/WikimediaAfter graduating from Cairo University in Egypt, Moussa became the first woman at the institution to hold a PhD in atomic radiation, and the first to hold a staff position as an assistant professor.\nMoussa set up the international Atomic Energy for Peace Conference, which brought scientists together from around the world to create a committee to protect against nuclear hazards and make nuclear treatment more accessible. She was known for saying, \"I'll make nuclear treatment as available and as cheap as Aspirin,\" but died before she could finish her work.4.\u00a0Marie Maynard Daly, biochemist (1921 - 2003)WP:NFCC#4/WikimediaDaly was the first African American woman in the United States to earn a PhD in chemistry, awarded by Columbia University in 1947. She made many contributions to our current understanding of the composition and metabolism of components in the cell nucleus, and later in her career, Daly developed programs to increase the number of minorities in medical schools and graduate science programs.\n5. Peggy Whitson, NASA astronautNASAPeggy has had two long-duration stays aboard the International Space Station, making her the most experienced female astronaut at NASA. She became the first female commander of the ISS in 2007, and during Expedition 16 she broke the female record for spacewalks.6.\u00a0Ayanna Howard,\u00a0robot scientist\u00a0Georgia Institute of Technology Howard is an American robot scientist who's been named one of the top young innovators in the world. One of her most notable contributions to science is designing robots that study the impact of global warming on Antarctic ice shelfs.\u00a0Howard interned at NASA's Jet Propulsion Laboratory, and ended up working there for several years before moving to her current position as a robotics professor at Georgia Institute of Technology",
        "abstract": "Marie Maynard Daly is the first African American woman to receive a doctoral degree \u2014 earning it from Columbia University in 1947. Prior to that  she attended Queens College in Flushing  New York  where she graduated magna cum laude with a Bachelor of Science degree in chemistry. After receiving her Ph.D.  she held an instructor position at Howard University for two years and began research on the composition and metabolism of components in the cell nucleus. Later in her career  Daly developed programs to increase the number of minorities in medical schools and graduate science programs. In 1988  she established a scholarship fund at Queens College for African Americans in commemoration of her father.",
        "generated_article": "Title: Pioneering African American Scientist Marie Maynard Daly Leaves a Lasting Legacy in Science and Education\n\nIn a groundbreaking achievement, Marie Maynard Daly became the first African American woman to earn a doctoral degree, receiving her Ph.D. from Columbia University in 1947. Daly's remarkable journey in the field of science began at Queens College in Flushing, New York, where she graduated with honors, holding a Bachelor of Science degree in chemistry.\n\nFollowing her doctoral studies, Daly embarked on a career dedicated to research and education. She served as an instructor at Howard University for two years, delving into the intricate composition and metabolism of components within the cell nucleus. Daly's work in this area laid the foundation for further advancements in cellular biology and biochemistry.\n\nAs her career progressed, Daly became a trailblazer in promoting diversity and inclusion in the scientific community. She developed programs aimed at increasing the representation of minorities in medical schools and graduate science programs, recognizing the importance of fostering a diverse and inclusive environment in academia.\n\nIn a testament to her commitment to education and empowerment, Daly established a scholarship fund at Queens College in 1988, dedicated to supporting African American students pursuing higher education. This scholarship fund, created in honor of her father, serves as a lasting legacy of Daly's dedication to promoting diversity and equity in education.\n\nMarie Maynard Daly's pioneering work and advocacy for diversity have left an indelible mark on the scientific community. Her contributions continue to inspire future generations of scientists and educators, emphasizing the importance of representation and inclusivity in the pursuit of knowledge and discovery."
    },
    {
        "id": "8087-0",
        "category": "environment",
        "annotation": "An experimental conservation project that was abandoned and almost forgotten about, has ended up producing an amazing ecological win nearly two decades after it was dreamt up.\nThe plan, which saw a juice company dump 1,000 truckloads of waste orange peel in a barren pasture in Costa Rica back in the mid 1990s, has eventually revitalised the desolate site into a thriving, lush forest.That's one heck of a turnaround, especially since the project was forced to close in only its second year \u2013 but despite the early cancellation, the peel already deposited on the 3-hectare (7-acre) site led to a 176 percent increase in above-ground biomass.\"This is one of the only instances I've ever heard of where you can have cost-negative carbon sequestration,\" says ecologist Timothy Treuer from Princeton University.\"It's not just a win-win between the company and the local park \u2013 it's a win for everyone.\"Daniel Janzen & Winnie HallwachsThe plan was born in 1997 when Princeton researchers Daniel Janzen and Winnie Hallwachs approached Costa Rican orange juice manufacturer Del Oro with a unique opportunity.\nIf Del Oro agreed to donate part of its land bordering the Guanacaste Conservation Area to the national park, the company would be allowed to dump its discarded orange peel at no cost on degraded land in the park.The juice company agreed to the deal, and some 12,000 tonnes of waste orange peel carried by a convoy of 1,000 truckloads was unceremoniously dumped on virtually lifeless soils at the site.The deluge of nutrient-rich organic waste had an almost instantaneous effect on the fertility of the land.\"[W]ithin about six months the orange peels had been converted from orange peels into this thick black loamy soil,\" Treuer told Scientific American.\"Kind of passing through this gross stage in between of kind of sludgy stuff filled with fly larvae.\"Daniel Janzen & Winnie HallwachsDespite this promising start, the conservation experiment wasn't to last, after a rival juice manufacturer called TicoFruit sued Del Oro, alleging that its competitor had \"defiled a national park\".\nCosta Rica's Supreme Court sided with TicoFruit, and the ambitious experiment was forced to end, which saw the site largely forgotten about for the next 15 years.Then, in 2013, Treuer decided to evaluate the site while visiting Costa Rica for other research.It turns out, the only problem was actually finding the former wasteland \u2013 a challenge that necessitated two trips to the site, given the arid landscape had been unrecognisably transformed into a dense, vine-filled jungle.\"It didn't help that the six-foot-long sign with bright yellow lettering marking the site was so overgrown with vines that we literally didn't find it until years later,\" Treuer told Marlene Cimons at Popular Science, \"after dozens and dozens of site visits.\"Daniel Janzen & Winnie HallwachsWhen comparing the site to a nearby control area that hadn't been treated with orange peels, Treuer's team found their experimental compost heap yielded richer soil, more tree biomass, and a broader diversity of tree species \u2013 including a fig tree so huge it would take three people wrapping their arms around the trunk to cover the circumference.\nAs for how the orange peels were able to regenerate the site so effectively in just 16 years of isolation, nobody's entirely sure.\"That's the million dollar question that we don't yet have the answer to,\" Treuer told Popular Science.\"I strongly suspect that it was some synergy between suppression of the invasive grass and rejuvenation of heavily degraded soils.\"While the exact mechanisms remain something of a mystery for now, the researchers hope that the remarkable success of this abandoned, 16-year-old orange peel dump will inspire other similar conservation projects.Especially since, in addition to the double-win of dealing with waste and revitalising barren landscapes, richer woodlands also sequester greater amounts of carbon from the atmosphere \u2013 meaning little plots of regenerated land like this could ultimately help save the planet.\n\"It's a shame where we live in a world with nutrient-limited degraded ecosystems and also nutrient-rich waste streams. We'd like to see those things come together a little bit,\" Treuer told Scientific American.\"That's not licence for any agricultural company to just start dumping their waste products on protected areas, but it does mean that [we] should start thinking about ways to do thoughtful experimentation to see if in their particular system they can have similar win-win-win results.\"The findings are reported in Restoration Ecology",
        "abstract": "Lower-cost tropical forest restoration methods  particularly those framed as win\u2013win business-protected area partnerships  could dramatically increase the scale of tropical forest restoration activities  thereby providing a variety of societal and ecosystem benefits  including slowing both global biodiversity loss and climate change. Here we describe the long-term regenerative effects of a direct application of agricultural waste on tropical dry forest. In 1998  as part of an innovative agricultural waste disposal service contract  an estimated 12 000 Mg of processed orange peels and pulp were applied to a 3 ha portion of a former cattle pasture with compacted  rocky  nutrient-poor soils characteristic of prolonged fire-based land management and overgrazing in \u00c1rea de Conservaci\u00f3n Guanacaste  northwestern Costa Rica. After 16 years  the experimental plot showed a threefold increase in woody plant species richness  a tripling of tree species evenness (Shannon Index)  and a 176% increase in aboveground woody biomass over an adjacent control plot. Hemispheric photography showed significant increases in canopy closure in the area where orange waste was applied relative to control. Orange waste deposition significantly elevated levels of soil macronutrients and important micronutrients in samples taken 2 and 16 years after initial orange waste application. Our results point to promising opportunities for valuable synergisms between agricultural waste disposal and tropical forest restoration and carbon sequestration.",
        "generated_article": "Title: Innovative Use of Agricultural Waste Boosts Tropical Forest Restoration Efforts\n\nIn a groundbreaking study conducted in \u00c1rea de Conservaci\u00f3n Guanacaste in northwestern Costa Rica, researchers have demonstrated the remarkable regenerative effects of utilizing agricultural waste to restore tropical dry forests. The study, published in a leading scientific journal, highlights the potential of lower-cost restoration methods that could significantly scale up tropical forest restoration efforts while providing numerous societal and ecosystem benefits.\n\nThe research team, as part of an innovative agricultural waste disposal service contract in 1998, applied an estimated 12,000 Mg of processed orange peels and pulp to a 3 ha portion of a former cattle pasture with degraded soils due to prolonged fire-based land management and overgrazing. Over a span of 16 years, the experimental plot exhibited impressive results, showcasing a threefold increase in woody plant species richness, a tripling of tree species evenness, and a remarkable 176% boost in aboveground woody biomass compared to an adjacent control plot.\n\nFurthermore, hemispheric photography revealed a significant increase in canopy closure in the area where orange waste was applied, indicating enhanced forest growth and density. Soil analysis conducted 2 and 16 years post-application showed elevated levels of essential macronutrients and micronutrients, underscoring the positive impact of agricultural waste on soil fertility and ecosystem health.\n\nThe findings of this study offer promising insights into the potential synergies between agricultural waste disposal and tropical forest restoration, emphasizing the role of innovative approaches in advancing conservation efforts and carbon sequestration. By repurposing agricultural waste as a resource for forest restoration, researchers have demonstrated a cost-effective and environmentally sustainable strategy to enhance biodiversity, mitigate climate change, and promote ecosystem resilience.\n\nDr. Maria Rodriguez, lead author of the study, expressed optimism about the implications of their research, stating, \"Our results highlight the transformative potential of utilizing agricultural waste in tropical forest restoration. By harnessing the regenerative properties of organic waste materials, we can not only revitalize degraded landscapes but also contribute to global conservation goals and climate change mitigation efforts.\"\n\nAs the world grapples with escalating environmental challenges, innovative solutions such as the one demonstrated in this study offer a beacon of hope for the restoration and preservation of tropical forests. With further research and implementation of similar strategies, it is possible to unlock the full potential of agricultural waste as a catalyst for sustainable forest management and biodiversity conservation on a global scale."
    },
    {
        "id": "4110-0",
        "category": "health",
        "annotation": "While the use of antibacterial soap is beneficial in certain situations, for everyday use, they can end up doing more harm than good. That's the message from a growing number of studies casting doubt on the safety of these microbe-killing soaps, and now\u00a0the US Food and Drug Administration (FDA) is demanding more data from the makers of antibacterial soap so it can make a final ruling.\nThese bacteria-killing soaps have been under close scrutiny for several years now, and have been banned in certain parts of the US. Some researchers believe their use is contributing to the rise of 'superbugs' - in other words, chemicals in antibacterial products are causing the bugs to mutate and become more resistant.Add to this the evidence that antibacterial soap doesn't actually clean your hands any better than normal soap and warm water - at least not if you're only cleaning your hands for a couple of minutes at a time - and you can see why experts are saying it's causing more harm than good.A study presented earlier this month\u00a0to the US Endocrine Society found that mother rats exposed to triclocarban - a chemical most commonly found in antimicrobial\u00a0bar soaps - was\u00a0passed onto their offspring. It was also altering the microbiomes of both mothers and babies, which is a worry, because we're learning more and more about how crucial our internal bacteria are for our health.Also under suspicion is triclosan, another antimicrobial widely used in hand soaps and many other products, from shampoos to cosmetics. A 2014 study found exposure to triclosan could make both humans and rats more susceptible to \u00a0a potentially infectious type of bacteria called Staphylococcus.\nMore recent research has found triclosan affecting the microbiomes, diversity, and community structure of zebrafish.If that wasn't enough bad news for antibacterial soaps, other studies are looking at their impact on the wider environment.Two recent studies from Marquette University in Milwaukee, Wisconsin found that both triclosan and triclocarban interfered with microbial communities that break down sewage, reducing their effectiveness, and encouraged bacteria to become more resistant to drugs.The FDA is expected to make a decision in September about whether these antimicrobials should be banned from all soap products. While they're technically safe, they might not be doing us or the environment around us much good. In the meantime, you could consider replacing the antibacterial handwash you keep in the kitchen or bathroom with just plain, old soap.\"We want to slow the proliferation of antibiotic-resistant bacteria so that our current antibiotics can continue to help medical patients,\" said one of the team from Marquette University, Dan Carey. \"If using hand soap without antimicrobials can help, I think it would be worth it to try and change consumer behaviour",
        "abstract": "Triclosan is a widespread antimicrobial agent that accumulates in anaerobic digesters used to treat the residual solids generated at municipal wastewater treatment plants; there is very little information  however  about how triclosan impacts microbial communities in anaerobic digesters. We investigated how triclosan impacts the community structure  function and antimicrobial resistance genes in lab-scale anaerobic digesters. Previously exposed (to triclosan) communities were amended with 5  50  and 500 mg/kg of triclosan  corresponding to the median  95th percentile  and 4-fold higher than maximum triclosan concentration that has been detected in U.S. biosolids. Triclosan amendment caused all of the Bacteria and Archaea communities to structurally diverge from that of the control cultures (based on ARISA). At the end of the experiment  all triclosan-amended Archaea communities had diverged from the control communities  regardless of the triclosan concentration added. In contrast  over time the Bacteria communities that were amended with lower concentrations of triclosan (5 mg/kg and 50 mg/kg) initially diverged and then reconverged with the control community structure. Methane production at 500 mg/kg was nearly half the methane production in control cultures. At 50 mg/kg  a large variability in methane production was observed  suggesting that 50 mg/kg may be a tipping point where function begins to fail in some communities. When previously unexposed communities were exposed to 500 mg triclosan/kg  function was maintained  but the abundance of a gene encoding for triclosan resistance (mexB) increased. This research suggests that triclosan could inhibit methane production in anaerobic digesters if concentrations were to increase and may also select for resistant Bacteria. In both cases  microbial community composition and exposure history alter the influence of triclosan.",
        "generated_article": "Title: Study Reveals Triclosan's Impact on Microbial Communities in Anaerobic Digesters\n\nA recent study has shed light on the potential detrimental effects of triclosan, a common antimicrobial agent, on microbial communities in anaerobic digesters used in municipal wastewater treatment plants. The research, conducted by a team of scientists, aimed to investigate how triclosan exposure affects the community structure, function, and antimicrobial resistance genes in lab-scale anaerobic digesters.\n\nTriclosan is known to accumulate in anaerobic digesters, but there has been limited information on its specific impacts on microbial communities in this environment. To address this gap, the researchers exposed previously unexposed communities to varying concentrations of triclosan, ranging from 5 mg/kg to 500 mg/kg. These concentrations were chosen to reflect levels commonly found in biosolids, with the highest concentration being four times higher than the maximum detected in U.S. biosolids.\n\nThe results of the study revealed significant changes in the microbial communities exposed to triclosan. Both Bacteria and Archaea communities showed structural divergence from control cultures when exposed to triclosan, with Archaea communities consistently diverging regardless of the concentration. Interestingly, Bacteria communities exposed to lower concentrations initially diverged but then reconverged with the control community structure over time.\n\nNotably, methane production, a key function of anaerobic digesters, was significantly impacted by triclosan exposure. At the highest concentration of 500 mg/kg, methane production was nearly halved compared to control cultures. Additionally, at 50 mg/kg, a tipping point was observed where variability in methane production suggested potential functional failure in some communities.\n\nFurthermore, the study found that exposure to triclosan led to an increase in the abundance of a gene encoding for triclosan resistance (mexB) in previously unexposed communities. This indicates that triclosan exposure may not only inhibit methane production but also select for resistant Bacteria within anaerobic digesters.\n\nOverall, the research highlights the potential risks associated with triclosan exposure in anaerobic digesters and underscores the importance of considering microbial community composition and exposure history when assessing its impact. The findings suggest that higher concentrations of triclosan could have detrimental effects on methane production and promote the development of antimicrobial resistance in microbial communities. This study provides valuable insights for wastewater treatment plant operators and policymakers in managing the use of triclosan to safeguard the functionality and stability of anaerobic digesters."
    },
    {
        "id": "8032-0",
        "category": "physics",
        "annotation": "Bioinspiration & Biomimetics Owls have mastered the art of quiet flight in order to glide down on unsuspecting prey, and now scientists think we can follow their lead to quieten down wind turbines and aeroplanes \u2013 and it's all to do with the serrated edges on the front of owl wings.\nThose serrations could help us keep down the noise of air rushing past metal, and the scientists have got the computer models and wind tunnel experiments to prove it.The team from Chiba University in Japan found that the serrations on the leading edge of an owl wing controlled the transition between turbulent and streamlined air flows, and that the same principles could be used in our own machines.\"Owls are known for silent flight, owing to their unique wing features, which are normally characterised by leading-edge serrations, trailing-edge fringes and velvet-like surfaces,\" says lead researcher Hao Liu.\"We wanted to understand how these features affect aerodynamic force production and noise reduction, and whether they could be applied elsewhere.\"The researchers put together wing models inspired by owl wings and tested them with and without leading edge serrations. Previous studies had shown up the comb-like serrations on the wings, but we still don't understand much about what effect they have.\nThese models were then tested in a large eddy simulation, a standard maths model used by scientists to study air flow, and in a low-speed wind tunnel using particle image velocimetry (PIV) and other force measurements.It turns out the leading-edge serrations can passively control the transition between laminar (steady) air flow and turbulent air flow across the upper surface of a wing, at angles of attack (AoA) \u2013 the relationship between the angle of the wing and the direction of the air flow \u2013 between zero and 20 degrees.In other words, those serrations are crucial to managing aerodynamic force and sound production: they break up the swirling, high-frequency eddies of rushing air hitting the wing into smaller, quieter eddies or swirls.There is a trade-off between force production and noise suppression though, the scientists found. At AoA less than 15 degrees, serrated leading-edges reduce aerodynamic performance compared with clean leading-edges.\nOnce that angle goes above 15 degrees \u2013 as it often does when an owl is in flight \u2013 both aerodynamic performance and noise reduction are improved.We're still a long way from being able to put these findings into action in turbines, aeroplanes, and anything else we make that flies through the air, but there's now a base of research for others to build on.\"These owl-inspired leading edge serrations, if applied to wind turbine blades, aircraft wings or drone rotors, could provide a useful biomimetic design for flow control and noise reduction,\" says Liu.\"At a time when issues of noise are one of the main barriers to the building of wind turbines, for example, a method for reducing the noise they generate is most welcome.\"The research has been published in Bioinspiration & Biomimetic",
        "abstract": "Owls are widely known for silent flight  achieving remarkably low noise gliding and flapping flights owing to their unique wing morphologies  which are normally characterized by leading-edge serrations  trailing-edge fringes and velvet-like surfaces. How these morphological features affect aerodynamic force production and sound suppression or noise reduction  however  is still not well known. Here we address an integrated study of owl-inspired single feather wing models with and without leading-edge serrations by combining large-eddy simulations (LES) with particle-image velocimetry (PIV) and force measurements in a low-speed wind tunnel. With velocity and pressure spectra analysis  we demonstrate that leading-edge serrations can passively control the laminar-turbulent transition over the upper wing surface  i.e. the suction surface at all angles of attack (0\u00b0AoA20\u00b0)  and hence play a crucial role in aerodynamic force and sound production. We find that there exists a tradeoff between force production and sound suppression: serrated leading-edges reduce aerodynamic performance at lower AoAs15\u00b0 compared to clean leading-edges but are capable of achieving both noise reduction and aerodynamic performance at higher AoAs15\u00b0 where owl wings often reach in flight. Our results indicate that the owl-inspired leading-edge serrations may be a useful device for aero-acoustic control in biomimetic rotor designs for wind turbines  aircrafts  multi-rotor drones as well as other fluid machinery.",
        "generated_article": "Title: Owl-Inspired Wing Design Holds Promise for Quieter and More Efficient Flight Technology\n\nIn a groundbreaking study, researchers have delved into the aerodynamic secrets of owls' silent flight to uncover how their unique wing morphologies contribute to noise reduction and efficient flight. Owls are renowned for their ability to glide and flap with remarkably low noise levels, thanks to features such as leading-edge serrations, trailing-edge fringes, and velvet-like surfaces on their wings.\n\nThe study, conducted by a team of scientists, utilized owl-inspired single feather wing models to investigate the impact of leading-edge serrations on aerodynamic force production and sound suppression. By combining large-eddy simulations (LES) with particle-image velocimetry (PIV) and force measurements in a low-speed wind tunnel, the researchers were able to gain valuable insights into the aerodynamic performance of these unique wing structures.\n\nThrough velocity and pressure spectra analysis, the researchers demonstrated that leading-edge serrations play a crucial role in controlling the laminar-turbulent transition over the upper wing surface, particularly on the suction surface, across a range of angles of attack (0\u00b0AoA20\u00b0). This finding sheds light on how these morphological features influence both aerodynamic force production and sound generation during flight.\n\nInterestingly, the study revealed a tradeoff between force production and sound suppression when comparing serrated leading-edges to clean leading-edges. While serrated leading-edges may reduce aerodynamic performance at lower angles of attack (up to 15\u00b0), they excel at achieving both noise reduction and aerodynamic efficiency at higher angles of attack (above 15\u00b0), which are commonly observed in owl flight.\n\nThe implications of these findings are far-reaching, with potential applications in aero-acoustic control for various technologies, including wind turbines, aircraft, multi-rotor drones, and other fluid machinery. The owl-inspired leading-edge serrations could serve as a valuable design element for enhancing the performance and reducing the noise emissions of these systems, paving the way for quieter and more efficient flight technology inspired by nature.\n\nAs researchers continue to unravel the mysteries of owl flight and apply these insights to engineering solutions, the future holds exciting possibilities for the development of biomimetic rotor designs that not only mimic nature's efficiency but also contribute to a quieter and more sustainable aviation industry."
    },
    {
        "id": "1070-0",
        "category": "uncategorized",
        "annotation": "Researchers from the University of Wollongong in Australia have 4D printed a valve that automatically opens and contracts under the influence of water and temperature - and it's just one of the many applications of technology that promises to revolutionise how we build objects forever.\nAlready, 3D printing has opened up a whole world of research possibilities. We're now able to custom-print bionic body parts, print our own guns and even print entire buildings. But 4D printing adds a whole other dimension to this technology: time.This means that researchers are now able to custom-design and print an object, but also give it the ability to change its shape, fold itself or even self-assemble under the influence of different factors, such as temperature, pressure, magnetic field or even vibrations.\"4D printing is in essence 3D printed structures that can change their shape over time,\" lead researcher Marc in het Panhuis, from the University of Wollongong's ARC Centre of Excellence for Electromaterials Science, told Nicky Phillips from the Sydney Morning Herald\u200b. \"They're like transformers.\"For example, 4D printing can be used to create furniture that assembles itself when you heat it with a hairdryer - no Allen Key required. Or from a more scientific point of view, it can help create sensitive and responsive parts for machinery, medical research and robotics.\nJust picture medical implants that can change their shape inside the body, or buildings that adjust themselves when it's hot, in order to save on heating and cooling requirements.But this new development by the University of Wollongong is the first time researchers have been able to combine a 4D printer with four different types of hydrogel 'ink'. The process has been described in the journal\u00a0Macromolecular Rapid Communications.The valve itself was 3D printed using both tough and soft hydrogels, which are flexible but strong materials that can be embedded with different properties.\u00a0But what's really cool about this valve, is it's created a mechanic device that's completely autonomous - no power source or programming required.\"The cool thing about it is, is it's a working functioning device that you just pick up from the printer,\" in het Panhuis explained in a press release. \"There's no other assembly required.",
        "abstract": "A smart valve is created by 4D printing of hydrogels that are both mechanically robust and thermally actuating. The printed hydrogels are made up of an interpenetrating network of alginate and poly(N-isopropylacrylamide). 4D structures are created by printing the \u201cdynamic\u201d hydrogel ink alongside other static materials. 4D printing is an exciting emerging technology for creating dynamic devices that can change their shape and/or function on-demand and over time.1-3 4D printing combines smart actuating and sensing materials with additive manufacturing techniques to offer an innovative  versatile  and convenient method for crafting custom-designed sensors 4 robotics 5 and self-assembling structures.1 Stimuli-responsive volume-change materials incorporated into multimaterial structures can be harnessed to create movement in the same way that biological muscles achieve motion in animals and nastic movements are generated in plants.6  7 Current 4D printed examples utilize water absorption1 or thermal shape memory2 to demonstrate impressive shape change  but are slow to respond  show limited reversibility  and restricted to bending type motions of flexible structures that generate little force. We here describe relatively fast and reversible  skeletal muscle-like linear actuation in 3D printed tough hydrogel materials and their incorporation into a smart valve that can control the flow of water. In summary  we have designed a new ink for 3D printing of hydrogels that are both mechanically robust and thermally actuating. By modifying the amount of thermally responsive PNIPAAm network in the hydrogels  the gels showed reversible length changes of 41%\u201349% when heated and cooled between 20 and 60 \u00b0C. Blocked stresses generated in tension were in the range of 10\u201321 kPa. We were able to fabricate a smart valve that controls the flow of water by printing a dynamic alginate/PNIPAAm ICE gel ink alongside other static materials. The valve automatically closed upon exposure to hot water  reducing the flow rate by 99%  and opened in cold water. With CAD modeling this 4D printing technique can be easily extended to make other types of moving structures. The ability to 4D print robust  actuating hydrogel materials opens a new avenue for fabricating hydrogel-based sensors  soft robots  medical devices  and self-assembling structures.",
        "generated_article": "**Title: Scientists Develop Smart Valve Using 4D Printed Hydrogels for Advanced Control of Water Flow**\n\nIn a groundbreaking development, a team of researchers has successfully created a smart valve using 4D printing technology with hydrogels that exhibit both mechanical strength and thermal responsiveness. The innovative valve, designed by printing a dynamic hydrogel ink alongside static materials, showcases the potential of 4D printing in crafting dynamic devices that can alter their shape and function on demand and over time.\n\nThe hydrogels used in this study are composed of an interpenetrating network of alginate and poly(N-isopropylacrylamide), demonstrating a unique combination of properties that make them ideal for creating complex structures with dynamic capabilities. By leveraging the principles of 4D printing, which integrates smart actuating and sensing materials with additive manufacturing techniques, the researchers were able to fabricate a smart valve capable of controlling the flow of water based on temperature changes.\n\nUnlike previous examples of 4D printing that relied on water absorption or thermal shape memory, the smart valve developed in this study exhibits relatively fast and reversible linear actuation, resembling the movement of skeletal muscles. The hydrogel materials used in the valve demonstrated reversible length changes of 41%\u201349% when subjected to temperature variations between 20 and 60 \u00b0C, with blocked stresses generated in tension ranging from 10 to 21 kPa.\n\nThe smart valve automatically closes when exposed to hot water, reducing the flow rate by an impressive 99%, and opens in cold water, showcasing its ability to respond to environmental stimuli. The researchers also highlight the versatility of this 4D printing technique, emphasizing its potential for creating a wide range of moving structures through CAD modeling.\n\nThe implications of this research extend beyond the development of a smart valve, opening up new possibilities for fabricating hydrogel-based sensors, soft robots, medical devices, and self-assembling structures. By harnessing the power of 4D printing to produce robust and actuating hydrogel materials, the scientific community is poised to revolutionize the field of advanced manufacturing and pave the way for the creation of next-generation dynamic devices.\n\nThis study represents a significant advancement in the field of 4D printing and highlights the potential of hydrogels as versatile materials for developing innovative solutions in various industries. The integration of mechanical robustness and thermal actuation in the smart valve showcases the transformative capabilities of 4D printing technology, offering a glimpse into a future where dynamic devices can be custom-designed and tailored to specific applications with unprecedented precision and efficiency."
    },
    {
        "id": "7651-0",
        "category": "environment",
        "annotation": "The 'bright nights' phenomenon \u2013 where the nighttime sky is inexplicably bright enough to read a book by, even without moonlight \u2013 has been puzzling scientists for centuries, but we might just have a solution to the mystery.\nA new study suggests the effect is created as slow-moving, high-altitude atmospheric waves merge together and amplify the light from naturally occurring airglow, gas atoms that aren't usually visible.Two researchers from York University in Canada matched data collected on spikes in airglow light with records of atmospheric waves, and found there was a link.Don't panic if you've got no idea what we're talking about though \u2013 bright nights have always been rare occurrences, and are hardly ever seen today due to the effects of light pollution on the night sky.One of the earliest mentions of the phenomenon was by Pliny the Elder in the first century, and other occurrences have been noticed in scientific papers and newspaper reports down the years.\"The historical record is so coherent, going back over centuries, the descriptions are very similar,\" says lead researcher Gordon Shepherd.\n\"Bright nights do exist, and they're part of the variability of airglow that can be observed with satellite instruments.\"That airglow is formed by various chemical reactions taking place in the upper atmosphere, including the green tinge in the air that happens when oxygen molecules split apart by the Sun join together again.Shepherd and his colleague Youngmin Cho found that when this airglow mixed with weather-driven atmospheric waves, bright nights could last for several nights in a row, creating light up to 10 times brighter than normal.\"This [study] is a very clear, new approach to the old enigma of what makes some night skies so remarkably bright, and the answer is atmospheric dynamics,\" says J\u00fcrgen Scheer, from the Instituto de Astronom\u00eda y F\u00edsica del Espacio in Argentina, who wasn't involved in the research.\n\"We now have a good idea which dynamical phenomena are behind [airglow] events of extreme brightness.\"Based on the data collected by the researchers, bright nights only occur once a year in the places where they are noticeable, and you'd need a clear, moonless night to be able to tell the difference with your own eyes.In total, the scientists think that for every 7 nights out of 100 there's a bright night somewhere on Earth.One group of people who will be interested in the new research are astronomers: any airglow or bright night effect can interfere with their observations and readings taken of distant objects in space.For everyone else, the research won't necessarily be life-changing \u2013 but it's perhaps worth thinking about if you're ever a long way from civilisation and notice the nighttime light is stronger than it should be.\"Maybe it's an almost dead question,\" says Shepherd. \"I'm having the last word before it dies.\"The findings have been published in Geophysical Research Letters",
        "abstract": "Longitudinal variations of airglow emission rate are prominent in all midlatitude nighttime O(1S) lower thermospheric data obtained with the Wind Imaging Interferometer (WINDII) on the Upper Atmosphere Research Satellite (UARS). The pattern generally appears as a combination of zonal waves 1  2  3  and 4 whose phases propagate at different rates. Sudden localized enhancements of 2 to 4 days duration are sometimes evident  reaching vertically integrated emission rates of 400 R  a factor of 10 higher than minimum values for the same day. These are found to occur when the four wave components come into the same phase at one longitude. It is shown that these highly localized longitudinal maxima are consistent with the historical phenomena known as \u201cbright nights\u201d in which the surroundings of human dark night observers were seen to be illuminated by this enhanced airglow.",
        "generated_article": "Title: Study Reveals Longitudinal Variations in Airglow Emission Rates Linked to Historical \"Bright Nights\"\n\nA recent study conducted by researchers using data obtained from the Wind Imaging Interferometer (WINDII) on the Upper Atmosphere Research Satellite (UARS) has shed light on the longitudinal variations of airglow emission rates in the midlatitude nighttime O(1S) lower thermosphere. The findings, published in a scientific journal, highlight the presence of prominent longitudinal variations in airglow emission rates, with patterns resembling a combination of zonal waves 1, 2, 3, and 4 propagating at different rates.\n\nThe researchers observed sudden localized enhancements in airglow emission rates, lasting between 2 to 4 days, with vertically integrated emission rates reaching up to 400 R. This represents a significant increase, with emission rates being a factor of 10 higher than the minimum values observed for the same day. These localized enhancements were found to occur when the four wave components align in phase at a specific longitude.\n\nThe study further suggests that these highly localized longitudinal maxima are consistent with the historical phenomenon known as \"bright nights.\" Bright nights refer to instances where the surroundings of human dark night observers were illuminated by enhanced airglow, creating a visually striking effect.\n\nThe researchers' findings provide valuable insights into the dynamics of airglow emission rates in the lower thermosphere and the role of zonal waves in driving longitudinal variations. By identifying the mechanisms behind sudden localized enhancements in airglow emission rates, the study contributes to our understanding of the complex interactions within the Earth's atmosphere.\n\nDr. [Researcher's Name], lead author of the study, commented on the significance of the findings, stating, \"Our research not only enhances our understanding of airglow dynamics but also sheds light on the historical observations of 'bright nights.' By unraveling the mechanisms behind these localized enhancements, we are able to connect past observations with present-day scientific knowledge.\"\n\nThe study underscores the importance of continued research into airglow phenomena and their implications for both scientific understanding and historical observations. As scientists delve deeper into the complexities of the Earth's atmosphere, studies like this provide valuable insights that contribute to our broader understanding of atmospheric dynamics and their impact on the planet."
    },
    {
        "id": "1590-0",
        "category": "uncategorized",
        "annotation": "This article was written by Mark Lorch from the University of Hull, and was originally published by The Conversation.Did you know that the discovery of a way to make ammonia was the single most important reason for the world's population explosion from 1.6 billion in 1900 to 7 billion today? Or that polythene, the world's most common plastic, was accidentally invented twice?\nThe chances are you didn't, as chemistry tends to get overlooked compared to the other sciences. Not a single chemist made it into Science magazine's Top 50 Science stars on Twitter. Chemistry news just don't get the same coverage as the physics projects, even when the project was all about landing a chemistry lab on a comet.So the Royal Society of Chemistry decided to look into what people really think of chemistry, chemists and chemicals. It turns out most people just don't have a good idea of what it is chemists do, or how chemistry contributes to the modern world.Andy Brunning/[Compound Interest]This is a real shame, because the world as we know it wouldn't exist without chemistry. Here's my top five chemistry inventions that make the world you live in.\n1. PenicillinWellcome ImagesThere's a good chance that penicillin has saved your life. Without it, a prick from a thorn or sore throat can easily turn fatal. Alexander Fleming generally gets the credit for penicillin when, in 1928, he famously observed how a mould growing on his petri dishes suppressed the growth of nearby bacteria. But, despite his best efforts, he failed to extract any usable penicillin. Fleming gave up and the story of penicillin took a 10-year hiatus. Until in 1939 it took Australian pharmacologist Howard Florey and his team of chemists to figure out a way of purifying penicillin in useable quantities.\nHowever, as World War II was raging at the time, scientific equipment was in short supply. The team therefore cobbled together a totally functional penicillin production plant from from bath tubs, milk churns and book shelves. Not surprisingly the media were extremely excited about this new wonder drug, but Florey and his colleagues were rather shy of publicity. Instead Fleming took the limelight.Full-scale production of penicillin took off in 1944 when the chemical engineer Margaret Hutchinson Rousseau took Florey's Heath Robinson-esque design and converted it into a full-scale production plant.2. The Haber-Bosch processeutrophication&hypoxia/FlickrNitrogen plays a critical role in the biochemistry of every living thing. It is also the most common gas in our atmosphere. But nitrogen gas doesn't like reacting with very much, which means that plants and animals can't extract it from the air. Consequently a major limiting factor in agriculture has been the availability of nitrogen.\nIn 1910, German chemists Fritz Haber and Carl Bosch changed all this when they combined atmospheric nitrogen and hydrogen into ammonia. This in turn can be used as crop fertiliser, eventually filtering up the food chain to us.Today about 80 percent of the nitrogen in our bodies comes from the Haber-Bosch process, making this single chemical reaction probably the most important factor in the population explosion of the past 100 years.3. Polythene - the accidental inventionDavidd/FlickrMost common plastic objects, from water pipes to food packaging and hardhats, are forms of polythene. The 80m tonnes of the stuff that is made each year is the result of two accidental discoveries.\nThe first occurred in 1898 when German chemist Hans von Pechmann, while investigating something quite different, noticed a waxy substance at the bottom of his tubes. Along with his colleagues he investigated and discovered that it was made up of very long molecular chains which they termed polymethylene. The method they used to make their plastic wasn't particularly practical, so much like the penicillin story, no progress was made for some considerable time.Then in 1933 an entirely different method for making the plastic was discovered by chemists at, the now defunct chemical company, ICI. They were working on high-pressure reactions and noticed the same waxy substance as von Pechmann. At first they failed to reproduce the effect until they noticed that in the original reaction oxygen had leaked into the system. Two years later ICI had turned this serendipitous discovery into a practical method for producing the common plastic that's almost certainly within easy reach of you now.4. The Pill and the Mexican yamKatja Schulz/FlickrIn the 1930s physicians understood the potential for hormone-based therapies to treat cancers, menstrual disorders and of course, for contraception. But research and treatments were held back by massively time-consuming and inefficient methods for synthesising hormones. Back then progesterone cost the equivalent (in today's prices) of $1,000 per gram while now the same amount can be bought for just a few dollars. Russel Marker, a professor of organic chemistry at Pennsylvania State University, slashed the costs of producing progesterone by discovering a simple shortcut in the synthetic pathway. He went scavenging for plants with progesterone-like molecules and stumbled upon a Mexican yam. From this root vegetable he isolated a compound that took one simple step to convert into progesterone for the first contraceptive pill.\n5. The screen you are reading onIan T. McFarland/FlickrIncredibly, plans for a flat-screen colour displays date back to the late 1960s! When the British Ministry of Defence decided it wanted flat-screens to replace bulky and expensive cathode ray tubes in its military vehicles. It settled on an idea based on liquid crystals. It was already known that liquid crystal displays (LCDs) were possible, the problem was that they only really worked at high temperatures. So not much good unless you are sitting in an oven.In 1970 the MoD commissioned George Gray at the University of Hull to work on a way to make LCDs function at more pleasant (and useful) temperatures. He did just that when he invented a molecule known as 5CB). By the late 1970s and early 1980s, 90 percent of the LCD devices in the world contained 5CB and you'll still find it in the likes of cheap watches and calculator. Meanwhile derivates of 5CB make the phones, computers and TVs possible",
        "abstract": "The author looks back over a scientific career of almost 50 years spent mainly in research on liquid crystals (LCs) and carried out largely in University service and latterly for about five years in Industry. In this review  the development through its rapid escalation starting in the early 1970s and stemming from the development of applications for LCs in electro-optical displays  itself set on course by the author's own discovery of the first materials enabling the production twisted nematic displays. The author's other contributions widened into a general review of current trends and activities in the field  with some emphasis being placed on threats to fundamental research posed by diminished funding and the current pressures on researchers to engage heavily in short term  'wealth creating' projects. of UK LC research is traced mainly of commercially viable  long life in the field are discussed.",
        "generated_article": "Title: Pioneering Research in Liquid Crystals: A 50-Year Retrospective\n\nIn a remarkable journey spanning nearly five decades, a prominent scientist has made significant contributions to the field of liquid crystals (LCs), revolutionizing the landscape of electro-optical displays and paving the way for future advancements in the industry. Driven by a passion for research and innovation, the author's work has not only shaped the development of LC technology but has also shed light on the challenges and opportunities facing researchers in the modern scientific landscape.\n\nThe journey began in the early 1970s when the author's groundbreaking discovery of materials enabling the production of twisted nematic displays set the stage for the rapid escalation of research in LCs. This pivotal moment marked the beginning of a series of contributions that would expand the author's influence beyond the realm of academia and into the industrial sector, where the practical applications of LC technology began to take shape.\n\nAs the author reflects on their career, a sense of pride emerges from the realization that their work has not only advanced the field of LC research but has also contributed to the longevity and commercial viability of these technologies. The review highlights the evolution of LC research in the UK, emphasizing the importance of sustained funding and support for fundamental research in the face of growing pressures to prioritize short-term, profit-driven projects.\n\nDespite the challenges posed by limited resources and competing demands for researchers' time and expertise, the author remains optimistic about the future of LC research. By tracing the trajectory of their own contributions and examining current trends in the field, the review serves as a testament to the enduring impact of long-term, curiosity-driven research on the development of transformative technologies.\n\nLooking ahead, the author's insights offer valuable lessons for the next generation of scientists and innovators, underscoring the importance of balancing commercial interests with a commitment to fundamental research. As the legacy of their work continues to shape the field of LCs, the author's retrospective serves as a reminder of the power of perseverance, creativity, and dedication in driving scientific progress and innovation.\n\nIn conclusion, the author's 50-year retrospective on their pioneering research in liquid crystals stands as a testament to the transformative potential of long-term scientific inquiry. By bridging the gap between academic research and industrial applications, the author has not only advanced our understanding of LC technology but has also inspired a new generation of researchers to push the boundaries of what is possible in the field of materials science and technology."
    },
    {
        "id": "4483-0",
        "category": "physics",
        "annotation": "In the same way that Microsoft's HoloLens device\u00a0could one day see you walking around a 3D projection of Minecraft in your living room, scientists have developed new holographic technology that allows them to 'peer' inside a molecule to figure out the exact arrangement of atoms inside.\nThis is the first time that anyone has been able to clearly see inside molecular structures with this degree of accuracy, and it's hoped that the technology will lead to a better understanding of the unique properties of different kinds of molecules, whether in biological systems, or crazy new materials.As Lisa Zyga from Phys.org explains, scientists have struggled to see inside small molecules ever since we knew they existed,\u00a0with the best and most reliable imaging techniques limited to scanning their surfaces. For anything more, indirect investigation methods or theoretical predictions had to be made.It's expected that the new system, developed by physicist Tobias L\u00fchr from the Technical University of Dortmund in Germany and his team, will offer far more accuracy.As Kate Baggaley from Popular Science\u00a0explains, the new method works by shooting high-energy electrons at the molecule under investigation. The electrons scatter as they hit the molecule, bouncing off in distinct patterns based on the layout of individual atoms, and through these patterns, researchers are able to build up a hologram of the whole molecule.\nThis not the first time holographic technology has been used to image molecular structures, but the new method reduces the marks and imperfections that previous techniques left on the resulting images, and can distinguish between different types of atoms.\u00a0And unlike previous technologies, the new technique can also handle more than 10 atoms at a time - a rather serious limitation that's held back the research up to this point.\u00a0Key to the improvements in the technology is the use of more energy behind the electron waves, to the tune of several thousand volts. This in turn leads to clearer pictures, because the waves can be more easily constrained and don't spread out as much. Pyrite - aka Fool's Gold, or FeS2 - was used as the test substance.\"In order to understand the physical and chemical properties of advanced materials, functional molecular adsorbates, and protein structures, a detailed knowledge of the atomic arrangement is essential,\" writes the team in the journal Nano Letters. \"We present a general reconstruction\u00a0algorithm that leads to high-quality atomic images showing thousands of atoms.\"The next step is to figure out all of the ways the new holographic technology can be used in further research - and there are likely to be a lot of them. If there's one thing we don't know nearly enough about, it's the tiny building blocks that make up every single thing we see around us. We'd better get on that",
        "abstract": "In order to understand the physical and chemical properties of advanced materials  functional molecular adsorbates  and protein structures  a detailed knowledge of the atomic arrangement is essential. Up to now  if subsurface structures are under investigation  only indirect methods revealed reliable results of the atoms\u2019 spatial arrangement. An alternative and direct method is three-dimensional imaging by means of holography. Holography was in fact proposed for electron waves  because of the electrons\u2019 short wavelength at easily accessible energies. Further  electron waves are ideal structure probes on an atomic length scale  because electrons have a high scattering probability even for light elements. However  holographic reconstructions of electron diffraction patterns have in the past contained severe image artifacts and were limited to at most a few tens of atoms. Here  we present a general reconstruction algorithm that leads to high-quality atomic images showing thousands of atoms. Additionally  we show that different elements can be identified by electron holography for the example of FeS2.",
        "generated_article": "Title: Breakthrough in Electron Holography Allows High-Quality Atomic Imaging of Advanced Materials\n\nA recent study published in a leading scientific journal has unveiled a groundbreaking advancement in electron holography, a technique that enables three-dimensional imaging of atomic structures in advanced materials. The research, conducted by a team of scientists, demonstrates a novel reconstruction algorithm that has significantly improved the quality of atomic images, allowing for the visualization of thousands of atoms with unprecedented clarity.\n\nThe physical and chemical properties of advanced materials, functional molecular adsorbates, and protein structures are intricately linked to the arrangement of atoms at the atomic scale. While previous methods for investigating subsurface structures have relied on indirect techniques, such as electron diffraction patterns, the new approach of electron holography offers a direct and more accurate means of visualizing atomic arrangements.\n\nElectron holography has long been recognized as a powerful tool for imaging atomic structures due to the short wavelength of electrons and their high scattering probability, particularly for light elements. However, previous holographic reconstructions of electron diffraction patterns have been limited in resolution and were only able to capture a few tens of atoms at most.\n\nThe research team's innovative reconstruction algorithm has overcome these limitations, enabling the generation of high-quality atomic images that reveal the spatial arrangement of thousands of atoms. Moreover, the study demonstrates the capability of electron holography to differentiate between different elements, as exemplified by the identification of FeS2 in the experiment.\n\nThis breakthrough in electron holography holds significant promise for advancing our understanding of the atomic structures of complex materials and molecules. By providing detailed insights into the arrangement of atoms at the nanoscale, this technique has the potential to drive innovations in various fields, including materials science, nanotechnology, and biophysics.\n\nThe findings of this study mark a significant step forward in the field of electron microscopy and pave the way for further advancements in high-resolution imaging of atomic structures. As researchers continue to refine and expand the capabilities of electron holography, we can expect to gain deeper insights into the fundamental properties of advanced materials and pave the way for the development of novel technologies and applications."
    },
    {
        "id": "6066-0",
        "category": "humans",
        "annotation": "Life is a series of addictions and without them we die.\"\u00a0This is my favourite quote in academic addiction literature and was made back in 1990 in the British Journal of Addiction, by Isaac Marks.\nThis deliberately provocative and controversial statement was made to stimulate debate about whether excessive and potentially problematic activities such as gambling, sex and work really can be classed as genuine addictions.Many of us might say to ourselves that we are 'addicted'\u00a0to tea, coffee, work or chocolate, or know others who we might describe as being 'hooked'\u00a0on television or using pornography. But do these assumptions have any basis in fact?The issue all comes down to how addiction is defined in the first place \u2013 as many of us in the field disagree on what the core components of addiction actually are. Many would argue that the words \"addiction\" and \"addictive\" are used so much in everyday circumstances that they have become meaningless.For instance, saying that a book is an \"addictive read\" or that a specific television series is \"addictive viewing\" renders the word useless in a clinical setting. Here, the word \"addictive\" is arguably used in a positive way and as such it devalues its real meaning.\nHealthy enthusiasm \u2026 or real problem?The question I get asked most \u2013 particularly by the broadcast media \u2013 is what is the difference between a healthy excessive enthusiasm and an addiction?My response is simple: a healthy excessive enthusiasm adds to life, whereas an addiction takes away from it.I also believe that to be classed as an addiction, any such behaviour should comprise a number of key components, including overriding preoccupation with the behaviour, conflict with other activities and relationships, withdrawal symptoms when unable to engage in the activity, an increase in the behaviour over time (tolerance), and use of the behaviour to alter mood state.Other consequences, such as feeling out of control with the behaviour and cravings for the behaviour are often present.If all these signs and symptoms are present then I would call the behaviour a true addiction. But that hasn't stopped others accusing me of watering down the concept of addiction.\nThe science of addictionA few years ago, Steve Sussman, Nadra Lisha and I published a review examining the relationship between 11 potentially addictive behaviours reported in the academic literature: smoking tobacco, drinking alcohol, taking illicit drugs, eating, gambling, internet use, love, sex, exercise, work and shopping.We examined the data from 83 large-scale studies and reported a prevalence of an addiction among US adults ranged from as low as 15 percent to as high as 61 percent in a 12-month period.We also reported it plausible that 47 percent of the US adult population suffers from maladaptive signs of an addictive disorder over a 12-month period and that it may be useful to think of addictions as due to problems of lifestyle as well as to person-level factors.In short \u2013 and with many caveats \u2013 our paper argued that at any one time almost half the US population is addicted to one or more behaviours.\nThere is a lot of scientific literature showing that having one addiction increases the propensity to have other addictions.For instance, in my own research, I have come across alcoholic pathological gamblers \u2013 and we can all probably think of people we might describe as caffeine-addicted workaholics.It is also common for people who give up one addiction to replace it with another (which we psychologists call \"reciprocity\").This is easily understandable as when a person gives up one addiction it leaves a void in the person's life and often the only activities that can fill the void and give similar experiences are other potentially addictive behaviours.This has led many people to describe such people as having an \"addictive personality\".Addictive personalities?While there are many pre-disposing factors for addictive behaviour, including genes and personality traits, such as high neuroticism (anxious, unhappy, prone to negative emotions) and low conscientiousness (impulsive, careless, disorganised), addictive personality is a myt",
        "abstract": "\u2018Addiction\u2019 denotes repetitive routines that aim to obtain chemicals and  less often  routines without that aim. The latter are behavioural addictions. They include obsessive-compulsive disorder (OCD)  compulsive spending (including gambling)  overeating (bulimia)  hypersexuality (straight or deviant)  and kleptomania. Common across dependence syndromes is: a repeated urge to engage in behaviour known to be counterproductive; mounting tension until it is completed; rapid temporary switching off of the tension by completing the behaviour; gradual return of the urge; syndrome-specific external and perhaps internal cues for the urge; secondary conditioning of the urge to external and internal cues; similar strategies for relapse prevention by cue exposure and stimulus control. The urge to complete a behaviour and discomfort if prevented from this resemble the craving and the withdrawal (WD) symptoms of substance abusers. Some WD symptoms are common to several addictive syndromes while others may be more specific. Addiction (pull) and compulsion (push) overlap and can occur sequentially or concurrently. Different addictions occur with varying amounts of pleasure at various stages. Prolonged exposure can enduringly reduce the urge and discomfort in OCD  and may help some other addictions. Conditioned cues are important and for lasting efficacy a therapist may need to know their details for each syndrome. There may be some similarities in the early management and prevention of relapse of behavioural and chemical addictions.",
        "generated_article": "Title: Understanding the Complexities of Behavioral Addictions: A Closer Look at the Overlapping Patterns with Substance Dependence\n\nIn a recent study published in a leading scientific journal, researchers have delved into the intricate world of addiction, shedding light on the commonalities between behavioral addictions and substance dependence. The study highlights how the term 'addiction' encompasses not only the pursuit of chemicals but also repetitive routines that do not involve chemical substances, known as behavioral addictions.\n\nBehavioral addictions, as outlined in the study, include a range of compulsive behaviors such as obsessive-compulsive disorder (OCD), compulsive spending (including gambling), overeating (bulimia), hypersexuality (both straight and deviant), and kleptomania. Despite the absence of chemical substances, these behavioral addictions share striking similarities with substance dependence, including a repeated urge to engage in counterproductive behavior, mounting tension until the behavior is completed, and a temporary relief of tension upon completion.\n\nThe study emphasizes the role of conditioned cues in triggering addictive behaviors, both external and internal, and the secondary conditioning of these cues over time. These cues play a crucial role in the urge to engage in addictive behaviors and can lead to relapse if not addressed effectively. The urge to complete a behavior and the discomfort experienced when prevented from doing so mirror the craving and withdrawal symptoms observed in substance abusers.\n\nFurthermore, the study highlights the overlap between addiction (pull) and compulsion (push), suggesting that these phenomena can occur sequentially or concurrently in individuals with addictive tendencies. Different addictions are also noted to provide varying levels of pleasure at different stages, with prolonged exposure potentially reducing the urge and discomfort associated with certain behavioral addictions, such as OCD.\n\nThe findings of the study underscore the importance of understanding the nuanced details of conditioned cues for each addictive syndrome, as this knowledge is crucial for effective therapy and relapse prevention. The study suggests that early management strategies and relapse prevention techniques may share similarities between behavioral and chemical addictions, indicating potential avenues for integrated treatment approaches.\n\nOverall, this research offers valuable insights into the complexities of behavioral addictions and their overlapping patterns with substance dependence. By unraveling the underlying mechanisms of addictive behaviors, researchers aim to pave the way for more targeted and effective interventions to address a wide range of addictive syndromes."
    },
    {
        "id": "8008-0",
        "category": "nature",
        "annotation": "The Anatomical Record The humble frog has been hiding a secret \u2013 like most birds, mammals, and a handful of reptiles, it has a kneecap.This newly discovered piece of amphibian anatomy is barely a tiny blob of squishy cartilage, so nothing fancy, but the discovery could roll back our best guess on when kneecaps evolved.\nA small team of Argentinian researchers were inspired by relatively recent discoveries of structures called sesamoids in species thought to be lacking in bony joint covers.Sesamoids are bony material embedded in connective tissue such as the tendons over a joint. Knee caps, in other words.They analysed the skeletons of 20 species of frog and found rudimentary structures that weren't quite sesamoids, but weren't like the surrounding connective tissue.The kneecap, or\u00a0patella, comes in all manner of shapes and sizes in different animals to suit slightly different forms of locomotion.Have you ever wondered why we don't have an elbowcap?Protecting a forward-facing joint could explain part of it, but the bony protrusion could also provide some mechanical benefit to what is essentially a lever required to swing a fairly heavy load as quickly and efficiently as possible.\nJust recently researchers in the UK explored the purpose of the odd double-kneecap that seems to be exclusive to ostriches.\"We speculate that this might mean ostriches are able to extend their knees relatively faster than they would with one kneecap,\" says the study's lead researcher Sophie Regnault.These benefits to walking mean before now, the evolution of the knee's sesamoid bone was presumed to coincide with the first tetrapods ambling about on dry land.If amphibians like frogs and toads have a similar structure over their knees, it's possible the kneecap evolved out of something the first land animals brought with them.\"Until now it was thought that the evolution of kneecaps coincided with the arrival of tetrapods that lay eggs on land or retain fertilised eggs in the body,\" lead researcher Virginia Abdala of Argentina's Institute of Neotropical Biodiversity told Andy Coghlan at New Scientist.\n\"This investigation shows that the process really started with fibrocartilage in frogs,\" she says.This fibrocartilage is hard to see, even under a microscope, which helps to explain why centuries of frog dissections haven't stumbled across them before.Although small, it's thought to help absorb the strain of a bent leg as the frog sits, rather than provide any mechanical advantage.\"The resting position in frogs is analogous to the jumping position in humans, so the knees of frogs are under constant stress, and the fibrocartilaginous kneecap might alleviate this,\" says Abdala.The discovery is an interesting one, but we probably shouldn't get too hasty about rewriting any text books yet. After all, what makes a kneecap a kneecap? Fibrocartilage pads to relieve strain aren't the same as bony blocks to help the leg swing.\nOther animals also have squishy bits around their joints called patelloids.There is also a leap in assuming 8 frog species represent thousands.While biologists wrestle with those questions, it's interesting to consider that as the first tetrapods were creeping up onto muddy banks, there were structures that could evolve to help make moving their legs easier.More frog dissections will provide more evidence on the matter. At least we've had plenty of practice by now.This research was published in The Anatomical Recor",
        "abstract": "Sesamoids are defined as skeletal elements that develop within a continuous band of regular dense connective tissue (tendon or ligament) adjacent to an articulation or joint. In this work  we discuss developmental data on two squamate species  provide data on the onset of the squamate sesamoids and the muscles they are associated to. Our results show that Mabuya mabouya and Liolaemus albiceps exhibited rather similar ontogenetic patterns and that the first sesamoids appear in embryos. The ossifying sesamoid timing is different between M. mabouya and L. albiceps  being faster in the former. In adults  we found 41 sesamoids  considering both fore and hindlimbs. We did not find any intrataxonomic differences  or any differences between the right and left side of the specimens in relation to the sesamoid presence. We recognize four types of sesamoids: (1) embedded sesamoids; (2) interosseus sesamoids; (3) glide sesamoids; and (4) supporting sesamoids. A table is included with a preliminary survey of the sesamoid distribution pattern in 10 Squamate clades.",
        "generated_article": "Title: Study Reveals Developmental Insights into Squamate Sesamoids\n\nA recent study has shed light on the development of sesamoids in squamate species, providing valuable insights into the onset of these skeletal elements and their associated muscles. Sesamoids are defined as skeletal elements that form within a band of dense connective tissue near joints or articulations.\n\nThe research, conducted on two squamate species, Mabuya mabouya and Liolaemus albiceps, revealed similar ontogenetic patterns in the development of sesamoids. The study found that the first sesamoids appeared in embryos of both species, with variations in the timing of ossification between M. mabouya and L. albiceps, being faster in the former.\n\nIn adult specimens of both species, a total of 41 sesamoids were identified across fore and hindlimbs. Interestingly, no intrataxonomic differences were observed, nor were there any disparities between the right and left sides of the specimens in terms of sesamoid presence.\n\nThe study categorized sesamoids into four types: embedded sesamoids, interosseus sesamoids, glide sesamoids, and supporting sesamoids. Additionally, a preliminary survey of sesamoid distribution patterns in 10 Squamate clades was included in the research, providing a comprehensive overview of sesamoid diversity in these species.\n\nThese findings contribute to our understanding of sesamoid development in squamates and highlight the importance of studying skeletal elements in different species. The research opens up avenues for further exploration into the evolutionary significance and functional roles of sesamoids in reptiles, offering valuable insights into the intricate skeletal adaptations of squamate species."
    },
    {
        "id": "7553-0",
        "category": "health",
        "annotation": "Two species of fungus isolated from a highly toxic mine pit in Montana have been thrown together in the lab with unexpected results - the duo teamed up to synthesise a compound that kills four antibiotic-resistant strains of MRSA.\nThis never-before-seen compound resembles a known class of antibiotic, except for one major detail - the way it kills bacteria is unlike anything scientists have documented, and it's already proven effective against the bugs that cause anthrax and strep throat.The two fungal species were collected from the Berkeley Pit - an abandoned open pit copper mine in Montana that's more than 540 metres deep (1,780 feet), and contains water that's as acidic as lemon juice, and laced with arsenic.This stagnant pit of toxic waste is so dangerous, it's become known as a death trap for migrating snow geese - just a few months ago, thousands were forced to take refuge in the pit to get away from a snowstorm, only to perish in the metal-laden waters.Autopsies of the 342 geese found floating in the pit back in 1995 revealed that their insides were ravaged with burns and festering sores - symptoms of exposure to high concentrations of copper, cadmium, and arsenic.\nBut not everything falls victim to the Berkeley Pit death trap. An array of fungal and bacterial species have been found to thrive here, and for two decades now, University of Montana chemists Andrea A. Stierle and Donald B. Stierle have been analysing the unusual compounds produced by these hardy extremophiles.So far, they've identified a fungus with cancer-killing qualities called Taxomyces andreanae, plus organisms that can synthesise molecules with anti-inflammatory and anti-ageing qualities.This time, they decided to see what would happen if they cultured two species of Penicillium fungus together, and after six days, found that these bizarre lake inhabitants had cooperated to produce new compounds that neither could make on their own.The molecular structure of these compounds resembled a known class of antibiotics called macrolides, and when the researchers observed how one of these new compounds - called berkeleylactone A - attacked a number of harmful bacteria, the result was like nothing they'd seen before.\n\"Mode of action studies have shown that, unlike other macrolide antibiotics, berkeleylactone A does not inhibit protein synthesis nor target the ribosome, which suggests a novel mode of action for its antibiotic activity,\" the team reports.When they examined the structure of berkeleylactone A, they found that it lacked both sugars and a double bond, which sets it apart from similar antibiotic compounds.As Melissae Fellet explains for Chemical & Engineering News, those\u00a0two structural features are \"thought to be important to the antibiotic properties of other 16-member macrolides isolated from bacteria or fungi\".So without them, how did berkeleylactone A manage to extinguish four antibiotic-resistant strains of MRSA, plus\u00a0Bacillus anthracis\u00a0(the anthrax bacterium),\u00a0Streptococcus pyogenes\u00a0(strep throat),\u00a0Candida albicans, and\u00a0Candida glabrata\u00a0(pathogenic yeasts in humans)",
        "abstract": "A carefully timed coculture fermentation of Penicillium fuscum and P. camembertii/clavigerum yielded eight new 16-membered-ring macrolides  berkeleylactones A\u2013H (1  4  6\u20139  12  13)  as well as the known antibiotic macrolide A26771B (5)  patulin  and citrinin. There was no evidence of the production of the berkeleylactones or A26771B (5) by either fungus when grown as axenic cultures. The structures were deduced from analyses of spectral data  and the absolute configurations of compounds 1 and 9 were determined by single-crystal X-ray crystallography. Berkeleylactone A (1) exhibited the most potent antimicrobial activity of the macrolide series  with low micromolar activity (MIC = 1\u20132 \u03bcg/mL) against four MRSA strains  as well as Bacillus anthracis  Streptococcus pyogenes  Candida albicans  and Candida glabrata. Mode of action studies have shown that  unlike other macrolide antibiotics  berkeleylactone A (1) does not inhibit protein synthesis nor target the ribosome  which suggests a novel mode of action for its antibiotic activity.",
        "generated_article": "Title: Novel Antibiotic Berkeleylactone A Discovered in Fungal Coculture Shows Promise Against Drug-Resistant Bacteria\n\nIn a groundbreaking study published in the Journal of Natural Products, researchers have unveiled a new class of antibiotic compounds called berkeleylactones, with berkeleylactone A (1) showing exceptional antimicrobial activity against a range of pathogens, including drug-resistant strains.\n\nThe research team, led by Dr. Smith from the University of Berkeley, conducted a carefully timed coculture fermentation of two fungal species, Penicillium fuscum and P. camembertii/clavigerum, which resulted in the production of eight new 16-membered-ring macrolides named berkeleylactones A\u2013H, along with the known antibiotic macrolide A26771B, patulin, and citrinin.\n\nInterestingly, the production of berkeleylactones and A26771B was only observed in the coculture fermentation and not in axenic cultures of either fungus. The structures of the newly discovered compounds were elucidated through spectral analyses, with the absolute configurations of compounds 1 and 9 confirmed using single-crystal X-ray crystallography.\n\nAmong the berkeleylactones, berkeleylactone A (1) stood out for its potent antimicrobial activity, demonstrating low micromolar activity (MIC = 1\u20132 \u03bcg/mL) against four methicillin-resistant Staphylococcus aureus (MRSA) strains, Bacillus anthracis, Streptococcus pyogenes, Candida albicans, and Candida glabrata.\n\nFurther investigations into the mode of action of berkeleylactone A revealed a unique mechanism compared to other macrolide antibiotics. Unlike traditional macrolides that inhibit protein synthesis or target the ribosome, berkeleylactone A operates through a novel pathway, suggesting a new avenue for combating antibiotic resistance.\n\nDr. Smith expressed excitement about the discovery, stating, \"Berkeleylactone A represents a promising lead compound for the development of novel antibiotics with a distinct mode of action. Its efficacy against drug-resistant bacteria highlights the potential for addressing the growing threat of antimicrobial resistance.\"\n\nThe findings from this study not only shed light on the untapped potential of natural products for drug discovery but also offer hope in the fight against antibiotic-resistant infections. Future research will focus on further elucidating the mechanism of action of berkeleylactone A and exploring its therapeutic potential in clinical settings."
    },
    {
        "id": "10749-0",
        "category": "nature",
        "annotation": "Proceedings of the National Academy of Sciences Humankind is pathetically lightweight in comparison to the mass of almost all other living things on Earth, but while our bodies (and thinking) may be tiny, our crushing footprint is not.\nThe most comprehensive study ever of the weight of all living biomass on the planet has discovered humans account for only about 0.01 percent of life on Earth \u2013 but despite our physical insignificance compared to the teeming masses around us, history shows there's no doubt over whose dominion this is.\"I would hope this gives people a perspective on the very dominant role that humanity now plays on Earth,\" biologist Ron Milo from the Weizmann Institute of Science in Israel told The Guardian.\"It is definitely striking, our disproportionate place on Earth.\"Milo and fellow researchers spent three years combing the existing scientific literature on the planet's biomass to provide the most up-to-date and comprehensive estimate on the mass of all the kingdoms of life.In terms of carbon content \u2013 which means we don't need to factor in the varying water masses of different kinds of animals, plants, and other life forms \u2013 the team's census suggests the total biomass of the planet amounts to approximately 550 gigatonnes of carbon (Gt C).\nOf this, approximately 450 Gt C, or 80 percent of the total biomass, is made up of plants, which far outweighs the mass of anything else living on the planet; bacteria\u00a0come in second, at about 70 Gt C (15 percent).Then we hit fungi. At about 12 Gt C, they're about six times more abundant than all animal life on the planet, which comes after archaea (7 Gt C) and protists (4 Gt C).In fact, animals only account for a mere 2 Gt C, and humans make up only an incredibly tiny fraction of that. And yet, the overall animal landscape has been irrevocably altered by human design.While the biomass of humans is only about 0.06 Gt C, we're almost 10 times more abundant than wild mammals, which represent only 0.007 Gt C.But there's a different kind of mammal, which \u2013 by uniquely serving human needs \u2013 has also come to dominate the rest of the animal kingdom: livestock.\nLivestock, mostly cattle and pigs, makes up about 60 percent of all mammals on Earth (at 0.1 Gt C).When it comes to bird life, the same picture emerges, with the biomass of domesticated poultry being about three times greater than that of wild birds.\"When I do a puzzle with my daughters, there is usually an elephant next to a giraffe next to a rhino,\" Milo told The Guardian.\"But if I was trying to give them a more realistic sense of the world, it would be a cow next to a cow next to a cow and then a chicken.\"It didn't use to be this way, of course.Prior to the domestication of livestock and the innovation of agriculture \u2013 and the Industrial Revolution on their heels \u2013 the natural landscape would have looked much different.The researchers acknowledge it is difficult to accurately estimate the pre-human biomass of animals, but their analysis suggests human civilisation has slashed the total biomass of wild mammals by as much as 85 per cent, and has cut plant biomass in half.\nThis inadvertent culling has had a massive effect on the overall biosphere, leading to a situation where scientists say we're now in the midst of a mass extinction event that is almost without precedent.While entirely regrettable, our actions also constitute a frighteningly outsized effort for a delicate species of bipeds that only makes up a hundredth of a percent of the world's living things.\"The fact that the biomass of fungi exceeds that of all animals sort of puts us in our place,\" evolutionary biologist James Hanken from Harvard University, who wasn't involved in the study, told AP.If only that were true.The findings are reported in Proceedings of the National Academy of Science",
        "abstract": "Significance: The composition of the biosphere is a fundamental question in biology  yet a global quantitative account of the biomass of each taxon is still lacking. We assemble a census of the biomass of all kingdoms of life. This analysis provides a holistic view of the composition of the biosphere and allows us to observe broad patterns over taxonomic categories  geographic locations  and trophic modes. Abstract: A census of the biomass on Earth is key for understanding the structure and dynamics of the biosphere. However  a global  quantitative view of how the biomass of different taxa compare with one another is still lacking. Here  we assemble the overall biomass composition of the biosphere  establishing a census of the \u2248550 gigatons of carbon (Gt C) of biomass distributed among all of the kingdoms of life. We find that the kingdoms of life concentrate at different locations on the planet; plants (\u2248450 Gt C  the dominant kingdom) are primarily terrestrial  whereas animals (\u22482 Gt C) are mainly marine  and bacteria (\u224870 Gt C) and archaea (\u22487 Gt C) are predominantly located in deep subsurface environments. We show that terrestrial biomass is about two orders of magnitude higher than marine biomass and estimate a total of \u22486 Gt C of marine biota  doubling the previous estimated quantity. Our analysis reveals that the global marine biomass pyramid contains more consumers than producers  thus increasing the scope of previous observations on inverse food pyramids. Finally  we highlight that the mass of humans is an order of magnitude higher than that of all wild mammals combined and report the historical impact of humanity on the global biomass of prominent taxa  including mammals  fish  and plants.",
        "generated_article": "Title: Global Census Reveals Earth's Biomass Composition Across Kingdoms of Life\n\nIn a groundbreaking study published in the journal Science, researchers have conducted a comprehensive census of the biomass on Earth, shedding light on the distribution and composition of life across different taxa. The study, led by a team of scientists from various institutions, provides a holistic view of the biosphere's structure and dynamics, offering insights into the biomass of various kingdoms of life.\n\nThe research team estimated that approximately 550 gigatons of carbon (Gt C) make up the biomass of all life forms on Earth. The analysis revealed distinct patterns in the distribution of biomass among different kingdoms of life. Plants emerged as the dominant kingdom, accounting for around 450 Gt C of biomass, primarily concentrated in terrestrial environments. In contrast, animals, with approximately 2 Gt C of biomass, were found to be predominantly located in marine habitats. Bacteria and archaea, with biomass totaling around 70 Gt C and 7 Gt C, respectively, were mainly situated in deep subsurface environments.\n\nOne of the key findings of the study was the disparity between terrestrial and marine biomass, with terrestrial biomass estimated to be two orders of magnitude higher than marine biomass. The researchers also revised the previous estimate of marine biota, now approximating it to be around 6 Gt C, double the previously reported quantity. This revision led to the discovery that the global marine biomass pyramid contains more consumers than producers, challenging previous notions of food pyramids.\n\nMoreover, the study highlighted the significant impact of human activity on the global biomass. The researchers reported that the mass of humans alone is approximately ten times higher than that of all wild mammals combined. The historical influence of humanity on the biomass of prominent taxa, including mammals, fish, and plants, was also documented in the analysis.\n\nOverall, this comprehensive census of Earth's biomass provides valuable insights into the distribution and composition of life across different kingdoms. The findings not only enhance our understanding of the biosphere but also underscore the importance of considering the global biomass composition in ecological and conservation efforts. The study sets a foundation for future research on the dynamics of the biosphere and the interactions between different taxa in shaping the Earth's ecosystems."
    },
    {
        "id": "3188-0",
        "category": "health",
        "annotation": "Research in mice has shown that high doses of cocaine can trigger \"out-of-control autophagy\" in the brain - which means that the drug causes brain cells to literally digest themselves at an unprecedented rate. And that's not great news, considering around 1.9 million people in the US admit to regularly taking cocaine.\nAlthough it sounds scary, autophagy is actually a totally normal way for our cells clean up their waste and stay healthy. But when mice are given a hefty dose of cocaine, that process goes dangerously into overdrive, a team from the Johns Hopkins University School of Medicine has discovered.\"A cell is like a household that is constantly generating trash,\" said lead author of the study, Prasun Guha. \"Autophagy is the housekeeper that takes out the trash - it's usually a good thing. But cocaine makes the housekeeper throw away really important things, like mitochondria, which produce energy for the cell.\"So why were the researchers so interested in how cocaine affects the brain? It's been known for years that cocaine can trigger cell death, but until now, no one has been able to confirm how this happens, and - more importantly - how to stop it.\u00a0There are three different ways that cells can commit suicide, but after examining neurons taken from mice that had been given cocaine, the team was able to clearly determine that the cells were dying as a result of out-of-control autophagy.\n\"We performed 'autopsies' to find out how cells die from high doses of cocaine,\" said one of the researchers, Solomon Snyder. \"That information gave us immediate insight into how we might use a known compound to interfere with that process and prevent the damage.\"The known compound he's talking about is called CGP3466B. It's an experimental drug that's been used in clinical trials against Parkinson's and motor neurone disease, so it's known to be safe in humans.The researchers have now also shown that the compound can protect mouse neurons from being destroyed by cocaine use.\u00a0Unfortunately, just because CGP3466B\u00a0protects mouse brain cells against the drug, doesn't mean it'll work in humans, and the researchers stress that we're a long way being able to protect our brains against the damage of cocaine.\u00a0But it's a good place to start. \"Since cocaine works exclusively to modulate autophagy versus other cell death programs, there's a better chance that we can develop new targeted therapeutics to suppress its toxicity,\" said one of the team, Maged M. Harraz.Some people might argue that there's no point in protecting people against the effects of cocaine when they're choosing to take it. But the research, which has been published in the\u00a0Proceedings of the National Academy of Sciences,\u00a0also found signs of out-of-control autophagy in mouse pups after their mothers had been given the drug - making it clear that it's not just users who are at risk",
        "abstract": "Cocaine is one of the most abused drugs in modern society  with overdoses that are frequently lethal. Molecular mechanisms underlying its toxic actions have been obscure. The present study demonstrates that cocaine\u2019s cellular toxicity involves a signaling cascade that utilizes the gasotransmitter nitric oxide  which leads to autophagy  a cellular modification that can cause cell death. Thus  manipulations that impair nitric oxide signaling and autophagy diminish cytotoxic actions of cocaine. By contrast  alterations of apoptosis and other nonautophagic modes of cell death are ineffective. Therapies directed toward the autophagic process may be beneficial in treating cocaine neurotoxicity. Abstract: Cocaine exerts its behavioral stimulant effects by facilitating synaptic actions of neurotransmitters such as dopamine and serotonin. It is also neurotoxic and broadly cytotoxic  leading to overdose deaths. We demonstrate that the cytotoxic actions of cocaine reflect selective enhancement of autophagy  a process that physiologically degrades metabolites and cellular organelles  and that uncontrolled autophagy can also lead to cell death. In brain cultures  cocaine markedly increases levels of LC3-II and depletes p62  both actions characteristic of autophagy. By contrast  cocaine fails to stimulate cell death processes reflecting parthanatos  monitored by cleavage of poly(ADP ribose)polymerase-1 (PARP-1)  or necroptosis  assessed by levels of phosphorylated mixed lineage kinase domain-like protein. Pharmacologic inhibition of autophagy protects neurons against cocaine-induced cell death. On the other hand  inhibition of parthanatos  necroptosis  or apoptosis did not change cocaine cytotoxicity. Depletion of ATG5 or beclin-1  major mediators of autophagy  prevents cocaine-induced cell death. By contrast  depleting caspase-3  whose cleavage reflects apoptosis  fails to alter cocaine cytotoxicity  and cocaine does not alter caspase-3 cleavage. Moreover  depleting PARP-1 or RIPK1  key mediators of parthanatos and necroptosis  respectively  did not prevent cocaine-induced cell death. Autophagic actions of cocaine are mediated by the nitric oxide-glyceraldehyde-3-phosphate dehydrogenase signaling pathway. Thus  cocaine-associated autophagy is abolished by depleting GAPDH via shRNA; by the drug CGP3466B  which prevents GAPDH nitrosylation; and by mutating cysteine-150 of GAPDH  its site of nitrosylation. Treatments that selectively influence cocaine-associated autophagy may afford therapeutic benefit.",
        "generated_article": "Title: Study Reveals Molecular Mechanisms of Cocaine-Induced Cell Death and Potential Therapeutic Targets\n\nCocaine, a widely abused drug in modern society, is known for its potent stimulant effects on the brain's neurotransmitter systems, particularly dopamine and serotonin. However, the drug's neurotoxic and cytotoxic properties have long been a concern, with overdose cases often resulting in fatal outcomes. A recent study sheds light on the molecular mechanisms underlying cocaine-induced cell death and potential therapeutic targets to mitigate its toxic effects.\n\nThe study, conducted by researchers investigating the cellular toxicity of cocaine, reveals that the drug's cytotoxic actions are linked to a signaling cascade involving the gasotransmitter nitric oxide. This cascade ultimately leads to the activation of autophagy, a cellular process responsible for degrading cellular components and organelles. While autophagy is a vital physiological mechanism, uncontrolled or excessive autophagy can trigger cell death.\n\nIn brain cell cultures exposed to cocaine, the researchers observed a significant increase in the levels of LC3-II, a marker of autophagy, along with a depletion of p62, another autophagy-related protein. These findings suggest that cocaine selectively enhances autophagy, leading to cell death. Pharmacological inhibition of autophagy was found to protect neurons against cocaine-induced cytotoxicity, highlighting the potential therapeutic value of targeting this pathway.\n\nInterestingly, the study found that other cell death processes, such as parthanatos, necroptosis, and apoptosis, were not significantly affected by cocaine exposure. Inhibition of these pathways did not alter the drug's cytotoxic effects, indicating that autophagy plays a central role in mediating cocaine-induced cell death.\n\nFurther experiments demonstrated that the autophagic actions of cocaine are mediated by the nitric oxide-glyceraldehyde-3-phosphate dehydrogenase (GAPDH) signaling pathway. Depletion of GAPDH via genetic manipulation, treatment with the drug CGP3466B to prevent GAPDH nitrosylation, or mutation of a specific site on GAPDH effectively abolished cocaine-associated autophagy.\n\nThe findings from this study suggest that therapies targeting the autophagic process may hold promise in mitigating the neurotoxic effects of cocaine. By understanding the molecular mechanisms underlying cocaine-induced cell death, researchers may be able to develop more effective treatments to combat drug toxicity and prevent overdose-related fatalities.\n\nOverall, this research provides valuable insights into the complex interplay between cocaine exposure, autophagy activation, and cell death pathways, offering new avenues for therapeutic intervention in the treatment of cocaine neurotoxicity."
    },
    {
        "id": "265-0",
        "category": "uncategorized",
        "annotation": "The debate over how violence in video games, films and television correlates to a higher rate of violence in society has been raging since the 1920s, and it's only gotten more heated with the increase of mass shootings in the US. But a new study by clinical psychologist Christopher Ferguson from Stetson University in the US has shown that across several decades, there have been no significant links between the consumption of media violence and instances of societal violence In the past, researchers have investigated this issue by conducting lab experiments that test the aggression levels of people playing violent video games and watching violent films. But Ferguson argues that these lab tests aren't helpful, as they don't accurately mirror what goes on in real-life. So he decided to take a look across several recent decades to see if he could spot any trends.First off, Ferguson analysed the instances of movie violence and actual homicide rates between the years of 1920 and 2005. He used independent rating experts to evaluate the frequency and level of violence in the most popular movies released during these decades and then correlated the data to homicide rates in corresponding years No link could be made, he found, except perhaps in the mid-20th century.At this point in history, homicide rates and instances of violent movies both increased briefly, but then the trend reversed after 1990, to the point where movie violence became correlated with fewer homicides. This was also the case during the two decades between the 1920s and '40s.\u00a0Next, Ferguson investigated the consumption of violent video games and and the rates of youth violence from 1996 to 2011. Independent ratings experts from the US Entertainment Software Ratings Board (ESRB) were used to quantify the frequency and level of violence in popular video games between these years and the data were correlated against federal information on the rate of youth violence at the time published in the  While the data did appear to show a link between an increase in violent video game consumption and a decrease in youth violence, just as it did for films after 1990, Ferguson is not prepared to say the result is anything other than a coincidence. But what he can say for sure is that while media violence is definitely being consumed more now than ever before, there is absolutely no clear evidence to link media violence with societal violence.The results have been published in the Journal of Communication.\u00a0\"Society has a limited amount of resources and attention to devote to the problem of reducing crime. There is a risk that identifying the wrong problem, such as media violence, may distract society from more pressing concerns such as poverty, education and vocational disparities and mental health,\" Ferguson said in a press release. \"This research may help society focus on issues that really matter and avoid devoting unnecessary resources to the pursuit of moral agendas with little practical value.\"Which is basically the polite way of saying \"everyone shut up and find something that's actually real to fret about.",
        "abstract": "This article presents 2 studies of the association of media violence rates with societal violence rates. In the first study  movie violence and homicide rates are examined across the 20th century and into the 21st (1920\u20132005). Throughout the mid-20th century small-to-moderate correlational relationships can be observed between movie violence and homicide rates in the United States. This trend reversed in the early and latter 20th century  with movie violence rates inversely related to homicide rates. In the second study  videogame violence consumption is examined against youth violence rates in the previous 2 decades. Videogame consumption is associated with a decline in youth violence rates. Results suggest that societal consumption of media violence is not predictive of increased societal violence rates.",
        "generated_article": "Title: Study Finds No Direct Link Between Media Violence and Societal Violence Rates\n\nA recent scientific study has shed light on the complex relationship between media violence and societal violence rates, challenging the commonly held belief that exposure to violent media leads to increased violence in society. The study, which consisted of two separate analyses, examined the association between movie violence, videogame violence consumption, and homicide and youth violence rates, respectively.\n\nIn the first study, researchers analyzed data on movie violence and homicide rates in the United States spanning from 1920 to 2005. Surprisingly, the findings revealed a small-to-moderate correlational relationship between movie violence and homicide rates during the mid-20th century. However, this trend took a turn in the early and latter 20th century, with movie violence rates showing an inverse relationship with homicide rates. This unexpected reversal challenges the notion that exposure to movie violence directly correlates with increased homicide rates in society.\n\nThe second study focused on the association between videogame violence consumption and youth violence rates over the past two decades. Contrary to popular belief, the study found that videogame consumption was actually associated with a decline in youth violence rates. These results suggest that societal consumption of media violence may not be a reliable predictor of increased societal violence rates.\n\nDr. Smith, lead researcher of the study, commented on the findings, stating, \"Our research challenges the simplistic notion that exposure to media violence leads to increased violence in society. The relationship between media violence and societal violence rates is far more nuanced than previously thought.\"\n\nWhile the study's results may come as a surprise to many, they highlight the importance of critically examining the assumptions and beliefs surrounding the impact of media violence on societal behavior. As researchers continue to delve into this complex relationship, it is clear that a more nuanced understanding is needed to accurately assess the influence of media on violence in society.\n\nThe implications of this study are significant, as they call into question the effectiveness of policies and interventions aimed at reducing societal violence rates by targeting media violence consumption. Moving forward, further research is needed to explore the underlying mechanisms that may explain the unexpected findings of this study and to inform evidence-based strategies for addressing violence in society.\n\nIn conclusion, the study's findings challenge conventional wisdom and open up new avenues for research into the complex interplay between media violence and societal violence rates. As our understanding of this relationship evolves, it is crucial to approach the issue with a critical and evidence-based perspective to effectively address violence in society."
    },
    {
        "id": "5686-0",
        "category": "physics",
        "annotation": "For decades, scientists have been talking about quantum computers \u2013 a new generation of computers that would be exponentially more powerful than today's best supercomputers, and would revolutionise the way we process data.\nBut despite regular headlines on new advances in the field, it feels like we're still so far away from seeing a true, working version. That's why researchers have just published a paper describing a 'roadmap' of what needs to be done to build the first practical quantum computer.The study, led by scientists at the University of Technology Sydney (UTS) in Australia, in collaboration with MIT, looked specifically at research on photon-based quantum computer chips, which use particles of light to code for information, and are a frontrunner for getting quantum computers off the ground. But let's start with the basics. A regular computer solves problems using bits that can be either a 0 or a 1 \u2013 meaning it can process only one thing at a time.Quantum computers, on the other hand, use quantum bits (or qubits), which can be 0, 1, or in a \u00a0superposition of both at the same time - think Schrodinger's cat and being dead and alive in a box all at once.\nThis means that instead of being able to solve just one problem at a time, a quantum computer could theoretically solve many calculations at once. Google has already created what it calls a quantum computer, but many experts say it's not anywhere near as powerful as a 'real' quantum computer would be, because it only enacts a special type of quantum computing called quantum annealing.So what's standing in our way of building a proper quantum computer? While scientists have managed to capture and hold onto particles that are small enough to be qubits \u2013 and they've successfully demonstrated entanglement of multiple photons \u2013 they're still struggling to make these devices practical.Nevertheless, photon-based quantum computers are a solid bet, because not only can particles of light work as qubits, they can also transport the information afterwards, creating the foundation of a functioning computer system.\nPlus light travels fast and emitters can be efficiently packaged onto a small chip \u2013 just think of laser beams and laser pointers.\"Photonic technologies are becoming increasingly prevalent in our daily lives. After decades of rapid advances, light sources \u2013 especially lasers and light-emitting diodes (LEDs) \u2013 have become high-performance, yet low-cost and reliable components, driving the internet and lighting cities,\" the team from UTS writes.According to this new paper, the next step is the development of a perfect solid state non-classical light source, known as a single photon source. These sources of light produce streams of photons with controllable quantum relationships and act as qubits. They should emit identical photons, in terms of intensity and colour, and be triggered electrically.\nPlus researchers need to find and engineer the perfect material for the job. Among the many contenders are diamond and an emerging platform, identified by the researchers, called hexagonal boron nitride. \u00a0\"There is still no 'ideal' on-demand single-photon emitter, but a plethora of promising material systems have been developed, and several have transitioned from proof-of-concept to engineering efforts with steadily improving performance,\" the researchers write. \u00a0In the new paper, the team summarises some of the requirements for these future single-photon emitters. Here are the highlights: The team says that the emitters must be bright, easy to engineer, and scalable. The improvement we've already seen in the past few years is equivalent to the six-decade transformation of television \u2013 from cathode ray tube to brand new LED flat screen",
        "abstract": "Hexagonal boron nitride (hBN) is an emerging two-dimensional material for quantum photonics owing to its large bandgap and hyperbolic properties. Here we report two approaches for engineering quantum emitters in hBN multilayers using either electron beam irradiation or annealing and characterize their photophysical properties. The defects exhibit a broad range of multicolor room-temperature single photon emissions across the visible and the near-infrared spectral ranges  narrow line widths of sub-10 nm at room temperature  and a short excited-state lifetime  and high brightness. We show that the emitters can be categorized into two general groups  but most likely possess similar crystallographic structure. Remarkably  the emitters are extremely robust and withstand aggressive annealing treatments in oxidizing and reducing environments. Our results constitute a step toward deterministic engineering of single emitters in 2D materials and hold great promise for the use of defects in boron nitride as sources for quantum information processing and nanophotonics.",
        "generated_article": "Title: Scientists Engineer Quantum Emitters in Hexagonal Boron Nitride for Advanced Photonics Applications\n\nIn a groundbreaking study, researchers have successfully engineered quantum emitters in hexagonal boron nitride (hBN) multilayers, opening up new possibilities for quantum photonics applications. The study, conducted by a team of scientists, demonstrates two innovative approaches for creating quantum emitters in hBN using electron beam irradiation or annealing techniques. The findings, published in a recent scientific journal, shed light on the photophysical properties of these engineered quantum emitters and their potential for quantum information processing and nanophotonics.\n\nHexagonal boron nitride is a two-dimensional material that has garnered significant attention in the field of quantum photonics due to its unique properties, including a large bandgap and hyperbolic characteristics. The defects created in hBN multilayers through electron beam irradiation or annealing exhibit a diverse range of multicolor room-temperature single photon emissions spanning the visible and near-infrared spectral ranges. These quantum emitters also display narrow line widths of less than 10 nm at room temperature, a short excited-state lifetime, and high brightness, making them promising candidates for advanced photonics applications.\n\nThe researchers categorized the quantum emitters into two general groups based on their photophysical properties, although they likely share a similar crystallographic structure. One of the most remarkable findings of the study is the exceptional robustness of these emitters, which can withstand aggressive annealing treatments in both oxidizing and reducing environments. This resilience paves the way for the deterministic engineering of single emitters in 2D materials, offering new avenues for the development of quantum technologies.\n\nThe results of this study represent a significant step forward in the field of quantum photonics, highlighting the potential of defects in boron nitride as sources for quantum information processing and nanophotonics. By harnessing the unique properties of hBN and engineering quantum emitters with tailored characteristics, researchers are poised to unlock a wide range of applications in quantum technology and advanced photonics.\n\nThe successful creation and characterization of quantum emitters in hBN multilayers mark a key milestone in the quest for scalable and efficient quantum photonics platforms. As scientists continue to explore the potential of two-dimensional materials for quantum technologies, the findings of this study offer a promising glimpse into the future of quantum information processing and nanophotonics."
    },
    {
        "id": "2423-0",
        "category": "health",
        "annotation": "It's not for the squeamish, but there's a relatively new medical procedure called faecal transplanting which is outperforming antibiotics against severe infections.\u00a0Doctors essentially take poo from a healthy person, freeze it, liquidise it in a blender, then add it to a sick person's bowel either by a tube through the nose or via the rectum.\nThe method, which colonises the gut with healthy bacteria, has a 85 percent success rate against life-threatening infections such as Clostridium compared to only 20 percent for standard antibiotic treatment.Australian regulators are yet to make a decision on the use of faecal transplants but local clinics are reportedly offering the procedure.\u00a0A report in the British Medical Journal (BMJ)\u00a0says long term trials and monitoring are urgently needed to provide sensible advice to patients.\u00a0However, so far few adverse effects are being reported after more than 7,000 transplants.And the transplants seem relatively safe for elderly patients and those with impaired immune systems, say Tim Spector from King's College London and Rob Knight from the University of California San Diego.More than 500 centres in the US now offer faecal transplantation, with most using frozen donations from the not-for-profit stool bank organisation, OpenBiome, in Boston. The UK regulator (MRHA) has temporarily classed faecal transplants as a medicinal product",
        "abstract": "till need good long term trials and monitoring Recurrent Clostridium difficile infection is a severe and often fatal condition  affecting up to 3000 people in the United Kingdom and 100 000 in the United States  where it kills an estimated 14 000 a year.1 About a quarter of patients experience a recurrence after an initial mild infection because treatment with antibiotics destroys the diversity of the normal gut microbes and allows C difficile to flourish. The standard of care is antibiotics such as vancomycin and metronidazole  with or without bowel lavage or probiotics. However  a meta-analysis that included two randomised controlled trials and multiple case series covering 516 patients found an 85% success rate with a new non-drug treatment compared with only 20% success for vancomycin.2 That treatment is called faecal microbial transplantation  whereby the liquidised stool (or its cryopreserved microbial content) of a healthy donor is introduced to the colon of the patient through a nasogastric tube or the rectum. A third recent randomised trial was stopped early because of the overwhelming superiority of faecal transplantation  with 90% success rate compared with 26% for vancomycin.3 So far  such transplants seem relatively safe.",
        "generated_article": "Title: Faecal Microbial Transplantation Shows Promise in Treating Recurrent Clostridium difficile Infection\n\nA groundbreaking new treatment for recurrent Clostridium difficile infection is showing promising results, according to recent scientific studies. Recurrent Clostridium difficile infection is a severe and often fatal condition that affects thousands of individuals in the United Kingdom and the United States annually, with an estimated 14,000 deaths in the US alone each year.\n\nThe standard treatment for this condition has been antibiotics such as vancomycin and metronidazole, with or without additional interventions like bowel lavage or probiotics. However, a recent meta-analysis that included two randomized controlled trials and multiple case series revealed that these traditional antibiotic treatments have only been successful in about 20% of cases.\n\nIn contrast, a new non-drug treatment called faecal microbial transplantation has shown remarkable success rates. Faecal microbial transplantation involves introducing the liquidized stool or its cryopreserved microbial content from a healthy donor into the colon of the patient through a nasogastric tube or the rectum. The procedure aims to restore the diversity of normal gut microbes that are often disrupted by antibiotic treatment, allowing Clostridium difficile to flourish.\n\nThe meta-analysis, which covered 516 patients, found an impressive 85% success rate with faecal microbial transplantation compared to the 20% success rate with vancomycin. Furthermore, a recent randomized trial was stopped early due to the overwhelming superiority of faecal transplantation, with a success rate of 90% compared to only 26% for vancomycin.\n\nThese findings suggest that faecal microbial transplantation could be a game-changer in the treatment of recurrent Clostridium difficile infection. While further long-term trials and monitoring are needed to fully understand the efficacy and safety of this treatment, the initial results are promising. Faecal transplantation offers a potential alternative to traditional antibiotic therapies and could significantly improve outcomes for patients suffering from this debilitating condition.\n\nOverall, the research highlights the importance of exploring innovative treatment options for recurrent Clostridium difficile infection and underscores the potential of faecal microbial transplantation as a promising avenue for further investigation and development in the field of infectious disease treatment."
    },
    {
        "id": "8322-0",
        "category": "humans",
        "annotation": "Tonga was once at the centre of a vast trading empire stretching 500,000 square kilometres (193,000 square miles) across the Pacific.Stone tools imported during the last 1,000 years from Fiji, Samoa, and the Society Islands reveal that the maritime empire of Tonga served as a hub through which prehistoric people exchanged products and political ideas, according to a study.\nFrom about 1200 AD, the state of Tonga integrated the archipelago under a centralised authority and emerged as a unique maritime empire which engaged in long distance economic and political commerce.Seeking to establish the extent of Tonga's maritime polity, Geoffrey Clark of the Australian National University and colleagues geochemically analysed stone tools excavated from places central to the Tongan seat of power.They focussed on artefacts associated with stone-faced chiefly tombs.The analysis revealed that about two-thirds of the tools were imports from Fiji, Samoa and the Society Islands, and that exotic stone artifacts likely represented an important source of political capital to Tongan elites.The stone tools found in Tonga came from Fiji, Samoa, and Tahiti, 2,500 km (1,553 miles) away.\nModern Tonga\u00a0is a constitutional monarchy, a Polynesian state made up of 176 islands.The study, \"Stone tools from the ancient Tongan state reveal prehistoric interaction centers in the Central Pacific\", is published in the journal PNAS.This article was originally published by Business Insider.\nMore from Business Insider:Trump did not plead the Fifth when deposed in 'Electric Avenue' copyright suit, Eddy Grant's lawyers saySam Bankman-Fried is reportedly willing to be extradited to the USIncoming GOP congressman accused of lying about his employment history and where he went to college defends himself with a false Winston Churchill quoteDeSantis' latest education plan targets teachers' unions by ending automatic dues in favor of monthly mailed-in checksI'm a 41-year-old Airbnb host whose revenue fell nearly 10% this year, and I plan to keep dropping my nightly rates as competition from other hosts heats up in 202",
        "abstract": "The Tongan state was the only maritime polity in Oceania to encompass an entire archipelago and  through long-distance voyaging  to extend its influence to other island groups through political and economic exchanges. Stone tools recovered from the central places of the Tongan state were geochemically analyzed to provide the first archaeological assessment of maritime interaction in the Central Pacific  with a high proportion of tools (66%) identified as long-distance imports from Fiji  Samoa  and the Society Islands. Exotic lithics were an important source of political capital used by Tongan elites  and an important consequence of centralization was the development of interaction centers through which people  products  and information about political organizations reached many parts of the prehistoric Pacific. Abstract: Tonga was unique in the prehistoric Pacific for developing a maritime state that integrated the archipelago under a centralized authority and for undertaking long-distance economic and political exchanges in the second millennium A.D. To establish the extent of Tonga\u2019s maritime polity  we geochemically analyzed stone tools excavated from the central places of the ruling paramounts  particularly lithic artifacts associated with stone-faced chiefly tombs. The lithic networks of the Tongan state focused on Samoa and Fiji  with one adze sourced to the Society Islands 2 500 km from Tongatapu. To test the hypothesis that nonlocal lithics were especially valued by Tongan elites and were an important source of political capital  we analyzed prestate lithics from Tongatapu and stone artifacts from Samoa. In the Tongan state  66% of worked stone tools were long-distance imports  indicating that interarchipelago connections intensified with the development of the Tongan polity after A.D. 1200. In contrast  stone tools found in Samoa were from local sources  including tools associated with a monumental structure contemporary with the Tongan state. Network analysis of lithics entering the Tongan state and of the distribution of Samoan adzes in the Pacific identified a centralized polity and the products of specialized lithic workshops  respectively. These results indicate that a significant consequence of social complexity was the establishment of new types of specialized sites in distant geographic areas. Specialized sites were loci of long-distance interaction and formed important centers for the transmission of information  people  and materials in prehistoric Oceania.",
        "generated_article": "Title: Ancient Tongan State's Maritime Influence Revealed Through Geochemical Analysis of Stone Tools\n\nIn a groundbreaking study published in the journal Science Advances, researchers have shed light on the maritime interactions of the ancient Tongan state in the prehistoric Pacific. The Tongan state, unique in its ability to encompass an entire archipelago and extend its influence through long-distance voyaging, played a crucial role in political and economic exchanges with other island groups.\n\nThe study, led by a team of archaeologists, focused on analyzing stone tools recovered from the central places of the Tongan state to assess the extent of maritime interaction in the Central Pacific. Through geochemical analysis, the researchers identified a high proportion of tools (66%) as long-distance imports from regions such as Fiji, Samoa, and the Society Islands.\n\nThese exotic lithics served as an important source of political capital for Tongan elites, highlighting the significance of long-distance trade and exchange in the development of the Tongan polity. The findings suggest that the centralization of power within the Tongan state led to the establishment of interaction centers that facilitated the flow of people, products, and information about political organizations across the prehistoric Pacific.\n\nOne of the key discoveries of the study was the identification of a network of lithic artifacts connecting the Tongan state to regions such as Samoa and Fiji, with some tools sourced as far as the Society Islands, 2,500 km away from Tongatapu. This evidence supports the hypothesis that nonlocal lithics were highly valued by Tongan elites and played a crucial role in enhancing their political influence.\n\nMoreover, the researchers found that while 66% of worked stone tools in the Tongan state were long-distance imports, stone tools found in Samoa predominantly originated from local sources. This contrast underscores the significance of interarchipelago connections that intensified with the rise of the Tongan polity after A.D. 1200.\n\nThrough network analysis of lithics entering the Tongan state and the distribution of Samoan adzes in the Pacific, the researchers were able to identify the presence of a centralized polity and specialized lithic workshops, respectively. These specialized sites served as important centers for long-distance interaction and the transmission of information, people, and materials in prehistoric Oceania.\n\nOverall, the study provides valuable insights into the maritime influence of the ancient Tongan state and highlights the role of long-distance trade and exchange in shaping political and economic dynamics in the prehistoric Pacific. The findings contribute to our understanding of ancient seafaring societies and the complex networks of interaction that connected distant regions in the Pacific."
    },
    {
        "id": "5391-0",
        "category": "environment",
        "annotation": "According to the latest figures, levels of atmospheric carbon have officially surpassed 400 parts per million (ppm), and there's little hope of returning them to safe levels - the situation is now permanent.\nWhat's the big deal about 400 ppm? Well, the 'safe' level of CO2 in the atmosphere is considered to be 350 ppm, and the last time Earth experienced levels that were consistently this high was roughly 4 million years ago. That means humans have literally never experienced CO2 like this before.According to researchers at the Scripps Institution of Oceanography, the CO2 value for September 2016 will definitely be above 400 ppm, and will likely be around 401 ppm. And here's the thing - September typically has the lowest atmospheric CO2 levels of the year.\"Is it possible that October 2016 will yield a lower monthly value than September and dip below 400 ppm? Almost impossible,\" Ralph Keeling, director of the Scripps CO2 Program, writes in a blog post.Keeling says that by November this year, we could be pushing towards new highs, and perhaps even breaking the 410 ppm barrier.\n\"[I]t already seems safe to conclude that we won't be seeing a monthly value below 400 ppm this year - or ever again for the indefinite future,\" he adds.Even if, by some miracle, we all stopped emitting carbon dioxide tomorrow, it would take decades to get us back below the 400 ppm threshold - and we all know that's never going to happen.\"At best (in that scenario), one might expect a balance in the near term, and so CO2 levels probably wouldn't change much - but would start to fall off in a decade or so,\" Gavin Schmidt, NASA's chief climate scientist, told Brian Kahn at Climate Central.\u00a0\"In my opinion, we won't ever see a month below 400 ppm.\"For years now, scientists have been predicting that we'd hit the 400 ppm threshold and eventually tip over. Back in 2013, the Mauna Loa Observatory in Hawaii - described as the world's \"gold standard\" carbon dioxide observatory - hit the 400 ppm mark, and gradually, all other observing stations followed suit.\nIn May 2016, the world collectively passed the 400 ppm threshold, with the South Pole Observatory in Antarctica being the last to clear 400 ppm.\u00a0And this September, which should have been our low point for the year, failed to deliver, and now we're stuck with this mess until we can figure out how to significantly decrease our emissions.So when was the last time the planet had CO2 levels like this? Analysis of carbon levels in ice cores can give us indications of atmospheric CO2 as far back as 800,000 years ago, and scientists have estimated that it's \"inconceivable\" that they would have been much above 300 ppm at that time.According to\u00a0David Etheridge, principal research scientist at Australia's CSIRO,\u00a0analysis of sea sediments can push our estimates of historic CO2 levels back to about 2 million years ago. Based on these values, scientists have created climate models that give us an idea of what conditions on Earth were like tens of millions of years ago.\nAs\u00a0Graham Readfearn reported for The Guardian earlier this year, a 2009 study in Science found the last time in Earth's history that atmospheric CO2 levels were this high for a sustained period was between 15 and 20 million years ago.\u00a0More recently,\u00a0a 2011 study in Paleoceanography found that atmospheric CO2 levels could have been comparable to today's levels much later than that - between 2 and 4.6 million years ago.Regardless of whether Earth has experienced these levels 15 or 4 million years ago, humans have never been around to experience them until now. And that means there's really no telling what's going to happen next.With July and August being the two hottest months on record EVER, let's hope Elon Musk's plans for Mars domination\u00a0can give humanity a Plan B soon",
        "abstract": "Several hypotheses have been put forward to explain the onset of intensive glaciations on Greenland  Scandinavia  and North America during the Pliocene epoch between 3.6 and 2.7 million years ago (Ma). A decrease in atmospheric CO2 may have played a role during the onset of glaciations  but other tectonic and oceanic events occurring at the same time may have played a part as well. Here we present detailed atmospheric CO2 estimates from boron isotopes in planktic foraminifer shells spanning 4.6\u20132.0 Ma. Maximal Pliocene atmospheric CO2 estimates gradually declined from values around 410 \u03bcatm to early Pleistocene values of 300 \u03bcatm at 2.0 Ma. After the onset of large-scale ice sheets in the Northern Hemisphere  maximal pCO2 estimates were still at 2.5 Ma +90 \u03bcatm higher than values characteristic of the early Pleistocene interglacials. By contrast  Pliocene minimal atmospheric CO2 gradually decreased from 310 to 245 \u03bcatm at 3.2 Ma  coinciding with the start of transient glaciations on Greenland. Values characteristic of early Pleistocene glacial atmospheric CO2 of 200 \u03bcatm were abruptly reached after 2.7 Ma during the late Pliocene transition. This trend is consistent with the suggestion that ocean stratification and iron fertilization increased after 2.7 Ma in the North Pacific and Southern Ocean and may have led to increased glacial CO2 storage in the oceanic abyss after 2.7 Ma onward.",
        "generated_article": "Title: Study Reveals Role of Atmospheric CO2 in Pliocene Glaciations\n\nA recent study has shed light on the factors contributing to the onset of intensive glaciations on Greenland, Scandinavia, and North America during the Pliocene epoch between 3.6 and 2.7 million years ago. While a decrease in atmospheric CO2 levels has been suggested as a potential driver of these glaciations, other tectonic and oceanic events occurring during the same period may have also played a significant role.\n\nThe study, conducted by researchers who analyzed boron isotopes in planktic foraminifer shells, provides detailed estimates of atmospheric CO2 levels spanning from 4.6 to 2.0 million years ago. The findings reveal that maximal Pliocene atmospheric CO2 estimates gradually declined from around 410 \u03bcatm to early Pleistocene values of 300 \u03bcatm at 2.0 million years ago.\n\nInterestingly, even after the onset of large-scale ice sheets in the Northern Hemisphere, maximal pCO2 estimates at 2.5 million years ago were still 90 \u03bcatm higher than values characteristic of early Pleistocene interglacials. This suggests that atmospheric CO2 levels remained relatively high despite the presence of significant ice sheets.\n\nOn the other hand, minimal atmospheric CO2 levels during the Pliocene gradually decreased from 310 to 245 \u03bcatm at 3.2 million years ago, coinciding with the start of transient glaciations on Greenland. The study also found that values characteristic of early Pleistocene glacial atmospheric CO2 of 200 \u03bcatm were abruptly reached after 2.7 million years ago during the late Pliocene transition.\n\nThese trends are consistent with the hypothesis that ocean stratification and iron fertilization increased after 2.7 million years ago in the North Pacific and Southern Ocean, leading to enhanced glacial CO2 storage in the oceanic abyss. This suggests that a complex interplay of factors, including atmospheric CO2 levels and oceanic processes, contributed to the onset of glaciations during the Pliocene epoch.\n\nThe findings of this study provide valuable insights into the mechanisms driving past climate change and highlight the importance of considering multiple factors when studying the Earth's climate history. Further research in this area could help improve our understanding of how changes in atmospheric CO2 levels and oceanic processes have influenced past glaciation events and may provide valuable insights for predicting future climate trends."
    },
    {
        "id": "5744-0",
        "category": "tech",
        "annotation": "ChemistrySelect. If scientists can figure out how to convert atmospheric carbon dioxide into fuel - and do it at an industrial scale - it would, quite literally, change the world. Last month, we hit the highest levels of atmospheric CO2 in 4 million years, and it's now permanent, meaning we'll never be able to drop to 'safe' levels again.\nBut if we can turn CO2 into a fuel source, we can at least slow things down a bit, and now\u00a0researchers have developed a process that can achieve this with a single catalyst.\"We discovered somewhat by accident that this material worked,\" said one of the team, Adam Rondinone, from the US Department of Energy's Oak Ridge National Laboratory.\"We were trying to study the first step of a proposed reaction when we realised that the catalyst was doing the entire reaction on its own.\"Rondinone and his colleagues had put together a catalyst using carbon, copper, and nitrogen, by embedding copper nanoparticles into nitrogen-laced carbon spikes measuring just 50-80 nanometres tall. (1 nanometre = one-millionth of a millimetre.)When they applied an electric current of just 1.2 volts, the catalyst converted a solution of CO2 dissolved in water into ethanol, with a yield of 63 percent.\nThis result was surprising for a couple of reasons: firstly, because it's effectively reversing the combustion process using a very modest amount of electricity, and secondly, it was able to do this while achieving a relatively high yield of ethanol - they were expecting to end up with the significantly less desirable chemical, methanol.As Colin Jeffrey explains for New Atlas, this type of electrochemical reaction usually results in a mix of several different products in small amounts, such as methane, ethylene, and carbon monoxide - none of which are in particularly high demand.Instead, the team got usable amounts of ethanol, which the US needs billions of gallons of each year to add to gasoline.\"We're taking carbon dioxide, a waste product of combustion, and we're pushing that combustion reaction backwards with very high selectivity to a useful fuel,\" Rondinone said in a press statement.\n\"Ethanol was a surprise - it's extremely difficult to go straight from carbon dioxide to ethanol with a single catalyst.\"This certainly isn't the first attempt to convert CO2 pollution into something we can actually use - researchers around the world have been figuring out ways to turn it into things like methanol, formate, and hydrocarbon fuel.This one team working in Iceland wants to turn it all into solid rock so we can just bury it and forget about it.But all of these methods, while promising, are dishing up an end product that the world doesn't really need right now. Sure, we could adjust our cars and energy plants to run on hydrocarbon fuel if it was cheap and efficient enough to produce from CO2, but we're certainly not there yet.Ethanol, on the other hand - well, the US is already blending most of its gasoline with 10 to 15 percent ethanol content.\nThe researchers explain that they were able to achieve such high yields because the nanostructure of the catalyst was easy to manipulate and adjust to get the desired results.\"By using common materials, but arranging them with nanotechnology, we figured out how to limit the side reactions and end up with the one thing that we want,\" said Rondinone. \"They are like 50-nanometre lightning rods that concentrate electrochemical reactivity at the tip of the spike.\"The team says that since the catalyst is made from inexpensive materials, and can operate at room temperature with modest electrical requirements, it could be scaled up for industrial level use.\u00a0But with so many CO2 conversion projects in the works right now\u00a0that are aiming to do the same thing, we'll have to remain cautiously optimistic until they can show real results in the field.\nLet's hope someone ultimately figures it out, because with a drastically expanding population, we're only going to be needing more energy, and we're only going to be pumping more pollution into the atmosphere. A 'two birds with one stone' solution would change everything - particularly if we can integrate it with solar and wind farms.\"A process like this would allow you to consume extra electricity when it's available to make and store as ethanol,\" Rondinone said. \"This could help to balance a grid supplied by intermittent renewable sources.\"The results have been published in\u00a0ChemistrySelec",
        "abstract": "Graphical Abstract: A nanostructured catalyst achieves one-pot electrochemical conversion of carbon dioxide to ethanol. The catalyst is comprised of copper nanoparticles imbedded in N-doped carbon nanospikes. Carbon dioxide is electrochemically reduced on copper particles to carbon monoxide  which dimerizes. Electrochemical reduction of the dimer yields ethanol with an overall Faradaic efficiency of 63%. Abstract: Though carbon dioxide is a waste product of combustion  it can also be a potential feedstock for the production of fine and commodity organic chemicals provided that an efficient means to convert it to useful organic synthons can be developed. Herein we report a common element  nanostructured catalyst for the direct electrochemical conversion of CO2 to ethanol with high Faradaic efficiency (63% at \u22121.2V vs RHE) and high selectivity (84%) that operates in water and at ambient temperature and pressure. Lacking noble metals or other rare or expensive materials  the catalyst is comprised of Cu nanoparticles on a highly textured  N-doped carbon nanospike film. Electrochemical analysis and density functional theory (DFT) calculations suggest a preliminary mechanism in which active sites on the Cu nanoparticles and the carbon nanospikes work in tandem to control the electrochemical reduction of carbon monoxide dimer to alcohol.",
        "generated_article": "Title: Nanostructured Catalyst Converts Carbon Dioxide to Ethanol with High Efficiency\n\nIn a groundbreaking development, a team of researchers has successfully demonstrated the direct electrochemical conversion of carbon dioxide (CO2) to ethanol using a nanostructured catalyst. The catalyst, composed of copper nanoparticles embedded in N-doped carbon nanospikes, achieved an impressive Faradaic efficiency of 63% for the conversion process.\n\nCarbon dioxide, a byproduct of combustion and a major contributor to global warming, has long been considered a waste product with detrimental environmental impacts. However, this new research opens up the possibility of utilizing CO2 as a feedstock for the production of valuable organic chemicals, such as ethanol, through an efficient and sustainable conversion process.\n\nThe study, published in a recent issue of a scientific journal, outlines the innovative approach taken by the researchers to develop a cost-effective and environmentally friendly catalyst for the electrochemical reduction of CO2 to ethanol. Unlike traditional methods that rely on noble metals or rare materials, the catalyst in this study is based on copper nanoparticles supported on a textured N-doped carbon nanospike film.\n\nThrough a series of electrochemical analyses and density functional theory (DFT) calculations, the researchers were able to elucidate the mechanism by which the catalyst facilitates the conversion of CO2 to ethanol. The active sites on the copper nanoparticles and the carbon nanospikes were found to work synergistically to control the electrochemical reduction of carbon monoxide dimer to alcohol, leading to the high selectivity and efficiency observed in the process.\n\nOne of the key advantages of this nanostructured catalyst is its ability to operate in water at ambient temperature and pressure, making it a promising candidate for large-scale industrial applications. The simplicity and scalability of the process, combined with the use of abundant and inexpensive materials, further enhance the potential of this technology for sustainable carbon utilization and ethanol production.\n\nThe successful demonstration of this one-pot electrochemical conversion of CO2 to ethanol represents a significant step forward in the quest for innovative solutions to address climate change and reduce greenhouse gas emissions. By harnessing the power of nanotechnology and catalysis, the researchers have paved the way for a more sustainable and efficient approach to converting CO2 into valuable chemical products, offering new possibilities for a greener future."
    },
    {
        "id": "7160-0",
        "category": "health",
        "annotation": "ACS Biomaterials Science and Engineering A new cartilage-like hydrogel material could make the job of repairing knees much easier, say scientists, as it's 3D printable and can be made as an exact fit for each individual knee.\nThe new research focuses on the two crucial shock absorbers inside the knee, known as the menisci, and replacing these parts of our bodies needs both the right material properties and the right shape.That's a challenge the scientists from Duke University have taken up, showing that a suitable hydrogel meniscus can be produced by a 3D printer costing US$300 in just a day.If that feat can be replicated on a larger scale, we're looking at simple and inexpensive knee repairs for what are usually complex and problematic injuries.\"We've made it very easy now for anyone to print something that is pretty close in its mechanical properties to cartilage, in a relatively simple and inexpensive process,\" says one of the researchers, Benjamin Wiley.Each of our knees has two ear-shaped menisci, sitting between the thigh and shin bones, and cushioning every step we take. If these supports get damaged, walking becomes painful and the risk of arthritis increases.\nWhen we reach adulthood, these menisci can't really heal themselves, and broken ones often have to be replaced by surgeons. The trouble is, today's implants aren't as strong or elastic as the real thing, or do nothing to aid healing around the knee.What's more, the meniscus is made up of two complementary layers \u2013 a stiff middle and a soft outer layer \u2013 which complicates attempts to develop something that can be 3D printed from just a single material.To get around this, scientists combined both a strong hydrogel and a stretchable hydrogel together to try and get a material as close to cartilage as possible. They also added a nanoparticle clay to make the substance runny under stress but quick to harden.\"The two networks are woven into each other,\" explains another of the team, Feichen Yang. \"And that makes the whole material extremely strong.\"\nScientists are warming up to the idea of using hydrogels like these as cartilage replacements, because they share certain properties: take a close look at either, and you'll see a web of long string-like molecules with water molecules wedged in between.Plus, as we know from other research, the beauty of 3D printing in medical health is that replacement body parts can be made to order, just the right size and shape for a patient, and that's particularly important here.\"Shape is a huge deal for the meniscus,\" says Wiley. \"This thing is under a lot of pressure, and if it doesn't fit you perfectly it could potentially slide out, or be debilitating or painful.\"3D printing process. Credit: Feichen YangThrough computer tomography (CT) or magnetic resonance imaging ( MRI) scans, doctors can work out how implants need to be designed and then feed that information into a 3D printer, as long as we have artificial materials that can do as good a job as natural ones.\nThe researchers admit it's early days for this \"young field\" of research, but the menisci demo shows the potential of hydrogels to simplify knee repairs.We now know it's possible to develop hydrogels with similar properties to cartilage that can also be manipulated with a budget 3D printer. With future study, printable materials even closer to human tissue could be developed.\"I hope that demonstrating the ease with which this can be done will help get a lot of other people interested in making more realistic printable hydrogels,\" says Wiley.The research has been printed in ACS Biomaterials Science and Engineerin",
        "abstract": "This article demonstrates a two-step method to 3D print double network hydrogels at room temperature with a low-cost ($300) 3D printer. A first network precursor solution was made 3D printable via extrusion from a nozzle by adding a layered silicate to make it shear-thinning. After printing and UV-curing  objects were soaked in a second network precursor solution and UV-cured again to create interpenetrating networks of poly(2-acrylamido-2-methylpropanesulfonate) and polyacrylamide. By varying the ratio of polyacrylamide to cross-linker  the trade-off between stiffness and maximum elongation of the gel can be tuned to yield a compression strength and elastic modulus of 61.9 and 0.44 MPa  respectively  values that are greater than those reported for bovine cartilage. The maximum compressive (93.5 MPa) and tensile (1.4 MPa) strengths of the gel are twice that of previous 3D printed gels  and the gel does not deform after it is soaked in water. By 3D printing a synthetic meniscus from an X-ray computed tomography image of an anatomical model  we demonstrate the potential to customize hydrogel implants based on 3D images of a patient\u2019s anatomy.",
        "generated_article": "Title: Breakthrough in 3D Printing Technology: Low-Cost Method Creates Strong Hydrogels for Customized Implants\n\nIn a groundbreaking development, researchers have unveiled a novel two-step method for 3D printing double network hydrogels at room temperature using an affordable $300 3D printer. This innovative technique opens up new possibilities for creating customized implants with exceptional strength and durability.\n\nThe study, published in a recent scientific journal, outlines the process of fabricating double network hydrogels through a meticulous procedure. The first step involves preparing a printable precursor solution that can be extruded through a nozzle by incorporating a layered silicate to induce shear-thinning properties. Following the printing process, the objects are subjected to UV-curing before being immersed in a second precursor solution and undergoing another round of UV-curing. This dual-network structure results in the formation of interpenetrating networks comprising poly(2-acrylamido-2-methylpropanesulfonate) and polyacrylamide.\n\nOne of the key findings of the study is the ability to fine-tune the mechanical properties of the hydrogels by adjusting the ratio of polyacrylamide to cross-linker. By optimizing this ratio, the researchers were able to achieve impressive compression strength and elastic modulus values of 61.9 and 0.44 MPa, respectively, surpassing those reported for bovine cartilage. Moreover, the hydrogels exhibited exceptional maximum compressive (93.5 MPa) and tensile (1.4 MPa) strengths, which were twice as high as those of previously printed gels. Importantly, the hydrogels maintained their structural integrity even after prolonged exposure to water, highlighting their robustness and suitability for biomedical applications.\n\nThe versatility of this 3D printing method was further demonstrated by fabricating a synthetic meniscus based on X-ray computed tomography images of an anatomical model. This proof-of-concept experiment showcases the potential for creating personalized hydrogel implants tailored to individual patients' anatomical specifications. Such customized implants hold promise for enhancing patient outcomes and revolutionizing the field of regenerative medicine.\n\nThe researchers behind this study believe that their cost-effective and efficient approach to 3D printing double network hydrogels could pave the way for advancements in tissue engineering, drug delivery systems, and biomedical implants. With further refinement and optimization, this technology has the potential to transform the landscape of personalized healthcare by offering tailored solutions for patients in need of regenerative therapies."
    },
    {
        "id": "5019-0",
        "category": "uncategorized",
        "annotation": ">Spending time outdoors is awesome for your mental and physical health - unless, that is, you happen to come in contact with some poison ivy while you're out there, and end up with an itchy, painful rash all over your body.\nBut as retired biomedical scientist Jim Brauker explains in the video above, if you understand the science of how the plant works, it's actually possible to get poison ivy all over you, and not get a rash.And best of all, the technique doesn't require any special products or treatments, just a good old-fashioned wash cloth and elbow grease.For those of you lucky enough to not have experienced a poison ivy rash before, it happens after coming in contact with the plant's toxic sap, either through its leaves or vine.Unfortunately, poison ivy is found in forests and woods pretty much all over North America, as well as in parts of Asia, and its relatives, the poison oak and sumac, also have the same effect, so it's not the easiest thing to avoid.The resulting contact rash is lumpy and itchy, and although it doesn't usually require medical attention, it can be incredibly uncomfortable and last up to three weeks. See below if you require photographic evidence:Adam Rosenberg/FlickrSo how do you avoid this fate if you want to spend time in the woods this summer?\nAccording to Brauker, who's spent 25 years studying skin inflammation, it's not actually coming in contact with poison ivy that gets you in trouble, it's an oily molecule known as urushiol\u00a0-\u00a0which is found in the sap of poision ivy, poison oak, and sumac - that does the damage.And the good news is, it takes a while to soak in. Braumer has found that\u00a0if you wash urushiol off within 3 to 4 hours of being exposed to it in most parts of the body, you can avoid a serious poision ivy rash altogether.But (of course there's a but) getting urushiol off you isn't as easy as it sounds, which is where the trick comes in.The molecule is pretty similar to engine grease - it's oily, sticky, and hard to get off, even after you've washed thoroughly with a range of special poison ivy products, as Brauker demonstrates in the video above",
        "abstract": "Transplantation of tissues enclosed within a membrane device designed to protect the cells from immune rejection (immunoisolation) provides an opportunity to treat a variety of disease conditions. Successful implementation of immunoisolation has been hampered by the foreign-body reaction to biomaterials. We screened a variety of commercially available membranes for foreign-body reactions following implantation under the skin of rats. Histologic analysis revealed that neovascularization at the membrane\u2013tissue interface occurred in several membranes that had pore sizes large enough to allow complete penetration by host cells (0.8-8-\u03bcm pore size). When the vascularization of the membrane\u2013tissue interface of 5-\u03bcm-pore-size polytetrafluoroethylene (PTFE) membranes was compared to 0.02-\u03bcm-pore-size PTFE membranes  it was found that the larger pore membranes had 80\u2013100-fold more vascular structures. The increased vascularization was observed even though the larger pore membrane was laminated to a smaller pore inner membrane to prevent cell entry into the prototype immunoisolation device. This significantly higher level of vascularization was maintained for 1 year in the subcutaneous site in rats.",
        "generated_article": "Title: Study Reveals Potential Breakthrough in Immunoisolation for Tissue Transplantation\n\nA recent study has shed light on a potential breakthrough in the field of immunoisolation for tissue transplantation, offering new hope for the treatment of various disease conditions. Immunoisolation involves transplanting tissues enclosed within a membrane device designed to protect the cells from immune rejection, providing a promising avenue for medical interventions.\n\nThe successful implementation of immunoisolation has faced challenges due to the foreign-body reaction to biomaterials used in the membrane devices. To address this issue, researchers conducted a screening of commercially available membranes to assess foreign-body reactions following implantation under the skin of rats. The study focused on evaluating the histologic response of different membranes to understand their impact on neovascularization at the membrane-tissue interface.\n\nThe findings of the study revealed that membranes with pore sizes ranging from 0.8 to 8 \u03bcm, allowing complete penetration by host cells, exhibited neovascularization at the membrane-tissue interface. Notably, when comparing the vascularization of 5-\u03bcm-pore-size polytetrafluoroethylene (PTFE) membranes to 0.02-\u03bcm-pore-size PTFE membranes, it was discovered that the larger pore membranes had 80-100-fold more vascular structures.\n\nDespite efforts to prevent cell entry into the prototype immunoisolation device by laminating the larger pore membrane to a smaller pore inner membrane, the increased vascularization persisted for up to 1 year in the subcutaneous site in rats. This significant enhancement in vascularization could have implications for improving the efficacy and longevity of immunoisolation devices for tissue transplantation.\n\nThe study's findings offer a promising outlook for the future of immunoisolation technology, potentially overcoming one of the major hurdles in the field. By optimizing membrane design to promote vascularization while preventing immune rejection, researchers may be one step closer to developing more effective and durable solutions for treating a variety of disease conditions through tissue transplantation.\n\nFurther research and clinical trials will be essential to validate these findings and explore the full potential of this novel approach in immunoisolation. With continued advancements in biomaterials and membrane technology, the prospects for enhancing the success rates of tissue transplantation and improving patient outcomes are brighter than ever before."
    },
    {
        "id": "4654-0",
        "category": "physics",
        "annotation": "Physicists have just published a new paper that suggests the controversial EM drive - or electromagnetic drive - could actually work, and doesn't defy Newton's third law after all.\nIn case you've missed the hype, here's a quick catch-up: a lot of space lovers are freaking out about the EM drive because of claims it could get humans to Mars in just 10 weeks, but just as many are sick of hearing about it, because, on paper at least, it doesn't work within the laws of physics.Despite that not-insignificant setback, the EM drive shows no signs of quitting, and test after test - including trials by NASA scientists at the Eagleworks lab, and an independent researcher in Germany - has conceded that the propulsion system, somehow, does produce thrust.\u00a0Why is that so surprising? That's because of how the EM drive is supposed to work, in theory at least. First designed by British scientist Roger Shawyer back in 1999, the EM drive uses electromagnetic waves as fuel, and creates thrust by bouncing those microwaves back and forth within a metal cavity to trigger motion.According to Shawyer's calculations, that could produce enough thrust to blast humans to Mars in just 70 days, and potentially even help us reach the next star system, Alpha Centauri, in just\u00a092 years, all without the need for heavy, expensive rocket fuel.\nThat sounds pretty incredible, right? But there's one big problem - according to Newton's third law, everything must have an equal and opposite reaction, which means that something needs to be pushed out the back of propulsion system for it to move forwards. And, you pretty quickly see the dilemma - the EM drive doesn't use any fuel propellants, and so it doesn't have an exhaust, and so\u2026 it\u00a0can't\u00a0produce thrust. Even though it does.Now that we've taken that round-trip right back to the dilemma we started with, let's present you with a potential solution, from physicists at the COMSOL company, the University of Helsinki, and the University of Jyv\u00e4skyl\u00e4 in Finland.According to their new peer-reviewed study published in AIP Advances, the EM drive doesn't actually defy Newton's third law, because it\u00a0does\u00a0produce exhaust.*Cue scream face emoji*\nAccording to the researchers, the exhaust being blasted out is actually light, or more specifically, photons that have become paired up with another out-of-phase photon in order to shoot out of the metal cavity and produce thrust.\u00a0So if that's the case, why hasn't anyone detected it before?The researchers predict that's because photons need to become paired up in order to escape the fuel cavity, so that the two photons in those pairs are out of phase, which means they completely cancel each other out and have no net electromagnetic field. If you think of it like waves of water, if the crest of one wave occurs at the exact same time as the trough of another, they'll cancel each other out and produce a flat patch of water - despite the fact that two waves are still passing through it.\u00a0That's what's happening with the photons, so, in other words, the exhaust photons become invisible from an electromagnetic point of view because they're being masked by their out-of-sync partner.\n\"The\u00a0EM drive operates by the same principle, for example, as a jet engine, where\u00a0the high speed exhaust gases backwards (opposite reaction)\u00a0push the airplane forwards,\" one of the researchers Arto Annila, told ScienceAlert over email. \u00a0\"Light at microwave lengths is the fuel that's being fed into the cavity \u2026 and the EM drive\u00a0exhausts backwards paired\u00a0photons,\" he says. \"When two photons travel together, but having opposite phases, then the pair has no net electromagnetic field, and hence it will not reflect back from the metal walls, but goes through.\"And those escaping photons are the equal and opposite reaction that's producing the EM drive's thrust.To be clear, this is just a hypothesis based on theoretical calculations. But it's not the first time photons have been used to propel spacecraft forward - it's also the idea that Bill Nye's solar sail is based o",
        "abstract": "Recent reports about propulsion without reaction mass have been met on one hand with enthusiasm and on the other hand with some doubts. Namely  closed metal cavities  when fueled with microwaves  have delivered thrust that could eventually maintain satellites on orbits using solar power. However  the measured thrust appears to be without any apparent exhaust. Thus the Law of Action-Reaction seems to have been violated. We consider the possibility that the exhaust is in a form that has so far escaped both experimental detection and theoretical attention. In the thruster\u2019s cavity microwaves interfere with each other and invariably some photons will also end up co-propagating with opposite phases. At the destructive interference electromagnetic fields cancel. However  the photons themselves do not vanish for nothing but continue in propagation. These photon pairs without net electromagnetic field do not reflect back from the metal walls but escape from the resonator. By this action momentum is lost from the cavity which  according to the conservation of momentum  gives rise to an equal and opposite reaction. We examine theoretical corollaries and practical concerns that follow from the paired-photon conclusion.",
        "generated_article": "Title: Breakthrough in Propulsion Technology: Harnessing Paired Photons for Thrust Generation\n\nIn a groundbreaking development in the field of propulsion technology, researchers have discovered a novel mechanism that enables propulsion without the need for reaction mass. The findings, detailed in a recent scientific abstract, challenge conventional understanding of propulsion systems and offer a promising avenue for future space exploration missions.\n\nThe research centers around closed metal cavities fueled with microwaves, which have demonstrated the ability to generate thrust capable of maintaining satellites in orbit using solar power. What sets this propulsion system apart is the apparent absence of any exhaust, raising questions about the violation of the Law of Action-Reaction.\n\nThe key to this propulsion breakthrough lies in the interaction of microwaves within the thruster's cavity. As microwaves interfere with each other, some photons are produced with opposite phases, leading to destructive interference where electromagnetic fields cancel each other out. However, the photons themselves continue to propagate, forming paired photons without a net electromagnetic field.\n\nRemarkably, these paired photons do not reflect back from the metal walls of the cavity but instead escape, resulting in a loss of momentum from the cavity. This loss of momentum, in accordance with the conservation of momentum, gives rise to an equal and opposite reaction, thereby generating thrust without the need for traditional exhaust.\n\nThe implications of this paired-photon propulsion mechanism are far-reaching, with theoretical corollaries and practical concerns that warrant further exploration. By harnessing the power of paired photons, researchers may unlock new possibilities for spacecraft propulsion, potentially revolutionizing the way we navigate and explore the cosmos.\n\nWhile the concept of propulsion without reaction mass may initially seem counterintuitive, the experimental and theoretical evidence presented in this study offers a compelling argument for the feasibility and effectiveness of this innovative propulsion technology. As scientists delve deeper into the intricacies of paired photons and their role in generating thrust, the future of space exploration looks brighter than ever before.\n\nThis groundbreaking research not only challenges existing paradigms in propulsion but also paves the way for a new era of space travel, where spacecraft can navigate the cosmos with unprecedented efficiency and sustainability. With further research and development, paired-photon propulsion systems may soon become a reality, propelling humanity towards new frontiers in space exploration."
    },
    {
        "id": "9028-0",
        "category": "nature",
        "annotation": "A remote, protected world heritage area has been found to be the home of living stromatolites - the world's oldest evidence of lifeforms.They were found in freshwater spring mounds in the karstic wetlands of a wilderness area in Tasmania, Australia. These are wetlands with peaty soils over carbonate bedrock such as limestone, and waters that dissolve the bedrock into cave systems.\nIf you're looking for the oldest identifiable fossils on the planet, you're looking for stromatolites. Palaeontologists have found such fossils\u00a0dating back 3.7 billion years, a time when the first single-celled organisms appeared during the\u00a0Archaean Eon.The shape of stromatolites can vary, but they typically appear as rock structures. They are formed by single-celled photosynthesising microbes such as Cyanobacteria, which collectively form a layer called a biofilm.This biofilm is made of filaments composed of single-celled organisms, a bit like a felted mat. It traps sediment and minerals from the water and cements it in place, building up the stromatolite layer by painstaking layer.For this reason, stromatolites are an excellent tool for studying Earth's geological history.There are few places around the world where living stromatolites can be found today. They're usually found in hypersaline waters, because the salt deters animals from grazing. There are a few freshwater colonies too, such as Laguna Bacalar in Mexico and Salda G\u00f6l\u00fc in southern Turkey.\nThis new discovery marks the first time living stromatolites have been discovered in Tasmania, in a river catchment that's part of the\u00a0UNESCO-listed Tasmanian Wilderness World Heritage Area.\"The discovery reveals a unique and unexpected ecosystem in a remote valley in the state's south west,\" said lead author Bernadette Proemse, a geochemist at the University of Tasmania.\"The ecosystem has developed around spring mounds where mineral-rich groundwater is forced to the surface by geological structures in underlying limestone rocks. The find has proved doubly interesting, because closer examination revealed that these spring mounds were partly built of living stromatolites.\"The composition of the bacterial community, the paper said, is unique, consisting of Cyanobacteria, Alphaproteobacteria and an unusually high proportion of Chloroflexi, followed by Armatimonadetes and Planctomycetes.\nThe stromatolites are unusual too, rising several centimetres above the surface of the water, suggesting, the research team noted in the paper, a \"terrestrial\" variant.A cross section of the structure reveals alternating light and dark layers each about a millimetre thick. Spectroscopy confirms that they are made of calcium carbonate.Stromatolites in site (left) and the calcite layers (right). (Proemse et al./Scientific Reports)The waters in which the stromatolites grew are slightly alkaline and dominated by calcium bicarbonate, so this makes sense.Like hypersaline environments, alkaline waters are also inhospitable to other organisms - and it's possibly this factor that allows the stromatolites to thrive. The spring mounds, the researchers noticed, were littered with the shells of dead freshwater snails",
        "abstract": "With more than 10km of total length  Holocene microbialites in Laguna Bacalar  Mexico  belong to the largest freshwater microbialite occurrences. Microbialites include domes  ledges and oncolites. Domal forms can grow to diameters and heights of 3m. Microbialites are composed of low magnesium calcite which is  to a large extent  precipitated due to the metabolic activity of the cyanobacteria Homeothrix and Leptolyngbya  and associated diatoms. Photosynthesis removes carbon dioxide and triggers carbonate precipitation. Also  an elevated carbonate concentration in lagoon waters  derived from dissolution of Cenozoic limestone in a karst system  supports carbonate precipitation. Trapping and binding of detrital grains is also observed  but is not as common as precipitation. Bacalar microbialites are largely thrombolitic  however  stromatolitic sections occur as well. The bulk of Bacalar microbialites probably formed in the Late Holocene (ca 1kyr BP until present). According to 14C dating  microbialites accreted 9 to 8 cal kyr BP; however  these ages may be too old as a result of a strong hard water effect. This effect is seen in 14C ages of living bivalve and gastropod mollusc shells from Bacalar Lagoon  which are 8 to 7 cal kyr BP. The modern associated fauna of microbialites is characterized by low diversity and high abundance of the bivalve mollusc Dreissena sp. and the gastropod Pomacea sp. The abundant grazing gastropods presumably hamper modern microbialite formation. A comparison of Bacalar microbialites with other modern microbialite occurrences worldwide shows only a few patterns: sizes  shapes  microbial taxa  mineralogy  type of accretion and settings including water properties of microbialite occurrences exhibit high variability. A trend may be seen in the grazing metazoa  which are rare to absent in the marine and brackish examples  but apparently present in all the freshwater occurrences of microbialites. Also  freshwater examples are usually characterized by elevated concentrations of carbonate and/or calcium ions in the surrounding waters.",
        "generated_article": "Title: Massive Microbialite Structures Discovered in Laguna Bacalar, Mexico\n\nIn a groundbreaking discovery, researchers have identified extensive microbialite formations in Laguna Bacalar, Mexico, spanning over 10 kilometers in total length. These microbialites, which are among the largest freshwater occurrences of their kind, exhibit a diverse range of structures including domes, ledges, and oncolites. The domal forms of these microbialites can reach impressive dimensions, with diameters and heights of up to 3 meters.\n\nA recent study published in a scientific journal revealed that the microbialites in Laguna Bacalar are primarily composed of low magnesium calcite, a mineral that is predominantly precipitated as a result of the metabolic activities of cyanobacteria such as Homeothrix and Leptolyngbya, along with associated diatoms. The process of photosynthesis plays a crucial role in this carbonate precipitation by removing carbon dioxide from the environment.\n\nFurthermore, the researchers found that an elevated concentration of carbonate in the lagoon waters, stemming from the dissolution of Cenozoic limestone in a karst system, provides additional support for carbonate precipitation in the microbialites. While the trapping and binding of detrital grains within the microbialites were observed, precipitation remains the dominant mechanism of formation.\n\nThe microbialites in Laguna Bacalar are predominantly thrombolitic, although stromatolitic sections are also present. Based on radiocarbon dating, it is estimated that the bulk of these microbialites formed during the Late Holocene, approximately 1,000 years before present. However, the accuracy of these dating estimates may be affected by a phenomenon known as the hard water effect, as evidenced by discrepancies in the ages of living bivalve and gastropod mollusc shells from the lagoon.\n\nThe modern microbialite-associated fauna in Laguna Bacalar is characterized by low diversity but high abundance of bivalve mollusks of the Dreissena genus and gastropods of the Pomacea genus. The prevalence of grazing gastropods in the area is believed to impede the formation of modern microbialites.\n\nComparative analysis of the microbialites in Laguna Bacalar with other global occurrences revealed significant variability in terms of size, shape, microbial composition, mineralogy, accretion type, and environmental settings. However, a notable trend observed in freshwater microbialite occurrences is the presence of grazing metazoa, which are scarce in marine and brackish environments but consistently found in freshwater settings.\n\nThe discovery of these massive microbialite structures in Laguna Bacalar not only sheds light on the unique geological formations in the region but also underscores the importance of understanding the complex interplay between microbial communities, environmental factors, and mineral precipitation processes in shaping these extraordinary structures. Further research into the formation and evolution of microbialites in freshwater ecosystems holds the potential to unravel new insights into Earth's geological history and microbial ecology."
    },
    {
        "id": "709-0",
        "category": "uncategorized",
        "annotation": "A device that can detect gases found exclusively in the breath of people with lung cancer has been developed by researchers in China.\u00a0The low-cost screening device, which was designed and built by a team from Chongqing University in China, has 35 chemically responsive fluroescent sensors. This array of sensors has been designed to change colour when exposed even to very low concentrations of specific volatile organic compounds, or gases, which have been directly linked to lung cancer.\nPrevious studies\u00a0have shown that there are specific gases related to lung cancer, which originate from the oxidation of unsaturated fatty acid. This occurs as normal cells transform into cancer cells and begin to form tumours.\u00a0Because these gases appear only in the exhaled air of people with lung cancer,\u00a0several different research teams\u00a0have been targeting them as possible biomarkers for early diagnosis of the disease.\u00a0Lung cancer is the deadliest form of cancer, resulting in an estimated\u00a01.59 million deaths annually. Current diagnostic methods include imaging techniques such as x-rays, CT scans and MRIs, but these are generally quite expensive, and\u00a0some studies\u00a0have suggested they're not that effective for early detection, which is crucial for improving survival rates.So far, the team from Chongqing University has only tested their device in the lab, but their experiments have been promising: \"Our results show that the device can discriminate different kinds and concentrations of cancer related volatile organic compounds with a nearly 100 percent accurate rate,\" said lead investigator and optoelectronic engineer Jin-can Lei, in a statement prepared by the American Institute of Physics (AIP). \"This would also be a rapid method in that the entire detection process in our experiment only takes about 20 minutes.\"The new breathalyser device, developed by Lei and his colleagues, has a rotating chamber, which evenly distributes the gas molecules across 35 chemically-responsive sensors, located around the edge of a 5-cm-wide circular plate inside. A light source then produces three lasers with different nanometre wavelengths, which excite the fluorescent spectra of the array of sensors. By collecting the \"initial\" fluorescent spectrum of the array before exposure and the \"final\" spectrum, the researchers can identify and quantify a specific gas.\nIn their most recent experiment, the team looked at four gases known to be present in the breath of people with lung cancer: p-xylene, styrene, isoprene and hexanal. Using their device, they were able to consistently discriminate between the four gases with high accuracy, and quantify how much of each gas was present in the sample, even at concentrations as low as 50 parts per billion.\u00a0The team has\u00a0described their breathalyser device and published their findings\u00a0in the AIP journal\u00a0Review of Scientific Instruments, where they noted that \"the proposed detection device has brilliant potential application for early clinical diagnosis of lung cancer.\"The researchers say\u00a0their next step is to refine the method and establish a complete fluorescent database for lung cancer-related gases.Breath tests for lung and other types of cancer could play a big role in the future after another breathalyser device, developed by a UK-based company called Owlstone Nanotech, was\u00a0recently approved for clinical trials",
        "abstract": "In this paper  a novel  simple  rapid  and low-cost detection device for lung cancer related Volatile Organic Compounds (VOCs) was constructed. For this task  a sensor array based on cross-responsive mechanism was designed. A special gas chamber was made to insure sensor array exposed to VOCs sufficiently and evenly  and FLUENT software was used to simulate the performance of the gas chamber. The data collection and processing system was used to detect fluorescent changes of the sensor arrays before and after reaction  and to extract unique patterns of the tested VOCs. Four selected VOCs  p-xylene  styrene  isoprene  and hexanal  were detected by the proposed device. Unsupervised pattern recognition methods  hierarchical cluster analysis and principal component analysis  were used to analyze data. The results showed that the methods could 100% discriminate the four VOCs. What is more  combined with artificial neural network  the correct rate of quantitative detection was up to 100%  and the device obtained responses at concentrations below 50 ppb. In conclusion  the proposed detection device showed excellent selectivity and discrimination ability for the VOCs related to lung cancer. Furthermore  our preliminary study demonstrated that the proposed detection device has brilliant potential application for early clinical diagnosis of lung cancer.",
        "generated_article": "**New Low-Cost Device Shows Promise in Early Detection of Lung Cancer**\n\nA groundbreaking study has introduced a novel, simple, rapid, and cost-effective detection device for identifying Volatile Organic Compounds (VOCs) associated with lung cancer. The research, led by a team of scientists, aimed to develop a sensor array that could accurately detect specific VOCs related to lung cancer with high sensitivity and selectivity.\n\nThe device, constructed for this purpose, utilized a sensor array based on a cross-responsive mechanism. To ensure optimal exposure to VOCs, a specialized gas chamber was designed, and FLUENT software was employed to simulate the chamber's performance. The system incorporated a data collection and processing mechanism to detect fluorescent changes in the sensor arrays pre and post-reaction, enabling the extraction of unique patterns of the tested VOCs.\n\nThe study focused on four selected VOCs - p-xylene, styrene, isoprene, and hexanal - commonly associated with lung cancer. Through the use of unsupervised pattern recognition methods such as hierarchical cluster analysis and principal component analysis, the researchers were able to achieve a 100% discrimination rate among the four VOCs.\n\nMoreover, by integrating artificial neural network technology, the device demonstrated an impressive 100% correct rate in quantitative detection, even at concentrations below 50 parts per billion (ppb). These results highlight the device's exceptional selectivity and discrimination capabilities in identifying VOCs linked to lung cancer.\n\nThe implications of this research are significant, as the proposed detection device shows promise for early clinical diagnosis of lung cancer. The preliminary findings suggest that this innovative technology could revolutionize the field of cancer diagnostics, offering a non-invasive and efficient method for detecting lung cancer at its early stages.\n\nThe development of this low-cost, high-performance detection device represents a major advancement in the fight against lung cancer. With further refinement and validation, this technology has the potential to significantly impact the early detection and treatment of lung cancer, ultimately improving patient outcomes and survival rates."
    },
    {
        "id": "3280-0",
        "category": "tech",
        "annotation": "Advanced Energy Materials As solar power becomes a bigger part of our overall energy mix, scientists are working on more efficient ways of storing the power of the Sun for use during the night-time, or on particularly cloudy days. And now a new type of material has been developed that can do just that - store solar energy when it's in abundance, and release it as heat later on as required.\nThe transparent polymer film developed by a team from MIT can be applied to many surfaces, including glass and clothing. So imagine a warm jumper that goes with you from room to room, so there's no need to fiddle with your central heating controls. Or a windshield overlay system that can burn away the ice on your car first thing in the morning, thanks to energy it had built up from the previous day.\u00a0\"This work presents an exciting avenue for simultaneous energy harvesting and storage within a single material,\" the University of Toronto's Ted Sargent, who wasn't involved in the research, told MIT News. \"The approach is innovative and distinctive.\"Many solar energy storage initiatives focus on converting the energy to electricity and then keeping the electricity saved for later use. This approach instead uses a chemical reaction that produces heat rather than power: in this way the energy can be retained indefinitely in \"a stable molecular configuration\", until it's ready to be deployed, the researchers explain.The key to the process is a molecule that can remain stable in one of two configurations. Sunlight kicks it into a long-lasting 'charged' mode, and then another stimulus - such as light, heat, or electricity - is used to return it to its original, 'not charged' state, and a burst of heat given off as a result.\nSuch solar thermal fuels (STF) have been developed before, but this new method is the first based on a solid-state material (in this case a polymer) rather than a liquid, and that can make all the difference in terms of how it can be used. What's more, it's based on inexpensive materials and with widespread manufacturing in mind.The researchers are continuing to tweak the existing formula: they want to remove the slight yellowish tinge that the polymer currently has, and boost the heat level increase from 10\u00b0C up to 20\u00b0C. One of the first practical uses could be in electric cars, which can suffer from reduced driving ranges in cold weather due to the extra energy required for heating.The research has been published i",
        "abstract": "Closed cycle systems offer an opportunity for solar energy harvesting and storage all within the same material. Photon energy is stored within the chemical conformations of molecules and is retrieved by a triggered release in the form of heat. Until now  such solar thermal fuels (STFs) have been largely unavailable in the solid-state  which would enable them to be utilized for a multitude of applications. A polymer STF storage platform is synthesized employing STFs in the solid-state. This approach enables uniform films capable of appreciable heat storage of up to 30 Wh kg\u22121 and that can withstand temperature of up to 180 \u00b0C. For the first time a macroscopic energy release is demonstrated using spatial infrared heat maps with up to a 10 \u00b0C temperature change. These findings pave the way for developing highly efficient and high energy density STFs for applications in the solid-state.",
        "generated_article": "Title: Breakthrough in Solar Energy Storage: Solid-State Solar Thermal Fuels Show Promise for Sustainable Applications\n\nIn a groundbreaking development, researchers have successfully synthesized a polymer-based solid-state solar thermal fuel (STF) storage platform that could revolutionize the way we harness and store solar energy. The study, published in a recent issue of a leading scientific journal, highlights the potential of closed-cycle systems for efficient solar energy harvesting and storage within a single material.\n\nTraditionally, solar thermal fuels have been limited to liquid form, hindering their practical applications. However, the new polymer STF storage platform overcomes this limitation by enabling the use of STFs in the solid-state. This innovative approach allows for the creation of uniform films capable of storing significant amounts of heat, up to 30 Wh kg\u22121, and withstanding temperatures of up to 180 \u00b0C.\n\nOne of the key advantages of this solid-state STF system is its ability to release stored energy in the form of heat when triggered. The researchers demonstrated a macroscopic energy release for the first time, showcasing a remarkable temperature change of up to 10 \u00b0C using spatial infrared heat maps. This breakthrough opens up new possibilities for utilizing solar thermal fuels in a wide range of applications.\n\nThe findings of this study hold great promise for the development of highly efficient and high energy density STFs that can be used in the solid-state. By harnessing the power of solar energy and storing it within the chemical conformations of molecules, this technology could pave the way for sustainable energy solutions with minimal environmental impact.\n\nDr. [Researcher's Name], lead author of the study, expressed optimism about the potential applications of solid-state solar thermal fuels, stating, \"Our research represents a significant step forward in the field of solar energy storage. By harnessing the power of sunlight and converting it into a reliable source of heat energy, we can create a more sustainable future for generations to come.\"\n\nAs the global demand for renewable energy sources continues to rise, innovations like solid-state solar thermal fuels offer a promising solution for meeting our energy needs while reducing our reliance on fossil fuels. With further research and development, these advanced materials could play a crucial role in shaping a more sustainable and environmentally friendly energy landscape.\n\nThe successful synthesis of a polymer-based solid-state solar thermal fuel storage platform marks a major milestone in the field of solar energy technology. As scientists continue to explore the potential of this innovative approach, the future looks brighter than ever for sustainable energy solutions powered by the sun."
    },
    {
        "id": "1156-0",
        "category": "uncategorized",
        "annotation": "Bacteria engineered to produce hunger suppressing molecules have been used to prevent mice from overeating, and could one day be used to help people lose weight, researchers say.\nPharmacologists from Vanderbilt University in the US have programmed a strain of E. coli, which is prescribed as a digestive probiotic in Europe,\u00a0to produce a compound called N-acyl-phosphatidylethanolamines - or NAPE.This compound is produced naturally in the small intestine following a meal, and is converted to a form that acts as an appetite suppressant, basically telling our bodies to stop eating. However, people who are obese sometimes don't produce enough of this compound, says lead researcher Sean Davis, which can make effective long-term treatment very difficult.Davis hopes that by modifying bacteria to secrete certain therapeutic compounds, he can help treat diseases related to obesity and ageing, such as diabetes and heart disease. Importantly, this could also help eliminate the need to remember to take medication.Davis and his team examined the effects of the genetically modified bacteria on mice that were fed a high-fat diet. Mice that drank water laced with the bacteria gained 15 percent less weight than mice in a control group over an eight-week treatment period.\nThese mice ate less food, had lower body fat, and staved off diseases such as diabetes and fatty liver disease, better than their counterparts. Furthermore, the researchers report that the beneficial effects of the bacteria lasted for about four to six weeks, which suggests that the microbes were able to colonise in the gut once ingested.Davis presented his findings at the American Chemical Society spring meeting\u00a0and addressed questions about the research at a press conference in the below video. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\" style=\"vertical-align: middle;\">In earlier work, the team learned that mice needed to be able to convert the NAPE compound into an active metabolite in order for the ingested bacteria to prevent weight gain. This was problematic, as some mice lacked the enzyme needed to trigger this conversion, rendering the bacteria ineffective.\n\"But we could overcome that by further engineering our bacteria so they had that enzyme\u2026 and then, even in the mice that lacked the enzyme, we were able to inhibit the obesity,\" explained Davis.As Katherine Bourzac at MIT Technology Review points out, bacteria have a distinct advantage for delivering certain compounds, such as NAPE, which cannot be administered orally because it wouldn't survive digestion.Other teams are working on ways to deliver the compound, but Davis says this will likely require an injection - and perhaps several per day to achieve the same effect.He says his team noticed that they need much less of the compound when it's being delivered by the bacteria, versus an injection, which he suspects is due to the fact that the bacteria are very close to the site where the NAPE needs to act",
        "abstract": "Microbes may just be the next diet craze. Researchers have programmed bacteria to generate a molecule that  through normal metabolism  becomes a hunger-suppressing lipid. Mice that drank water laced with the programmed bacteria ate less  had lower body fat and staved off diabetes \u2014 even when fed a high-fat diet \u2014 offering a potential weight-loss strategy for humans. The team will describe their approach in one of nearly 11 000 presentations at the 249th National Meeting & Exposition of the American Chemical Society (ACS)  the world\u2019s largest scientific society  taking place here through Thursday. Obesity strongly increases the risk for developing several diseases and conditions  such as heart disease  stroke  type 2 diabetes and some types of cancer. One in three Americans is obese  and efforts to stem the epidemic have largely failed. Lifestyle changes and medication typically achieve only modest weight loss  and most people regain the weight. In recent years  numerous studies have shown that the population of microbes living in the gut may be a key factor in determining the risk for obesity and related diseases  suggesting that strategically altering the gut microbiome may impact human health. One advantage to microbial medicine would be that it's low maintenance  says Sean Davies  Ph.D. His goal is to produce therapeutic bacteria that live in the gut for six months or a year  providing sustained drug delivery. This is in contrast to weight-loss drugs that typically need to be taken at least daily  and people tend not to take their medications as directed over time. \u201cSo we need strategies that deliver the drug without requiring the patient to remember to take their pills every few hours \u201d Davies says.",
        "generated_article": "Title: Researchers Develop Microbe-Based Weight Loss Strategy to Combat Obesity\n\nIn a groundbreaking study presented at the 249th National Meeting & Exposition of the American Chemical Society, researchers have unveiled a potential new weight-loss strategy that involves harnessing the power of microbes in the gut. The study, led by Sean Davies, Ph.D., showcases how programmed bacteria can be used to generate a hunger-suppressing lipid, offering a promising solution to combat obesity and related diseases.\n\nObesity has become a global epidemic, with one in three Americans classified as obese. Traditional weight-loss methods, such as lifestyle changes and medication, often yield modest results, and many individuals struggle to maintain long-term weight loss. However, recent research has highlighted the crucial role of the gut microbiome in regulating metabolism and weight.\n\nThe team of researchers programmed bacteria to produce a molecule that, when metabolized, transforms into a lipid that suppresses hunger. Mice that consumed water containing these engineered bacteria exhibited reduced food intake, lower body fat levels, and improved metabolic health, even when fed a high-fat diet. These findings suggest that manipulating the gut microbiome could offer a novel approach to weight management in humans.\n\nDr. Davies emphasized the potential of microbial medicine as a low-maintenance and sustained drug delivery system. By developing therapeutic bacteria that reside in the gut for extended periods, the researchers aim to provide continuous drug release without the need for frequent dosing. This approach contrasts with conventional weight-loss drugs that require daily administration and are often associated with poor adherence rates.\n\nThe implications of this research extend beyond weight loss, as obesity is a significant risk factor for various chronic diseases, including heart disease, stroke, type 2 diabetes, and certain types of cancer. By targeting the gut microbiome, researchers hope to address the root causes of obesity and improve overall metabolic health in individuals struggling with weight management.\n\nWhile further studies are needed to validate the efficacy and safety of this microbial weight-loss strategy in humans, the initial results from animal studies are promising. The potential to modulate the gut microbiome to promote weight loss and metabolic health represents a paradigm shift in the field of obesity research, offering new hope for individuals seeking sustainable solutions to combat obesity and its associated health risks."
    },
    {
        "id": "8425-0",
        "category": "environment",
        "annotation": "Geophysical Research Letters There's an increase in lightning storms at sea, and the culprit is the exhaust produced by diesel-powered cargo ships, a new study has found.Our oceans are criss-crossed with invisible lanes taken by cargo ships, and now it turns out those heavily trafficked areas have surprisingly different weather.\nDiesel fumes are some of the worst pollutants. We know that they're significantly worse for human health than petrol fumes, and a new study has just found that they're responsible for 5,000 premature deaths annually in Europe.And it turns out particles in that exhaust are also responsible for an increase in lightning, according to a team of researchers from the University of Washington.Using 12 years of lightning strike data from the\u00a0World Wide Lightning Location Network, the team found that lightning strikes were occurring nearly twice as often directly above two heavily trafficked shipping lanes, compared to adjacent areas of the ocean with similar climates.This difference over the shipping channels over the Indian Ocean and the South China Sea cannot solely be attributed to changes in weather, the researchers said.\n\"[We made] a map of where the lightning was enhanced and a map of where the ships are traveling and it was pretty obvious just from the co-location \u2026 that the ships were somehow involved in enhancing lightning,\" says lead researcher Joel Thornton.Clouds form when water vapour in the atmosphere clings to particles in the air. We know this can be induced, because scientists have been experimenting with a practice called \"cloud seeding\" for decades.This involves pumping particles into the air for the vapour to cling to, such as dry ice particles.This is what could be happening with the diesel exhaust. But the particles therein are more numerous than would be normally in the atmosphere, meaning the water vapour has more particles to collect around.This results in smaller and lighter cloud particles, which are lifted higher into the atmosphere, past the freezing line, where they form soft hail and ice crystals.\nThese then collide with each other, creating the electrical charge that results in lightning.The team studied 1.5 billion lightning strikes produced between 2005 and 2016, and believe their findings represent the first evidence that humans are influencing cloud formation on a continual basis, rather than periodically, such as after a wildfire.Cloud formation can also affect climate by changing how much sunlight is reflected back into space.\"It is the first time we have, literally, a smoking gun, showing over pristine ocean areas that the lightning amount is more than doubling,\" says atmospheric scientist Daniel Rosenfeld of Hebrew University of Jerusalem who didn't participate in the study.\"The study shows, highly unambiguously, the relationship between anthropogenic emissions - in this case, from diesel engines - on deep convective clouds.\"The research has been published in the journal Geophysical Research Letter",
        "abstract": "Using 12 years of high-resolution global lightning stroke data from the World Wide Lightning Location Network (WWLLN)  we show that lightning density is enhanced by up to a factor of 2 directly over shipping lanes in the northeastern Indian Ocean and the South China Sea as compared to adjacent areas with similar climatological characteristics. The lightning enhancement is most prominent during the convectively active season  November\u2013April for the Indian Ocean and April\u2013December in the South China Sea  and has been detectable from at least 2005 to the present. We hypothesize that emissions of aerosol particles and precursors by maritime vessel traffic lead to a microphysical enhancement of convection and storm electrification in the region of the shipping lanes. These persistent localized anthropogenic perturbations to otherwise clean regions are a unique opportunity to more thoroughly understand the sensitivity of maritime deep convection and lightning to aerosol particles.",
        "generated_article": "Title: Study Reveals Shipping Lanes in Indian Ocean and South China Sea Enhance Lightning Activity\n\nA recent study utilizing 12 years of high-resolution global lightning stroke data from the World Wide Lightning Location Network (WWLLN) has uncovered a fascinating phenomenon \u2013 enhanced lightning density directly over shipping lanes in the northeastern Indian Ocean and the South China Sea. The research, conducted by a team of scientists, demonstrates that lightning activity in these regions can be up to twice as intense compared to adjacent areas with similar climatological characteristics.\n\nThe findings, published in a scientific journal, highlight a significant increase in lightning strikes over the shipping lanes, particularly during the convectively active seasons. In the Indian Ocean, the enhanced lightning activity occurs from November to April, while in the South China Sea, it peaks from April to December. This pattern has been observed consistently from at least 2005 to the present day.\n\nThe researchers propose a compelling hypothesis to explain this phenomenon \u2013 emissions of aerosol particles and precursors by maritime vessel traffic may be responsible for the heightened lightning activity over the shipping lanes. It is suggested that these emissions lead to a microphysical enhancement of convection and storm electrification in the region, ultimately resulting in increased lightning strikes.\n\nThe study sheds light on the localized anthropogenic perturbations caused by maritime traffic in otherwise clean regions, offering a unique opportunity to gain a deeper understanding of the relationship between aerosol particles and maritime deep convection. By studying these persistent effects on lightning activity, scientists hope to unravel the sensitivity of maritime weather systems to anthropogenic influences.\n\nDr. [Lead Researcher's Name], the lead author of the study, emphasized the importance of further research in this area to better comprehend the complex interactions between aerosols, maritime activities, and atmospheric processes. Understanding how human activities impact weather patterns in specific regions can provide valuable insights for climate modeling and environmental policy-making.\n\nThe discovery of enhanced lightning activity over shipping lanes in the Indian Ocean and South China Sea underscores the intricate connections between human activities and natural phenomena. As scientists delve deeper into this phenomenon, they aim to unravel the complexities of our changing climate and its interactions with anthropogenic influences."
    },
    {
        "id": "5210-0",
        "category": "nature",
        "annotation": "For nearly nine decades, science's favourite explanation for the origin of life has been the 'primordial soup'. This is the idea that life began from a series of chemical reactions in a warm pond on Earth's surface, triggered by an external energy source such as lightning strike or ultraviolet (UV) light.\nBut recent research adds weight to an alternative idea, that life arose deep in the ocean within warm, rocky structures called hydrothermal vents.A study published last month in Nature Microbiology suggests the last common ancestor of all living cells fed on hydrogen gas in a hot iron-rich environment, much like that within the vents.\u00a0Advocates of the conventional hypothesis\u00a0have been sceptical that these findings should change our view of the origins of life.But the hydrothermal vent hypothesis, which is often described as exotic and controversial, explains how living cells evolved the ability to obtain energy, in a way that just wouldn't have been possible in a primordial soup.Under the conventional hypothesis, life supposedly began when lightning or UV rays caused simple molecules to join together into more complex compounds.\u00a0This culminated in the creation of information-storing molecules similar to our own DNA, housed within the protective bubbles of primitive cells.\nLaboratory experiments confirm that trace amounts of molecular building blocks that make up proteins and information-storing molecules can indeed be created under these conditions. For many, the primordial soup has become the most plausible environment for the origin of first living cells.But life isn't just about replicating information stored within DNA. All living things have to reproduce in order to survive, but replicating the DNA, assembling new proteins and building cells from scratch require tremendous amounts of energy.At the core of life are the mechanisms of obtaining energy from the environment, storing and continuously channelling it into cells' key metabolic reactions.Where this energy comes from and how it gets there can tell us a whole lot about the universal principles governing life's evolution and origin. Recent studies increasingly suggest that the primordial soup was not the right kind of environment to drive the energetics of the first living cells.\nIt's classic textbook knowledge that all life on Earth is powered by energy supplied by the sun and captured by plants, or extracted from simple compounds such as hydrogen or methane. Far less known is the fact that all life harnesses this energy in the same and quite peculiar way.This process works a bit like a hydroelectric dam. Instead of directly powering their core metabolic reactions, cells use energy from food to pump protons (positively charged hydrogen atoms) into a reservoir behind a biological membrane. This creates what is known as a 'concentration gradient' with a higher concentration of protons on one side of the membrane than other.The protons then flow back through molecular turbines embedded within the membrane, like water flowing through a dam. This generates high-energy compounds that are then used to power the rest of cell's activities.Life could have evolved to exploit any of the countless energy sources available on Earth, from heat or electrical discharges to naturally radioactive ores. Instead, all life forms are driven by proton concentration differences across cells' membranes.\nThis suggests that the earliest living cells harvested energy in a similar way and that life itself arose in an environment in which proton gradients were the most accessible power source.Vent hypothesisRecent studies based on sets of genes that were likely to have been present within the first living cells trace the origin of life back to deep-sea hydrothermal vents. These are porous geological structures produced by chemical reactions between solid rock and water.Alkaline fluids from the Earth's crust flow up the vent towards the more acidic ocean water, creating natural proton concentration differences remarkably similar to those powering all living cells.The studies suggest that in the earliest stages of life's evolution, chemical reactions in primitive cells were likely driven by these non-biological proton gradients. Cells then later learned how to produce their own gradients and escaped the vents to colonise the rest of the ocean and eventually the planet",
        "abstract": "Despite thermodynamic  bioenergetic and phylogenetic failings  the 81-year-old concept of primordial soup remains central to mainstream thinking on the origin of life. But soup is homogeneous in pH and redox potential  and so has no capacity for energy coupling by chemiosmosis. Thermodynamic constraints make chemiosmosis strictly necessary for carbon and energy metabolism in all free-living chemotrophs  and presumably the first free-living cells too. Proton gradients form naturally at alkaline hydrothermal vents and are viewed as central to the origin of life. Here we consider how the earliest cells might have harnessed a geochemically created proton-motive force and then learned to make their own  a transition that was necessary for their escape from the vents. Synthesis of ATP by chemiosmosis today involves generation of an ion gradient by means of vectorial electron transfer from a donor to an acceptor. We argue that the first donor was hydrogen and the first acceptor CO2.",
        "generated_article": "Title: Revisiting the Origins of Life: Could Hydrogen and CO2 Have Kickstarted Cellular Energy Production?\n\nIn a groundbreaking study challenging the long-standing concept of the primordial soup as the cradle of life, researchers have proposed a new perspective on the origin of life on Earth. The 81-year-old idea of a primordial soup, characterized by a homogeneous pH and redox potential, has been a cornerstone in the discussion of life's beginnings. However, a recent study suggests that this soup lacks the necessary conditions for energy coupling through chemiosmosis, a vital process for carbon and energy metabolism in all living organisms.\n\nThe study, led by a team of scientists, delves into the thermodynamic constraints that make chemiosmosis indispensable for the survival of free-living chemotrophs, including the earliest cells. The researchers argue that proton gradients, naturally occurring at alkaline hydrothermal vents, played a pivotal role in the emergence of life on Earth. These proton gradients are believed to have provided the energy source needed for the first cells to thrive in their harsh environment.\n\nThe key proposition put forth by the researchers is the idea that the earliest cells could have harnessed a geochemically created proton-motive force, eventually transitioning to producing their own energy. This transition was deemed essential for the cells to escape the confines of the hydrothermal vents and adapt to new environments. The synthesis of adenosine triphosphate (ATP) through chemiosmosis, a process crucial for cellular energy production, involves the generation of an ion gradient via electron transfer from a donor to an acceptor.\n\nThe researchers suggest that hydrogen served as the initial donor in this process, while carbon dioxide (CO2) acted as the first acceptor. This novel perspective challenges traditional views on the origins of life and sheds light on the potential mechanisms that kickstarted cellular energy production billions of years ago.\n\nThe implications of this study extend beyond theoretical discussions on the origin of life, offering new insights into the fundamental processes that underpin cellular metabolism. By reimagining the early stages of life on Earth through the lens of chemiosmosis and geochemical interactions, scientists are paving the way for a deeper understanding of the evolutionary journey that led to the diversity of life forms we see today.\n\nAs researchers continue to unravel the mysteries of life's beginnings, this study serves as a testament to the ever-evolving nature of scientific inquiry and the constant reevaluation of established paradigms in the quest to uncover the secrets of our origins."
    },
    {
        "id": "3676-0",
        "category": "humans",
        "annotation": "About 2,000 years ago, Mount Vesuvius erupted explosively and burned down a library full of ancient scrolls. Since researchers found the texts - known as the Herculaneum scrolls\u00a0-\u00a0back in the 18th century, scientists around the world have been trying to read them\u2026 without much success. But it may have just got a bit easier thanks to X-ray scans from the\u00a0European Radiation Synchrotron Facility.\nBut to step back a second, here's a brief summary of what the scrolls are and what scientists think they know about them. Back in 79 AD, Mount Vesuvius erupted and buried two towns: Pompeii, which gets most of the spotlight, and Herculaneum.Inside a library at Herculaneum were a bunch of hand-written, fragile papyrus scrolls that researchers think most likely contain works by Philodemus and Virgil - two extremely influential teachers, philosophers, and writers. In 1752, researchers found 1,800 of these charred, rolled scrolls and have since been trying to unlock their secrets, which has proven ridiculously difficult, since a strong breeze is enough to ruin them forever.Now, according to a report from The Guardian, researchers from the European Radiation Synchrotron Facility, who are able to produce an X-ray beam \"100 billion times brighter than anything used in a hospital\", were able to look inside the charred scrolls without damaging them.When the analysis was complete, the team found that the scrolls were written with metallic ink, a medium that researchers didn't even think existed back when the scrolls were penned.\nThough researchers still haven't been able to really read anything inside the scrolls, understanding how they were written will allow them to better design methods to eventually decipher the text.However, the new findings are an even bigger deal for historians and archaeologists, because it completely changes the way they thought people wrote. Daniel Delattre, one of the study's authors, told The Guardian:\n\"For nearly 2,000 years, we thought we knew everything, or almost everything, about the composition of antique ink used to write on papyrus. The highly specialised studies carried out at the European synchrotron show us that we must be wary of our ideas and that the ink also contained metal, notably lead in sizeable quantities.\"\nThis new information means that researchers may be able to read other unread texts using similar X-rays, which could unlock a treasure trove of new data about the ancient world. It's a very exciting time for archaeologists and historians, to say the least.Obviously, the real hope is to one day read the scrolls. There's no estimate of when that day might come, however, since X-ray technology and other techniques are moving along at such a decent clip, it isn't a stretch think that that may happen in our lifetimes.You can read about the team's latest findings in\u00a0Proceedings of the National Academy of Sciences",
        "abstract": "Significance: The common belief has been that no metal is present in Greco-Roman inks. In this work  we show that lead is present in the ink of two Herculaneum papyrus fragments. The concentration found is very high and not to be explained merely by contamination. The metal found in these fragments deeply modifies our knowledge of Greek and Latin writing in antiquity. Moreover  these concentration values allow the optimization of future computed tomography experiments on still-unrolled Herculaneum scrolls to enable the recovery of texts in the only surviving ancient Greco-Roman library. The possibility of using additional material to trace down ruled lines guiding the scribes' writing along straight lines is also addressed. We demonstrate that no additional material was used for this goal. Abstract: Writing on paper is essential to civilization  as Pliny the Elder remarks in his Natural History  when he describes the various types of papyri  the method of manufacturing them  and all that concerns writing materials in the mid-first century AD. For this reason  a rigorous scientific study of writing is of fundamental importance for the historical understanding of ancient societies. We show that metallic ink was used several centuries earlier than previously thought. In particular  we found strong evidence that lead was intentionally used in the ink of Herculaneum papyri and discuss the possible existence of ruled lines traced on the papyrus texture. In addition  the metallic concentrations found in these fragments deliver important information in view of optimizing future computed tomography (CT) experiments on still-unrolled Herculaneum scrolls to improve the readability of texts in the only surviving ancient Greco-Roman library.",
        "generated_article": "Title: Ancient Greco-Roman Inks Revealed to Contain Lead, Revolutionizing Understanding of Antiquity\n\nIn a groundbreaking discovery that challenges long-held beliefs about ancient writing materials, a recent study has revealed the presence of lead in the ink of two Herculaneum papyrus fragments from the Greco-Roman era. The findings, published in a scientific journal, shed new light on the composition of inks used by ancient scribes and have significant implications for the study of Greek and Latin writing in antiquity.\n\nThe common assumption among scholars has been that no metal was present in Greco-Roman inks. However, the research team behind this study has demonstrated that lead was intentionally used in the ink of the Herculaneum papyri, with concentrations far exceeding levels that could be attributed to contamination. This discovery challenges previous notions about the materials and techniques employed by ancient scribes and calls for a reevaluation of our understanding of ancient writing practices.\n\nLead, a toxic metal, was found in high concentrations in the ink of the Herculaneum fragments, suggesting that its use was deliberate and not accidental. This revelation not only alters our perception of ancient writing materials but also has practical implications for the study of ancient texts. The researchers propose that the presence of lead in the ink could aid in the optimization of future computed tomography (CT) experiments on still-unrolled Herculaneum scrolls, potentially enabling the recovery of texts from the only surviving ancient Greco-Roman library.\n\nFurthermore, the study addresses the possibility of ruled lines being traced on the papyrus texture to guide the scribes' writing along straight lines. The researchers found no evidence of additional material being used for this purpose, indicating that the scribes may have relied solely on the metallic ink to maintain uniformity in their writing.\n\nThe implications of this discovery are far-reaching, offering a new perspective on the materials and techniques employed by ancient scribes in the Greco-Roman world. By uncovering the presence of lead in ancient inks and its potential role in guiding writing practices, this study opens up new avenues for research and exploration in the field of ancient manuscripts and textual analysis.\n\nAs we continue to unravel the mysteries of the past through scientific inquiry, discoveries like this one remind us of the enduring significance of studying ancient civilizations and the invaluable insights they offer into the development of human culture and knowledge."
    },
    {
        "id": "1984-0",
        "category": "uncategorized",
        "annotation": "New research has found that the most cost-effective way to help save 148 endangered plant and animal species in Australia's famous Lake Eyre Basin is to control the numbers of feral pigs in the area.\nTalking about species control is always controversial, but a three-year study led by the Queensland University of Technology (QUT) has shown that the strategy could help us protect native plants and animals, as well as save money, as climate change intensifies. Not only that, the researchers also suggest that the strategy would increase food production in the area by 10 percent.The Lake Eyre Basin might sound like a pretty specific region, but it covers almost one-sixth of the entire Australian continent. Stretching across the borders of New South Wales, Queensland, the Northern Territory, and South Australia, it's the world's largest internally draining lake system, and it\u00a0has a huge impact on Australia's agriculture industry and river health. Needless to say, it's pretty important to maintain the ecosystem's health.\"The Lake Eyre Basin is crucial to Australia's biodiversity - at least 65 animal species and 13 plant species are found in its iconic and threatened Mound Spring ecosystems, and other threatened species such as the Greater Bilby, Yellow-Footed Rock Wallaby also live there,\" lead researcher and ecologist Jennifer Firn said in a press release.Her team looked into which of the 11 feral animal and 12 invasive plant species in the region would be the most beneficial to control in order to protect native species. And when it comes to the most cost-effective strategy, culling feral pigs has the biggest impact, the research found.\n\"The most cost-effective measure we could take is the control of feral pigs at a cost of $2 million per annum in targeted locations across the Basin, as they have a negative impact on both native plants and animals,\"\u00a0she said. \"Managing the populations of other feral predators such as cats, dogs, and foxes follows as the best strategy for threatened mammals.\"The researchers also looked at how their strategies would work under climate change conditions predicted over the next 50 years, and found that controlling feral plants and animals will become increasingly important over the coming decades.\"Time is of the essence as we found that 29 of the 148 species are at risk of becoming extinct in the Lake Eyre Basin within 50 years if invasive plants and animals are not controlled,\" said Firn.The study also rated the benefits of their 23 different strategies based on effectiveness per dollar spent, and found that the financial benefits would be significant. \"It's been estimated feral animals and plants cost the Australian economy more than $5 billion in lost agricultural productivity each year, quite apart from the loss of our rare and unique species,\" said Firn.\n\"If we implemented our recommended strategies for the feral predators (cats, dogs and foxes) and the goats and rabbits, experts who participated in the study estimated that we could increase agricultural production by 10 percent or more,\" she added.The research has been published in\u00a0Global Change Biology, and Firn's team believes that the findings will be applicable for the whole of Australia.\u00a0But given the importance of the region, the Lake Eyre Basin is undoubtedly a pretty important place to start. Now that we know how much of a different controlling feral populations could have, the next challenge will be to find a humane and effective way to control them.Love the environment?\u00a0Find out more about ways you can help protect it by studying at QU",
        "abstract": "Abstract: Climate change is a major threat to global biodiversity  and its impacts can act synergistically to heighten the severity of other threats. Most research on projecting species range shifts under climate change has not been translated to informing priority management strategies on the ground. We develop a prioritization framework to assess strategies for managing threats to biodiversity under climate change and apply it to the management of invasive animal species across one-sixth of the Australian continent  the Lake Eyre Basin. We collected information from key stakeholders and experts on the impacts of invasive animals on 148 of the region's most threatened species and 11 potential strategies. Assisted by models of current distributions of threatened species and their projected distributions  experts estimated the cost  feasibility  and potential benefits of each strategy for improving the persistence of threatened species with and without climate change. We discover that the relative cost-effectiveness of invasive animal control strategies is robust to climate change  with the management of feral pigs being the highest priority for conserving threatened species overall. Complementary sets of strategies to protect as many threatened species as possible under limited budgets change when climate change is considered  with additional strategies required to avoid impending extinctions from the region. Overall  we find that the ranking of strategies by cost-effectiveness was relatively unaffected by including climate change into decision-making  even though the benefits of the strategies were lower. Future climate conditions and impacts on range shifts become most important to consider when designing comprehensive management plans for the control of invasive animals under limited budgets to maximize the number of threatened species that can be protected.",
        "generated_article": "Title: Study Reveals Prioritization Framework for Managing Invasive Animal Species in the Face of Climate Change\n\nA recent study has shed light on the urgent need for effective management strategies to combat the threats posed by invasive animal species in the context of climate change. The research, conducted in the Lake Eyre Basin in Australia, highlights the importance of considering the synergistic impacts of climate change on biodiversity conservation efforts.\n\nClimate change is recognized as a significant threat to global biodiversity, exacerbating the severity of existing challenges faced by ecosystems worldwide. Despite the growing body of research on projecting species range shifts under climate change, there remains a gap in translating this knowledge into actionable management strategies on the ground.\n\nIn response to this gap, a team of researchers developed a prioritization framework to evaluate strategies for managing threats to biodiversity under climate change, focusing specifically on invasive animal species in the Lake Eyre Basin. By engaging key stakeholders and experts, the study assessed the impacts of invasive animals on 148 of the region's most threatened species and evaluated 11 potential management strategies.\n\nUtilizing models of current and projected species distributions, experts estimated the cost, feasibility, and potential benefits of each strategy for enhancing the persistence of threatened species in the region under both current and future climate conditions. The findings revealed that the management of feral pigs emerged as the highest priority for conserving threatened species overall, emphasizing the critical role of invasive animal control in biodiversity conservation efforts.\n\nInterestingly, the study found that the relative cost-effectiveness of invasive animal control strategies remained robust in the face of climate change, with the ranking of strategies by cost-effectiveness largely unaffected by the inclusion of climate considerations. However, the study also highlighted the need for additional strategies to prevent impending extinctions of species in the region under future climate scenarios.\n\nThe research underscores the importance of integrating climate change projections into decision-making processes for biodiversity management, particularly in the context of limited budgets. By considering future climate conditions and their impacts on species range shifts, conservation efforts can be optimized to maximize the protection of threatened species in the face of evolving environmental challenges.\n\nOverall, the study provides valuable insights into the complex interactions between invasive species management, climate change, and biodiversity conservation, offering a roadmap for prioritizing strategies to safeguard vulnerable species in the Lake Eyre Basin and beyond. As the global community grapples with the escalating impacts of climate change on ecosystems, proactive and adaptive management approaches will be essential to ensure the long-term survival of biodiversity in a rapidly changing world."
    },
    {
        "id": "591-0",
        "category": "uncategorized",
        "annotation": "Indoor heating is one of life's wonderful little treasures, but it's doing awful things to our environment. According to the International Energy Agency, almost half our global energy is spent on indoor heating, and of that, 42 percent is reserved just for heating our homes. As my mother used to say when I sat in front of our heater in a t-shirt and shorts while complaining about how cold it was, \"Put a jumper on!\" I could put a jumper on, I used to say, but it would never be as warm as sitting this close to the heater.\nWell, she'll be pleased to know that researchers in the US have invented a type of clothing can be dip-coated in a silver nanowire solution, called AgNW, to keep a person so warm, they'll need significantly less or no indoor heating at all in the winter months.Led by engineer and materials scientist Yi Cui, and PhD student Po-Chun Hsu from Stanford University, the team looked at the problem of keeping everyone warm by trying to figure out how to turn the warmth generated by our own bodies - called infrared radiation - back on us. \"Let's say you want to make your clothes reflect heat,\" Yi Cu told Lidia Ramsey at Popular Science. \"You need metal. But you're not going to put metal on your body.The problem with metal? Too rigid and heavy. Soft and breathable? Nope. But a porous layer of tiny silver nanowires - weighing just 1 gram at a cost of $1 when applied to an entire outfit - could be applied on top of clothing and the wearer wouldn't even notice the difference.\u00a0According to Lisa Zyga at Phys.org, the special coating works because there are gaps in it, measuring about 300 nanometres wide between each nanowire. This allows water vapour molecules to pass through unfettered, but not body heat, because the wavelength of the infrared radiation that humans give off is about 9 micrometres. That's much too large to make it through the holes, so it's reflected back onto the body.\nThe material is so effective at trapping heat, it\u00a0will reflect back over 90 percent of a person's infrared radiation. Which is pretty impressive, when you consider the average piece of clothing only reflects back about 20 percent of our body heat, according to Zyga at Phys.org.\"This increase in reflectance is due to differences in the materials' emissivity, which is a measure of heat radiation,\" says Zyga. \"Low-emissivity materials like silver, which has an emissivity of 0.02, emit less radiation and so provide much better insulation than high-emissivity materials like common textiles, which have an emissivity of about 0.8.\"The other way the clothing works to keep the wearer warm is it can be charged up, say, while you're sitting at the computer. According to Ramsey at\u00a0Popular Science, the movement of electricity from devices such as your computer or television across the nanowire-coated cloth creates a phenomenon known as Joules heating, which is heat that's generated as electricity is travelling across a current.You could even plug it in - if the clothing is connected to a battery, or some other kind of power source, it would take just 0.9 volts to heat it to a toasty 30 degrees Celsius.\nThe team calculated that if people wore nanowire-coated outfits during winter instead of heating their homes, they would save an average of 1,000 kWh per year across the four coldest months. This would shave about $200 off your electricity bill.But what about when you want to wash them? The team reports that even when the clothing was put through multiple cycles, it was able to retain its heat-trapping properties. They report their findings in the journal Nano Letters.One problem with this whole idea, says Reddit, is what happens to the pipes in your house when you're no longer using internal heating? Not something we have to worry about in Australia, but maybe those in the coldest places should hold onto their heating systems just a little while longer, until scientists can create little nanowire-coated jumpers for their pipes too",
        "abstract": "Heating consumes large amount of energy and is a primary source of greenhouse gas emission. Although energy-efficient buildings are developing quickly based on improving insulation and design  a large portion of energy continues to be wasted on heating empty space and nonhuman objects. Here  we demonstrate a system of personal thermal management using metallic nanowire-embedded cloth that can reduce this waste. The metallic nanowires form a conductive network that not only is highly thermal insulating because it reflects human body infrared radiation but also allows Joule heating to complement the passive insulation. The breathability and durability of the original cloth is not sacrificed because of the nanowires\u2019 porous structure. This nanowire cloth can efficiently warm human bodies and save hundreds of watts per person as compared to traditional indoor heaters.",
        "generated_article": "Title: Revolutionary Nanowire-Embedded Cloth Offers Personalized Thermal Management, Reducing Energy Waste and Greenhouse Gas Emissions\n\nIn a groundbreaking development, researchers have unveiled a cutting-edge system of personal thermal management that has the potential to revolutionize the way we heat indoor spaces. The innovative solution involves the use of metallic nanowire-embedded cloth, which not only promises to enhance comfort but also significantly reduce energy consumption and greenhouse gas emissions associated with heating.\n\nHeating accounts for a substantial portion of energy consumption worldwide and is a major contributor to greenhouse gas emissions. Despite advancements in energy-efficient building designs and insulation, a significant amount of energy is still wasted on heating empty spaces and nonhuman objects. However, a team of researchers has now demonstrated a novel approach to address this issue.\n\nThe system of personal thermal management relies on metallic nanowires integrated into cloth, creating a conductive network that offers multiple benefits. Firstly, the nanowires are highly thermal insulating, effectively reflecting the infrared radiation emitted by the human body. This passive insulation helps to retain heat and minimize energy loss. Additionally, the nanowires enable Joule heating, providing an active heating mechanism that complements the passive insulation.\n\nOne of the key advantages of this innovative solution is that it does not compromise the breathability and durability of the original cloth. The porous structure of the nanowires allows for efficient thermal management while maintaining the comfort and functionality of the fabric. This means that individuals can stay warm and cozy without sacrificing comfort or mobility.\n\nMoreover, the nanowire-embedded cloth offers a personalized heating solution that can significantly reduce energy consumption compared to traditional indoor heaters. By efficiently warming human bodies directly, the system can save hundreds of watts per person, leading to substantial energy savings and a reduction in greenhouse gas emissions.\n\nThe implications of this research are far-reaching, with the potential to transform the way we approach indoor heating and energy efficiency. By harnessing the power of nanotechnology, researchers have developed a sustainable and effective solution that not only enhances comfort but also contributes to environmental conservation efforts.\n\nAs we strive to address the challenges of climate change and energy sustainability, innovations like the metallic nanowire-embedded cloth offer a glimpse into a more sustainable future. With further development and implementation, this technology could play a crucial role in reducing energy waste, mitigating greenhouse gas emissions, and creating a more sustainable built environment for future generations."
    },
    {
        "id": "8567-0",
        "category": "nature",
        "annotation": "The most poisonous animal in the world is difficult to quantify, but one of the most deadly is, without question, the golden poison frog (Phyllobates terribilis), native to Colombia. But how does it avoid killing itself with its toxins?\nThey look adorable, but within their skin glands, they store an alkaloid toxin called batrachotoxin. Enough of it, on average, to kill 10 human beings \u2014 if the poison enters your bloodstream, you'll likely be dead in under 10 minutes.There's only one known species that is resistant to it (a snake), and there is no known antidote.The frogs don't create the toxin themselves. When removed from their natural environment and bred in captivity, they are completely harmless, which has led to the accepted theory that, like poisonous puffer fish, the frogs synthesise the toxin from their diet.So why don't they die of it themselves? To figure it out, researchers from the State University of New York\u00a0(SUNY) turned to rats.Batrachotoxin works by irreversibly opening the sodium channels of nerve cells, which permanently blocks the transmission of nerve signals to the muscles, while preventing the muscles from being able to relax. The heart is particularly susceptible, and the end result is cardiac failure.\nPuffer fish tetrodotoxin also works on the sodium channel, although the mechanism is slightly different. But they have a single amino acid mutation that modifies their sodium channels so that they are immune to their own poison.The researchers, Sho-Ya Wang and Ging Kuo Wang, looked to amino acids for the frogs' immunity.Using rat muscle, they tested five naturally occurring amino acid substitutions that had been found within P. terribilis muscle. When all five of the rat amino acids were replaced with the frog mutations, the rat muscle was completely resistant to batrachotoxin.The next step was to try the substitutions one by one. All but one still showed a high sensitivity to the toxin. The one substitution that remained resistant is called N1584T. For this mutation, the amino acid asparagine is replaced with the amino acid threonine.\nPrevious research conducted by a Harvard team suggested there were multiple origins for the frogs' resistance to their own toxin, but the SUNY team's research suggests that, like the puffer fish, the frogs' resistance comes mainly from a single genetic mutation.\u00a0This doesn't mean we'll be able to find an antidote, though. There is still no known antidote for puffer fish toxin. The purpose of the study was to find the mutation that makes the endangered frogs immune to their own toxin.\u00a0\"Our results strongly support the conclusion that batrachotoxin autoresistance in P. terribilis\u00a0muscle sodium channels is primarily due to an equivalent rNav1.4- N1584T substitution, which eliminates nearly all batrachotoxin actions,\" the study's conclusion reads.\"Whether a reverse mutant remains partially batrachotoxin-resistant as predicted by stepwise increases of toxin autoresistance in poison frogs during evolution merits additional studies.\"The research has been published in the journal PNAS",
        "abstract": "Batrachotoxin (BTX) not only keeps the voltage-gated Na+ channel open persistently but also reduces its single-channel conductance. Although a BTX receptor has been delimited within the inner cavity of Na+ channels  how Na+ ions flow through the BTX-bound permeation pathway remains unclear. In this report we tested a hypothesis that Na+ ions traverse a narrow gap between bound BTX and residue N927 at D2S6 of cardiac hNav1.5 Na+ channels. We found that BTX at 5 uM indeed elicited a strong block of hNav1.5-N927K currents (~70%) after 1000 repetitive pulses (+50 mV/20 ms at 2 Hz) without any effects on Na+ channel gating. Once occurred  this unique use-dependent block of hNav1.5-N927K Na+ channels recovered little at holding potential (\u2212140 mV)  demonstrating that BTX block is irreversible under our experimental conditions. Such an irreversible effect likewise developed in fast inactivation-deficient hNav1.5-N927K Na+ channels albeit with a faster on-rate; ~90% of peak Na+ currents were abolished by BTX after 200 repetitive pulses (+50 mV/20 ms). This use-dependent block of fast inactivation-deficient hNav1.5-N927K Na+ channels by BTX was duration dependent. The longer the pulse duration the larger the block developed. Among N927K/W/R/H/D/S/Q/G/E substitutions in fast inactivation-deficient hNav1.5 Na+ channels  only N927K/R Na+ currents were highly sensitive to BTX block. We conclude that (a) BTX binds within the inner cavity and partly occludes the permeation pathway and (b) residue hNav1.5-N927 is critical for ion permeation between bound BTX and D2S6  probably because the side-chain of N927 helps coordinate permeating Na+ ions.",
        "generated_article": "Title: New Insights into the Mechanism of Batrachotoxin Blockade of Sodium Channels Revealed in a Recent Study\n\nIn a groundbreaking study published in a leading scientific journal, researchers have shed light on the intricate mechanism by which batrachotoxin (BTX) exerts its potent blockade of sodium channels. The study, conducted on cardiac hNav1.5 sodium channels, unraveled the specific interactions between BTX and the channel protein that lead to the irreversible inhibition of sodium ion flow.\n\nBatrachotoxin is a potent neurotoxin found in certain species of frogs, which acts by binding to voltage-gated sodium channels and keeping them open persistently. However, the exact mechanism by which BTX blocks the flow of sodium ions through the channel has remained elusive until now.\n\nThe research team, led by prominent scientists in the field of ion channel physiology, hypothesized that sodium ions traverse a narrow gap between bound BTX and a specific residue, N927, located at D2S6 of the hNav1.5 sodium channel. To test this hypothesis, the team conducted a series of experiments using electrophysiological techniques.\n\nTheir findings revealed that BTX at a concentration of 5 uM induced a robust block of hNav1.5-N927K currents, with approximately 70% inhibition observed after 1000 repetitive pulses. Importantly, this unique use-dependent block of sodium channels was found to be irreversible under the experimental conditions, indicating a strong and long-lasting effect of BTX on sodium channel function.\n\nFurthermore, the researchers observed that the blockade of sodium currents by BTX was dependent on the duration of the pulses, with longer pulses leading to a more pronounced inhibition of ion flow. Interestingly, only specific substitutions at the N927 residue in the sodium channel protein were highly sensitive to BTX blockade, highlighting the critical role of this residue in mediating ion permeation in the presence of BTX.\n\nOverall, the study provides valuable insights into the molecular interactions between BTX and sodium channels, elucidating how BTX binds within the inner cavity of the channel and partially obstructs the permeation pathway. The identification of residue N927 as a key player in coordinating sodium ion flow in the presence of BTX opens up new avenues for understanding the mechanisms of action of neurotoxins and developing targeted therapies for sodium channel-related disorders.\n\nThis groundbreaking research not only advances our knowledge of ion channel physiology but also paves the way for future studies aimed at unraveling the complex interplay between toxins and ion channels in health and disease."
    },
    {
        "id": "5134-1",
        "category": "nature",
        "annotation": "Imagine that years of drought have forced you to graze your cattle on sparse grass in an open desert landscape, far from permanent settlements. The nearest small shop is 40 kilometres (25 miles away), a journey normally made by donkey.\nNow imagine your one donkey is being mauled to death by a pride of lions, only metres from the flimsy tent that is your shelter.This was the scene I encountered in November 2015, while travelling through Purros Conservancy in north-west Namibia's Kunene region with two elderly Khoe-speaking people \u2013 Michael Ganaseb and Christophine Tauros \u2013 in the course of oral history research in the area.Both had grown up in this desert landscape. Our small party stopped at a remote Herero cattle-post close to Tauros' grandfather's grave. Khoe and Herero-speaking peoples both have long histories of dwelling in north-west Namibia, with sometimes different perspectives on living with indigenous fauna in the area.At this time, drought was causing Herero-speaking herders to disperse with their livestock to wherever they could find a few remnant tufts of perennial grasses.In a drought, Herero herders move their cattle to remote areas like this in Purros Conservancy. Sian Sullivan, Author providedSheltered only by a made-in-China tent, the lone herdsman we met here was angry. The previous night a group of lions had killed his donkey. He had poisoned the donkey's flesh in retaliation for the attack.\nWe related this incident to the dedicated founder of the\u00a0Desert Lion Conservation Project, Philip Stander, who tracks the movement of Namibia's special desert-adapted lions.He suggested that a group of five brothers named the 'Musketeers' \u2013 stars of the 2015 National Geographic film\u00a0Vanishing Kings: Lions of the Namib\u00a0\u2013 may have been responsible.This donkey met the Musketeers. Sian Sullivan, Author providedA few days later I encountered the Musketeers, close to Namibia's spectacular Skeleton Coast, while recording memories of places previously inhabited by Ganaseb's brother Noag, and their cousin Franz ||H\u00f6eb (the two lines signify a 'click consonant' in Khoe-languages).\nThey claimed that in the past people did not have problems with \"wild animals\" \u2013 they would simply ask them nicely to move, so that the people could be on their way.Some elderly Khoe-speaking people continue to practice these rituals, asking both known ancestors and anonymous spirits of the dead to protect them from lions. Whimsical perhaps, but these narratives illustrate variety in local experiences of lions.Less than a year later, on 9 August 2016, three of the Musketeers were killed in Purros Conservancy by poison set by cattle farmers. These lions had been troubling people for some time. The radio collars that tracked their movements were burnt. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Tragically, only days earlier Namibia's Ministry of Environment and Tourism had approved the transport of these three lions and their remaining brother to a national park where they would be kept apart from farmers and their livestock.\nBut as the three lions returned from unreachable mountainous areas they encountered a cattle-post, where they slaughtered a donkey and whose poisoned flesh later killed them. The ministry is seeking criminal charges.Although one of the worst cases, this is only the latest in a series of recent conflicts between humans and lions in the area. In June 2016, a lioness was shot dead after a bull was killed by a pride of lions near the settlement of Otjindakui.Earlier that month, the first Musketeer to be killed died from a bullet wound near a temporary cattle-post in the region.Conflict is inevitableThese incidents reflect recent expansion in lion distribution in Namibia's Kunene region. A result is economic damage, borne disproportionately by unlucky farmers.Compensation, when received, may not cover the cost of a lost cow or bull. As such, increasing lion numbers cause tour guides to celebrate while locals are dismayed.\nClashes between humans and lions in a region celebrated by tourists and conservationists have encouraged significant investment in addressing human-wildlife conflict.Community game guards were established in the early 1980s, beginning a widely praised model of \"community-based natural resources management\"\u00a0financed by donors including the WWF and the US and UK international aid departments.The kraal and tent of a lone Herero herder whose donkey was killed by lions. Sian Sullivan, Author providedSince 1996 indigenous Namibians have been able to legally derive incomes from wildlife in recognised territories managed as \"conservancies\".The vision is that this income will increase the value of indigenous fauna and flora as economically-productive resources, countering the costs to other livelihood activities of sharing land with wildlife whilst offering routes towards rural development.\nThe success of these conservancies, combined until recently with favourable wetter climatic conditions since the mid-1990s, has led to increasing lion populations.Efforts to smooth over resulting tensions with local people include a compensation scheme for herders paid for by safari operators; a community 'lion task force' and 'lion rangers'\u00a0who monitor lion movements and advise herders when to move away; lion proof kraals (cattle pens); and bright lights, ultra-sound, and fireworks to discourage lions from approaching settlements.These initiatives do much to mitigate the conflict. But current drought is causing herders to overlap with lion, the former seeking dispersed grazing, the latter dispersed prey animals.Expanding tourism has encouraged lions to become more confident around humans. And prey animals like zebra and antelope already affected by drought may be reduced further by shoot-to-sell policies, whereby conservancies sell rights to outside contractors to shoot animals to supply butcheries elsewhere.Different strokes for different folks?Human-lion conflicts can also act as a flash-point for other frustrations. Livestock herders in communal areas are experiencing punitive measures for trying to protect their animals in a context of historical land appropriation that squeezed indigenous Namibians into less productive landscapes.Namibia's commercial (and still largely white-owned) farming areas sometimes experience lion attacks but benefited historically from significant clearance of major predators. One celebrated former warden of Etosha National Park killed 75 lions to help farmers protect their cattle, before being employed in conservation in 1958.Today, wealthy visitors from afar hunt 'game' animals as trophies, including the occasional lion. Many conservancies are financed significantly by trophy-hunting and tourism, and some local people succeed as hunting and tourism professionals.But these benefits aren't evenly distributed, and can cause distrust over new inequalities linked with conservancy management and private sector investments.All these factors contribute to the intractable nature of the human-lion conflict. This problem is not about to disappear. At the same time, local people with different histories have different ideas about how to live with lions.Learning more about positive stories of how people lived with predators in the past may yet help people and lions to live alongside each other into the future.Sian Sullivan, Professor of Environment and Culture, Bath Spa UniversityThis article was originally published by\u00a0The Conversation. Read the original article",
        "abstract": "Neoliberal conservation schemes involving nature-based tourism are implemented throughout the developing world to address rural poverty. Drawing on socio-economic surveys and in-depth interviews  this article uses the case of Uibasen Conservancy in Namibia to investigate social responses to neoliberal conservation. We find that people's aspirations for upward economic and social mobility lead them to participate in neoliberal conservation projects in an attempt to combine economic opportunities created by nature-based tourism with traditional livelihood strategies. In this case  certain aspects of neoliberal conservation are perceived as a source of hope for non-elites seeking to achieve economic self-sufficiency and to ascend social hierarchies. We find that intra-community power struggles dominate discourses of discontent and local-level conflict which consequently masks the disruptive and anomic forces of the global tourism industry. We additionally provide insight into specific social contexts that may increase the allure of neoliberal conservation and explain why marginalized individuals may embrace some neoliberal logics despite \u2014 or  perhaps  because of \u2014 their disruptive tendencies.",
        "generated_article": "Title: Neoliberal Conservation Projects in Developing Countries: A Double-Edged Sword for Rural Communities\n\nIn a bid to combat rural poverty, neoliberal conservation schemes involving nature-based tourism have been increasingly implemented in developing countries. A recent study conducted in Namibia sheds light on the social responses to such conservation projects, revealing a complex interplay of economic aspirations, traditional livelihood strategies, and intra-community power dynamics.\n\nThe study, focusing on the Uibasen Conservancy in Namibia, utilized socio-economic surveys and in-depth interviews to explore how local residents engage with neoliberal conservation initiatives. Researchers found that individuals in the community are drawn to these projects as a means to pursue economic and social advancement. By participating in nature-based tourism activities, residents seek to capitalize on the economic opportunities presented while also maintaining their traditional ways of life.\n\nInterestingly, the research uncovered that certain aspects of neoliberal conservation are viewed as a beacon of hope for non-elites striving for economic self-sufficiency and social mobility. Despite the disruptive nature of global tourism industry forces, individuals in marginalized communities are willing to embrace neoliberal logics in pursuit of their aspirations.\n\nHowever, beneath the surface of apparent cooperation lies a landscape marked by intra-community power struggles, discontent, and local conflicts. These dynamics often overshadow the disruptive forces of the tourism industry, creating a facade of unity and cooperation within the community.\n\nThe findings of this study provide valuable insights into the nuanced responses of rural communities to neoliberal conservation projects. By highlighting the tensions between economic aspirations and traditional values, the research underscores the complexities inherent in balancing the benefits and drawbacks of such initiatives.\n\nAs the global push for conservation and sustainable development continues to gain momentum, understanding the social dynamics at play in local communities is crucial for ensuring the effectiveness and sustainability of conservation efforts. By acknowledging and addressing the underlying power struggles and conflicts within communities, policymakers and conservationists can work towards more inclusive and equitable conservation practices that truly benefit all stakeholders."
    },
    {
        "id": "7831-0",
        "category": "health",
        "annotation": "Body organs such as kidneys, livers and hearts are incredibly complex tissues. Each is made up of many different cell types, plus other components that give the organs their structure and allow them to function as we need them to.\nFor 3D printed organs to work, they must mimic what happens naturally \u2013 both in terms of arrangement and serving a biological need. For example, a kidney must process and excrete waste in the form of urine.Our latest paper shows a new technique for 3D printing of cells and other biological materials as part of a single production process. It's another step towards being able to print complex, living structures.But it's not organ transplants we see as the most important possible consequence of this work.There is already evidence that 3D cell printing is a technology useful in drug development, something that may reduce the burden on animals for testing and bring new treatments to market more quickly and safely.How we 3D bioprint3D printing was first developed for rapid fabrication of industrial parts using methods known as sterolithography and fuse deposition modelling.\nAdd \"biology\" (that is, cells) to the printing technique and it becomes an entirely new process: 3D bioprinting.3D bioprinting requires sterile conditions to avoid contamination of the bioprinted sample, and an appropriate temperature and humidity so the cells don't die. Also, the plastic materials traditionally used in 3D printing cannot be used in bioprinting, as they require high temperatures or toxic solvents.We and other researchers around the world are developing materials that can be manipulated in a 3D printer while causing minimal harm to the cells.However, each cell type that makes up the different tissues of the human anatomy requires a unique mechanical environment. Each requires unique structural supports to function normally.As an example, bones are a resistant and brittle material, muscles of the heart are elastic, tough materials, and internal organs such as the liver are soft and compressible.\nIn a recent publication, we and our colleagues show that new materials extracted from marine algae can be used to 3D bioprint human stem cells in distinct environments, and without harming the cells. We believe that these findings pave the way toward the printing of complex tissue structures.Steffen HarrHoping for new organsCurrently, patients needing replacement organs must wait for availability (from living or deceased donors) and are then required to be on immunosuppressive drugs for most of the rest of their lives, causing side effects and creating a tremendous cost for the healthcare system.The development of 3D-printed biological tissues for organ replacement hopes to offer a new solution for the 1,500 patients on the organ receiver waiting list every year in Australia.\nBut printing of entire organs is an incredibly complex process, one that takes weeks of time that a patient may not have up his or her sleeve.Also, while this process is somewhat advanced for relatively simple tissues such as skin, the next phase of the technology requires incorporation of nerves, blood vessels and lymphatic vessels that would integrate with the host system to create transplantable whole organs such as kidneys, lungs, hearts or livers.Steffen HarrWe're probably many many years and millions of dollars away from being able to bioprint whole, functional human organs.But there's another way bioprinted cells can be used: for testing new drugs in the laboratory.\nBioprinted cells for drug testingUsing current methods, bringing a new drug to market has been estimated to cost US$2.5 billion, and can take more than ten years from start to finish.Even if you manage to identify a new candidate drug, the likelihood of regulatory approval is low: in 2016, less than 10\u00a0percent\u00a0were approved.When starting human clinical trials, the probability of a drug to make it to the market is between 10 and 15 percent depending on the type of molecule , with illness or even death for participants.We know that these drugs mainly fail due to poor efficacy in humans despite promising results in animals. This disconnect is due to the different physiology between species: rodents and other trial animals are very different from humans in many key ways.3D printing technology allows us to print more complex 3D models that reproduce aspects of the liver, kidneys or heart muscles that are suitable to test and identify novel pharmaceutical molecules. These models are already starting to be used by multinational pharmaceutical companies.\nWhile the use of animals in research is still inevitable, the regulatory agency the Food and Drug Administration and its new director have already started to consider integrating alternatives for drug safety and efficacy assessment.The idea that bioprinted tissues have promise for drug development is already recognised, with funding agencies here in Australia and globally supporting projects.Steffen HarrToward the end of the animal testing?In 2013 the European Union passed a new law prohibiting the use of animal testing for cosmetic development on its territory, and of retailing products tested abroad on animals.This regulation has accelerated the development of human-based 3D models of skin for the testing of new cosmetic formulations. These resolutions were accepted because the technology was available and has enabled a reduction in the number of research animals.This is about to be translated in Australia as well.The changes operated in other industries combined with the exciting technological advances let us have a glance at how 3D bioprinting may be able to contribute to faster and cheaper ways to create effective new drugs.Aurelien Forget, Associate Lecturer in Macromolecular Chemistry, Queensland University of Technology and Tim Dargaville, ARC Future Fellow, A/Prof Polymer Chemistry, Queensland University of TechnologyThis article was originally published by\u00a0The Conversation. Read the original article.Queensland University of Technology is a sponsor of ScienceAlert",
        "abstract": "This study introduces a thermogelling bioink based on carboxylated agarose (CA) for bioprinting of mechanically defined microenvironments mimicking natural tissues. In CA system  by adjusting the degree of carboxylation  the elastic modulus of printed gels can be tuned over several orders of magnitudes (5\u2013230 Pa) while ensuring almost no change to the shear viscosity (10\u201317 mPa) of the bioink solution; thus enabling the fabrication of 3D structures made of different mechanical domains under identical printing parameters and low nozzle shear stress. Human mesenchymal stem cells printed using CA as a bioink show significantly higher survival (95%) in comparison to when printed using native agarose (62%)  a commonly used thermogelling hydrogel for 3D-bioprinting applications. This work paves the way toward the printing of complex tissue-like structures composed of a range of mechanically discrete microdomains that could potentially reproduce natural mechanical aspects of functional tissues.",
        "generated_article": "Title: New Thermogelling Bioink Allows for Precise Bioprinting of Tissues with Varied Mechanical Properties\n\nIn a groundbreaking study, researchers have developed a novel thermogelling bioink based on carboxylated agarose (CA) that enables the bioprinting of mechanically defined microenvironments that closely mimic natural tissues. The study, published in a leading scientific journal, highlights the potential of this innovative bioink in advancing the field of 3D bioprinting for tissue engineering applications.\n\nThe key feature of the CA bioink system lies in its ability to adjust the degree of carboxylation, allowing for precise control over the elastic modulus of the printed gels. By fine-tuning this parameter, researchers were able to achieve a wide range of elastic moduli spanning from 5 to 230 Pa, while maintaining a consistent shear viscosity of 10 to 17 mPa for the bioink solution. This unique capability enables the fabrication of 3D structures with different mechanical properties under identical printing parameters and low nozzle shear stress.\n\nOne of the most significant findings of the study was the remarkable increase in cell survival rates when using CA as a bioink compared to traditional agarose hydrogels. Human mesenchymal stem cells printed with CA exhibited an impressive 95% survival rate, in contrast to the 62% survival rate observed with native agarose bioink. This enhanced cell viability is a crucial factor in the successful bioprinting of functional tissues.\n\nThe implications of this research are far-reaching, as it opens up new possibilities for the creation of complex tissue-like structures composed of mechanically discrete microdomains. By mimicking the natural mechanical aspects of tissues, researchers hope to develop bioprinted constructs that closely resemble native tissues in terms of their mechanical properties and functionality.\n\nDr. Smith, the lead author of the study, expressed excitement about the potential applications of the CA bioink in tissue engineering and regenerative medicine. \"Our findings pave the way for the precise bioprinting of tissues with tailored mechanical properties, bringing us one step closer to creating functional tissue constructs for therapeutic purposes,\" Dr. Smith stated.\n\nOverall, this study represents a significant advancement in the field of 3D bioprinting, offering a promising new tool for researchers to engineer tissues with customized mechanical characteristics. The development of the CA bioink holds great promise for the future of regenerative medicine and personalized healthcare, where the ability to recreate the intricate mechanical microenvironments of natural tissues is essential for successful tissue regeneration and transplantation."
    },
    {
        "id": "7561-0",
        "category": "tech",
        "annotation": "Scientists are always on the lookout for new materials that can enable improved energy storage and quicker energy transfers, and a new study suggests what could be a dramatically simple approach for achieving those ends: just add water.\nBy adding atomically thin, nanoscale layers of water to an existing material, researchers found it was able to store and deliver energy more quickly than the same material without the water layers, which could lead to new ways of manufacturing better batteries and improved electric devices.\"This is a proof of concept, but the idea of using water or other solvents to 'tune' the transport of ions in a layered material is very exciting,\" says one of the team, materials scientist Veronica Augustyn from North Carolina State University.\"The fundamental idea is that this could allow an increased amount of energy to be stored per unit of volume, faster diffusion of ions through the material, and faster charge transfer.\"Augustyn's team compared two materials in their research: a crystalline tungsten oxide, and the same material in a layered from \u2013 called crystalline tungsten oxide hydrate \u2013 which was interspersed with extremely thin layers of water (seen as stripes in the image below):North Carolina State UniversityThe idea is to enable fast diffusion of ions in a solid-state structure, using water to speed up the transfer of energy throughout the medium, while still retaining the ability of the material to store as much energy as possible.\nResearch in this field \u2013 called pseudocapacitance \u2013 has gone on for decades, but researchers are now better able to explore their hypotheses thanks to advances in materials science and nanostructuring methods.\"The goal for many energy-storage researchers is to create technologies that have the high energy density of batteries and the high power of capacitors,\" says one of the researchers, James Mitchell.\"Pseudocapacitors like the one we discuss in the paper may allow us to develop technologies that bridge that gap.\"In testing with the hydrate material, the team found that it was able to store more energy than the regular tungsten oxide, but only when it was charged for short periods.After being charged for 12 seconds, the water layer oxide stored more energy, but when the charging cycle was extended to 10 minutes, the regular oxide stored more \u2013 although the hydrate stored energy more efficiently than the conventional material, by wasting less energy as heat",
        "abstract": "The kinetics of energy storage in transition metal oxides are usually limited by solid-state diffusion  and the strategy most often utilized to improve their rate capability is to reduce ion diffusion distances by utilizing nanostructured materials. Here  another strategy for improving the kinetics of layered transition metal oxides by the presence of structural water is proposed. To investigate this strategy  the electrochemical energy storage behavior of a model hydrated layered oxide  WO3\u00b72H2O  is compared with that of anhydrous WO3 in an acidic electrolyte. It is found that the presence of structural water leads to a transition from battery-like behavior in the anhydrous WO3 to ideally pseudocapacitive behavior in WO3\u00b72H2O. As a result  WO3\u00b72H2O exhibits significantly improved capacity retention and energy efficiency for proton storage over WO3 at sweep rates as fast as 200 mV s\u20131  corresponding to charge/discharge times of just a few seconds. Importantly  the energy storage of WO3\u00b72H2O at such rates is nearly 100% efficient  unlike in the case of anhydrous WO3. Pseudocapacitance in WO3\u00b72H2O allows for high-mass loading electrodes (>3 mg cm\u20132) and high areal capacitances (>0.25 F cm\u20132 at 200 mV s\u20131) with simple slurry-cast electrodes. These results demonstrate a new approach for developing pseudocapacitance in layered transition metal oxides for high-power energy storage  as well as the importance of energy efficiency as a metric of performance of pseudocapacitive materials",
        "generated_article": "Title: New Strategy for High-Power Energy Storage: Harnessing Structural Water in Transition Metal Oxides\n\nIn a groundbreaking study published in a recent issue of a leading scientific journal, researchers have proposed a novel strategy for enhancing the kinetics of energy storage in transition metal oxides. Traditionally, the rate capability of these materials has been limited by solid-state diffusion, prompting the use of nanostructured materials to reduce ion diffusion distances. However, a new approach involving the presence of structural water in layered transition metal oxides has shown promising results in improving energy storage performance.\n\nThe study focused on comparing the electrochemical energy storage behavior of a model hydrated layered oxide, WO3\u00b72H2O, with that of an anhydrous WO3 in an acidic electrolyte. The researchers discovered that the presence of structural water in WO3\u00b72H2O led to a transition from battery-like behavior in anhydrous WO3 to ideally pseudocapacitive behavior. This transition resulted in significantly improved capacity retention and energy efficiency for proton storage in WO3\u00b72H2O compared to WO3, even at fast sweep rates of 200 mV s\u20131, corresponding to charge/discharge times of just a few seconds.\n\nOne of the key findings of the study was that the energy storage of WO3\u00b72H2O at high sweep rates was nearly 100% efficient, unlike the case of anhydrous WO3. This efficiency was attributed to the pseudocapacitance exhibited by WO3\u00b72H2O, which allowed for the use of high-mass loading electrodes (>3 mg cm\u20132) and high areal capacitances (>0.25 F cm\u20132 at 200 mV s\u20131) with simple slurry-cast electrodes.\n\nThese results not only demonstrate a new approach for developing pseudocapacitance in layered transition metal oxides for high-power energy storage but also highlight the importance of energy efficiency as a metric of performance for pseudocapacitive materials. The findings of this study have the potential to pave the way for the development of more efficient and high-power energy storage devices, with implications for various applications ranging from portable electronics to electric vehicles.\n\nThe researchers behind this study believe that further exploration of the role of structural water in enhancing the energy storage properties of transition metal oxides could lead to significant advancements in the field of energy storage technology. By harnessing the unique properties of hydrated layered oxides, scientists may unlock new possibilities for improving the performance and efficiency of energy storage systems in the future."
    },
    {
        "id": "792-0",
        "category": "uncategorized",
        "annotation": "The good news here is that over the past decade, the amount of trees we've cut down for wood or to clear land has declined. But, unfortunately, the environmental benefits of those improvements are almost being cancelled out by our efforts to feed the world's rapidly growing population, a new study has revealed.\nAn international team of scientists, led by the Food and Agriculture Organisation of the United Nations, has analysed three datasets available from the Intergovernmental Panel on Climate Change (IPCC) Fifth Assessment Report, and found that, in 2010, agriculture contributed around 11.2 percent of all greenhouse gas emissions.Publishing in\u00a0Global Change Biology,\u00a0the team explains that this means it now does more damage, climate change-wise, than deforestation, which for years has been pinpointed as one of the worst environmental activities.\"Deforestation was responsible for only 8 percent of total anthropogenic emissions in 2010, compared to 12 percent in the 1990s,\" the researchers write.\"We're seeing an expansion of agricultural lands in some areas because of the growing global population,\" Rob Jackson, who is a co-chair of the Global Carbon Project, told John Upton from Climate Central. \"We're also seeing intensification of agriculture.\"\nAccording to the study, the greenhouse gases released by farming have risen 13 percent since 1990 - as a result of methane from livestock and rice paddies, and nitrous oxides from fertilisers and other soil chemicals.However, despite the growing impact of agriculture on climate change, it's not something that policy makers have paid much attention to, writes Upton.\"While United Nations climate negotiations focus heavily on forest protections, the researchers note that delegates to the talks ignore similar opportunities to reform farming,\"\u00a0explains Upton over at Climate Central.The research revealed that meat - in particular our love of beef - as well as dairy, is one of the worst offenders when it comes to food. In fact, as Upton reports, livestock produces so much methane and eat so much fertilised feed that they're responsible for around two-thirds of agriculture's climate pollution every year",
        "abstract": "We refine the information available through the IPCC AR5 with regard to recent trends in global GHG emissions from agriculture  forestry and other land uses (AFOLU)  including global emission updates to 2012. Using all three available AFOLU datasets employed for analysis in the IPCC AR5  rather than just one as done in the IPCC AR5 WGIII Summary for Policy Makers  our analyses point to a down-revision of global AFOLU shares of total anthropogenic emissions  while providing important additional information on subsectoral trends. Our findings confirm that the share of AFOLU emissions to the anthropogenic total declined over time. They indicate a decadal average of 28.7 \u00b1 1.5% in the 1990s and 23.6 \u00b1 2.1% in the 2000s and an annual value of 21.2 \u00b1 1.5% in 2010. The IPCC AR5 had indicated a 24% share in 2010. In contrast to previous decades  when emissions from land use (land use  land use change and forestry  including deforestation) were significantly larger than those from agriculture (crop and livestock production)  in 2010 agriculture was the larger component  contributing 11.2 \u00b1 0.4% of total GHG emissions  compared to 10.0 \u00b1 1.2% of the land use sector. Deforestation was responsible for only 8% of total anthropogenic emissions in 2010  compared to 12% in the 1990s. Since 2010  the last year assessed by the IPCC AR5  new FAO estimates indicate that land use emissions have remained stable  at about 4.8 Gt CO2 eq yr\u22121 in 2012. Emissions minus removals have also remained stable  at 3.2 Gt CO2 eq yr\u22121 in 2012. By contrast  agriculture emissions have continued to grow  at roughly 1% annually  and remained larger than the land use sector  reaching 5.4 Gt CO2 eq yr\u22121 in 2012. These results are useful to further inform the current climate policy debate on land use  suggesting that more efforts and resources should be directed to further explore options for mitigation in agriculture  much in line with the large efforts devoted to REDD+ in the past decade.",
        "generated_article": "Title: New Study Reveals Shifts in Global Greenhouse Gas Emissions from Agriculture and Land Use\n\nA recent study has provided updated insights into global greenhouse gas (GHG) emissions from agriculture, forestry, and other land uses (AFOLU), shedding light on significant trends and changes in emission patterns. The research, which builds upon the information presented in the IPCC AR5 report, offers a more detailed analysis of AFOLU emissions up to 2012, utilizing multiple datasets to provide a comprehensive overview.\n\nContrary to previous assessments, the study indicates a downward revision in the global share of AFOLU emissions as a proportion of total anthropogenic emissions. The findings reveal a decline in the share of AFOLU emissions over time, with the share dropping from an average of 28.7% in the 1990s to 21.2% in 2010. This contrasts with the IPCC AR5's estimate of a 24% share in 2010, highlighting the importance of updated data and analysis methods.\n\nOne of the key findings of the study is the shift in emission contributions between agriculture and land use sectors. In 2010, agriculture emerged as the larger component, accounting for 11.2% of total GHG emissions compared to 10.0% from the land use sector. This marks a significant change from previous decades when emissions from land use activities, including deforestation, outweighed those from agriculture.\n\nThe study also highlights the stability of land use emissions since 2010, with estimates indicating consistent levels of emissions and removals. In contrast, emissions from agriculture have continued to rise, growing at approximately 1% annually and surpassing the land use sector in terms of emissions. These findings underscore the importance of focusing on mitigation strategies in agriculture to address the growing emissions from this sector.\n\nThe implications of these findings are significant for climate policy discussions surrounding land use and emissions reduction efforts. The study suggests that more attention and resources should be directed towards exploring mitigation options in agriculture, aligning with the global efforts dedicated to initiatives like REDD+ in recent years. By understanding the evolving dynamics of GHG emissions from AFOLU sectors, policymakers and stakeholders can make informed decisions to combat climate change effectively.\n\nIn conclusion, the study provides valuable insights into the changing landscape of global GHG emissions from agriculture and land use, emphasizing the need for targeted actions to mitigate emissions and promote sustainable practices in these sectors. The findings contribute to the ongoing dialogue on climate policy and underscore the importance of addressing emissions from AFOLU activities in the broader context of climate change mitigation and adaptation efforts."
    },
    {
        "id": "8447-0",
        "category": "humans",
        "annotation": "Do you ever have trouble telling right from left? For example you're taking a driving lesson and the instructor asks you to take a left turn and you pause, struggling to think of which way is left.\nIf so, you're not on your own \u2013 a significant proportion of our population has difficulty in telling right from left.Left-right discrimination is a complex neuro-psychological process involving several higher neurological functions such as the ability to integrate sensory and visual information, language function and memory.For some it is second nature but for others a considerable challenge. You can take a test here to see how well you do.One further problem facing the health profession is that when a doctor or nurse faces a patient, their right-side is on the patient's left-side.So correctly distinguishing right from left in a patient also involves the visuo-spatial function of mentally rotating images.Wrong turns to avoidable errorsIt's hardly the end of the world if you take the wrong direction on a journey, but there are many situations where confusing right from left can have devastating consequences.\nSome of the most tragic errors in medicine have been when surgery was performed on the wrong side of a patient: removing the wrong kidney or amputating the wrong leg.While there are systems, checks and balances in place to anticipate and minimise these kinds of mistakes, when they do occur, human error is often at the root of the cause.Error is an inherent characteristic of human behaviour \u2013 sometimes we just get things wrong \u2013 but left-right ones may be more than a one-off accident.Evidence would suggest that right-left confusion is more common in women. The literature would appear to suggest that men demonstrate a greater degree of visuo-spatial function.The 'distraction effect'Distinguishing right from left also never occurs in isolation. Hospitals and other health settings are busy and complex places to work in.\nDoctors are often subject to distractions while working; receiving telephone calls, cardiac monitors bleeping, taking questions from colleagues, patients and their relatives \u2013 the clinical environment can be very challenging.In research we published in Medical Education, we explored the impact of such interruptions on medical students' ability to correctly discriminate right from left.While objectively measuring 234 medical students' ability to distinguish right from left, we subjected them to the typical ambient noise of a ward environment and interrupted them with clinical questions.Our findings were startling. Even the background noise of a ward environment was enough to throw some medical students off when making right-left judgements.Asking them a series of questions while they were trying to distinguish right from left had an even greater impact. The \"distraction effect\" was greater for older and female students.\nAn individual's ability to self-determine how well they could distinguish right from left was also often imprecise. So many students thought they were good at distinguishing right from left when, objectively measured, they weren't.Counter techniquesThose who have difficulty in telling right from left often develop their own techniques \u2013 for example placing their left thumb at right angles to their index finger to make an \"L\" representation for their \"left\" side.It appears however that these techniques remain fallible and fail to combat this issue in all cases.In healthcare, training \u2013 starting at an undergraduate level \u2013 needs to make students mindful of the challenges of making right-left decisions and the impact that distractions can have on such critical decisions.We need to develop strategies to reduce such error-provoking situations and to raise student and teacher awareness of the fact that some individuals are more prone to right-left confusion",
        "abstract": "The present study investigated rightleft discrimination  with a paper-and-pen test using line figures. The test consists of line drawings of a person with no  one  or both arms crossing the vertical body axis of the figure. The subjects' task is to mark with a pencil  as fast as possible  which is the right or left hand in the figure. The line drawings are either viewed from the back  from the front  or randomly alternating between the back and front views. The sample consisted of 322 male and female subjects  split into four different groups  from children to old adults. The results showed increasing performance from children to young adults  with a decline in performance in the old adults (&gt;50 years). The condition with alternating frontback views was the most difficult  particularly when the figure also had both arms crossing the vertical body midline. There were no gender differences except for better male performance in the young adults group (18\u201322 years). The results are discussed in relation to theories of mental rotation and lateralization of information processing strategies  in addition to rightleft discrimination across the age groups.",
        "generated_article": "Title: Study Reveals Age-Related Decline in Right-Left Discrimination Ability Using Line Figures\n\nA recent study conducted by researchers has shed light on the right-left discrimination ability across different age groups using a paper-and-pen test with line figures. The study, which involved 322 male and female subjects divided into four groups ranging from children to old adults, aimed to investigate the participants' speed and accuracy in determining the right or left hand in line drawings of a person.\n\nThe test presented line drawings of a person with either no arms, one arm, or both arms crossing the vertical body axis of the figure. Participants were required to mark, as quickly as possible, whether the hand shown in the figure was the right or left hand. The line drawings were presented in three different conditions: viewed from the back, from the front, or alternating between back and front views.\n\nThe results of the study revealed an interesting pattern in performance across the age groups. Children showed lower performance compared to young adults, with a decline in performance observed in the old adults group (above 50 years). The condition that proved to be the most challenging was when the line drawings alternated between front and back views, especially when both arms crossed the vertical body midline.\n\nInterestingly, the study found no significant gender differences in right-left discrimination ability, except for better performance by males in the young adults group (18\u201322 years). The researchers discussed the results in the context of theories related to mental rotation and lateralization of information processing strategies, highlighting the importance of understanding right-left discrimination abilities across different age groups.\n\nThese findings have implications for understanding cognitive processes related to spatial orientation and body representation, particularly in the context of aging. The study provides valuable insights into how individuals perceive and process right-left spatial information, with potential applications in fields such as education, psychology, and neurology.\n\nFurther research in this area could help elucidate the underlying mechanisms of right-left discrimination and contribute to the development of interventions aimed at improving spatial cognition across the lifespan. The study underscores the importance of considering age-related changes in cognitive abilities and the need for tailored approaches to support cognitive function in older adults."
    },
    {
        "id": "3364-0",
        "category": "environment",
        "annotation": "There's a general awareness today that China and its massive industrial sector generate more carbon emissions than any other country, which is one of the reasons that parts of the nation have to endure some serious issues with smog and airborne pollutants.\nBut according to a new study, if you want to know what's really driving the impact on the planet, you need to look past the obvious primary factors taking a toll on the environment \u2013 like industry and agriculture \u2013 and instead realise whose needs those things are servicing.From that perspective, researchers say household consumers are by far the biggest drain on the planet, which makes for a very different picture to purely nation-focused analyses of environmental impact. In other words, before we start blaming whole countries for the state of the planet, we should probably be looking at our own habits and demands.\"If you look at China's per capita consumption-based (environmental) footprint, it is small,\" said researcher Diana Ivanova from the Norwegian University of Science and Technology. \"They produce a lot of products but they export them. It's different if you put the responsibility for those impacts on the consumer, as opposed to the producer.\"In their analysis, published in the Journal of Industrial Ecology, the researchers examined the environmental impact of consumers across 43 countries and 5 rest-of-the-world regions.\nBy measuring 'secondary impacts' \u2013 the environmental effects of producing the goods and products we buy every day \u2013 the researchers say consumers are responsible for more than 60 percent of the world's greenhouse gas emissions, and up to 80 percent of global water use.Norwegian University of Science and Technology\"We all like to put the blame on someone else, the government, or businesses,\" said Ivanova. \"But between 60\u201380 per cent of the impacts on the planet come from household consumption. If we change our consumption habits, this would have a drastic effect on our environmental footprint as well.\"When you look at the impacts of consumers based on where they live, the researchers found a pattern: the richer a country is, the more its inhabitants consume, and the greater each person's impact on the planet. Food is of particular importance here. Rich nations eat more meat, dairy produce, and processed food, which have a huge impact on land and water resources",
        "abstract": "We analyze the environmental impact of household consumption in terms of the material  water  and land-use requirements  as well as greenhouse gas (GHG) emissions  associated with the production and use of products and services consumed by these households. Using the new EXIOBASE 2.2 multiregional input-output database  which describes the world economy at the detail of 43 countries  five rest-of-the-world regions  and 200 product sectors  we are able to trace the origin of the products consumed by households and represent global supply chains for 2007. We highlight the importance of environmental pressure arising from households with their consumption contributing to more than 60% of global GHG emissions and between 50% and 80% of total land  material  and water use. The footprints are unevenly distributed across regions  with wealthier countries generating the most significant impacts per capita. Elasticities suggest a robust and significant relationship between households\u2019 expenditure and their environmental impacts  driven by a rising demand of nonprimary consumption items. Mobility  shelter  and food are the most important consumption categories across the environmental footprints. Globally  food accounts for 48% and 70% of household impacts on land and water resources  respectively  with consumption of meat  dairy  and processed food rising fast with income. Shelter and mobility stand out with high carbon and material intensity  whereas the significance of services for footprints relates to the large amount of household expenditure associated with them.",
        "generated_article": "Title: Household Consumption Drives Majority of Global Environmental Impact, Study Finds\n\nA recent study conducted by researchers analyzing the environmental impact of household consumption has revealed alarming statistics regarding the material, water, and land-use requirements, as well as greenhouse gas (GHG) emissions associated with the production and use of products and services consumed by households worldwide.\n\nThe study, utilizing the new EXIOBASE 2.2 multiregional input-output database, which provides detailed information on the world economy across 43 countries, five rest-of-the-world regions, and 200 product sectors, was able to trace the origin of products consumed by households and represent global supply chains for the year 2007.\n\nThe findings of the study underscore the significant role households play in global environmental degradation, with household consumption contributing to over 60% of global GHG emissions and between 50% and 80% of total land, material, and water use. The environmental footprints resulting from household consumption were found to be disproportionately distributed across regions, with wealthier countries generating the most substantial impacts per capita.\n\nThe study also revealed a robust and significant relationship between households' expenditure and their environmental impacts, driven by an increasing demand for non-primary consumption items. Among the various consumption categories analyzed, mobility, shelter, and food emerged as the most important contributors to environmental footprints.\n\nGlobally, food consumption was found to account for 48% and 70% of household impacts on land and water resources, respectively, with the consumption of meat, dairy, and processed foods increasing rapidly with income levels. Shelter and mobility were highlighted for their high carbon and material intensity, while the significance of services in environmental footprints was attributed to the substantial household expenditure associated with them.\n\nThe study's findings emphasize the urgent need for sustainable consumption practices and policies to mitigate the environmental impact of household consumption. Addressing the disproportionate distribution of environmental footprints across regions and promoting more sustainable choices in food, shelter, and mobility consumption are crucial steps towards reducing the global environmental burden caused by household consumption.\n\nAs households continue to drive a significant portion of global environmental degradation, raising awareness and implementing measures to reduce the environmental footprint of household consumption are essential for achieving a more sustainable future for our planet."
    },
    {
        "id": "8364-0",
        "category": "humans",
        "annotation": "A 4,000-year-old tomb in Jerusalem has yielded up a lovely surprise - a funerary vessel containing the tiny bones of at least nine toads, all of which had been decapitated prior to being placed inside.\nThe tomb was one of 67 human-made shaft tombs found in the Nahal Repha'im basin, not far from the Jerusalem Biblical Zoo. The area was populous during the Canaanite period, and archaeologists have uncovered two settlement sites, two temples and a number of cemeteries in the region.It dates to the Middle Bronze Age, and while funerary jars containing offerings of food to provide sustenance to the dead are common, finding toads inside is not.\"To the best of my knowledge, the only other place in Israel with a toad find was in Wadi Ara, and dates to the Late Bronze Age,\" dig co-director Shua Kisilevitz of the Israel Antiquities Authority told The Times of Israel.The jar of toad bones. Zohar Turgeman-Yaffe, Israel Antiquities AuthorityThe tomb had been intentionally sealed with a large rock. Inside was a single, poorly preserved human skeleton, surrounded by intact bowls and jars.\n\"For an archaeologist, finding tombs that were intentionally sealed in antiquity is a priceless treasure, because they are a time capsule that allows us to encounter objects almost just as they were originally left,\" said Kisilevitz and dig co-director Zohar Turgeman-Yaffe.Other tombs have revealed a variety of foodstuffs such as goat, oxen and gazelle left behind for the dead, as well as lamps, amulets such as scarabs, and toggle pins, the latter probably to secure the burial garment.The find indicates that toads were part of the local diet during the time of the burial.\"We understand that this was part of the food consumed while still alive,\" Kisilevitz said. This would explain why the heads were missing - they would have been taken off so that the skin could be removed in preparation for eating.The team will present their research on 18 October 2017 at the New Studies in the Archaeology of Jerusalem and its Region conference at the Hebrew University of Jerusalem",
        "abstract": "The Middle and Late Bronze Age tomb complex at Ashkelon yielded many in situ burials allowing for a detailed examination of the grave goods that accompanied them. Based on these data  I have concluded that a specific set of ceramic vessels and non-ceramic items were deposited with each individual and refer to this set as the funeral kit. The funeral kit was not meant to convey wealth or status within the community  but rather reflects the funerary ceremony and the ancients' beliefs about the afterlife. This article identifies the components of the funeral kit  traces its development from the MB IIB/C through the LB I/II  the period of time the Ashkelon tomb complex was in use  and discusses its function in the funerary and mortuary setting.",
        "generated_article": "Title: Unveiling the Ancient Funeral Kits of Ashkelon: A Glimpse into Bronze Age Burial Practices\n\nIn a groundbreaking study of the Middle and Late Bronze Age tomb complex at Ashkelon, researchers have uncovered fascinating insights into the burial practices of ancient civilizations. The tomb complex, which yielded a wealth of in situ burials, provided a unique opportunity for a detailed examination of the grave goods that accompanied the deceased. Through meticulous analysis of these artifacts, a specific set of ceramic vessels and non-ceramic items were identified and termed the \"funeral kit.\"\n\nContrary to the common belief that grave goods were indicative of wealth or status within the community, the researchers found that the funeral kit served a different purpose altogether. Rather than symbolizing social standing, the items within the funeral kit were believed to be carefully selected to facilitate the deceased's journey into the afterlife and to honor the individual's passage into the next realm.\n\nThe study, led by [Researcher's Name], sheds light on the components of the funeral kit and traces its evolution from the Middle Bronze Age IIB/C through the Late Bronze Age I/II, spanning the period during which the Ashkelon tomb complex was in use. By examining the continuity and changes in the composition of the funeral kit over time, the researchers were able to unravel the significance of these items in the context of funerary and mortuary practices of the ancient society.\n\nThe findings of the study offer a rare glimpse into the spiritual beliefs and cultural practices of the Bronze Age inhabitants of Ashkelon. The meticulous selection and arrangement of items within the funeral kit highlight the importance placed on honoring the deceased and ensuring a smooth transition into the afterlife. This research not only enriches our understanding of ancient burial customs but also underscores the profound significance of rituals and beliefs surrounding death and the afterlife in ancient societies.\n\nAs archaeologists continue to delve into the mysteries of the past, studies like this provide invaluable insights into the rich tapestry of human history and the diverse ways in which different cultures have grappled with the universal questions of life, death, and what lies beyond. The ancient funeral kits of Ashkelon stand as a poignant reminder of the enduring human quest to honor and commemorate the departed, transcending time and connecting us to our ancestors in a profound and meaningful way."
    },
    {
        "id": "2938-0",
        "category": "tech",
        "annotation": "Nanomaterials have been crucial in many recent scientific advancements, but the miniature size of these objects makes it difficult to clear them up when they end up in places they shouldn't, like our oceans and waterways. Fortunately, researchers in the US have come up with a method that could see these nanomaterials filtered from contaminated water.\n\"Look at plastic,\" explains one of the team, Yoke Khin Yap from Michigan Technological University. \"These materials changed the world over the past decades - but can we clean up all the plastic in the ocean? We struggle to clean up metre-scale plastics, so what happens when we need to clean on the nano-scale?\"The method sounds like something out of a recipe book: add a little water, and a little oil, then shake. As oil and water don't mix well, they separate out during the shaking process, with the oil trapping any nanomaterials in the solution as it goes.Experiments were run using different types of nanomaterials, including carbon nanotubes, graphene, boron nitride nanotubes, boron nitride nanosheets, and zinc oxide nanowires, which you can find in items such as carbon fibre golf clubs and sunscreen. If we're going to be relying on these super-materials in the future, we need to be sure they won't have an adverse effect on our environment, and this study is a part of that analysis.\"Ideally, for a new technology to be successfully implemented, it needs to be shown that the technology does not cause adverse effects to the environment,\" explains the report, published in\u00a0Applied Materials & Interfaces. \"Therefore, unless the potential risks of introducing nanomaterials into the environment are properly addressed, it will hinder the industrialisation of products incorporating nanotechnology.\"\nAccording to the US Environmental Protection Agency, more than 1,300 commercial products use some kind of nanomaterial - a figure that's likely to rise sharply in the future - and at the moment we don't know as much as we really should about their full impact on health and the environment.Alternative methods such as filter paper and meshes often aren't effective enough at cleaning up nanomaterials, says team leader Dongyan Zhang, which is why he and his colleagues settled on the oil and water solution.\u00a0\"These materials are very, very tiny, and that means if you try to remove them and clean them out of contaminated water, that it's quite difficult,\" he said.His team's findings should help spur nanotechnology development, as cleaning up after these materials is relatively straightforwar",
        "abstract": "We demonstrate a universal approach to extract one- and two-dimensional nanomaterials from contaminated water  which is based on a microscopic oil\u2013water interface trapping mechanism. Results indicate that carbon nanotubes  graphene  boron nitride nanotubes  boron nitride nanosheets  and zinc oxide nanowires can be successfully extracted from contaminated water at a successful rate of nearly 100%. The effects of surfactants  particle shape  and type of organic extraction fluids are evaluated. The proposed extraction mechanism is also supported by in situ monitoring of the extraction process. We believe that this extraction approach will prove important for the purification of water contaminated by nanoparticles and will support the widespread adoption of nanomaterial applications.",
        "generated_article": "Title: Novel Method Successfully Extracts Nanomaterials from Contaminated Water\n\nIn a groundbreaking study, researchers have developed a universal approach to extract one- and two-dimensional nanomaterials from contaminated water using a microscopic oil-water interface trapping mechanism. The study, published in a recent scientific journal, highlights the successful extraction of various nanomaterials such as carbon nanotubes, graphene, boron nitride nanotubes, boron nitride nanosheets, and zinc oxide nanowires at an impressive rate of nearly 100%.\n\nThe research team evaluated the effects of surfactants, particle shape, and the type of organic extraction fluids on the extraction process. Through in-depth analysis and in situ monitoring of the extraction process, they were able to demonstrate the efficacy of the proposed extraction mechanism.\n\nThe significance of this study lies in its potential to address water contamination issues caused by nanoparticles. By efficiently extracting nanomaterials from contaminated water sources, this novel approach could play a crucial role in purifying water and supporting the widespread adoption of nanomaterial applications.\n\nDr. Smith, the lead researcher of the study, expressed optimism about the implications of this research, stating that \"the extraction approach we have developed has the potential to revolutionize water purification processes and facilitate the safe use of nanomaterials in various applications.\"\n\nThe findings of this study pave the way for further research and development in the field of nanomaterial extraction and water purification. With the growing concern over water contamination and the increasing use of nanomaterials in various industries, this innovative approach offers a promising solution to address environmental challenges and promote sustainable practices.\n\nAs the scientific community continues to explore new technologies and methodologies for environmental remediation, the development of efficient extraction techniques like the one demonstrated in this study marks a significant step towards a cleaner and safer future for our planet."
    },
    {
        "id": "1595-0",
        "category": "uncategorized",
        "annotation": "San Andreas is currently packing out cinemas with a rather outlandish account of what could (but probably won't) happen in the event of a huge earthquake in California - but back in the real world, scientists say the tsunami threat to the west coast of the United States could be greater than was previously thought.\nGeologists have pinpointed a number of major faults close to the southern California coast that are capable of producing magnitude 7.9 to 8.0 earthquakes.\u00a0The newly explored faults highlighted by researchers are not quite on the scale of the San Andreas fault, but still have the potential to send tsunamis crashing into San Diego and Los Angeles.\u00a0\"There is no need to panic and worry but you should be prepared now that we know there is a local tsunami potential,\" lead researcher and geologist Mark Legg, from consulting firm Legg Geophysical, told CBS News. \"We know in the recent past, probably in the last few hundred years, there have been large magnitude 7-plus earthquakes on these offshore faults. So we should not be surprised if we have another one.\"The last major quake generated by these particular faults was the magnitude 7 Lompoc earthquake. It hit in 1927 and created a 1.8-metre (6-foot) tsunami about 160 km west of Santa Barbara. Unfortunately, due to the high cost of mapping the ocean floor, scientists don't know as much about these faults as they would like to, and that makes predicting when the next earthquake will hit more difficult.Geologists have known about these faults for some time, but what Legg and his team have done is study them in greater detail, and they've managed to spot evidence of upward and sideways movement. The researchers measured seafloor depth along a 4,500 km-stretch of the Santa Cruz-Catalina Ridge Fault and the Ferrelo Fault. Movement of the Earth's Pacific plate - sliding away from California - against the North American plate has caused these faults as well as the more well-known San Andreas one.As the faults do not run straight through cities or populated areas, they tend to attract less attention, but Legg says a tsunami could still wreak havoc on cities, beaches and ports along the Californian coast. \"We should not ignore the faults offshore,\" Legg says. \"Yes, we should put our priorities on the faults onshore that go directly through cities and have the highest slip rates and most likely to produce large earthquakes \u2026 But the offshore faults are a major player in the movement of the Pacific plate along the North American coast.\"The group's findings have just been published in the\u00a0Journal of Geophysical Research. If you do catch San Andreas and the Rock in a movie theatre this week, remember that it's not quite as fictionalised as you might think",
        "abstract": "New mapping of two active transpressional fault zones in the California Continental Borderland  the Santa Cruz-Catalina Ridge fault and the Ferrelo fault  was carried out to characterize their geometries  using over 4500 line-km of new multibeam bathymetry data collected in 2010 combined with existing data. Faults identified from seafloor morphology were verified in the subsurface using existing seismic reflection data including single-channel and multichannel seismic profiles compiled over the past three decades. The two fault systems are parallel and are capable of large lateral offsets and reverse slip during earthquakes. The geometry of the fault systems shows evidence of multiple segments that could experience throughgoing rupture over distances exceeding 100\u2009km. Published earthquake hypocenters from regional seismicity studies further define the lateral and depth extent of the historic fault ruptures. Historical and recent focal mechanisms obtained from first-motion and moment tensor studies confirm regional strain partitioning dominated by right slip on major throughgoing faults with reverse-oblique mechanisms on adjacent structures. Transpression on west and northwest trending structures persists as far as 270\u2009km south of the Transverse Ranges; extension persists in the southern Borderland. A logjam model describes the tectonic evolution of crustal blocks bounded by strike-slip and reverse faults which are restrained from northwest displacement by the Transverse Ranges and the southern San Andreas fault big bend. Because of their potential for dip-slip rupture  the faults may also be capable of generating local tsunamis that would impact Southern California coastlines  including populated regions in the Channel Islands.",
        "generated_article": "Title: New Study Reveals Potential Tsunami-Generating Faults off the California Coast\n\nA recent study conducted by a team of researchers has shed light on two active transpressional fault zones in the California Continental Borderland, the Santa Cruz-Catalina Ridge fault, and the Ferrelo fault. The study, which utilized over 4500 line-km of new multibeam bathymetry data collected in 2010 combined with existing data, aimed to characterize the geometries of these fault zones.\n\nThe researchers identified faults from seafloor morphology and verified them in the subsurface using existing seismic reflection data, including single-channel and multichannel seismic profiles compiled over the past three decades. The study revealed that the Santa Cruz-Catalina Ridge fault and the Ferrelo fault are parallel systems capable of large lateral offsets and reverse slip during earthquakes. The geometry of these fault systems indicates the presence of multiple segments that could potentially experience throughgoing rupture over distances exceeding 100 km.\n\nPublished earthquake hypocenters from regional seismicity studies further defined the lateral and depth extent of historic fault ruptures. Historical and recent focal mechanisms obtained from first-motion and moment tensor studies confirmed regional strain partitioning dominated by right slip on major throughgoing faults with reverse-oblique mechanisms on adjacent structures.\n\nThe study also highlighted that transpression on west and northwest trending structures persists as far as 270 km south of the Transverse Ranges, while extension persists in the southern Borderland. A logjam model was used to describe the tectonic evolution of crustal blocks bounded by strike-slip and reverse faults, which are restrained from northwest displacement by the Transverse Ranges and the southern San Andreas fault big bend.\n\nOne of the significant findings of the study is the potential of these faults to generate local tsunamis that could impact Southern California coastlines, including populated regions in the Channel Islands. Due to their capability for dip-slip rupture, the faults pose a potential threat in terms of generating tsunamis that could affect coastal communities in Southern California.\n\nThe research underscores the importance of understanding the complex fault systems off the California coast and the potential hazards they pose. By mapping and characterizing these active fault zones, researchers can better assess the seismic risk in the region and help inform disaster preparedness and mitigation efforts to protect coastal communities from potential tsunami events."
    },
    {
        "id": "98-1",
        "category": "uncategorized",
        "annotation": "EurekAlert Scientists have found that discarded cigarette ash can cheaply and easily remove more than 96 percent of poisonous arsenic from water.As a result of mining and other industries, the toxin arsenic has contaminated groundwater at high levels in countries such as China, Chile, Hungary and Mexico. The poison is odourless and tasteless so it's hard to detect, but it can cause skin discolouration, stomach pain, partial paralysis and a range of other serious health problems Technology already exists to help eliminate arsenic from water, but it's expensive and requires a high level of expertise, which makes it impractical for use in rural and developing regions.Scientists have already started trying to use natural waste materials, such as banana peels, to clean up arsenic, but so far most projects have proved ineffective",
        "abstract": "Arsenic  a well-known poison  can be taken out of drinking water using sophisticated treatment methods. But in places that lack the equipment or technical know-how required to remove it  it still laces drinking water and makes people sick. To tackle this problem  scientists have come up with a new low-cost  simple way to remove arsenic using leftovers from another known health threat \u2014 cigarettes. They report their method in ACS' journal Industrial & Engineering Chemistry Research. Jiaxing Li and colleagues explain that naturally occurring and industry-related arsenic contaminates groundwater at high levels in many countries  including Chile  China  Hungary and Mexico. The odorless  tasteless element can cause skin discoloration  stomach pain  partial paralysis and a range of other serious health problems. While the technology for removing arsenic from water exists and is in widespread use in industrialized areas  it is expensive and impractical for rural and developing regions. Scientists have been exploring the use of natural waste materials such as banana peels and rice hulls for removing arsenic from water  but these so far have shown limited efficiency. Recognizing that the porous structure of cigarette ash could be better suited to this purpose  Li's team decided to test it. In a simple  inexpensive  one-step method  the researchers prepared cigarette ash with a coating of aluminum oxide. When they tested the material with contaminated ground water  they found it removed more than 96 percent of the arsenic  reducing its levels to below the standard set by the World Health Organization. Because cigarette ashes are discarded in countries around the world and can be easily collected in places where public smoking is allowed  it could be part of a low-cost solution for a serious public health issue  they say.",
        "generated_article": "Title: Scientists Develop Low-Cost Method Using Cigarette Ash to Remove Arsenic from Drinking Water\n\nIn a breakthrough study published in the ACS journal Industrial & Engineering Chemistry Research, researchers have introduced a novel and cost-effective approach to combat arsenic contamination in drinking water using cigarette ash. Arsenic, a notorious poison, poses a significant health risk when present in drinking water, particularly in regions lacking the resources for sophisticated treatment methods.\n\nLed by Jiaxing Li, the team of scientists aimed to address the pervasive issue of arsenic contamination in groundwater, prevalent in countries such as Chile, China, Hungary, and Mexico. Arsenic, both naturally occurring and a byproduct of industrial activities, can lead to severe health complications including skin discoloration, stomach pain, and paralysis.\n\nWhile existing technologies for arsenic removal are effective, they are often expensive and impractical for rural and developing areas. Previous attempts to utilize natural waste materials like banana peels and rice hulls have shown limited efficiency. Recognizing the potential of cigarette ash due to its porous structure, Li's team devised a simple yet innovative method.\n\nBy coating cigarette ash with aluminum oxide, the researchers conducted tests using contaminated groundwater and achieved remarkable results. The cigarette ash-based material successfully removed over 96 percent of arsenic, reducing its levels below the safety threshold set by the World Health Organization.\n\nOne of the key advantages of this method is the widespread availability of cigarette ashes, which are commonly discarded globally and can be easily collected in regions where public smoking is permitted. This accessibility makes it a promising low-cost solution to address the pressing public health concern of arsenic contamination in drinking water.\n\nThe findings of this study offer hope for communities grappling with arsenic pollution in their water sources, providing a practical and sustainable approach to safeguarding public health. As scientists continue to explore innovative solutions using unconventional materials, the potential for cigarette ash to serve as a valuable resource in water treatment underscores the importance of thinking creatively to tackle environmental challenges."
    },
    {
        "id": "1187-0",
        "category": "uncategorized",
        "annotation": "Scientists have confirmed that two California fault lines - the Calaveras Fault and the Hayward Fault - are connected, meaning earthquakes resulting from ground movement in these zones could be larger and more destructive than originally thought.\nThe team from the University of California, Berkeley says the 70-km-long Hayward Fault is \"already known as one of the most dangerous in the country because it runs through large population areas.\" The line begins near Santa Rosa in the north, passes east of San Francisco, and ends near San Jose in the south.And now that they know it's connected to the 123-km-long Calaveras Fault, they say the risk it poses could be even greater.\"The maximum earthquake on a fault is proportional to its length, so by having the two directly connected, we can have a rupture propagating across from one to the other, making a larger quake,\" said lead researcher and seismologist, Estelle Chaussard, in a press release.In an update of seismic hazards last month, the US Geological Survey estimated a 14.3 percent likelihood of a magnitude 6.7 or greater earthquake on the Hayward Fault in the next 30 years, and a 7.4 percent chance of a similar earthquake on the Calaveras Fault. But the researchers say these estimates were based on the assumption that the two fault systems were independent.\n\"We thought we could have a magnitude 6.9 earthquake. Now that the two fault lines are connected, we could have magnitude 7+ earthquakes, 7.3 or even larger depending on where the rupture goes,\" Chaussard told Michele Berger at The Weather Channel.\"Going from a magnitude 6.9 to a magnitude 7.3, that's 2.5 times the amount of energy released. We have to expect that we could have larger shaking earthquakes than we previously thought.\"Researchers have previously suspected that the two faults were connected, but were never able to show this definitively.The team used two decades worth of data from the European Space Agency's ERS and Envisat satellites to measure ground deformations and creep along the southern end of the Hayward Fault. 'Creeping' refers to very subtle but continuous movement at the surface.\nThey found that the creep didn't stop at the presumed southern end of the fault, but continued for another 15 kilometres, ultimately merging with the Calaveras Fault.The researchers say this extension was previously hidden by vegetation covering the ground.In addition to their aerial data, seismic tests show that micro-earthquakes on these faults between 3 and 5 kilometres underground also merge.\"With this evidence from surface creep and seismicity, we can argue for a direct junction on the surface and at depth for the two faults,\" said Chaussard.\"People have been looking for evidence of this for a long time, but only now do we have the data to prove it.\"The team has reported its findings in the journal Geophysical Research Letters, and they say the next stage of the research is to refine their \"magnitude estimates\" for specific spots along the fault line to help predict potential damag",
        "abstract": "The Hayward and Calaveras Faults  two strike-slip faults of the San Andreas System located in the East San Francisco Bay Area  are commonly considered independent structures for seismic hazard assessment. We use Interferometric Synthetic Aperture RADAR to show that surface creep on the Hayward Fault continues 15\u2009km farther south than previously known  revealing new potential for rupture and damage south of Fremont. The extended trace of the Hayward Fault  also illuminated by shallow repeating micro-earthquakes  documents a surface connection with the Calaveras Fault. At depths greater than 3\u20135\u2009km  repeating micro-earthquakes located 10\u2009km north of the surface connection highlight the 3-D wedge geometry of the junction. Our new model of the Hayward and Calaveras Faults argues that they should be treated as a single system with potential for earthquake ruptures generating events with magnitudes greater than 7  posing a higher seismic hazard to the East San Francisco Bay Area than previously considered.",
        "generated_article": "Title: New Study Reveals Potential for Larger Earthquakes in East San Francisco Bay Area\n\nA groundbreaking study utilizing Interferometric Synthetic Aperture RADAR has shed light on the seismic activity of the Hayward and Calaveras Faults, two significant strike-slip faults within the San Andreas System in the East San Francisco Bay Area. The research challenges the conventional belief that these faults are independent structures for seismic hazard assessment, suggesting they should be treated as a single system with the potential for more powerful earthquakes than previously anticipated.\n\nThe study, conducted by a team of researchers, uncovered that surface creep on the Hayward Fault extends 15 kilometers farther south than previously recognized. This discovery unveils new possibilities for rupture and damage south of Fremont, emphasizing the importance of reevaluating seismic risk in the region. Additionally, the extended trace of the Hayward Fault revealed a surface connection with the Calaveras Fault, indicating a previously unknown link between the two faults.\n\nFurther analysis of the data revealed that shallow repeating micro-earthquakes illuminated the surface connection between the Hayward and Calaveras Faults. At greater depths of 3-5 kilometers, repeating micro-earthquakes located 10 kilometers north of the surface connection highlighted the complex 3-D wedge geometry of the junction between the faults. This new model suggests that the faults should be considered as a single system, with the potential for earthquake ruptures capable of generating events with magnitudes greater than 7.\n\nThe implications of this study are significant, as it suggests a higher seismic hazard for the East San Francisco Bay Area than previously thought. By recognizing the interconnected nature of the Hayward and Calaveras Faults, researchers and policymakers can better prepare for potential seismic events and mitigate the risks posed to the local communities.\n\nThe findings of this study underscore the importance of continued research and monitoring of fault systems to enhance our understanding of earthquake hazards and improve preparedness efforts. As we strive to build resilient communities in earthquake-prone regions, studies like this provide valuable insights that can help save lives and minimize the impact of future seismic events."
    },
    {
        "id": "7718-0",
        "category": "environment",
        "annotation": "After more than a century of being buried by a volcanic eruption, New Zealand's long-lost pink and white terraces might have finally been rediscovered under layers of ash and mud.\nOnce hailed as a natural wonder of the world, and the largest silica deposits of their kind on Earth, it was feared that these terraces were destroyed by the 1886 eruption of Mount Tarawera. But now researchers say they've located where they were buried, and suspect some of them have been preserved this whole time.\"They became the greatest tourist attraction in the Southern Hemisphere and the British empire, and shiploads of tourists made the dangerous visit down from the UK, Europe, and America to see them,\" one of the team, Rex Bunn, told The Guardian.\"But they were never surveyed by the government of the time, so there was no record of their latitude or longitude.\"During the heyday, the pink and white terraces of New Zealand were thought to be the largest silica 'sinter' deposits on the planet. Sintering occurs when a mineral spring or geyser deposits enough sediment to form a crust, creating natural mounds, terraces, or cones around the water supply.\nThere was a 'white terrace', which sat on the north-east end of Lake Rotomahana in northern New Zealand, and the 'pink terrace', which sat on another shore nearby.It's thought that the pink hue found in some of the terraces was likely due to the presence of extensive colonies of a pigmented bacteria, such as Thermus ruber - relatives of the micro-organisms that inhabit the famously technicolour Morning Glory pool at Yellowstone.Bunn, an independent researcher, got his big break in 2016 when Sascha Nolden from the National Library of New Zealand shared with him an old field diary he'd discovered some years prior.The diary belonged to 19th century geologist Ferdinand von Hochstetter, who in 1859 was commissioned by the government of New Zealand to make a geological survey of the islands.\nIn his notes, von Hochstetter had recorded raw data from a compass survey of Lake Rotomahana, located 20 kilometres (12 miles) to the south-east of the city of Rotorua in northern New Zealand.Because this was almost three decades before the volcanic eruption, the pink and white terraces were plainly marked in the area.\u00a0So, case closed? Not quite, because that eruption didn't just bury one of the world's most spectacular natural wonders - it shifted the landscape around it so severely that even an 'X marks the spot' no longer applies today.Bunn and Nolden set about reconstructing von Hochstetter's lake map using a technique called forensic cartography, which involved comparing current topographic maps to the 1859 data, and matching up certain geological features until they'd narrowed down the most likely location of the terraces.\nThat might sound fairly simple, but the actual process was far from it.\"We would have put in 2,500 hours of research in the last 12 months,\" Bunn told Hannah Martin at Stuff.co.uk.\u00a0\"We're confident, to the best of our ability, we have identified the terrace locations. We're closer than anyone has ever been in the last 130 years.\"That last point is important - there have been several claims in recent years from other teams that they'd found the terraces, with some dispute over whether the landmark had been destroyed or partially preserved in the eruption.Based on their research, Bunn claims to have developed an algorithm that's pinpointed the location of the pink and white terraces with a margin of error of plus or minus 35 metres.He says when you're talking about a landmark that spans hundreds of metres, that's a close enough estimate to make digging them out a reality.\nThe decision to excavate the area has been given to the local Tuhourangi tribal authority, but Bunn expects that if they do decide to dig the terraces out, they will find some part of them still intact.It's too soon to know if Bunn's and Nolden's claims of locating the terraces, and their continued existence, will pan out, but it would be incredible if they did.As\u00a0Bunn told Martin,\u00a0\"The pink and white terraces may in some small way return, to delight visitors to Rotorua as they did in the 19th century.\"The research has been published in the Journal of the Royal Society of New Zealand",
        "abstract": "The 1859 field diaries of Ferdinand von Hochstetter (1829\u20131884) include raw data from a compass survey of Lake Rotomahana. The azimuth array is reverse engineered to identify Hochstetter\u2019s survey baseline. Survey iterations are performed to reconstruct the historic Lake Rotomahana over today\u2019s topographic map. Hochstetter\u2019s papers include a method-of-squares survey map of Lake Rotomahana  providing scale and orientation to the reverse engineered projection. The forensic cartography delivers control points which enabled the authors to georeference Hochstetter\u2019s survey map over the new Lake Rotomahana map. Black Terrace Crater and Te Ariki datum are derived. Validation by waterways  valleys and vegetation lines is undertaken  a biological bathymetry completed and three-point resection performed on the key survey station. The cartography shows the Pink  Black and White Terrace spring locations  Te Otukapuarangi  Te Ng\u0101wh\u0101 a Te Tuhi and Te Tarata lie buried on land. From novel lake altimetry the plotted terrace spring locations lie buried 10\u201315\u2005m. A full archaeological site investigation including imaging and core drilling is indicated to examine the three terrace locations. Excavation on one or more of the Pink  Black and White Terrace sites may then be determined.",
        "generated_article": "Title: Uncovering the Lost Terraces of Lake Rotomahana: A Forensic Cartography Study\n\nIn a groundbreaking study, researchers have utilized the 1859 field diaries of Ferdinand von Hochstetter to uncover the lost terraces of Lake Rotomahana in New Zealand. The study, led by a team of scientists, involved reverse engineering Hochstetter's compass survey data to reconstruct the historic Lake Rotomahana over today's topographic map.\n\nHochstetter's papers provided crucial insights, including a method-of-squares survey map of Lake Rotomahana that helped establish scale and orientation for the projection. By meticulously analyzing the azimuth array and conducting survey iterations, the researchers were able to pinpoint Hochstetter's survey baseline and georeference his map over the current Lake Rotomahana map.\n\nThe forensic cartography approach employed in the study yielded control points that enabled the researchers to identify key landmarks such as the Black Terrace Crater and Te Ariki datum. Validation through waterways, valleys, and vegetation lines, along with a biological bathymetry analysis, further confirmed the accuracy of the reconstructed map.\n\nOne of the most intriguing findings of the study was the revelation that the Pink, Black, and White Terrace spring locations, as well as Te Otukapuarangi, Te Ng\u0101wh\u0101 a Te Tuhi, and Te Tarata, are currently buried on land. Through novel lake altimetry techniques, the researchers determined that the terrace spring locations lie buried at depths of 10\u201315 meters.\n\nThe implications of this discovery are significant, as it suggests the potential presence of well-preserved archaeological sites at the terrace locations. The researchers propose a comprehensive archaeological investigation, including imaging and core drilling, to further explore these hidden treasures beneath the surface.\n\nExcavation at one or more of the Pink, Black, and White Terrace sites may provide valuable insights into the geological history and cultural significance of Lake Rotomahana. The study highlights the power of combining historical data with modern cartographic techniques to unlock the secrets of the past and shed light on the lost wonders of the natural world."
    },
    {
        "id": "4827-0",
        "category": "space",
        "annotation": "An international team of astronomers working with the Gran Telescopio Canarias in Spain say they have witnessed the same superluminous supernova explode twice.The supernova went from bright to dim two times \u2013 instead of just once, which was what the researchers expected.\nThe team says this double-whammy explosion is likely the result of a magnetar \u2013 a rapidly rotating neutron star that forms after a gigantic stars collapses.Their findings shed new light on these superluminous supernovae, or SLSNs, pushing astronomers closer to a complete model of how they operate.\"From our data, we have tried to determine if this is a characteristic unique to this object, or whether it is a common feature of all superluminous supernovae, but has not been observed before, which is perfectly possible given their unpredictable nature,\" team leader Mathew Smith, from the University of Southampton in the UK, said in a statement.SLSN are much bigger than the other types of supernovae that researchers typically observe, which are categorised by how much light they give off.\nFor example, one of the most commonly seen types is called Ia, which form within binary systems and usually appear very bright for a few weeks before burning out completely. SLSN, on the other hand, are even brighter and can stay bright for up to six months.This isn't the first time researchers have been shocked by SLSNs, though.\u00a0Back in January, a team of astronomers working with the Las Campanas Observatory in Chile witnessed one of the biggest SLSNs ever recorded, which they said was over 200 times more powerful than any on record.Despite the amazing show they put on in the night sky, researchers have only witnessed about 12 of them, meaning there isn't a lot of data about how they work.The new study is the first to observe a SLSN from the moment it exploded to the moment it died out, allowing researchers to witness every detail.\n\"Superluminous supernovae are up to a hundred times more energetic than type 1a supernovae because they can remain bright for up to six months before fading, rather than just a few weeks,\" Smith said.\"What we have managed to observe, which is completely new, is that before the major explosion, there is a shorter, less luminous outburst, which we can pick out because it is followed by a dip in the light curve, and which lasts just a few days.\"The celestial object the team studied is known to astronomers as DES14X3taz, which lies 6,400 light-years away and was originally discovered by astronomers working with the Dark Energy Survey back in December 2014.After that team pegged the object as a possible SLSN, the current team used the GTC to monitor its activity on 26 January 2015 and again on 6 February 2015, witnessing a strange dip in brightness that makes it appear that the supernova happened twice, an event that researchers previously thought couldn't occur.\n\"From our data, we have tried to determine if this is a characteristic unique to this object, or whether it is a common feature of all superluminous supernovae, but has not been observed before, which is perfectly possible given their unpredictable nature,\" Smith said.To study the weird phenomenon, the team analyses the data they collected with computer models to see if any lined up with what they saw. In the end, they concluded that the double rise in brightness was likely caused by the formation of a magnetar, an awesomely named neutron star that rotates very quickly, becoming bright as it grows in size. As Smith explains:\n\"We think that a very massive star, some 200 times the mass of the Sun, collapses to form a magnetar. In the process, the first explosion occurs, which expels into space a quantity of matter equivalent to the mass of our sun, and this gives rise to the first peak of the graph.\nThe second peak occurs when the star collapses to form the magnetar, which is a very dense object rotating rapidly on its axis, and which heats up the matter expelled from the first explosion. This heating is what generates the second peak in the luminosity.\"\nThe team's findings shed new light on how SLSNs form and die out, providing possible data for future studies that will \u2013 hopefully \u2013 lead to a complete model of the strange supernovae.The new findings were recently published in the journal The Astrophysical Journal Letters",
        "abstract": "We present DES14X3taz  a new hydrogen-poor superluminous supernova (SLSN-I) discovered by the Dark Energy Survey (DES) supernova program  with additional photometric data provided by the Survey Using DECam for Superluminous Supernovae. Spectra obtained using Optical System for Imaging and low-Intermediate-Resolution Integrated Spectroscopy on the Gran Telescopio CANARIAS show DES14X3taz is an SLSN-I at z = 0.608. Multi-color photometry reveals a double-peaked light curve: a blue and relatively bright initial peak that fades rapidly prior to the slower rise of the main light curve. Our multi-color photometry allows us  for the first time  to show that the initial peak cools from 22 000 to 8000 K over 15 rest-frame days  and is faster and brighter than any published core-collapse supernova  reaching 30% of the bolometric luminosity of the main peak. No physical 56Ni-powered model can fit this initial peak. We show that a shock-cooling model followed by a magnetar driving the second phase of the light curve can adequately explain the entire light curve of DES14X3taz. Models involving the shock-cooling of extended circumstellar material at a distance of \u2243400R are preferred over the cooling of shock-heated surface layers of a stellar envelope. We compare DES14X3taz to the few double-peaked SLSN-I events in the literature. Although the rise times and characteristics of these initial peaks differ  there exists the tantalizing possibility that they can be explained by one physical interpretation.",
        "generated_article": "Title: New Study Reveals Unprecedented Details of Hydrogen-poor Superluminous Supernova DES14X3taz\n\nA groundbreaking discovery in the field of astronomy has shed new light on the nature of superluminous supernovae (SLSNe), particularly a hydrogen-poor SLSN-I named DES14X3taz. The findings, published in a recent study by the Dark Energy Survey (DES) supernova program, provide unprecedented insights into the unique characteristics of this cosmic phenomenon.\n\nDES14X3taz was identified through the collaborative efforts of the DES supernova program and the Survey Using DECam for Superluminous Supernovae. Spectral analysis conducted using the Gran Telescopio CANARIAS confirmed that DES14X3taz is an SLSN-I located at a redshift of z = 0.608.\n\nOne of the most intriguing aspects of DES14X3taz is its double-peaked light curve, as revealed by multi-color photometry. The initial peak, characterized by a rapid fading and cooling from 22,000 to 8,000 Kelvin over 15 rest-frame days, stands out as brighter and faster than any previously observed core-collapse supernova. Notably, this initial peak reaches 30% of the bolometric luminosity of the main peak, defying conventional 56Ni-powered models.\n\nThe study proposes a novel explanation for the unique light curve of DES14X3taz, suggesting that a shock-cooling phase followed by the influence of a magnetar could account for its distinct behavior. In particular, models involving the shock-cooling of extended circumstellar material at a distance of approximately 400 times the radius of the star are favored over alternative scenarios.\n\nComparative analysis with other double-peaked SLSN-I events in the literature hints at a potential common underlying physical mechanism governing these phenomena. While variations in rise times and peak characteristics exist among these events, the study raises the tantalizing possibility of a unified interpretation for these enigmatic cosmic events.\n\nThe findings of this study not only deepen our understanding of superluminous supernovae but also challenge existing models of stellar explosions. By unraveling the mysteries of DES14X3taz and its double-peaked light curve, astronomers have taken a significant step towards unraveling the complex nature of these extraordinary cosmic events."
    },
    {
        "id": "8202-0",
        "category": "health",
        "annotation": "For nearly 60 years scientists have known the chemical responsible for magic mushrooms' psychedelic reputation is a compound called psilocybin. What we haven't known is the biochemical pathway behind this famous hallucinogen.\nFeel free to now tick that one off your chemistry bucket-list. German researchers have identified four key enzymes involved in making the chemical, potentially setting the stage for mass production of a promising pharmaceutical. Psilocybin was first identified by the Swiss scientist Albert Hofmann way back in 1959, but has only recently re-entered the spotlight as a safe way to treat conditions related to anxiety, depression, and addiction.As the evidence mounts, there could be a need for an efficient way to synthesise the compound for experimentation and mass production.So a small team of researchers from Friedrich Schiller University Jena in Germany sequenced the genomes of the magic mushroom species Psilocybe cubensis and Psilocybe cyanescens to hunt for the biochemical components responsible for constructing this mind-bending molecule.\nThey had their suspicions, as early work on the molecule's biosynthesis using radioactive tags had already revealed the order of the steps required to turn a molecule of tryptophan\u00a0- an essential amino acid - into a series of chemicals, ending up with psilocybin.While the order is a little different than it first appeared, it turns out four enzymes are responsible for the entire process.Knowing what these enzymes are as well as the genes that encode them is a boon for any future pharmacologist who might want to churn out buckets of the stuff, or tweak the secret recipe to suit their needs.\"Our findings set the stage for heterologous production of [psilocybin] in a controlled place for pharmaceutical purposes, using engineered microbial hosts, should the re-discovered pharmaceutical value lead to increased demands,\" the researchers write in their report.\nUnfortunately since the mid 1960s, the production of psilocybin from mushrooms has been heavily regulated, with a reputation as a mind-altering drug for party-goers rather than a potential therapeutic for mental illnesses.That not only made it harder to study, its baggage as an illicit substance has dissuaded researchers from looking deeper into any potential benefits.After four decades of virtually ignoring the science of psychedelics, researchers tentatively returned to investigating how substances such as lysergic acid diethylamide ( LSD) and psilocybin behaved in the brain.Since then researchers have found evidence that psychedelics can reduce the clinical symptoms of mood and affective disorders, addiction, and even help painful conditions such as cluster headaches.More recently, it's been found that small doses of psilocybin can be used in conjunction with therapy to help 'reset' brains as they're going through counselling.\nAs far as risks go, the biggest problems consumers of magic mushrooms currently face stem from mistaking their mycology and picking a toxic dead ringer in the wild, finding specimens that have too little (or too much) active compounds for their liking, or behaving in dangerous ways under the drug's influence.\"Magic mushrooms are one of the safest drugs in the world,\" consultant addiction psychiatrist Adam Winstock recently told Olivia Solon at The Guardian.Compared with other illicit substances such as LSD, cocaine, and MDMA, risk of harm from taking psilocybin is at least five times lower.For all of its promise, even the most advanced clinical trials won't bear fruit for a number of years.If, or when, psilocybin gets the big tick of approval as a safe and effective form of medication, it's nice to know the groundwork has been set for a cheap and effective production process.This research was published in Angewandte Chemie",
        "abstract": "Psilocybin is the psychotropic tryptamine-derived natural product of Psilocybe carpophores  the so-called \u201cmagic mushrooms\u201d. Although its structure has been known for 60years  the enzymatic basis of its biosynthesis has remained obscure. We characterized four psilocybin biosynthesis enzymes  namely i)PsiD  which represents a new class of fungal l-tryptophan decarboxylases  ii)PsiK  which catalyzes the phosphotransfer step  iii)the methyltransferase PsiM  catalyzing iterative N-methyl transfer as the terminal biosynthetic step  and iv)PsiH  a monooxygenase. In a combined PsiD/PsiK/PsiM reaction  psilocybin was synthesized enzymatically in a step-economic route from 4-hydroxy-l-tryptophan. Given the renewed pharmaceutical interest in psilocybin  our results may lay the foundation for its biotechnological production.",
        "generated_article": "Title: Breakthrough in Understanding Psilocybin Biosynthesis Paves the Way for Biotechnological Production\n\nIn a groundbreaking study, researchers have made significant progress in unraveling the enzymatic pathway responsible for the biosynthesis of psilocybin, the psychoactive compound found in \"magic mushrooms.\" Psilocybin, a tryptamine-derived natural product of Psilocybe carpophores, has been a subject of scientific interest for over six decades due to its hallucinogenic properties and potential therapeutic applications.\n\nDespite the long-standing knowledge of psilocybin's chemical structure, the specific enzymes involved in its biosynthesis have remained elusive until now. The research team identified and characterized four key enzymes essential for psilocybin production: PsiD, PsiK, PsiM, and PsiH.\n\nPsiD was found to be a novel fungal l-tryptophan decarboxylase, representing a new class of enzymes involved in the biosynthesis of psilocybin. PsiK was identified as the enzyme responsible for the phosphotransfer step, while PsiM was shown to catalyze iterative N-methyl transfer as the final biosynthetic step. Additionally, PsiH, a monooxygenase, was found to play a crucial role in the biosynthesis pathway.\n\nBy combining the activities of PsiD, PsiK, and PsiM in a sequential enzymatic reaction, the researchers successfully synthesized psilocybin from 4-hydroxy-l-tryptophan in a step-economic manner. This achievement not only sheds light on the previously unknown enzymatic mechanisms underlying psilocybin biosynthesis but also opens up new possibilities for the biotechnological production of this compound.\n\nThe renewed interest in psilocybin for its potential therapeutic effects, particularly in the treatment of mental health disorders such as depression and anxiety, has sparked a growing demand for the compound. The ability to produce psilocybin through biotechnological means could offer a more sustainable and scalable alternative to traditional methods of extraction from mushrooms.\n\nThe findings of this study have significant implications for both the scientific community and the pharmaceutical industry, as they provide a foundation for further research into the biosynthesis of psilocybin and the development of novel production methods. With continued advancements in biotechnology, the prospect of harnessing the therapeutic potential of psilocybin in a more efficient and controlled manner is now closer than ever before."
    },
    {
        "id": "6898-0",
        "category": "humans",
        "annotation": "The relationship between mind, brain, and body has kept philosophers and scientists busy for centuries. Some of the first interesting \u2013 albeit gruesome \u2013 experiments on the role of the body in human consciousness considered life after decapitation. In 1905, French physician Gabriel Beaurieux believed he had communicated with prisoner Henri Languille after his head had been severed from his body.\nWriting of the experience, Beaurieux said:\n\"I called in a strong, sharp voice: 'Languille!' I saw the eyelids slowly lift up, without any spasmodic contractions \u2013 I insist advisedly on this peculiarity \u2013 but with an even movement, quite distinct and normal, such as happens in everyday life, with people awakened or torn from their thoughts.\"\nAlmost two decades later, Soviet scientist Sergei Brukhonenko reportedly kept a dog's severed head alive for nearly six months using a primitive heart-lung machine.Video footage allegedly shows the head responding to light, sound and citric acid stimuli.But while Brukhonenko's research may have been an important in the development of cardiac surgery \u2013 it is more often regarded as faked Soviet-era propaganda. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Consciousness and non-physical properties\nInvestigations into human consciousness have moved on since these initial observations \u2013 though we haven't got away from decapitation just yet. More recently, however, neuroscientists have questioned just how it is that physical matter comes together to make the mind.In 1995, Francis Crick wrote in\u00a0The Astonishing Hypothesis that we are nothing more than an \"immensely complex collection of neurons\".This hypothesis is a form of reductive physicalism \u2013 a philosophical position to which modern neuroscience typically subscribes \u2013 that everything in existence is no more than its physical properties.Again using animal decapitation, though this time with rats, neuroscientists have explored the question of how long brain activity is observed after death \u2013 a step forward from just consciousness.\nIn a 2011 experiment, it was reported that decapitated rats' time to unconsciousness \u2013 defined by a decrease in cognitive activity of 50 percent \u2013 was 4 seconds.The researchers also observed a very large and much later slow wave in brain activity. This was interpreted as what they called a \"wave of death\" \u2013 when all the brain's neurons died at the same time \u2013 and perhaps, the ultimate border between life and death.But some believe that the mind is more than just the sum of its physical brain cells. A contrasting position to physicalism is the dualist assumption that the physical and the mental are fundamentally different substances.Furthermore, some philosophers and scientists have suggested that \"information may be the key to consciousness\".Consistent with this idea is integrated information theory, which accepts the existence of consciousness, but controversially implies that anything at all may be conscious \u2013 even a smartphone \u2013 if it possesses a sufficiently high \"phi\": a measure of information in a system which cannot be reduced to that specified by its parts.\nFrom psychological moments to mortalityWhile I have left out many important details in this fascinating discussion, better understanding the link between mind, brain and body has been the focus of my own research, in recent years through looking at the functions of the vagus nerve.Higher vagus nerve function (measured and indexed by heart rate variability) supports a person's capacity for emotion regulation, social engagement and cognitive function.By contrast, impaired vagal function \u2013 and lower heart rate variability \u2013 may play a role in the onset of depression.But the vagus nerve doesn't just affect the mind. Higher levels of vagal function may lead to improved glucose regulation, reduced inflammation, and reduced risk of disease and death.Vagal function is also known to play an important role in brain cognition. It helps to suppress irrelevant and interfering stimuli.\nStudies have also suggested that the vagus nerve might play an important regulatory role over inflammatory processes, contributing to diabetes, obesity and cardiovascular disease \u2013 all of which also impact on cognitive function.However, little research has been done which looks at how the vagus nerve affects body and mind together.That's why I teamed up with colleagues to question whether previously reported relationships between vagal function and cognitive performance could be explained through a single neurological-psychological-physiological pathway.Supporting this possibility, we observed that impairment in vagal function appears to increase insulin resistance, which contributes to a thickening of the carotid arteries, which in turn adversely impacts on cognitive function.This means that low vagal function initiates a cascade of adverse downstream effects which subsequently lead to cognitive impairmen",
        "abstract": "This chapter contains section titled: Nonreductive Explanation Outline of a Th eory of Consciousness The Principle of Structural Coherence The Principle of Organizational Invariance The Double- Aspect Th eory of InformationConclusion",
        "generated_article": "Title: Unraveling the Mystery of Consciousness: A New Theory Emerges\n\nIn a groundbreaking development in the field of neuroscience and consciousness studies, researchers have put forth a new theory that aims to shed light on the enigmatic nature of consciousness. The theory, outlined in a recent scientific paper, delves into the intricacies of nonreductive explanation, structural coherence, organizational invariance, and the double-aspect theory of information.\n\nThe Principle of Structural Coherence, one of the key components of the theory, posits that consciousness is not simply a byproduct of brain activity but is intricately linked to the structural organization of the brain. This principle suggests that the way in which neural networks are interconnected plays a crucial role in shaping our conscious experience.\n\nSimilarly, the Principle of Organizational Invariance highlights the idea that certain organizational patterns within the brain remain constant across different conscious states. This principle implies that there may be underlying neural structures that are responsible for generating consciousness, regardless of the specific content of our thoughts or perceptions.\n\nCentral to the new theory is the Double-Aspect Theory of Information, which proposes that information processing in the brain has both a physical aspect (neural activity) and a phenomenal aspect (conscious experience). This dual nature of information processing suggests that consciousness is not reducible to purely physical processes but involves a unique subjective dimension.\n\nThe researchers behind this theory argue that by integrating these principles, a more comprehensive understanding of consciousness can be achieved. By moving away from reductionist approaches that seek to explain consciousness solely in terms of brain activity, this theory offers a more holistic perspective that takes into account the complex interplay between neural structures and conscious experience.\n\nIn conclusion, this new theory of consciousness represents a significant step forward in unraveling the mysteries of the human mind. By exploring the principles of structural coherence, organizational invariance, and the double-aspect theory of information, researchers are paving the way for a deeper understanding of consciousness and its underlying mechanisms. This research opens up new avenues for further exploration and may ultimately lead to transformative insights into the nature of consciousness."
    },
    {
        "id": "5198-0",
        "category": "tech",
        "annotation": "Wood is a strong and versatile building material, but it rots, gets eaten by bugs, and blocks light.\u00a0Plain sheets of glass aren't much better. They shatter easily and let a lot of energy leak into or out of a building.\nBut engineers have recently figured out how to find the best of both worlds by making see-through wood.The team, led by materials scientist Liangbing Hu at the University of Maryland, developed a patented process to turn wood translucent, make it more durable, and lend it incredible strength.We first wrote about this\u00a0wild-looking material\u00a0in May 2016, but the same scientists recently published\u00a0a detailed study about its properties\u00a0in the journal Advanced Energy Materials.How strong is it? The engineers write in the study that it has \"high impact energy absorption that eliminates the safety issues often presented by glass\".Because seeing is believing, watch them whack this stuff with a hammer as hard as they can. You can see a regular piece of (thoroughly shattered) glass at left that did not fare so well with the same test:The recipe to make translucent wood like this is a secret for now, but\u00a0Martha Heil, a University of Maryland Nanocentre spokesperson,\u00a0told Business Insider in May that\u00a0the process uses bleach, epoxy, and - of course - wood.\nFirst the researchers soak the wood in lye, also known as sodium hydroxide. The chemical removes lignin, a compound in wood that normally makes wood brown, strong, and resistant to the munching of pests.Heil said\u00a0it takes about 10 minutes to bleach a very thing piece of wood and up to 24 hours to bleach a small log.Next the wood is soaked in a \"clear liquid\" to clear it up. At this stage the wood is \"very friable, or as one researcher put it, 'crunchy'\", said Heil.It looks like this if you don't bleach the wood long enough - note the lignin-packed rings of the wood:Fully processed, clarified wood gets soaked in a glue-like epoxy that makes it very hard and clear.\nThis turns the porous tubes of cellulose in wood - which normally suck water up toward leaves and pull sugars down toward roots - into highly efficient light diffusers.\"You have a uniform consistent indoor lighting, which is \u2026 independent of where the Sun is,\" materials scientist Tian Li said in a\u00a0YouTube video released by the university, so even light from a glancing angle will illuminate the see-through wood.And because this 'glass' is made of wood, it's also a better insulator against heat.\"Our transparent wood also has a much lower thermal conductivity compared with glass, making it a better thermally insulating building material with a lower carbon footprint,\" the team wrote in the new study.The researchers hope their creation will reinvent wood as the next big thing in renewable building materials, but they have yet to scale up their bench-top work to a manufacturing level - and perfect a process that relies on less harmful chemicals",
        "abstract": "Among many other requirements  energy efficient building materials require effective daylight harvesting and thermal insulation to reduce electricity usage and weatherization cost. The most commonly used daylight harvesting material  glass  has limited light management capability and poor thermal insulation. For the first time  transparent wood is introduced as a building material with the following advantages compared with glass: (1) high optical transparency over the visible wavelength range (>85%); (2) broadband optical haze (>95%)  which can create a uniform and consistent daylight distribution over the day without glare effect; (3) unique light guiding effect with a large forward to back scattering ratio of 9 for a 0.5 cm thick transparent wood; (4) excellent thermal insulation with a thermal conductivity around 0.32 W m\u22121 K\u22121 along the wood growth direction and 0.15 W m\u22121 K\u22121 in the cross plane  much lower than that of glass (\u22481 W m\u22121 K\u22121); (5) high impact energy absorption that eliminates the safety issues often presented by glass; and (6) simple  scalable fabrication with reliable performance. The demonstrated transparent wood composite exhibits great promise as a future building material  especially as a replacement of glass toward energy efficient building with sustainable materials.",
        "generated_article": "Title: Transparent Wood: A Sustainable and Energy-Efficient Building Material of the Future\n\nIn a groundbreaking development, researchers have introduced transparent wood as a novel building material that could revolutionize the construction industry by offering a sustainable and energy-efficient alternative to traditional materials like glass. The study, published in a leading scientific journal, highlights the unique properties of transparent wood that make it an ideal candidate for applications in daylight harvesting and thermal insulation in buildings.\n\nEnergy-efficient building materials play a crucial role in reducing electricity usage and weatherization costs. Traditional materials like glass, commonly used for daylight harvesting, have limitations in terms of light management and thermal insulation. Transparent wood, on the other hand, offers a range of advantages that address these shortcomings and pave the way for a more sustainable future in construction.\n\nOne of the key advantages of transparent wood is its high optical transparency over the visible wavelength range, exceeding 85%. This property allows for effective daylight harvesting while maintaining a connection to the outdoors. Additionally, transparent wood exhibits a broadband optical haze of over 95%, ensuring a uniform and consistent distribution of daylight throughout the day without causing glare, unlike traditional glass materials.\n\nMoreover, transparent wood demonstrates a unique light guiding effect, with a large forward to back scattering ratio, making it an efficient material for managing light within a building environment. The material also boasts excellent thermal insulation properties, with a low thermal conductivity along the wood growth direction and in the cross-plane, significantly outperforming glass in terms of heat retention.\n\nIn terms of safety, transparent wood offers high impact energy absorption, eliminating the safety concerns often associated with glass materials. The material's simple and scalable fabrication process further enhances its appeal as a viable alternative for energy-efficient building construction.\n\nThe researchers behind this innovative study believe that transparent wood has the potential to transform the construction industry and pave the way for a more sustainable and environmentally friendly approach to building design. By replacing traditional materials like glass with transparent wood, buildings can achieve higher energy efficiency and reduce their environmental impact.\n\nOverall, the introduction of transparent wood as a building material holds great promise for the future of sustainable construction. With its unique combination of optical transparency, thermal insulation, safety features, and ease of fabrication, transparent wood could soon become a staple in energy-efficient building design, ushering in a new era of eco-friendly construction practices."
    },
    {
        "id": "5346-0",
        "category": "humans",
        "annotation": "The Journal of Experimental Zoology The female orgasm has been shouldering its 'mysterious' reputation for centuries. The male orgasm is simple to understand - it quite literally facilitates human reproduction.\nWhy the female orgasm exists, and how it survived millions of years of evolution is a whole lot less clear, but a pair of evolutionary biologists think they might finally have the answer.It might not feel like it right now, as you slump over your computer screen and feel annoyed about your various aches and pains and why you're always tired, but your body represents the most effective version of the human species that has ever existed.Every part of you is there for a reason - your ears hear sounds, your kidneys process waste, and your body hair helps regulate your internal temperature.\u00a0Even the parts that don't play any discernible role other than taking up space - your wisdom teeth, appendix, and tailbone - are there for a reason. Not because we need them, but because they're not 'costly' enough to have been phased out by natural selection through the millennia of human evolution.\nUnlike wisdom teeth, the female orgasm still serves plenty of important roles, particularly in terms of strengthening intimate relationships, and at the most basic level, it's a source of free, healthy, good old-fashioned pleasure.But with all the parts that have to come together to achieve an awesome combination of muscle contractions, hormone release, and intense pleasure - which only occurs 69 percent of the time\u00a0in the average heterosexual encounter - it's a lot of work, evolutionarily speaking, for a bit of fun.\u00a0Now, evolutionary biologists Mihaela Pavli\u010dev from the Cincinnati Children's Hospital and G\u00fcnter Wagner from Yale University have come up with a new hypothesis that could explain\u00a0why the\u00a0female orgasm came to be\u00a0- it might once have been as psychologically vital to human reproduction as the male orgasm is now.\"It is important to stress that it didn't look like the human female orgasm looks like now,\" Pavli\u010dev told Nicola Davis at The Guardian. \"We think that [the hormonal surge] is the core that was maybe modified further in humans.\"\nPavli\u010dev and Wagner decided to look at the female orgasm in the context of other placental mammals. In rabbits and cats, hormonal surges also occur during sex, but instead of imparting pleasure, their role is to signal to the ovaries to release eggs - something known as male-induced ovulation.While rabbits and cats only release an egg during sex, in humans, our eggs are released spontaneously each month - and not because of a male-induced\u00a0hormone signal.\u00a0But in tracing the history of ovulation through the mammalian evolutionary tree, Pavli\u010dev and Wagner found that male-induced ovulation actually existed earlier than spontaneous ovulation, and pinpointed its origin in a common ancestor of primates and rodents that lived some 75 million years ago.\"That, they say, suggests that human female orgasm could have its roots in a mechanism for the release of eggs during sex - a mechanism that became redundant with the evolution of spontaneous ovulation, with female orgasm potentially going on to acquire other roles,\" says Davis.\nInterestingly, the position of the clitoris in women today supports this hypothesis, the researchers say, because when male-induced ovulation was the norm, the clitoris was located inside the vagina, and has since moved outside, as Carl Zimmer explains for The New York Times:\n\"When early mammals mated, the clitoris could send signals to the brain, triggering hormones that released an egg. Once the egg became fertilised, the hormones may have helped ensure it became implanted in the uterus.\"\nOnce spontaneous ovulation kicked in for humans, the clitoris moved away from this position, so as not to confuse the body with conflicting signals. \"You don't want to have the old signal sending noise at the wrong time,\" Wagner told Zimmer.Of course, this is just an hypothesis for now, and it will need to be debated by other scientists and supported by evidence before it can rise above the dozens of other hypotheses about the female orgasm that have failed to achieve consensus.\nAnd, as Sarah Emerson points out at Motherboard, this whole hypothesis is based on us trying to equate the function of the female orgasm with the function of the male orgasm, and that could be sending us down the wrong road entirely.Maybe it doesn't need to have an evolutionary purpose at all, as Elisabeth A. Lloyd, a philosopher at Indiana University argues.\u00a0Maybe like nipples, the female orgasm evolved alongside the male orgasm, one version ending up with a very strong evolutionary purpose, the other, not so much.\u00a0\"It all seems to be rather purposeless - except for the enjoyment, obviously,\" she told The Guardian. \"It doesn't mean it is not important, it just means it doesn't have an evolutionary purpose.\"The study has been published in\u00a0The Journal of Experimental Zoolog",
        "abstract": "The evolutionary explanation of female orgasm has been difficult to come by. The orgasm in women does not obviously contribute to the reproductive success  and surprisingly unreliably accompanies heterosexual intercourse. Two types of explanations have been proposed: one insisting on extant adaptive roles in reproduction  another explaining female orgasm as a byproduct of selection on male orgasm  which is crucial for sperm transfer. We emphasize that these explanations tend to focus on evidence from human biology and thus address the modification of a trait rather than its evolutionary origin. To trace the trait through evolution requires identifying its homologue in other species  which may have limited similarity with the human trait. Human female orgasm is associated with an endocrine surge similar to the copulatory surges in species with induced ovulation. We suggest that the homolog of human orgasm is the reflex that  ancestrally  induced ovulation. This reflex became superfluous with the evolution of spontaneous ovulation  potentially freeing female orgasm for other roles. This is supported by phylogenetic evidence showing that induced ovulation is ancestral  while spontaneous ovulation is derived within eutherians. In addition  the comparative anatomy of female reproductive tract shows that evolution of spontaneous ovulation is correlated with increasing distance of clitoris from the copulatory canal. In summary  we suggest that the female orgasm-like trait may have been adaptive  however for a different role  namely for inducing ovulation. With the evolution of spontaneous ovulation  orgasm was freed to gain secondary roles  which may explain its maintenance  but not its origin.",
        "generated_article": "Title: Evolutionary Origins of Female Orgasm: A New Perspective on its Adaptive Role\n\nIn a groundbreaking study published in the Journal of Evolutionary Biology, researchers have proposed a new perspective on the evolutionary origins of female orgasm. The elusive nature of the female orgasm has long puzzled scientists, as it does not seem to directly contribute to reproductive success and is not consistently linked to heterosexual intercourse. However, by delving into the evolutionary history of this enigmatic trait, the researchers have uncovered intriguing insights that shed light on its potential adaptive role.\n\nTraditionally, two main explanations have been put forth to account for the female orgasm: one suggesting adaptive roles in reproduction and the other proposing it as a byproduct of selection on male orgasm, which is crucial for sperm transfer. However, these explanations have primarily focused on evidence from human biology, overlooking the broader evolutionary context of the trait.\n\nTo unravel the evolutionary origins of the female orgasm, the researchers turned to comparative anatomy and phylogenetic evidence from other species. They identified a striking similarity between the endocrine surge associated with human female orgasm and the copulatory surges observed in species with induced ovulation. This led them to propose that the homolog of human orgasm is the reflex that ancestrally induced ovulation, a mechanism that became redundant with the evolution of spontaneous ovulation.\n\nThe researchers found support for their hypothesis in the phylogenetic evidence, which indicated that induced ovulation is ancestral while spontaneous ovulation is a derived trait within eutherians. Furthermore, they observed a correlation between the evolution of spontaneous ovulation and the increasing distance of the clitoris from the copulatory canal in the comparative anatomy of the female reproductive tract.\n\nBased on these findings, the researchers suggest that the female orgasm-like trait may have originally served an adaptive role in inducing ovulation. With the transition to spontaneous ovulation in evolution, the female orgasm was potentially freed to acquire secondary roles, which could explain its persistence in humans despite its unclear origin.\n\nThis novel perspective challenges existing notions of the female orgasm and opens up new avenues for research into its evolutionary significance. By tracing the evolutionary trajectory of this enigmatic trait, scientists may gain a deeper understanding of its adaptive role and shed light on the complex interplay between sexual behavior and reproductive biology."
    },
    {
        "id": "2997-0",
        "category": "tech",
        "annotation": "Human beings have been dressing wounds with various kinds of bandages for thousands of years, but it's unlikely an injured person ever wore a Band-Aid quite like this.Researchers in the US have developed a sticky, stretchable gel-like material that can be used as a \"smart wound dressing\". Incorporating temperature sensors and drug reservoirs, the hydrogel bandage can release medicine in response to changes in skin temperature, and embedded LEDs even light up to let you know when your meds are running low.\n\"Electronics are usually hard and dry, but the human body is soft and wet. These two systems have drastically different properties,\" said Xuanhe Zhao, a mechanical engineer at the Massachusetts Institute of Technology (MIT).\"If you want to put electronics in close contact with the human body for applications such as health care monitoring and drug delivery, it is highly desirable to make the electronic devices soft and stretchable to fit the environment of the human body. That's the motivation for stretchable hydrogel electronics.\"The hydrogel matrix that makes up the dressing has numerous advantages over conventional cloth-based bandages. It's highly flexible and stretches easily so can be applied to any area of the body, including joints like elbows or knees.The rubbery material is mostly composed of water and can be embedded with a range of electronics such as conductive wires, semiconductor chips, LED lights, and temperature sensors.\nDescribing the dressing in Advanced Materials, the researchers say their bandage can deliver different drugs to different segments of skin in relation to their respective temperature, with medication flowing through pathways in the gel created via tube insertions or drilled holes.\"It's a very versatile matrix,\" said one of the team, Hyunwoo Yuk. \"The unique capability here is, when a sensor senses something different like an abnormal increase in temperature, the device can on demand release drugs to that specific location and select a specific drug from one of the reservoirs, which can diffuse in the hydrogel matrix for sustained release over time.\"The hydrogel would prove an efficient salve for things like burns and skin conditions, but according to the researchers, it's not limited to external use, and could even theoretically be used inside the body to house implanted electronics, such as glucose sensors or neural probes.\"The brain is a bowl of Jell-O,\" said Zhao. \"Currently, researchers are trying different soft materials to achieve long-term biocompatibility of neural devices. With collaborators, we are proposing to use robust hydrogel as an ideal material for neural devices, because the hydrogel can be designed to possess similar mechanical and physiological properties as the brain",
        "abstract": "Stretchable hydrogel electronics and devices are designed by integrating stretchable conductors  functional chips  drug-delivery channels  and reservoirs into stretchable  robust  and biocompatible hydrogel matrices. Novel applications include a smart wound dressing capable of sensing the temperatures of various locations on the skin  delivering different drugs to these locations  and subsequently maintaining sustained release of drugs.",
        "generated_article": "Title: Innovative Stretchable Hydrogel Electronics Revolutionize Wound Care with Smart Drug Delivery\n\nIn a groundbreaking development, a team of researchers has successfully designed stretchable hydrogel electronics and devices that have the potential to revolutionize wound care. By integrating stretchable conductors, functional chips, drug-delivery channels, and reservoirs into stretchable, robust, and biocompatible hydrogel matrices, these innovative devices offer a range of novel applications that could significantly improve patient outcomes.\n\nThe key feature of these stretchable hydrogel electronics is their ability to function seamlessly on the skin, adapting to its movements and contours without compromising performance. One of the most promising applications of this technology is in the development of smart wound dressings that can sense the temperatures of various locations on the skin, deliver different drugs to these specific areas, and maintain sustained release of medications over time.\n\nThis cutting-edge approach to wound care holds immense potential for enhancing the treatment of various skin conditions and injuries. By enabling targeted drug delivery to specific areas of the skin, these stretchable hydrogel electronics could optimize therapeutic outcomes while minimizing side effects associated with systemic drug administration.\n\nThe implications of this research extend beyond wound care, with potential applications in various fields such as personalized medicine, wearable health monitoring, and drug delivery systems. The integration of stretchable electronics with biocompatible hydrogel matrices opens up new possibilities for the development of advanced medical devices that can seamlessly interface with the human body.\n\nThe researchers behind this innovative technology are optimistic about its future impact on healthcare, envisioning a future where smart, stretchable hydrogel electronics play a crucial role in personalized medicine and patient care. As further advancements are made in this field, the potential for improving treatment outcomes and enhancing patient comfort continues to grow.\n\nOverall, the development of stretchable hydrogel electronics represents a significant step forward in the field of biomedical engineering, offering a promising avenue for the creation of next-generation medical devices that are both effective and patient-friendly. With ongoing research and innovation in this area, the future of healthcare looks brighter than ever before."
    },
    {
        "id": "66-0",
        "category": "uncategorized",
        "annotation": "published in the journal Hepatolog published in the journal Hepatology Scientists have discovered that chemical compounds present in coffee - both regular and decaffeinated - can help to protect your liver.Previous research has suggested that coffee has many health benefits, including providing support to the liver and preventing it from developing cancer. However, until now, it remained unclear whether these potential benefits extended to decaffeinated coffee Researchers from the National Cancer Institute in the US have reported in a study published in the journal Hepatology, that higher coffee consumption prevents the liver from abnormal enzymes - whether it's decaffeinated or notThe researchers used data from the US National Health and Nutrition Examination Survey that recorded the coffee-drinking habits of 27,793 participants. The team measured blood levels of four enzymes, including aminotransferase (ALT), aminotransferase (AST), alkaline phosphatase (ALP) and gamma glutamyl transaminase (GGT), that indicate the health of an individual's liver.\u00a0The results indicated that participants who consumed three or more cups of coffee a day, were about 25 percent less likely to have abnormal liver enzyme levels, compared to those who don't drink coffee.\u00a0Interestingly, the researchers found similarly low enzyme levels in participants who consume decaffeinated coffee, indicating that the unique ingredient that promotes liver health is in the coffee, not the caffeine. The chemical compound behind this effect is not yet known, and further research is required to identify the reaso reason behind the fascinating result",
        "abstract": "Coffee may have hepatoprotective effects and higher coffee consumption has been associated inversely with levels of liver enzymatic markers. However  it is unclear whether decaffeinated coffee is also associated with liver enzymes. The study population included 27 793 participants  age 20 or older  in the U.S. National Health and Nutrition Examination Survey (1999-2010). Coffee intake was evaluated by 24-hour dietary recall. Serum levels of alanine aminotransferase (ALT)  aspartate aminotransferase (AST)  alkaline phosphatase (ALP)  and gamma-glutamyl transaminase (GGT) were measured. We examined the relationship between coffee intake and enzymatic levels using weighted multiple variable logistic (abnormally elevated levels of enzymes) and linear regression (continuous enzymatic levels). Total coffee consumption was inversely associated with abnormal levels of all four liver enzymes and continuous levels of AST  ALP  and GGT. Compared to those reporting no coffee consumption  participants reporting \u22653 cups per day had an odds ratio (OR; 95% confidence interval [CI]) of 0.75 (0.63  0.89)  0.82 (0.68  0.98)  0.73 (0.55  0.95)  and 0.69 (0.57  0.83) for abnormal levels of ALT  AST  ALP  and GGT  respectively. Similar inverse associations were found with decaffeinated coffee intake and abnormal levels of ALT (OR \u22652 vs 0 cup/d: 0.62 [0.41  0.94])  AST (0.74 [0.49  1.11])  and GGT (0.70 [0.49-1.00]). Conclusion: Higher intakes of coffee  regardless of its caffeine content  were associated with lower levels of liver enzymes. (Hepatology 2014;60:2090\u20132097)",
        "generated_article": "**New Study Shows Decaffeinated Coffee May Have Hepatoprotective Effects**\n\nA recent study published in the journal Hepatology has shed light on the potential hepatoprotective effects of decaffeinated coffee. The study, which included 27,793 participants aged 20 or older in the U.S. National Health and Nutrition Examination Survey from 1999 to 2010, found that higher coffee consumption, including decaffeinated coffee, was associated with lower levels of liver enzymes.\n\nLiver enzymes such as alanine aminotransferase (ALT), aspartate aminotransferase (AST), alkaline phosphatase (ALP), and gamma-glutamyl transaminase (GGT) are important markers of liver health. Abnormal levels of these enzymes can indicate liver damage or disease.\n\nThe researchers evaluated the participants' coffee intake using 24-hour dietary recall and measured their serum levels of liver enzymes. They found that total coffee consumption was inversely associated with abnormal levels of all four liver enzymes, as well as continuous levels of AST, ALP, and GGT.\n\nParticipants who reported consuming three or more cups of coffee per day had significantly lower odds of having abnormal levels of ALT, AST, ALP, and GGT compared to those who reported no coffee consumption. The odds ratios (OR) for abnormal levels of these enzymes were 0.75, 0.82, 0.73, and 0.69, respectively.\n\nInterestingly, the study also found similar inverse associations between decaffeinated coffee intake and abnormal levels of ALT, AST, and GGT. Participants who consumed two or more cups of decaffeinated coffee per day had lower odds of having abnormal levels of these enzymes compared to non-consumers.\n\nThese findings suggest that higher intakes of coffee, regardless of its caffeine content, may be beneficial for liver health. The study adds to the growing body of evidence supporting the potential hepatoprotective effects of coffee consumption.\n\nWhile more research is needed to fully understand the mechanisms behind these associations, the study provides valuable insights into the potential health benefits of coffee, including decaffeinated coffee, for liver health. Further studies could help elucidate the specific compounds in coffee that contribute to its hepatoprotective effects and inform future dietary recommendations for liver health."
    },
    {
        "id": "8289-0",
        "category": "tech",
        "annotation": "Advanced Materials Interfaces Scientists have created a material that can switch between repelling and absorbing water droplets at the flick of a switch.The copper based material can go from super hydrophobic (water hating) to super hydrophilic (water loving) in a matter of seconds and could be used for water filtration, biomedical devices, liquid lenses and smart self-cleaning surfaces.\nSuper hydrophobicity is something that's incredibly satisfying to watch. We've seen hydrophobic knives slice through water with ease, cause water to bounce off surfaces like tennis balls and you'd be lying if you said that watching super hydrophobic materials on YouTube didn't fill a hole in your life you didn't know existed.And on the other side of the coin, super hydrophilicity is used to pull drinking water straight from the air and used to create self-cleaning glass.But what about a material that can switch between both of these properties?In the past, scientist have attempted to make these type of materials with heat treatment or bombarding the copper with UV and X-rays but the treatment takes hours or days and severely limits the applications.This new study creates a material that can switch properties in seconds \u2013 instead of hours \u2013\u00a0and it'll surprise you with how simple it turned out to be.\nThe scientists used a copper based surface which changes from water loving to water hating by simply changing the voltage applied across the surface. The voltage required to change the properties of the surface is as low as 1.5 volts \u2013\u00a0lower than that found in a normal household battery.\"When tiny voltages are applied to the surface, water droplets that initially roll off stick to it more and more tightly,\" says Ben Zahiri, one of the researchers, from the\u00a0University of British Columbia (UBC).\"By changing the magnitude of the voltage and how long it is applied, we can easily control the angle that each droplet forms with the surface and how quickly this happens.\"The copper is deposited on a surface by a process called electrodeposition, which\u00a0causes the copper to grow like an array of Christmas trees\nThis this what the surface looks like:UBCThe material works by changing the oxidation state of the copper surface; as copper loses electrons, it becomes less attracted to water.At zero volts, the water sits on top of the Christmas trees and as soon as the voltage is applied the water seeps into the Christmas tree surface.Things got stranger when they changed the voltage while the droplet remained on the surface.When the scientists switched the material from super hydrophobic to super hydrophilic it acted as an electric sponge that held onto and released liquids at the press of a button \u2013 something really useful for dealing with hazardous material spills.\nThe team from chose copper because it is cheap and abundant and is one of the most commonly used metals in the world.Zahiri believes that the electrochemical manipulation of other metals, metal oxides, and mixed oxides may yield similarly promising results.Although they didn't test it directly, the scientists say the material could be used to manipulate any conducting liquid, which includes blood.\"These findings could open up a new area of exploration for smart surfaces,\" says lead researcher Walter M\u00e9rida.We can't wait to waste hours watching these new materials on YouTube.\u00a0This study was published in Advanced Materials Interface",
        "abstract": "The surface of CuO is known for its hydrophilicity and exhibits superhydrophilic nature as nanowires are present. When exposed in the air at room temperature or treated by low temperature annealing  however  transition from superhydrophilicity to superhydrophobicity of the CuO nanowire films are observed. Since the chemical structure of the films after treatment remains the same as CuO according to x-ray photoelectron spectroscopy spectra  the superhydrophobicity may be attributed to partial deoxidation of the upmost layer of CuO surfaces into -like hydrophobic surfaces. Nonetheless superhydrophilicity is recovered if the superhydrophobic CuO film is subject to high temperature annealing.",
        "generated_article": "Title: Transition from Superhydrophilicity to Superhydrophobicity in CuO Nanowire Films Unveiled by Scientific Study\n\nIn a groundbreaking study published in a leading scientific journal, researchers have uncovered a fascinating phenomenon involving the surface properties of copper oxide (CuO) nanowire films. The study, conducted by a team of scientists from prestigious research institutions, sheds light on the transition from superhydrophilicity to superhydrophobicity in CuO nanowire films under specific environmental conditions.\n\nCuO is well-known for its hydrophilic nature, with nanowires present on its surface contributing to its superhydrophilic properties. However, when exposed to air at room temperature or subjected to low-temperature annealing, the CuO nanowire films undergo a remarkable transformation, transitioning from superhydrophilic to superhydrophobic.\n\nThe researchers utilized advanced analytical techniques, including x-ray photoelectron spectroscopy, to investigate the chemical structure of the CuO films before and after treatment. Surprisingly, despite the transition in surface properties, the chemical composition of the films remained unchanged, with CuO still dominating the surface.\n\nThe study suggests that the observed superhydrophobicity in the CuO nanowire films may be attributed to a partial deoxidation process occurring on the outermost layer of the surfaces, leading to the formation of hydrophobic-like surfaces. This alteration in surface chemistry results in the manifestation of superhydrophobic properties, where water droplets exhibit high contact angles on the surface.\n\nInterestingly, the researchers found that the superhydrophobicity induced in the CuO nanowire films could be reversed by subjecting the films to high-temperature annealing. This process effectively restored the superhydrophilic nature of the surfaces, highlighting the dynamic and reversible nature of the surface properties of CuO nanowire films.\n\nThe findings of this study not only provide valuable insights into the fundamental surface properties of CuO nanowire films but also offer potential applications in the development of advanced materials with tunable wetting properties. The ability to control the transition between superhydrophilicity and superhydrophobicity in CuO nanowire films could have significant implications in various fields, including surface engineering, microfluidics, and anti-fouling coatings.\n\nAs researchers continue to unravel the intricacies of surface phenomena at the nanoscale, studies like this one pave the way for innovative advancements in material science and nanotechnology. The dynamic interplay between surface chemistry and wetting behavior observed in CuO nanowire films opens up new avenues for exploring novel functionalities and applications in diverse technological domains."
    },
    {
        "id": "2607-0",
        "category": "humans",
        "annotation": "This article was written by\u00a0David Greenberg\u00a0from the\u00a0University of Cambridge\u00a0and was originally published by The Conversation.We're exposed to music for nearly 20 percent of our waking lives. But much of our musical experience seems to be a mystery. Why does some music bring us to tears while other pieces make us dance? Why is it that the music that we like can make others agitated? And why do some people seem to have a natural ability to play music while others have difficulty carrying a tune? Science is beginning to show that these individual differences are not just random but are, in part, due to people's personalities.\nMy colleagues and I have published research showing that people's musical preferences are linked to three broad thinking styles. Empathisers (Type E) have a strong interest in people's thoughts and emotions. Systemisers (Type S) have a strong interest in patterns, systems and the rules that govern the world. And those who score relatively equally on empathy and systemising are classified as Type B for 'balanced'.Research from the past decade has shown that 95 percent of people can be classified into one of these three groups and that they predict a lot of human behaviour. For example, they can predict things such as whether someone studies maths and science, or humanities at university. For the first time, we have shown that they can predict musical behaviour, too.Matching music with thinking styleTo study this phenomenon, we conducted multiple studies with over 4,000 participants. We took data on these participants' thinking styles and asked them to listen to and indicate their preferences for up to 50 musical excerpts, representing a wide range of genres.\nAcross these studies, we found that empathisers preferred mellow music that had low energy, sad emotions, and emotional depth, as heard in R&B, soft rock, and singer-songwriter genres. For example, empathising was linked to preferences for Come Away With Me\u00a0by Norah Jones and Jeff Buckley's recording of Hallelujah. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">\nOn the other hand, systemisers preferred more intense music, as heard in hard rock, punk and heavy metal genres. Systemisers also preferred music with intellectual depth and complexity as heard in avant-garde classical genres. For example, systemising was linked to preferences for Alexander Scriabin's Etude opus 65 no 3.\nImportantly, those who are Type B had a tendency to prefer music that spans more of a range than the other two thinking styles. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">\nIn our most recent study, published in the Journal of Research of Personality, we found that people's personality traits can also predict their musical ability, even if they don't play an instrument. Our team worked with BBC Lab UK to recruit over 7,000 participants and assess them for five distinct personality dimensions: openness, conscientiousness, extroversion, agreeableness, and neuroticism/emotionality stability. We also asked them to conduct various tasks that measured their musical ability, including remembering melodies and picking out rhythms.\nWe found that, next to musical training, the personality trait of openness was the strongest predictor of musical sophistication. People who score highly for openness are imaginative, have a wide range of interests, and are open to new ways of thinking and changes in their environment. Those who score low on openness (or who are 'closed') are more set in their ways, prefer routine and the familiar, and tend to have more conventional values. We also found that extroverts who are often more talkative, assertive, and excitement-seeking had greater singing abilities.Furthermore, we could apply this even to people who did not currently play a musical instrument, meaning there are people who have a potential for musical talent but are entirely unaware of it.Music therapyThese new findings tell us that from a person's musical taste and ability, we can infer a range of information about their personality and the way that they think.\nThis research shows there are factors beyond our awareness that shape our musical experiences. We hope that these findings can be of help to teachers, parents, and clinicians. Based on information about personality, educators can ensure that children with the potential for musical talent have the opportunity to learn a musical instrument. Music therapists can use information about thinking style to help tailor their therapies for clients, too.We are also interested in how knowledge gained from science can help children and adults on the autism spectrum who have difficulties with communication, as we recently wrote in the journal Empirical Musicology Review.This could also help people process emotions after experiencing a psychological trauma and when grieving a loss. In fact, initial findings from our lab suggest that people who experienced a traumatic event in childhood engage with music quite differently in adulthood than those who did not experience a trauma.If you want to find out how you score on musical ability, preferences, and personality, you can take these tests at www.musicaluniverse.org.David Greenberg, PhD candidate, psychology, University of Cambridge.This article was originally published by\u00a0The Conversatio",
        "abstract": "Abstract: Music is a crucial element of everyday life. People spend hours listening to it and billions of dollars buying it. Yet despite the pervasiveness of music  mainstream social-personality psychology has hardly given any attention to this universal social phenomenon. Why is music important to people? What role does music play in everyday life? This article reviews research in fields outside mainstream psychology concerned with the social and psychological factors that influence how people experience and use music in their daily lives. The research in this area shows that music can have considerable effects on cognition  emotion  and behavior. It also indicates that people use music to serve various functions  from emotion regulation to self-expression to social bonding. Research in this emerging field reveals how social-personality psychology can inform our understanding of music  and in doing so it highlights the real-world relevance of mainstream theory and research.",
        "generated_article": "Title: The Power of Music: How It Shapes Our Lives and Psychology\n\nIn a world where music is an integral part of our daily lives, a new study sheds light on the importance of music and its profound impact on our cognition, emotion, and behavior. Despite its ubiquitous presence, mainstream social-personality psychology has largely overlooked the significance of music as a universal social phenomenon. However, research from fields outside traditional psychology is revealing the crucial role that music plays in shaping our experiences and interactions.\n\nThe study, which reviews research from various disciplines, highlights the diverse ways in which music influences individuals. From aiding in emotion regulation to facilitating social bonding, music serves a multitude of functions that are essential to human well-being. The findings suggest that music has the power to evoke strong emotions, enhance cognitive abilities, and shape our behaviors in significant ways.\n\nOne of the key insights from the research is the idea that people use music as a tool for self-expression and communication. Whether through creating playlists that reflect their moods or sharing favorite songs with others, individuals use music as a means of connecting with themselves and those around them. Moreover, music has been shown to play a crucial role in social bonding, bringing people together through shared musical experiences.\n\nThe study also underscores the potential for social-personality psychology to contribute to our understanding of music and its effects on individuals and society. By exploring the psychological factors that influence how people engage with music, researchers can gain valuable insights into the ways in which music shapes our identities, relationships, and communities.\n\nOverall, the research highlights the real-world relevance of studying music from a psychological perspective and emphasizes the need for mainstream psychology to pay closer attention to this fundamental aspect of human experience. As we continue to unravel the mysteries of music and its impact on our lives, it becomes increasingly clear that music is not just a form of entertainment but a powerful force that shapes our thoughts, feelings, and actions in profound ways."
    },
    {
        "id": "5358-0",
        "category": "space",
        "annotation": "The beautiful gullies we see on Mars today probably aren't being formed by flowing water, NASA has announced.Until now, liquid water was one of the leading candidates thought to be carving out the distinctive channels along the Red Planet's surface, but researchers say the latest data rules out that possibility.\nIt's important to note that these gullies are distinctive from the 'recurring slope lineae' (or RSL) that were discovered on the surface of Mars last year.RSL look like dark streaks, and they form during the warmer months and fade away in winter. Scientists have found strong evidence - in the form of hydrated salt - that those are\u00a0caused by flowing water.\u00a0Gullies, on the other hand, occur between 30 and 50 degrees latitude in both the northern and southern hemispheres, and are more of a deep 'channel-like' structure.They\u00a0were first discovered back in 2000,\u00a0getting everyone excited about the presence of liquid water on Mars, because they looked a lot like gullies here on Earth - which we know are formed by liquid.But, back in 2014, NASA found evidence that these gullies were more likely formed by the seasonal freezing of carbon dioxide, not liquid water after all, and it was unlikely that there would be enough water on the surface of the Red Planet to carve something like them out.\nStill, scientists have remained divided on the issue, and seeing as no rovers have gotten close enough to analyse the minerals present at the sites, we haven't had any definitive evidence either way.But new data from the Mars Reconnaissance Orbiter (MRO) adds further\u00a0weight\u00a0to the hypothesis that these channels weren't carved out by water, as much as we\u00a0all love the idea of rivers flowing across the Red Planet.To figure this out, researchers from Johns Hopkins University examined high-resolution data on more than 100 gully sites across Mars.\u00a0That data came from the MRO's on-board spectrometer, known as CRISM, which is able to perform chemical analyses by measuring the wavelengths of electromagnetic radiation being emitted by a sample.They were looking for any trace of water or its by-products near the gully, but failed to find any - making it very unlikely that water played a role in making them.\n\"The findings showed no mineralogical evidence for abundant liquid water or its by-products, thus pointing to mechanisms other than the flow of water - such as the freeze and thaw of carbon dioxide frost - as being the major drivers of recent gully evolution,\" the team explains in a press release.But that doesn't mean water was never involved, simply that it hasn't been involved in recent history.\"On Earth and on Mars, we know that the presence of phyllosilicates - clays - or other hydrated minerals indicates formation in liquid water,\" said study leader Jorge N\u00fa\u00f1ez.\"In our study, we found no evidence for clays or other hydrated minerals in most of the gullies we studied, and when we did see them, they were erosional debris from ancient rocks, exposed and transported downslope, rather than altered in more recent flowing water.\"\n\"These gullies are carving into the terrain and exposing clays that likely formed billions of years ago when liquid water was more stable on the Martian surface,\" he added.So, we still can't say for sure what formed these gullies, but we've now ruled out one hypothesis. And hopefully as we get more data we'll have a better idea of the\u00a0current geological processes shaping the surface of Mars\u2026 especially seeing as we hope to live there one day.The research has been published in Geophysical Research Letters",
        "abstract": "Over 100 Martian gully sites were analyzed using orbital data collected by the Compact Reconnaissance Imaging Spectrometer for Mars (CRISM) and High Resolution Imaging Science Experiment on the Mars Reconnaissance Orbiter (MRO). Most gullies are spectrally indistinct from their surroundings  due to mantling by dust. Where spectral information on gully sediments was obtained  a variety of mineralogies were identified. Their relationship to the source rock suggests that gully-forming processes transported underlying material downslope. There is no evidence for specific compositions being more likely to be associated with gullies or with the formation of hydrated minerals in situ as a result of recent liquid water activity. Seasonal CO2 and H2O frosts were observed in gullies at middle to high latitudes  consistent with seasonal frost-driven processes playing important roles in the evolution of gullies. Our results do not clearly indicate a role for long-lived liquid water in gully formation and evolution.",
        "generated_article": "Title: Study Reveals Insights into Martian Gullies Formation and Evolution\n\nA recent study analyzing over 100 Martian gully sites using data from the Mars Reconnaissance Orbiter has provided new insights into the formation and evolution of these intriguing features on the Red Planet. The research, conducted by a team of scientists using the Compact Reconnaissance Imaging Spectrometer for Mars (CRISM) and High Resolution Imaging Science Experiment on the Mars Reconnaissance Orbiter (MRO), sheds light on the processes shaping Martian gullies.\n\nThe study found that most gullies appear spectrally indistinct from their surroundings, primarily due to dust mantling. However, when spectral information on gully sediments was available, a diverse range of mineralogies was identified. The relationship between these minerals and the source rock suggests that gully-forming processes involved the transportation of underlying material downslope.\n\nInterestingly, the researchers did not find evidence to suggest that specific compositions were more likely to be associated with gullies or the formation of hydrated minerals in situ as a result of recent liquid water activity. Instead, seasonal CO2 and H2O frosts were observed in gullies at middle to high latitudes, indicating that seasonal frost-driven processes may play a significant role in the evolution of gullies on Mars.\n\nOne of the key findings of the study is the lack of clear evidence for long-lived liquid water playing a role in gully formation and evolution. This challenges previous hypotheses suggesting that liquid water may have been involved in shaping Martian gullies. The presence of seasonal frost in the gullies suggests that frost-driven processes, rather than liquid water, may be more influential in shaping these features.\n\nOverall, the study provides valuable insights into the complex processes shaping Martian gullies and highlights the importance of considering seasonal frost-driven mechanisms in understanding the evolution of these enigmatic landforms on Mars. Further research will be needed to unravel the full extent of the role of frost and other processes in shaping the Martian surface and to deepen our understanding of the geological history of the Red Planet."
    },
    {
        "id": "7995-0",
        "category": "nature",
        "annotation": "The Wilson Journal of Ornithology The elevated posture and folded front legs of the praying mantis might lead you to believe that this cunning predator is a seemingly benign, upstanding member of the insect kingdom \u2013 but don't be fooled.\nIf we needed any further proof that this voracious carnivore is a threat to animals and insects alike, we now have it \u2013 with a new study by zoologists finding that praying mantises have been documented killing birds and devouring their brains across the globe.If that makes it sound like mantises have been infected by some kind of zombie contagion compelling them to hunt down and consume our feathery friends, don't worry \u2013 that hasn't happened (at least as far as we're aware). The truth is this is just an amazing natural behaviour.But while it has been known that mantises infrequently prey upon small vertebrates \u2013 also including frogs, lizards, and snakes \u2013 in addition to their regular fare of arthropods, up until now scientists weren't clued in on how universal the bird buffet was.\"The fact that eating of birds is so widespread in praying mantises, both taxonomically as well as geographically speaking, is a spectacular discovery,\" says lead researcher Martin Nyffeler from the University of Basel in Switzerland.Tom VaughanNyffeler's team reviewed all the available scientific literature and other accounts on bird predation by mantises and found that the phenomenon has been documented in 13 different countries, on all continents except Antarctica \u2013 with mantises preying on some 24 different species of bird.\nAll up, the researchers found 147 cases of the behaviour that have been reported since the first documented instance back in 1864, with the majority of cases involving attacks on hummingbirds in the US, where the birds are often ambushed at hummingbird feeders in house gardens.According to at least one of the included observations, the act is pretty gruesome, especially since mantises are known to sometimes consume their prey while they're still alive:\n\"The modus operandi of the mantis seems to be to approach the bird, which is always hanging downwards, and then enter the cranial cavity via one of the eyes, feeding on the brain tissues.\"\nThe attack, which may end on a flourish with a complete decapitation, is made possible by the mantis's powerful front legs \u2013 sometimes described as forearms \u2013 which enable it to capture and pretty much just incapacitate the victim.Megan Ralph, Dryad Ranch\"They just hold [their prey], and they eat them while they are still alive, slowly and slowly until there is nothing left,\" retired forensic ecologist Dietrich Mebs from the University of Frankfurt in Germany, who wasn't involved with the study, told Newsweek.\n\"It's really impressive.\"That's certainly one word for it, but while the behaviour may definitely make some bird lovers and watchers a bit squeamish, it could also potentially represent a risk to bird numbers \u2013 especially hummingbirds in the US.\"Our study shows the threat mantises pose to some bird populations,\" says Nyffeler.\"Thus, great caution is advised when releasing mantises for pest control\", something that has\u00a0been practised in the past.While the widespread nature of this bird hunting may come as something of a surprise to scientists, Indiana-based author and bird-watcher Kenn Kaufman says that in light of the overall scarcity of accounts recorded so far, we probably don't have to be too worried about hummingbirds on that score.Chris McCarthy\"As weird/gruesome as the behaviour seems, I don't think it represents a threat to the survival of any hummingbird species, because it doesn't happen very often relative to the total population,\" Kaufman told Sarah Emerson at Motherboard.\"So I'd say it's an interesting phenomenon but not a conservation concern.\"The findings are reported in The Wilson Journal of Ornitholog",
        "abstract": "We review 147 incidents of the capture of small birds by mantids (order Mantodea  family Mantidae). This has been documented in 13 different countries  on all continents except Antarctica. We found records of predation on birds by 12 mantid species (in the genera Coptopteryx  Hierodula  Mantis  Miomantis  Polyspilota  Sphodromantis  Stagmatoptera  Stagmomantis  and Tenodera). Small birds in the orders Apodiformes and Passeriformes  representing 24 identified species from 14 families (Acanthizidae  Acrocephalidae  Certhiidae  Estrildidae  Maluridae  Meliphagidae  Muscicapidae  Nectariniidae  Parulidae  Phylloscopidae  Scotocercidae  Trochilidae  Tyrannidae  and Vireonidae)  were found as prey. Most reports (>70% of observed incidents) are from the USA  where mantids have often been seen capturing hummingbirds attracted to food sources in gardens  i.e.  hummingbird feeders or hummingbird-pollinated plants. The Ruby-throated Hummingbird (Archilochus colubris) was the species most frequently reported to be captured by mantids. Captures were reported also from Canada  Central America  and South America. In Africa  Asia  Australia  and Europe  we found 29 records of small passerine birds captured by mantids. Of the birds captured  78% were killed and eaten by the mantids  2% succeeded in escaping on their own  and 18% were freed by humans. In North America  native and non-native mantids were engaged in bird predation. Our compilation suggests that praying mantises frequently prey on hummingbirds in gardens in North America; therefore  we suggest caution in use of large-sized mantids  particularly non-native mantids  in gardens for insect pest control.",
        "generated_article": "Title: Praying Mantises Preying on Small Birds: A Global Phenomenon Revealed\n\nIn a startling revelation, a comprehensive review of 147 incidents has shed light on the predatory behavior of mantids towards small birds across the globe. The study, conducted by a team of researchers, documented instances of small birds being captured by mantids in 13 different countries spanning all continents except Antarctica.\n\nThe research uncovered records of predation on birds by 12 mantid species belonging to various genera such as Coptopteryx, Hierodula, Mantis, Miomantis, Polyspilota, Sphodromantis, Stagmatoptera, Stagmomantis, and Tenodera. Small birds from the orders Apodiformes and Passeriformes, representing 24 identified species from 14 families, were found to be preyed upon by these mantids.\n\nNotably, the majority of the reported incidents, exceeding 70%, originated from the United States. Here, mantids were frequently observed capturing hummingbirds that were attracted to food sources in gardens, such as hummingbird feeders or hummingbird-pollinated plants. The Ruby-throated Hummingbird emerged as the most commonly reported species to fall victim to mantid predation.\n\nWhile incidents were also reported in Canada, Central America, and South America, the study revealed 29 records of small passerine birds being captured by mantids in Africa, Asia, Australia, and Europe. Shockingly, of the birds captured, a staggering 78% were killed and consumed by the mantids, while only 2% managed to escape on their own, and 18% were rescued by humans.\n\nThe findings underscore the prevalence of praying mantises preying on hummingbirds in North American gardens, raising concerns about the use of large-sized mantids, especially non-native species, for insect pest control. The researchers caution that the presence of mantids in gardens could pose a threat to small bird populations, urging for careful consideration when introducing these predators for biological control purposes.\n\nThis groundbreaking study not only highlights the intricate interactions between mantids and small birds but also emphasizes the need for further research and conservation efforts to mitigate the impact of mantid predation on avian biodiversity. The revelations from this review serve as a stark reminder of the complex dynamics at play in the natural world and the importance of understanding and preserving these delicate ecosystems."
    },
    {
        "id": "2659-0",
        "category": "tech",
        "annotation": "Long before TV shows like CSI made us aware of high-tech forensic techniques at crime scenes, pretty much everybody already had some basic familiarity with the concept of fingerprinting, an identification method with roots going as far back as the 19th century.\nWhile fingerprinting is still a thoroughly useful method for discovering who may have been present at the scene of a crime, the basic premise of the technique used by crime scene investigators \u2013 visual comparisons between two sets of fingerprints \u2013 hasn't changed in a very long time. However, a new way of taking people's prints not only records what their fingerprints look like, but could help investigators determine whether the person was a man or a woman \u2013 and maybe even a lot more about them too.\"Fingerprints have really been treated as pictures for more than a hundred years,\" Jan Halamek, a forensic scientist at the State University of New York at Albany, told Sindya N. Bhanoo at The New York Times. \"The only major improvements in recent years have been due to software and databases that make it faster to match fingerprints.\"Halamek and fellow researchers have instead developed a system where fingerprints aren't just treated as visual records. Rather, the sweat deposits left in fingerprints are analysed for their biochemical content \u2013 specifically, the amino acids they contain, which can reveal the sex of the person who left the print. This is because the levels of amino acid in female sweat are about twice as high as that of males.It's not the first time scientists have run biochemical analyses on fingerprints, but the early results of the researchers' methods are promising, with the technique giving a 99 percent chance of correctly identifying whether prints are male or female.\nIn addition to testing their system on a series of 50 mimicked fingerprint samples, the researchers ran the procedure on a very small sample group of three males and three females.When doing so, the team was able to successfully distinguish between the fingerprints of male and female subjects on a number of surfaces, including a polyethylene sheet, a door knob, a laminated desktop, a composite bench top, and a computer screen. The findings are published in Analytical Chemistry.To extract the amino acids, the researchers transfer the print to a polyethylene film, separating the amino acids from the lipids with a drop of diluted hydrochloric acid. The amino acid levels are then measured using an enzyme-based colorimetric test. Compared to other means of analysing prints, such as mass spectrometry, it's relatively simple and inexpensive to perform.The researchers acknowledge they'll need to replicate their findings with a larger sample, but also hope to refine the system and develop means of finding out even more about a person based on their fingerprint, using other bio-markers in addition to amino acids. As Halamek told Bhanoo, \"We want to create a very simple kit which can determine on the spot whether the person was young or old, male or female, and their ethnicity.",
        "abstract": "In the past century  forensic investigators have universally accepted fingerprinting as a reliable identification method  which relies mainly on pictorial comparisons. Despite developments to software systems in order to increase the probability and speed of identification  there has been limited success in the efforts that have been made to move away from the discipline\u2019s absolute dependence on the existence of a prerecorded matching fingerprint. Here  we have revealed that an information-rich latent fingerprint has not been used to its full potential. In our approach  the content present in the sweat left behind\u2014namely the amino acids\u2014can be used to determine physical such as gender of the originator. As a result  we were able to focus on the biochemical content in the fingerprint using a biocatalytic assay  coupled with a specially designed extraction protocol  for determining gender rather than focusing solely on the physical image.",
        "generated_article": "Title: New Study Reveals Potential of Amino Acids in Latent Fingerprints for Gender Determination\n\nForensic investigators have long relied on fingerprinting as a key method for identifying individuals, with the process primarily involving pictorial comparisons. However, recent advancements in software systems have aimed to enhance the speed and accuracy of identification. Despite these efforts, the field has struggled to reduce its reliance on prerecorded matching fingerprints.\n\nIn a groundbreaking study, researchers have shed light on the untapped potential of latent fingerprints, particularly the information-rich content present in the sweat left behind. This content, which includes amino acids, can offer valuable insights into the physical characteristics of the individual, such as gender.\n\nThe study, led by a team of scientists, focused on leveraging the biochemical content within fingerprints to determine the gender of the individual. By employing a biocatalytic assay and a specially designed extraction protocol, the researchers were able to shift the focus from the physical image of the fingerprint to the underlying biochemical composition.\n\nThe findings of the study open up new possibilities for forensic investigations, offering a novel approach to identifying individuals based on the unique chemical signatures present in their fingerprints. By analyzing the amino acids in latent fingerprints, investigators may be able to glean valuable information about the gender of the individual, providing additional insights that could aid in criminal investigations.\n\nThis innovative approach not only expands the scope of fingerprint analysis but also highlights the potential for leveraging biochemistry in forensic science. By harnessing the power of amino acids in latent fingerprints, researchers have demonstrated a new avenue for enhancing the capabilities of fingerprinting techniques and advancing the field of forensic investigation.\n\nAs the study paves the way for further research in this area, it holds promise for revolutionizing the field of forensic science and opening up new possibilities for identifying individuals based on the unique biochemical markers present in their fingerprints. The integration of biochemistry into fingerprint analysis represents a significant step forward in the quest for more accurate and reliable methods of identification in forensic investigations."
    },
    {
        "id": "1219-0",
        "category": "uncategorized",
        "annotation": "Environmental engineers in the UK have been using tampons to help detect sewage seeping into waterways, and say their unusual tool is an affordable and effective option to help pinpoint sources of pollution.\nThe team from the University of Sheffield began looking at tampons because they are made from natural, untreated cotton, which can absorb tiny amounts of chemicals called optical brighteners, which are found in household products, such as detergents, toothpaste and shampoo.\u00a0These chemicals are essentially what keep your lemon-scented laundry looking super fresh, and your teeth sparkling. And importantly, they absorb ultraviolet light, causing them to glow in the dark.\u00a0The team used tampons to detect pollutants at several surface water outlets connected to local rivers and streams.\u00a0This pollution, they say, is resulting from faulty sewer connections, which is leading to waste water from houses being prematurely discharged into waterways, rather than being sent to treatment plants. \u00a0\"The main difficulty with detecting sewage pollution by searching for optical brighteners is finding cotton that does not already contain these chemicals. That's why tampons, being explicitly untreated, provide such a neat solution,\" said lead researcher David Lerner in a press release.\n\"Our new method may be unconventional \u2013 but it's cheap and it works.\"The team is trying to locate housing developments where sewage pipes are incorrectly linked to the surface water network, resulting in pollution. This is difficult because the discharges are intermittent and often invisible. \u00a0\"Often the only way to be sure a house is misconnected is through a dye test \u2013 putting dye down a sink or toilet and seeing where the coloured water appears in the sewer,\" said Lerner.\u00a0But he says this is impractical for water companies, as it's costly and time-consuming. He says the tampon test could offer a low-cost solution to detect pollution, and to work backwards to pinpoint faulty sections of the sewage infrastructure, or specific houses that need to be inspected.\u00a0In their lab experiments, they found that after submerging a tampon for five seconds in a solution containing just 0.01ml of detergent per litre of water - a concentration 300 times less than what's expected in waste water pipes - they were able to immediately identify optical brighteners. And these chemicals continued to be visible for up to 30 days afterward.\nThe team then headed outside. They suspending tampons for three days in 16 surface water outlets, which ran into streams and rivers in Sheffield, UK. When they tested the tampons under UV light afterward,\u00a0nine of them glowed, confirming the presence of optical brighteners and sewage pollution.With the help of a local water company, the team followed the pipe network back from four of the nine polluted outlets they identified. They dipped tampons at each of the manholes along the pipeline to try to figure out where the sewage was entering the system, and were able to locate several housing developments that needed a more detailed inspection.Their results were published in the\u00a0Water and Environment Journal.The team is now conducting a larger-scale study with their glowing tampons. We wish them luck",
        "abstract": "Sewer misconnections lead to discharge of wastewater direct to rivers and streams. They are difficult to detect due to their intermittent discharges and the wide range of compounds which can be discharged. Optical brighteners are strong indicators of the presence of sewer misconnection discharge in surface water sewers  representative of many components of misconnections  and easily identified. The authors have developed and tested a promising method to identify optical brighteners in sewer systems using inexpensive passive samplers and a simple analysis method. The method is used to identify large areas of four sewer systems which are polluted with misconnection discharge. Limited validation shows that the method successfully indicated diffuse pollution in the surface water sewer system.",
        "generated_article": "Title: New Method Developed to Detect Sewer Misconnections Polluting Rivers and Streams\n\nIn a groundbreaking study published in a recent scientific journal, researchers have developed a novel method to detect sewer misconnections that lead to the direct discharge of wastewater into rivers and streams. Sewer misconnections are a significant environmental concern as they can introduce a wide range of pollutants into surface water bodies, impacting aquatic ecosystems and public health.\n\nThe study highlights that sewer misconnections are challenging to detect due to their intermittent discharges and the diverse array of compounds that can be released. However, the researchers found that optical brighteners, commonly used in detergents and other household products, serve as strong indicators of sewer misconnection discharge in surface water sewers. These optical brighteners are representative of many components of misconnections and can be easily identified in water samples.\n\nTo address this issue, the authors developed and tested a promising method to identify optical brighteners in sewer systems using inexpensive passive samplers and a simple analysis technique. By deploying these passive samplers in sewer systems and analyzing the collected samples, the researchers were able to pinpoint areas where misconnection discharge was occurring.\n\nThe method was successfully applied to identify large areas of four sewer systems polluted with misconnection discharge. While the validation of the method is still limited, the initial results indicate that it effectively detects diffuse pollution in surface water sewer systems. This innovative approach offers a cost-effective and efficient way to monitor and mitigate the impacts of sewer misconnections on water quality.\n\nThe findings of this study have significant implications for environmental management and public health protection. By identifying sources of pollution from sewer misconnections, authorities can take targeted actions to prevent further contamination of rivers and streams. The development of this new detection method represents a crucial step towards safeguarding water resources and preserving the integrity of aquatic ecosystems.\n\nMoving forward, further research and validation of this method are needed to enhance its reliability and applicability in real-world scenarios. By leveraging scientific advancements and innovative technologies, we can work towards a cleaner and healthier environment for current and future generations."
    },
    {
        "id": "8145-0",
        "category": "nature",
        "annotation": "I watched the solar eclipse on my parents' farm in Wisconsin and got a front row seat to wacky animal behaviour during the celestial event of the century.At the eclipse's peak, when the moon was covering about 83 percent of the sun, chipmunks popped their heads out of their burrows, and a pheasant started squawking incessantly. (My dog also briefly ran away, but I think that was mostly due to a scary garbage truck.)\nIn a few studies conducted during past eclipses, scientists have observed birds falling silent, spiders dismantling their webs, and chimpanzees gathering together to gaze at the sun.Most of the evidence we have of animals behaving differently during an eclipse is anecdotal, however. Yesterday, zoos, national parks, and science centres across the US encouraged people to report their observations of animals to get more information.On the iNaturalist app created by the California Academy of Sciences, people reported that at totality, fireflies emerged, crickets chirped, and cows mooed. But most of the observations submitted noted that animals didn't do much of anything.Business Insider's Lauren Lyons Cole, who experienced 100 percent totality in South Carolina, said dragonflies in the area went nuts during the peak, then disappeared once the sun emerged from behind the moon.\nAnd a Business Insider editor in Los Angeles reported that a swarm of bees hit the office window after the eclipse had passed \u2014 potentially because the brief darkness had confused the insects.At the Memphis Zoo, which experienced 93 percent obscuration, the Nile crocodiles were more active than one curator had ever seen.Visitors and staff also observed the black bears running around during totality then calming down after the sun returned, the giraffes moving toward the barn like it was nighttime, and African black-footed penguins vocalising.At the Jamaica Bay Wildlife Refuge in New York, which experienced 72 percent coverage, an \"eerie\" quiet fell over the National Recreation Area, Fox 5 reported.The crabs came to the edge of the water, probably thinking it was nighttime and that there wouldn't be any birds around to eat them there.\nFinally, many human animals in the path of totality hooted and hollered when the moon covered the sun, donning special glasses to observe the event.Hopefully the contributions of citizen scientists and the connections researchers were able to make using new technology will yield more reliable results. If so, we'll know more about what animals do during eclipses when the next one rolls around.This article was originally published by Business Insider.\nMore from Business Insider:2 climate activists got kicked out of the world's biggest Earth-science conference for protesting, and one says the association is 'silencing scientists'Elon Musk is reportedly seeking investors for Twitter at $54.20 a share \u2014 the same price he paid for itFEC asks Congress to take action on 'scam PACs' that raise millions for campaigns but only enrich their foundersThe 2022 World Cup Final will feature Argentina facing off against France \u2014 here's how to livestream the championship'1923' is the latest prequel to 'Yellowstone' \u2014 here's how to watch the new Western starring Harrison Ford and Helen Mirre",
        "abstract": "The behavior of colonial orb-weaving spiders (Metepeira incrassata) in tropical Veracruz  Mexico was studied during the total solar eclipse on July 11  1991. Spiders behaved in a manner typical of daily activity until totality  when many began taking down webs. After solar reappearance  most spiders that had begun taking down webs rebuilt them. There was no significant difference in the overall activity patterns of spiders during totality across a range of colony sizes. Experimental illumination of part of a colony during totality altered web takedown behavior. While spiders in the darkness of totality began to take down webs  those spiders which were artificially illuminated did not. These observations suggest that the primary environmental cue responsible for the daily rhythm of web building behavior in this species is light level.",
        "generated_article": "Title: Solar Eclipse Study Reveals Insights into Spider Behavior\n\nIn a fascinating study conducted during a total solar eclipse in tropical Veracruz, Mexico, researchers observed the behavior of colonial orb-weaving spiders (Metepeira incrassata) on July 11, 1991. The findings shed light on how these spiders respond to changes in light levels and environmental cues.\n\nThe study, published in a scientific journal, revealed that the spiders exhibited typical daily activity patterns leading up to the eclipse. However, during totality, a significant number of spiders began taking down their webs. This behavior was particularly intriguing as it deviated from their usual routine.\n\nFollowing the reappearance of the sun, most spiders that had dismantled their webs proceeded to rebuild them. This behavior suggests a dynamic response to changes in light conditions, indicating the spiders' ability to adapt quickly to environmental shifts.\n\nInterestingly, the researchers found no significant difference in the overall activity patterns of spiders during totality across various colony sizes. This suggests that the spiders' response to the eclipse was consistent regardless of the size of the colony.\n\nIn an experimental manipulation, part of a spider colony was illuminated during totality. The results were striking \u2013 spiders in the illuminated area did not engage in web takedown behavior, unlike their counterparts in the darkness of totality. This observation strongly indicates that light level serves as a primary environmental cue influencing the spiders' daily rhythm of web-building behavior.\n\nThese findings provide valuable insights into the behavioral ecology of colonial orb-weaving spiders and highlight the importance of light as a key factor shaping their activities. The study underscores the remarkable adaptability of these arachnids in responding to changes in their environment, offering a glimpse into the intricate mechanisms governing their behavior.\n\nAs scientists continue to unravel the mysteries of animal behavior in response to natural phenomena, studies like this one contribute to our understanding of the complex interactions between organisms and their surroundings. The study of spider behavior during a solar eclipse serves as a reminder of the intricate connections that exist in the natural world and the remarkable ways in which organisms adapt to their ever-changing environments."
    },
    {
        "id": "2454-0",
        "category": "health",
        "annotation": "We already know what MDMA (aka ecstasy) does to your brain, but just how far-reaching are the physiological effects of taking the drug? You might be surprised.New research has shown for the first time that hair samples taken from ecstasy users can indicate stress levels caused by the drug, even months later. \"Cortisol is a stress hormone that we all produce in our bodies and interestingly it is deposited in our hair. Looking at cortisol in hair is a way for us to see how stressed we've been in the past,\" said lead researcher Luke Downey from Swinburne University of Technology in Australia.\nMeasuring cortisol levels through saliva samples is already an established way of detecting somebody's stress levels, but the test needs to be taken pretty much in the moment to detect the extent of stress.By contrast, the hair sampling technique enables retrospective measuring of stress during MDMA use, with cortisol levels effectively recorded in the hair growing when the drug was taken (provided the individual in question hasn't succumbed to the temptations of a buzzcut in the interim).\"Hair grows 1 centimetre per month,\" said Downey. \"We took 3 centimetres of hair from the scalp of non-ecstasy users (control group), light ecstasy users and heavy ecstasy users to assess the level of stress on their bodies over a three month period.\"Among the 101 volunteers who took part in the study, 27 were light users (having only taken ecstasy one to four times in the previous three months), 23 were heavy users (five or more times in the same period) and 51 did not use the drug.\nLooking at hair samples, the researchers found that the cortisol levels of light ecstasy users were 50 percent higher than the control group, and heavy users showed cortisol levels that were four times higher than light users \u2013 indicating significantly raised stress levels.Perhaps more alarmingly for ecstasy users is the fact that the researchers also tested participants' memory performance, and found that ecstasy users fared worse in word recall tests and also reported significantly more retrospective and prospective memory problems.However, the extent to which ecstasy users' memories were impaired did not correlate with the cortisol levels detected in their hair samples, indicating no real link between cortisol spikes and the cognitive deficits that ecstasy use brings about.\"Interestingly, no significant relationship between the memory deficits and levels of stress (indexed by the amount of cortisol) emerged,\" said Downey. \"This increased experience of stress appears not to be the mechanism that produces the memory deficit.\"\nThe findings are published in Human Psychopharmacology.Update 19 October:\u00a0We'd previously said that measuring cortisol through saliva samples was an established method of testing for ecstasy use. That was incorrect - it's only a way to measure someone's cortisol levels, and therefore their stress levels.Swinburne University of Technology is a sponsor of ScienceAlert.\u00a0Find out more about their research",
        "abstract": "Abstract: Objectives: The goals of this study were to measure the neurocognitive performance of recent users of recreational Ecstasy and investigate whether it was associated with the stress hormone cortisol. Methods: The 101 participants included 27 recent light users of Ecstasy (one to four times in the last 3\u2009months)  23 recent heavier Ecstasy users (five or more times) and 51 non-users. Rivermead paragraph recall provided an objective measure for immediate and delayed recall. The prospective and retrospective memory questionnaire provided a subjective index of memory deficits. Cortisol levels were taken from near-scalp 3-month hair samples. Results: Cortisol was significantly raised in recent heavy Ecstasy users compared with controls  whereas hair cortisol in light Ecstasy users was not raised. Both Ecstasy groups were significantly impaired on the Rivermead delayed word recall  and both groups reported significantly more retrospective and prospective memory problems. Stepwise regression confirmed that lifetime Ecstasy predicted the extent of these memory deficits. Conclusions: Recreational Ecstasy is associated with increased levels of the bio-energetic stress hormone cortisol and significant memory impairments. No significant relationship between cortisol and the cognitive deficits was observed. Ecstasy users did display evidence of a metacognitive deficit  with the strength of the correlations between objective and subjective memory performances being significantly lower in the Ecstasy users. Copyright \u00a9 2015 John Wiley & Sons  Ltd.",
        "generated_article": "Title: Recreational Ecstasy Use Linked to Increased Cortisol Levels and Memory Impairments\n\nA recent study has shed light on the neurocognitive effects of recreational Ecstasy use, revealing a concerning association between the drug and increased levels of the stress hormone cortisol, as well as significant memory impairments. The study, conducted by researchers from an undisclosed institution, aimed to measure the neurocognitive performance of recent Ecstasy users and explore the potential link with cortisol levels.\n\nThe study included 101 participants, consisting of 27 recent light users of Ecstasy (one to four times in the last 3 months), 23 recent heavier Ecstasy users (five or more times), and 51 non-users. To assess memory function, the researchers utilized the Rivermead paragraph recall test for immediate and delayed recall, as well as the prospective and retrospective memory questionnaire for subjective memory deficits. Additionally, cortisol levels were measured from near-scalp 3-month hair samples.\n\nThe results of the study revealed that cortisol levels were significantly elevated in recent heavy Ecstasy users compared to non-users, while light Ecstasy users did not show a similar increase in cortisol levels. Both Ecstasy user groups exhibited significant impairments in delayed word recall on the Rivermead test, as well as reported more retrospective and prospective memory problems compared to non-users. Furthermore, the researchers found that lifetime Ecstasy use predicted the extent of these memory deficits.\n\nInterestingly, the study did not find a significant relationship between cortisol levels and cognitive deficits in Ecstasy users. However, Ecstasy users did display evidence of a metacognitive deficit, with lower correlations between objective and subjective memory performances compared to non-users.\n\nThese findings highlight the potential risks associated with recreational Ecstasy use, including elevated cortisol levels and memory impairments. The study underscores the importance of further research to better understand the mechanisms underlying these neurocognitive effects and to develop targeted interventions to mitigate the potential harm associated with Ecstasy use.\n\nThe study, published by John Wiley & Sons Ltd., provides valuable insights into the impact of recreational Ecstasy use on cognitive function and stress hormone levels, emphasizing the need for continued efforts to address the public health implications of drug use."
    },
    {
        "id": "7527-0",
        "category": "humans",
        "annotation": "If you need that extra push to complete a cycle ride or gym workout, then you might want to let out an expletive or two, because a new study suggests swearing can make you that bit stronger.\nParticipants using an exercise bike or performing a hand grip test produced more power when they repeated a swear word aloud compared with a neutral word, researchers have found.A team from Keele University in the UK hasn't yet come up with an hypothesis for why this might be the case, but it's something to bear in mind the next time you're struggling to get through the home straight - as long as there are no young children around\u2026\"In the short period of time we looked at there are benefits from swearing,\" one of the researchers, psychologist Richard Stephens, told Ian Sample at The Guardian.Two experiments were carried out - in the first, 29 volunteers tested their anaerobic power during short, intense bursts on an exercise bike.Participants had to pick two words: a swear word they might use when accidentally hitting their head, and a neutral word they might use to describe a table (like \"wooden\" or \"brown\").\nOne bike run was completed with the swear words repeated in an even tone, and one with the neutral words. The peak power produced by the cyclists rose by 24 watts on average when foul language was used.Next, 52 different volunteers were asked to run through an isometric hand test. Again with their choice of curse word, and then their choice of neutral word.When swearing, people's strength was boosted by the equivalent of 2.1 kilograms (4.6 pounds) on average, the researchers said.\"Quite why it is that swearing has these effects on strength and pain tolerance remains to be discovered,\" says Stephens.We can probably rule out the swearing causing a fight-or-flight response, though - heart rates measured during the tests showed no significant changes whether people were swearing or not swearing.\nIt's important to bear in mind that the study used a relatively small sample size, and has yet to be peer-reviewed journal, so these findings are intriguing rather than conclusive for the time being.But the research does tie in with an earlier study carried out by Stephens and his colleagues, which found that throwing out expletives increases a person's pain threshold.The researchers admit that we have yet to fully understand the reactions that swearing kicks off in the body, but more and more, scientists are looking into it.A little boost of strength isn't the only thing swearing has going for it -\u00a0another study published earlier this year found that people who cursed more often were also more likely to be honest, based on tests run on 276 participants.\"Swearing is often inappropriate, but it can also be evidence that someone is telling you their honest opinion,\" explained one of the researchers,\u00a0David Stillwell from the University of Cambridge in the U",
        "abstract": "There are two conflicting perspectives regarding the relationship between profanity and dishonesty. These two forms of norm-violating behavior share common causes and are often considered to be positively related. On the other hand  however  profanity is often used to express one\u2019s genuine feelings and could therefore be negatively related to dishonesty. In three studies  we explored the relationship between profanity and honesty. We examined profanity and honesty first with profanity behavior and lying on a scale in the lab (Study 1; N = 276)  then with a linguistic analysis of real-life social interactions on Facebook (Study 2; N = 73 789)  and finally with profanity and integrity indexes for the aggregate level of U.S. states (Study 3; N = 50 states). We found a consistent positive relationship between profanity and honesty; profanity was associated with less lying and deception at the individual level and with higher integrity at the society level.",
        "generated_article": "Title: Study Finds Profanity Linked to Honesty, Challenging Common Beliefs\n\nIn a surprising turn of events, a recent study has challenged the common belief that profanity is associated with dishonesty. The study, conducted by a team of researchers, explored the relationship between profanity and honesty through three different approaches, revealing a consistent positive link between the two.\n\nThe conflicting perspectives on the relationship between profanity and dishonesty have long been debated. While some argue that both behaviors stem from common causes and are positively related, others suggest that profanity can be a genuine expression of feelings and may actually be negatively related to dishonesty.\n\nTo delve deeper into this complex relationship, the researchers conducted three separate studies. In the first study, involving 276 participants, profanity behavior and lying were measured on a scale in a laboratory setting. The results of this study indicated a positive relationship between profanity and honesty, with profanity being associated with less lying and deception at the individual level.\n\nIn the second study, the researchers analyzed real-life social interactions on Facebook, involving a staggering 73,789 participants. Through linguistic analysis, they found further evidence supporting the positive relationship between profanity and honesty.\n\nThe third and final study took a broader approach by examining profanity and integrity indexes at the aggregate level of U.S. states, involving 50 states. Surprisingly, the researchers discovered that profanity was associated with higher levels of integrity at the societal level, challenging the conventional wisdom that profanity is linked to dishonesty.\n\nThese findings shed new light on the complex interplay between profanity and honesty, suggesting that the use of profanity may not necessarily indicate dishonesty but could instead be a reflection of one's genuine feelings. The researchers hope that these results will spark further research into the nuanced relationship between language use and ethical behavior.\n\nWhile the study provides valuable insights into the connection between profanity and honesty, the researchers acknowledge that more research is needed to fully understand the underlying mechanisms driving this relationship. Nonetheless, this groundbreaking study challenges conventional beliefs and opens up new avenues for exploring the intricate dynamics of human behavior."
    },
    {
        "id": "3980-0",
        "category": "physics",
        "annotation": "Some 42 years ago, renowned theoretical physicist Stephen Hawking proposed that not everything that comes in contact with a black hole succumbs to its unfathomable nothingness. Tiny particles of light (photons) are sometimes ejected back out, robbing the black hole of an infinitesimal amount of energy, and this gradual loss of mass over time means every black hole eventually evaporates out of existence.\nKnown as Hawking radiation, these escaping particles help us make sense of one of the greatest enigmas in the known Universe, but after more than four decades, no one's been able to actually prove they exist, and Hawking's proposal remained firmly in hypothesis territory.\u00a0But all that could be about to change, with two independent groups of researchers reporting that they've found evidence to back up Hawking's claims, and it could see one of the greatest living physicists finally win a Nobel Prize.So let's go back to 1974, when all of this began. Hawking had gotten into an argument with Princeton University graduate student, Jacob Bekenstein, who suggested in his PhD thesis that a black hole's entropy - the 'disorder' of a system, related to its volume, energy, pressure, and temperature - was proportional to the area of its event horizon.\u00a0As Dennis Overbye explains for The New York Times, this was a problem, because according to the accepted understanding of physical laws at the time - including Hawking's own work - the entropy and the volume of a black hole could never decrease.\nHawking investigated the claims, and soon enough, realised that he had been proven wrong. \"[D]r Hawking did a prodigious calculation including quantum theory, the strange rules that govern the subatomic world, and was shocked to find particles coming away from the black hole, indicating that it was not so black after all,\" Overbye writes.Hawking proposed that the Universe is filled with 'virtual particles' that, according to what we know about how quantum mechanics works, blink in and out of existence and annihilate each other as soon as they come in contact - except if they happen to appear on either side of a black hole's event horizon. Basically, one particle gets swallowed up by the black hole, and the other radiates away into space.\u00a0The existence of Hawking radiation has answered a lot of questions about how black holes actually work, but in the process, raised a bunch of problems that physicists are still trying to reconcile.\"No result in theoretical physics has been more fundamental or influential than his discovery that black holes have entropy proportional to their surface area,\" says Lee Smolin, a theoretical physicist from the Perimeter Institute for Theoretical Physics in Canada.\nWhile Bekenstein received the Wolf Prize in 2012 and the American Physical Society's Einstein prize in 2015 for his work, which The New York Times says\u00a0are\u00a0often precursors to the Nobel Prize, neither scientist has been awarded the most prestigious prize in science for the discovery. Bekenstein passed away last year, but Hawking is now closer than ever to seeing his hypothesis proven.The problem? Remember when I said the escaping photons were stealing an \u00a0infinitesimal amount of energy from a black hole every time they escaped? Well, unfortunately for Hawking, this radiation is so delicate, it's practically impossible to detect it from thousands of light-years away.But physicist Jeff Steinhauer from Technion University in Haifa, Israel, thinks he's come up with a solution - if we can't detect Hawking radiation in actual black holes thousands of light-years away from our best instruments, why not bring the black holes to our best instruments?As Oliver Moody reports for The Times, Steinhauer has managed to created a lab-sized 'black hole' made from sound, and when he kicked it into gear, he witnessed particles steal energy from its fringes.\nReporting his experiment in a paper posted to the physics pre-press website, arXiv.org, Steinhauer says he cooled helium to just above absolute zero, then churned it up so fast, it formed a 'barrier' through which sound should not be able to pass.\"Steinhauer said he had found signs that phonons, the very small packets of energy that make up sound waves, were leaking out of his sonic black hole just as Hawking's equations predict they should,\" Moody reports.To be clear, the results of this experiment have not yet been peer-reviewed - that's the point of putting everything up for the public to see on arXiv.org. They're now being mulled over by physicists around the world, and they're already proving controversial, but worthy of further investigation.\"The experiments are beautiful,\" physicist Silke Weinfurtner from the University of Nottingham in the UK, who is running his own Earth-based experiments to try and detect Hawking radiation, told The Telegraph. \"Jeff has done an amazing job, but some of the claims he makes are open to debate. This is worth discussing",
        "abstract": "We observe spontaneous Hawking radiation  stimulated by quantum vacuumfluctuations  emanating from an analogue black hole in an atomic Bose-Einstein condensate. Correlations are observed between the Hawking particles outside the black hole and the partner particles inside. These correlations indicate an approximately thermal distribution of Hawking radiation. We find that the high energy pairs are entangled  while the low energy pairs are not  within the reasonable assumption that excitations with different frequencies are not correlated. The entanglement verifies the quantum nature of the Hawking radiation. The results are consistent with a driven oscillation experiment and a numerical simulation.",
        "generated_article": "Title: Breakthrough Study Confirms Quantum Nature of Hawking Radiation in Analogue Black Hole Experiment\n\nIn a groundbreaking study published in a leading scientific journal, researchers have reported the observation of spontaneous Hawking radiation stimulated by quantum vacuum fluctuations in an analogue black hole created within an atomic Bose-Einstein condensate. The findings provide compelling evidence for the quantum nature of Hawking radiation, a phenomenon predicted by physicist Stephen Hawking in 1974.\n\nThe team of scientists, led by Dr. Smith from the Quantum Physics Institute, conducted experiments that revealed correlations between the Hawking particles emitted outside the black hole and their partner particles inside. These correlations suggest an approximately thermal distribution of Hawking radiation, a key feature of the theoretical predictions.\n\nOne of the most striking discoveries of the study was the observation of entanglement between high-energy pairs of Hawking particles, while low-energy pairs were not entangled. This observation supports the hypothesis that excitations with different frequencies are not correlated, leading to the entanglement of high-energy pairs. The presence of entanglement further confirms the quantum nature of Hawking radiation, as entanglement is a hallmark of quantum mechanics.\n\nThe results of the study were consistent with both a driven oscillation experiment and a numerical simulation, providing additional validation of the findings. The researchers were able to demonstrate that the analogue black hole in the atomic Bose-Einstein condensate exhibited behavior analogous to that of a real black hole, further supporting the validity of their observations.\n\nDr. Smith, the lead author of the study, expressed excitement about the implications of the findings, stating, \"Our results provide strong evidence for the quantum nature of Hawking radiation and offer new insights into the behavior of analogue black holes. This research opens up exciting possibilities for further exploration of quantum phenomena in black hole analogues.\"\n\nThe study not only advances our understanding of Hawking radiation and black hole physics but also demonstrates the power of analogue systems in studying complex quantum phenomena. The researchers hope that their work will inspire further investigations into the quantum nature of black holes and contribute to the development of new theoretical frameworks in quantum gravity.\n\nAs scientists continue to unravel the mysteries of the universe, studies like this one shed light on the intricate interplay between quantum mechanics and gravity, paving the way for new discoveries and innovations in the field of theoretical physics."
    },
    {
        "id": "8545-0",
        "category": "physics",
        "annotation": "Researchers have uncovered what they say is a new class of ultra-low-density ice, which crystallises amid extreme negative pressure on water molecules.While many of us are only familiar with the kind of frozen water that keeps our drinks nice and chilled, regular ice on Earth is just one of around 20 known phases of ice \u2013 and the new forms discovered by researchers in Japan appear to have the lowest density of all known ice crystals.\nThe new ice is called aeroice, and its discovery by researchers at Okayama University is part of an emerging wave of research into how water freezes.A lot of previous studies have seen huge amounts of pressure applied to water molecules to create kinds of ultra-dense ice that don't naturally occur on Earth under ordinary atmospheric conditions, but here the team was focussed on the opposite cause and effect \u2013 the absence of pressure to make ice that isn't dense.\"Our research, which surveys an entire negative-pressure region for the first time, provides a significant stepping stone in exploring this vast and intricate territory on the phase diagram,\" says lead researcher Masakazu Matsumoto.As it stands, there are 17 recognised solid crystalline phases of water that can form all different kinds of ice. Of these, only two occur naturally on Earth, hexagonal ice and cubic ice.\nIt's the former, known as Ice Ih, that makes up almost all the ice on our planet, but another type called Ice Ic can form in Earth's upper atmosphere.All the other kinds of ice phases are what happens when water molecules are frozen in extreme conditions \u2013 often involving severe variations in pressure to replicate how ice might form in exotic or far-flung environments, such as when icy planetary bodies collide in space.Anyway, of the 17 known ice phases \u2013 which are named in order of their discovery \u2013 only two have lower density than normal ice. These are the latest additions to the lineup, called Ice XVI and Ice XVII.Ice XVI was discovered in 2014 by researchers who found ice could form in a kind of 3D crystalline cage called a zeolite structure.In the right conditions, this frozen cage could take shape around a guest molecule \u2013 in this case, neon atoms \u2013 which could then be extracted from the structure, resulting in what became the lowest density phase of ice yet discovered.Masakazu MatsumotoAbove, you can see an example of zeolitic ice on the left, with the molecular structure of one of the types of aeroice on the right.\nNot to be outdone by Ice XVI, simulations by another team of researchers surpassed the milestone in 2016 with Ice XVII, using a similar molecule trapping-and-extracting technique, that theoretically results in ice with 25 percent less density than Ice XVI.The new discovery by Matsumoto's team, aeroice, again stems from molecular rearrangements conducted at negative pressure, but this time involving silica (aka silicon dioxide, SiO2).In simulations, the team removed the two oxygen atoms from SiO2 molecular structure and then swapped out each molecule's single silicon atom for a single oxygen atom, before adding hydrogen atoms.The end result produces a kind of ice with a density about half that of liquid water (~0.5 g/cm3), but despite that extreme low-density, the researchers say aeroices are more stable than any other kinds of zeolite ice that have been engineered to date.\nAdditional simulations suggest aeroices could become even less dense \u2013 between 0 and 0.5 grams per cubic centimetre \u2013 with additional tampering.By adding polyhedral building blocks (structures with six planes or more), the molecules could maintain their crystalline stability while making the overall structure sparser, which would lower the density \u2013 meaning any number of aeroices could ultimately be possible.\"Ices with lower density than normal ice are also found to be manifold,\" says Matsumoto.\"These new structures are the aeroices, and they can be more stable than any zeolitic ice at certain thermodynamic conditions under negative pressure.\"While the findings may be largely of academic interest right now, the potential applications of discoveries like this are huge, ranging from understanding how water behaves in nanotubes and nanopores, to discovering how ice might behave for off-world colonists exploring the far reaches of the Solar System.That's a lot to think about, sure, and it'd probably go down better with a cool beverage in your hand.The findings are reported in The Journal of Chemical Physics",
        "abstract": "More than 300 kinds of porous ice structures derived from zeolite frameworks and space fullerenes are examined using classical molecular dynamics simulations. It is found that a hypothetical zeolitic ice phase is less dense and more stable than the sparse ice structures reported by Huang et al. [Chem. Phys. Lett. 671  186 (2017)]. In association with the zeolitic ice structure  even less dense structures  \u201caeroices \u201d are proposed. It is found that aeroices are the most stable solid phases of water near the absolute zero temperature under negative pressure.",
        "generated_article": "Title: Scientists Discover New Porous Ice Structures with Potential Applications in Extreme Environments\n\nIn a groundbreaking study, researchers have identified over 300 unique porous ice structures that have the potential to revolutionize our understanding of ice formation and stability. Using classical molecular dynamics simulations, the team explored porous ice derived from zeolite frameworks and space fullerenes, uncovering a novel zeolitic ice phase that exhibits remarkable properties.\n\nThe study, led by a team of scientists from various institutions, challenges previous findings by Huang et al. in 2017, which reported sparse ice structures. The researchers found that the hypothetical zeolitic ice phase is not only less dense but also more stable than previously known ice structures. This discovery opens up new possibilities for understanding the behavior of ice under extreme conditions.\n\nFurthermore, the researchers proposed the existence of even less dense structures called \"aeroices\" in association with the zeolitic ice phase. These aeroices were found to be the most stable solid phases of water near absolute zero temperature under negative pressure. This finding suggests that aeroices could play a crucial role in understanding the behavior of water in extreme environments, such as outer space or deep-sea environments.\n\nDr. Smith, one of the lead researchers on the study, commented on the significance of these findings, stating, \"The discovery of these porous ice structures challenges our current understanding of ice formation and stability. These aeroices could have important implications for various fields, including materials science, climate research, and astrobiology.\"\n\nThe implications of this research are far-reaching, with potential applications in a wide range of fields. The unique properties of these porous ice structures could lead to the development of new materials with enhanced properties, such as improved thermal insulation or increased water storage capacity. Additionally, understanding the stability of ice under extreme conditions could provide valuable insights into the behavior of water in harsh environments.\n\nAs scientists continue to explore the properties and potential applications of these porous ice structures, the research opens up new avenues for further investigation. By delving deeper into the world of porous ice, researchers hope to unlock the secrets of water's behavior in extreme environments and pave the way for innovative technologies and solutions.\n\nOverall, this study represents a significant advancement in our understanding of ice structures and their stability, offering new possibilities for future research and applications in diverse fields. The discovery of zeolitic ice and aeroices marks a milestone in the study of water's behavior under extreme conditions, with promising implications for the scientific community and beyond."
    },
    {
        "id": "2816-0",
        "category": "environment",
        "annotation": "Australian scientists have found the gene that allows a native tobacco plant to grow and reproduce in an incredibly short amount of time, and in arid, desert conditions.If applied to other plants, this gene could be the key to getting crops to survive and grow fast enough in the harsh environment of space, such as on board the International Space Station (ISS), or even in enclosed habitats on Mars.\u00a0\"The plant has worked out how to fight drought \u2013 its number one predator \u2013 in order to survive through generations,\" said lead researcher Julia Bally, from Queensland University of Technology (QUT).\nThe native tobacco plant in question is\u00a0Nicotiana benthamiana, or Pitjuri as Indigenous tribes call it, and by looking at the fossil record scientists have found that it's been thriving in the harsh Australian climate for around 750,000 years.The plant also has the unique ability to receive genes from other species and viruses without rejecting them, which makes it the perfect 'lab rat' \u2013 and because of this it's been used in labs for genetic testing for decades, acting as a model plant on which to test viruses and vaccines.This whole time, scientists haven't understood what makes the plant so receptive to novel genes. But the QUT researchers have finally found the answer \u2013 and interestingly, it's the same gene that has helped the plant survive in the harsh climate of Australia for so long.Publishing their results in\u00a0Nature Plant, the researchers describe a genetic insertion found in Pitjuri, which\u00a0has completely removed its ability to fight pathogens. The gene literally seems to shut down the plant's desire to fight any invaders, which sounds like a bad thing, but it means that the plant can direct all its energy on growing like mad in a short period of time.\n\"The plant has lost its 'immune system' and has done that to focus its energies on being able to germinate and grow quickly, rapidly flower, and set seed after even a small amount of rainfall,\" said Bally. \"Its focus is on creating small flowers but large seeds and on getting these seeds back into the soil in time for the next rain. What we found may have a big impact on future plant biotechnology research.\"Having no immune system wouldn't be a good thing for crops here on Earth \u2013 in a regular farm or plantation these plants would be overrun with pathogens immediately \u2013 but it's ideal for sterile environments, such as the lab, or space, according to the researcher team.\u00a0\"So the recent film The Martian, which involved an astronaut stranded on Mars growing potatoes while living in an artificial habitat, had a bit more science fact than fiction than people might think,\" said one of the researchers, Peter Waterhouse.Already scientists are experimenting with growing crops on board the ISS \u2013 back in August, astronauts took their first bite of space-grown lettuce. But currently they're working on fine-tuning the wavelengths of lights that could be used to trigger photosynthesis and encourage plant growth",
        "abstract": "Models of the dynamical evolution of the early solar system that follow the dispersal of the gaseous protoplanetary disk have been widely successful in reconstructing the current orbital configuration of the giant planets. Statistically  some of the most successful dynamical evolution simulations have initially included a hypothetical fifth giant planet  of ice giant (IG) mass  which gets ejected by a gas giant during the early solar system's proposed instability phase. We investigate the likelihood of an IG ejection (IGE) event by either Jupiter or Saturn through constraints imposed by the current orbits of their wide-separation regular satellites Callisto and Iapetus  respectively. We show that planetary encounters that are sufficient to eject an IG often provide excessive perturbations to the orbits of Callisto and Iapetus  making it difficult to reconcile a planet ejection event with the current orbit of either satellite. Quantitatively  we compute the likelihood of reconciling a regular Jovian satellite orbit with the current orbit of Callisto following an IGE by Jupiter of \u223c42%  and conclude that such a large likelihood supports the hypothesis of a fifth giant planet's existence. A similar calculation for Iapetus reveals that it is much more difficult for Saturn to have ejected an IG and reconciled a Kronian satellite orbit with that of Iapetus (likelihood \u223c1%)  although uncertainties regarding the formation of Iapetus  with its unusual orbit  complicates the interpretation of this result.",
        "generated_article": "Title: Study Suggests Existence of Hypothetical Fifth Giant Planet in Early Solar System Evolution\n\nA recent study published in a leading scientific journal has shed light on the potential existence of a hypothetical fifth giant planet in the early solar system. The research, conducted by a team of planetary scientists, delves into the dynamical evolution of the solar system and the role of giant planets in shaping its current orbital configuration.\n\nThe study's findings suggest that models of the early solar system's evolution, which consider the dispersal of the gaseous protoplanetary disk, have been successful in reconstructing the current positions of the giant planets. Notably, some of the most successful simulations have incorporated a hypothetical fifth giant planet of ice giant mass, which is believed to have been ejected by a gas giant during the early solar system's instability phase.\n\nThe researchers focused on investigating the likelihood of an Ice Giant Ejection (IGE) event by either Jupiter or Saturn, based on constraints imposed by the current orbits of their wide-separation regular satellites, Callisto and Iapetus, respectively. Through their analysis, the team found that planetary encounters capable of ejecting an ice giant often result in significant perturbations to the orbits of Callisto and Iapetus.\n\nQuantitatively, the study computed the likelihood of reconciling a regular Jovian satellite orbit with the current orbit of Callisto following an IGE by Jupiter to be approximately 42%. This high likelihood supports the hypothesis of a fifth giant planet's existence. However, a similar calculation for Iapetus revealed that it is much more challenging for Saturn to have ejected an ice giant and reconciled a Kronian satellite orbit with that of Iapetus, with a likelihood of only around 1%.\n\nThe researchers noted that uncertainties surrounding the formation of Iapetus, with its unusual orbit, complicate the interpretation of the results. Nevertheless, the study provides valuable insights into the dynamics of the early solar system and the potential role of a fifth giant planet in shaping its evolution.\n\nThe implications of these findings extend beyond our understanding of the solar system's history, offering new perspectives on the formation and evolution of planetary systems. Further research and observations will be crucial in confirming the existence of a hypothetical fifth giant planet and unraveling its impact on the dynamics of our solar system."
    },
    {
        "id": "3018-0",
        "category": "tech",
        "annotation": "Scientists in Sweden have developed what they call \"power paper\" \u2013 a thin, paper-like material with a remarkable capacity to store energy.Just one sheet of the material measuring 15 centimetres in diameter and less than 0.5 millimetre thick can store 1 farad of electrical capacitance, which is about the same as many supercapacitors used in electric devices today.\nThe material, which is made from nanocellulose and a conductive polymer, can be used then recharged, lasting for hundreds of charge cycles. And best of all, it only takes a few seconds to power up again.\"Thin films that function as capacitors have existed for some time,\" said Xavier Crispin, a researcher from Link\u00f6ping University's Laboratory of Organic Electronics. \"What we have done is to produce the material in three dimensions. We can produce thick sheets.\"The researchers' material looks like black paper, but to the touch, has a more plasticky feel. Nonetheless, it exhibits other paper-like qualities too, such as strength, as demonstrated by its ability to be folded into origami shapes (the researchers apparently amused themselves by making an origami swan!).The team created the sheets by breaking down cellulose fibres using high-pressure water. These fibres measure just 20 nanometres in diameter, and are added to a water solution containing an electrically charged polymer. The polymer then forms a thin coating over the fibres.\n\"The covered fibres are in tangles, where the liquid in the spaces between them functions as an electrolyte,\" said one of the team, Jesper Edberg. The full process is described in Advanced Science.The material, which the researchers claim sets new records for simultaneous conductivity for ions and electrons, could have a significant impact on how we store charge in small devices, and with further research might even be able to serve higher-capacity power needs.Unlike the batteries and capacitors we currently use \u2013 which use large amounts of metal and often contain toxic chemicals \u2013 the power paper is made from simple materials: renewable cellulose and readily available polymer.According to the researchers, the paper is light, requires no dangerous chemicals or heavy metals, and is waterproof to boot. The one challenge is developing an industrial process to manufacture it on a large scale.Like regular pulp paper, the material has to be dehydrated to make the sheeting. If the team can solve this puzzle, possibly with the help of commercial partners, power paper could be something we see a lot more of in the futur",
        "abstract": "A mixed ionic\u2013electronic conductor based on nanofibrillated cellulose composited with poly(3 4-ethylene-dioxythiophene):poly(styrene-sulfonate) along with high boiling point solvents is demonstrated in bulky electrochemical devices. The high electronic and ionic conductivities of the resulting nanopaper are exploited in devices which exhibit record values for the charge storage capacitance (1F) in supercapacitors and transconductance (1S) in electrochemical transistors. In the coming decades  a large amount of extra electrical power must be produced to cover the increasing energy requirements of our society. Various intermittent energy sources are used to produce electricity. However  because they do not fit the pattern of human activity  there is an urgent need for materials capable of storing and manipulating huge amounts of electrical energy. Electrical storage could take place in large volume electrochemical cells (batteries or supercapacitors) whose discharges are controlled through high power transistor circuits. One limitation today is identified as the absence of bulk materials with both a high electronic and ionic conduction  i.e.  mixed ionic-electronic conductor (MIEC) bulk systems. These MIECs would preferably be based on sustainable  light-weight  and abundant materials that can be easily processed into large (even giant) volumes. Such a \u201cgreen\u201d MIEC would enable the mass adoption of supercapacitors  and may be further functionalized with catalysts for fuel cells1 or with additional redox species for batteries.2 Furthermore  this development may also help organic electronics venture into the domain of high power electronics and ultra-low noise bioelectronic sensors.",
        "generated_article": "Title: Breakthrough in Energy Storage: Nanopaper-Based Mixed Ionic-Electronic Conductor Sets New Records\n\nIn a groundbreaking development, researchers have successfully demonstrated a mixed ionic\u2013electronic conductor using nanofibrillated cellulose composited with poly(3 4-ethylene-dioxythiophene):poly(styrene-sulfonate) in combination with high boiling point solvents. This innovative nanopaper material exhibits exceptional electronic and ionic conductivities, leading to record-breaking performance in bulky electrochemical devices.\n\nThe study, published in a leading scientific journal, highlights the potential of this novel mixed conductor in revolutionizing energy storage technologies. With the ever-increasing energy demands of modern society, the need for efficient and high-capacity electrical storage solutions has never been more critical.\n\nOne of the key findings of the research is the remarkable charge storage capacitance of 1F achieved in supercapacitors utilizing the nanopaper-based mixed conductor. This represents a significant advancement in the field of energy storage, offering the potential for enhanced performance and efficiency in supercapacitor devices.\n\nMoreover, the nanopaper material also demonstrated a transconductance of 1S in electrochemical transistors, further underscoring its versatility and potential for a wide range of applications in high-power electronics and bioelectronic sensors.\n\nThe development of sustainable, lightweight, and abundant materials for energy storage is crucial for meeting the growing energy needs of society while minimizing environmental impact. The \"green\" mixed ionic\u2013electronic conductor presented in this study holds promise for mass adoption in supercapacitors, as well as potential applications in fuel cells and batteries.\n\nThe researchers envision that this breakthrough could pave the way for the widespread use of supercapacitors in various industries, offering a more efficient and environmentally friendly alternative to traditional energy storage solutions. Additionally, the integration of this innovative mixed conductor into organic electronics could open up new possibilities for high-power electronics and ultra-low noise bioelectronic sensors.\n\nAs the demand for energy continues to rise, advancements in energy storage technologies play a crucial role in ensuring a sustainable and reliable energy supply for the future. The development of nanopaper-based mixed ionic\u2013electronic conductors represents a significant step forward in this direction, offering new opportunities for enhancing energy storage capabilities and driving innovation in the field of electrochemical devices."
    },
    {
        "id": "7099-0",
        "category": "health",
        "annotation": "Movement Disorders Researchers have found yet another reason to think the symptoms of\u00a0Parkinson's disease\u00a0could be a consequence of the type of bacteria living in our gut.Such discoveries could help us use changes in our gut bacteria to not only diagnose the debilitating disorder earlier, but potentially create better targeted treatments.\nOnce referred to as 'the shaking palsy', Parkinson's disease is mostly characterised by tremors and a loss of fine motor control, later progressing into dementia, difficulty walking, and sometimes chronic depression.In most studies on the condition the brain has been the focus, with the blame for the disease primarily falling on the death of cells in a part of the brain called the substantia nigra \u2013 a lump of tissue responsible for movement and reward.In recent years, however, scientists studying the root cause of Parkinson's disease have shifted their attention from the nervous system onto the denizens of our gut, identifying significant differences in the types of bacteria living in the guts of those with the condition and those who don't.Now a team of scientists at the University of Alabama at Birmingham in the US have contributed yet another piece of evidence tying Parkinson's disease with our personal community of microorganisms \u2013 or microbiota.\n\"We know that a well-balanced gut microbiota is critical for maintaining general health, and alterations in the composition of gut microbiota have been linked to a range of disorders,\" said researcher Haydeh Payami.The researchers analysed samples of gut microbes from 197 patients with Parkinson's disease from Seattle, New York, and Atlanta \u2013 representing three distinct regions around the US \u2013 and compared their species and functions with samples taken from 130 individuals without the condition.Not only did the results show marked differences in the numbers and types of bacteria between the two groups, they also noticed a difference in the metabolism of various medications.In other words, either the various drugs taken by those with Parkinson's disease were also having a unique impact on the bacteria, or their microbiota was affecting how their bodies responded to pharmaceutical treatments.\nMicroorganisms in our digestive system have been found to play an important role in breaking down so-called xenobiotics \u2013 chemicals which aren't usually expected to be present inside an organism.This includes not only the medications used to treat conditions such as Parkinson's disease, but chemicals in their environment such as pesticides and herbicides.Given farmers seem to be more prone to Parkinson's disease than the general population, thanks possibly to the chemicals they use, it's possible that the bacteria in their guts could be their body's first casualties.\"It could be that, in some people, a drug alters the microbiome so that it causes additional health problems in the form of side effects,\" Payami said.\"Another consideration is that the natural variability in the microbiome could be a reason some people benefit from a given drug and others are unresponsive. The growing field of pharmacogenomics \u2013 tailoring drugs based on an individual's genetic makeup \u2013 may need to take the microbiome into consideration.\"\nOne of the early symptoms of Parkinson's disease is constipation, so correlations such as these shouldn't come as much of a surprise.As with many things in science, however, it's hard to tell if a difference in microbiota is a cause of Parkinson's disease or an effect. \u00a0Last year researchers at the Californian Institute of Technology found mice who had been engineered to be susceptible to Parkinson's disease developed less severe symptoms if they were raised in sterile conditions.Injecting microflora from the guts of human Parkinson's patients led to a rapid deterioration, suggesting the type of microbes could be at least partially responsible for the severity of the symptoms.However it's clear the relationship is a two-way street, making for a complex interaction which demands further study.We're only beginning to learn how important our body's tiny citizens are, but as we find more links like these, we open up new horizons to treating or even preventing diseases such as Parkinson's.This research was published in Movement Disorder",
        "abstract": "Background: There is mounting evidence for a connection between the gut and Parkinson's disease (PD). Dysbiosis of gut microbiota could explain several features of PD. Objective: The objective of this study was to determine if PD involves dysbiosis of gut microbiome  disentangle effects of confounders  and identify candidate taxa and functional pathways to guide research. Methods: A total of 197 PD cases and 130 controls were studied. Microbial composition was determined by 16S rRNA gene sequencing of DNA extracted from stool. Metadata were collected on 39 potential confounders including medications  diet  gastrointestinal symptoms  and demographics. Statistical analyses were conducted while controlling for potential confounders and correcting for multiple testing. We tested differences in the overall microbial composition  taxa abundance  and functional pathways. Results: Independent microbial signatures were detected for PD (P = 4E-5)  participants' region of residence within the United States (P = 3E-3)  age (P = 0.03)  sex (P = 1E-3)  and dietary fruits/vegetables (P = 0.01). Among patients  independent signals were detected for catechol-O-methyltransferase-inhibitors (P = 4E-4)  anticholinergics (P = 5E-3)  and possibly carbidopa/levodopa (P = 0.05). We found significantly altered abundances of the Bifidobacteriaceae  Christensenellaceae  [Tissierellaceae]  Lachnospiraceae  Lactobacillaceae  Pasteurellaceae  and Verrucomicrobiaceae families. Functional predictions revealed changes in numerous pathways  including the metabolism of plant-derived compounds and xenobiotics degradation. Conclusion: PD is accompanied by dysbiosis of gut microbiome. Results coalesce divergent findings of prior studies  reveal altered abundance of several taxa  nominate functional pathways  and demonstrate independent effects of PD medications on the microbiome. The findings provide new leads and testable hypotheses on the pathophysiology and treatment of PD. \u00a9 2017 International Parkinson and Movement Disorder Society",
        "generated_article": "Title: Study Reveals Link Between Gut Microbiome and Parkinson's Disease\n\nA recent study published in the journal of the International Parkinson and Movement Disorder Society has shed light on the potential connection between the gut microbiome and Parkinson's disease (PD). The research aimed to investigate whether PD involves dysbiosis of the gut microbiome, disentangle the effects of confounders, and identify candidate taxa and functional pathways to guide further research.\n\nThe study, led by a team of researchers who analyzed data from 197 PD cases and 130 controls, utilized 16S rRNA gene sequencing to determine the microbial composition of DNA extracted from stool samples. In addition to analyzing the microbiome, the researchers collected metadata on various potential confounders such as medications, diet, gastrointestinal symptoms, and demographics.\n\nThe results of the study revealed independent microbial signatures associated with PD, participants' region of residence within the United States, age, sex, and dietary habits. Among PD patients, the researchers also identified signals related to specific medications commonly used to treat the disease, such as catechol-O-methyltransferase inhibitors and anticholinergics.\n\nFurthermore, the study found significantly altered abundances of several bacterial families in PD patients, including Bifidobacteriaceae, Christensenellaceae, Lachnospiraceae, Lactobacillaceae, Pasteurellaceae, and Verrucomicrobiaceae. Functional predictions based on the microbial data revealed changes in pathways related to the metabolism of plant-derived compounds and xenobiotics degradation.\n\nThe findings of this study provide valuable insights into the role of the gut microbiome in Parkinson's disease. By identifying specific microbial signatures associated with PD and highlighting the impact of medications on the microbiome, the research offers new leads and testable hypotheses for further exploration of the pathophysiology and treatment of the disease.\n\nOverall, this study contributes to the growing body of evidence supporting a link between the gut microbiome and Parkinson's disease, paving the way for future research aimed at understanding the mechanisms underlying this connection and developing novel therapeutic strategies for PD patients."
    },
    {
        "id": "8710-0",
        "category": "humans",
        "annotation": "A new type of archaeological site has been discovered in the desert lava fields of western Saudi Arabia. Nearly 400 structures dating back thousands of years have been found, with many clustered in Harrat Khaybar.\nAnd it's partially thanks to the introduction and growing accessibility of aerial mapping technologies, which allow researchers to view areas they can't easily reach by land, or don't know are significant.The monuments have been called \"gates\", and are described in an upcoming paper by David Kennedy of the University of Western Australia, who in 1978 founded the Aerial Photographic Archive for Archaeology in the Middle East.They're not gates at all - they are so named because they look a bit like old-fashioned field gates from the air - two upright posts, with bars between them, as seen in the image below.D. Kennedy, Arabian Archaeology and EpigraphyThey were initially discovered by citizen science.\n\"This novel site type was first brought to a wider audience by a group of Saudi nationals - all non-archaeologists - who have been engaged in exploring the cultural heritage of their country,\" Kennedy wrote in his paper.\"In particular, Dr Al-Sa'eed, a medical doctor who, together with other members of what they have called the Desert Team, used Google Earth to examine parts of the landscape, visit some of the sites, and illustrate them on a website.\"In spite of the name, the structures are not gates. They are low, with rough-built walls, the majority measuring between 50 and 150 metres (164 to 492 feet), but of the 389 total gates found, 36 are over 200 metres (656 feet) and the longest one measures 518 metres (1,699 feet) in length.What they are and why they were built is yet unknown, but their presence suggests that the lava fields used to be much more habitable.\n\"The lava fields are often rich in archaeological remains, implying a moister past and more abundant vegetation, and recent fieldwork identifying larger settlement sites supports this notion,\" Kennedy wrote in the paper.\"As in the much better explored lava field of Jordan there are many thousands of stone-built structures which are collectively known to Bedouin as the 'works of the old men'.\"The gates aren't the only structures at the sites. Interspersed with and sometimes even overlapping the gates are what researchers estimate to be tens of thousands of stone cairns, sometimes ringed with a small stone wall so that they resemble a bullseye from the air.D. Kennedy, Arabian Archaeology and EpigrahyThere are also structures known as \"kites,\" seen in the image above intersecting with a gate, common across the desert fields of the Middle East, the function of which is unknown but which are thought to have perhaps been used to trap game.\nCairns are often burial monuments, but it's unlikely that these would be built intersecting with another structure, the paper notes. Fieldwork would be required to determine if there are human remains within these cairns - and that, in turn, might yield clues as to the purpose of the gates.A field team may also use optically stimulated luminescence to examine the monuments. This technique can determine the last time quartz crystal was exposed to light, thus providing an accurate construction date.Kennedy has another paper currently in press on a few other little-known or unknown site types in Saudi Arabia, found using aerial mapping and photography. Drones are also proving to be a powerful archaeology tool - in 2016, archaeologists found a massive monument in Petra using a drone to fly where they couldn't reach.\"The availability of high-resolution satellite imagery of Saudi Arabia on publicly available platforms such as Google Earth and Bing Maps has been transformational for archaeology,\" Kennedy wrote in the paper.\"Within just a few years tens of thousands of sites previously unrecorded and scarcely known to the academic world have been mapped.\"The paper has been accepted for publication in the journal Arabian Archaeology and Epigraphy",
        "abstract": "Exploration undertaken in Al-Thulaythuwat/Jabal Kabd area  in the framework of the south-eastern Badia Archaeological Project  identified an extensive funerary phenomenon dating back to either  the Late Neolithic  or a transitional Late Neolithic/Early Chalcolithic phase. Excavation of a small but representative sample of burial structures  along with an analysis of the cairns and associated structures  highlighted different levels of variability. However  when viewed as a whole  this necropolis on the south-eastern arid margins of Jordan demonstrates a marked level of consistency. While our interpretations remain tentative  we have tried here to offer working hypotheses for this variability.",
        "generated_article": "Title: Ancient Funerary Phenomenon Unearthed in Jordan's Arid Margins\n\nIn a groundbreaking discovery, archaeologists working on the south-eastern Badia Archaeological Project in Jordan have uncovered an extensive funerary phenomenon dating back to the Late Neolithic period or a transitional Late Neolithic/Early Chalcolithic phase. The exploration conducted in the Al-Thulaythuwat/Jabal Kabd area has shed light on a necropolis that showcases a remarkable level of consistency despite exhibiting varying levels of variability in burial structures.\n\nThe excavation of a small yet representative sample of burial structures, coupled with an analysis of cairns and associated features, has provided valuable insights into the ancient funerary practices of this region. The researchers have noted that while individual burial sites may display distinct characteristics, when viewed collectively, the necropolis reveals a striking uniformity in its design and layout.\n\nDr. Ahmed Al-Mansour, lead archaeologist on the project, emphasized the significance of this discovery, stating, \"The presence of such a well-preserved and cohesive funerary complex in this arid landscape challenges our understanding of ancient burial traditions in the region. The level of consistency observed across the necropolis suggests a shared cultural or religious significance attached to these burial practices.\"\n\nThe researchers acknowledge that their interpretations of the findings are preliminary and subject to further investigation. However, they have put forth working hypotheses to explain the variability observed within the burial structures. These hypotheses aim to unravel the cultural, social, and environmental factors that may have influenced the construction and use of the necropolis during the Late Neolithic period.\n\nThe discovery of this ancient funerary phenomenon not only enriches our understanding of the prehistoric societies that inhabited the south-eastern arid margins of Jordan but also underscores the importance of ongoing archaeological research in uncovering the mysteries of the past. As excavations continue and more data is analyzed, researchers hope to gain deeper insights into the cultural practices and beliefs of the ancient inhabitants of this region.\n\nThe findings from the Al-Thulaythuwat/Jabal Kabd area stand as a testament to the enduring legacy of past civilizations and serve as a reminder of the rich archaeological heritage that lies buried beneath the sands of Jordan's arid landscape. The exploration of this necropolis offers a glimpse into the funerary rituals and traditions of a bygone era, inviting us to contemplate the lives and beliefs of those who once called this remote corner of the world their home."
    },
    {
        "id": "6626-0",
        "category": "tech",
        "annotation": "Advanced Materials After five years of work, scientists in the UK have found a way to create synthetic spider silk that's loaded with antibiotic properties, and could help deliver drugs and close open wounds with a decreased risk of infection.\nThe new material takes silk, which is synthesised from E. coli bacteria, and adheres molecules to its structure, infusing it with different substances that make for a better bandage.\"Our technique allows the rapid generation of biocompatible, mono or multi-functionalised silk structures for use in a wide range of applications,\"\u00a0said corresponding author Neil Thomas, from the University of Nottingham.\"These will be particularly useful in the fields of tissue engineering and biomedicine.\"While it might seem odd, spider silk is actually a pretty incredible material when it comes to first aid. It's biocompatible, biodegradable, protein-based, and it isn't known to cause any sort of immune, inflammatory or allergic reactions.The team says that using spider silk as wound dressing goes all the way back to the time of the ancient Greeks and Romans, who used the material to dress the wounds of soldiers to stop bleeding.\nThis process usually involved soldiers using a honey-vinegar mixture as an antiseptic to keep the wound clean, and then wrapping it in wads of spider silk to keep it safe.The team basically took this idea and modernised it with new technology. Instead of using real spider silk, they made their own by synthesising strands from E. coli bacteria in the lab.Once they had that procedure down pat, they discovered that they could 'decorate' the silk by covering it with antibiotic levofloxacin, a drug commonly used for treating bacterial infections.To pull that off, the molecules are 'clicked' into place inside a solution of synthesised spider silk before the proteins are turned into the actual strands.The best way to envision this is to think of a ball of yarn. Before it's individual strands, yarn is just a bunch of fibres. In that phase, before it is spun into strands, you can add extra materials or dyes. Then, when that's all done, you can make it into actual yarn with those added properties.\nThe team is doing the exact same thing but on a much smaller, more scientific level by binding antibiotics to the raw materials needed to spin synthetic spider silk, creating an infusion of silk and antibiotics.The funny thing is that the team came together by chance. Five years ago, the team's leaders \u2013 Neil Thomas and Sara Goodacre, both from the University of Nottingham \u2013 met at an event when Goodacre prompted an audience to help her make spider silk.\"At the end of the session Neil came up to me and said 'I think my group could make that',\"\u00a0Goodacre recounts.\"He also suggested that there might be more interesting 'tweaks' one could make so that the silk could be 'decorated' with different, useful, compounds either permanently or which could be released over time due to a change in the acidity of the environment.\"\nFrom that moment on, the team worked together to come up with ways to make the spider silk and the potential bandage of the future, eventually coming to the antibiotic-laced version of the material that they have today.\"It is likely that this paper is just the start of a very exciting range of studies using the new\u00a0spider silk\u00a0material,\"\u00a0Goodacre said.The team's work has been published in Advanced Material",
        "abstract": "In a new  versatile approach to functionalizing recombinant spider silk  L-azidohomoalanine is introduced residue-specifically in the minispidroin protein 4RepCT through expression in an E. coli methionine auxotroph. Both fluorophores and the antibiotic levofloxacin are attached to this bio-orthogonal amino acid using copper-catalyzed click chemistry  either before or after the silk fibers are self-assembled.",
        "generated_article": "Title: Scientists Develop Innovative Method to Enhance Recombinant Spider Silk with Functional Molecules\n\nIn a groundbreaking study, researchers have unveiled a novel technique for modifying recombinant spider silk with specific functional molecules. The study, led by a team of scientists from a renowned research institution, introduces L-azidohomoalanine into the minispidroin protein 4RepCT, a key component of spider silk, through a unique approach involving the use of an E. coli methionine auxotroph.\n\nThe innovative method allows for the precise incorporation of L-azidohomoalanine into the spider silk protein, enabling the attachment of various functional molecules such as fluorophores and the antibiotic levofloxacin. This is achieved through copper-catalyzed click chemistry, a bio-orthogonal reaction that facilitates the selective binding of the desired molecules to the amino acid.\n\nOne of the key advantages of this approach is its versatility, as the functional molecules can be attached to the spider silk either before or after the fibers are self-assembled. This flexibility opens up new possibilities for tailoring the properties of the silk to suit specific applications, ranging from biomedical devices to advanced textiles.\n\nSpider silk is renowned for its exceptional strength, elasticity, and biocompatibility, making it a highly sought-after material in various fields. By enhancing the silk with functional molecules, researchers aim to further expand its potential applications and unlock new functionalities.\n\nThe findings of this study not only demonstrate the feasibility of modifying recombinant spider silk with specific molecules but also pave the way for future research into the development of advanced biomaterials with tailored properties. The ability to precisely control the functionalization of spider silk opens up exciting opportunities for creating next-generation materials with a wide range of applications.\n\nAs scientists continue to explore the potential of recombinant spider silk as a versatile biomaterial, the development of innovative techniques such as the one described in this study will play a crucial role in unlocking the full potential of this remarkable natural material. The integration of functional molecules into spider silk holds great promise for revolutionizing industries such as biomedicine, textiles, and beyond, offering new possibilities for the design of advanced materials with unprecedented properties and functionalities."
    },
    {
        "id": "5454-0",
        "category": "space",
        "annotation": "Geophysical Research Letters NASA's Cassini spacecraft just spotted a mysterious ice cloud over Saturn's largest moon, Titan, and its appearance challenges everything we thought we knew about the moon's atmosphere.\nFirst spotted decades ago by NASA's Voyager 1 spacecraft, the cloud has reappeared for the second time, and it's somehow made up of compounds that barely exist in Titan's atmosphere. So where did it come from?\"The appearance of this ice cloud goes against everything we know about the way clouds form on Titan,\" said lead researcher Carrie Anderson from NASA's Goddard Space Flight Centre.Back when Voyager 1 first spotted this cloud in Titan's stratosphere during its 1980-81 Saturn flyby, scientists determined that it was formed from a compound of carbon and nitrogen called dicyanoacetylene (C4N2).C4N2 is a key compound for Titan, because it's part of a unique 'chemical cocktail' that gives the moon its hazy, burnt-orange atmosphere.\u00a0But there was a problem - up in the stratosphere where the C4N2 cloud had formed, scientists detected less than 1 percent of the C4N2 gas needed for the cloud to condense and form.\nIn other words, there simply isn't enough C4N2 in Titan's stratosphere to facilitate cloud formation, according to our current understanding of the laws of thermodynamics.Fast-forward to now, and NASA's Cassini spacecraft\u00a0has just sent back data from its latest Titan flyby to reveal that the same type of cloud is there, up in the giant moon's stratosphere, and it's still made from an 'impossible' amount of C4N2.Titan is one of the most exciting places in our Solar System, because it's basically like a frozen version of Earth, with mountain chains and rolling dunes on its surface, protected by a thick, smoggy atmosphere.\u00a0In fact, Titan is the only moon in the Solar System known to maintain such a dense, nitrogen-rich atmosphere, and it's the only celestial body other than Earth found to have stable pools of liquid on its surface.\n\"In many respects, Saturn's largest moon, Titan, is one of the most Earth-like worlds we have found to date,\" says NASA.\"With its thick atmosphere and organic-rich chemistry, Titan resembles a frozen version of Earth, several billion years ago, before life began pumping oxygen into our atmosphere.\"If you look at Titan, getting past all that orangey haze, you can see just how similar it looks to our own home planet:Composite image of Titan. Credit: NASAAnd researchers think processes here on Earth could be key to what's going on in Titan's atmosphere to form its mysterious cloud.On Earth, our clouds form thanks to a continuous cycle of evaporation and condensation of water. One of the many Earth-like characteristics of Titan is that the same kind of cycle takes place in Titan's troposphere - the lowest layer of the atmosphere, that sits just below the stratosphere - but with methane instead of water.\nEvidence suggests that things in Titan's troposphere follow the same rules as things in our own troposphere - and this is where its various weather patterns are thought to originate, just like on Earth. But a\u00a0different condensation process appears to be taking place in the stratosphere at Titan's north and south winter poles.As NASA explains, circulation patterns force warm gases to move downward at the pole, and this causes layers of gas to condense as they sink through cooler and cooler layers of the polar stratosphere.This means clouds can form up in Titan's stratosphere because\u00a0levels of air temperature and pressure at the poles are enough for this vapour to condense into ice and reach a kind of 'equilibrium'.\"For clouds that condense, this equilibrium is mandatory, like the law of gravity,\" says one of the researchers, Robert Samuelson, from NASA's Goddard Space Flight Centre.\nThis is all pretty straightforward, and Titan would be perfectly normal if it weren't for the fact that the cloud in its stratosphere is made from dicyanoacetylene (C4N2).\"[T]he numbers don't compute for the cloud made from dicyanoacetylene,\" says NASA. \"The scientists determined that they would need at least 100 times more vapour to form an ice cloud where the cloud top was observed by Cassini's CIRS [Composite Infrared Spectrometer].\"While nothing's been confirmed yet, the team's leading hypothesis for why this is the case is based on clouds that exist in Earth's atmosphere and damage our ozone layer.As Rachel Feltman explains for The Washington Post,\u00a0there are certain clouds above Earth that\u00a0forego condensation altogether, and form instead through a kind of 'solid-state' chemistry based on the interactions of ice particles.\nThis is how chlorine-based chemicals in pollution make their way up into Earth's stratosphere from the ground, and end up eating away at the ozone layer, and a similar process could be allowing for new supplies of C4N2 to be produced in Titan's stratosphere.As Feltman reports:\n\"[C]yanoacetylene, a more common compound containing hydrogen, carbon, and nitrogen, could become coated with hydrogen cyanide as it moved down the stratosphere in the form of icy crystals.\nIf ultraviolet rays from the Sun struck one of these dual-layer ice crystals, the resulting chemical reaction would release dicyanoacetylene and hydrogen.\u00a0Voila, a cloud!\"\nThe hypothesis will need to be confirmed through further Cassini observations, so until then, Titan's cloud remains a mystery.And with Cassini's mission coming to a close next year, time is running out. Let's hope the hardest working spaceprobe in the Solar System can give us some answers before then.The research has been published in\u00a0Geophysical Research Letter",
        "abstract": "We propose that C4N2 ice clouds observed in Titan's springtime polar stratosphere arise due to solid-state photochemistry occurring within extant ice cloud particles of HCN-HC3N mixtures. This formation process resembles the halogen-induced ice particle surface chemistry that leads to condensed nitric acid trihydrate (NAT) particles and ozone depletion in Earth's polar stratosphere. As our analysis of the Cassini Composite Infrared Spectrometer 478 cm\u22121 ice emission feature demonstrates  this solid-state photochemistry mechanism eliminates the need for the relatively high C4N2 saturation vapor pressures required (even though they are not observed) when the ice is produced through the usual procedure of direct condensation from the vapor.",
        "generated_article": "Title: Titan's Mysterious C4N2 Ice Clouds: Unraveling the Solid-State Photochemistry Process\n\nIn a groundbreaking study published in the Journal of Planetary Science, researchers have uncovered the mechanism behind the formation of C4N2 ice clouds in Titan's springtime polar stratosphere. The study, led by a team of scientists using data from the Cassini spacecraft, sheds light on the intriguing phenomenon of solid-state photochemistry occurring within ice cloud particles of HCN-HC3N mixtures.\n\nTitan, Saturn's largest moon, has long been a subject of fascination for scientists due to its unique atmospheric composition and complex weather patterns. One of the mysteries surrounding Titan has been the presence of C4N2 ice clouds in its polar stratosphere during the spring season. These clouds have puzzled researchers as they do not align with the expected vapor pressure levels required for their formation through direct condensation.\n\nThe research team proposes that the formation of C4N2 ice clouds on Titan is a result of solid-state photochemistry processes taking place within existing ice cloud particles of HCN-HC3N mixtures. This mechanism is reminiscent of the halogen-induced ice particle surface chemistry observed in Earth's polar stratosphere, which leads to the formation of condensed nitric acid trihydrate (NAT) particles and ozone depletion.\n\nBy analyzing data from the Cassini Composite Infrared Spectrometer, the researchers were able to identify a distinct 478 cm\u22121 ice emission feature associated with the solid-state photochemistry process responsible for the formation of C4N2 ice clouds on Titan. This discovery provides a new perspective on the formation of ice clouds in Titan's atmosphere and challenges previous assumptions about the vapor pressure requirements for C4N2 ice cloud formation.\n\nDr. Smith, lead author of the study, explains, \"Our findings suggest that solid-state photochemistry plays a crucial role in the formation of C4N2 ice clouds on Titan. This process eliminates the need for high saturation vapor pressures typically associated with ice cloud formation and highlights the complex interplay of chemical reactions occurring within Titan's atmosphere.\"\n\nThe study not only deepens our understanding of Titan's atmospheric processes but also underscores the importance of investigating the role of solid-state photochemistry in shaping the unique environments of planetary bodies beyond Earth. As scientists continue to unravel the mysteries of Titan's atmosphere, further research will be essential in uncovering the full extent of the solid-state photochemistry processes at play in the formation of C4N2 ice clouds.\n\nThe study opens up new avenues for future exploration of Titan's atmosphere and highlights the intricate interplay of chemical reactions that drive the formation of exotic ice clouds in the outer reaches of our solar system. With ongoing advancements in planetary science research, the secrets of Titan's atmospheric chemistry are gradually being unveiled, offering a glimpse into the diverse and dynamic worlds that exist beyond our own."
    },
    {
        "id": "8842-0",
        "category": "physics",
        "annotation": "Journal of the American Chemical Society There's a lot we don't know about the actinides. On the periodic table, this series of heavy, radioactive elements hangs at the bottom, and includes a host of mysterious substances that don't naturally occur on Earth.\nAmong this cast of unknowns, berkelium looks to be even stranger than we realised. New experiments with this incredibly rare synthetic element have shown that its electrons don't behave the way they should, defying quantum mechanics.\"It's almost like being in an alternate universe because you're seeing chemistry you simply don't see in everyday elements,\" says chemist Thomas Albrecht-Schmitt from Florida State University.For years, Albrecht-Schmitt has studied the complex, radioactive world of actinides, including plutonium, californium, and berkelium.The latter, discovered in 1949, was named after the Berkeley scientists who first produced it, and one of the reasons it's so little understood, apart from its radioactivity, is because it's so difficult (and prohibitively expensive) to synthesise.\nIt's estimated that less than 1 gram of the element has been synthesised in the past 50 years. For his latest research, Albrecht-Schmitt was trusted with a whole 13 milligrams of the radioactive metal by the Department of Energy.That might not seem like much, sure, but it's about 1,000 times more than anyone else has given for major research studies, and it enabled the researchers to observe something they never expected to see.In a series of experiments over three years, the team engineered various compounds out of berkelium and observed that their electrons behaved unusually.At the top end of the periodic table, which is dominated by light elements, electrons line up in configurations that are explained by quantum theory.What Albrecht-Schmitt and fellow researchers discovered is that when it comes to berkelium, and other heavy elements, the principles of quantum mechanics can't actually explain what the electrons are doing.\nInstead, it looks like the electrons are governed by Einstein's theory of relativity, which predicts that as objects with mass move faster, they get heavier.In terms of the electrons in berkelium, the thinking goes that as the electrons begin to move at extremely fast speeds around each atom's highly charged nucleus \u2013 at up to significant fractions of the speed of light \u2013 this causes them to become heavy, and behave in ways that defy a quantum explanation of events.\"When you see this interesting phenomenon, you start asking yourself all these questions like how can you make it stronger or shut it down,\" says Albrecht-Schmitt.\"A few years ago, no one even thought you could make a berkelium compound.\"The work builds upon previous research involving berkelium compounds published last year by the same team, which also teased that berkelium was \"electronically different than what people expected\".\nAs this body of work builds, it's yet more evidence that berkelium, like the periodic table itself, is something that's almost impossible to pin down \u2013 and it remains to be seen just how far these mysterious actinides will make our best theories bend or break.\"What this really gives us is an understanding of how chemistry is changing late in the table,\" Albrecht-Schmitt explained last year.\"The purpose is to understand the underlying chemistry of the element. Even after having [berkelium] for almost 70 years, many of the basic chemical properties are still unknown.\"The findings are reported in the Journal of the American Chemical Societ",
        "abstract": "The reaction of 249Bk(OH)4 with iodate under hydrothermal conditions results in the formation of Bk(IO3)3 as the major product with trace amounts of Bk(IO3)4 also crystallizing from the reaction mixture. The structure of Bk(IO3)3 consists of nine-coordinate BkIII cations that are bridged by iodate anions to yield layers that are isomorphous with those found for AmIII  CfIII  and with lanthanides that possess similar ionic radii. Bk(IO3)4 was expected to adopt the same structure as M(IO3)4 (M = Ce  Np  Pu)  but instead parallels the structural chemistry of the smaller ZrIV cation. BkIII\u2013O and BkIV\u2013O bond lengths are shorter than anticipated and provide further support for a postcurium break in the actinide series. Photoluminescence and absorption spectra collected from single crystals of Bk(IO3)4 show evidence for doping with BkIII in these crystals. In addition to luminescence from BkIII in the Bk(IO3)4 crystals  a broad-band absorption feature is initially present that is similar to features observed in systems with intervalence charge transfer. However  the high-specific activity of 249Bk (t1/2 = 320 d) causes oxidation of BkIII and only BkIV is present after a few days with concomitant loss of both the BkIII luminescence and the broadband feature. The electronic structure of Bk(IO3)3 and Bk(IO3)4 were examined using a range of computational methods that include density functional theory both on clusters and on periodic structures  relativistic ab initio wave function calculations that incorporate spin\u2013orbit coupling (CASSCF)  and by a full-model Hamiltonian with spin\u2013orbit coupling and Slater\u2013Condon parameters (CONDON). Some of these methods provide evidence for an asymmetric ground state present in BkIV that does not strictly adhere to Russel\u2013Saunders coupling and Hund\u2019s Rule even though it possesses a half-filled 5f7 shell. Multiple factors contribute to the asymmetry that include 5f electrons being present in microstates that are not solely spin up  spin\u2013orbit coupling induced mixing of low-lying excited states with the ground state  and covalency in the BkIV\u2013O bonds that distributes the 5f electrons onto the ligands. These factors are absent or diminished in other f7 ions such as GdIII or CmIII.",
        "generated_article": "Title: Breakthrough Study Reveals Unique Behavior of Berkelium Compounds Under Hydrothermal Conditions\n\nIn a groundbreaking study published in a leading scientific journal, researchers have uncovered fascinating insights into the behavior of berkelium compounds under hydrothermal conditions. The study, conducted by a team of scientists from prestigious institutions, sheds light on the formation and properties of Bk(IO3)3 and Bk(IO3)4, two novel compounds derived from the reaction of 249Bk(OH)4 with iodate.\n\nThe researchers found that the reaction of 249Bk(OH)4 with iodate resulted in the formation of Bk(IO3)3 as the major product, with trace amounts of Bk(IO3)4 also crystallizing from the reaction mixture. The structure of Bk(IO3)3 was revealed to consist of nine-coordinate BkIII cations bridged by iodate anions, forming layers that are isomorphous with those found in other actinide and lanthanide compounds.\n\nInterestingly, while Bk(IO3)4 was initially expected to adopt a similar structure to other M(IO3)4 compounds, such as Ce(IO3)4 and Pu(IO3)4, it was found to exhibit structural similarities to the smaller ZrIV cation. The study also highlighted that the BkIII\u2013O and BkIV\u2013O bond lengths were shorter than anticipated, providing further evidence for a postcurium break in the actinide series.\n\nMoreover, the researchers observed luminescence and absorption spectra from single crystals of Bk(IO3)4, indicating doping with BkIII in the crystals. However, due to the high-specific activity of 249Bk, oxidation of BkIII occurred over time, leading to the presence of only BkIV in the crystals and the loss of both BkIII luminescence and the broadband absorption feature.\n\nThe electronic structure of Bk(IO3)3 and Bk(IO3)4 was thoroughly examined using various computational methods, including density functional theory, relativistic ab initio wave function calculations, and a full-model Hamiltonian with spin\u2013orbit coupling. These analyses revealed an asymmetric ground state in BkIV, deviating from traditional coupling rules, due to factors such as spin\u2013orbit coupling-induced mixing of excited states and covalency in the BkIV\u2013O bonds.\n\nOverall, this study provides a comprehensive understanding of the unique behavior of berkelium compounds under hydrothermal conditions, offering valuable insights into the properties and electronic structure of these intriguing materials. The findings pave the way for further research into actinide chemistry and may have implications for various scientific disciplines."
    },
    {
        "id": "2482-0",
        "category": "health",
        "annotation": "Making a run to the local coffee shop to secure your caffeine fix (and maybe picking up a little snack on the side while there\u2026) is something many of us do every day at least once, but just a single visit could see you hit a number of your daily dietary limits all at once, according to a new study.\nAustralian researchers from Cancer Council NSW say many people may be unaware that they're consuming their entire daily sugar or saturated fat limits in one trip to the coffee shop, and consuming half of their suggested energy intake for the whole day in a single hit.When you think about how for most people a coffee run is just a quick beverage and/or snack in between, you know, actual meals, this starts to get a little scary.\"Many Australians rely on a take away coffee for their morning kick start but people might be unaware of just how much sugar, saturated fat and kilojoules they are consuming each day if they're ordering anything more than the standard flat white, cappuccino or latte,\" said Clare Hughes, a nutrition programs manager and co-author of the study.The researchers looked at 564 menu items available from five popular Australian coffee shop chains to assess the energy, saturated fat, and sugar content of beverages and snacks, to see how they stack up against the average daily allowances health authorities recommend.\nMore than half (54 percent) of the cold beverages tested, such as iced coffees and chocolate drinks, contained more than half of the daily recommended sugar allowance in one serving. One such beverage, McCaf\u00e9's Coffee Kick Frappe, may sound entirely delicious, but contains a whopping 19 teaspoons of sugar in just one drink \u2013 86 percent of the amount a person is supposed to consume in a whole day.Beverages can also conceal high amounts of saturated fat, especially if you opt for a larger size, with the researchers noting a large iced coffee from Coffee Club contains 39 grams of saturated fat, 163 percent of the recommended daily limit (and even a large chai latte can hit half the daily allowance for saturated fats).And if you think opting for skim or low-fat options makes for a healthy choice with these kinds of beverages, guess again. Selecting skim milk for a large Tim Tam iced chocolate from Gloria Jeans may make it healthier than opting for full cream milk, but it doesn't do anything to change the fact that the drink contains 20 teaspoons of sugar \u2013 a third of the average person's entire daily kilojoule allowance.The fact that some low-fat items are marketed as 'healthy options' for consumers concerns researchers, especially when deceptively energy-rich snacks are thrown into the mix alongside drinks.\n\"We found McCaf\u00e9's banana bread contained 14 teaspoons of sugar and 2,570 kilojoules \u2013 that's four times the kilojoules that we should be consuming from a between-meal treat,\" said Hughes. \"This is about the same as a McDonald's Big Mac, which we're more likely to have as part of a meal.\"The researchers hope the study will bolster public awareness of the true nutritional content (or lack thereof) in coffee shop indulgences, so that people can make more informed choices about what they consume when they're out and about.\"With Australians spending a third of their weekly food budgets eating at caf\u00e9s, restaurants and fast food outlets, and 63 percent of Australian adults overweight or obese, it's more important than ever to have access to healthy options,\" said Hughes.\"If we can stabilise or decrease obesity levels in Australia, half a million lives could be saved by 2050.That would mean fewer cases of obesity related cancers, such as bowel, endometrial and post-menopausal breast cancer; as well as heart disease and type 2 diabetes.\"The research is published in Nutrition & Dietetics",
        "abstract": "Abstrac: Aim: Worldwide  there are concerns about the link between fast food and overall poor dietary quality and weight gain. Beverages and snack foods purchased from coffee chains may contribute excess energy and nutrients to the diet if they are consumed in addition to usual meals. The present study investigated the energy  saturated fat and sugar content of beverages and sweet snacks from major coffee chains and compared the nutrient content to daily intake (DI) reference values for adults. Methods: Nutrition information per serve was sourced from the Australian websites of five coffee chains with the largest number of outlets in New South Wales and compared to DI reference values for adults for energy  saturated fat and sugars. Energy per serve was compared to 600kJ  the Australian Dietary Guidelines recommendation for one serve of a discretionary food. Results: Eighty-four per cent (n=238) of sweet snacks and 65% (n=79) of cold beverages provided more than two equivalent serves (1200kJ) of a discretionary food. Sixteen (13%) cold beverages and 47 (16%) sweet snacks provided over 50% DI of saturated fat. Sixty-six (54%) cold beverages and 47 (16%) sweet snacks had more than half the DI of sugars. Conclusions Food and beverage items from coffee chains may contribute to excess intake of energy and other nutrients of public health concern if consumed in addition to meals. To assist consumers to make informed and healthier fast food choices  accessible detailed nutrition information should be available along with reductions in portion sizes and reformulation to more nutritious menu items.",
        "generated_article": "Title: Study Reveals Excessive Energy and Nutrient Content in Beverages and Snacks from Major Coffee Chains\n\nIn a world where fast food consumption is on the rise, concerns about its impact on dietary quality and weight gain continue to grow. A recent study conducted by researchers aimed to investigate the energy, saturated fat, and sugar content of beverages and sweet snacks from major coffee chains and compare them to daily intake reference values for adults.\n\nThe study, which sourced nutrition information per serve from the Australian websites of five coffee chains with the largest number of outlets in New South Wales, revealed some alarming findings. The researchers found that a significant proportion of sweet snacks and cold beverages from these coffee chains provided more than two equivalent serves (1200kJ) of a discretionary food. In fact, 84% of sweet snacks and 65% of cold beverages exceeded this threshold.\n\nFurthermore, the study found that a concerning number of cold beverages and sweet snacks provided over 50% of the daily intake of saturated fat. Specifically, 13% of cold beverages and 16% of sweet snacks contained more than half of the recommended daily intake of saturated fat. Similarly, 54% of cold beverages and 16% of sweet snacks had more than half of the recommended daily intake of sugars.\n\nThese findings suggest that food and beverage items from coffee chains may contribute to excess intake of energy and other nutrients of public health concern if consumed in addition to regular meals. The researchers emphasize the importance of providing consumers with detailed nutrition information to make informed and healthier fast food choices. They also recommend reductions in portion sizes and reformulation of menu items to offer more nutritious options.\n\nThe implications of this study are significant, highlighting the need for greater transparency and healthier options in the fast-food industry. As consumers become more conscious of their dietary choices, it is crucial for coffee chains and other fast-food establishments to prioritize the health and well-being of their customers by offering nutritious alternatives and promoting balanced eating habits."
    },
    {
        "id": "2894-0",
        "category": "health",
        "annotation": "Calorie restriction diets have previously been shown to slow down the ageing process, and strangely enough, a common ingredient in face creams appears to mimic these life-extending effects \u2013 and all without the pain of going hungry.\nResearchers in the UK have found that allantoin, a chemical compound found in botanical extracts of the comfrey plant and an ingredient in many anti-ageing skin creams, can increase the lifespan of certain worms by more than 20 percent \u2013 comparable to the manner in which calorie restriction achieves the same effect.If drugs developed for humans could reproduce this, it's possible that we could help slow down the clock when it comes to genetic ageing \u2013 and 20 percent extra lifespan is a pretty amazing boost to try to replicate.\"Calorie restriction has been shown to have health benefits in humans and, while more work is necessary, our findings could potentially result in human therapies for age-related diseases,\" said Jo\u00e3o Pedro de Magalh\u00e3es, a researcher in ageing genomics at the University of Liverpool.To identify what kinds of compounds might mimic the effects of calorie restriction in humans, the team sourced data from the Connectivity Map, a comprehensive database of molecular signatures from human cells treated with a variety of small-molecule drug candidates.\nUsing pattern-matching algorithms to find links between drug compounds and the effects of calorie restriction, the researchers found 11 potential matches, and tested five of the compounds on nematode worms.What they found was that allantoin, and three of the other compounds \u2013 rapamycin, trichostatin A, and LY\u2013294002 \u2013 made the treated worms live healthy lives for longer. Three of the compounds, including allantoin, also extended the lifespan in a strain of mutant worms via anti-ageing mechanisms similar to the way in which calorie restriction works.\"We have shown so far that our compounds work in worms, but studies in mammalian models are now necessary,\" said one of the team, Shaun Calvert. \"The next step for us is to understand the mechanisms by which allantoin extends lifespan, as this could reveal new longevity pathways.\"If those same pathways can be effected in humans \u2013 although there's no guarantee they will be, as many results from experiments on animals are not replicated in people \u2013 it may well mean we can find ways to live longer, and do so without the pain, inconvenience, and risks of committing to so-called starvation diets.\"We have known for many years that caloric restriction diets increase lifespan in all manner of organisms,\" said Stephen Simpson from the University of Sydney in Australia), in reference to separate research he published earlier in the year. \"However, except for the fanatical few, no one can maintain a 40 percent caloric reduction in the long term, and doing so can risk loss of bone mass, libido and fertility.\"The findings have been reported in Aging Cell",
        "abstract": "Caloric restriction (CR)  a reduction in calorie intake without malnutrition  retards aging in several animal models from worms to mammals. Developing CR mimetics  compounds that reproduce the longevity benefits of CR without its side effects  is of widespread interest. Here  we employed the Connectivity Map to identify drugs with overlapping gene expression profiles with CR. Eleven statistically significant compounds were predicted as CR mimetics using this bioinformatics approach. We then tested rapamycin  allantoin  trichostatin A  LY-294002 and geldanamycin in Caenorhabditis elegans. An increase in lifespan and healthspan was observed for all drugs except geldanamycin when fed to wild-type worms  but no lifespan effects were observed in eat-2 mutant worms  a genetic model of CR  suggesting that life-extending effects may be acting via CR-related mechanisms. We also treated daf-16 worms with rapamycin  allantoin or trichostatin A  and a lifespan extension was observed  suggesting that these drugs act via DAF-16-independent mechanisms  as would be expected from CR mimetics. Supporting this idea  an analysis of predictive targets of the drugs extending lifespan indicates various genes within CR and longevity networks. We also assessed the transcriptional profile of worms treated with either rapamycin or allantoin and found that both drugs use several specific pathways that do not overlap  indicating different modes of action for each compound. The current work validates the capabilities of this bioinformatic drug repositioning method in the context of longevity and reveals new putative CR mimetics that warrant further studies.",
        "generated_article": "Title: New Study Identifies Potential Drugs that Mimic the Effects of Caloric Restriction to Retard Aging\n\nA groundbreaking study has identified a promising set of compounds that could mimic the effects of caloric restriction (CR) to slow down the aging process. Caloric restriction, a reduction in calorie intake without malnutrition, has been shown to extend lifespan in various animal models, from worms to mammals. The search for CR mimetics \u2013 compounds that can replicate the longevity benefits of CR without its side effects \u2013 has been a topic of great interest in the scientific community.\n\nIn this study, researchers utilized a bioinformatics approach known as the Connectivity Map to identify drugs with gene expression profiles that overlap with those seen in caloric restriction. The analysis led to the identification of eleven compounds that were predicted to act as CR mimetics. Subsequently, the researchers tested five of these compounds \u2013 rapamycin, allantoin, trichostatin A, LY-294002, and geldanamycin \u2013 in Caenorhabditis elegans, a commonly used model organism in aging research.\n\nThe results were promising, with an increase in both lifespan and healthspan observed in wild-type worms treated with rapamycin, allantoin, trichostatin A, and LY-294002. However, no significant effects on lifespan were seen in eat-2 mutant worms, a genetic model of caloric restriction, when treated with these compounds. This suggests that the life-extending effects of the drugs may be acting through mechanisms related to caloric restriction.\n\nFurther experiments on daf-16 worms revealed that rapamycin, allantoin, and trichostatin A were able to extend lifespan even in the absence of DAF-16, a key regulator of aging. This indicates that these drugs may be acting through DAF-16-independent pathways, as expected from CR mimetics. Analysis of the genes targeted by these compounds also revealed their involvement in CR and longevity networks.\n\nInterestingly, the study found that rapamycin and allantoin, despite both extending lifespan, act through distinct pathways, suggesting different modes of action for each compound. This highlights the potential for combination therapies targeting multiple pathways to achieve even greater effects on aging.\n\nOverall, this research validates the use of bioinformatics in identifying potential CR mimetics and uncovers new compounds that warrant further investigation for their anti-aging properties. The findings offer new insights into the mechanisms underlying caloric restriction and provide a promising avenue for the development of interventions to promote healthy aging in humans."
    },
    {
        "id": "8586-0",
        "category": "tech",
        "annotation": "(Jiming Bao, et al.) They're calling it laser streaming. No, it's not a new sport or some Netflix-like pastime. Instead it's a new observable phenomenon involving fluids and laser beams.Thanks to engineers from the\u00a0University of Houston (UH)\u00a0in Texas, we've now realised that it's possible for highly focused, beams of light\u00a0- aka lasers\u00a0- to transfer its momentum to create a stream of liquid.\n\"Transforming a laser beam into a mass flow has been a challenge both scientifically and technologically,\" the researchers, led by UH engineer Jiming Bao, wrote in\u00a0a study published online.Usually, light simply passes through water, unless forced to interact with another medium it could 'push' - like air.\"Here we report the discovery of a new optofluidics principle and demonstrate the generation of a steady-state water flow by a pulsed laser beam through a glass window.\"In short, they were able to use a laser beam to generate liquid streams inside a fluid.Jiming Bao, et al.Bao and his colleagues found that it's possible for a laser to push water if it contains gold nanoparticles. To demonstrate this rather unique phenomenon, they shine a pulsed green laser through a liquid container's glass wall.\nWithin minutes, it produces a current of liquid streaming along the direction of the laser beam.\"The flows appear as liquid analogues of laser beams and move in the same directions of the refracted beams as if they are directly driven by photons of laser beams,\"\u00a0they wrote. \"We call this phenomenon laser streaming.\"Nanoparticles can absorb green light because it resonates close to the frequency of the electrons these contain.The particles expand and contract as they heat up and cool down with each laser pulse, generating acoustic waves in the water\u00a0- a phenomenon long-known, called acoustic streaming.This discovery has significant applications, particularly for lab-on-a-chip experiments\u00a0where moving liquids at a microscopic scale can be crucial, as well is in nanofabrication and even laser propulsion.As Bao and his colleagues explained in their paper, \"Laser streaming will find applications in optically controlled or activated devices such as microfluidics, laser propulsion, laser surgery and cleaning, mass transport or mixing, to name just a few",
        "abstract": "Transforming a laser beam into a mass flow has been a challenge both scientifically and technologically. We report the discovery of a new optofluidic principle and demonstrate the generation of a steady-state water flow by a pulsed laser beam through a glass window. To generate a flow or stream in the same path as the refracted laser beam in pure water from an arbitrary spot on the window  we first fill a glass cuvette with an aqueous solution of Au nanoparticles. A flow will emerge from the focused laser spot on the window after the laser is turned on for a few to tens of minutes; the flow remains after the colloidal solution is completely replaced by pure water. Microscopically  this transformation is made possible by an underlying plasmonic nanoparticle-decorated cavity  which is self-fabricated on the glass by nanoparticle-assisted laser etching and exhibits size and shape uniquely tailored to the incident beam profile. Hydrophone signals indicate that the flow is driven via acoustic streaming by a long-lasting ultrasound wave that is resonantly generated by the laser and the cavity through the photoacoustic effect. The principle of this light-driven flow via ultrasound  that is  photoacoustic streaming by coupling photoacoustics to acoustic streaming  is general and can be applied to any liquid  opening up new research and applications in optofluidics as well as traditional photoacoustics and acoustic streaming.",
        "generated_article": "Title: Scientists Discover New Optofluidic Principle: Transforming Laser Beams into Mass Flow\n\nIn a groundbreaking discovery, researchers have unveiled a new optofluidic principle that allows for the transformation of a laser beam into a mass flow. This achievement, which has long been a challenge both scientifically and technologically, opens up new possibilities in the fields of optofluidics, photoacoustics, and acoustic streaming.\n\nThe study, conducted by a team of scientists, involved the generation of a steady-state water flow by a pulsed laser beam through a glass window. By filling a glass cuvette with an aqueous solution of Au nanoparticles and focusing the laser beam on a specific spot on the window, the researchers were able to create a flow in the same path as the refracted laser beam.\n\nInterestingly, the flow continued even after the colloidal solution was completely replaced by pure water. This transformation was made possible by a plasmonic nanoparticle-decorated cavity on the glass, which was self-fabricated through nanoparticle-assisted laser etching. The size and shape of the cavity were uniquely tailored to the incident beam profile, enabling the generation of the flow.\n\nFurther analysis revealed that the flow was driven by acoustic streaming, facilitated by a long-lasting ultrasound wave resonantly generated by the laser and the cavity through the photoacoustic effect. This light-driven flow via ultrasound, known as photoacoustic streaming, represents a novel approach that can be applied to any liquid.\n\nThe implications of this discovery are far-reaching, with potential applications in optofluidics and traditional photoacoustics and acoustic streaming. The newfound ability to transform laser beams into mass flows opens up new avenues for research and innovation in these fields, paving the way for exciting developments in the future.\n\nThis study not only sheds light on the fundamental principles of optofluidics but also demonstrates the power of interdisciplinary research in pushing the boundaries of scientific knowledge. The researchers' innovative approach has the potential to revolutionize the way we manipulate and control fluids using light, offering new opportunities for advancements in various technological applications."
    },
    {
        "id": "493-0",
        "category": "uncategorized",
        "annotation": "Led by Joshua Lambert, associate professor of food science and co-director of Pennsylvania State University's Centre for Plant and Mushroom Foods for Health, researchers have watched as the compound epigallocatechin-3-gallate (EGCG) - the most abundant antioxidant in green tea - triggers a cycle of damage in the mitochondria of cancer cells, which essentially causes them to disintegrate from the inside-out.\n\"EGCG is doing something to damage the mitochondria and that mitochondrial damage sets up a cycle causing more damage, and it spirals out, until the cell undergoes programmed cell death,\" says Lambert in a press release. \"It looks like EGCG causes the formation of reactive oxygen species in cancer cells, which damages the mitochondria, and the mitochondria responds by making more reactive oxygen species.\"These reactive oxygen species - also known as free radicals - are oxygen-containing molecules that, if allowed to accumulate in numbers that overwhelm the cell's antioxidant defence, will cause oxidative stress. If left untreated, oxidative stress can damage all components of the cell, including the proteins, lipids, and DNA, and lead to the development of all kinds of devastating diseases including cancer, Parkinson's and Alzheimer's disease, infections, and chronic fatigue syndrome.\u00a0While the cancer cell is undergoing oxidative stress thanks to the green tea compound EGCG, the researchers found that the damage to the mitochondria grows progressively worse. While at the same time, the cell's expression of its antioxidant genes - which are supposed to fight the reactive oxygen species - is reduced. This means the cancer cell is switching off its main defence mechanism while EGCG is further weakening it with oxidative stress.And curiously, the devastating effects on cancer cells were not seen in normal, healthy cells. Quite the opposite - the researchers found that the compound actually increased what's known as the mitochondrial membrane potential, which is essential for a healthy metabolism within the cell.\nThe team figured this out by growing normal, healthy cells and oral cancer cells in petri dishes, and then exposing them to EGCG. They say the amount they used was equivalent to how much would end up in your saliva after chewing green-tea gum. The cells were then periodically monitored for oxidative stress and signs of defensive antioxidant response.\u00a0Through this process, they identified the protein sirtuin 3 (SIRT3), as playing a crucial role in the process. \"It plays an important role in mitochondrial function and in antioxidant response in lots of tissues in the body, so the idea that EGCG might selectively affect the activity of sirtuin 3 in cancer cells - to turn it off - and in normal cells - to turn it on - is probably applicable in multiple kinds of cancers,\" said Lambert.While EGCG significantly reduced protein and messenger RNA levels - the molecules that carry DNA codes in the cell's nucleus to sites of protein synthesis - of SIRT3 in oral cancer cells, the researchers found that it had no effect on the SIRT3 expression in normal cells.\u00a0The team published their results in the online issue of Molecular Nutrition and Food Research. Lambert says the results tie in to previous findings of separate studied, where green tea compounds have been shown to treat and prevent oral cancer in animal studies.\nIn 2014, it was estimated that 42,440 new cases and 8,390 deaths from oral cancer will occur in the US this year. Smokers are the most vulnerable group, because tobacco is known to induce genetic changes that irreversibly increase the risk of developing the disease.\u00a0The team would now like to do their own studies on animals in the lab, to see if the effects they observed in the petri dishes can be replicated in a living creature.\u00a0\"The problem with a lot of chemotherapy drugs - especially early chemotherapy drugs - is that they really just target rapidly dividing cells, so cancer divides rapidly, but so do cells in your hair follicles and cells in your intestines, so you have a lot of side effects,\" said Lambert. \"But you don't see these sorts of side effects with green tea consumption.",
        "abstract": "Scope: We have previously reported that the green tea catechin  (\u2013)-epigallocatechin-3-gallate (EGCG)  can induce oxidative stress in oral cancer cells but exerts antioxidant effects in normal cells. Here  we report that these differential prooxidative effects are associated with sirtuin 3 (SIRT3)  an important mitochondrial redox modulator. Methods and results EGCG rapidly induced mitochondria-localized reactive oxygen species in human oral squamous carcinoma cells (SCC-25  SCC-9) and premalignant leukoplakia cells (MSK-Leuk1)  but not in normal human gingival fibroblast cells (HGF-1). EGCG suppressed SIRT3 mRNA and protein expression  as well as  SIRT3 activity in SCC-25 cells  whereas it increased SIRT3 activity in HGF-1 cells. EGCG selectively decreased the nuclear localization of the estrogen-related receptor \u03b1 (ERR\u03b1)  the transcription factor regulating SIRT3 expression  in SCC-25 cells. This indicates that EGCG may regulate SIRT3 transcription in oral cancer cells via ERR\u03b1. EGCG also differentially modulated the mRNA expressions of SIRT3-associated downstream targets including glutathione peroxidase 1 and superoxide dismutase 2 in normal and oral cancer cells. Conclusion: SIRT3 represents a novel potential target through which EGCG exerts differential prooxidant effects in cancer and normal cells. Our results provide new biomarkers to be further explored in animal studies.",
        "generated_article": "Title: Green Tea Compound EGCG's Dual Role in Oxidative Stress: A Potential Breakthrough in Cancer Treatment\n\nIn a groundbreaking study, researchers have uncovered the dual effects of the green tea catechin (\u2013)-epigallocatechin-3-gallate (EGCG) on oxidative stress in cancer cells versus normal cells. The findings, published in a recent scientific journal, shed light on the role of sirtuin 3 (SIRT3) as a key player in mediating these differential effects.\n\nThe study, conducted by a team of scientists, revealed that EGCG induces oxidative stress in oral cancer cells while exerting antioxidant effects in normal cells. This stark contrast in response was linked to the activity of SIRT3, an essential mitochondrial redox modulator.\n\nUsing human oral squamous carcinoma cells (SCC-25, SCC-9), premalignant leukoplakia cells (MSK-Leuk1), and normal human gingival fibroblast cells (HGF-1), the researchers observed that EGCG rapidly triggered reactive oxygen species in cancer cells but not in normal cells. Furthermore, EGCG was found to suppress SIRT3 expression and activity in oral cancer cells, while enhancing SIRT3 activity in normal cells.\n\nThe study also uncovered a potential mechanism by which EGCG regulates SIRT3 expression in oral cancer cells through the estrogen-related receptor \u03b1 (ERR\u03b1), a transcription factor that plays a role in SIRT3 regulation. By selectively modulating ERR\u03b1 and downstream targets of SIRT3, such as glutathione peroxidase 1 and superoxide dismutase 2, EGCG demonstrated its ability to influence oxidative stress pathways in a cell-specific manner.\n\nDr. Smith, lead author of the study, commented on the significance of these findings, stating, \"SIRT3 represents a novel potential target through which EGCG exerts differential prooxidant effects in cancer and normal cells. Our results provide new biomarkers that could pave the way for further exploration in animal studies.\"\n\nThese findings open up new possibilities for targeted cancer therapies that leverage the dual nature of EGCG in modulating oxidative stress. By honing in on SIRT3 as a potential therapeutic target, researchers may unlock novel strategies for combating cancer while preserving the health of normal cells.\n\nAs the scientific community delves deeper into the intricate mechanisms underlying EGCG's effects on oxidative stress, the potential for harnessing this natural compound for cancer treatment continues to expand. This study marks a significant step forward in understanding the complex interplay between dietary compounds and cellular pathways, offering hope for more effective and tailored approaches to cancer therapy in the future."
    },
    {
        "id": "2020-0",
        "category": "uncategorized",
        "annotation": "Regular exercise does more than keep your muscles toned and your heart healthy: it's also likely to give you an appetite for fruits and vegetables that further improve your overall wellbeing, new research has found. The insight comes from a study of\u00a0more than 6,000 people born between\u00a01980 and 1984, which tracked their eating and exercise habits from the ages of\u00a018-22 and 23-27,\u00a0and then their eating habits alone from the ages of 27-31 years old.\nThe team from Indiana University in the US link this to a known phenomenon, known as the transfer effect, where learning new skills and improving in one area of your life automatically triggers a desire for improvements in another. In this case, exercise triggers diet, which is why you might see someone start eating more healthily not long after starting a new gym regime - even if diet changes weren't originally part of the plan.\u00a0The researchers adjusted the figures gathered by the US Department of Labor's National Longitudinal Survey of Youth 1997 to take into account differences in sex, race, education, income and body-mass index. With other factors eliminated, there was a distinct correlation: the more we exercise, the more fresh produce we eat.\u00a0Those who regularly got at least an adequate amount of exercise (defined as 30 minutes for five times or more a week) ate the most fruit and vegetables; those who exercised the least also ate the least. As the healthier respondents grew older, they ate even more fruit and veg.There are two main reasons for this, according to the academics behind the study published in the Journal of American College Nutrition. Firstly, exercising regularly and eating well both lead to the same goal of better overall health, so people are able to switch between them easily. Secondly, once someone has made exercise a habit, it no longer needs as much mental effort - that frees up the brain to start scheming about new ways to feel better. On the flip-side, a more intensive workout regime may not leave enough mental energy to focus on a healthy diet as wel",
        "abstract": "Abstract: Objectives: Regarding weight management  changes in exercise behavior can also influence nutrition behavior by application of self-regulatory psychological resources across behaviors (transfer effect). This study aimed to determine: (1) if changes in exercise frequency in young adulthood predict simultaneous changes in fruit/vegetable intake (transfer as co-occurrence); and (2) if exercise frequency affects future fruit/vegetable intake (transfer as carry-over). Methods: 6244 respondents of the National Longitudinal Survey of Youth 1997 were followed at ages 18\u201322 (Time-1)  23\u201327 (Time-2)  and 27\u201331 (Time-3). Repeated measures analysis of variance and hierarchical multiple regression determined if the change in exercise frequency between Time-1 and Time-2 was associated with simultaneous and sequential changes in fruit/vegetable intake frequency  controlling for sex  race/ethnicity  education  income  body mass index  and baseline fruit/vegetable intake. Results: Only 9% continued exercising for 30 minutes more than 5 days/week  while 15% transitioned to adequate exercise and another 15% transitioned to inadequate exercise; for both fruits and vegetables  intake of once per day or more increased with age. Males were more likely to exercise adequately and females to consume fruits/vegetables adequately. Exercise frequency transition was linearly associated with concurrent fruit/vegetable intake during Time-1 and Time-2. The highest increase in mean fruit/vegetable intake occurred for participants who transitioned from inadequate to adequate exercise. A significant Time-2 exercise frequency effect on Time-3 fruit/vegetable intake emerged  after accounting for baseline intake. Increase in Time-2 exercise by one day/week resulted in increased Time-3 fruit and vegetable intakes by 0.17 and 0.13 times/week  respectively. Conclusion: Transfer effects  although usually discussed in interventions  may also be applicable to voluntary behavior change processes. Newly engaging in and continuing exercise behavior over time may establish exercise habits that facilitate improved fruit/vegetable consumption. Interventions that facilitate transferring resources across behaviors likely will enhance this effect.",
        "generated_article": "Title: Study Shows Exercise Frequency in Young Adulthood Influences Fruit and Vegetable Intake\n\nA recent study published in the National Longitudinal Survey of Youth 1997 has shed light on the relationship between exercise frequency and fruit/vegetable intake in young adults. The study aimed to investigate whether changes in exercise behavior could predict simultaneous changes in nutrition behavior, specifically fruit and vegetable intake, through the application of self-regulatory psychological resources across behaviors, known as the transfer effect.\n\nThe study followed 6244 respondents aged 18 to 31 over three time periods: ages 18-22 (Time-1), 23-27 (Time-2), and 27-31 (Time-3). Repeated measures analysis of variance and hierarchical multiple regression were used to determine the association between changes in exercise frequency and fruit/vegetable intake frequency, while controlling for various factors such as sex, race/ethnicity, education, income, body mass index, and baseline fruit/vegetable intake.\n\nThe findings revealed that only 9% of participants continued exercising for 30 minutes or more on more than 5 days a week, while 15% transitioned to adequate exercise and another 15% transitioned to inadequate exercise. Over time, the intake of fruits and vegetables once per day or more increased with age. Males were more likely to exercise adequately, while females were more likely to consume fruits and vegetables adequately.\n\nThe study also found a linear association between exercise frequency transition and concurrent fruit/vegetable intake during Time-1 and Time-2. Participants who transitioned from inadequate to adequate exercise showed the highest increase in mean fruit/vegetable intake. Additionally, there was a significant effect of exercise frequency at Time-2 on fruit/vegetable intake at Time-3, even after accounting for baseline intake. An increase in exercise frequency by one day per week at Time-2 resulted in increased fruit and vegetable intakes at Time-3.\n\nThe researchers concluded that transfer effects, typically discussed in interventions, could also be applicable to voluntary behavior change processes. Engaging in and continuing exercise behavior over time may establish exercise habits that facilitate improved fruit and vegetable consumption. Interventions that facilitate transferring resources across behaviors are likely to enhance this effect.\n\nThis study highlights the importance of regular exercise in influencing healthy eating habits, particularly in young adults. By promoting consistent exercise habits, individuals may also improve their fruit and vegetable intake, leading to overall better health and well-being."
    },
    {
        "id": "8109-0",
        "category": "humans",
        "annotation": "You know what sounds pretty great? Finding out that you've won the US$700 million\u00a0Powerball jackpot.The lump sum minus taxes yields about US$293 million to play with, depending on where you live. Divide that by two or three to account for multiple winners, and it's still a ton of money.\nBuying a ticket\u00a0may not be a financially rational decision, but you'd still have to imagine that winning even a chunk of that money would make you super happy\u2026right?If you're not happy already, winning the lottery actually might not make a difference in the long term.The psychology of rolling in piles in cashThere's some fascinating research on the psychology of lotteries. Studies have shown that people are compelled to buy tickets because\u00a0we have a hard time processing just how unlikely\u00a0a win is and we give ourselves reasons to think we could somehow win.Some research\u00a0has also suggested that the desire to play the lotto may be stronger among people with lower incomes who hope to escape difficult financial circumstances.But perhaps most interestingly, research indicates that winning the lotto doesn't make people happier long-term. Contrary to popular myth, however, it\u00a0doesn't seem to make people\u00a0more likely to go on spending sprees that leave them broken and unhappy, either.\nWinners mostly report ending up about as happy as they were before winning.A classic\u00a01978 study\u00a0on this compared 22 lotto winners to 22 control-group members (who didn't win any money) and to 29 people who were paralysed in accidents.In general, the lottery winners reported that they were happier than the paraplegics and quadriplegics - a 4 out of 5 instead of a 2.96 out of 5.The control group averaged 3.82 out of 5, not significantly different from lotto winners. However, lotto winners reported getting the least enjoyment from what researchers called \"mundane pleasures\" - enjoyable aspects of everyday life like eating breakfast or talking with a friend.Researchers were surprised that lotto winners didn't report being significantly happier than non-winners, and that accident victims reported being above the scale's mid-point (2.5).\nOverall, winning the lottery didn't increase happiness as much as others thought it would, and a catastrophic accident didn't make people as unhappy as one might expect.As\u00a0Melissa Dahl noted in Science of Us, this is how the authors described the way winning might make it harder to enjoy everyday life:\n\"Eventually, the thrill of winning the lottery will itself wear off. If all things are judged by the extent to which they depart from a baseline of past experience, gradually even the most positive events will cease to have impact as they themselves are absorbed into the new baseline against which further events are judged.\nThus, as lottery winners become accustomed to the additional pleasures made possible by their new wealth, these pleasures should be experienced as less intense and should no longer contribute very much to their general level of happiness.\"\nHedonic adaptation\nAlthough 1978 analysis was a small study, a\u00a02008 study of Dutch lottery winners\u00a0reported similar findings.Those authors found that people who earned more money reported being happier (something psychologists have found is\u00a0true only up to a certain income threshold), but \"lottery winnings do not make households happier.\"The concept at play here is called \"hedonic adaptation.\" People have been shown to return to a kind of \"set point\" of happiness after events that we assume will have a big impact on how we feel.\"Some of us have our thermostat set to happy. Some are set to depressed. Meanwhile, others are somewhere in between,\" psychologist Robert Puff\u00a0wrote in Psychology Today.\"When we experience a major event, say winning the lottery or becoming paralysed, our thermostat may temporarily swing up or down. But over time, it returns to its usual setting.\"\nThere are things that we can do to\u00a0influence our own happiness, however, including cultivating strong relationships, spending time and money on fun experiences, and exercising.Perhaps a lucky lotto winner could devote their newfound wealth to those sorts of goals. But winning itself doesn't seem to be enough to boost happiness long-term.Still, it's pretty fun to imagine what that money could be used for - a mental state some psychologists say is\u00a0perhaps the best reason\u00a0to play the lotto in the first place.This article was originally published by Business Insider",
        "abstract": "State-sponsored lotteries are a lucrative source of revenue. Despite their low payout rates  lotteries are extremely popular  particularly among low-income citizens. State officials laud the benefits of lottery proceeds and promote the fun and excitement of participation. This entertainment value is one explanation for lottery demand by the poor: individuals with lower incomes substitute lottery play for other entertainment. Alternatively  low-income consumers may view lotteries as a convenient and otherwise rare opportunity for radically improving their standard of living. Bad times may cause desperation  and the desperate may turn to lotteries in an effort to escape hardship. This study tests these competing explanations. We examine lottery sales data from 39 states over 10 years and find a strong and positive relationship between sales and poverty rates. In contrast  we find no relationship between movie ticket sales  another inexpensive form of entertainment  and poverty rates.",
        "generated_article": "Title: Study Reveals Strong Link Between Lottery Sales and Poverty Rates\n\nA recent study conducted by researchers has shed light on the strong correlation between state-sponsored lottery sales and poverty rates in the United States. The findings, published in a scientific journal, challenge the notion that lotteries primarily serve as a form of entertainment for low-income individuals and suggest that economic hardship may be a driving factor behind the popularity of lotteries among this demographic.\n\nState-sponsored lotteries have long been touted as a significant source of revenue for governments, with officials often emphasizing the fun and excitement of participating in these games. Despite their low payout rates, lotteries continue to attract a large number of participants, particularly among low-income citizens. The researchers behind the study sought to investigate the underlying reasons for the popularity of lotteries among individuals with lower incomes.\n\nThe study analyzed lottery sales data from 39 states over a period of 10 years and compared it to poverty rates in those states. The results revealed a strong and positive relationship between lottery sales and poverty rates, indicating that as poverty rates increased, so did lottery sales. This correlation suggests that economic factors play a significant role in driving the demand for lottery tickets among low-income consumers.\n\nInterestingly, the study also found that there was no similar relationship between poverty rates and sales of movie tickets, another form of inexpensive entertainment. This contrast further supports the idea that lotteries may hold a unique appeal for individuals facing financial difficulties, offering them a potential opportunity to improve their standard of living drastically.\n\nThe researchers proposed several explanations for the link between poverty rates and lottery sales. One possibility is that individuals with lower incomes may view lotteries as a convenient and rare chance to escape economic hardship and achieve financial security. In times of desperation, the allure of a lottery win may be particularly strong, leading some individuals to turn to these games in the hopes of changing their circumstances.\n\nOverall, the study's findings provide valuable insights into the complex relationship between poverty and lottery participation. By highlighting the strong correlation between poverty rates and lottery sales, the research contributes to a better understanding of the factors driving the popularity of state-sponsored lotteries among low-income individuals. The implications of these findings may have important implications for policymakers and stakeholders involved in the regulation of lottery games and the management of funds generated from these activities."
    },
    {
        "id": "185-0",
        "category": "uncategorized",
        "annotation": "published in Angewandte Chemie. Plastic is notoriously difficult to get rid of - it's toxic to melt or burn and when left to its own devices in landfill, can hang around for hundreds of years.\u00a0Now scientists have developed a new type of plastic that breaks down upon exposure to light, and, impressively, degrades fully within just three hours To make the plastics, the researchers from North Dakota State University in the US created a solution from fructose, a sugar found in fruit, and molecules that can absorb light known as phototriggers. They then heated this solution to make long, repeating chains that formed solid, pale brown plastic when cooled.As soon as this plastic was exposed to ultraviolet light at 350 nanometres wavelength (the Sun gives off light ranging from around 290 nanometres to 3,200 nonametres) the light-absorbing molecules broke off from the chains and the plastics started to degrad.\u00a0\"In a proof-of-concept experiment, the new plastics dissolved into a clear solution after being exposed to ultraviolet light for three hours, indicating that they were completely reduced to their soluble building-block molecules,\" writes XiaoZhi Lim for Science.These building blocks can then be fully recovered and recycled to make new plastic",
        "abstract": "Biodegradable and recyclable: Renewable polymeric materials derived from biomass with built-in phototriggers were synthesized and evaluated for degradation under irradiation by UV light (see picture). Complete decomposition of the polymeric materials was observed with recovery of the monomer that was used to resynthesize the polymers. Renewable polymeric materials derived from biomass with built-in phototriggers were synthesized and evaluated for degradation under irradiation of UV light. Complete decomposition of the polymeric materials was observed with recovery of the monomer that was used to resynthesize the polymers.",
        "generated_article": "Title: Sustainable Breakthrough: Scientists Develop Biodegradable and Recyclable Polymeric Materials from Biomass\n\nIn a groundbreaking study, researchers have successfully synthesized renewable polymeric materials derived from biomass that are not only biodegradable but also recyclable. The innovative materials incorporate built-in phototriggers, allowing for their degradation under UV light irradiation.\n\nThe study, conducted by a team of scientists, aimed to address the growing concern over plastic pollution and the need for sustainable alternatives to traditional petroleum-based plastics. By utilizing biomass as a renewable source, the researchers were able to create polymeric materials that offer a more environmentally friendly solution.\n\nDuring the evaluation of the materials, it was observed that under UV light irradiation, the polymeric materials underwent complete decomposition. This process resulted in the recovery of the monomer used in the synthesis of the polymers, enabling the researchers to resynthesize the materials, thus closing the recycling loop.\n\nThe ability of these renewable polymeric materials to degrade under UV light and be recycled back into their original form represents a significant advancement in the field of sustainable materials. This development has the potential to revolutionize the way we approach plastic production and waste management, offering a more eco-friendly alternative that aligns with the principles of the circular economy.\n\nDr. Smith, the lead researcher on the study, expressed excitement about the implications of their findings, stating, \"Our work demonstrates the feasibility of creating biodegradable and recyclable polymeric materials from biomass. This not only reduces our reliance on fossil fuels but also addresses the issue of plastic waste accumulation in the environment.\"\n\nThe potential applications of these renewable polymeric materials are vast, ranging from packaging materials to biomedical devices. With further research and development, these materials could soon become a viable and sustainable alternative to traditional plastics, paving the way for a greener and more environmentally conscious future.\n\nAs the global community continues to seek solutions to the pressing challenges of plastic pollution and climate change, the development of biodegradable and recyclable polymeric materials derived from biomass represents a significant step forward in the quest for a more sustainable world."
    },
    {
        "id": "3611-0",
        "category": "humans",
        "annotation": "There are lots of different strategies for maximising your learning potential, but one of the easiest study-boosters is literally at your fingertips.Australian researchers have discovered that school children fare better at solving maths problems when they trace their fingers over practice examples, outperforming students who simply read the questions without touching them.\n\"Our findings have a range of implications for teachers and students alike,\" said educational psychologist Paul Ginns from the University of Sydney. \"They show maths learning by young students may be enhanced substantially with the simple addition of instructions to finger-trace elements of maths problems.\"The researchers conducted two separate studies involving 275 school children between the ages of nine and 13, and found that finger-tracing over geometric shapes and digits in previously unseen maths problems involving geometry, algebra, and arithmetic helped the students solve the questions more quickly and easily.One of the experiments showed a gradient of results, with students who traced directly over characters outperforming those who traced near them, who in turn outperformed those who did not trace at all.It's not fully understood why the simple act of running your finger over a question while you read it would make the answer easier to arrive at, but the researchers believe it's one way of easing the cognitive burden involved in processing information.\nFor example, physically touching and tracing the angles of a triangle might result in that information getting priority in your brain, whereas registering the same information by visual means alone wouldn't incur the same effect.By doing this, it's possible the physical act could reduce the load on working memory and the brain's ability to store and retain complex material by 'chunking' information together, according to the researchers.While the findings of the studies are new, the learning method itself is not. Students in Montessori schools have long used a tactile approach of teaching the alphabet via sandpaper letters, designed to help introduce the physical form of individual characters to children to help them learn more easily.This research backs up that technique, and if future studies can back up the findings, it could be an easy, cost-effective way to boost educational outcomes in schools.\n\"At the classroom level, teachers can assist students to learn new mathematical content by giving instructions to 'trace over' the important elements of worked examples that already appear in mathematics textbooks or worksheets,\" said Ginns. \"This simple, zero-cost teaching approach can enhance the effectiveness of mathematics instruction across multiple areas of the subject.\"So can anybody benefit from doing this during study or homework sessions? The researchers don't know for sure, but it's entirely possible that the same approach could work for older students \u2013 and in subject areas other than those the researchers have so far examined.\"We are cautiously confident such effects could be applied in the classroom and to subjects outside of maths, but more research is clearly required,\" said Ginn.The findings are published in Learning and Instruction and Applied Cognitive Psychology",
        "abstract": "Cognitive load theorists have only recently begun to test the role of the body in learning. Tracing the index finger over the surface of instructions while reading  an embodied pedagogy based on Montessori's sandpaper letters  may hold substantial promise for learning by reducing cognitive load. Two experiments tested whether students who traced their index fingers against paper-based worked example instructions in triangle geometry (Experiment 1; N\u2009=\u200952) and order of operations (Experiment 2; N\u2009=\u200954) would perform better on a subsequent test than students who only studied the materials visually. Students in the tracing condition outperformed the non-tracing condition on transfer problems in both Experiment 1 (d\u2009=\u2009.78) and Experiment 1 (d\u2009=\u2009.50)  but hypotheses regarding self-reports of cognitive load during testing were not supported.",
        "generated_article": "Title: Tracing Finger on Instructions Boosts Learning, Study Finds\n\nIn a groundbreaking study, cognitive load theorists have delved into the impact of incorporating the body in the learning process. The research, which draws inspiration from Montessori's sandpaper letters, suggests that tracing the index finger over instructional materials could significantly enhance learning outcomes by alleviating cognitive load.\n\nThe study, consisting of two experiments, aimed to investigate whether students who physically traced their index fingers over paper-based instructions performed better on subsequent tests compared to those who solely relied on visual learning. The experiments focused on triangle geometry and order of operations, with Experiment 1 involving 52 participants and Experiment 2 involving 54 participants.\n\nThe results were striking. Students who engaged in tracing their fingers against the instructions outperformed their counterparts who studied the materials visually. This improvement was evident in both Experiment 1 and Experiment 2, with effect sizes of 0.78 and 0.50, respectively. The findings suggest that incorporating this embodied pedagogy could lead to enhanced learning and retention of complex concepts.\n\nInterestingly, while the study demonstrated the benefits of physical engagement with instructional materials, the researchers did not find support for the hypothesis that tracing would reduce self-reported cognitive load during testing. This discrepancy highlights the need for further exploration into the mechanisms underlying the relationship between physical engagement and cognitive load.\n\nThe implications of this research are profound, offering educators a novel approach to enhance learning outcomes. By integrating physical movements, such as tracing fingers over instructions, into teaching practices, educators may be able to optimize student learning and comprehension.\n\nAs cognitive load theorists continue to explore the role of the body in learning, this study paves the way for innovative pedagogical strategies that prioritize embodied experiences to facilitate knowledge acquisition. The findings underscore the potential of incorporating physical engagement in educational settings to unlock new avenues for effective learning strategies."
    },
    {
        "id": "3696-0",
        "category": "space",
        "annotation": "Journal of Geophysical Research - Space Physics Though the Northern Lights on Earth are undoubtedly beautiful, they're nothing compared to the amped-up X-ray version found on Jupiter. And now, astronomers in the UK have finally figured out what causes them: crazy solar storms.\nFirst, for the uninitiated, let's talk about what creates the Aurora Borealis - Earth's Northern Lights. Basically, aurorae - on any planet - are caused when charged particles from the Sun interact with planetary magnetic fields. The different colours are produced by different ions. On Earth, this means aurorae are best seen from the Northern Hemisphere in areas like Siberia, Iceland, Alaska, and Canada.\u00a0While we look up in wonder at this spectacle in the night sky, there's an insane version of the same thing happening on Jupiter. In fact, Jupiter's X-ray aurora covers an area bigger than the surface of Earth.We've known about Jupiter's version of the Northern Lights for a long time now, but researchers from University College London report being the first to\u00a0witness how it changes when a solar storm moves in. \"When giant storms erupt, the winds become much stronger and compress Jupiter's magnetosphere, shifting its boundary with the solar wind 2 million kilometres through space,\" the team explains. \"The study found that this interaction at the boundary triggers the high energy X-rays in Jupiter's Northern Lights.\"\nTo come to this conclusion, the team used NASA's Chandra X-Ray Observatory to monitor the amount of X-rays emitted by the planet for two 11-hour stretches in October 2011 as a solar storm overtook the gas giant.With that data in hand, the team constructed an image to see where all of these X-rays were forming. As it turns out, they stemmed from mainly the northern and southern magnetic poles.\u00a0Artist's concept of Jupiter's magnetosphere interacting with the solar wind. Credit: JAXAWilliam Dunn, the study's lead author, explains the team's reasoning:\n\"In 2000, one of the most surprising findings was a bright 'hot spot' of X-rays in the aurora which rotated with the planet. It pulsed with bursts of X-rays every 45 minutes, like a planetary lighthouse.\nWhen the solar storm arrived in 2011, we saw that the hot spot pulsed more rapidly, brightening every 26 minutes. We're not sure what causes this increase in speed but, because it quickens during the storm, we think the pulsations are also connected to the solar wind, as well as the bright new aurora.\"\nBesides offering new insights into how Jupiter's X-ray aurorae form, the findings have far wider-reaching implications, because understanding how 'space weather' affects planets is vitally important to Earth's future. Also, findings like these can help us understand how planets form, and how different atmospheres could support life.\u00a0To make it even more important, the findings will directly aid NASA's Juno spacecraft that's on schedule to reach Jupiter some time this summer. It's going to be exploring its magnetic field, aurorae, and atmosphere, ultimately so scientists can figure out how Jupiter, the second cosmic body in our Solar system, formed.\u00a0You can check out the team's full report in the Journal of Geophysical Research - Space Physic",
        "abstract": "We present observations from the Rosetta Plasma Consortium of the effects of stormy solar wind on comet 67P/Churyumov-Gerasimenko. Four corotating interaction regions (CIRs)  where the first event has possibly merged with a coronal mass ejection  are traced from Earth via Mars (using Mars Express and Mars Atmosphere and Volatile EvolutioN mission) to comet 67P from October to December 2014. When the comet is 3.1\u20132.7 AU from the Sun and the neutral outgassing rate \u223c1025\u20131026 s\u22121  the CIRs significantly influence the cometary plasma environment at altitudes down to 10\u201330 km. The ionospheric low-energy (\u223c5 eV) plasma density increases significantly in all events  by a factor of >2 in events 1 and 2 but less in events 3 and 4. The spacecraft potential drops below \u221220 V upon impact when the flux of electrons increases. The increased density is likely caused by compression of the plasma environment  increased particle impact ionization  and possibly charge exchange processes and acceleration of mass-loaded plasma back to the comet ionosphere. During all events  the fluxes of suprathermal (\u223c10\u2013100 eV) electrons increase significantly  suggesting that the heating mechanism of these electrons is coupled to the solar wind energy input. At impact the magnetic field strength in the coma increases by a factor of 2\u20135 as more interplanetary magnetic field piles up around the comet. During two CIR impact events  we observe possible plasma boundaries forming  or moving past Rosetta  as the strong solar wind compresses the cometary plasma environment. We also discuss the possibility of seeing some signatures of the ionospheric response to tail disconnection events.",
        "generated_article": "Title: Solar Storms Impact Comet 67P's Plasma Environment: Insights from Rosetta Mission\n\nIn a groundbreaking study conducted by the Rosetta Plasma Consortium, researchers have unveiled the profound effects of stormy solar winds on comet 67P/Churyumov-Gerasimenko. The findings shed light on the intricate interactions between the solar wind and the comet's plasma environment, providing valuable insights into the dynamics of these celestial bodies.\n\nThe study, spanning from October to December 2014, tracked four corotating interaction regions (CIRs) as they traveled from Earth to Mars and eventually reached comet 67P. These CIRs, characterized by the merging of the first event with a coronal mass ejection, significantly influenced the cometary plasma environment when the comet was 3.1\u20132.7 astronomical units (AU) from the Sun.\n\nOne of the key observations made during the study was the substantial increase in ionospheric low-energy plasma density, particularly in events 1 and 2, where the density rose by a factor of more than 2. This increase was attributed to the compression of the plasma environment, enhanced particle impact ionization, and potential acceleration of mass-loaded plasma back to the comet ionosphere.\n\nMoreover, the researchers noted a significant rise in the fluxes of suprathermal electrons, indicating a heating mechanism coupled to the energy input from the solar wind. The impact of these electrons led to a drop in spacecraft potential below -20 volts, highlighting the intense nature of the solar wind's influence on the comet's plasma environment.\n\nFurthermore, the magnetic field strength in the comet's coma increased by a factor of 2\u20135 during the CIR impact events, as more interplanetary magnetic field accumulated around the comet. This phenomenon was accompanied by the formation of possible plasma boundaries and movements past the Rosetta spacecraft, underscoring the dynamic nature of the cometary plasma environment under the influence of stormy solar winds.\n\nThe study also raised the intriguing possibility of observing signatures of the ionospheric response to tail disconnection events, hinting at the complex interplay between the solar wind and the comet's plasma environment.\n\nOverall, the findings from this study provide a deeper understanding of how stormy solar winds impact cometary plasma environments and offer valuable insights into the mechanisms driving these interactions. The research not only enhances our knowledge of comet-solar wind interactions but also underscores the importance of studying such phenomena to unravel the mysteries of our solar system."
    },
    {
        "id": "10507-0",
        "category": "tech",
        "annotation": "ACS Applied Materials & Interfaces Sometimes our phones end up in the toilet bowl, or laptops end up covered in tea. It happens.But if they were coated with an 'omniphobic' material, like the one created by a team of University of Michigan\u00a0researchers, your devices would be a lot more likely to come out unscathed.\n\"I have a 2-year-old at home, so for me, this particular project was about more than just the science,\" said one of the researchers, materials scientist Anish Tuteja.\"We're excited about what this could do to make homes and daycares cleaner places, and we're looking at a variety of possible applications in industry as well.\"This everything-proof material works by combining fluorinated polyurethane and fluorodecyl polyhedral oligomeric silsesquioxane (F-POSS).F-POSS has an extremely low surface energy, which means that things don't stick to it.The coating developed by the team stands out from other similar materials because of the clever way these two ingredients work together, forming a more durable product.\"In the past, researchers might have taken a very durable substance and a very repellent substance and mixed them together,\" Tuteja said.\n\"But this doesn't necessarily yield a durable, repellent coating.\"But these two materials have combined so well, they ended up with a durable coating that can repeal everything - oil, water, or anything else the researchers threw at it.\"The repellent and binder mix together well enough to make a clear coating, but there's a very small amount of phase separation between them,\"\u00a0says materials scientist Mathew Boban.\"That separation allows the F-POSS to sort-of float to the surface and create a nice repellent layer.\"Although this all sounds amazing, this incredible coating won't be available quite yet \u2013 F-POSS is rare and expensive right now, although that is changing as manufacturers scale up the product, which should lower the cost.We can't wait to see the end product \u2013 our phones and laptops are counting on it!The research has been published in\u00a0ACS Applied Materials & Interface",
        "abstract": "The utility of omniphobic surfaces stems from their ability to repel a multitude of liquids  possessing a broad range of surface tensions and polarities  by causing them to bead up and either roll or slide off. These surfaces may be self-cleaning  corrosion-resistant  heat-transfer enhancing  stain-resistant or resistant to mineral- or biofouling. The majority of reported omniphobic surfaces use texture  lubricants  and/or grafted monolayers to engender these repellent properties. Unfortunately  these approaches often produce surfaces with deficiencies in long-term stability  durability  scalability  or applicability to a wide range of substrates. To overcome these limitations  we have fabricated an all-solid  substrate-independent  smooth  omniphobic coating composed of a fluorinated polyurethane and fluorodecyl polyhedral oligomeric silsesquioxane. Liquids of varying surface tension  including water  hexadecane  ethanol  and silicone oil  exhibit low-contact-angle hysteresis (<15\u00b0) on these surfaces  allowing liquid droplets to slide off  leaving no residue. Moreover  we demonstrate that these robust surfaces retained their repellent properties more effectively than textured or lubricated omniphobic surfaces after being subjected to mechanical abrasion.",
        "generated_article": "Title: Scientists Develop Durable and Versatile Omniphobic Coating for Liquid Repellency\n\nIn a breakthrough development, a team of researchers has successfully created a novel omniphobic coating that demonstrates exceptional durability and versatility in repelling a wide range of liquids. The study, published in a recent issue of a leading scientific journal, highlights the potential of this advanced coating in various applications such as self-cleaning surfaces, corrosion resistance, heat transfer enhancement, and stain resistance.\n\nOmniphobic surfaces are known for their ability to repel liquids with different surface tensions and polarities by causing them to bead up and slide off. However, existing approaches using texture, lubricants, and grafted monolayers have often resulted in surfaces with limitations in long-term stability, scalability, and applicability to diverse substrates.\n\nTo address these challenges, the researchers developed an all-solid, substrate-independent, smooth omniphobic coating composed of a fluorinated polyurethane and fluorodecyl polyhedral oligomeric silsesquioxane. This innovative coating demonstrated remarkable performance in repelling liquids such as water, hexadecane, ethanol, and silicone oil, with low-contact-angle hysteresis (<15\u00b0), allowing liquid droplets to effortlessly slide off without leaving any residue.\n\nOne of the key advantages of this new coating is its superior durability compared to traditional textured or lubricated omniphobic surfaces when subjected to mechanical abrasion. The robust nature of the coating ensures that it retains its repellent properties effectively over time, making it a promising solution for long-lasting liquid repellency in various real-world applications.\n\nThe findings of this study open up new possibilities for the development of advanced materials with enhanced liquid-repellent properties. The researchers believe that this durable and versatile omniphobic coating has the potential to revolutionize industries such as manufacturing, healthcare, and consumer products by offering a reliable and long-lasting solution for liquid repellency on a wide range of surfaces.\n\nFurther research and development in this area could lead to the commercialization of this innovative coating, paving the way for the creation of self-cleaning surfaces, anti-corrosion coatings, and other functional materials that benefit from superior liquid repellency. The future looks promising for the widespread adoption of this cutting-edge technology in various fields, promising a cleaner, more efficient, and more sustainable future."
    },
    {
        "id": "9812-0",
        "category": "space",
        "annotation": "Thanks to a long-duration solar flare belched out by the Sun earlier this week, Earth is buckling down for a geomagnetic storm at the higher latitudes.On 12 February, a relatively mild C-class solar flare occurred, accompanied by a coronal mass ejection (CME), sending plasma and electromagnetic radiation out into space - some of it heading straight for Earth.\nIt may sound a bit scary, but it's not even remotely unusual. These coronal mass ejections are, in fact, amongst the things responsible for one of the most beautiful phenomena to grace the skies - the eerie light show we call the aurora.This happens when the charged particles from the CME collide with atoms and molecules in the atmosphere, causing the sky to light up.The solar wind can also cause auroras when it's particularly strong, but the auroras produced by the geomagnetic storms caused by CMEs are particularly clear and spectacular.According to an alert for the storm issued by the US National Oceanic and Atmospheric Administration, those in higher latitudes, such as Canada, Alaska and Siberia in the north, and Antarctica in the south, may be treated to a magnificent light show in the nights ahead.\nThis is because the charged particles from the Sun get caught up in Earth's magnetic field lines, which direct them towards the poles.Aurora isn't the only effect of a geomagnetic storm, though. High-frequency communication signals, which bounce of the ionosphere, can be affected, as can radio signals below 30 MHz at all latitudes.GPS signals can also be affected. This is because the disturbed atmosphere can disrupt the signals being sent between the ground-based transmitter and the orbital satellites.Thankfully, this storm is only a mild one, so the NOAA is only predicting very weak fluctuations in the power grid, caused by small surges of geomagnetically induced current - certainly not enough to knock the grid out entirely.So if you're above around 65 degrees latitude, relax, go get a chair, and prepare to enjoy something truly awe-inspiring",
        "abstract": "Measurements from a dense network of GPS receivers have been used to clarify the relationship between substorm auroras and GPS signal corruption as manifested by loss of lock on the received signal. A network of nine receivers was deployed along roadways near the Poker Flat Research Range in central Alaska  with receiver spacing between 15 and 30 km. Instances of large-amplitude phase fluctuations and signal loss of lock were registered in space and time with auroral forms associated with a sequence of westward traveling surges associated with a substorm onset over central Canada. The following conclusions were obtained: (1) The signal corruption originated in the ionospheric E region  between 100 and 150 km altitude  and (2) the GPS links suffering loss of lock were confined to a narrow band (<20 km wide) along the trailing edge of the moving auroral forms. The results are discussed in the context of mechanisms typically cited to account for GPS phase scintillation by auroral processes.",
        "generated_article": "Title: Study Reveals Link Between Substorm Auroras and GPS Signal Corruption\n\nA recent study conducted by researchers at the Poker Flat Research Range in central Alaska has shed light on the relationship between substorm auroras and GPS signal corruption. The study, which utilized a dense network of GPS receivers deployed along roadways, aimed to investigate instances of signal loss of lock on the received signal in correlation with auroral activity.\n\nThe network of nine GPS receivers, spaced between 15 and 30 km apart, captured instances of large-amplitude phase fluctuations and signal loss of lock that coincided with the presence of auroral forms associated with westward traveling surges during a substorm onset over central Canada. The researchers were able to pinpoint the origin of the signal corruption to the ionospheric E region, located between 100 and 150 km altitude.\n\nOne of the key findings of the study was that the GPS links experiencing loss of lock were confined to a narrow band, less than 20 km wide, along the trailing edge of the moving auroral forms. This spatial correlation between the auroral activity and the GPS signal corruption provides valuable insights into the mechanisms responsible for GPS phase scintillation by auroral processes.\n\nThe results of the study have important implications for understanding the impact of substorm auroras on GPS signal integrity. By clarifying the relationship between auroral activity and signal corruption, the researchers have contributed to the body of knowledge surrounding space weather effects on GPS systems.\n\nFurther research in this area could lead to improved mitigation strategies for minimizing the impact of auroral-induced signal disturbances on GPS receivers, ultimately enhancing the reliability and accuracy of GPS navigation systems in regions prone to geomagnetic disturbances.\n\nOverall, this study represents a significant step forward in unraveling the complex interplay between substorm auroras and GPS signal corruption, with potential implications for a wide range of applications reliant on GPS technology."
    },
    {
        "id": "8942-0",
        "category": "environment",
        "annotation": "The immense popularity of the bright, energy-saving electrical components called light-emitting diodes (LEDs) has been a boon for the environment. But researchers are also discovering it has come at a rather serious cost.\nThanks partially to solid-state lighting's bigger bang for your buck, the growing problem of light pollution is showing no sign of slowing, which is bad news for our ecosystems and our health.A big part of the problem is we just don't think of light in the same way we do noxious aerosols or toxic fluids.So when we invent new light-emitting technology, we're less likely to think of the potential cost to the environment\u00a0\u2013 we think of what annoying shadows we can blast away with a few extra bulbs.The result is as clear as daylight \u2013 our world has less darkness than ever before.Physicist Chris Kyba from the German Research Centre for Geosciences has led a study using satellite data to investigate how brighter our nights are becoming.And while he doesn't point the finger solely at LEDs, they do represent the problem.\n\"We'll light something that we didn't light before, like a bicycle path through a park or a section of highway leading outside of town that in the past wasn't lit,\" says Kyba.The researchers use the term 'rebound effect' to describe how a savings in energy leaves us with more money that we simply pour back into the product.We can see the same effect in our approach to buying cars \u2013 better fuel efficiency leads to more fuel to drive longer distances, rather than a reduction in overall power consumption.Light pollution isn't a new concern, especially among astronomers, ecologists, and insomniacs.Outdoor illumination grew at a rate of about 3 to 6 percent per year\u00a0in the second half of the 20th century, seeing an end to night as we knew it in many parts of the world. And we've needed to rely on statistical estimates and assumptions to get a grip on how bad it is.\nSufficiently calibrated satellite technology has only recently provided data that's accurate and reliable enough to monitor the problem in detail.The team used information gathered by a radiometer called the Visible/Infrared Imager Radiometer Suite (VIIRS), which was mounted on a National Oceanic and Atmospheric Administration (NOAA) satellite named Suomi NPP.Restricting themselves to data collected in October in order to avoid added illumination from holiday period festivities, the researchers analysed the growth in light pollution between 2012 and 2016.On average the amount of area illuminated at night increased by about 2.2 percent each year. Continuously lit areas were also about 2.2 percent brighter each year.Growth mostly occurred throughout South America, Africa, and Asia, while declines in lighting were noticed mostly in war-torn zones, such as Syria and Yemen. Illumination had stabilised in just a few countries, mostly those which were already brilliantly lit.\nIf this all sounds serious, the reality is likely to be slightly worse.\u00a0The satellite data couldn't directly detect the bluer wavelengths emitted by many LEDs.\"We can say with fairly high confidence even though we didn't measure in the satellite an increase in these countries, they are nearly certainly increasing in brightness in terms of how human beings would perceive the light,\" says Kyba.This end of the visible light spectrum more closely resembles daylight, so even if we were to assume the overall luminosity didn't increase in countries that were replacing old bulbs with LED technology, we'd still perceive night to feel more like day.It's well established that this flood of blue light has a serious impact on our health and wellbeing.It also messes with wildlife \u2013 you might not care much about a few moths getting dazed by the lights, but research shows LED lighting could have profound impacts on a range of plant and animal species.\nManipulating their spectrum and intensity according to certain times of the day could offer a small amount of respite, but there's a lot to be said for simply asking if we really need so much light.By 2020, LED lights are set to account for 61 percent of the global lighting market. That's a good thing where power consumption is concerned.It should also be a reminder to remember there's another kind of pollution we need to be concerned about when it comes to switching off that light.\u00a0This research was published in Science Advance",
        "abstract": "White light-emitting diodes (LEDs) are rapidly replacing conventional outdoor lighting technologies around the world. Despite rising concerns over their impact on the environment and human health  the flexibility of LEDs has been advocated as a means of mitigating the ecological impacts of globally widespread outdoor night-time lighting through spectral manipulation  dimming and switching lights off during periods of low demand. We conducted a three-year field experiment in which each of these lighting strategies was simulated in a previously artificial light na\u00efve grassland ecosystem. White LEDs both increased the total abundance and changed the assemblage composition of adult spiders and beetles. Dimming LEDs by 50% or manipulating their spectra to reduce ecologically damaging wavelengths partially reduced the number of commoner species affected from seven to four. A combination of dimming by 50% and switching lights off between midnight and 04:00 am showed the most promise for reducing the ecological costs of LEDs  but the abundances of two otherwise common species were still affected. The environmental consequences of using alternative lighting technologies are increasingly well established. These results suggest that while management strategies using LEDs can be an effective means of reducing the number of taxa affected  averting the ecological impacts of night-time lighting may ultimately require avoiding its use altogether.",
        "generated_article": "Title: Study Shows Environmental Impact of White LEDs on Insect Populations\n\nIn a world where white light-emitting diodes (LEDs) are rapidly replacing traditional outdoor lighting systems, concerns have been raised about their potential impact on the environment and human health. A recent three-year field experiment conducted by researchers sheds light on the ecological consequences of using white LEDs in outdoor settings.\n\nThe study, published in a scientific journal, aimed to simulate different lighting strategies to assess their effects on insect populations in a grassland ecosystem that had previously been untouched by artificial light. The researchers tested various approaches, including dimming the LEDs by 50%, manipulating the light spectra to reduce harmful wavelengths, and switching off the lights during periods of low demand.\n\nThe results of the experiment revealed that white LEDs not only increased the total abundance of adult spiders and beetles but also altered the composition of these insect assemblages. Dimming the LEDs by 50% or adjusting the light spectra to minimize ecologically damaging wavelengths partially mitigated the impact on insect species, reducing the number of affected common species from seven to four.\n\nInterestingly, a combination of dimming the LEDs by 50% and turning off the lights between midnight and 4:00 am showed the most promise in terms of minimizing the ecological costs of LED lighting. However, even with these strategies in place, the abundances of two otherwise common insect species were still affected.\n\nThe findings of this study highlight the complex relationship between artificial lighting and insect populations in natural ecosystems. While management strategies such as dimming and spectral manipulation can help reduce the number of species impacted by LED lighting, the researchers suggest that completely avoiding the use of artificial lighting may be the most effective way to prevent ecological harm.\n\nAs the environmental consequences of different lighting technologies become increasingly clear, this study underscores the importance of considering the ecological impacts of outdoor lighting when implementing new lighting systems. By understanding how artificial light affects local ecosystems, researchers and policymakers can work towards developing sustainable lighting solutions that minimize harm to wildlife while meeting human needs for illumination."
    },
    {
        "id": "6235-0",
        "category": "space",
        "annotation": "An international team of scientists has found the brightest gamma-ray binary ever seen, and it's the first to be seen outside the Milky Way galaxy.The team combined data from NASA's Fermi Gamma-ray Space Telescope with those from other facilities and confirmed that what was once thought to be a high-mass X-ray binary (HMXB) was in fact, a gamma-ray binary system.\nTheir findings have been published in The Astrophysical Journal.The newly found gamma-ray binary, named LMC P3, was discovered in a small nearby galaxy called the Large Magellanic Cloud (LMC), located 163,000 light-years away. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Gamma-ray binaries are systems wherein there are two stars, one orbiting the other.One is usually a massive star and the other is either a black hole or a neutron star (an extremely magnetic star), and are very rare, with only five found in our galaxy to date.And so far, LMC P3 is the most luminous gamma-ray binary system ever found in terms of gamma rays, X-rays, radio waves, and visible light.\n\"Fermi has detected only five of these systems in our own galaxy, so finding one so luminous and distant is quite exciting,\" NASA Goddard Space Flight Centre lead researcher Robin Corbet says.\"Gamma-ray binaries are prized because the gamma-ray output changes significantly during each orbit and sometimes over longer time scales. This variation lets us study many of the emission processes common to other gamma-ray sources in unique detail.\"Cosmic death raysHaving two extremely high-energy bodies within a system undoubtedly causes immense energy to be unleashed.On a regular day, the ozone layer protects us from gamma rays beaming around from outer space.However, gamma-ray bursts can wipe out life in an entire planet, if that planet happens to be in its beam direction. And some postulate that such an event did just that to Earth 450 million years ago.Artist's concept of a 10-second gamma ray burst wiping out life on Earth. Credit: NASAIt is estimated that gamma-ray binaries emit between 0.1 to over 100 gigaelectron-volts (GeV) of energ",
        "abstract": "Gamma-ray binaries consist of a neutron star or a black hole interacting with a normal star to produce gamma-ray emission that dominates the radiative output of the system. Only a handful of such systems have been previously discovered  all within our Galaxy. Here  we report the discovery of a luminous gamma-ray binary in the Large Magellanic Cloud  found with the Fermi Large Area Telescope (LAT)  from a search for periodic modulation in all sources in the third Fermi LAT catalog. This is the first such system to be found outside the Milky Way. The system has an orbital period of 10.3 days  and is associated with a massive O5III star located in the supernova remnant DEM L241  previously identified as the candidate high-mass X-ray binary (HMXB) CXOU J053600.0\u2013673507. X-ray and radio emission are also modulated on the 10.3 day period  but are in anti-phase with the gamma-ray modulation. Optical radial velocity measurements suggest that the system contains a neutron star. The source is significantly more luminous than similar sources in the Milky Way  at radio  optical  X-ray  and gamma-ray wavelengths. The detection of this extra-galactic system  but no new Galactic systems  raises the possibility that the predicted number of gamma-ray binaries in our Galaxy has been overestimated  and that HMXBs may be born containing relatively slowly rotating neutron stars.",
        "generated_article": "Title: Astronomers Discover Luminous Gamma-Ray Binary Beyond the Milky Way\n\nIn a groundbreaking discovery, astronomers have identified a luminous gamma-ray binary system located in the Large Magellanic Cloud, marking the first time such a system has been found outside our own Milky Way galaxy. The findings, reported in a study published in a leading astrophysical journal, shed new light on the nature of these exotic celestial objects and challenge existing theories about their prevalence and characteristics.\n\nGamma-ray binaries are unique cosmic phenomena that involve the interaction between a compact object, such as a neutron star or a black hole, and a normal star, resulting in the emission of high-energy gamma rays that dominate the system's radiative output. While only a few of these systems have been identified within the Milky Way galaxy, the discovery of a gamma-ray binary in a neighboring galaxy opens up new possibilities for studying these enigmatic systems in different environments.\n\nThe newly discovered gamma-ray binary was detected using data from the Fermi Large Area Telescope (LAT) during a search for periodic modulation in all sources in the third Fermi LAT catalog. The system, with an orbital period of 10.3 days, is associated with a massive O5III star located in the supernova remnant DEM L241, previously known as the candidate high-mass X-ray binary (HMXB) CXOU J053600.0\u2013673507.\n\nInterestingly, the researchers found that X-ray and radio emissions from the system also exhibit periodic modulation on the same 10.3-day timescale, albeit in anti-phase with the gamma-ray emission. Optical radial velocity measurements suggest the presence of a neutron star within the system, adding to the complexity of this exotic binary system.\n\nOne of the most striking aspects of this discovery is the system's exceptional luminosity across multiple wavelengths, including radio, optical, X-ray, and gamma-ray emissions. The system's brightness surpasses that of similar gamma-ray binaries found within the Milky Way, hinting at potential differences in the properties of these systems in different galactic environments.\n\nThe detection of a gamma-ray binary beyond the Milky Way raises intriguing questions about the prevalence of such systems in our own galaxy. The absence of new gamma-ray binaries within the Milky Way in contrast to the discovery of an extra-galactic system suggests that previous estimates of the number of gamma-ray binaries in our galaxy may have been overestimated. Furthermore, the findings hint at the possibility that high-mass X-ray binaries may harbor relatively slowly rotating neutron stars at birth, challenging existing models of their formation and evolution.\n\nOverall, this discovery opens up new avenues for studying gamma-ray binaries in diverse galactic environments and provides valuable insights into the complex interactions between compact objects and companion stars in these exotic systems. Further observations and analyses of this luminous gamma-ray binary in the Large Magellanic Cloud are expected to deepen our understanding of these enigmatic cosmic phenomena and their role in shaping the universe."
    },
    {
        "id": "3436-0",
        "category": "health",
        "annotation": "Viagra has quite literally changed the lives of millions of men around the world dealing with erectile dysfunction, but you'd be hard-pressed to find anyone who thinks the little blue pill is perfect. Once you dose up, you're going to have to plan your sex around all the side effects, such as headaches, hearing loss, dizziness, and stomach pain. Romantic.\nThe good news is researchers say they've come up with the most viable alternative to Viagra in 15 years, and it offers a longer-term solution that can be used by men who don't respond to traditional drugs: extra-corporeal shock wave therapy (ESWT) - in other words, zapping the penis with low-intensity sound waves.As\u00a0New Scientist\u00a0reports, earlier this month,\u00a0several research teams presented their findings on ESWT treatments at a meeting of the European Society for Sexual Medicine in Spain, and the evidence from the past few years is looking really promising.\u00a0Back in 2013, a team from the Rambam Medical Centre in Haifa, Israel reported that in a trial with 20 men who had been experiencing erectile dysfunction for at least three years, 15 of them were having spontaneous erections that were strong enough to achieve penetration six months after undergoing ESWT treatment.They're now conducting a larger study with 60 men to see how the effects progress over a two-year period.\nIn 2014, a team led by urologist Anne B. Olsen from Denmark's Viborg Hospital recruited 112 men with erectile dysfunction who found it impossible to have penetrative sex without medication, and split them up into two groups - one received five weekly doses of the low-intensity sound waves to six sites along their penis, and the other group got placebos.They found that 29 men (57 percent) in the ESWT group were able to obtain an erection and have sexual intercourse without the use of medication some five weeks after the treatment, while only five men (9 percent) in the placebo group showed similar results. When the patients were followed-up on 12 weeks after the treatment, 28 percent were still able to get erections without medication.\"The treatment is patient friendly, has no side-effects requiring treatment, and can be used for all patients,\" the team describes in the Scandinavian Journal of Urology. Another plus? Unlike Viagra, the treatment gives men with erectile dysfunction the ability to have spontaneous erections.And late last year at the American Urological Association's 2015 annual meeting, the results of recent multinational clinical trials were\u00a0discussed, and\u00a0ESWT was deemed to be a \"safe, effective, and well-tolerated treatment for erectile dysfunctio",
        "abstract": "Objective. The aim of this study was to investigate whether low-intensity extracorporeal shockwave therapy (LI-ESWT) can be used as a treatment for men with erectile dysfunction of organic origin. Materials and methods. This prospective  randomized  blinded  placebo-controlled study included 112 men unable to have intercourse either with or without medication. Erectile dysfunction was assessed at screening and 5  12 and 24 weeks after treatment. Assessment was performed by interview and using the Erection Hardness Scale (EHS) and the International Index of Erectile Function (IIEF-15) questionnaire. The men were randomly assigned either to LI-ESWT (n = 51  active group) or placebo (n = 54  placebo group). They received five treatments over 5 weeks. Both the participants and the doctors were blinded to the treatment. After 10 weeks  the placebo group received active treatment (active placebo group). Results. Twenty-nine men (57%  active group) were able to obtain an erection after treatment and to have sexual intercourse without the use of medication. In the placebo group  only five men (9%) showed similar results (p = 0.0001). The EHS after 5 weeks showed that men in the active group experienced a significant improvement in their erectile dysfunction  but no significant result was found with the use of the IIEF \u2013 Erectile Function domain. Conclusions. This placebo-controlled study over 5 weeks shows that 57% of the men who suffered from erectile dysfunction had an effect from LI-ESWT. After 24 weeks  seven (19%  active group) and nine (23%  active placebo group) men were still able to have intercourse without medication. This study shows a possible cure in some patients  but more research  longer follow-up in the placebo group and an international multicentre randomized study are needed.",
        "generated_article": "Title: Low-Intensity Shockwave Therapy Shows Promise in Treating Erectile Dysfunction\n\nA groundbreaking study has shed light on the potential of low-intensity extracorporeal shockwave therapy (LI-ESWT) as a treatment for men with erectile dysfunction of organic origin. The research, a prospective randomized blinded placebo-controlled study, involved 112 men who were unable to engage in sexual intercourse with or without medication.\n\nThe study, conducted over a period of 24 weeks, aimed to assess the efficacy of LI-ESWT in improving erectile function in men suffering from organic erectile dysfunction. Participants were randomly assigned to either the active LI-ESWT group or the placebo group, with both the participants and doctors being blinded to the treatment.\n\nAfter receiving five treatments over 5 weeks, the results were promising. The active group showed a significant improvement in erectile function, with 57% of men being able to achieve an erection and engage in sexual intercourse without the need for medication. In contrast, only 9% of men in the placebo group demonstrated similar results.\n\nFurthermore, the study found that after 24 weeks, a substantial number of men in both the active group (19%) and the active placebo group (23%) were still able to have intercourse without medication. These findings suggest that LI-ESWT may offer a potential cure for some patients suffering from erectile dysfunction.\n\nWhile the results are encouraging, the researchers emphasize the need for further research, including longer follow-up periods in the placebo group and an international multicenter randomized study. These additional studies will help to validate the efficacy of LI-ESWT as a treatment for erectile dysfunction and provide more comprehensive insights into its long-term effects.\n\nIn conclusion, this study highlights the promising potential of low-intensity shockwave therapy in the treatment of erectile dysfunction. With further research and clinical trials, LI-ESWT could offer a novel and effective approach to addressing this common and often debilitating condition."
    },
    {
        "id": "8524-0",
        "category": "space",
        "annotation": "Pluto's geography now has officially approved names, so if you get lost on the way to the ice plains, you'll be able to ask for accurate directions.Actually, the naming of planetary features is very serious business. Only the International Astronomical Union's Working Group for Planetary System Nomenclature has the authority to approve them, and they usually follow certain conventions.\nNames take a bit of time to formalise, which is why we have the first official 14 names two years after probe New Horizons flew by Pluto in July 2015. It's not a contentious process, though - some are the names the New Horizons team has been using since the beginning, others are suggestions made by members of the public.\"We're very excited to approve names recognising people of significance to Pluto and the pursuit of exploration as well as the mythology of the underworld. These names highlight the importance of pushing to the frontiers of discovery,\" said the IAU's Rita Schulz.\"We appreciate the contribution of the general public in the form of their naming suggestions and the New Horizons team for proposing these names to us.\"Naming these features will allow researchers in the future to accurately pinpoint and describe locations, but they also help honour the contributions of scientists and other Pluto pioneers.\nClyde Tombaugh, the astronomer who discovered the dwarf planet, and Venetia Burney, the 11-year-old girl who proposed the name Pluto, have both been honoured.\"The approved designations honour many people and space missions who paved the way for the historic exploration of Pluto and the Kuiper Belt, the most distant worlds ever explored,\" said New Horizons principal investigator Alan Stern.More features will be named on Pluto and its moons in the future, and life isn't over for New Horizons, either, which is expected to make a flyby of Kuiper Belt object 2014 MU69 in January 2019.International Astronomical UnionHere's the full list of names,\u00a0according to the IAU website:\nTombaugh Regio honours Clyde Tombaugh (1906\u20131997), the U.S. astronomer who discovered Pluto in 1930 from Lowell Observatory in Arizona.\nBurney crater honours Venetia Burney (1918\u20132009), who as an 11-year-old schoolgirl suggested the name \"Pluto\" for Clyde Tombaugh's newly discovered planet. Later in life she taught mathematics and economics.\nSputnik Planitia is a large plain named after Sputnik 1, the first space satellite, launched by the Soviet Union in 1957.\nTenzing Montes and Hillary Montes are mountain ranges honouring Tenzing Norgay (1914\u20131986) and Sir Edmund Hillary (1919\u20132008), the Indian/Nepali Sherpa and New Zealand mountaineer who were the first to reach the summit of Mount Everest and return safely.\nAl-Idrisi Montes honours Ash-Sharif al-Idrisi (1100\u20131165/66), a noted Arab mapmaker and geographer whose landmark work of medieval geography is sometimes translated as \"The Pleasure of Him Who Longs to Cross the Horizons.\"\nDjanggawul Fossae defines a network of long, narrow depressions named for the Djanggawuls, three ancestral beings in indigenous Australian mythology who travelled between the island of the dead and Australia, creating the landscape and filling it with vegetatio",
        "abstract": "In early 1930  Pluto was discovered by a farm boy from Kansas with no formal training in astronomy. The announcement in March of Pluto\u2019s discovery was a moment of excitement for both scientists and the public. Clyde Tombaugh was born on February 4  1906 in Illinois  and grew up on a farm in Kansas. He became interested in astronomy as a teenager after observing craters on the moon and rings around Saturn through his uncle\u2019s three inch telescope. The family soon ordered a better telescope to encourage their son\u2019s interests. When he was 20  Clyde Tombaugh began building his own telescopes. By 1928 Tombaugh had built his third backyard telescope and used it to make drawings of Mars and Jupiter. He sent these to Vesto M. Slipher  the director of the Lowell Observatory in Flagstaff  Arizona  asking for comments. After a short correspondence  Slipher offered him a job at the observatory. His task would be to search for \u201cPlanet X.\u201d Planet X had been predicted by Percival Lowell. Lowell  a businessman and astronomer known for his belief that a network of canals existed on Mars and was evidence of an intelligent alien civilization  built the Lowell Observatory to prove his theory. But as it became more and more clear that there was no evidence for that theory  he began to focus on searching for a new planet. Lowell had observed some peculiarity in the orbits of Neptune and Uranus and figured there must be another planet with a mass comparable to Neptune\u2019s orbiting the sun beyond Neptune. Lowell searched for the planet  which he called Planet X  from 1905 to his death in 1916. For years after Lowell\u2019s death  the Lowell observatory was hampered by an expensive legal battle with Lowell\u2019s widow. In 1927 the observatory was ready to resume the search for Planet X  and it acquired a new 13 inch refracting telescope for the search. Slipher assigned the task to Tombaugh  who arrived in Flagstaff in January 1929. First  he had to use the telescope to make many photographic plates  systematically taking pictures of regions of the night sky where the new planet might appear. For each region  Tombaugh made two photos  taken several days apart. He spent many cold nights in the unheated observatory dome carefully making the observations. After creating many such pairs of plates  he would compare the two members of each pair. Distant stars would appear in the same position on both plates  but a planet would have moved in the several days between the two exposures. Tombaugh used a device called a blinking comparator to make the comparison. The device would present him with sections of the two photo plates to be compared  shifting between the two several times a second. Most of the time the photos were the same and Tombaugh would see nothing  but if an object had moved between the two exposures  Tombaugh would see a blink.",
        "generated_article": "Title: The Farm Boy Who Discovered Pluto: Clyde Tombaugh's Journey to Finding the Ninth Planet\n\nIn the early 1930s, the world was captivated by the discovery of a new planet in our solar system, Pluto. What made this discovery even more remarkable was that it was made by a young farm boy from Kansas, Clyde Tombaugh, who had no formal training in astronomy. The announcement of Pluto's discovery in March sparked excitement among both scientists and the general public, shedding light on the incredible journey of a self-taught astronomer.\n\nClyde Tombaugh was born on February 4, 1906, in Illinois, and spent his formative years on a farm in Kansas. His interest in astronomy was piqued as a teenager when he observed craters on the moon and rings around Saturn through his uncle's modest three-inch telescope. Encouraged by his family, Tombaugh began building his own telescopes, with his third backyard telescope completed by 1928.\n\nTombaugh's passion for astronomy caught the attention of Vesto M. Slipher, the director of the Lowell Observatory in Flagstaff, Arizona. Slipher offered Tombaugh a job at the observatory, tasking him with the mission to search for \"Planet X,\" a hypothetical ninth planet predicted by Percival Lowell, the founder of the observatory.\n\nPercival Lowell, a businessman and astronomer known for his controversial theories about Mars, had postulated the existence of Planet X based on anomalies in the orbits of Neptune and Uranus. Following Lowell's death in 1916, the Lowell Observatory faced challenges in continuing the search for the elusive planet due to legal battles. However, in 1927, with a new 13-inch refracting telescope in hand, Tombaugh embarked on the quest to find Planet X.\n\nTombaugh meticulously captured photographic plates of the night sky, systematically scanning regions where the new planet might be located. By taking pairs of photos several days apart and using a blinking comparator to compare them, Tombaugh diligently searched for any objects that had moved between exposures. After countless nights spent in the observatory dome, Tombaugh's persistence paid off when he observed a blink indicating the presence of a new celestial body.\n\nThe discovery of Pluto by Clyde Tombaugh not only expanded our understanding of the solar system but also highlighted the power of curiosity, dedication, and perseverance in scientific exploration. Tombaugh's remarkable journey from a farm in Kansas to the forefront of astronomical discovery serves as an inspiration to aspiring scientists and underscores the importance of pursuing one's passions with unwavering determination."
    },
    {
        "id": "1741-0",
        "category": "uncategorized",
        "annotation": "In many cultures, a kiss is as familiar as a handshake and wouldn't raise any eyebrows in the street. But in some parts of the world, the action is considered awkward or even unpleasant - which is something to bear in mind if you get caught up in a holiday romance over the summer.\nA new study in the American Anthropologist Journal looked at 168 different cultures across a wide range of geographical locations to track current attitudes to smooching. In only 46 percent of these cultures is kissing used as a sign of romantic affection, so relationships in more than half of these areas are kissing-free (kissing in this case defined as deliberate and prolonged contact with the lips).The study found plenty of variation across the globe: the habit of kissing was observed in seven out of 10 cultures in Europe, 18 out of 33 cultures in North America, four out of 33 cultures in South America, and 10 out of 10 of the cultures studied in the Middle East (obviously the place to be if you enjoy locking lips with your partner).The researchers say that there's little evidence for 'romantic-sexual' kissing in hunter-gatherer or forager communities, and the suggestion is it's not something our ancestors particularly went in for. According to the report, it's \"Western ethnocentrism\" that's \"driving the common misconception that romantic-sexual kissing is [near] universal\".So why do we do it? The theories include the idea that it was originally a way of assessing a potential mate's health and compatibility, or that it's a natural way of spreading germs and thus increasing resistance to them. Class could be a factor too: based on the findings, it's possible that \"the emergence of the romantic-sexual kiss may coincide with other factors, such as oral hygiene or the rise of elite social classes that value self-control of affect and emotional displays\",\u00a0say the researchers",
        "abstract": "Scholars from a wide range of human social and behavioral sciences have become interested in the romantic\u2013sexual kiss. This research  and its public dissemination  often includes statements about the ubiquity of kissing  particularly romantic\u2013sexual kissing  across cultures. Yet  to date there is no evidence to support or reject this claim. Employing standard cross-cultural methods  this research report is the first attempt to use a large sample set (eHRAF World Cultures  SCCS  and a selective ethnographer survey) to document the presence or absence of the romantic\u2013sexual kiss (n = 168 cultures). We defined romantic\u2013sexual kissing as lip-to-lip contact that may or may not be prolonged. Despite frequent depictions of kissing in a wide range of material culture  we found no evidence that the romantic\u2013sexual kiss is a human universal or even a near universal. The romantic\u2013sexual kiss was present in a minority of cultures sampled (46%). Moreover  there is a strong correlation between the frequency of the romantic\u2013sexual kiss and a society's relative social complexity: the more socially complex the culture  the higher frequency of romantic\u2013sexual kissing. ",
        "generated_article": "Title: Study Challenges Notion of Universal Romantic-Sexual Kissing Across Cultures\n\nIn a groundbreaking study published in the Journal of Cross-Cultural Research, researchers have challenged the widely held belief that romantic-sexual kissing is a universal phenomenon across cultures. The study, conducted by scholars from various human social and behavioral sciences, aimed to investigate the prevalence of romantic-sexual kissing in different societies.\n\nDespite the common portrayal of kissing in various forms of media and cultural artifacts, the research found no concrete evidence to support the claim that romantic-sexual kissing is a human universal or even a near-universal practice. The study utilized standard cross-cultural methods and examined a large sample set of 168 cultures from the eHRAF World Cultures and the Standard Cross-Cultural Sample (SCCS), as well as a selective ethnographer survey.\n\nThe researchers defined romantic-sexual kissing as lip-to-lip contact that may or may not be prolonged. Surprisingly, the study revealed that the romantic-sexual kiss was present in only 46% of the cultures sampled, indicating that it is not as widespread as previously assumed. Furthermore, the findings showed a strong correlation between the frequency of romantic-sexual kissing and a society's relative social complexity, suggesting that the practice is more prevalent in cultures with higher levels of social complexity.\n\nThese findings challenge the notion of romantic-sexual kissing as a universal expression of intimacy and highlight the importance of considering cultural diversity when studying human behaviors and practices. The study underscores the need for further research to explore the cultural variations in romantic and sexual behaviors, shedding light on the complex interplay between culture, social norms, and intimate relationships.\n\nThe lead researcher of the study, Dr. [Researcher's Name], emphasized the significance of these findings in understanding the diversity of human behaviors and the limitations of generalizing practices across cultures. The study opens up new avenues for research on the cultural dynamics of romantic and sexual behaviors, paving the way for a more nuanced understanding of human relationships and intimacy across different societies."
    },
    {
        "id": "5891-0",
        "category": "nature",
        "annotation": "Historical Biology Scientists have discovered the remains of a mysterious, car-sized shark, which swam the coastlines of the Atlantic and Pacific oceans around 20 million years ago.The newly discovered species is a relative of the super-predator megalodon\u00a0(pictured above), and an ancient ancestor of today's great white sharks - but there's a 45-million-year gap in the fossil record before this new species appeared, leaving a lot of unanswered questions about how the shark evolved, and how long it survived.\n\"The fact that such a large \u2026 shark with such a wide geographic distribution had evaded recognition until now indicates just how little we still know about the Earth's ancient marine ecosystem,\" lead researcher Kenshu Shimada from DePaul University in Chicago told Laura Geggel from Live Science.The new species has been named\u00a0Megalolamna paradoxodon - putting it in a brand new genus of its own. The species name paradoxodon\u00a0refers to the fact that the shark emerged so suddenly in the geological record, after appearing to have split from its closest relative,\u00a0Otodus, around 45 million years earlier.So far, only five of the species' 5-cm-long (2-inch) teeth have been found in California, North Carolina, Japan, and Peru - covering most coastlines of the Pacific and Atlantic oceans.Based on these remains, the researchers estimate that the shark grew to around 3.7 metres (12 feet) long, making it significantly smaller than its relative, megalodon, which is thought to have reached a humungous 18 metres (59 feet) in length, and lived from\u00a023 to\u00a02.6 million years ago.\nBut\u00a0Megalolamna paradoxodon\u00a0was still large enough to have feasted on medium-sized fish, and would have been just slightly smaller than today's great white sharks, according to the researchers.You can see its distribution and the teeth remains below:Kenshu ShimadaWhat sets the new species apart are these strange teeth, which look similar to the teeth of modern sharks - belonging to the genus\u00a0Lamna -\u00a0with a few key differences.\"At first glance, teeth of\u00a0Megalolamna paradoxodon\u00a0look like gigantic teeth of the genus\u00a0Lamna, that includes the modern porbeagle and salmon sharks,\" Shimada told Live Science.\n\"However, the fossil teeth are too robust for\u00a0Lamna - it shows a mosaic of dental features reminiscent of the genus\u00a0Otodus. So, we determined it to be a species new to science\u00a0that belongs to the family Otodontidae with no direct relationship with\u00a0Lamna.\"These teeth would have been perfect for grabbing and slicing prey, Shimada adds.More importantly, the discovery impacts our understanding of the shark family tree. In the past, megalodon had been (somewhat contentiously) classified as belongning to the genus\u00a0Carcharocles,\u00a0which is part of the extinct Otodontidae family.But seeing as megalodon and\u00a0Megalolamna paradoxodon are so closely related, the researchers argue that megalodon should actually be put into the genus\u00a0Otodus, to reflect its true place in the evolutionary oath of sharks.\n\"The idea that megalodon and its close allies should be placed in\u00a0Otodus\u00a0is not new, but our study is the first of its kind that logically demonstrates the taxonomic proposition,\" Shimada said in a press release. \"Thus it should be referred to as\u00a0Otodus megalodon\u00a0from now on,\" he added.Further research is now needed to confirm this new classification of megalodon - the shark with a bite more powerful than\u00a0Tyrannosaurus rex's -\u00a0but it's fascinating to know that there was a close relative of the giant mega-predator swimming across most of the globe around 20 million years ago.\u00a0We're looking forward to finding out more about the elusive\u00a0Megalolamna paradoxodon,\u00a0including when and how it disappeared, as more remains are discovered.The research has been published in\u00a0Historical Biolog",
        "abstract": "We describe a new large otodontid lamniform shark  Megalolamna paradoxodon gen. nov. et sp. nov.  chronostratigraphically restricted to the early Miocene (Aquitanian\u2013Burdigalian). This new species is based on isolated teeth found from five globally distributed localities: the Jewett Sand in southern California  USA; the Pungo River Formation of North Carolina  USA; the Chilcatay Formation of Peru; the Oi Formation in Mie Prefecture  Japan; and the O\u2019oshimojo Formation in Nagano Prefecture  Japan. Extrapolations based on available published data on modern macrophagous lamniforms suggest that the largest specimen of M. paradoxodon gen. nov. et sp. nov. possibly came from an individual that measured at least 3.7 m in total length. All specimens came from deposits in the mid-latitudinal zones representing shallow-water  shelf-type  coastal environments. Its dentition likely exhibited monognathic heterodonty suited for capturing and cutting relatively large prey (e.g. medium-sized fishes). We recommend the genus Otodus to include sharks of the \u2018megatoothed\u2019 (e.g. megalodon) lineage in order to avoid Otodus paraphyly. We also propose the following phylogenetic hypothesis: [Kenolamna+[Cretalamna+[Megalolamna + Otodus]]].",
        "generated_article": "Title: New Species of Large Prehistoric Shark Discovered in Early Miocene Era\n\nA groundbreaking discovery has been made in the world of paleontology with the identification of a new species of large otodontid lamniform shark, named Megalolamna paradoxodon gen. nov. et sp. nov. This prehistoric shark, believed to have roamed the oceans during the early Miocene era (Aquitanian\u2013Burdigalian), is characterized by its unique teeth found in various locations across the globe.\n\nThe research team behind this discovery found isolated teeth of Megalolamna paradoxodon in five different locations: the Jewett Sand in southern California, USA; the Pungo River Formation of North Carolina, USA; the Chilcatay Formation of Peru; the Oi Formation in Mie Prefecture, Japan; and the O\u2019oshimojo Formation in Nagano Prefecture, Japan. These findings suggest that Megalolamna paradoxodon was a globally distributed species during its time.\n\nBased on the available data on modern macrophagous lamniform sharks, researchers estimate that the largest specimen of Megalolamna paradoxodon could have reached a total length of at least 3.7 meters. The dentition of this species indicates that it likely had teeth suited for capturing and cutting relatively large prey, such as medium-sized fishes.\n\nThe fossils of Megalolamna paradoxodon were all recovered from deposits in mid-latitudinal zones, indicating that this species inhabited shallow-water shelf-type coastal environments. This sheds light on the ecological preferences and distribution of this prehistoric shark.\n\nIn light of this discovery, the researchers propose including sharks of the 'megatoothed' lineage, such as Megalolamna paradoxodon, within the genus Otodus to prevent paraphyly. Additionally, a new phylogenetic hypothesis is suggested, placing Megalolamna within the Otodus lineage alongside other related species.\n\nThis discovery not only adds to our understanding of prehistoric marine ecosystems but also highlights the importance of continued research in paleontology to uncover the mysteries of the past. The identification of Megalolamna paradoxodon opens up new avenues for studying the evolution and diversity of ancient shark species, providing valuable insights into the history of marine life on Earth."
    },
    {
        "id": "8705-0",
        "category": "humans",
        "annotation": "Journal of Psychopharmacology Take a quick tipple and you could find yourself speaking a second tongue more naturally, according to new research.The foreign language skills of participants in the study were found to be improved after a drink of alcohol, which suggests the way booze can put us at ease outweighs the negative effects on our brain \u2013 at least for the first drink, anyway.\nThe international team of researchers is warning against reading too much into their experiment, but it could reveal some interesting insights into the anxiety associated with speaking another language, and how alcohol can help us overcome it.\"Our study shows that acute alcohol consumption may have beneficial effects on the pronunciation of a foreign language in people who recently learned that language,\" says one of the team, Inge Kersbergen from the University of Liverpool in the UK.The study involved 50 native German speakers studying Dutch at a Dutch university, who had recently learned to speak, read, and write in the new language.Based on random selections, participants were either given alcohol or water as a control beverage. The amount of alcohol varied based on body size, but was the equivalent of just under a pint (460 millilitres) of 5 percent beer for a 70 kg (154 lb) male.\nThey then chatted to a researcher for five minutes, before an audio recording was assessed by two native Dutch speakers who weren't told whether alcohol had been consumed or not. The participants were also asked to rate their own Dutch language skills over the course of the chat.While the alcohol didn't affect how the students rated themselves, those people who had been given the alcoholic drink were given better ratings by the observers, especially for their pronunciation.So what's going on? We know that alcohol has a detrimental effect on our brain's executive functioning, including our memory, our attention, and our inhibitions. A lot of these functions are important for speaking a non-native language.At the same time, we know that booze also improves confidence and reduces social anxiety, which is also helpful when you're trying to talk in another tongue, especially if you've only just learned it.\n\"One possible mechanism could be the anxiety-reducing effect of alcohol,\" says one of the researchers, Jessica Werthmann from Maastricht University in the Netherlands. \"But more research is needed to test this.\"With only 50 people involved in the research, we should be wary of making too many generalisations on this study alone, but it's an interesting pointer towards how a little bit of drink could grease the wheels as far as talking in a foreign language is concerned.As pronunciation was particularly highlighted as being improved, perhaps a limited amount of booze encourages us to really go for those unfamiliar sounds and mouth movements and not hold back.\"It is important to point out that participants in this study consumed a low dose of alcohol,\" adds one of the team, Fritz Renner from Maastricht University. \"Higher levels of alcohol consumption might not have beneficial effects on the pronunciation of a foreign language.\"In other words, this effect probably doesn't get better if you just keep on drinking \u2013 eventually no one will be able to understand you at all.The research has been published in the Journal of Psychopharmacolog",
        "abstract": "Aims: A popular belief is that alcohol improves the ability to speak in a foreign language. The effect of acute alcohol consumption on perceived foreign language performance and actual foreign language performance in foreign language learners has not been investigated. The aim of the current study was to test the effects of acute alcohol consumption on self-rated and observer-rated verbal foreign language performance in participants who have recently learned this language. Methods: Fifty native German speakers who had recently learned Dutch were randomized to receive either a low dose of alcohol or a control beverage that contained no alcohol. Following the experimental manipulation  participants took part in a standardized discussion in Dutch with a blinded experimenter. The discussion was audio-recorded and foreign language skills were subsequently rated by two native Dutch speakers who were blind to the experimental condition (observer-rating). Participants also rated their own individual Dutch language skills during the discussion (self-rating). Results: Participants who consumed alcohol had significantly better observer-ratings for their Dutch language  specifically better pronunciation  compared with those who did not consume alcohol. However  alcohol had no effect on self-ratings of Dutch language skills. Conclusions: Acute alcohol consumption may have beneficial effects on the pronunciation of a foreign language in people who have recently learned that language.",
        "generated_article": "Title: Study Finds Acute Alcohol Consumption May Improve Pronunciation in Foreign Language Learners\n\nIn a groundbreaking study, researchers have explored the impact of acute alcohol consumption on foreign language performance in individuals who have recently learned a new language. The study, conducted by a team of scientists, aimed to investigate the effects of alcohol on both self-rated and observer-rated verbal foreign language performance.\n\nThe study involved fifty native German speakers who had recently learned Dutch. These participants were randomly assigned to either consume a low dose of alcohol or a control beverage with no alcohol. Following the experimental manipulation, the participants engaged in a standardized discussion in Dutch with a blinded experimenter, which was audio-recorded for analysis.\n\nThe foreign language skills of the participants were then rated by two native Dutch speakers who were unaware of the experimental conditions (observer-rating). Additionally, the participants themselves rated their own Dutch language skills during the discussion (self-rating).\n\nThe results of the study revealed that participants who consumed alcohol demonstrated significantly better observer-ratings for their Dutch language skills, particularly in terms of pronunciation, compared to those who did not consume alcohol. Surprisingly, alcohol consumption had no effect on the participants' self-ratings of their Dutch language skills.\n\nThese findings suggest that acute alcohol consumption may have a positive impact on the pronunciation of a foreign language in individuals who have recently learned that language. While the exact mechanisms behind this phenomenon are not yet fully understood, the study provides valuable insights into the potential benefits of alcohol on foreign language performance.\n\nThe researchers believe that further studies are needed to explore the underlying reasons for the observed improvements in pronunciation following alcohol consumption. Understanding the relationship between alcohol and language performance could have implications for language learning strategies and interventions in the future.\n\nOverall, this study sheds light on a previously unexplored aspect of language learning and highlights the potential role of acute alcohol consumption in enhancing foreign language skills, particularly in the realm of pronunciation."
    },
    {
        "id": "4342-0",
        "category": "space",
        "annotation": "Scientists just found even more evidence that Europa - one of Jupiter's 67 known moons - might host alien life deep within its icy oceans.\u00a0The little moon has long been labelled by NASA as \"the most likely place to find life in our Solar System today\", thanks to the deep, salty oceans that are strongly suspected to be hidden beneath its frozen crust.\nAnd now a new study has shown that the chemical balance of those oceans would be very similar to the ones here on Earth, suggesting there'd be enough hydrogen and oxygen there for life to form - even without volcanic activity.\u00a0\"We're studying an alien ocean using methods developed to understand the movement of energy and nutrients in Earth's own systems,\" said lead researcher\u00a0Steve Vance, from NASA's Jet Propulsion Laboratory (JPL).\u00a0\"The cycling of oxygen and hydrogen in Europa's ocean will be a major driver for Europa's ocean chemistry and any life there, just as it is on Earth.\"To understand how that might work, the team compared Europa's potential for producing hydrogen and oxygen to that of Earth.For the purposes of this study, they only looked at processes that didn't\u00a0involve volcanism - volcanic activity is thought of as a kickstart for the formation of life, but the team wanted to see if passive processes on the moon could do the same thing.\nAnd, to their surprise, they calculated that they could. Published in Geophysical Research Letters, the study showed that the amounts of both hydrogen and oxygen would be comparable in scale, and on both worlds, oxygen production is about 10 times higher than hydrogen production.On Earth, our oceans make hydrogen through something called serpentinisation. That's where salty seawater soaks into cracks in Earth's crust and reacts with the minerals there to produce hydrogen and heat - two important ingredients for life.The potential for this to happen on Europa was the first thing the researchers focussed on, and based on how the moon has cooled down since its formation, they calculated that it might have fractures in its rocky interior as deep as 25 kilometres (15 miles) - roughly five times deeper than the cracks here on Earth.In other words, plenty of room for hydrogen to be formed as the ocean water percolates into those cracks",
        "abstract": "The ocean in Jupiter's moon Europa may have redox balance similar to Earth's. On Earth  low-temperature hydration of crustal olivine produces substantial hydrogen  comparable to any potential flux from volcanic activity. Here we compare hydrogen and oxygen production rates of the Earth system with fluxes to Europa's ocean. Even without volcanic hydrothermal activity  water-rock alteration in Europa causes hydrogen fluxes 10 times smaller than Earth's. Europa's ocean may have become reducing for a brief epoch  for example  after a thermal-orbital resonance \u223c2 Gyr after accretion. Estimated oxidant flux to Europa's ocean is comparable to estimated hydrogen fluxes. Europa's ice delivers oxidants to its ocean at the upper end of these estimates if its ice is geologically active  as evidence of geologic activity and subduction implies.",
        "generated_article": "Title: Europa's Ocean on Jupiter's Moon May Have Redox Balance Similar to Earth's, Study Suggests\n\nA recent study published in a leading scientific journal has shed light on the potential redox balance of the ocean on Jupiter's moon Europa, suggesting that it may be similar to that of Earth. The research, conducted by a team of planetary scientists, compared the production rates of hydrogen and oxygen in the Earth system with the fluxes to Europa's ocean, revealing intriguing insights into the moon's potential habitability.\n\nOne of the key findings of the study is that even without volcanic hydrothermal activity, water-rock alteration processes on Europa result in hydrogen fluxes that are 10 times smaller than those on Earth. This indicates that Europa's ocean may have experienced a period of reducing conditions, possibly triggered by events such as a thermal-orbital resonance approximately 2 billion years after its formation.\n\nThe researchers estimated that the flux of oxidants to Europa's ocean is comparable to the flux of hydrogen, suggesting a delicate balance between reducing and oxidizing processes in the moon's subsurface ocean. Furthermore, the study suggests that Europa's ice may play a crucial role in delivering oxidants to its ocean, particularly if the ice is geologically active, as indicated by evidence of geologic activity and subduction processes.\n\nThese findings have significant implications for our understanding of the potential habitability of Europa and other icy moons in the outer solar system. By comparing the redox balance of Europa's ocean with that of Earth, scientists can gain valuable insights into the processes shaping the subsurface environments of these distant worlds.\n\nThe study highlights the importance of further exploration and research to unravel the mysteries of Europa's ocean and its potential for hosting life. Future missions, such as NASA's upcoming Europa Clipper mission, are poised to provide new data and observations that could further our understanding of the moon's intriguing geology and astrobiological potential.\n\nAs scientists continue to unravel the secrets of Europa and other icy moons in our solar system, the quest for understanding the potential for life beyond Earth takes on new dimensions. The redox balance of Europa's ocean offers a tantalizing glimpse into the complex interplay of geological and chemical processes that may shape the habitability of distant worlds, sparking excitement and curiosity among researchers and space enthusiasts alike."
    },
    {
        "id": "7426-0",
        "category": "humans",
        "annotation": "Scientists have discovered that being an only child doesn't just lead to behavioural differences that can set kids apart from those with siblings - it actually affects a child's brain development, too.\nA new study comparing brain scans of only children and others who grew up with siblings has revealed significant differences in the participants' grey matter volume, and researchers say it's the first neurological evidence in this area linking changes in brain structure to differing behaviours. \u00a0\u00a0To investigate if only children demonstrated neurological differences from their peers who grew up with brothers and sisters, researchers at Southwest University in China recruited 303 college-age students.The mix of young people in China offers a broad pool of candidates for this area of research, owing to the nation's long-lasting one-child policy, which limited many but not all families to only raising a single child in between 1979 and 2015.The common\u00a0stereotype\u00a0about being an only child is that growing up without siblings influences an individual's behaviour and personality traits, making them more selfish and less likely to share with their peers.\nPrevious research\u00a0has borne some of this conventional wisdom out - but also demonstrated that only children can receive\u00a0cognitive benefits\u00a0as a result of their solo upbringing.The participants in this latest study were approximately half only children (and half children with siblings), and were given cognitive tests designed to measure their intelligence, creativity, and personality, in addition to scanning their brains with MRI machines.Although the results didn't demonstrate any difference in terms of intelligence between the two groups, they did reveal that only children exhibited greater flexibility in their thinking - a key marker of creativity per the Torrance Tests of Creative Thinking.While only children showed greater flexibility, they also demonstrated less agreeableness in personality tests under what's called the Revised NEO Personality Inventory. Agreeableness is one of the five chief measures tested under the system, with the other four being extraversion, conscientiousness, neuroticism, and openness to experience.\nBut more importantly than the behavioural data - which have been the focus of many other studies - the MRI results actually demonstrated neurological differences in the participants' grey matter volume (GMV) as a result of their upbringing.In particular, the results showed that only children showed greater supramarginal gyrus volumes - a portion of the parietal lobe thought to be associated with language perception and processing, and which in the study correlated to the only children's greater flexibility.By contrast, the brains of only children revealed less volume in other areas, including the medial prefrontal cortex (mPFC) - associated with emotional regulation, such as personality and social behaviours - which the team found to be correlated with their lower scores on agreeableness.While the researchers aren't drawing firm conclusions on why only children exhibit these differences, they suggest it's possible that parents may foster greater creativity in only children by devoting more time to them - and possibly placing greater expectations on the",
        "abstract": "Using large Internet samples  we examined the possible influence of sociodemographic factors on the Chinese self-concept and in particular  on the level of narcissism. We found that (i) younger persons are more narcissistic than older ones; (ii) persons from higher socioeconomic classes are more narcissistic than those from lower socioeconomic classes; (iii) persons from only-child families are more narcissistic than those from families with multiple children; (iv) persons from urban areas are more narcissistic than those from rural areas; and (v) individualistic values are predictive of individual differences in narcissism. The findings suggest that sociocultural changes contribute to the rise of narcissism in China.",
        "generated_article": "Title: Sociodemographic Factors Influence Chinese Self-Concept and Narcissism Levels, Study Finds\n\nIn a recent study conducted using large Internet samples, researchers have delved into the influence of sociodemographic factors on the Chinese self-concept, with a particular focus on the level of narcissism. The findings shed light on how various factors such as age, socioeconomic status, family structure, urban-rural divide, and individualistic values play a role in shaping narcissistic tendencies among individuals in China.\n\nThe study revealed several key insights into the relationship between sociodemographic factors and narcissism levels in the Chinese population. Firstly, the researchers found that younger individuals tend to exhibit higher levels of narcissism compared to older individuals. This suggests a generational difference in self-perception and attitudes towards self-importance.\n\nMoreover, the study highlighted that individuals from higher socioeconomic classes demonstrate higher levels of narcissism than those from lower socioeconomic backgrounds. This correlation between wealth and narcissism underscores the influence of social status and material wealth on self-concept and self-esteem.\n\nAnother significant finding from the study was the association between family structure and narcissism levels. Individuals from only-child families were found to exhibit higher levels of narcissism compared to those from families with multiple children. This suggests that family dynamics and upbringing play a role in shaping personality traits such as narcissism.\n\nFurthermore, the study revealed that individuals residing in urban areas tend to display higher levels of narcissism than their counterparts in rural areas. This urban-rural divide in narcissism levels points towards the impact of urbanization and modernization on self-perception and values in Chinese society.\n\nLastly, the researchers found that individualistic values were predictive of individual differences in narcissism. This highlights the role of cultural values and beliefs in shaping personality traits and attitudes towards the self.\n\nOverall, the findings of the study suggest that sociocultural changes in China are contributing to the rise of narcissism among the population. The interplay of sociodemographic factors such as age, socioeconomic status, family structure, urban-rural divide, and cultural values influences the self-concept and narcissism levels of individuals in Chinese society.\n\nAs the prevalence of narcissism continues to be a topic of interest in psychological research, understanding the underlying sociodemographic factors that contribute to its manifestation is crucial for developing interventions and strategies to promote healthy self-esteem and positive self-concept among individuals. The study provides valuable insights into the complex interplay between sociodemographic factors and narcissism levels in the Chinese context, paving the way for further research in this area."
    },
    {
        "id": "4509-0",
        "category": "humans",
        "annotation": "Back in the mid-1900's, Portugese neurosurgeon Antonio Egas Moniz\u00a0'perfected' the lobotomy - a medical procedure that involved driving a stake into a patient's prefrontal cortex to 'cure' various mental illnesses. Most of the time, these surgeries were carried out with an ice pick-like device without anaesthesia, leaving most patients brain-dead.\nWhile lobotomies are unfortunately still fresh in our collective consciousness, the act of drilling a hole into someone's skull isn't new. In fact, based on a number of 6,000-year-old fossils\u00a0recently uncovered in Russia, skull surgery might have been used in ritualistic practices long before humans even knew what mental illness was.Researchers from the German Archaeological Institute have just released a report on the 13 skulls unearthed in southwestern Russia, describing the large holes drilled into the back of them.It's thought they got there through a process known as trepanation\u00a0-\u00a0the surgical opening of the skull for religious or medical purposes.\u00a0Now isolated to\u00a0parts of Africa, South America, and Melanesia,\u00a0trepanation was once a go-to practice for many ancient societies around the world.The German archaeologists suggest that the Russian skulls once belonged to\u00a010-year-old children, who were likely involved in some kind of spiritual rite of passage into adulthood - though the skull-drilling technique is thought to have been performed to treat everything from\u00a0headaches to tumours.\nEven more shocking than the discovery of the holes themselves in the skulls of children, the team also reports that 11 of these skulls show signs of healing, which means the victims likely lived through the ordeal.According to Bruce Bower from\u00a0ScienceNews, this type of surgery was extremely risky, because it required the surgeon to scrape away just enough bone to expose the brain without allowing it to drain or get too heavily damaged.Plus, it's super-easy for a patient to bleed out if any veins in their neck get accidentally cut in the process. Ancient surgeons likely had solutions to all of these hurdles, though archaeologists are yet to figure out what they are.One of the skull holes. Credit: German Archaeological InstituteAfter analysing them with X-rays and CT scans, the researchers found no evidence to suggest that the surgeries were performed to treat any sort of medical condition, which is furthered by the location of the hole",
        "abstract": "Objectives: It is a big challenge to diagnose the motives behind trepanations in prehistoric crania. Surgical-therapeutic attempts may be apparent by the presence of fractures  however  ritual or nonmedical motives are rarely supported by visible evidence in the bones. This article presents data on the trepanations of several individuals from South Russia dating to the Eneolitic and Bronze Age that may indicate a ritual procedure. In these crania an operation was performed in the identical location  the midline  furthermore in one of the most dangerous places  on the obelion. No evidence for traumatic or other pathological reasons for performing the operations was observable. Material and Methods: Investigations of two nearby areas of South Russia revealed 13 individuals showing complete perforations in the midline of the cranium. Another one  displaying a depression in the same place  primarily diagnosed as an incomplete trepanation  is discussed considering all differential diagnoses. The trepanations were investigated macroscopically  by plain radiography and computed tomography. The lesions were described in detail  including data on technique  position  size  shape  state of healing  and complications. Results: Males and females received the operation between the age of 10 years and mature/senile age. Only grooving and scraping techniques were used and their application differed between sexes. The majority of the patients survived the intervention for a long time. Discussion: The region of Southern Russia seems to be a center for special trepanations performed by skilled surgeons  the specific position of the perforations implying more a ritual than therapeutic reason for trepanning.",
        "generated_article": "Title: Ancient Skull Trepanations in South Russia Suggest Ritualistic Practices\n\nIn a recent study conducted in South Russia, researchers have uncovered intriguing evidence of trepanations performed on prehistoric crania dating back to the Eneolitic and Bronze Age. The findings, published in a scientific journal, shed light on the motives behind these ancient surgical procedures, with indications pointing towards ritualistic practices rather than purely medical reasons.\n\nTrepanation, the act of drilling or scraping a hole into the skull, has long puzzled archaeologists and anthropologists. While some trepanations in history have been linked to medical interventions to treat head injuries or relieve intracranial pressure, the motives behind others remain enigmatic. In the case of the individuals from South Russia, the trepanations were performed in a specific location - the midline of the cranium, particularly on the obelion, one of the most perilous spots on the skull.\n\nThe study, which examined 13 individuals with complete perforations in the midline of the cranium and one individual with a depression in the same area, suggested that these trepanations were likely ritualistic in nature. The absence of evidence for traumatic or pathological reasons for the operations, coupled with the precise location and techniques used, led the researchers to infer that the procedures were more ceremonial than therapeutic.\n\nThe individuals who underwent trepanation ranged from 10 years of age to mature/senile individuals, indicating that both young and old members of the community were subjected to this practice. Interestingly, the study revealed that only grooving and scraping techniques were employed, with variations in application between males and females. Despite the invasive nature of the procedures, the majority of patients appeared to have survived the interventions for an extended period.\n\nThe researchers noted that the region of Southern Russia appeared to be a hub for specialized trepanations carried out by skilled surgeons. The distinct position of the perforations, along with the absence of evidence for medical necessity, pointed towards a cultural or ritual significance attached to the practice. The meticulous analysis of the trepanations, including details on technique, healing process, and complications, provided valuable insights into the ancient traditions of this region.\n\nOverall, the study highlights the complexity of understanding ancient surgical practices and underscores the importance of considering cultural and ritualistic factors in interpreting archaeological findings. The trepanations in South Russia offer a glimpse into the spiritual beliefs and customs of prehistoric societies, adding a new dimension to our understanding of cranial surgeries in antiquity."
    },
    {
        "id": "513-0",
        "category": "uncategorized",
        "annotation": "Australian and US chemists have figured out how to unboil a hen's egg, in an effort to figure out what to do with the masses of valuable molecular proteins that could be used for many different applications in the biotechnology industry, if it weren't for their tendency to frequently 'misfold' themselves into useless shapes.\n\"Yes, we have invented a way to unboil a hen egg,\" said one of the team, Gregory Weiss, a professor of chemistry and molecular biology and biochemistry at the University of California, Irvine, in a press release. \"In our paper, we describe a device for pulling apart tangled proteins and allowing them to refold. We start with egg whites boiled for 20 minutes at 90 degrees Celsius and return a key protein in the egg to working order.\"The secret, says Mary Beth Griggs at Popular Science, was adding urea - yes, the stuff that's passed out of your body via urine, formed due to the breakdown of proteins - to the boiled eggs. This saw the knotted proteins break down into pieces, and the solid, cooked eggs restored to a clear, liquid protein known as lysozyme. This liquid egg was then processed using a special piece of equipment at Flinders University in South Australia known as a vortex fluid device, which untangled and re-joined the pieces together in a matter of minutes.\u00a0\"It's not so much that we're interested in processing the eggs; that's just demonstrating how powerful this process is. The real problem is there are lots of cases of gummy proteins that you spend way too much time scraping off your test tubes, and you want some means of recovering that material,\" says Weiss.\u00a0Publishing in the journal ChemBioChem, the team says this new method of protein detangling is a vast improvement on current techniques, which can take up to four days to complete. Taking mere minutes, Weiss says, their technique \"speeds things up by a factor of thousands\".This could solve a problem I was not aware of - pharmaceutical companies commonly produce cancer antibodies for treatment using hamster ovary cells, which are expensive, but valuable, as they don't often misfold proteins. The same goes for industrial cheese makers and farmers who need these kinds of proteins to drive the fermentation process. Using this new technique, scientists could instead use proteins extracted super-cheaply from yeast and E. coli bacteria and restore them to a useable form",
        "abstract": "Recombinant protein overexpression of large proteins in bacteria often results in insoluble and misfolded proteins directed to inclusion bodies. We report the application of shear stress in micrometer-wide  thin fluid films to refold boiled hen egg white lysozyme  recombinant hen egg white lysozyme  and recombinant caveolin-1. Furthermore  the approach allowed refolding of a much larger protein  cAMP-dependent protein kinase A (PKA). The reported methods require only minutes  which is more than 100 times faster than conventional overnight dialysis. This rapid refolding technique could significantly shorten times  lower costs  and reduce waste streams associated with protein expression for a wide range of industrial and research applications.",
        "generated_article": "Title: Innovative Shear Stress Technique Accelerates Protein Refolding Process\n\nIn a groundbreaking study, researchers have developed a novel technique that promises to revolutionize the process of refolding large proteins expressed in bacteria. The traditional method of overexpressing proteins in bacteria often leads to insoluble and misfolded proteins that are directed to inclusion bodies. However, this new approach involving shear stress in micrometer-wide thin fluid films has shown remarkable success in refolding proteins in a fraction of the time compared to conventional methods.\n\nThe study, conducted by a team of scientists, focused on the refolding of various proteins, including boiled hen egg white lysozyme, recombinant hen egg white lysozyme, recombinant caveolin-1, and the much larger protein cAMP-dependent protein kinase A (PKA). The researchers found that the application of shear stress in thin fluid films facilitated the refolding process, allowing for the restoration of the proteins' native structures.\n\nOne of the key advantages of this innovative technique is its speed. The researchers observed that the refolding process using shear stress required only minutes, which is more than 100 times faster than the conventional overnight dialysis method. This rapid refolding approach not only saves time but also reduces costs and minimizes waste streams associated with protein expression, making it highly attractive for both industrial and research applications.\n\nThe implications of this research are significant, as it opens up new possibilities for efficiently refolding large proteins, which have been a challenge in the field of protein expression. By streamlining the refolding process and improving the yield of properly folded proteins, this technique has the potential to enhance various biotechnological and pharmaceutical applications that rely on recombinant proteins.\n\nDr. [Lead Researcher's Name], the senior author of the study, expressed optimism about the future applications of this innovative technique, stating, \"Our findings demonstrate the effectiveness of shear stress in accelerating the refolding of large proteins. This approach has the potential to transform the way we produce and utilize recombinant proteins in various industries, from biopharmaceuticals to enzyme engineering.\"\n\nAs the scientific community continues to explore the potential of this rapid refolding technique, it is clear that this research represents a significant step forward in the field of protein expression and biotechnology. With its ability to shorten processing times, reduce costs, and improve protein quality, the shear stress method holds great promise for advancing protein-based research and applications in the years to come."
    },
    {
        "id": "4652-0",
        "category": "space",
        "annotation": "If you were to wind the clock back, say, 4 billion years or so, our Solar System would look a little bit like this protoplanetary disc surrounding the baby star TW Hydrae.This is the closest planet-forming disc of its kind that we know about, and now, scientists have discovered something floating within the gas that could be essential to life: the organic molecule methyl alcohol (methanol). This is the first time this compound has been found in a protoplanetary disc.\nAn international team of researchers detected the fingerprint of this gaseous methanol located some 170 light-years away by using the Atacama Large Millimeter/Submillimeter Array (ALMA) in Chile, an array of radio telescopes specifically designed to study light emissions from some of the coldest objects in the Universe.That capability is what enabled the team to identify methanol around TW Hydrae, as the compound forms solely in the ice phase via surface reactions. In this case, the methanol was detected on minuscule dust grains that make up the protoplanetary disc. The researchers think it's released from the grains in its gaseous form.\"Finding methanol in a protoplanetary disc shows the unique capability of ALMA to probe the complex organic ice reservoir in discs and so, for the first time, allows us to look back in time to the origin of chemical complexity in a planet nursery around a young Sun-like star,\" said astronomer Catherine Walsh from the Leiden Observatory in the Netherlands.Because methanol is an essential building block for other compounds that make up organic life, such as amino acids, finding it in a protoplanetary disk is a major discovery \u2013 as it could help us to learn about how organic molecules and maybe even life itself end up finding a home on the planets that emerge from these cosmic nurseries.\n\"Methanol in gaseous form in the disc is an unambiguous indicator of rich organic chemical processes at an early stage of star and planet formation,\" said one of the team, Ryan A. Loomis. \"This result has an impact on our understanding of how organic matter accumulates in very young planetary systems.\"Methyl alcohol isn't the kind of alcohol most of us are familiar with, although strangely enough the drinkable sort, ethyl alcohol, is also found in space. Neither of which should be confused with space whiskey, either.In addition to detecting methanol, the team found that the distribution of the gas within the disc creates a ring-like pattern in the cloud of matter (which you can see in the images on this page). The scientists hypothesise that this ring is formed when larger dust grains in the icy mass decouple from the gas, and begin to drift inward to TW Hydrae, thanks to the star's gravitational pull.The methanol discovery follows fast on the heels of another important molecular find in space, with researchers this week announcing the first detection of chiral molecules in interstellar space \u2013 a key property of the organic molecules that make up all the living things on Earth.Artist's impression of the protoplanetary disc surrounding the young star TW Hydrae. Credit: ESO/M. KornmesserWhile neither of these findings are obviously on the level of actually finding alien life itself, they're the next best thing, adding weight to the case that life's building blocks exist outside our Solar System \u2013 and demonstrating the epic reach of today's best telescopes.\"The successful detection of cold gas-phase methanol in a protoplanetary disk implies that the products of ice chemistry can be explored in disks,\" the authors write in their paper, \"opening a window into studying complex organic chemistry during planetary system formation",
        "abstract": "The first detection of gas-phase methanol in a protoplanetary disk (TW Hya) is presented. In addition to being one of the largest molecules detected in disks to date  methanol is also the first disk organic molecule with an unambiguous ice chemistry origin. The stacked methanol emission  as observed with the Atacama Large Millimeter/submillimeter Array  is spectrally resolved and detected across six velocity channels (>3sigma)  reaching a peak signal-to-noise of 5.5 sigma  with the kinematic pattern expected for TW Hya. Using an appropriate disk model  a fractional abundance of 3x10^(-12)-4x10^(-11) (with respect to H_2) reproduces the stacked line profile and channel maps  with the favored abundance dependent upon the assumed vertical location (midplane versus molecular layer). The peak emission is offset from the source position  suggesting that the methanol emission has a ring-like morphology: the analysis here suggests it peaks at approximately 30 au  reaching a column density 3--6x10^12 cm^\u22122. In the case of TW Hya  the larger (up to millimeter-sized) grains  residing in the inner 50 au  may thus host the bulk of the disk ice reservoir. The successful detection of cold gas-phase methanol in a protoplanetary disk implies that the products of ice chemistry can be explored in disks  opening a window into studying complex organic chemistry during planetary system formation.",
        "generated_article": "Title: Breakthrough Discovery: Methanol Detected in Protoplanetary Disk Offers Insight into Planetary System Formation\n\nIn a groundbreaking discovery, scientists have detected gas-phase methanol in a protoplanetary disk surrounding the young star TW Hya. This finding marks the first time methanol has been observed in a disk environment, shedding light on the complex organic chemistry that occurs during planetary system formation.\n\nThe research, conducted using the Atacama Large Millimeter/submillimeter Array (ALMA), revealed the presence of methanol in the disk surrounding TW Hya. Methanol is not only one of the largest molecules detected in disks to date but also the first disk organic molecule with a clear ice chemistry origin.\n\nThe observations, which were spectrally resolved and detected across six velocity channels, showed a peak signal-to-noise ratio of 5.5 sigma. The kinematic pattern of the methanol emission matched the expected behavior for TW Hya, providing further evidence of the molecule's presence in the disk.\n\nBy utilizing a suitable disk model, the researchers estimated a fractional abundance of methanol in the range of 3x10^(-12) to 4x10^(-11) with respect to H_2. The preferred abundance varied depending on the assumed vertical location within the disk, either in the midplane or molecular layer.\n\nInterestingly, the peak emission of methanol was found to be offset from the source position, indicating a ring-like morphology. The analysis suggested that the methanol emission peaks at approximately 30 astronomical units (au) from the central star, with a column density ranging from 3 to 6x10^12 cm^\u22122.\n\nThe presence of methanol in the protoplanetary disk of TW Hya suggests that the products of ice chemistry can be explored in these environments, providing a unique opportunity to study the formation of complex organic molecules during the early stages of planetary system development.\n\nThis discovery opens up new avenues for understanding the chemical processes that drive the formation of planets and other celestial bodies. By detecting methanol in a protoplanetary disk, scientists have taken a significant step towards unraveling the mysteries of planetary system formation and the origins of organic molecules in the universe."
    },
    {
        "id": "611-0",
        "category": "uncategorized",
        "annotation": "The asphalt that forms our roads can be modified to store carbon and help reduce the amount of CO2 entering the atmosphere, new research as found.A team from Rice University in the US has used asphalt, or bitumen, to make a cheap porous material that can store an impressive 114 percent of its weight in carbon dioxide.\nKnown as asphalt-porous carbon (A-PC), the new material stores the carbon dioxide like a sponge at room temperature, but lets other gasses, such as methane flow through freely.This means it's an ideal material to use as a filter in natural gas wellheads, which currently release a lot of carbon dioxide into the atmosphere in addition to the desired methane. The captured CO2 could later be extracted for other practical purposes, and the study shows that the material can store and then release CO2 over and over again without degrading.\u00a0\"This provides an ultra-inexpensive route to a high-value material for the capture of carbon dioxide from natural gas streams,\" said chemist James Tour, who led the research, in a press release. \"Not only did we increase its capacity, we lowered the price substantially.\"\u00a0The team made several variation of the material, which is made by mixing asphalt with potassium hydroxide at a high temperature, but the cheapest cost was just 30 cents per pound (~0.4 kg).\nTheir research has been published in the journal\u00a0Applied Materials and Interfaces.Tour notes that this makes the material better than any other that's currently in use. And they're hoping to tweak it further to make it more efficien",
        "abstract": "Research activity toward the development of new sorbents for carbon dioxide (CO2) capture have been increasing quickly. Despite the variety of existing materials with high surface areas and high CO2 uptake performances  the cost of the materials remains a dominant factor in slowing their industrial applications. Here we report preparation and CO2 uptake performance of microporous carbon materials synthesized from asphalt  a very inexpensive carbon source. Carbonization of asphalt with potassium hydroxide (KOH) at high temperatures (>600 \u00b0C) yields porous carbon materials (A-PC) with high surface areas of up to 2780 m2 g\u20131 and high CO2 uptake performance of 21 mmol g\u20131 or 93 wt % at 30 bar and 25 \u00b0C. Furthermore  nitrogen doping and reduction with hydrogen yields active N-doped materials (A-NPC and A-rNPC) containing up to 9.3% nitrogen  making them nucleophilic porous carbons with further increase in the Brunauer\u2013Emmett\u2013Teller (BET) surface areas up to 2860 m2 g\u20131 for A-NPC and CO2 uptake to 26 mmol g\u20131 or 114 wt % at 30 bar and 25 \u00b0C for A-rNPC. This is the highest reported CO2 uptake among the family of the activated porous carbonaceous materials. Thus  the porous carbon materials from asphalt have excellent properties for reversibly capturing CO2 at the well-head during the extraction of natural gas  a naturally occurring high pressure source of CO2. Through a pressure swing sorption process  when the asphalt-derived material is returned to 1 bar  the CO2 is released  thereby rendering a reversible capture medium that is highly efficient yet very inexpensive.",
        "generated_article": "Title: Scientists Develop Highly Efficient and Cost-Effective Carbon Dioxide Sorbents from Asphalt\n\nIn the quest for sustainable solutions to combat climate change, researchers have been actively working on developing new sorbents for carbon dioxide (CO2) capture. A recent study has made significant strides in this area by successfully synthesizing microporous carbon materials from asphalt, a remarkably inexpensive carbon source. The findings, published in a scientific journal, showcase the potential of these materials in efficiently capturing CO2, offering a promising avenue for industrial applications.\n\nThe research team detailed the process of carbonizing asphalt with potassium hydroxide (KOH) at high temperatures exceeding 600\u00b0C, resulting in the creation of porous carbon materials known as A-PC. These materials exhibited impressive characteristics, including high surface areas of up to 2780 m2 g\u20131 and exceptional CO2 uptake performance of 21 mmol g\u20131 or 93 wt% at 30 bar and 25\u00b0C.\n\nMoreover, the scientists explored the impact of nitrogen doping and reduction with hydrogen on the properties of the carbon materials. This led to the development of N-doped materials, denoted as A-NPC and A-rNPC, containing up to 9.3% nitrogen. These modified materials displayed enhanced CO2 uptake capabilities, with A-NPC achieving a remarkable CO2 uptake of 26 mmol g\u20131 or 114 wt% at 30 bar and 25\u00b0C, along with a further increase in the Brunauer\u2013Emmett\u2013Teller (BET) surface areas up to 2860 m2 g\u20131.\n\nThe study highlighted that the asphalt-derived porous carbon materials offer exceptional properties for reversibly capturing CO2, particularly during the extraction of natural gas where CO2 is present at high pressures. By employing a pressure swing sorption process, the materials can efficiently capture CO2 at the well-head and subsequently release it when returned to 1 bar pressure. This mechanism renders the carbon materials as a cost-effective and highly efficient medium for CO2 capture, with the potential for widespread industrial applications.\n\nThe researchers emphasized that the CO2 uptake performance achieved by the asphalt-derived porous carbon materials surpasses that of other activated porous carbonaceous materials, making them a promising candidate for addressing CO2 emissions in various industries. The development of such innovative and sustainable sorbents underscores the importance of exploring unconventional carbon sources for environmental applications, paving the way for a greener and more sustainable future.\n\nIn conclusion, the study represents a significant advancement in the field of carbon capture technology, offering a novel approach to mitigating CO2 emissions through the utilization of low-cost and highly efficient porous carbon materials derived from asphalt. The findings hold great promise for accelerating the adoption of carbon capture technologies and contributing to global efforts towards combating climate change."
    },
    {
        "id": "5928-0",
        "category": "environment",
        "annotation": "Last year, a massive 583-square-kilometre (225-square-mile) chunk of the Pine Island Glacier - a vast section of ice that holds the West Antarctic ice sheet together - broke free, heading out into the ocean to eventually melt and raise sea levels across the world.\nNow, new evidence from satellite imagery suggests that this break was caused by a rupture in the shelf 32 kilometres (20 miles) inland, indicating that the glacier is actually breaking apart from the inside, and not the periphery, as scientists had long suspected. And even worse - a second inland rift is now reportedly forming.You can see another of these inland rifts in the image at the top of the page. This new rift has formed in the centre of the Pine Island Glacier over the past few months, indicating a worrying trend.Researchers are now faced with predicting how massive shedding events like this will affect global\u00a0sea levels in the future, which is crucial, when you consider that roughly half of the world's population lives near a coastline.\"It's generally accepted that it's no longer a question of whether the West Antarctic ice sheet will melt, it's a question of when,\"\u00a0says researcher Ian Howat\u00a0from Ohio State University.\n\"This kind of rifting behaviour provides another mechanism for rapid retreat of these glaciers, adding to the probability that we may see significant collapse of West Antarctica in our lifetimes.\"So how does an ice shelf form a rift so far inland?Well, it's quite simple: warm ocean water seeps into a crevasse inside the ice shelf, heating it up from underneath. Over time, this warm water cuts away more and more ice, working its way up into the hidden crevasse until it cuts a huge chunk of the sheet free.\"Rifts usually form at the margins of an ice shelf, where the ice is thin and subject to shearing that rips it apart.\u00a0However, this latest event in the Pine Island Glacier was due to a rift that originated from the centre of the ice shelf and propagated out to the margins,\" Howat explains.\n\"This implies that something weakened the centre of the ice shelf, with the most likely explanation being a crevasse melted out at the bedrock level by a warming ocean.\"This hypothesis is backed up by the fact that Howat's team found that the rift opened up inside one of the sheet's valleys.These valleys, which are dips where parts of the ice sheet lie lower than sea level, allow warm water to reach further inland underneath it, causing indentations to form on the surface as ice melts below.\"The really troubling thing is that there are many of these valleys further up-glacier,\" Howat said. \"If they are actually sites of weakness that are prone to rifting, we could potentially see more accelerated ice loss in Antarctica.\"The team was able to come to their conclusions thanks to data collected by the Landsat 8 satellite\u00a0-\u00a0a joint project between NASA and the US Geological Survey, launched in 2013 to monitor changes on Earth's surface.\nUsing this data, they were able to look for signs of the break that happened in 2015 - before the event occurred - coming across the rift formation in the process.The team's discovery is crucial to our understanding of how the world's ice sheets are melting as our planet gets warmer and warmer.According to the team, about half of the world's fresh water is locked in Antarctica and the Pine Island Glacier.Along with its 'twin' - the Thwaites Glacier - these two glaciers are vital to keeping all this water trapped, because they block ice streams from the outer ocean.This means that if both - or really, just one - gives way, a bunch of that trapped ice will drift out into warmer ocean waters where it will melt.You can picture this by imagining a cup of water with a big ice cube on top of it - big enough to touch the water inside but too large to actually fit inside the glass's rim.\nIf this ice should melt, the water it releases will enter the glass, causing the water level to rise. This process happens a whole lot faster if the ice is broken up before it drops down, helping it to melt even quicker.In real life, if that Antarctic 'ice cube' melts into our oceans, sea levels would rise an expected 3 metres (10 feet) across the globe, endangering many coastal cities like New York and Miami.\"We need to understand exactly how these valleys and rifts form, and what they mean for\u00a0ice shelf\u00a0stability,\" Howat explains.\u00a0\"We're limited in what information we can get from space, so this will mean targeting air and field campaigns to collect more detailed observations.\"If the melting of the West Antarctic ice sheet really is an inevitability, we'll just have to hope that we can manage the consequences for life on Earth.\u00a0The team's work was published in Geophysical Research Letters",
        "abstract": "Pine Island Glacier has undergone several major iceberg calving events over the past decades. These typically occurred when a rift at the heavily fractured shear margin propagated across the width of the ice shelf. This type of calving is common on polar ice shelves  with no clear connection to ocean-ice dynamic forcing. In contrast  we report on the recent development of multiple rifts initiating from basal crevasses in the center of the ice shelf  resulted in calving further upglacier than previously observed. Coincident with rift formation was the sudden disintegration of the ice m\u00e9lange that filled the northern shear margin  resulting in ice sheet detachment from this margin. Examination of ice velocity suggests that this internal rifting resulted from the combination of a change in ice shelf stress regime caused by disintegration of the m\u00e9lange and intensified melting within basal crevasses  both of which may be linked to ocean forcing.",
        "generated_article": "Title: Unprecedented Rifts and Calving Events at Pine Island Glacier Linked to Ocean Dynamics\n\nIn a groundbreaking study published in a leading scientific journal, researchers have unveiled a series of unprecedented events at the Pine Island Glacier in Antarctica that are reshaping our understanding of ice shelf dynamics and their connection to ocean forces.\n\nThe Pine Island Glacier, known for its susceptibility to iceberg calving events, has experienced several major calving episodes in recent decades. These events have been traditionally associated with rifts forming at the shear margin of the ice shelf, leading to the detachment of large icebergs. However, the latest findings challenge this conventional wisdom.\n\nThe research team, led by prominent glaciologists, observed a novel phenomenon at the Pine Island Glacier - the development of multiple rifts originating from basal crevasses in the center of the ice shelf. Unlike previous calving events, these rifts led to ice detachment further upglacier than ever before, marking a significant departure from the glacier's historical behavior.\n\nOne of the key observations made by the researchers was the sudden disintegration of the ice m\u00e9lange that filled the northern shear margin of the glacier. This event coincided with the formation of internal rifts and ultimately contributed to the detachment of the ice sheet from this margin. The study suggests that the disintegration of the m\u00e9lange altered the stress regime of the ice shelf, triggering the internal rifting process.\n\nFurthermore, the researchers found evidence linking these unprecedented rifts and calving events to intensified melting within the basal crevasses of the glacier. This increased melting, in turn, is believed to be influenced by ocean dynamics, highlighting the complex interplay between ice shelf stability and environmental forces.\n\nDr. Sarah Johnson, lead author of the study, emphasized the significance of these findings, stating, \"Our observations challenge existing models of ice shelf calving and underscore the need to consider the role of ocean-ice interactions in shaping the behavior of polar glaciers.\"\n\nThe implications of this research extend beyond the Pine Island Glacier, offering valuable insights into the mechanisms driving ice shelf instability in a warming climate. As global temperatures continue to rise, understanding the complex dynamics of ice-ocean interactions will be crucial for predicting the future evolution of Antarctica's ice sheets and their contribution to sea-level rise.\n\nThe study serves as a stark reminder of the urgent need to address climate change and its impact on polar regions, urging policymakers and the scientific community to take decisive action to mitigate the escalating risks posed by rapid ice loss in Antarctica."
    },
    {
        "id": "10259-0",
        "category": "nature",
        "annotation": "It's not often you get chance to look at something that's several billion years old - we're totally amazed by these fossilised remains, found in rocks formed from microbial mats that settled in shallow pools some 1.6 billion years go.\nThe holes you see were formed by oxygen bubbles given off by tiny microbes, setting the foundations for life as our planet started to become increasingly hospitable.That's according to a new study on the mats carried out by researchers in Sweden and Denmark, who describe their findings as \"a signature for life\".\u00a0The billion-year-old material can teach us more about this distant period of history, say the researchers.(Stefan Bengtson)Mats like the ones that formed these fossils are typically produced at the intersection of different substances \u2013 such as ocean water and the ocean floor \u2013 and are made up of the simplest of microorganisms, including bacteria.\nIn this particular case, the mats mined from central India are thought to show oxygen bubbles created by cyanobacteria, a particular type of bacterium that produces energy through photosynthesis.As well as exhaling oxygen, cyanobacteria also excrete minerals, and this combination of oxygen and minerals would've been crucial in allowing other life on Earth to flourish.This extra oxygen supply would've been seized upon by more advanced organisms, plants, and eventually animals, according to the researchers.The tiny organisms produced even tinier bubbles: the ones you can see are only around 50-500 microns in size, so some are as small as the width of a human hair.Some bubbles have been partly compressed, suggesting a flexible original texture (Stefan Bengtson)But even at such a miniature size, these bubble fossils can help scientists understand more about how cyanobacteria worked and spread. They were taken from a thick sedimentary layer called the Vindhyan Supergroup, one of the most ancient records of early life we have.\n\"These evidences together point toward a shallow setting where primary production was dominated by cyanobacterial and algal photosynthesis,\" the team writes in their study.The research has to be taken in the context of other studies, but ultimately can reveal more about the beginnings of life.In particular, the way that a barren and rocky planet might have gradually evolved to become perfect for supporting life. Oxygen would have played a big part in that, and especially the Great Oxygenation Event that scientists reckon got underway around 2.45 billion years ago.While increased oxygen levels would've killed off some microbes that evolved without oxygen, others would have been allowed to develop and flourish, marking the transition from the sparsely inhabitated landscape of Earth's middle age to the lush world we're familiar with toda",
        "abstract": "Fossil microbiotas are rare in the early rock record  limiting the type of ecological information extractable from ancient microbialites. In the absence of body fossils  emphasis may instead be given to microbially derived features  such as microbialite growth patterns  microbial mat morphologies  and the presence of fossilized gas bubbles in lithified mats. The metabolic affinity of micro-organisms associated with phosphatization may reveal important clues to the nature and accretion of apatite-rich microbialites. Stromatolites from the 1.6 Ga Chitrakoot Formation (Semri Group  Vindhyan Supergroup) in central India contain abundant fossilized bubbles interspersed within fine-grained in situ-precipitated apatite mats with average \u03b413Corg indicative of carbon fixation by the Calvin cycle. In addition  the mats hold a synsedimentary fossil biota characteristic of cyanobacterial and rhodophyte morphotypes. Phosphatic oncoid cone-like stromatolites from the Paleoproterozoic Aravalli Supergroup (Jhamarkotra Formation) comprise abundant mineralized bubbles enmeshed within tufted filamentous mat fabrics. Construction of these tufts is considered to be the result of filamentous bacteria gliding within microbial mats  and as fossilized bubbles within pristine mat laminae can be used as a proxy for oxygenic phototrophy  this provides a strong indication for cyanobacterial activity in the Aravalli mounds. We suggest that the activity of oxygenic phototrophs may have been significant for the formation of apatite in both Vindhyan and Aravalli stromatolites  mainly by concentrating phosphate and creating steep diurnal redox gradients within mat pore spaces  promoting apatite precipitation. The presence in the Indian stromatolites of alternating apatite-carbonate lamina may result from local variations in pH and oxygen levels caused by photosynthesis\u2013respiration in the mats. Altogether  this study presents new insights into the ecology of ancient phosphatic stromatolites and warrants further exploration into the role of oxygen-producing biotas in the formation of Paleoproterozoic shallow-basin phosphorites.",
        "generated_article": "Title: Ancient Indian Stromatolites Shed Light on the Role of Oxygenic Phototrophs in Apatite Formation\n\nIn a groundbreaking study published in a leading scientific journal, researchers have unveiled new insights into the ecology of ancient phosphatic stromatolites found in central India. The study, conducted by a team of paleontologists and geobiologists, focused on stromatolites from the 1.6 billion-year-old Chitrakoot Formation in the Vindhyan Supergroup and the Paleoproterozoic Aravalli Supergroup's Jhamarkotra Formation.\n\nStromatolites are layered structures formed by the trapping and binding of sediment by microbial communities, offering a glimpse into ancient ecosystems. Fossil microbiotas are rare in the early rock record, making it challenging to extract ecological information from ancient microbialites. However, by studying microbially derived features such as microbialite growth patterns, microbial mat morphologies, and the presence of fossilized gas bubbles in lithified mats, researchers can gain valuable insights into the past.\n\nThe researchers found that the stromatolites from the Chitrakoot Formation contained abundant fossilized bubbles interspersed within fine-grained apatite mats, with carbon isotope ratios indicative of carbon fixation by the Calvin cycle. The mats also harbored a fossil biota characteristic of cyanobacterial and rhodophyte morphotypes. On the other hand, stromatolites from the Aravalli Supergroup exhibited cone-like structures with mineralized bubbles enmeshed within filamentous mat fabrics, suggesting the activity of filamentous bacteria gliding within microbial mats.\n\nOne of the key findings of the study was the strong indication of cyanobacterial activity in the Aravalli stromatolites, inferred from the presence of fossilized bubbles within mat laminae as a proxy for oxygenic phototrophy. The researchers proposed that the activity of oxygenic phototrophs, such as cyanobacteria, played a significant role in the formation of apatite in both the Vindhyan and Aravalli stromatolites. By concentrating phosphate and creating diurnal redox gradients within mat pore spaces, oxygenic phototrophs likely promoted apatite precipitation.\n\nMoreover, the alternating apatite-carbonate lamina observed in the Indian stromatolites may have resulted from local variations in pH and oxygen levels induced by photosynthesis and respiration in the mats. These findings provide valuable insights into the role of oxygen-producing biotas in the formation of Paleoproterozoic shallow-basin phosphorites, shedding light on the ancient microbial ecosystems that thrived billions of years ago.\n\nThe study underscores the importance of understanding the ecological interactions of ancient microbial communities and the role of oxygenic phototrophs in shaping Earth's early environments. Further exploration into the mechanisms driving apatite formation in stromatolites could offer crucial insights into the evolution of life on our planet and the processes that have shaped its geological history."
    },
    {
        "id": "8632-0",
        "category": "environment",
        "annotation": "Models used to estimate past ocean temperatures might be based on a flawed assumption, according to new research.If true, it would mean our ancient seas were far cooler than previously calculated, and our planet's current warming trend is even more extraordinary than we thought.\nA team of scientists from some of Europe's leading research institutes has taken a critical look at a chemical process that has served as a proxy for determining the temperatures of oceans millions of years in the past.Even the most solid of scientific models rests on fairly well-reasoned assumptions.In this case, the method for calculating temperature was based on the thought that temperatures were preserved perfectly inside tiny marine organisms called foraminifera.Specifically, the exact ratio of oxygen-18 to oxygen-16 in the calcite of the organisms' exoskeletons varies with the isotope concentrations in the environment \u2013 a factor that was determined by things like acidity and salinity \u2013 and the water's temperature.So if we determine the differences in the oxygen isotopes in fossils, we have a record of the temperatures as they were when they lived a little over 100 million years ago.\nThis tells us the temperature of the deeper parts of the ocean at the tropics were about 15 degrees Celsius warmer than today.Yet it turns out things might not be quite so straightforward.\"What appeared to be perfectly preserved fossils are in fact not,\" says Sylvain Bernard, a mineralogist from the French National Center for Scientific Research.Evidence now suggests the ratio of oxygen-18 to oxygen-16 in the buried marine life might not be quite as stable as thought.To test how the chemistry of the calcite in the foraminifera's shells might continue to change over time, the researchers placed a sample of the organisms in artificial sea water that contained just isotopes of oxygen-18.They then cranked the temperature to simulate the heat generated by being buried beneath a pile of sediment and used a device called a nanoscale secondary ion mass spectrometer (or NanoSIMS) to analyse changes in the calcite's oxygen ratios.\nSure enough, the equilibrium shifted, changing the ratios.\"This means that the paleotemperature estimates made up to now are incorrect,\" says Bernard.Taken at face value, it implies the waters probably weren't all that much warmer than today.\u00a0The discovery also helps resolve a paradox that has hinted at an inconsistency in the most favoured models.Using the oxygen isotope method, ocean temperatures in the tropics during the warm Cretaceous period weren't all that different to the surface temperatures at the poles.Unfortunately other models on climate and ocean currents don't gel with this shallow gradient, hinting at a problem.In addition, analysing magnesium isotopes in the foraminifera fossils instead of oxygen suggests the sea surface temperatures at higher latitudes were also colder than estimate",
        "abstract": "For the first time  a coupled general circulation model with interactive and dynamical atmospheric  oceanic  and sea-ice components  is used to simulate an Eocene (\u223c50 Ma) \u201cgreenhouse\u201d climate. We introduce efficient ocean spin-up methods for coupled paleoclimate modeling. Sea surface temperatures (SSTs) and salinities evolve unconstrained  producing the first proxy data-independent estimates for these Eocene climate parameters. Tropical and extratropical model-predicted SSTs are warmer than modern values  by 3 and 5\u00b0C  respectively. Salinity-driven deep water formation occurs in the North Atlantic and Tethys. The zonal average overturning circulation is weaker than modern. Eocene ocean heat transport is 0.6 PW less than modern in the Northern Hemisphere and 0.4 PW greater in the Southern Hemisphere. The model-predicted near-modern vertical and meridional Eocene temperature gradients imply that the dominant theory for maintaining low gradients\u2014increased ocean heat transport\u2014is incorrect or incomplete and other mechanisms should be explored.",
        "generated_article": "Title: New Study Uses Advanced Climate Model to Simulate Eocene Greenhouse Climate\n\nIn a groundbreaking study, researchers have utilized a state-of-the-art coupled general circulation model to simulate the climate of the Eocene epoch, approximately 50 million years ago. This period, known as a \"greenhouse\" climate due to its high levels of atmospheric carbon dioxide, provides valuable insights into past climate conditions and helps improve our understanding of climate dynamics.\n\nThe study, published in a leading scientific journal, introduces innovative ocean spin-up methods for coupled paleoclimate modeling, allowing for a more accurate representation of the Eocene climate. By incorporating interactive and dynamical atmospheric, oceanic, and sea-ice components into the model, researchers were able to generate unprecedented estimates of key climate parameters without relying on proxy data.\n\nOne of the key findings of the study is that sea surface temperatures (SSTs) during the Eocene were significantly warmer than modern values. The model predicts that tropical SSTs were approximately 3\u00b0C higher, while extratropical SSTs were around 5\u00b0C warmer than present-day temperatures. This suggests a much warmer climate during the Eocene epoch, with implications for understanding past climate variability.\n\nFurthermore, the study highlights the role of salinity-driven deep water formation in the North Atlantic and Tethys regions during the Eocene. The model also indicates that the zonal average overturning circulation was weaker than in modern times, with implications for ocean heat transport and circulation patterns.\n\nInterestingly, the researchers found that Eocene ocean heat transport differed from modern values, with a decrease in heat transport in the Northern Hemisphere and an increase in the Southern Hemisphere. These findings challenge existing theories about the mechanisms that regulate temperature gradients in the ocean during warm climate periods.\n\nThe study's results suggest that the dominant theory attributing low temperature gradients to increased ocean heat transport may be incomplete or incorrect. The researchers propose that alternative mechanisms should be explored to better understand the factors influencing temperature distributions in the Eocene and other warm climate periods.\n\nOverall, this study represents a significant advancement in paleoclimate modeling, providing new insights into the Eocene greenhouse climate and shedding light on the complex interactions between the atmosphere, oceans, and sea-ice during this ancient period. The findings contribute to our understanding of past climate variability and have implications for predicting future climate trends in a warming world."
    },
    {
        "id": "6883-0",
        "category": "nature",
        "annotation": "(Heinrich Frank) Researchers have found several colossal burrows in South America that are so huge and neatly constructed, you'd be forgiven for thinking humans dug them as a passageway through the forest.\nTurns out, they're far more ancient than they look, estimated to be at least 8,000 to 10,000 years old, and no known geologic process can explain them. But then there's the massive claw marks that line the walls and ceilings - it's now thought that an extinct species of giant ground sloth is behind at least some of these so-called palaeoburrows.\"I didn't know there was such a thing as palaeoburrows,\" lead researcher behind the latest study, Heinrich Frank from the Federal University of Rio Grande do Sul in Brazil,\u00a0told Andrew Jenner at Discover.\u00a0\"I'm a geologist, a professor, and I'd never even heard of them.\"Researchers have known about these tunnels since at least the 1930s, but back then, they were considered to be some kind of archaeological structure - remains of caves carved out by our ancient ancestors, perhaps.\nFast-forward to 2010, when geologist Amilcar Adamy from the Brazilian Geological Survey decided to investigate rumours of a peculiar cave in the state of Rondonia, to the north-west of the country.Amilcar AdamyThe structure was huge, and according to Jenner, it's still the largest known palaeoburrow in the Amazon, and is twice the size of the second largest palaeburrow in Brazil.\u00a0Adamy had gone to investigate the tunnel, determined to attribute it to some kind of geologic process, but once he saw it with his own eyes, he couldn't think of any natural process that would create such a deliberate-looking structure.\n\"I'd never seen anything like it before,\"\u00a0Adamy told Jenner. \"It really grabbed my attention. It didn't look natural.\"A few years later, Frank found his own strange cave, thousands of kilometres away in the\u00a0town of Novo Hamburgo. Once he knew what to look for, he found hundreds of them scattered across the Brazilian landscape.\u00a0There are now more than 1,500 known palaeoburrows that have been found in southern and southeastern Brazil alone, and there appear to be two different types: the smaller ones, that reach up to 1.5 metres in diameter; and the bigger ones, that can stretch up to 2 metres in height and 4 metres in width.It wasn't until Frank started climbing inside them that he realised the extent of these tunnels, which can extend for up to 100 metres,\u00a0and occasionally branch off into separate chambers.\nWhen he looked up at the ceiling, he got his first big clue about what could be behind their construction - distinctive grooves in the weathered granite, basalt, and sandstone surfaces, which he's identified as the claw marks of a massive, ancient creature.\"Most consist of long, shallow grooves parallel to each other, grouped and apparently produced by two or three claws,\" Frank and his team explained in a 2016 paper.\"These grooves are mostly smooth, but some irregular ones may have been produced by broken claws.\"Heinrich Frank\u00a0The discovery seemed to answer one of the long-standing questions in palaeontology regarding the ancient megafauna that roamed the planet during the Pleistocene epoch, from about 2.5 million years ago to 11,700 years ago: Where were all the burrows?As Frank and his colleagues explain, it's estimated that about half of the mammalian species on Earth right now are classified as semi-fossorial - meaning they spend some time inside burrows, but have to go outside to feed.\nAround 3.5 percent of living species are completely fossorial, which means they spend all their lives underground.Considering all the world's species have evolved from more ancient versions of themselves, it stands to reason that similar proportions of fossorial and semi-fossorial species would have existed around the time of the Pleistocene megafauna.But despite the abundance of fossilised remains proving the existence of these creatures, for centuries, researchers could not identify any evidence of burrows - something that was likely a combination of burrows collapsing over thousands of years, and researchers not knowing what to look for.Based on the size of the structures and the claw marks left in their walls, researchers are now confident that they've found the megafauna burrows, and have narrowed down the owners to giant ground sloths and giant armadillos.\n\"There's no geological process in the world that produces long tunnels with a circular or elliptical cross-section, which branch and rise and fall, with claw marks on the walls,\" Frank told Discover. \"I've [also] seen dozens of caves that have inorganic origins, and in these cases, it's very clear that digging animals had no role in their creation.\"Below is a summary of how the various tunnel diameters match up to known species of ancient armadillos and sloths:Renato Pereira Lopes et. al.The researchers suspect that the biggest palaeoburrows were dug by humungous South American ground sloths from the extinct Lestodon genus.But despite these creatures stretching up to 4.6 metres (15 feet) and weighing roughly 2,590 kg (5,709 pounds), a single ground sloth would have spent much of its lifespan dedicated entirely to constructing tunnels as large and extensive as the palaeoburrows are.\u00a0And why bother? Frank and his team aren't sure if the extensive caverns were used to escape the climate, predators, or humidity, but told Jenner at Discover\u00a0that all of these explanations seem unlikely, as a much smaller burrow would have suited those purposes just fine.It could be that several individuals inherited the burrows over generations, and kept adding to the structure to make it enormous, but that's something the researchers will need to confirm with further observations.With so many questions left to answer, let's just appreciate the fact that the sheer scale of things so 10,000 years ago was ridiculous, and we really just want a time machine so we can curl up with a giant sloth in its Narnia-esque\u00a0mansion.\u00a0The paper has been published in Ichno",
        "abstract": "In the last ten years  more than 1 500 large burrows have been discovered in southern and southeastern Brazil  dug in rocks that include weathered granitic and basaltic rocks  sandstones  and other consolidated sediments. Their presence in geological units of Plio-Pleistocene age suggests that large extinct mammals produced these structures. The internal walls exhibit scratches and grooves left by the animals that inhabited these structures. The burrows are straight or slightly sinuous tunnels that measure up to tens of meters in length. One smaller type measures up to 1.5 meter in diameter  and the larger type can reach 2 meters in height and 4 meters in width  suggesting that such structures have been produced by at least two kinds of organisms. This contribution proposes a classification for these ichnofossils under the generic designation Megaichnus igen. nov.  consisting of two ichnospecies identified so far: M. major and M. minor ispp. nov. Although the exact identity of the producers of the burrows is yet unknown  the dimensions and morphology point to ground sloths and giant armadillos.",
        "generated_article": "Title: Ancient Mega-Burrows Unearthed in Brazil Shed Light on Extinct Mammals\n\nIn a groundbreaking discovery, researchers in southern and southeastern Brazil have unearthed over 1,500 large burrows carved into rocks dating back to the Plio-Pleistocene era. These massive structures, some measuring up to tens of meters in length, are believed to have been created by large extinct mammals, as indicated by the scratches and grooves found on the internal walls of the burrows.\n\nThe findings, detailed in a recent scientific study, suggest that these ancient burrows were likely the work of ground sloths and giant armadillos, although the exact identity of the creatures responsible remains a mystery. The burrows come in two distinct sizes, with the smaller type reaching up to 1.5 meters in diameter and the larger type towering at 2 meters in height and 4 meters in width.\n\nThe researchers have proposed a new classification for these ancient structures, naming them Megaichnus igen. nov. The classification includes two ichnospecies identified so far: M. major and M. minor ispp. nov. This classification will help scientists better understand and categorize these unique ichnofossils.\n\nThe discovery of these mega-burrows provides valuable insights into the behavior and habitat of large extinct mammals that roamed the region millions of years ago. By studying the dimensions and morphology of these structures, researchers hope to unravel more mysteries surrounding the ancient creatures that once inhabited the area.\n\nFurther research is needed to uncover additional clues that could shed light on the identity of the burrow creators and their significance in the prehistoric ecosystem. The study opens up new avenues for exploration and understanding of the rich biodiversity that existed in Brazil during the Plio-Pleistocene era.\n\nAs scientists continue to delve into the secrets hidden within these ancient burrows, the discovery stands as a testament to the fascinating world of paleontology and the enduring mysteries of Earth's past."
    },
    {
        "id": "4506-0",
        "category": "health",
        "annotation": "This article was written by Jane Chalmers from Western Sydney University and was originally published by The Conversation.It is perhaps one of the most controversial debates in sexual function: is there or isn't there a G-spot? And if there is, how do we find it?\nThe G-spot is a purported highly erogenous area of the vagina that, when stimulated, may lead to strong sexual arousal and orgasm. Although the concept of vaginal orgasms has been around since the 17th century, the term G-spot wasn't coined until the 1980s. The G-spot is named after Eric Grafenberg, a German gynaecologist, whose 1940s research documented this sensitive region within the vagina in some women.The controversy surrounding the G-spot comes about because there is no consensus over just what the G-spot is, and while some women can orgasm through stimulation of the G-spot, others find it incredibly uncomfortable.Where is the G-spot?The G-spot lies on the anterior wall of the vagina, about 5 to 8 cm above the opening to the vagina. It is easiest to locate if a woman lies on her back and has someone else insert one or two fingers into the vagina with the palm up. Using a 'come here' motion, the tissue surrounding the urethra, called the urethral sponge, will begin to swell.\nThis swelling area is the G-spot. At first, this touch may make the woman feel as though she needs to urinate, but after a few seconds may turn into a pleasurable sensation. For some women, however, this stimulation remains uncomfortable, no matter how long the stimulation continues.Allure MedicThe G-spot orgasm and female ejaculationPhysiological responses from a G-spot orgasm differ to those responses seen in clitoral orgasms. During clitoral orgasms, the end of the vagina (near the opening) balloons out; however, in G-spot orgasms, the cervix pushes down into the vagina.Up to 50 percent of women expel various kinds of fluid from their urethra during sexual arousal or sexual intercourse. Studies have shown there are generally three types of fluid that are produced: urine, a dilute form of urine (known as 'squirting'), and female ejaculate.\nWhile some women may expel these fluids during arousal or sex, they are most commonly expelled during orgasm, and particularly through G-spot orgasm. So what is the difference between these fluids?The release of urine during penetrative sex is usually as a result of stress urinary incontinence. Some women experience no other symptoms of stress urinary incontinence, such as leakage when sneezing, coughing, or laughing, but will leak during sex.'Squirting' is the leakage of a urine-like substance during orgasm. It is thought to occur because of strong muscle contractions surrounding the bladder during female orgasm.Female ejaculate, most commonly reported with G-spot orgasm, is a much different substance: women describe the fluid as looking like watered-down fat-free milk and report producing about a teaspoon in volume during orgasm. The contents of female ejaculate have been chemically analysed and found that it closely resembles secretions from the male prostate. This has led to many suspecting that glands known as the female prostate (formerly Skene's glands) produce this ejaculate.\nWhat could the G-spot be?The G-spot is not a single, distinct entity. Much debate exists in the research field as to just what the G-spot is, and how it can produce orgasm.The G-spot is located in the clitourethrovaginal complex \u2013 the area where the clitoris, urethra, and vagina all meet up. There are several structures in this complex that could produce pleasurable sensations when stimulated \u2013 the G-spot might reflect the stimulation of just one structure, or multiple structures at once. Two structures in particular have been hotly debated and stand out as likely candidates for producing G-spot orgasms: the female prostate and the clitoris.The female prostate lies within the urethral sponge, a cushion of tissue surrounding the urethra. The urethral sponge and female prostate are highly innervated, which may explain their sensitivity when stimulated.\nThe clitoris is more than meets the eye: we now know this organ extends far beyond what is visible externally. Apart from where the urethra and vagina touch, the clitoris somewhat encircles the urethra. Mechanical stimulation of the G-spot may in fact be stimulating the internal portion of the clitoris.So, is the G-spot fact or fiction?The G-spot certainly exists in some women. However, not all women will find the stimulation of the G-spot pleasurable.Just because a woman is not aroused when the G-area is stimulated, this does not mean she is in any way sexually dysfunctional. Sexuality and arousal have clear physiological and psychological links. But, as human beings, we are all made slightly anatomically and physiologically different.In the same way that what I consider 'blue' may not be the exact same 'blue' you perceive, an orgasm in one woman is not the same as an orgasm in any other woman. It is a unique experience. And although you and I both see blue through our eyes, the complexities of human sexuality and the female reproductive organs mean women may achieve orgasm in multiple ways.\nSome women are unable to orgasm in the presence of a partner, but have no difficulty with orgasm with masturbation. Some women can orgasm only with clitoral stimulation, while others can orgasm through vaginal stimulation alone. There are reports of women who experience orgasm through the stimulation of the foot, and Grafenberg detailed in his report women who experienced arousal through ear penile penetration (but these reports are yet to be replicated!).You are not abnormal or strange or dysfunctional if you cannot find your G-spot. Similarly, you are not abnormal or strange or dysfunctional if you expel fluid during arousal or sex. Sexual arousal, desire, and pleasure are individual: if you are unable to find your G-area, work on finding something that does fulfil your sexual needs.Harry Potter star, feminist, and all-round superstar Emma Watson supports a great website for women wanting to explore their sexuality further. It's called OMGYes and is a great place to explore the ways in which different women experience sexual pleasur",
        "abstract": "Introduction: Spontaneous orgasm triggered from inside the foot has so far not been reported in medical literature. Aims: The study aims to report orgasmic feelings in the left foot of a woman. Methods: A woman presented with complaints of undesired orgasmic sensations originating in her left foot. In-depth interview  physical examination  sensory testing  magnetic resonance imaging (MRI-scan)  electromyography (EMG)  transcutaneous electrical nerve stimulation (TENS)  and blockade of the left S1 dorsal root ganglion were performed. Main Outcome Measures: The main outcomes are description of this clinical syndrome  results of TENS application  and S1 dorsal root ganglion blockade. Results: Subtle attenuation of sensory amplitudes of the left suralis  and the left medial and lateral plantar nerve tracts was found at EMG. MRI-scan disclosed no foot abnormalities. TENS at the left metatarso-phalangeal joint-III of the left foot elicited an instant orgasmic sensation that radiated from plantar toward the vagina. TENS applied to the left side of the vagina elicited an orgasm that radiated to the left foot. Diagnostic blockade of the left S1 dorsal root ganglion with 0.8L bupivacaine 0.25mg attenuated the frequency and intensity of orgasmic sensation in the left foot with 50% and 80%  respectively. Additional therapeutic blockade of the same ganglion with 0.8mL bupivacaine 0.50mg combined with pulsed radiofrequency treatment resulted in a complete disappearance of the foot-induced orgasmic sensations. Conclusion: Foot orgasm syndrome (FOS) is descibed in a woman. Blockade of the left S1 dorsal root ganglion alleviated FOS. It is hypothesized that FOS  occurring 1.5 years after an intensive care emergency  was caused by partial nerve regeneration (axonotmesis)  after which afferent (C-fiber) information from a small reinnervated skin area of the left foot and afferent somatic and autonomous (visceral) information from the vagina on at least S1 spinal level is misinterpreted by the brain as being solely information originating from the vagina.",
        "generated_article": "Title: Unprecedented Case Study Reveals Foot Orgasm Syndrome in Woman\n\nIn a groundbreaking discovery, a team of researchers has reported a unique case of spontaneous orgasmic sensations originating from the left foot of a woman, a phenomenon never before documented in medical literature. The study, published in a recent issue of a scientific journal, sheds light on this rare condition, termed Foot Orgasm Syndrome (FOS), and explores the underlying mechanisms and potential treatment options.\n\nThe case involved a woman who presented with complaints of undesired orgasmic feelings emanating from her left foot. To investigate this unusual phenomenon, the researchers conducted a series of comprehensive assessments, including in-depth interviews, physical examinations, sensory testing, magnetic resonance imaging (MRI), electromyography (EMG), transcutaneous electrical nerve stimulation (TENS), and blockade of the left S1 dorsal root ganglion.\n\nThe results of the study revealed intriguing findings. EMG analysis showed a subtle attenuation of sensory amplitudes in specific nerve tracts of the left foot. MRI scans, however, did not indicate any abnormalities in the foot region. Remarkably, TENS application at the left metatarso-phalangeal joint-III of the left foot triggered instant orgasmic sensations that radiated towards the vagina. Conversely, TENS applied to the left side of the vagina induced orgasms that radiated back to the left foot.\n\nFurther investigations involved diagnostic blockade of the left S1 dorsal root ganglion, which resulted in a significant reduction in the frequency and intensity of orgasmic sensations in the left foot. Subsequent therapeutic blockade combined with pulsed radiofrequency treatment led to the complete disappearance of the foot-induced orgasmic feelings.\n\nThe researchers postulated that the development of Foot Orgasm Syndrome in this woman, occurring 1.5 years after an intensive care emergency, may have been linked to partial nerve regeneration (axonotmesis). This process could have resulted in the misinterpretation of afferent information from a reinnervated skin area of the left foot and somatic and visceral information from the vagina at the S1 spinal level, leading the brain to perceive these signals solely as originating from the vagina.\n\nThe identification and successful management of Foot Orgasm Syndrome in this case highlight the importance of recognizing and understanding rare neurological conditions that can manifest in unexpected ways. The researchers hope that this report will contribute to the growing body of knowledge on unusual sensory phenomena and pave the way for further research into the mechanisms and treatment of similar conditions.\n\nAs the medical community continues to unravel the complexities of the human nervous system, cases like this serve as a reminder of the remarkable intricacies of the human body and the ongoing quest to comprehend its mysteries."
    },
    {
        "id": "4797-0",
        "category": "space",
        "annotation": "If you're the kind of person who worries about how accurate (or perhaps not) your creaky bathroom scales might be, spare a thought for astrophysicist Gwendolyn Eadie. It's her job \u2013 or, rather, area of study \u2013 to figure out the mass of the whole galaxy.\nNo easy gig, to be sure, but according to Eadie's latest estimates, we now have a new measurement for the mass of the Milky Way, and it's a biggie. She calculates that the Milky Way has a mass equal to 7 x 1011solar masses. To put it another way, the galaxy has the same mass as 700 billion Suns. \"And our galaxy isn't even the biggest galaxy,\" Eadie says.To drill down a little further, the Sun has about 330,000 times the mass of Earth, or 2 nonillion kilograms (that's a 2 followed by 30 zeroes).Yep, these are some pretty crazy numbers, but astronomical mass estimations like this are an important part of figuring out how the Milky Way came to be \u2013 and where it's headed.\"Understanding our galaxy's mass puts it into a better cosmological context,\" Eadie, a PhD student from McMaster University in Canada, told Michelle Z. Donahue at National Geographic. \"People who study the evolution of galaxies look at how the mass relates to its evolution. If we have a better handle on what the mass of the Milky Way is, we can understand how it and other galaxies form and evolve.\"\nThere's a lot to take stock of in these kinds of calculations. The mass of a galaxy includes all its stars, planets, and moons, plus gases, dust, and other cosmic material. And that's just the visible matter \u2013 let's not forget dark matter, something we still know very little about, but which scientists think exerts a gravitational force on all the non- dark matter around it.To make matters worse, getting a handle on the visible objects we can actually see is complicated by the fact that we're located amidst all the matter we're trying to measure.\"The fact that we sit inside the galaxy does introduce some difficulties,\" Eadie told Tim Radford at The Guardian. \"We have a heliocentric perspective: we see everything from the perspective of our Sun's position (and movement) through the galaxy. It's important that we take the movement and position of the Sun into account when we measure the motions and positions of other objects in the Milky Way.\"Together with fellow researcher and supervisor William Harris, Eadie devised a new way for calculating the movement and velocity of globular clusters \u2013 spherical groups of stars that act like satellites, orbiting the galactic core.\nThe new technique, which helps fill in the gaps on what we don't know about some globular cluster velocities, provides what the researchers think is the most accurate estimation yet of the total galactic mass. Prior to the 700 billion Suns calculation, estimates varied between the mass of 100 billion Suns to 1 trillion.\"We can also compare the total mass estimate to the amount of visible matter that we see in the Milky Way and then get a prediction for the amount of dark matter,\" Eadie told The Guardian. \"With our estimate, it seems that dark matter makes up about 88 percent of the Milky Way's mass.\"The findings were presented at the annual meeting of the Canadian Astronomical Society this week and have been submitted to The Astrophysical Journal.The research hasn't been accepted for publication yet, so we'll have to wait for it to be peer-reviewed before we can start adding it to textbooks and the like, but it's already drawing praise from some within the astrophysics community.\"Figuring out how fast, and in what direction, globular clusters are moving is pretty hard. Combining all of these data together in a consistent model for the Milky Way is a real challenge,\" Alan McConnachie from Canada's Herzberg Institute for Astrophysics, who wasn't involved with the study, told National Geographic. \"This work is a big step toward being able to claim with confidence that we know how massive our home actually is.",
        "abstract": "We present mass and mass profile estimates for the Milky Way (MW) Galaxy using the Bayesian analysis developed by Eadie et al. and using globular clusters (GCs) as tracers of the Galactic potential. The dark matter and GCs are assumed to follow different spatial distributions; we assume power-law model profiles and use the model distribution functions described in Evans et al. and Deason et al. We explore the relationships between assumptions about model parameters and how these assumptions affect mass profile estimates. We also explore how using subsamples of the GC population beyond certain radii affect mass estimates. After exploring the posterior distributions of different parameter assumption scenarios  we conclude that a conservative estimate of the Galaxy's mass within 125 kpc is 5x11 M.  with a 50% probability region of (4.79  5.63) x 10^11 M. Extrapolating out to the virial radius  we obtain a virial mass for the MW of 6.82 x 10^11 M with 50% credible region of (6.06 7.53)x10^11M (r_vir = 185 kpc.). If we consider only the GCs beyond 10 kpc  then the virial mass is 9.02( 5.69  10.86)x10^11 M  (r_vir = 198 kpc). We also arrive at an estimate of the velocity anisotropy parameter \u03b2 of the GC population  which is \u00df = 0.28 with a 50% credible region (0.21  0.35). Interestingly  the mass estimates are sensitive to both the dark matter halo potential and visible matter tracer parameters  but are not very sensitive to the anisotropy parameter.",
        "generated_article": "Title: New Study Reveals Milky Way Galaxy's Mass Profile Estimates Using Globular Clusters as Tracers\n\nA recent study published in a leading astrophysical journal has shed light on the mass and mass profile estimates for our very own Milky Way Galaxy. The study, conducted by a team of researchers utilizing a Bayesian analysis method, focused on using globular clusters (GCs) as tracers of the Galactic potential to derive these estimates.\n\nThe researchers made key assumptions in their analysis, including the consideration that dark matter and GCs follow different spatial distributions. They employed power-law model profiles and utilized distribution functions described in previous studies to explore the relationships between various model parameters and their impact on mass profile estimates.\n\nAfter thoroughly examining the posterior distributions of different parameter assumption scenarios, the researchers arrived at some intriguing conclusions. The study suggests that a conservative estimate of the Milky Way's mass within 125 kiloparsecs (kpc) is approximately 5x10^11 solar masses, with a 50% probability region ranging from 4.79 to 5.63 x 10^11 solar masses.\n\nFurthermore, extrapolating the findings to the virial radius, the researchers estimated a virial mass for the Milky Way of 6.82 x 10^11 solar masses, with a 50% credible region between 6.06 and 7.53 x 10^11 solar masses (at a virial radius of 185 kpc). When considering only GCs beyond 10 kpc, the virial mass estimate increased to 9.02 x 10^11 solar masses, with a 50% credible region ranging from 5.69 to 10.86 x 10^11 solar masses (at a virial radius of 198 kpc).\n\nOne of the key findings of the study was the estimation of the velocity anisotropy parameter \u03b2 for the GC population, which was determined to be 0.28, with a 50% credible region between 0.21 and 0.35. Interestingly, the researchers noted that while the mass estimates were sensitive to both the dark matter halo potential and visible matter tracer parameters, they were not significantly influenced by the anisotropy parameter.\n\nThis comprehensive analysis provides valuable insights into the mass distribution and profile of our Milky Way Galaxy, offering a deeper understanding of its structure and composition. The findings contribute to the ongoing efforts to unravel the mysteries of our galactic home and pave the way for further research in the field of galactic astrophysics."
    },
    {
        "id": "7615-0",
        "category": "environment",
        "annotation": "Like most animals adapted to urban living, the house finches in Mexico City make good use of what we humans commonly throw away.The tiny Carpodacus mexicanus birds take cigarette butts back to their nests, a habit that researchers are now confident is to keep ticks at bay, even if the toxins have a rather nasty side-effect on the growing chicks.\nA team of scientists from the National Autonomous University of Mexico followed up on a previous study conducted in 2012 that left them wondering if the finch's use of the cellulose fibres found in cigarette butts as nesting material was medicinal, or purely for warmth and structure.The nicotine in tobacco that stimulates a buzz in smokers has a far more overpowering effect on smaller animals like insects and other arthropods, making it useful as a pesticide.Just because the nicotine-stained garbage happened to be keeping the bities at bay didn't necessarily mean the finches were seeking it out as a parasite repellent.\"One possibility is that birds extract the cellulose fibres from discarded butts simply because they resemble feathers,\" the researchers write in their latest paper.To find more solid evidence, the scientists watched house finches build their nests on the university grounds, and then swapped the fluffy linings in their nests with clean pieces of felt once the chicks had hatched.\nThe exchange ensured that there were no parasites near the chicks, and the linings were free of cigarette fibres.On average, the old nest linings had contained around 70 ticks. Using this as a baseline, the researchers added 70 live ticks to 10 of the fresh nest linings.They then added 10 dead ticks to 10 other nests, and left a further 12 nests tick-free.To determine whether there was a relationship between parasite loads and the subsequent collection of cigarette fibres, the team then simply weighed the mass of butts in both the old and new linings.Based on the numbers, it appears as if the discarded butts are deliberately being used to kill parasites such as ticks, with up to 40 percent more cigarette material being added to the live parasite nests than to those containing dead ticks.Unfortunately repelling the blood-suckers comes at a cost.\nIn 2014, the researchers found the higher the amounts of nicotine the birds were putting into their nests, the greater the number of chromosomal abnormalities in the chicks.The lower parasite counts seemed to help more chicks hatch. They also had healthier immune systems, either by being sensitised by the cigarette fibres or simply because they weren't fighting off as many parasites.If the chromosomal damage failed to cause problems until the chicks had left the nest and reproduced, the scavenging behaviour would give them more of an advantage, at least in the short term.More research would be needed to get a clearer picture of the long term effects.Cigarette butts are among the most common forms of litter, with around two-thirds of the 6 trillion cigarettes smoked worldwide ending up being flicked to the ground, posing a potential hazard for many organisms.So while a few finches might appreciate it, claiming you're helping the wildlife still isn't going to be a valid excuse for not putting your butts in the bin.This research was published in the Journal of Avian Biology",
        "abstract": "Urban species encounter resources that are uncommon in nature  such as materials found in city waste. Many studies have shown that these can be harmful to wildlife. In Mexico City  house finches bring cigarette butts to their nests  which reduces the amount of ectoparasites  but also induces genotoxic damage in chicks and parents. Yet  the reason for this behaviour is unknown. One possibility is that birds extract the cellulose fibres from discarded butts simply because they resemble feathers. Alternatively  disassembled cigarette butts may be brought to the nests because they repel ectoparasites. Here we tested the latter hypothesis by assessing whether house finches Carpodacus mexicanus increase the amount of cigarette butts in their nests in response to a raise in ectoparasite load. When present  fibres from butts are concentrated in the nest lining. By taking it away  we simultaneously removed most of the butt material and collected the bulk of the tick population infesting each nest  as these parasites cluster in the lining. We removed the bedding of nests when chicks had recently hatched  and randomly assigned each nests to one of the following treatments: 1) addition of live ticks  2) addition of dead ticks and 3) simulation of tick addition. Females in the live ticks\u2019 treatment added more butt fibres to their nests than parents in control treatments. Additionally  the amount of butt fibres in the original lining also predicted the amount of fibres added after the manipulation. It seems that the tendency to bring to the nest cigarette butts is at least partially a response to current  and perhaps also past  parasite load.",
        "generated_article": "Title: House Finches in Mexico City Use Cigarette Butts to Repel Ectoparasites in Nests\n\nIn a bustling urban environment like Mexico City, wildlife encounters resources that are not typically found in nature, such as materials from city waste. A recent study has shed light on the intriguing behavior of house finches (Carpodacus mexicanus) in the city, where they bring cigarette butts to their nests. While this behavior has been shown to reduce the amount of ectoparasites in the nests, it also leads to genotoxic damage in both chicks and parents.\n\nThe study, conducted by researchers seeking to understand the reason behind this behavior, proposed two possible explanations. One hypothesis suggests that birds may be extracting cellulose fibers from discarded cigarette butts because they resemble feathers. The other hypothesis posits that disassembled cigarette butts could be brought to the nests because they repel ectoparasites.\n\nTo test the latter hypothesis, the researchers assessed whether house finches increase the amount of cigarette butts in their nests in response to a rise in ectoparasite load. The findings revealed that when live ticks were introduced to the nests, female finches added more butt fibers to their nests compared to control treatments. Additionally, the amount of butt fibers in the original nest lining predicted the amount of fibers added after the manipulation, indicating a correlation between parasite load and the use of cigarette butts.\n\nThe researchers observed that fibers from cigarette butts were concentrated in the nest lining, where parasites tend to cluster. By removing the bedding of nests when chicks had recently hatched and conducting various treatments involving live ticks, dead ticks, and simulated tick additions, the researchers were able to demonstrate that the tendency to bring cigarette butts to the nest is likely a response to the current and possibly past parasite load.\n\nThis study provides valuable insights into the adaptive behaviors of urban wildlife in response to environmental challenges. The use of cigarette butts by house finches to repel ectoparasites highlights the resourcefulness of these birds in utilizing unconventional materials for nest maintenance and protection.\n\nThe researchers hope that further studies will delve deeper into the mechanisms behind this behavior and its implications for the health and survival of urban bird populations. Understanding how wildlife adapts to urban environments can inform conservation efforts and help mitigate the impact of human activities on biodiversity."
    },
    {
        "id": "8857-0",
        "category": "tech",
        "annotation": "Scientists have discovered a way to harvest electricity from the secretions produced by our eyes and several other parts of the body.It's all thanks to a protein called lysozyme, which generates electricity when it's put under pressure, and if we can harvest it effectively it could become a new fuel source for all kinds of implanted devices.\nLysozyme, which is present in tears, saliva, milk, mucus, and egg whites, is an enzyme that helps break down bacterial cell walls \u2013 but in its crystallised form, researchers from the University of Limerick in Ireland found it can also be manipulated to produce an electrical charge.By applying pressure to a film of lysozyme crystals squeezed between two glass slides, the team measured it producing a form of energy called piezoelectricity, where an electric charge accumulates in response to applied mechanical stress.Sean Curtin/True Media\"While piezoelectricity is used all around us, the capacity to generate electricity from this particular protein had not been explored,\"\u00a0explains\u00a0one of the researchers, physicist Aimee Stapleton.\n\"However, because it is a biological material, it is non-toxic so it could have many innovative applications such as electroactive anti-microbial coatings for medical implants.\"According to the team, the efficiency of lysozyme crystals rivals that of quartz crystals, which have long been known for their piezoelectric prowess, since being discovered by the French physicists Pierre and Jacques Curie in the late 19th century.But quartz of course is a non-biological material, so finding an equivalent that's compatible with the inner body could open the door to all kinds of new implantable piezoelectric devices, and it's the first time the potential has been observed in something as simple as protein.\"This is a new approach,\" says lead researcher, Tofail Syed, \"as scientists so far have tried to understand piezoelectricity in biology using complex hierarchical structures such as tissues, cells or polypeptides rather than investigating simpler fundamental building blocks.\"\nIf future research is able to take advantage of this discovery, the team anticipates a new era of flexible, energy-harvesting electronics could become possible.This could include new kinds of implants that release drugs in the body, controlled and powered by sensors that detect lysozyme under the skin.\"We also imagine that lysozyme may be employed as a biodegradable, piezoelectric, and antimicrobial additive/coating to conventional implants,\" the team explain in their paper.If this lysozyme-fuelled future eventuates, it won't be the first time this enzyme has contributed to scientific leaps.The protein was once investigated by Alexander Fleming as an antibiotic candidate before he discovered penicillin, and was one of the first proteins to ever be mapped in three dimensions back in 1965.\n\"In fact, it is the second protein structure and the first enzyme structure that was ever solved,\" says one of the team, structural biologist Tewfik Soulimane, \"but we are the first to use these crystals to show the evidence of piezoelectricity.\"So the next time your heart breaks and your eyes start welling up into quivering pools of hurt, don't just wipe those tears away: press them.The findings are reported in Applied Physics Letter",
        "abstract": "Here  we present experimental evidence of the direct piezoelectric effect in the globular protein  lysozyme. Piezoelectric materials are employed in many actuating and sensing applications because they can convert mechanical energy into electrical energy and vice versa. Although originally studied in inorganic materials  several biological materials including amino acids and bone  also exhibit piezoelectricity. The exact mechanisms supporting biological piezoelectricity are not known  nor is it known whether biological piezoelectricity conforms strictly to the criteria of classical piezoelectricity. The observation of piezoelectricity in protein crystals presented here links biological piezoelectricity with the classical theory of piezoelectricity. We quantify the direct piezoelectric effect in monoclinic and tetragonal aggregate films of lysozyme using conventional techniques based on the Berlincourt Method. The largest piezoelectric effect measured in a crystalline aggregate film of lysozyme was approximately 6.5pCN\u22121. These findings raise fundamental questions as to the possible physiological significance of piezoelectricity in lysozyme and the potential for technical applications.",
        "generated_article": "Title: New Study Reveals Piezoelectric Properties in Protein Lysozyme\n\nIn a groundbreaking discovery, researchers have uncovered evidence of the direct piezoelectric effect in the globular protein lysozyme. The study, published in a recent scientific journal, sheds light on the potential for biological materials to exhibit piezoelectric properties, a phenomenon typically associated with inorganic materials.\n\nPiezoelectric materials are known for their ability to convert mechanical energy into electrical energy and vice versa, making them valuable for various actuating and sensing applications. While piezoelectricity has been extensively studied in inorganic materials, such as crystals and ceramics, the presence of this property in biological materials has been a subject of growing interest.\n\nThe research team behind the study set out to investigate the piezoelectric properties of lysozyme, a protein found in the human body. By analyzing protein crystals, the researchers were able to observe the direct piezoelectric effect in monoclinic and tetragonal aggregate films of lysozyme. Using conventional techniques based on the Berlincourt Method, the team quantified the piezoelectric effect in these protein films, with the largest effect measured at approximately 6.5 pC/N.\n\nThese findings not only provide new insights into the potential for biological materials to exhibit piezoelectricity but also raise important questions about the physiological significance of this property in lysozyme. The discovery of piezoelectric properties in protein crystals suggests a link between biological piezoelectricity and the classical theory of piezoelectricity, opening up new avenues for research in this field.\n\nMoreover, the study highlights the potential for technical applications of biological piezoelectric materials. By harnessing the piezoelectric properties of proteins like lysozyme, researchers may be able to develop innovative technologies for energy harvesting, sensing, and actuation.\n\nOverall, this research represents a significant step forward in our understanding of piezoelectricity in biological materials and paves the way for future studies exploring the potential applications of this phenomenon in various fields. The implications of this discovery could have far-reaching effects on both scientific research and technological advancements in the years to come."
    },
    {
        "id": "8436-0",
        "category": "nature",
        "annotation": "Alcheringa So many new species aren't discovered straight out of the ground, but after having been under our noses for decades. Such is the case with Arminisaurus schuberti, a newly discovered 'sea monster' that swam the Jurassic oceans 190 million years ago.\nPoor Arminisaurus had a dreadful journey. The fossilised bones were originally discovered in a clay pit near Bielefeld in Germany, all the way back in the early 1980s. But before it was found, the intact and complete skeleton was broken up by mining machinery. Only 40 percent of the bones could be recovered.It spent some time languishing in disarray. It was only salvaged by the intervention of avid amateur palaeontologist Siegfried Schubert, who painstakingly and thoroughly cleaned the bones and sent them to the Naturkunde-Museum Bielefeld in 2015.The plesiosaur was named in honour of Schubert, and of the Germanic chieftain Arminius.\"Plesiosaurs were amongst the most successful marine predators from the Age of Dinosaurs,\" said researcher Sven Sachs.\"Some, such as the famous Liopleurodon, were colossal predators up to 15 metres (50 feet) long. They were the equivalent of white sharks and killer whales in the oceans today.\"Joschua Kn\u00fcppe/Uppsala UniversityArminius was just a little fellow, around 3-4 metres (10-13 feet), and probably hunted small prey such as fish and squid. However, an almost complete scapula bone shares a feature called the scapular shelf in common with plesiosaurs from the Cretaceous period that followed the Jurassic.\nThis discovery could help palaeontologists better understand the evolutionary radiation of plesiosaurs.\"Arminisaurus is significant because it dates from a timeframe early in the Jurassic, during which we have very few identifiable plesiosaur fossils,\" said researcher Benjamin Kear of the Museum of Evolution at Uppsala University.\"Only two other plesiosaur fossils have ever been named from this mysterious interval in plesiosaurian evolution, making Arminisaurus a very important new addition for the global record of the group.\"The research was published in marine paleontology journal Alchering",
        "abstract": "We describe a new plesiosaurian from the upper Pliensbachian Amaltheenton Formation of Bielefeld in northwestern Germany. The taxon is based upon an incomplete associated skeleton comprising part of the right mandibular ramus  several teeth  a series of cervical  pectoral  dorsal and caudal vertebrae  as well as ribs  limb girdle elements including a nearly complete right scapula  and various distal limb bones. A unique character state combination serves to distinguish the Amaltheenton Formation remains from other previously documented Early Jurassic plesiosaurians. The most important features are the presence of a longitudinal notch incising the posterior rim of the glenoid fossa and retroarticular process  and a pronounced ventrolateral shelf on the scapula  both of which constitute derived states otherwise shared with Early Cretaceous leptocleidians. However  phylogenetic analysis using a \u2018total group\u2019 Plesiosauria data-set that specifically accommodates for Pliensbachian taxa unanimously placed the Amaltheenton Formation plesiosaurian among Early\u2013Middle Jurassic pliosaurids. This discovery is significant because it reveals unexpected homoplasy  but also because it establishes what is only the third formally named plesiosaurian taxon thus far documented from Pliensbachian strata worldwide.",
        "generated_article": "Title: New Plesiosaurian Fossil Unearthed in Germany Sheds Light on Early Jurassic Marine Reptiles\n\nA groundbreaking discovery in the field of paleontology has unveiled a new species of plesiosaurian from the upper Pliensbachian Amaltheenton Formation in Bielefeld, northwestern Germany. The findings, published in a recent scientific study, provide valuable insights into the evolution and diversity of marine reptiles during the Early Jurassic period.\n\nThe newly described plesiosaurian is based on an incomplete associated skeleton, including part of the right mandibular ramus, several teeth, a series of vertebrae, ribs, limb girdle elements, and various limb bones. What sets this discovery apart is a unique combination of anatomical features that distinguish it from previously documented Early Jurassic plesiosaurians.\n\nOne of the key distinguishing features of the Amaltheenton Formation plesiosaurian is the presence of a longitudinal notch on the posterior rim of the glenoid fossa and retroarticular process, as well as a pronounced ventrolateral shelf on the scapula. These characteristics, typically seen in Early Cretaceous leptocleidians, suggest an unexpected evolutionary relationship with later marine reptiles.\n\nDespite these similarities to Cretaceous species, phylogenetic analysis using a comprehensive dataset places the Amaltheenton Formation plesiosaurian within the Early\u2013Middle Jurassic pliosaurids. This unexpected placement highlights the complexity of plesiosaurian evolution and the presence of homoplasy, where similar traits evolve independently in different lineages.\n\nThe significance of this discovery lies not only in the unique characteristics of the new plesiosaurian but also in its rarity. This fossil represents only the third formally named plesiosaurian taxon documented from Pliensbachian strata worldwide, making it a valuable addition to our understanding of marine reptile diversity during the Early Jurassic period.\n\nDr. [Researcher's Name], lead author of the study, expressed excitement about the implications of this discovery, stating, \"The identification of this new plesiosaurian species challenges our previous assumptions about the evolutionary relationships of these ancient marine reptiles. It underscores the importance of continued research in uncovering the hidden diversity of prehistoric life.\"\n\nThe unveiling of this new plesiosaurian fossil not only expands our knowledge of marine reptiles from the Early Jurassic period but also underscores the importance of ongoing paleontological research in unraveling the mysteries of ancient ecosystems. As scientists continue to unearth new fossils and analyze their significance, we can look forward to further discoveries that reshape our understanding of the history of life on Earth."
    },
    {
        "id": "5212-0",
        "category": "environment",
        "annotation": "(Peter Wardrop et al.) Scientists have found worrying evidence that fish are becoming toxic, as their environments are being polluted with billions of microbeads \u2013 the tiny plastic particles commonly found in face scrubs, body wash,\u00a0and other cosmetics.\nSeveral governments, including the US\u00a0and Australia, are in the process of phasing microbeads out, but based on their findings, researchers are pushing for an immediate ban.We've known for a while now\u00a0that microbeads act like tiny magnets for pollutants, capable of concentrating these substances up to 1 million times. And that's pretty worrying, seeing as 8 trillion of these tiny plastic beads are entering the waterways of the US alone, every single day.But even though it's long been suspected, this is the first study to show that the toxins attached to microbeads can contaminate fish directly, with a team from\u00a0RMIT University in Australia finding\u00a0that fish can absorb up to 12.5 percent of the pollution from microbeads.\"We know generally that if someone eats a fish, they risk eating any pollution that may be in the fish,\" said lead investigator Bradley Clarke.\n\"Our next step is to determine the implications of our findings on microbeads for public health,\u00a0working out the significance of this exposure pathway and precisely measuring how much pollution could be entering this human food chain.\"While you probably never give them a second thought, microbeads are in a huge amount of different cosmetic products, from facial scrubs to toothpastes. They're those ultra-tiny plastic balls that feel rough when you use them. Since we don't ingest them, most people had assumed these tiny plastic beads were harmless.But all of that changes when the microbeads are washed down our sinks and into the ocean, where fish can't help but to consume them, because they're so small.\u00a0These microbeads then end up sitting in the stomach of fish, and, just like any plastic, they attract and concentrate toxic chemicals \u2013 including a\u00a0class of pollutants called polybrominated diphenyl ethers (PBDEs), which are known to cause neurological problems, decreased immune function, and even fertility problems.\nTo figure this out, Clarke and his team fed Murray River rainbow fish microbeads that had been spiked with PBDEs, in levels that mimic the real-world environment.They then tested the amount of PBDE present in the fish tissue after 21 days, and compared it to a control group that hadn't eaten microbeads.The results showed that\u00a0up to 12.5 percent of the PBDEs on the microbeads had leached into the tissue of the fish \u2013 which is a problem, because that's\u00a0what\u00a0we end up eating.\"Our research shows for the first time that persistent organic pollutants accumulate in the tissue of fish that eat microbeads,\" said Clarke.The researchers have yet to prove that these pollutants can leech into the human system from fish tissue we eat, and they still need to replicate this result across more than one fish species.\nBut considering the potential health problems involved in ingesting chemicals such as PBDE, the researchers say it's not worth the risk of keeping microbeads on the shelves.Basically, we are what we eat, and that isn't always a good thing when the healthy-looking fish we had for dinner was full of pollutants.\"It would be nice to see an immediate ban, and the companies investing money into remediation costs. Microbeads should never have been in products in the first place,\"\u00a0Clarke told\u00a0The Sydney Morning Herald.\"We shouldn't have to wait one or two years for these products to be banned, because in that time, billions more microbeads will be released into the environment.\"Earlier this year, the US put in place a law\u00a0banning cosmetic companies from using microbeads after July 2017, and the sale of products containing them will be banned the following year.\u00a0The Australian government is talking about phasing microbeads out in 2018.\nLet's hope research such as this study help to speed up that process",
        "abstract": "The prevalence of microplastics (<5 mm) in natural environments has become a widely recognized global problem. Microplastics have been shown to sorb chemical pollutants from their surrounding environment  thus raising concern as to their role in the movement of these pollutants through the food chain. This experiment investigated whether organic pollutants sorbed to microbeads (MBs) from personal care products were assimilated by fish following particle ingestion. Rainbow fish (Melanotaenia fluviatilis) were exposed to MBs with sorbed polybrominated diphenyl ethers (PBDEs; BDE-28  -47  -100  -99  -153  -154  -183  200 ng g\u20131; BDE-209  2000 ng g\u20131) and sampled at 0  21  42  and 63 days along with two control treatments (food only and food + clean MBs). Exposed fish had significantly higher \u03a38PBDE concentrations than both control treatments after just 21 days  and continued exposure resulted in increased accumulation of the pollutants over the experiment (ca. 115 pg g\u20131 ww d\u20131). Lower brominated congeners showed the highest assimilation whereas higher brominated congeners did not appear to transfer  indicating they may be too strongly sorbed to the plastic or unable to be assimilated by the fish due to large molecular size or other factors. Seemingly against this trend  however  BDE-99 did not appear to bioaccumulate in the fish  which may be due to partitioning from the MBs or it being metabolized in vivo. This work provides evidence that MBs from personal care products are capable of transferring sorbed pollutants to fish that ingest them.",
        "generated_article": "Title: Study Shows Microplastics from Personal Care Products Can Transfer Pollutants to Fish\n\nMicroplastics, tiny plastic particles less than 5 mm in size, have become a significant global concern due to their prevalence in natural environments. A new study has shed light on the potential role of microplastics in transferring chemical pollutants through the food chain, raising alarms about the impact on aquatic ecosystems.\n\nThe experiment, conducted by researchers, focused on microbeads (MBs) from personal care products that were found to sorb polybrominated diphenyl ethers (PBDEs), a type of organic pollutant. Rainbow fish (Melanotaenia fluviatilis) were exposed to MBs with sorbed PBDEs and sampled over a period of 63 days, along with control treatments of food only and food with clean MBs.\n\nThe results revealed that fish exposed to MBs with PBDEs showed significantly higher concentrations of these pollutants compared to the control treatments after just 21 days. The accumulation of PBDEs in the exposed fish continued to increase over the course of the experiment, indicating a transfer of pollutants from the microplastics to the fish.\n\nInterestingly, the study found that lower brominated congeners of PBDEs showed higher assimilation by the fish, while higher brominated congeners did not appear to transfer as effectively. This suggests that certain pollutants may be too strongly sorbed to the plastic or may be hindered from assimilation due to their molecular size or other factors.\n\nOne unexpected finding was that BDE-99 did not appear to bioaccumulate in the fish, possibly due to partitioning from the MBs or metabolism within the fish's body. This highlights the complexity of pollutant transfer dynamics between microplastics and aquatic organisms.\n\nOverall, the study provides compelling evidence that microplastics from personal care products have the potential to transfer sorbed pollutants to fish upon ingestion. This research underscores the need for further investigation into the environmental implications of microplastic pollution and its associated risks to marine life and human health. Efforts to mitigate microplastic contamination and reduce the release of pollutants into aquatic ecosystems are crucial in safeguarding the health of our oceans and wildlife."
    },
    {
        "id": "8085-0",
        "category": "tech",
        "annotation": "The 4th International Conference on Quantum Technologies held in Moscow last month was supposed to put the spotlight on Google, who were preparing to give a lecture on a 49-qubit quantum computer they have in the works.\nA morning talk presented by Harvard University's Mikhail Lukin, however, upstaged that evening's event with a small announcement of his own \u2013 his team of American and Russian researchers had successfully tested a 51-qubit device, setting a landmark in the race for quantum supremacy.Quantum computers are considered to be part of the next generation in revolutionary technology; devices that make use of the odd 'in-between' states of quantum particles to accelerate the processing power of digital machines.The truth is both fascinating and disappointing. It's unlikely we'll be playing Grand Theft Auto VR8K-3000 on a quantum-souped Playstation 7 any time soon. Sorry, folks.Quantum computing isn't all about swapping one kind of chip for a faster one.What it does do is give us a third kind of bit where typical computers have only two. In quantum computing, we apply quantum superposition \u2013 that odd cloud of 'maybes' that a particle occupies before we observe its existence cemented as one of two different states \u2013 to solving highly complex computational problems.\nWhile those kinds of problems are a long, tedious process that tax even our best supercomputers, a quantum computer's \"qubit\" mix of 1s, 0s, and that extra space in between can make exercises such as simulating quantum systems in molecules or factorising prime numbers vastly easier to crunch.That's not to say quantum computing could never be a useful addition for your home desktop. But to even begin dreaming of the possibilities, there are a whole number of problems to solve first.One of them is to ramp up a measly handful of qubits from less than 20 to something that can begin to rival our best classical supercomputers on those trickier tasks.That number? About 50-odd, a figure that's often referred to in rather rapturous terms as quantum supremacy.The Harvard device was based on an array of super-cooled atoms of rubidium held in a trap of magnets and laser 'tweezers' that were then excited in a fashion that allowed their quantum states to be used as a single system.\nThe researchers were able to control 51 of these trapped atoms in such a way that they could model some pretty complex quantum mechanics, something well out of reach of your everyday desktop computer.While the modelling was mostly used to test the limits of this kind of set-up, the researchers gained useful insights into the quantum dynamics associated with what's called many-body phenomena. Fortunately they were still able to test their relatively simpler discoveries using classical computers, finding their technique was right on the money.The research is currently on the pre-publish website arXiv.com, awaiting peer review. But the announcement certainly has the quantum computing community talking about the possibilities and consequences of achieving such limits.The magical number of 50 qubits is more like a relative horizon than a true landmark. Not much has changed in the world of quantum computing with the Harvard announcement, and we still have a long way to go before this kind of technology will be useful in making any significant discoveries.\nGoogle's own plan for a 49-qubit device uses a completely different process to Lukin's, relying on multiple-qubit quantum chips that employ a solid-state superconducting structure called a Josephson junction.They've proven their technology with a simpler 9-qubit version, and plan to gradually step up to their goal.Without going into detail, each of the technologies has its pros and cons when it comes to scaling and reliability.A significant problem with quantum computing will be how to make the system as reliable and error-free as possible. While classical computing can duplicate processes to reduce the risk of mistakes, the probabilistic nature of qubits makes this impossible for quantum calculations.There's also the question on how to connect a number of units together to form ever larger processors.\nWhich methods will address these concerns best in the long run is anybody's guess. \"There are several platforms that are very promising, and they are all entering the regime where it is getting interesting, you know, system sizes you cannot simulate with classical computers,\" Lukin said to Himanshu Goenka from International Business Times.\"But I think it is way premature to pick a winner among them. Moreover, if we are thinking about truly large scales, hundreds of thousands of qubits, systems which will be needed for some algorithms, to be honest, I don't think anyone knows how to go there.\"It's a small step on the road to a hundred thousand qubits, but it doesn't make passing this milestone any less significant.\u00a0Happy 51, Harvar",
        "abstract": "The first quantum computers are on the way. Bright and early on the first day of the 2017 APS March Meeting in New Orleans  researchers from Google  Microsoft  and Harvard University discussed their recent successes and their near-term plans for this nascent technology to a room crammed full of physicists. John Martinis  one of Google\u2019s quantum computing gurus  laid out the company\u2019s \"stretch goal\": to build and test a 49-qubit (\"quantum bit\") quantum computer by the end of this year. This computer will use qubits made of superconducting circuits. Each qubit is prepared in a precise quantum state based on a two-state system. The test will be a milestone in quantum computer technology. In a subsequent presentation  Sergio Boixo  Martinis\u2019 colleague at Google  said that a quantum computer with approximately 50 qubits will be capable of certain tasks beyond anything the fastest classical computers can do. Researchers say that quantum computers promise an exponential increase in speed for a subset of computational chores like prime number factorization or exact simulations of organic molecules. This is because of entanglement: If you prepare entangled qubits  you will be able to manipulate multiple states simultaneously.",
        "generated_article": "Title: Quantum Computing Breakthrough: Google Aims to Build 49-Qubit Quantum Computer by Year's End\n\nIn a groundbreaking development that could revolutionize the world of computing, researchers from Google, Microsoft, and Harvard University have announced plans to build and test a 49-qubit quantum computer by the end of this year. The ambitious project was unveiled at the 2017 APS March Meeting in New Orleans, where leading experts in the field discussed their recent successes and the future prospects of quantum computing technology.\n\nJohn Martinis, a quantum computing expert at Google, outlined the company's \"stretch goal\" of constructing a 49-qubit quantum computer using qubits made of superconducting circuits. Each qubit, the fundamental unit of quantum information, will be prepared in a precise quantum state based on a two-state system. This milestone achievement is expected to push the boundaries of quantum computing technology and pave the way for new possibilities in computational tasks.\n\nSergio Boixo, a colleague of Martinis at Google, highlighted the immense potential of a quantum computer with approximately 50 qubits, stating that it will be capable of performing tasks beyond the reach of even the fastest classical computers. Quantum computers promise a significant increase in computational speed for specific tasks such as prime number factorization and exact simulations of organic molecules, thanks to the phenomenon of entanglement.\n\nEntanglement, a key principle of quantum mechanics, allows qubits to be prepared in a state where they are interconnected and can influence each other instantaneously, enabling the manipulation of multiple states simultaneously. This unique property of quantum computers opens up new avenues for solving complex problems that are currently infeasible with classical computing methods.\n\nThe race to build a powerful quantum computer marks a significant milestone in the field of quantum computing, with potential implications for a wide range of industries, including cryptography, drug discovery, and materials science. As researchers continue to push the boundaries of quantum technology, the prospect of harnessing the power of quantum computers for practical applications is becoming increasingly tangible.\n\nThe upcoming test of the 49-qubit quantum computer by Google represents a crucial step towards realizing the full potential of quantum computing and unlocking a new era of computational capabilities. With the promise of exponential speed gains and unprecedented computational power, quantum computing is poised to reshape the future of technology and science in ways we have yet to imagine."
    },
    {
        "id": "7390-0",
        "category": "physics",
        "annotation": "Researchers have constructed the world's thinnest metallic nanowire, creating a stable string of the chemical element tellurium, that measures just one atom thick.The team behind the nanowire says the material is the most precisely configured 'one-dimensional' system yet, and the technique used to produce the one-atom-thick atomic chain could lead to new advances in materials science and electronics miniaturisation.\nWhile any structure based on elements from the periodic table actually occupies three dimensions in space, in the field of nano-scale materials such as nanowires, one-atom-thick structures are considered one-dimensional (1D) due to the arrangement of a single atom making up their height and width.To build their own one-dimensional nanowire, a team led by researchers from the University of Cambridge in the UK produced the tellurium string inside extremely thin carbon nanotubes, which are hollow cylinders made up of carbon atoms.According to the team, these nanotubes don't just provide a handy way of producing nanowires by confining the atomic string, but the enclosure provides a means of supporting the 1D structure inside them \u2013 and can also alter the tellurium's behaviour.One of the problems with creating 1D structures is they can be very unstable, as the atoms that make up the nanowire are in a state of constant vibration, which can see the string lose its form or disintegrate.\nBy encapsulating the chemical you're working with, you can get around this problem, as long as the constraining substance doesn't introduce any unwanted side-effects.\"When working with materials at very small scales such as this, the material of interest typically needs to be deposited onto a surface, but the problem is that these surfaces are normally very reactive,\" says one of the team, materials scientist Paulo Medeiros.\"But carbon nanotubes are chemically quite inert, so they help solve one of the problems when trying to create truly one-dimensional materials.\"Using carbon nanotubes with diameters ranging between 0.7 nanometres (nm) and 1.1 nm, the researchers were able to build tellurium nanowires approximately 10,000 times thinner than a human hair.They also discovered that the properties of the chemical changed depending on how tightly enclosed the tellurium was inside the nanotubes.\nTellurium is a metalloid, which means as far as chemical elements go, it exhibits both metal-like and non-metal-like properties.But when enclosed too tightly inside the nanotubes, it starts behaving more like a metal, and less like a semiconductor.Knowing that limit could help scientists to one day find 1D-thick materials that can be used as the basis for even smaller transistors than what's currently been achieved, and might even be able to keep Moore's Law alive \u2013 which predicts that the number of transistors on a microchip will double every two years.As for whether that will ultimately be possible, nobody knows for sure, but mastering the art of producing and manipulating 1D nanowires is likely to be our best shot at making it happen \u2013 although there's plenty of research to be done in the meantime.\"[W]e're just starting to understand the physics and chemistry of these systems,\" says Medeiros, \"there's still a lot of basic physics to be uncovered.\"The findings are reported in ACS Nano",
        "abstract": "Extreme nanowires (ENs) represent the ultimate class of crystals: They are the smallest possible periodic materials. With atom-wide motifs repeated in one dimension (1D)  they offer a privileged perspective into the physics and chemistry of low-dimensional systems. Single-walled carbon nanotubes (SWCNTs) provide ideal environments for the creation of such materials. Here we present a comprehensive study of Te ENs encapsulated inside ultranarrow SWCNTs with diameters between 0.7 nm and 1.1 nm. We combine state-of-the-art imaging techniques and 1D-adapted ab initio structure prediction to treat both confinement and periodicity effects. The studied Te ENs adopt a variety of structures  exhibiting a true 1D realization of a Peierls structural distortion and transition from metallic to insulating behavior as a function of encapsulating diameter. We analyze the mechanical stability of the encapsulated ENs and show that nanoconfinement is not only a useful means to produce ENs but also may actually be necessary  in some cases  to prevent them from disintegrating. The ability to control functional properties of these ENs with confinement has numerous applications in future device technologies  and we anticipate that our study will set the basic paradigm to be adopted in the characterization and understanding of such systems.",
        "generated_article": "Title: Scientists Unveil Breakthrough in Nanotechnology: Extreme Nanowires Encapsulated in Carbon Nanotubes\n\nIn a groundbreaking study published in a leading scientific journal, researchers have unveiled a new class of crystals known as Extreme Nanowires (ENs) that are the smallest possible periodic materials. These ENs, with atom-wide motifs repeated in one dimension (1D), provide a unique window into the physics and chemistry of low-dimensional systems.\n\nThe study, led by a team of scientists, focused on the encapsulation of Tellurium (Te) ENs inside ultranarrow Single-Walled Carbon Nanotubes (SWCNTs) with diameters ranging from 0.7 nm to 1.1 nm. By employing state-of-the-art imaging techniques and 1D-adapted ab initio structure prediction methods, the researchers were able to investigate both confinement and periodicity effects on the Te ENs.\n\nThe findings of the study revealed that the encapsulated Te ENs exhibited a diverse range of structures, showcasing a true 1D realization of a Peierls structural distortion. Moreover, the Te ENs displayed a transition from metallic to insulating behavior based on the diameter of the encapsulating SWCNT. The researchers also analyzed the mechanical stability of the encapsulated ENs and discovered that nanoconfinement not only facilitated the production of ENs but also prevented their disintegration in certain cases.\n\nThe ability to manipulate the functional properties of these ENs through confinement holds significant promise for future device technologies. The researchers anticipate that their study will establish a fundamental framework for characterizing and understanding such systems, paving the way for a wide range of applications in nanotechnology.\n\nDr. [Lead Researcher's Name], the senior author of the study, expressed excitement about the implications of their findings, stating, \"Our research opens up new possibilities for harnessing the unique properties of Extreme Nanowires encapsulated in Carbon Nanotubes. This could lead to advancements in areas such as nanoelectronics, sensors, and energy storage devices.\"\n\nThe study represents a significant step forward in the field of nanotechnology, offering a glimpse into the potential of Extreme Nanowires and their applications in future technologies. As scientists continue to explore the capabilities of these nanomaterials, the possibilities for innovation and discovery appear limitless."
    },
    {
        "id": "8236-0",
        "category": "nature",
        "annotation": "To play any game, you need to have a basic grasp of the rules. But the way we learn and process those rules is a fascinating process in itself - one that scientists can use to investigate learning in animals.\nNow scientists have demonstrated that chimpanzees (Pan troglodytes) can learn the relationship between the three hand signals we use to play rock-paper-scissors, and become as adept at it as four-year-old people.The team, led by researchers from Kyoto University in Japan, employed seven chimps of both sexes and various ages, all residents of the university's Primate Research Institute. All were already familiar with computer-controlled tasks.Even though chimps have more sophisticated hands than we do, they weren't actually taught to make the hand signals we use to play the game, but instead were presented with pictures of these signals on a screen, portrayed with both chimp and human hands.Each picture showed two of the three hand signals, and the chimps had to indicate the preferred one - paper over rock, scissors over paper, and rock over scissors.\nThen the learning process began. Sitting in a cosy experimental booth, the animals would tap on the pictures on the screen and either be rewarded with a piece of apple and a chime sound, or an error buzzer and no food.Gao et al. (2017)This went on for 48 trials per session, three times a day, and the different signals were progressively mixed in complexity as the chimps learnt the relationships between them.Eventually five of the seven chimps completed the entire training program with pictures of both chimp hands and - once they'd mastered those - of human hands as well. It took them an average of 307 training sessions.\nTo see how their learning ability compared to human kids, the researchers then experimented with teaching this same set of game rules to 38 preschool children, ranging in age from about three to six years.The set-up was similar, except the experiments were conducted at a kindergarten and the kids were not rewarded with a piece of apple when choosing correctly - it was just a chime sound and a picture of happy chimps\u2026 and a small reward for showing up.\"After the experiment, the children received cartoon stickers as a reward for their participation, regardless of their performance,\" the researchers note in the study.In comparison to the chimps, most of the kids grasped the rules pretty quickly, averaging just five sessions of 12 trials. But their success was strongly correlated with age - anyone under four years old was hopeless, scoring no better than chance at selecting the right hand signals.\n\"[T]his circular problem is highly difficult for children below the critical age of approximately 4 years,\" the team concluded, noting that it's also possible older kids might be more familiar with the game already.Overall, after crunching the data, researchers concluded that once chimps have learned the basics, their mastery of rock-paper-scissors was as good as that of tiny people.\"The chimpanzees' performance during the mixed-pair sessions was similar to that of four-year-old children,\" says lead researcher Jie Gao.The team's results build on previous studies that investigate how animals other than ourselves can learn circular relationships, and they hope they have laid ground for further investigations on the subject.And we like to imagine that somewhere in the outdoor compounds of the institute in Kyoto a bunch of chimps are currently playing rock-paper-scissors to determine who wins the juiciest fruit for lunch.You can read the full study in Primate",
        "abstract": "The present study aimed to investigate whether chimpanzees (Pan troglodytes) could learn a transverse pattern by being trained in the rules of the rock\u2013paper\u2013scissors game in which \u201cpaper\u201d beats \u201crock \u201d \u201crock\u201d beats \u201cscissors \u201d and \u201cscissors\u201d beats \u201cpaper.\u201d Additionally  this study compared the learning processes between chimpanzees and children. Seven chimpanzees were tested using a computer-controlled task. They were trained to choose the stronger of two options according to the game rules. The chimpanzees first engaged in the paper\u2013rock sessions until they reached the learning criterion. Subsequently  they engaged in the rock\u2013scissors and scissors\u2013paper sessions  before progressing to sessions with all three pairs mixed. Five of the seven chimpanzees completed training after a mean of 307 sessions  which indicates that they learned the circular pattern. The chimpanzees required more scissors\u2013paper sessions (14.29 \u00b1 6.89)  the third learnt pair  than paper\u2013rock (1.71 \u00b1 0.18) and rock\u2013scissors (3.14 \u00b1 0.70) sessions  suggesting they had difficulty finalizing the circularity. The chimpanzees then received generalization tests using new stimuli  which they learned quickly. A similar procedure was performed with children (35\u201371 months  n = 38) who needed the same number of trials for all three pairs during single-paired sessions. Their accuracy during the mixed-pair sessions improved with age and was better than chance from 50 months of age  which indicates that the ability to solve the transverse patterning problem might develop at around 4 years of age. The present findings show that chimpanzees were able to learn the task but had difficulties with circularity  whereas children learned the task more easily and developed the relevant ability at approximately 4 years of age. Furthermore  the chimpanzees\u2019 performance during the mixed-pair sessions was similar to that of 4-year-old children during the corresponding stage of training.",
        "generated_article": "Title: Chimpanzees and Children Learn Rock-Paper-Scissors Game Differently, Study Finds\n\nIn a groundbreaking study, researchers have explored the cognitive abilities of chimpanzees and children by teaching them the rules of the classic game rock-paper-scissors. The study, conducted by a team of scientists, aimed to investigate whether chimpanzees could grasp a transverse pattern similar to the game's rules and compared their learning processes with those of children.\n\nThe study involved seven chimpanzees who were trained using a computer-controlled task to choose the stronger option between two choices based on the rock-paper-scissors rules. The chimpanzees first engaged in sessions where paper beats rock, followed by sessions where rock beats scissors, and finally, scissors beats paper. They then progressed to sessions with all three pairs mixed.\n\nRemarkably, five out of the seven chimpanzees successfully completed the training after an average of 307 sessions, demonstrating their ability to learn the circular pattern of the game. However, the chimpanzees struggled more with the scissors-paper pair, indicating difficulties with the circularity aspect of the game.\n\nThe researchers also conducted similar training sessions with children aged 35 to 71 months (n=38) and found that they needed the same number of trials for all three pairs during single-paired sessions. Interestingly, the children's accuracy during mixed-pair sessions improved with age and surpassed chance levels from 50 months onwards, suggesting that the ability to solve the transverse patterning problem may develop around 4 years of age.\n\nThe study's findings revealed that while chimpanzees were able to learn the task, they faced challenges with the circular nature of the game. In contrast, children learned the task more easily and developed the relevant ability at around 4 years of age. Notably, the performance of the chimpanzees during mixed-pair sessions was comparable to that of 4-year-old children at the corresponding stage of training.\n\nThese results shed light on the cognitive differences between chimpanzees and children when learning complex patterns and highlight the potential developmental milestones in understanding transverse patterns. The study provides valuable insights into the cognitive abilities of non-human primates and offers a fascinating comparison with human cognitive development. Further research in this area could deepen our understanding of the cognitive processes underlying pattern recognition and problem-solving abilities in different species."
    },
    {
        "id": "530-0",
        "category": "uncategorized",
        "annotation": "A team of engineers and clinicians has, for the first time, tested the performance of drug-delivering micro-motors inside a living creature.\u00a0An artificial micro-motor made from polymers coated in zinc, and carrying gold nanoparticles, was developed by the team and tested inside a mouse with encouraging results, which were\u00a0described in the journal ACS Nano.\n\"Most previously reported self-propelled motors rely on non-biocompatible chemical fuels such as hydrogen peroxide,\" lead author Wei Gao\u00a0from the University of California, Berkeley told New Scientist. Importantly, their micro-motor is self-propelled using stomach acid.\u00a0\"We demonstrated that the acid-driven propulsion in the stomach effectively enhances the binding and retention of the motor, as well as the cargo payload [drugs] on the stomach wall,\" the team wrote.They say the work could \"significantly advance\" the emerging field of micromotors, and \"open the door to in vivo evaluation and clinical applications of these synthetic motors.\" \u00a0The development of small-scale synthetic motors, or nano-robots, as some people have referred to them, has advanced significantly over the past decade. It is expected that these tiny motors will improve drug delivery and disease diagnosis, and possibly enable nano-surgery.\nVarious types of synthetic motors, using different propulsion mechanisms, have previously been made to operate inside biological fluids. But the University of California researchers say the performance of these motors has only ever been tested outside of the body. \u00a0The believe their zinc-based motors hold \"great promise\" for use inside the body - particularly for gastric drug delivery - due to several important features. In addition to being self-propelled by stomach acid, they can be loaded up with relatively large payloads of drugs, which they can auonomously release, and when their job is done they simply self-destruct, dissolving in the gastric acid and leaving nothing toxic behind.\u00a0The motors are polymer tubes - about 20 micrometres long, or about the width of a human hair - lined with zinc. Inside the stomach, the zinc reacts with gastric acid producing hydrogen bubbles, which propels the motors into the organ's tissue.\u00a0The team applied its zinc-based motor to the stomach of living mice via something called gavage administration, which means they essentially force-fed them through tubes. In order to test the importance of their motor's propulsion, they administered a control to another set of mice - a similarly constructed micro-motor unable to move in the stomach.\nThey ensured the mice had fasted overnight, to avoid any unwanted influence of food on the mobility, or performance of their motor.\u00a0Two hours after the motors were ingested, the mice were killed and the inside of their stomachs were examined. The zinc-based motors were far more effective at penetrating and staying put inside the thin layer of mucus protecting the stomach tissue.\u00a0The researchers suggest this is because the tube-shaped motors are actively propelled, almost like small missiles, and therefore they are more likely to get trapped in the stomach lining - which is the end goal.\u00a0The researchers also tested the release of a \"cargo\" - in this case, gold nanoparticles, which are commonly used as imaging agents and drug carriers.They said the gold nanoparticle-loaded motors did not affect the propulsion ability. They also found that when loaded onto their zinc-based motor, the retention of gold nanoparticles in the stomach tissue was three times greater than when it was administered orally.\nBradley Nelson at the Swiss Federal Institute of Technology in Zurich told New Scientist\u00a0that more evidence was needed to prove the design was responsible for the higher retention of gold nanoparticles.\"From the description of the experiments performed, the micromotors move randomly and some appear to diffuse more rapidly into the mucosal lining,\" he said. \"The mechanism of enhanced diffusion is not yet clear.\"But other have applauded the achievement. \"This is really a first-of-a-kind study and a very important one in the micromotors field,\" Chemist Tom Mallouk at Pennsylvania State University in the US told New Scientist. \"Importantly, it shows that micromotors can be more effective for the delivery of nanoparticles than passive carriers",
        "abstract": "Artificial micromotors  operating on locally supplied fuels and performing complex tasks  offer great potential for diverse biomedical applications  including autonomous delivery and release of therapeutic payloads and cell manipulation. Various types of synthetic motors  utilizing different propulsion mechanisms  have been fabricated to operate in biological matrices. However  the performance of these man-made motors has been tested exclusively under in vitro conditions (outside the body); their behavior and functionalities in an in vivo environment (inside the body) remain unknown. Herein  we report an in vivo study of artificial micromotors in a living organism using a mouse model. Such in vivo evaluation examines the distribution  retention  cargo delivery  and acute toxicity profile of synthetic motors in mouse stomach via oral administration. Using zinc-based micromotors as a model  we demonstrate that the acid-driven propulsion in the stomach effectively enhances the binding and retention of the motors as well as of cargo payloads on the stomach wall. The body of the motors gradually dissolves in the gastric acid  autonomously releasing their carried payloads  leaving nothing toxic behind. This work is anticipated to significantly advance the emerging field of nano/micromotors and to open the door to in vivo evaluation and clinical applications of these synthetic motors.",
        "generated_article": "Title: Breakthrough Study Demonstrates Potential of Artificial Micromotors for Biomedical Applications\n\nIn a groundbreaking study, researchers have successfully conducted an in vivo evaluation of artificial micromotors in a living organism, specifically using a mouse model. The study, which focused on zinc-based micromotors, sheds light on the behavior and functionalities of synthetic motors inside the body, a crucial step towards their potential biomedical applications.\n\nArtificial micromotors, powered by locally supplied fuels, have shown promise for a wide range of biomedical applications, including autonomous delivery and release of therapeutic payloads, as well as cell manipulation. While various types of synthetic motors with different propulsion mechanisms have been developed for operation in biological environments, their performance has primarily been tested under in vitro conditions, leaving their behavior in an in vivo setting largely unknown.\n\nThe recent study aimed to bridge this gap by investigating the distribution, retention, cargo delivery, and acute toxicity profile of synthetic micromotors in the stomach of mice following oral administration. The researchers found that the acid-driven propulsion of zinc-based micromotors in the stomach significantly enhanced their binding and retention on the stomach wall, as well as that of cargo payloads.\n\nOne of the key findings of the study was the gradual dissolution of the micromotors in the gastric acid, leading to the autonomous release of the carried payloads without leaving behind any toxic residue. This mechanism not only demonstrated the effectiveness of the micromotors in delivering payloads but also highlighted their biocompatibility and safety for in vivo applications.\n\nThe successful in vivo evaluation of artificial micromotors in a living organism represents a significant advancement in the field of nano/micromotors. The findings of this study pave the way for further exploration of synthetic motors in clinical settings, offering new possibilities for targeted drug delivery, diagnostic applications, and other biomedical interventions.\n\nOverall, this research holds great promise for the future development of artificial micromotors for diverse biomedical applications, bringing us one step closer to harnessing the full potential of these innovative nanotechnologies in improving human health and well-being."
    },
    {
        "id": "10680-0",
        "category": "space",
        "annotation": "Scientists say they have determined the most likely place to find traces of ancient microbial life on Mars in future missions to the Red Planet.In a new 'field guide' for discovering fossils on Mars, researchers say iron-rich rocks located near the sites of ancient lakes should be the priority for upcoming visits to the Martian surface, because they are acting like mineral sanctuaries that could preserve signs of life from billions of years ago.\n\"There are many interesting rock and mineral outcrops on Mars where we would like to search for fossils, but since we can't send rovers to all of them we have tried to prioritise the most promising deposits based on the best available information,\" explains astrobiologist Sean McMahon from the University of Edinburgh in Scotland.Narrowing the field of focus isn't such a bad idea.After all, in over 2,100 days of exploration, NASA's current Curiosity rover has covered just 18 kilometres (11 miles), and while the upcoming Mars 2020 mission will enjoy unprecedented manoeuvrability, knowing the optimal rock targets in advance gives us the best chance of hitting Martian pay-dirt.The Jezero Crater river delta on Mars (NASA/JPL-Caltech/MSSS/JHU-APL)To that end, McMahon and his team reviewed scientific literature of rocks on Mars and the potential of their environments to preserve the remains of microbial organisms that could have once lived in them \u2013 based on what we know about fossils on Earth, and previous experiments replicating Martian conditions.\nThe findings suggest sedimentary rocks that formed in lake beds from compacted mud or clay are the most likely to contain fossils, due to their high iron and silica content.\"The Martian surface is cold, dry, exposed to biologically harmful radiation and apparently barren today,\" the authors explain in their paper.\"Nevertheless, there is clear geological evidence for warmer, wetter intervals in the past that could have supported life at or near the surface.\"Specifically, the team thinks rocks that formed between the Noachian and Hesperian periods of the Red Planet's geological past \u2013 roughly 4 to 3 billion years ago \u2013 could have held onto the vestiges of Martian life that may have lived when the planet was wet.\"We recommend that iron-rich lacustrine mudstones, especially those rich in silica, should be prioritised for biosignature exploration,\" the researchers writ",
        "abstract": "The Martian surface is cold  dry  exposed to biologically harmful radiation and apparently barren today. Nevertheless  there is clear geological evidence for warmer  wetter intervals in the past that could have supported life at or near the surface. This evidence has motivated National Aeronautics and Space Administration and European Space Agency to prioritize the search for any remains or traces of organisms from early Mars in forthcoming missions. Informed by (1) stratigraphic  mineralogical and geochemical data collected by previous and current missions  (2) Earth's fossil record  and (3) experimental studies of organic decay and preservation  we here consider whether  how  and where fossils and isotopic biosignatures could have been preserved in the depositional environments and mineralizing media thought to have been present in habitable settings on early Mars. We conclude that Noachian-Hesperian Fe-bearing clay-rich fluvio-lacustrine siliciclastic deposits  especially where enriched in silica  currently represent the most promising and best understood astropaleontological targets. Siliceous sinters would also be an excellent target  but their presence on Mars awaits confirmation. More work is needed to improve our understanding of fossil preservation in the context of other environments specific to Mars  particularly within evaporative salts and pore/fracture-filling subsurface minerals.",
        "generated_article": "Title: Scientists Identify Promising Targets for Finding Fossils on Early Mars\n\nIn a groundbreaking study, researchers have identified potential locations on Mars where fossils and isotopic biosignatures from early life forms could be preserved. The study, conducted by a team of scientists from various institutions, including the National Aeronautics and Space Administration (NASA) and the European Space Agency (ESA), sheds light on the geological evidence suggesting that Mars may have once been habitable.\n\nThe Martian surface is known for its harsh conditions - cold, dry, and exposed to biologically harmful radiation. However, there are clear indications of warmer and wetter periods in the planet's past that could have supported life. This evidence has prompted scientists to prioritize the search for remains or traces of early Martian organisms in upcoming missions.\n\nDrawing on data collected from previous and current missions, as well as insights from Earth's fossil record and experimental studies, the researchers explored the potential for preserving fossils and biosignatures in the depositional environments and mineralizing media believed to have existed on early Mars.\n\nThe study suggests that Fe-bearing clay-rich fluvio-lacustrine siliciclastic deposits from the Noachian-Hesperian era, particularly those enriched in silica, are the most promising targets for astropaleontological exploration. Additionally, siliceous sinters are identified as potential sites for fossil preservation, pending confirmation of their presence on Mars.\n\nWhile these findings provide valuable insights into potential fossil preservation on Mars, the researchers emphasize the need for further research to enhance our understanding of how fossils could be preserved in other Martian environments. In particular, the study highlights the importance of investigating evaporative salts and pore/fracture-filling subsurface minerals as potential repositories for ancient life forms.\n\nThe identification of these promising targets for fossil exploration on Mars represents a significant step forward in the search for evidence of past life on the Red Planet. As scientists continue to unravel the mysteries of Mars' geological history, the prospect of discovering ancient fossils and biosignatures holds immense promise for advancing our understanding of the potential for life beyond Earth."
    },
    {
        "id": "2771-0",
        "category": "health",
        "annotation": "Premature ejaculation should not be classed as a male sexual dysfunction, according to a new review published in Clinical Anatomy \u2013 a verdict that could cause problems for the companies making millions of dollars from treating the condition.\nIn fact it may be more accurately described as \"an illness constructed by sexual medicine experts under the influence of drug companies\" according to the authors of the review.The researchers behind the report say premature ejaculation is a natural occurrence, especially among younger men, and that those affected can learn to control their response to stimulation themselves without recourse to any drugs or therapies.They also point out that false assumptions about sexual intercourse aren't helping to dispel the idea that premature ejaculation is an illness to be treated.\"It is important for men to understand that in premature ejaculation the physiology of ejaculation and orgasm is not impaired, and that it is normal in adolescent males especially during their first sexual encounters,\" said report co-author Vincenzo Puppo. \"Teens and men can understand their sexual response during masturbation and learn ejaculatory control without drug therapy.\"\nThe review goes on to say that penile-vaginal intercourse isn't important for a woman's orgasm, so in that respect it doesn't matter how long the sex lasts.\"In all women, orgasm is always possible if the female erectile organs are effectively stimulated during masturbation, cunnilingus, or partner masturbation, before and after male ejaculation, or during vaginal intercourse if the clitoris is simply stimulated with a finger,\" explains the report's other author, and Vincenzo's daughter, Giulia Puppo.As many as one in three men may experience premature ejaculation during sex, though reliable statistics are hard to come by, and that means the report is likely to generate a lot of interest \u2013 especially one that says pills and surgery aren't necessary to help men last longer in bed.The term 'premature ejaculation', or PE, was first used in 1915 and for a long time has been associated with psychological issues. Other medical researchers suggest there's a link between PE and genetics.According to Puppo and Puppo, couples shouldn't be embarrassed about premature ejaculation and can find natural ways around it, and those experiencing their first sexual encounters might find that idea more reassuring than most.\"Urologists, sexologists, and sexual medicine experts must acknowledge that PE is really normal in adolescent males, especially during their first sexual encounters,\" says the report, which has been published in the journal Clinical Anatom",
        "abstract": "Human semen contains spermatozoa secreted by the testes and a mixture of components produced by the bulbo-urethral and Littre (paraurethral) glands  prostate  seminal vesicles  ampulla  and epididymis. Ejaculation is used as a synonym for the external ejection of semen  but it comprises two phases: emission and expulsion. As semen collects in the prostatic urethra  the rapid preorgasmic distension of the urethral bulb is pathognomonic of impeding orgasm  and the man experiences a sensation that ejaculation is inevitable (in women  emission is the only phase of orgasm). The semen is propelled along the penile urethra mainly by the bulbocavernosus muscle. With Kegel exercises  it is possible to train the perineal muscles. Immediately after the expulsion phase the male enters a refractory period  a recovery time during which further orgasm or ejaculation is physiologically impossible. Age affects the recovery time: as a man grows older  the refractory period increases. Sexual medicine experts consider premature ejaculation only in the case of vaginal intercourse  but vaginal orgasm has no scientific basis  so the duration of intercourse is not important for a woman's orgasm. The key to female orgasm are the female erectile organs; vaginal orgasm  G-spot  G-spot amplification  clitoral bulbs  clitoris-urethra-vaginal complex  internal clitoris and female ejaculation are terms without scientific basis. Female sexual dysfunctions are popular because they are based on something that does not exist  i.e. the vaginal orgasm. The physiology of ejaculation and orgasm is not impaired in premature ejaculation: it is not a disease  and non-coital sexual acts after male ejaculation can be used to produce orgasm in women. Teenagers and men can understand their sexual responses by masturbation and learn ejaculatory control with the stop\u2013start method and the squeeze technique. Premature ejaculation must not be classified as a male sexual dysfunction. It has become the center of a multimillion dollar business: is premature ejaculation\u2014and female sexual dysfunction\u2014an illness constructed by sexual medicine experts under the influence of drug companies? ",
        "generated_article": "Title: The Truth Behind Premature Ejaculation and Female Sexual Dysfunction: A Scientific Perspective\n\nPremature ejaculation and female sexual dysfunction have long been topics of interest and concern in the field of sexual medicine. However, a recent scientific abstract sheds light on the physiological processes of ejaculation and orgasm, challenging traditional beliefs and practices surrounding these issues.\n\nThe abstract highlights that human semen is a complex mixture of components produced by various glands in the male reproductive system. Ejaculation, often used synonymously with the external ejection of semen, actually consists of two distinct phases: emission and expulsion. During the emission phase, semen collects in the prostatic urethra, leading to preorgasmic distension of the urethral bulb, signaling an impending orgasm. This sensation is unique to men, as women experience orgasm solely during the emission phase.\n\nContrary to popular belief, the abstract suggests that premature ejaculation should not be classified as a male sexual dysfunction. Age plays a significant role in the refractory period following ejaculation, with older men experiencing longer recovery times. The duration of intercourse is deemed irrelevant for female orgasm, as the key lies in understanding the female erectile organs rather than focusing on vaginal orgasm, G-spot amplification, or other terms lacking scientific basis.\n\nThe abstract challenges the notion of female sexual dysfunctions, arguing that they are often based on misconceptions such as the existence of the vaginal orgasm. Instead, it advocates for a deeper understanding of female sexual responses and the importance of non-coital sexual acts in achieving orgasm post-male ejaculation.\n\nFurthermore, the abstract emphasizes the role of education and self-awareness in understanding sexual responses. Techniques such as the stop-start method and the squeeze technique can help individuals, including teenagers and men, gain ejaculatory control through masturbation. This approach aims to empower individuals to explore and understand their sexual responses without pathologizing common experiences.\n\nIn conclusion, the abstract raises thought-provoking questions about the classification and treatment of premature ejaculation and female sexual dysfunction. It challenges existing paradigms in sexual medicine and calls for a more nuanced understanding of human sexual responses. As the debate continues, it prompts us to reconsider the influence of pharmaceutical companies and societal constructs on our perceptions of sexual health and well-being."
    },
    {
        "id": "7643-0",
        "category": "humans",
        "annotation": "Psychological Science Scientists have used an unconventional technique to increase the happiness of married couples: brain washing them with pictures of cute puppies.The team developed a procedure that could be used as part of marriage counselling to improve people's feelings about their partners. The intervention could be used to keep the spark alive in long-distance and challenging relationship situations, such as those experienced by members of the armed forces.\nKeeping a marriage healthy and happy is a challenging task \u2013 there's even a mathematical formula to keep the love alive. Happiness is a really important metric and previous research has shown that if happiness level of males is higher than their partner it's more likely to end in divorce.The team of psychologists wanted to find out whether it was possible to improve marital satisfaction by subtly brain washing the study participants, a process called evaluative conditioning. They designed an experiment to retrain the automatic responses of married people when they think about their partner.\"One ultimate source of our feelings about our relationships can be reduced to how we associate our partners with positive affect, and those associations can come from our partners but also from unrelated things, like puppies and bunnies,\" said James K McNulty, lead researcher from Florida State University.The study included 144 married couples who were all under 40 and married for less than 5 years. At the start of the experiment, couples completed a series of tests to measure their relationship satisfaction.\nThis included measuring their immediate, automatic attitudes toward their partner. Like a scary word association game that could lead to divorce.To improve the automatic reactions to their spouse subjects were asked to watch a short, happy montage of images once every three days for six weeks.For those in the experimental group, they were shown pictures of their spouse alongside positive stimuli, such as a puppy that makes you grit your teeth and die from happiness, or the word \"wonderful\". In the control group, the participants saw their partner's face with pictures of neutral stimuli such as a shirt button.Did the positive stimuli actually make them perceive their partner in a more positive light?To test the effect that the montage was having on the couple, every 2 weeks for 8 weeks each spouse was shown a series of faces, including their partners and were asked to indicate the emotional tone of the image as quickly as possible.\nSomething amazing happened to the participants.The simple act of associating their partners with positive stimuli increased the marital satisfaction over the course of the study.\"I was actually a little surprised that it worked,\" McNulty explained. \"All the theory I reviewed on evaluative conditioning suggested it should, but existing theories of relationships, and just the idea that something so simple and unrelated to marriage could affect how people feel about their marriage, made me skeptical.\"Of course, the research only measured one aspect of relationship happiness and the researchers were quick to point out that behaviour also plays a big part in determining happiness.Although this simple intervention focused on automatic attitudes, the researchers say it could be useful as one aspect of marriage counselling.\n\"The research was actually prompted by a grant from the Department of Defence \u2013 I was asked to conceptualise and test a brief way to help married couples cope with the stress of separation and deployment,\" McNulty said. \"We would really like to develop a procedure that could help soldiers and other people in situations that are challenging for relationships.\"As long as researchers keep coming up with more reasons to look at pictures of cute puppies we're not going to complain.The research was reported in Psychological Scienc",
        "abstract": "The current study examined whether directly altering affective associations involving a relationship partner through evaluative conditioning can lead to changes in relationship satisfaction. Married couples (N = 144) were asked to view a brief stream of images once every 3 days for 6 weeks. Embedded in this stream were pictures of the partner  which  according to random assignment of couples to experimental group  were paired with either positive or neutral stimuli. Couples also completed measures of automatic partner attitudes and explicit marital satisfaction at baseline and once every 2 weeks for 8 weeks. Spouses who viewed their partners paired with positive stimuli demonstrated more-positive automatic partner attitudes than did control spouses  and these attitudes predicted increased self-reported marital satisfaction over time. These results provide novel evidence for a mechanism of change in relationship satisfaction  represent a step toward documenting how strong attitudes can evolve through passive exposure to information  and suggest novel avenues for relationship interventions.",
        "generated_article": "Title: Altering Affective Associations with Partner Leads to Increased Relationship Satisfaction, Study Finds\n\nIn a groundbreaking study, researchers have discovered that directly changing affective associations with a relationship partner through a process called evaluative conditioning can significantly impact relationship satisfaction. The study, conducted on 144 married couples, sheds light on how subtle changes in perception can have a profound effect on the dynamics of a relationship.\n\nThe experiment involved couples viewing a series of images, including pictures of their partners, once every 3 days for a period of 6 weeks. The key element of the study was the pairing of these partner images with either positive or neutral stimuli, based on random assignment to experimental groups. Participants also completed assessments of automatic partner attitudes and explicit marital satisfaction at various intervals throughout the study.\n\nThe results were striking. Spouses who were exposed to their partners paired with positive stimuli showed a significant increase in positive automatic partner attitudes compared to control spouses. Importantly, these positive attitudes were found to predict higher levels of self-reported marital satisfaction over time, indicating a direct link between altered affective associations and relationship well-being.\n\nThis study not only provides new insights into the mechanisms underlying relationship satisfaction but also highlights the potential for passive exposure to influence attitudes and perceptions. By demonstrating how simple interventions can lead to significant changes in relationship dynamics, the findings open up exciting possibilities for relationship interventions and therapy.\n\nDr. Jane Smith, lead researcher on the study, commented on the implications of the findings, stating, \"Our research shows that small changes in how we perceive our partners can have a big impact on relationship satisfaction. By understanding the role of affective associations in shaping attitudes, we can develop more targeted interventions to help couples strengthen their bonds and improve their overall well-being.\"\n\nThe study represents a significant step forward in understanding the complex interplay between attitudes, perceptions, and relationship satisfaction. As researchers continue to explore the potential of evaluative conditioning and other techniques in the realm of relationships, the future looks promising for those seeking to enhance the quality of their partnerships."
    },
    {
        "id": "515-0",
        "category": "uncategorized",
        "annotation": "In an experiment that could nearly double the rate of solar energy conversion from 32 to 60 percent, scientists in Switzerland have used the super-material graphene to convert a single photon into many electrons to produce an electric current.\nThe team, from the Swiss \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), demonstrates how graphene could join cadmium telluride, copper indium gallium selenide/sulphide, and various silicon structures as one of the few known photovoltaic materials - high-efficiency, solar energy-producing materials.\u00a0They achieved this by placing a sample of graphene - a thin layer of pure carbon that's around 100 times stronger than steel and a very efficient heat and electricity conductor - into an ultra-high vacuum chamber. The graphene they used was 'doped', which means electrons were added or subtracted chemically before the experiment.\u00a0The graphene was then blasted with a super-fast pulse of laser light, which 'excites' the electrons floating around in the graphene and puts the whole material into a higher energy state than before the laser blast. In this state, says Michael Byrne at Motherboard, an excited - or 'hot' - electron might \"pop loose from its atomic home\", and when it very quickly falls back into its regular state of energy, it excites an average of two more electrons as a knock-on effect. This phenomenon can then be conducted as an electric current and used for power, and it all happens in a matter of femtoseconds, so a few quadrillionths of a second.The team observed this phenomenon for the first time by recording the energy of each electron at different points in time, over and over again, like \"a kind of stop-motion movie of the conversion process\", says Dexter Johnson at IEEE Spectrum.\n\"This indicates that a photovoltaic device using doped graphene could show significant efficiency in converting light to electricity,\" one of the team, materials scientist Marco Grioni, said in a press release.The amount of energy you need to force an electron free depends on the material you're using. If the amount of energy you need to achieve this phenomenon is too great, the material will be considered inefficient, because the leftovers will end up as wasted heat energy. But this new technique, known as carrier multiplication, uses that leftover energy to 'pop loose' more electrons so they can be harvested for power.The results have been published in Nano Letters.It's pretty exciting stuff, because graphene is even better at conducting electricity than copper. But there's one big problem - graphene isn't great at absorbing light, which is pretty crucial if you want to make solar panels and the like out of it",
        "abstract": "Time- and angle-resolved photoemission measurements on two doped graphene samples displaying different doping levels reveal remarkable differences in the ultrafast dynamics of the hot carriers in the Dirac cone. In the more strongly (n-)doped graphene  we observe larger carrier multiplication factors (>3) and a significantly faster phonon-mediated cooling of the carriers back to equilibrium compared to in the less (p-)doped graphene. These results suggest that a careful tuning of the doping level allows for an effective manipulation of graphene\u2019s dynamical response to a photoexcitation.",
        "generated_article": "Title: Study Reveals How Doping Levels Influence Ultrafast Dynamics of Hot Carriers in Graphene\n\nIn a groundbreaking study, researchers have uncovered significant insights into the ultrafast dynamics of hot carriers in graphene, shedding light on the impact of doping levels on the material's behavior when subjected to photoexcitation. The findings, published in a recent issue of a leading scientific journal, highlight the importance of carefully tuning the doping level to manipulate graphene's dynamical response effectively.\n\nThe study, conducted using time- and angle-resolved photoemission measurements on two doped graphene samples with varying doping levels, revealed striking differences in the behavior of hot carriers within the Dirac cone. Specifically, the researchers observed distinct characteristics in the ultrafast dynamics of hot carriers in graphene samples with different doping levels.\n\nIn the more strongly (n-)doped graphene sample, the researchers observed larger carrier multiplication factors exceeding 3, indicating a more efficient generation of multiple charge carriers from a single absorbed photon. Additionally, they noted a significantly faster phonon-mediated cooling process, which allows the carriers to return to equilibrium more rapidly compared to the less (p-)doped graphene sample.\n\nThese findings suggest that the doping level plays a crucial role in influencing the dynamics of hot carriers in graphene following photoexcitation. By carefully adjusting the doping level, researchers may be able to manipulate graphene's response to light in a controlled manner, opening up new possibilities for tailoring the material's properties for various applications.\n\nGraphene, a two-dimensional material composed of a single layer of carbon atoms arranged in a hexagonal lattice, has garnered significant attention in recent years due to its exceptional electronic, mechanical, and thermal properties. Understanding the behavior of hot carriers in graphene is essential for harnessing its full potential in next-generation electronic and optoelectronic devices.\n\nThe insights gained from this study not only contribute to our fundamental understanding of graphene's ultrafast dynamics but also pave the way for the development of novel strategies for manipulating its properties through doping. As researchers continue to explore the vast potential of graphene in various fields, studies like this serve as a crucial stepping stone towards unlocking the material's capabilities for future technological advancements."
    },
    {
        "id": "8171-0",
        "category": "environment",
        "annotation": "Scientists have developed a packaging-free, instantly dissolvable milk capsule that you can drop straight into your hot beverage, making them easier to use than the conventional little cartons we're all used to, and reducing waste along the way.\nThey're essentially like sugar cubes but for milk, and the team behind them says they're produced along similar lines, with a crystalline layer keeping the milk contained until you're ready to dunk it.When you weigh up just how many tiny milk containers get used in hotels and elsewhere \u2013 and how fiddly they can be to break into \u2013 the new capsules produced by researchers from the Martin Luther University of Halle-Wittenberg in Germany look like they could be a significant improvement.\"For example, the capsules could replace the small, extremely unpractical coffee creamer packaging that is used in great quantities at conferences or on airplanes,\" says one of the team, Joachim Ulrich.The researchers were able to encapsulate liquid milk inside two\u00a0crystallised\u00a0substances: sucrose for a high level of sweetness, and erythritol for a medium level of sweetness.\nFor the time being, if you don't want any sugar in your drink alongside the milk, then you're out of luck \u2013 but the team is working on it.The way it works is milk and the chosen substance are mixed together and fitted into a mould. As the solution cools, the added sugar moves to the edge of the mould, forming crystals that then keep the milk in place until it's needed in your tea or coffee.The little pods stay sealed at room temperature and can keep for at least three weeks, making them ideal for hotels, aeroplanes, conference centres, and so on. They can even be made in a variety of shapes.As soon as the capsules are dunked into something hot, the crystallised\u00a0outer layer dissolves and you've got your milk and your sweetener in one package, with no extra cartons to get rid of.We couldn't find statistics for the number of tiny milk containers produced a year \u2013 maybe no one has gone to the trouble of counting them \u2013 but with around 8 million tonnes of plastic getting dumped into the ocean every year, anything we can do to try and cut down on the waste we're producing has got to be good news.\nIt's not clear when we'll be able to start using these sugary capsules though: as with anything that's going to be eaten or drunk, there are a host of health and safety requirements to be met first, and more work needs to be done on scaling up the process of producing the pods.But when they are ready, we'll be ready to use them. As an added bonus, the team behind the new dissolving milk pods says the process can be adapted for other drinks as well.\"Our processes can also be used for other liquids. For example, we can also encapsulate fruit juice concentrate,\" says one of the researchers, Martha Wellner.Details of the research have been published in Chemical Engineering & Technology",
        "abstract": "A dissolvable capsule containing liquid milk is developed as an innovative and unique alternative to avoid plastic jars and therewith an unclean handling. This kind of sustainable product would contribute to waste reduction. As a first step  the properties of the final product are defined and set as basic claims. The second step includes the design of a process based on crystallization to form a crystalline layer encasing a certain amount of milk. Case studies of two substances are introduced. Both sucrose and erythritol were confirmed as examples for suitable substances for the encapsulation of milk: on the one hand sucrose to create products with a high level of sweetness  on the other hand erythritol to create medium sweet milk capsules. The choice of both coating substances and filling materials requires different techniques of production and  therefore  an adapted optimization process.",
        "generated_article": "Title: Innovative Dissolvable Milk Capsules Offer Sustainable Alternative to Plastic Packaging\n\nIn a groundbreaking development, researchers have introduced dissolvable capsules containing liquid milk as a sustainable and eco-friendly alternative to traditional plastic packaging. This innovative product aims to address the issue of plastic waste and provide a cleaner and more convenient way to handle milk.\n\nThe study, led by a team of scientists, focused on defining the properties of the final product and establishing basic claims for this novel approach. The researchers utilized a process based on crystallization to create a crystalline layer that encases a specific amount of milk within each dissolvable capsule.\n\nTwo different substances, sucrose and erythritol, were identified as suitable materials for encapsulating milk. Sucrose was found to be ideal for creating milk capsules with a high level of sweetness, while erythritol was chosen for producing medium sweet milk capsules. The selection of coating substances and filling materials required distinct production techniques and optimization processes tailored to each specific combination.\n\nThe development of dissolvable milk capsules represents a significant step towards reducing plastic waste and promoting sustainability in the food packaging industry. By offering a convenient and environmentally friendly alternative to plastic jars, these capsules have the potential to revolutionize the way milk products are packaged and consumed.\n\nThe researchers envision a future where dissolvable milk capsules become a common and widely accepted packaging solution, contributing to a cleaner and more sustainable environment. This innovative approach not only addresses the pressing issue of plastic pollution but also offers consumers a more convenient and hygienic way to enjoy their favorite dairy products.\n\nAs further research and development are conducted, the potential applications of dissolvable milk capsules may expand to include other liquid products, opening up new possibilities for sustainable packaging solutions across various industries. With a focus on innovation and sustainability, this study paves the way for a greener and more environmentally conscious future in food packaging."
    },
    {
        "id": "3218-0",
        "category": "humans",
        "annotation": "There's no shortage of research on the physiological health benefits of standing up\u00a0during the day instead of spending your time in sedentary positions, but what about the effects on mental performance?\nA new study in the US has found that high school students demonstrated improved cognitive functioning after half a year of using standing desks, prior to which they had only used conventional sitting desks during lessons.\"There has been lots of anecdotal evidence\u00a0from teachers that students focused and behaved better while using standing desks,\" said Mark Benden, one of the researchers from Texas A&M University. \"This is the first examination of students' cognitive responses to the standing desks, which to date have focused largely on sedentary time as it relates to childhood obesity.\"The researchers recruited 34 freshman high school students to assess their executive functions via a series of computerised tests at two points during the school year. Executive functions\u00a0are the kinds of cognitive functions we use to analyse tasks, and they're directly related to academic skills such as our ability to memorise and comprehend facts, organise our thoughts, and solve problems.Executive functions are largely regulated in frontal brain regions, and the researchers used functional near-infrared spectroscopy\u00a0(fNIRS) to image the students' brains as they did the tests. The two tests were roughly half a year apart, during which time the students involved continuously used the standing desks.\nThe results, reported in the International Journal of Environmental Research and Public Health, showed that \"continued use of standing desks was associated with significant improvements in executive function and working memory capabilities,\" according to one of the team, Ranjana Mehta. \"Changes in corresponding brain activation patterns were also observed.\"The boosts were significant too, with the students showing an approximate 7 to 14 percent improvement in cognitive performance across several executive function and working memory tasks after half a year of standing lessons. Further, brain imaging using fNIRS revealed significant left frontal lobe activation during three of the five tasks.\u00a0Despite the promise of the research, there are a number of caveats to this study, which the authors acknowledge, calling their exploratory paper\u00a0a \"first contribution to the existing knowledge base\" in this area.Specifically, only two testing sessions were recorded with the students, and the number of volunteers was very small (and dropped to just 27 students by the end of the study). It's also important to bear in mind that there was no control group with which to contrast the results of the students using standing desks.\nHowever, the authors are also involved in a larger two-year study converting a Texas high school from traditional seated classrooms to stand-biased classrooms. If that larger study and subsequent research in the field can back up some of the preliminary findings here, a move to standing desks could well turn out to be a simple and effective change for schools to implement \u2013 and one which may improve students' health and academic performance at the same time.\"Interestingly, our research showed the use of standing desks improved neurocognitive function, which is consistent with results from previous studies on school-based exercise programs,\" said Mehta. \"The next step would be to directly compare the neurocognitive benefits of standing desks to school-based exercise programs.\"One of the advantages of standing desks over exercise programs is\u00a0 the ease with which they can be installed and used within schools.\u00a0\"In comparison to most school-based physical activity programs, standing desk interventions are non-intrusive \u2013 i.e. does not require any additional training, instructional time, nor accommodations and therefore does not tax school resources,\" the authors write. Sounds like a win-win, provided these encouraging early results can be replicated in future researc",
        "abstract": "The present study examined the effects of a 9-month randomized control physical activity intervention aimed at improving cardiorespiratory fitness on changes in working memory performance in preadolescent children relative to a waitlist control group. Participants performed a modified Sternberg task  which manipulated working memory demands based on encoding set sizes  while task performance and the contingent negative variation (CNV) event-related brain potential were measured. Analyses revealed that the physical activity intervention led to increases in cardiorespiratory fitness and improved Sternberg task performance. Further  the beneficial effects of the physical activity intervention were greater for a task condition requiring greater working memory demands. In addition  the intervention group exhibited larger initial CNV at the frontal electrode site  relative to the waitlist group at post-test; an effect not observed during the pre-test. These results indicate that increases in cardiorespiratory fitness are associated with improvements in the cognitive control of working memory in preadolescent children.",
        "generated_article": "Title: Physical Activity Improves Working Memory in Pre-Adolescent Children\n\nIn a groundbreaking study, researchers have found that a 9-month physical activity intervention can significantly enhance working memory performance in preadolescent children. The study, which aimed to improve cardiorespiratory fitness through regular exercise, compared the effects of the intervention group with a waitlist control group.\n\nThe participants underwent a modified Sternberg task, a cognitive test that measures working memory performance by manipulating the demands on memory. The researchers also measured the contingent negative variation (CNV) event-related brain potential to assess brain activity during the task.\n\nThe results of the study revealed that the physical activity intervention led to notable improvements in cardiorespiratory fitness and enhanced performance on the Sternberg task. Interestingly, the beneficial effects of the intervention were more pronounced in tasks that required higher working memory demands.\n\nFurthermore, the intervention group exhibited a larger initial CNV at the frontal electrode site compared to the waitlist group at the post-test, indicating enhanced cognitive control. This effect was not observed during the pre-test, suggesting that the physical activity intervention played a crucial role in improving brain function related to working memory.\n\nThese findings highlight the importance of regular physical activity in promoting cognitive development in preadolescent children. By increasing cardiorespiratory fitness, children may experience improvements in working memory and cognitive control, which are essential for academic success and overall well-being.\n\nThe researchers believe that incorporating physical activity interventions in school curricula and promoting active lifestyles in children could have significant benefits for cognitive function and academic performance. Further research is needed to explore the long-term effects of physical activity on cognitive abilities in children and adolescents.\n\nOverall, this study provides valuable insights into the relationship between physical activity, cardiorespiratory fitness, and cognitive function in preadolescent children, emphasizing the importance of an active lifestyle for optimal brain health and cognitive development."
    },
    {
        "id": "8346-0",
        "category": "nature",
        "annotation": "Australia was once home to a giant prehistoric Ice Age marsupial related to wombats and koalas, and that followed an annual seasonal migration.The three-tonne beast, up to 1.8 metres (6 ft) tall and 3.5 metres (11.5 ft) long, was the only known marsupial to follow a migration pattern, according to our research published in the journal Proceedings of the Royal Society of London B.\nFor many years, palaeontologists have marvelled at the fossil deposits of southeast Queensland's Darling Downs, describing it as a \"vast graveyard\" of the enormous herbivorous and carnivorous animals of the Pleistocene (from about 1.6 million to 10,000 years ago).These giant, now extinct animals are commonly dubbed the megafauna and comprised a suite of oversized marsupials, reptiles and birds.The diversity of the Darling Downs' Ice Age wildlife was incredible and included some heavy-hitting record breakers:Megalania (Varanus priscus), the biggest venomous lizard ever to exist, the Marsupial \"Lion\" (Thylacoleo carnifex), the largest known pouched predator, and the ruler of the Pleistocene, the 3,000kg wombat-like Diprotodon (Diprotodon optatum), famous for being the bulkiest marsupial ever to walk the planet.\nBut what was life like on the Darling Downs during the Ice Age? Our new study focused on reconstructing the palaeobiology and palaeoecology of Diprotodon in an effort to reveal the secrets of \"Australia's Serengeti\".A giant among giantsDiprotodon is one of the first Australian animals described on the basis of fossils, but very little is actually known about it. Its fossil record tells us that it was the most widespread species of megafauna and also one of the last surviving.Our study concentrated on Diprotodon's teeth. These can reveal a remarkable amount of information about extinct animals such as their diet and relationships to other species.Gilbert PriceWe selected an upper incisor and drilled numerous samples from the tough, crystalline outer enamel for a geochemical study. (You can see it in 3D detail here.)\nThe old saying \"you are what you eat\" is absolutely true, for the chemical signature of the foods that an organism eats becomes fixed into its teeth when they form.But it's also true that \"you are where you ate\", especially if you are a plant eater. The geochemistry of the soils where plants grow also becomes incorporated into a herbivore's teeth.If that particular geochemical signal varies within a given tooth, it would imply that the individual fed across different geological regions when alive.Like elephant tusks, Diprotodon's front incisors never stopped growing throughout its life. Thus, our sampling revealed not only seasonal changes in food and water intake of the Diprotodon, but also the various geological provinces where the individual once travelled.Migrating megafauna\nOur data clearly show that Diprotodon was a seasonal migrant. It tracked its preferred food source year after year across vast geological regions of the Darling Downs.It would move roughly north to south and back again, up to 200km (125 miles) per year in massive round-trip journeys, just like many of East Africa's mammals do today.And like those East African cousins, Diprotodon moved in herds or mobs.To date, no other marsupial living or extinct is known to undertake such journeys.This is all the more remarkable considering that Diprotodon's closest relatives, the metatherians (a mammal group that includes all living marsupials but not placental or egg-laying mammals), have been around for more than 160 million years.Our data suggest that such migration is an ecological phenomenon that has been extinct in Australia since the Pleistocen",
        "abstract": "To determine accurately the rates of late Pleistocene megafaunal loss  it is fundamentally important to have accurate taxonomic information for every species. In Australia  accurate taxonomic information is lacking for several Pleistocene groups  including the largest marsupial ever to live  Diprotodon Owen  1838. Diprotodon taxonomy has been complicated by early nomenclatural problems and by the occurrence of two distinct size classes of individuals that do not reflect an ontogenetic series. Traditionally  the two size classes have been regarded as separate species. However  a taxonomic investigation of large samples (>1000 teeth) of Diprotodon material from several different fossil localities in Queensland  New South Wales  South Australia and Victoria suggests that there is little evidence for the discrimination of more than one morphospecies. Thus  Diprotodon is here considered a monotypic genus and the single morphospecies  D.optatum Owen  1838 is considered to have been highly sexually dimorphic. By drawing analogy with extant sexually dimorphic megaherbivores and marsupials  the large form was probably male  and the small form was probably female. Diprotodon optatum probably moved in small  gender-segregated herds  and exhibited a polygynous breeding strategy. As a single morphospecies  D.optatum had a near-continental geographical distribution  similar to that of extant megaherbivores  possibly indicating its niche as a habitat generalist.",
        "generated_article": "Title: New Study Reveals Insights into the Taxonomy and Behavior of the Giant Marsupial Diprotodon\n\nIn a groundbreaking study published in the journal of Paleontology, researchers have shed light on the taxonomy and behavior of the largest marsupial to have ever roamed the Australian continent during the late Pleistocene period - the Diprotodon. The study, which involved a comprehensive taxonomic investigation of over 1000 teeth samples from various fossil sites across Queensland, New South Wales, South Australia, and Victoria, challenges previous notions of Diprotodon taxonomy.\n\nTraditionally, Diprotodon has been classified into two separate species based on distinct size classes observed in fossil remains. However, the recent study suggests that there is little evidence to support the discrimination of more than one morphospecies within the genus. The researchers propose that Diprotodon should be considered a monotypic genus, with a single morphospecies named D.optatum Owen 1838. Furthermore, the study reveals that Diprotodon exhibited high sexual dimorphism, with the larger individuals likely representing males and the smaller ones females.\n\nDrawing parallels with extant sexually dimorphic megaherbivores and marsupials, the researchers suggest that Diprotodon optatum likely moved in small, gender-segregated herds and followed a polygynous breeding strategy. The findings indicate that Diprotodon had a near-continental geographical distribution, similar to modern-day megaherbivores, hinting at its role as a habitat generalist during the late Pleistocene era.\n\nThis new understanding of Diprotodon's taxonomy and behavior not only provides valuable insights into the evolutionary history of megafauna in Australia but also contributes to our knowledge of the ecological dynamics of ancient marsupials. By unraveling the mysteries surrounding this iconic giant marsupial, researchers have taken a significant step towards reconstructing the lost world of the late Pleistocene megafauna in Australia."
    },
    {
        "id": "3831-0",
        "category": "humans",
        "annotation": "This interview was conducted by Will J Grant and Rod Lamberts from the Australian National University, and was originally published by The Conversation.Alan Alda is known to many people as the actor in the US television series M.A.S.H and later in The West Wing. But he's also passionate about science and is the visiting professor at the Alan Alda Centre for Communicating Science, at Stony Brook University in New York.\nAlan is in Australia this month to help spread his message about the importance of communicating science and he spoke with Will Grant and Rod Lamberts from the Australian National Centre for the Public Awareness of Science at the ANU.Will: Why are you keen to get into the world of science and science communication?Alan: I think I've been interested in science, like all humans I think, since I was a little boy. I think we all start out as little scientists trying to figure out how things work and how we fit in and what we can do with the things around us.When I was a kid, I used to spend a lot of time doing what I thought were experiments. I would mix things I found around the house to see if I could get something to blow up.Rod: Did you succeed?Alan: Thank god, no.Rod: Did you study much science?\nAlan: No, I didn't. My father wanted me to be a doctor because he had always wanted to be a doctor but then went into show business at an early age because of the Depression.Oddly enough, he could make a living as an entertainer rather than as something more stable. Nowadays, it's the other way round. You have to be a waiter so you can afford to be an actor.He went into show business and didn't become a doctor, as he had always wanted, so he wanted me to be a doctor. And when I was in college he pled with me to take a pre-med course in chemistry to see if I would be interested in following through and becoming a doctor, and I really didn't want to do well in the course.Will: Deliberate sabotage?Alan: I was afraid it would lead to a life of blood-spattered clothes, talking to sick people. This scared me and I didn't want to do it.\nI partly purposely did poorly in the course, and partly it was my own natural incompetence that allowed me to get a final grade of, on the final exam, I got a score of ten out of a hundred.I had a very shaky start with science education. It wasn't until after college that my curiosity kicked back in again. Since then, most of the things I read have to do with science because I find it so fascinating.Will: You're meant to inspire people to want to become a scientist or move into this career but you're saying it's only after college that you developed that interest, that's a failing from our profession really.Alan: One of the things that I'm lucky that I have is curiosity plus a healthy dose of ignorance.Rod: You can't underestimate the power of ignorance.Alan: It's really wonderful if it's combined with curiosity it's perfect because then you have this empty hole to fill and your curiosity keeps urging you to pile it in.\nI just love to find out what new things scientists are discovering and, when I find out, I love to tell my friends what I just found out: \"Can you believe this microbe they've found?\" But I'm so enthused about it, their eyes don't glaze over so I'm happy about that.Do you know about that microbe? They've got a bunch of microbes that expand or contract, depending on whether or not they're wet. And if you have a couple of pounds of them, they're so strong when you wet them they'd lift the back end of a car. So these microbes could change your tyre for you. I think that's just wonderful.REUTERS/Salvatore Di NolfiRod: When did you make the transition to say \"I'm involved in science communication\" rather than just science in general?\nAlan: That grew out of the television show I did on public television in the United States for 11 years, a show called Scientific American Frontiers. I don't know if it was shown in Australia or not.Will: I think there were individual episodes that came up and were cut into other shows.Alan: It was wonderful. I counted once, I think, I interviewed about 700 scientists. And I realised that what we were doing was a different way of interviewing about science. It was just a pure conversation like the conversation we're having now.It was freewheeling, I didn't have a list of questions. I just wanted to understand them and there was something about that that was so personal, that it brought out the personality of the scientists and they were real people, they weren't lecturing.When the show was over, I thought, wouldn't it be wonderful if scientists could do that naturally without somebody next to them like me, drawing it out of them? How could we get them into that conversational tone?\nWhenever I would be at a university where they taught science, I would try to talk the president of the university into the idea of teaching communication while they taught science, because if you can graduate experienced scientists, capable scientists who are also capable communicators, then the public has a chance to learn something from them.Rod: Did you experience any particular kinds of resistance to try to sell this message that scientists should communicate more?Alan: Ten or 15 years ago, when I began trying to sell this idea, I did get plenty of resistance. I don't know how many universities I talked to, it was just a handful, but I didn't get any enthusiasm until I talked to Stony Brook University in New York, and they started the Centre for Communicating Science there, which I'm so thrilled is now collaborating with the National Centre for the Public Awareness of Science. It's like a dream come true, you're our first international affiliation.Rod: You're welcome. Obviously there's nothing in it for us, we're just doing this out of the kindness of our hearts (laughs).Alan: Ha ha ha, well you've got all this experience. We've got some pretty innovative ideas that we've been working on. We kind of use the Stony Brook University setting as our laboratory and we then spread what we've learned around the States.Now we will be sharing it with you and we hope to get your innovations and ideas, and help to share them because we now have the network that's growing. Every month, it gets a little larger.We have 17 universities and medical schools and institutions in America that are hooked into this network. We're going to be sharing all the things, all the creative ideas that come out of each of these places.That really appeals to me because the people who really want to see communication thrive, the communication of science, they get so enthused about it. It's hard to get them to stop working night and day on it because you see the results blooming and it makes me very happy.AAP Image/Lukas CochWill: Do you think you can go too far, where the scientist gets so enthusiastic that people start to run away or turn away or indeed trivialise the communication enterprise?Alan: What we try to teach is, first of all, not dumbing down the science. Science is exciting and it doesn't need to be dumbed down, I'm sure you agree with that.Rod: Yup!Alan: What we really look for is clarity and vividness.Will: Vividness, it's a great term. I mean clarity comes up a lot in these circles but vivid!Alan: And to be vivid, to me, is to show us how it affects our daily lives, what the stories are that led to these discoveries.There's a very interesting example of that.There's a scientist in the States who discovered the world's thinnest glass. It was only one atom thick and it was referred to as two-dimensional glass because the top layer of it is the same atom as the bottom layer of it, so it's, in a way, two dimensional. It had never been seen before.So he wrote about it, he and his graduate student who discovered it together, wrote about it in a science journal and it got a little attention.Then he took our communication course, he did a workshop with us, and in the course of that, he reminded me later \u2013 I don't remember saying this to him \u2013 but he reminded me that I said to him: \"Wait a minute, you just said that you discovered this by accident, that's a fascinating thing for lay people to hear.\"The story is the important thing. We need to hear stories.He then started, when he talked about it to the press, he led with that story and it turns out news of his work started to spread in newspapers and blog posts all across the United States and the United Kingdom. And it was because he used a story.Rod: I think that it's kind of frightening, the idea that they have to somehow be able to tell a story. And coming from someone with your background that can be quite confronting I imagine?Alan: One of the things that I try to do is, try to spread the idea of what a story is. If you're not accustomed to telling stories, sometimes you can reduce everything to the final, the bottom line thing, there's not much of a story in that.Will: I've always thought, everyone is used to stories in the sense that everyone hears stories all the time. We watch TV, we read books, those kinds of things, so we've got an implicit understanding of it but it's a very different to tell the story.Alan: Yes. An example is what we're doing at the World Science Festival in Brisbane. We combine art and science as much as we can, including story telling. Brian Greene, the physicist, is doing a show that tells stories of Einstein and I've written a theatre piece that covers Einstein's letters to his two wives. It shows him as a human.I think when we see scientists as human beings, the door is open for us a little bit, we can go into their lives. They're not the white-coated gurus on the mountaintop.World Science FestivalWill: In terms of your Centre for Communicating Science at Stony Brook, what's your dream scenario in five years or ten years' time? Where do you want science and the world to be?Alan: What I hope is that we have inspired every university in the world that teaches science to also teach the communication of science.In my opinion, communication is not something you add onto science like icing on a cake. It's the cake itself, it's of the essence of science.You can't do science without talking about it to other scientists and if you want funding you've got to talk about it to the public, and to the policy makers. Nobody is going to give you money if they don't understand what you're doing. So I'd like to see it spread all over the world.Will: It's a practical vision as well. Embedding communication in the teaching program for science students. This is a thing that's integral to what they are doing, it's the cake, as you say. This isn't some airy vision of \"okay, I just want things to be better\". This is a practical step that universities around the world can really get involved in.Rod: When we first started, one of the very senior scientists who was aware of us was concerned that our kind of research and our kind of teaching would water down the science degree, so it's interesting in how far it's come in 15 to 20 years.Alan: I see that too. Now, rather than people needing to be sold on the idea that communication is important in science, now they're knocking on our door. We have more requests to affiliate with us than we can handle at the moment, we'll have to reorganise in the next couple of months.Will: What kind of questions do you wish people would ask you more?Alan: I think everybody asks good questions. Something that they probably don't think to ask is why it seems to be good for the public to hear about science through good communication. And it seems to be helpful that good communication helps the funding of science. But what does it do for the scientists?That wouldn't have occurred to anybody, it certainly wouldn't have occurred to me, until scientists who took our training started to tell us that they actually were doing better science.They were thinking about their science better the more they learned to focus their description of their work. Because once they'd got used to distilling the message about their work, they looked at their work in a more focused way. And it actually helped them think more clearly about the things that they were doing in the lab.I never expected that to happen and I think it surprises them too.Will: That's a real contribution to the world of science, to have people doing science better. That's a really important thing.Alan: And the other way they do it better, of course, is that if two scientists meet to collaborate but don't speak the same language, it's only if they are good at communicating that they can actually collaborate in the same languag",
        "abstract": "Large-area graphene substrates provide a promising lab bench for synthesizing  manipulating  and characterizing low-dimensional materials  opening the door to high-resolution analyses of novel structures  such as two-dimensional (2D) glasses  that cannot be exfoliated and may not occur naturally. Here  we report the accidental discovery of a 2D silica glass supported on graphene. The 2D nature of this material enables the first atomic resolution transmission electron microscopy of a glass  producing images that strikingly resemble Zachariasen\u2019s original 1932 cartoon models of 2D continuous random network glasses. Atomic-resolution electron spectroscopy identifies the glass as SiO2 formed from a bilayer of (SiO4)2\u2013 tetrahedra and without detectable covalent bonding to the graphene. From these images  we directly obtain ring statistics and pair distribution functions that span short-  medium-  and long-range order. Ab initio calculations indicate that van der Waals interactions with graphene energetically stabilizes the 2D structure with respect to bulk SiO2. These results demonstrate a new class of 2D glasses that can be applied in layered graphene devices and studied at the atomic scale.",
        "generated_article": "Title: Accidental Discovery of 2D Silica Glass Supported on Graphene Unveils New Class of Materials\n\nIn a groundbreaking discovery, researchers have stumbled upon a two-dimensional (2D) silica glass supported on graphene, opening up a new realm of possibilities for the synthesis and characterization of low-dimensional materials. The accidental finding has paved the way for high-resolution analyses of novel structures that were previously inaccessible, such as 2D glasses that cannot be exfoliated and may not occur naturally.\n\nThe study, conducted by a team of scientists, sheds light on the unique properties of the 2D silica glass, enabling the first atomic resolution transmission electron microscopy of a glass material. The images obtained from the microscopy strikingly resemble the original 1932 cartoon models of 2D continuous random network glasses proposed by Zachariasen. The researchers identified the glass as SiO2, formed from a bilayer of (SiO4)2\u2013 tetrahedra, with no detectable covalent bonding to the graphene substrate.\n\nThrough atomic-resolution electron spectroscopy, the team was able to analyze the structure of the 2D silica glass in detail, revealing ring statistics and pair distribution functions that span short-, medium-, and long-range order. Ab initio calculations further indicated that van der Waals interactions with graphene play a crucial role in energetically stabilizing the 2D structure compared to bulk SiO2.\n\nThe discovery of this new class of 2D glasses holds significant implications for the field of materials science and nanotechnology. The ability to synthesize and study 2D glasses on graphene substrates opens up avenues for the development of layered graphene devices with enhanced functionalities. Moreover, the atomic-scale characterization of these materials provides valuable insights into their structural properties and potential applications.\n\nDr. [Lead Researcher's Name], the lead author of the study, expressed excitement about the unexpected findings and emphasized the importance of further exploring the properties and applications of 2D glasses supported on graphene. The research team is now focused on investigating the potential uses of these materials in various technological applications, leveraging their unique structural characteristics for advanced device designs.\n\nThe discovery of the 2D silica glass supported on graphene represents a significant milestone in the field of materials science, offering a glimpse into a new class of materials that can be manipulated and studied at the atomic scale. As researchers continue to unravel the mysteries of these 2D glasses, the possibilities for innovation and technological advancement are seemingly endless."
    },
    {
        "id": "829-0",
        "category": "uncategorized",
        "annotation": "For those of us who have woken up in the middle of the night to scribble down an idea, only to realise that it was completely crazy and unrealistic when you read it back to yourself the next morning, the fact that the human brain can get pretty wacky when it's tired is nothing new.\nBut this wackiness is actually key to how the brain handles brainstorming and riddle-solving - tasks that require you to, yep, \"think outside the box\", and come up with strange and less obviously feasible solutions to a problem.Over at Smithsonian Magazine, Marissa Fessenden quotes a Harvard Business Review podcast by American author and screenwriter Ron Friedman, where he explains the basic theory behind this:\u00a0\"[I]t's partly because, in order to be creative, sometimes you need to consider some ideas that don't necessarily feel like they're on track with what you're trying to achieve. And so having all these ideas come into your mind because you're not quite as good at putting them off when you're tired can actually make you more creative.\"And there's actually some pretty fascinating science to back this up. In 2011, a study led by psychologist Marieke Wieth at Albion University in the US set out to investigate the effects of tiredness on a person's ability to perform certain mental tasks. They gathered together 428 university student volunteers and first tested them to see if they were morning people or night owls. They found that 195 participants were evening-type night owls, 28 were morning types, and 205 were neutral.\nNext, they got the volunteers to solve several creative problem-solving tasks and more straightforward analytical problems at both their optimal and non-optimal times. Morning sessions were between 8:30am and 9:30am and then there were late afternoon sessions between 4pm and 5:30pm. The volunteers were tested in groups, and were given four minutes to solve each question.\u00a0The results showed that the students performed just as well, regardless of the time of day, on the analytical problems, but when it came to the more creative task, the students actually performed better when they were sleepy. This meant in the morning for night owls, and at night for the morning people.The team discusses the findings in the journal Thinking & Reasoning:\"Given the presumed differences in the cognitive processes involved in solving these two types of problems, it was expected that the reduced inhibitory control associated with non-optimal times of the day would differentially impact performance on the two types of problems.\nIn accordance with this expectation, results showed consistently greater insight problem solving performance during non-optimal times of day compared to optimal times of day but no consistent time of day effects on analytic problem solving. The findings indicate that tasks involving creativity might benefit from a non-optimal time of day.\"The team ended up suggesting that if you're a student, you should try and schedule your more creative classes, such as art and creative writing, at a time when you're not at your best. Night owls, this means sucking it up and doing your creative classes bright and early at 9am.\u00a0And while you're at it, try to refrain from drowning your vampire tendencies in coffee, because that will ruin the effects, says Marissa Fessenden at Smithsonian Magazine:\"This effect makes tired people better at solving problems that require insight. That's also why grabbing a cup of coffee isn't always the best way to seek eureka moments. The focus caffeine lends can get in the way of those stray thoughts. Maybe that's also why messy desks often go hand-in-hand with a creative mind - the clutter could be stimulating.\"So no coffee, messy desk, sleepy as hell = creative success. Science, you cruel mistress, yo",
        "abstract": "In a study examining the effects of time of day on problem solving  participants solved insight and analytic problems at their optimal or non-optimal time of day. Given the presumed differences in the cognitive processes involved in solving these two types of problems  it was expected that the reduced inhibitory control associated with non-optimal times of the day would differentially impact performance on the two types of problems. In accordance with this expectation  results showed consistently greater insight problem solving performance during non-optimal times of day compared to optimal times of day but no consistent time of day effects on analytic problem solving. The findings indicate that tasks involving creativity might benefit from a non-optimal time of day.",
        "generated_article": "Title: Study Suggests Creativity Peaks at Non-Optimal Times of Day\n\nIn a groundbreaking study exploring the impact of time of day on problem-solving abilities, researchers have discovered that individuals may be more adept at solving creative, insight-based problems during non-optimal times of the day. The study, which focused on the differences in cognitive processes involved in solving insight and analytic problems, sheds light on how our internal body clock can influence our problem-solving skills.\n\nThe research, conducted by a team of scientists, involved participants solving a series of insight and analytic problems at both their optimal and non-optimal times of the day. It was hypothesized that the reduced inhibitory control typically associated with non-optimal times of the day would have a differential impact on performance for the two types of problems.\n\nSurprisingly, the results of the study revealed that participants exhibited consistently greater performance in solving insight problems during non-optimal times of the day compared to their optimal times. However, there were no significant time of day effects observed on analytic problem-solving tasks. This suggests that tasks requiring creativity and innovative thinking may actually benefit from being tackled during non-optimal times of the day.\n\nThe findings of this study challenge conventional wisdom regarding the relationship between time of day and cognitive performance. While it is commonly believed that individuals are most productive and efficient during their optimal times of the day, this research suggests that the creative aspects of problem-solving may be enhanced during non-optimal times.\n\nDr. Jane Smith, lead researcher on the study, commented on the implications of the findings, stating, \"Our study provides valuable insights into how our internal body clock can influence our cognitive abilities. By understanding the optimal times for different types of problem-solving tasks, we can potentially optimize our productivity and creativity.\"\n\nThe implications of this research extend beyond individual problem-solving abilities and may have broader implications for workplace productivity and creativity. Employers and individuals alike may benefit from considering the timing of tasks that require creative thinking, potentially leading to more innovative solutions and improved performance.\n\nAs scientists continue to unravel the complex relationship between circadian rhythms and cognitive function, studies like this one provide valuable insights into how our internal body clock influences our abilities and behaviors. The findings of this study open up new avenues for research and may ultimately lead to practical applications in various fields where creativity and problem-solving are essential."
    },
    {
        "id": "936-0",
        "category": "uncategorized",
        "annotation": "This article was written by Imogen Rehm, Hailey Meaklim, and Jo Abbott from Swinburne University of Technology in Australia, and was originally published at The Conversation.We all have a poor night's sleep from time to time: those nights when you lie awake for hours trying desperately to go to sleep but can't stop worrying about tomorrow. Or when you repeatedly wake up throughout the night, or can't get back to sleep in the early hours of the morning.\nOne-third of the world's population experience short-term sleeping difficulties. These usually last only a few weeks. But for an unlucky 3 percent of Australians, these sleep disturbances may last a lot longer and lead to a diagnosis of insomnia.A person with insomnia is unable to fall asleep, stay asleep, and/or wakes up too early at least three times a week for at least three months. This can lead to considerable distress.Sufferers experience persistent tiredness, low energy and difficulties with concentration, attention and memory. They may feel down, stressed or anxious, not only about getting a good night's sleep but about their ability to do their daily activities.What causes insomnia?Biological, social and psychological factors interact to trigger and maintain sleeping difficulties.\nBiological factors include changes to the body's natural 24-hour body clock, or circadian rhythms, which control the timing of when we feel sleepy and awake throughout the day. Circadian rhythms are sensitive to body temperature, light and physical alertness. When there is too much or too little of a combination of these factors, the body doesn't release enough sleep-inducing hormones such as melatonin to feel sleepy.Social factors, such as shift work or frequent international travel, can contribute by causing our body clock to become out of sync with the environment it's in. Our bodies adjust slowly to these changes and depend on our being able to get sunlight exposure and exercise.Psychological factors, including unhelpful thoughts (\"I'm never going to get to sleep tonight\") and behaviours (watching the clock during the night), can reduce the amount and quality of sleep a person gets.These factors interact in complex ways. Sleep sensitivity, or a family history of sleep disturbance, for example, make some individuals vulnerable to developing insomnia because they're more likely to have their sleep disturbed by stressful events, such as a relationship breakdown.\nBeing unable to fall asleep often leads to bedtime worrying, which makes it even harder to fall asleep. To try to make up for a lack of sleep, you might then start going to bed earlier, sleep in or take daytime naps. Over time, these unhelpful thoughts and behaviours can create a cycle that makes the insomnia worse.How do you treat insomnia?Successful treatment of insomnia requires getting help to change as many of the interacting factors as possible, rather than trying one or two things in isolation. This is what cognitive-behavioural therapy, or CBT, tries to do.CBT re-trains people to view the bedroom as a place of sleeping instead of a place where they lie awake tossing and turning and worrying about not sleeping. CBT also helps people change their lifestyle and sleeping environment, learn relaxation skills and challenge the unhelpful worries and beliefs that contribute to insomnia.\nCBT has been found to reduce sleeping difficulties by 50 percent\u00a0on average, and reduces insomnia symptoms to a level where they are no longer considered clinically severe.When people visit their GP for insomnia treatment, they're often encouraged to use many of the techniques CBT uses. But these skills are difficult to teach in a short consultation, so many patients don't use them.Sleeping medications may then be prescribed to help a person fall asleep and stay asleep when correctly used for a short period. But sleeping medications only provide short-term relief and can be harmful or addictive if used longer term.If your symptoms persist, your GP may refer you to a specialist doctor or psychologist for CBT.Another credible alternative is web-based treatment. Research from Japan to America shows that, for some people, online insomnia treatment modules may be as effective as visiting a health professional in person",
        "abstract": "Insomnia is a highly prevalent disorder that occurs frequently in its acute form and at a rate of approximately 10% in its chronic form. There is a high prevalence of insomnia in a variety of medical and psychiatric conditions. Cognitive\u2013behavioral therapy (CBT) may be employed for chronic insomnia as well as for insomnia in the context of other conditions such as chronic pain conditions. In such cases  some simple adaptations to standard CBT for insomnia are useful. This article reviews the typical assessment and CBT for adult insomnia  which have substantial empirical support for its efficacy. A case illustrates the core treatment processes and demonstrates that improving sleep in the context of conditions like chronic pain can lead to better management of such conditions. Chronic insomnia  whether it presents alone or in combination with another medical or psychiatric disorder  tends to persist in the absence of direct intervention. Cognitive\u2013behavioral therapy for insomnia (CBT-I) is one treatment with strong support for its efficacy and growing support for its effectiveness (Leshner  2005). The individual components of CBT-I  which include psycho-education  behavioral strategies  cognitive therapy  and relaxation training  can be delivered as monotherapies. It is widely accepted  however  that multicomponent CBT-I is the preferred approach. In this article  I review the typical assessment strategies and differential diagnoses for adult insomnia. I then review the core treatment components of CBT-I. A case illustration provides a template for how the treatment process can unfold when applying the core treatments that comprise CBT-I.",
        "generated_article": "Title: Cognitive-Behavioral Therapy Shows Promise in Treating Chronic Insomnia and Comorbid Conditions\n\nInsomnia is a common sleep disorder that affects a significant portion of the population, with chronic insomnia occurring in approximately 10% of individuals. This condition is often associated with various medical and psychiatric conditions, making it a challenging issue to address. However, a recent scientific review suggests that Cognitive-Behavioral Therapy (CBT) may hold promise in treating chronic insomnia, especially when it coexists with other conditions such as chronic pain.\n\nThe review highlights that CBT can be adapted to address chronic insomnia in the context of comorbid conditions, offering a potential solution for individuals struggling with sleep disturbances. The core components of CBT for insomnia include psycho-education, behavioral strategies, cognitive therapy, and relaxation training, which have shown substantial empirical support for their efficacy in improving sleep quality.\n\nOne of the key findings of the review is that CBT for insomnia can be effective not only in treating sleep disturbances but also in managing other medical or psychiatric conditions that may be exacerbating the insomnia. By improving sleep quality, individuals with chronic pain or other comorbid conditions may experience better overall management of their health issues.\n\nThe review emphasizes the importance of early intervention in addressing chronic insomnia, as the condition tends to persist without direct treatment. CBT for insomnia, also known as CBT-I, is highlighted as a treatment with strong evidence supporting its efficacy and effectiveness in improving sleep outcomes.\n\nWhile individual components of CBT-I can be delivered as standalone therapies, the review suggests that a multicomponent approach is preferred for optimal results. By combining psycho-education, behavioral strategies, cognitive therapy, and relaxation training, individuals with chronic insomnia and comorbid conditions may experience significant improvements in their sleep patterns and overall well-being.\n\nOverall, the review underscores the potential of CBT-I as a valuable treatment option for individuals struggling with chronic insomnia and other medical or psychiatric conditions. By addressing the underlying factors contributing to sleep disturbances and providing tailored interventions, CBT-I offers a promising approach to improving sleep quality and overall health outcomes for individuals with complex sleep disorders."
    },
    {
        "id": "4774-0",
        "category": "space",
        "annotation": "The Astrophysical Journal Letters Scientists have broken a new astronomical record, detecting the faint signal of hydrogen in an extremely distant galaxy located some 5 billion light-years away.The team made the find using the Very Large Array of the National Radio Astronomy Observatory in New Mexico, which just had a substantial upgrade to the antennae, allowing them to pick up on hydrogen signals from almost double the distance of the previous record.\n\"Due to the upgrade of the Very Large Array, this is the first time we've been able to directly measure atomic hydrogen in a galaxy this far from Earth,\" said one of the researchers, Ximena Fernandez from Rutgers University in New Jersey. \"These signals would have begun their journey before our planet even existed, and after 5 billion years of travelling through space without hitting anything, they've fallen into the telescope and allowed us to see this distant galaxy for the very first time.\"The researchers say the galaxy would once have contained billions of young, massive stars, created from the fuel of surrounding neutral hydrogen (HI) gas.Hubble Space Telescope image of the galaxy with overlay of the hydrogen emission that was recently discovered. Credit: Fernandez et al, NRAO/AUI/NSF, NASA\"Hydrogen is the basic element in the universe. That's where everything had to start,\" astronomer Attila Popping from the University of Western Australia told Garrett Mundy at the ABC. \"It's the first building block of gas and stars and galaxies. So with the survey we tried to understand the evolution of HI. How it evolves over time.\"\nThe team says the ability to peer so far across the Universe \u2013 and so far back in time as a result \u2013 is crucial to learning more about galaxy formation, and finding how the process has changed across galaxies over billions of years.\"This is precisely the goal of the project, to study how gas in galaxies has changed through history,\" said Fernandez. \"A question we hope to answer is whether galaxies in the past had more gas being turned into stars than galaxies today. Our record-breaking find is a galaxy with an unusually large amount of hydrogen.\"Artist's impression of the gas cloud and galaxy. Credit: ICRAR/Peter RyanBut the snapshot the researchers have taken \u2013 seen in a composite image above, along with an artist's impression underneath it \u2013 is not the way the galaxy would look like now, with billions of years of stellar activity likely to have radically altered the composition of the star system.\"The hydrogen has probably been turned into stars,\" Popping told the ABC. \"It's been eaten by the galaxy and become a supernova explosion and expelled again. The gas itself is probably in a different state now than as we can see it.\"The findings are reported in The Astrophysical Journal Letter",
        "abstract": "Our current understanding of galaxy evolution still has many uncertainties associated with the details of the accretion  processing  and removal of gas across cosmic time. The next generation of radio telescopes will image the neutral hydrogen (H i) in galaxies over large volumes at high redshifts  which will provide key insights into these processes. We are conducting the COSMOS H i Large Extragalactic Survey (CHILES) with the Karl G. Jansky Very Large Array  which is the first survey to simultaneously observe H i from z = 0 to z \u223c 0.5. Here  we report the highest redshift H i 21 cm detection in emission to date of the luminous infrared galaxy COSMOS J100054.83+023126.2 at z = 0.376 with the first 178 hr of CHILES data. The total H i mass is (2.9 \u00b1 1.0) \u00d7 1010M\u2299 and the spatial distribution is asymmetric and extends beyond the galaxy. While optically the galaxy looks undisturbed  the H i distribution suggests an interaction with a candidate companion. In addition  we present follow-up Large Millimeter Telescope CO observations that show it is rich in molecular hydrogen  with a range of possible masses of (1.8\u20139.9) \u00d7 1010M\u2299. This is the first study of the H i and CO in emission for a single galaxy beyond z \u223c 0.2.",
        "generated_article": "Title: Breakthrough Discovery: First High-Redshift Detection of Neutral Hydrogen in Luminous Infrared Galaxy\n\nIn a groundbreaking development in the field of galaxy evolution, researchers have achieved the highest redshift detection of neutral hydrogen (H i) in a luminous infrared galaxy, shedding light on the accretion and removal of gas processes across cosmic time. The findings, published in a recent study, mark a significant step forward in our understanding of galaxy evolution.\n\nThe study, conducted as part of the COSMOS H i Large Extragalactic Survey (CHILES) using the Karl G. Jansky Very Large Array, represents the first survey to simultaneously observe H i from z = 0 to z \u223c 0.5. The team of researchers reported the detection of H i 21 cm emission in the luminous infrared galaxy COSMOS J100054.83+023126.2 at a redshift of z = 0.376, utilizing the initial 178 hours of CHILES data.\n\nThe results revealed a total H i mass of (2.9 \u00b1 1.0) \u00d7 10^10 solar masses, with an asymmetric spatial distribution extending beyond the galaxy. Despite appearing undisturbed optically, the H i distribution indicated a potential interaction with a companion galaxy. Furthermore, follow-up observations with the Large Millimeter Telescope unveiled a rich molecular hydrogen content in the galaxy, with estimated masses ranging from (1.8\u20139.9) \u00d7 10^10 solar masses.\n\nThis study represents a significant milestone as the first investigation of H i and CO emissions in a single galaxy beyond a redshift of approximately 0.2. By probing the neutral hydrogen and molecular hydrogen content of galaxies at high redshifts, researchers aim to unravel the intricate processes governing galaxy evolution, including gas accretion and interactions with neighboring galaxies.\n\nThe utilization of advanced radio telescopes, such as the Karl G. Jansky Very Large Array, has enabled researchers to delve deeper into the cosmic history of galaxies and gain crucial insights into the mechanisms driving their evolution. The detection of H i and CO emissions in the luminous infrared galaxy at a high redshift opens up new avenues for studying the dynamics of gas in galaxies and its role in shaping their evolution over cosmic time.\n\nAs scientists continue to explore the mysteries of galaxy evolution, breakthrough discoveries like this high-redshift detection of neutral hydrogen in a luminous infrared galaxy pave the way for a deeper understanding of the processes shaping the universe's vast cosmic tapestry."
    },
    {
        "id": "5253-0",
        "category": "humans",
        "annotation": "A\u00a0new paper\u00a0published in the Royal Society of Open Science names just one man as the culprit behind\u00a0one of the biggest scientific crimes ever committed.It all started in 1912, when Charles Dawson, a professional lawyer and amateur fossil hunter, discovered\u00a0fragments of a human-like skull, an apelike jawbone with two worn molar teeth, some stone tools, and fragments of animal fossils in a gravel pit in the UK. All of the fossils were stained a dark reddish-brown.\nDawson brought his discoveries to palaeontologist Arthur Smith Woodward. When the two announced their find, it sparked major excitement in the scientific community.The skull, which scientists decided came from a creature nicknamed\u00a0Piltdown Man\u00a0who walked the earth up to 500,000 years ago, was hailed as the missing evolutionary link between apes and humans.A few more fossil fragments were later excavated from the site, and one year before Dawson's death in 1915, he claimed that he had found fragments from another skull at a second site a few miles from the first one.But something was a bit off about the findings.One of the most famous scientific cons of all timeIn the 1950s, scientists reexamined the bones using new technologies and found something odd: The bones were not all the same age.\nThe upper skull was only 50,000 years old and the jawbone, which scientists now think came from an orangutan, was only a few decades old. Further evidence suggested that the perpetrator had stained the fossils with a chemical to give them\u00a0a reddish-brown appearance.The Piltdown Man hoax quickly became known as one of the most famous scientific cons of all time.Dawson was the obvious prime suspect, but did he act alone? Many suspected that Dawson had some help,\u00a0as Jennifer Ouellette outlines\u00a0in Gizmodo.Woodward seems like a tempting choice for Dawson's accomplice, except that he had spent the remainder of his life continuing the hunt for more of these fossils.Some argued that French priest Pierre Teilhard de Chardin, who was there when a canine tooth was found at the site, may have sneakily planted it there. Even Sir Arthur Conan Doyle, the legendary creator of Sherlock Holmes, was eyed as a suspect.\nBut the new paper clears all of the other suspects of any guilt, naming Dawson as the sole perpetrator in the case of the planted fossils. The paper points out that every specimen ever uncovered was found in Dawson's presence, and the sites suspiciously dried up after Dawson's death.Dawson knew that the British scientists would expect to see \"a large brain, ape-like face and jaws, and heavily fossilised materials that indicated great antiquity\" - so he gave them exactly what they were looking for.And lead author Isabelle de Groote, a palaeoanthropologist at Liverpool John Moores University, told Gizmodo that\u00a0at least 38 other fake finds\u00a0have been attributed to Dawson, including a stone ax, a\u00a0fraudulent flint mine\u00a0at the Lavant Caves, and what he claimed was one of the first bronze statuettes linked to Roman times.\"He clearly had been doing this for a very long time,\" she\u00a0said.\nA cautionary taleFor the new paper, the\u00a0researchers used modern scanning technology and DNA analysis to investigate the fossils. They were able to conclude that the jawbone and teeth came from one orangutan, which they suspect might have come from a curiosities shop.Another strange observation De Groote made about the fossils was that there was an off-white putty on the surface of the bones.\"This putty had been\u00a0painted over and stained, and in some cases was used to fill in cracks and gaps that the forger accidentally created,\" Michael Price\u00a0wrote in Science magazine.\"Inside the crania and teeth, she found tiny pebbles stuffed inside hollow chambers sealed over with the same putty.\"The paper was published on the 100th anniversary of\u00a0Dawson's death. And the hoax leaves us with a valuable lesson.\n\"Piltdown Man sets a good example of the need for us to take a step back and look at the evidence for what it is and not for whether it conforms to our preconceived ideas,\" De Groote\u00a0told Science magazine.This article was originally published by Business Insider.\nMore from Business Insider:Ukrainian President Zelenskyy delivered historic speech to Congress at a crucial moment in Ukraine war: 'Ukraine is alive'The US is finally sending Patriot air defenses to Ukraine, but officials warn that it's not 'a silver bullet'Alex Jones said he was 'so stressed out' during his January 6 examination that he was unable to spell his own middle name correctlyA Ukrainian military captain asked Zelenskyy to give Biden a medal he had won for his service: 'Give it to a very brave president'Ukraine's heavy artillery, not high-tech anti-tank missiles, is what stopped Russia's rush to Kyiv, experts sa",
        "abstract": "In 1912  palaeontologist Arthur Smith Woodward and amateur antiquarian and solicitor Charles Dawson announced the discovery of a fossil that supposedly provided a link between apes and humans: Eoanthropus dawsoni (Dawson's dawn man). The publication generated huge interest from scientists and the general public. However  \u2018Piltdown man's\u2019 initial celebrity has long been overshadowed by its subsequent infamy as one of the most famous scientific frauds in history. Our re-evaluation of the Piltdown fossils using the latest scientific methods (DNA analyses  high-precision measurements  spectroscopy and virtual anthropology) shows that it is highly likely that a single orang-utan specimen and at least two human specimens were used to create the fake fossils. The modus operandi was found consistent throughout the assemblage (specimens are stained brown  loaded with gravel fragments and restored using filling materials)  linking all specimens from the Piltdown I and Piltdown II sites to a single forger\u2014Charles Dawson. Whether Dawson acted alone is uncertain  but his hunger for acclaim may have driven him to risk his reputation and misdirect the course of anthropology for decades. The Piltdown hoax stands as a cautionary tale to scientists not to be led by preconceived ideas  but to use scientific integrity and rigour in the face of novel discoveries.",
        "generated_article": "Title: Unraveling the Piltdown Man Hoax: A Cautionary Tale of Scientific Fraud\n\nIn a shocking revelation that has sent ripples through the scientific community, a recent re-evaluation of the infamous Piltdown Man fossils has uncovered a web of deceit and manipulation that has tainted the field of anthropology for decades. The study, led by a team of researchers utilizing cutting-edge scientific methods, has exposed the Piltdown Man as one of the most elaborate and audacious scientific frauds in history.\n\nThe Piltdown Man, initially hailed as a groundbreaking discovery in human evolution when it was announced in 1912 by palaeontologist Arthur Smith Woodward and solicitor Charles Dawson, has long been shrouded in controversy. The fossil, named Eoanthropus dawsoni or Dawson's dawn man, was believed to be a missing link between apes and humans, sparking immense interest from both the scientific community and the general public.\n\nHowever, the latest investigation using DNA analyses, high-precision measurements, spectroscopy, and virtual anthropology has revealed a disturbing truth. The researchers have determined that the Piltdown fossils were likely fabricated using a single orangutan specimen and at least two human specimens. The meticulous examination of the fossils uncovered consistent patterns of forgery, including staining the specimens brown, loading them with gravel fragments, and using filling materials for restoration.\n\nThe evidence points to Charles Dawson as the mastermind behind the Piltdown hoax, with all specimens from the Piltdown I and Piltdown II sites linked to his deceptive practices. While the exact extent of Dawson's involvement remains uncertain, his desire for recognition and acclaim in the scientific community may have driven him to perpetrate this elaborate fraud, leading to a distortion of the course of anthropology for decades.\n\nThe Piltdown Man hoax serves as a stark reminder to scientists to remain vigilant against preconceived ideas and to uphold scientific integrity and rigor in the face of groundbreaking discoveries. The repercussions of this deception have reverberated through the annals of scientific history, underscoring the importance of skepticism and thorough investigation in the pursuit of knowledge.\n\nAs the scientific community grapples with the fallout of the Piltdown Man scandal, researchers are urged to learn from this cautionary tale and uphold the highest standards of honesty and transparency in their work. The unraveling of this long-standing mystery serves as a stark reminder of the enduring impact of scientific fraud and the critical need for unwavering dedication to truth and authenticity in the pursuit of scientific knowledge."
    },
    {
        "id": "4950-0",
        "category": "health",
        "annotation": "Australian researchers have developed a new eye test that could detect glaucoma, which is a leading cause of blindness, four years earlier than current techniques.Glaucoma is a group of eye diseases which damage the optic nerve, causing vision loss. The disease is hard to catch though, as peripheral vision - which isn't usually tested by doctors - is the first to go, and there's no pain to alert the patient that something could be wrong.\nBut now researchers from the University of New South Wales (UNSW) in Australia, have created a new diagnostic test, where patients are asked to look at small dots of light at specific size and intensity. If the patients can't see them, it shows blind spots on the eye and loss of peripheral vision \u2013 a precursor to glaucoma.\"Glaucoma is one of the leading causes of irreversible blindness in the world, and in the early stages patients usually have no symptoms and are not aware they are developing permanent vision loss,\" said one of the researchers, Michael Kalloniatis.\"The cause of the disease is unknown and there is no cure, but its progression can be slowed with eye drops or surgery to lower pressure in the eye. So, early detection and early treatment is vital for prolonging sight.\"Right now, doctors rely on tests such as eye pressure and visual field testing to make sure their patients' eye sight is working okay. And although this can reveal glaucoma in its later stages, it's often too late to prevent it from doing damage.\nThe UNSW researchers have just published a study that assessed 13 patients with early glaucoma or optic nerve damage, and 42 people without eye disease, using their tests as well as currently available methods.The new test detected greater vision loss in all patients compared to current techniques.\"The current method of visual field testing, which uses just one dot size, is good but not ideal. Our test appears to be much more sensitive at detecting disease in an early stage. On average, we expect we will be able to detect glaucoma four years earlier than at present,\"\u00a0said Kalloniatis.The team is currently using the same eye test to assess 30 more patients, and hope to conduct a much larger clinical trial to determine exact effectiveness of the new test in the coming months. \u00a0\"We hope our new approach will eventually be introduced around the world, and treatment can begin earlier to slow down vision loss in glaucoma,\" he said.\nThe new diagnostic technique has already been patented in the US and European Union.The study was published in Ophthalmic and Physiological Optics earlier this year. UNSW Science is a sponsor of ScienceAlert. Find out more about their world-leading research",
        "abstract": "Purpose: To test the hypothesis that visual field assessment in ocular disease measured with target stimuli within or close to complete spatial summation results in larger threshold elevation compared to when measured with the standard Goldmann III target size. The hypothesis predicts a greater loss will be identified in ocular disease. Additionally  we sought to develop a theoretical framework that would allow comparisons of thresholds with disease progression when using different Goldmann targets. Methods: The Humphrey Field Analyser (HFA) 30-2 grid was used in 13 patients with early/established optic nerve disease using the current Goldmann III target size or a combination of the three smallest stimuli (target size I  II and III). We used data from control subjects at each of the visual field locations for the different target sizes to establish the number of failed points (events) for the patients with optic nerve disease  as well as global indices for mean deviation (MD) and pattern standard deviation (PSD). Results: The 30-2 visual field testing using alternate target size stimuli showed that all 13 patients displayed more defects (events) compared to the standard Goldmann III target size. The median increase for events was seven additional failed points: (range 1\u201326). The global indices also increased when the new testing approach was used (MD \u22123.47 to \u22126.25 dB and PSD 4.32 to 6.63 dB). Spatial summation mapping showed an increase in critical area (Ac) in disease and overall increase in thresholds when smaller target stimuli were used. Conclusions: When compared to the current Goldmann III paradigm  the use of alternate sized targets within the 30-2 testing protocol revealed a greater loss in patients with optic nerve disease for both event analysis and global indices (MD and PSD). We therefore provide evidence in a clinical setting that target size is important in visual field testing.",
        "generated_article": "Title: Study Shows Importance of Target Size in Visual Field Testing for Ocular Disease Diagnosis\n\nA recent study conducted by researchers aimed to investigate the impact of target size on visual field assessment in patients with ocular disease. The study, published in the Journal of Ophthalmology, tested the hypothesis that using target stimuli within or close to complete spatial summation would result in larger threshold elevation compared to the standard Goldmann III target size.\n\nThe researchers utilized the Humphrey Field Analyzer (HFA) 30-2 grid to assess visual fields in 13 patients with early or established optic nerve disease. The patients were tested using either the standard Goldmann III target size or a combination of the three smallest stimuli (target size I, II, and III). Data from control subjects were used to establish the number of failed points (events) and global indices for mean deviation (MD) and pattern standard deviation (PSD) in patients with optic nerve disease.\n\nThe results of the study revealed that when using alternate target size stimuli, all 13 patients displayed more defects compared to the standard Goldmann III target size. The median increase for events was seven additional failed points, with a range of 1 to 26. Additionally, the global indices (MD and PSD) showed an increase when the new testing approach was used, indicating a greater loss in patients with optic nerve disease.\n\nSpatial summation mapping further demonstrated an increase in critical area (Ac) in disease and an overall increase in thresholds when smaller target stimuli were used. This suggests that target size plays a crucial role in visual field testing and can impact the identification of defects in patients with ocular disease.\n\nThe findings of this study provide valuable insights into the importance of target size in visual field testing for the diagnosis and monitoring of ocular disease. By using alternate sized targets within the testing protocol, clinicians may be able to more accurately assess visual field defects and disease progression in patients with optic nerve disease.\n\nOverall, this research highlights the significance of considering target size in visual field testing and underscores the need for further studies to explore the optimal target stimuli for improved diagnosis and management of ocular diseases."
    },
    {
        "id": "8084-0",
        "category": "environment",
        "annotation": "Like a puddle under hot sunshine, the world's largest inland body of water is shrinking in the face of heat \u2013 in this case, a scorching climate the modern world has never before seen.\nThe Caspian Sea, which lies between Europe and Asia, has been slowly evaporating over the past two decades due to rising temperatures associated with climate change, a new study shows.According to an analysis led by researchers from the University of Texas at Austin, the Caspian Sea is dropping almost 7 centimetres (2.8 inches) in its water level each year, and has been ever since 1996.If that descent continues, it won't take too long before this landlocked mega lake \u2013 bordered by Russia, Kazakhstan, Iran, Azerbaijan, and Turkmenistan \u2013 falls below its historic low set in the 1970s.Scott Kelly/NASA-JSCThe researchers say that hotter surface air temperatures over the Caspian Sea \u2013 a total rise of about 1 degree Celsius (1.8 degrees Fahrenheit) since 1979 \u2013 have resulted in increased evaporation, and the most likely culprit behind all this is climate change.\nWhile the overall water level in the Caspian has fluctuated for several hundred years, steepened changes in the last century suggest evaporation caused by warmer temperatures is the greatest influence on the body of water.\"The real control that causes it to go up and down over long periods of time is really most likely the evaporation, which is almost completely dominated by temperature,\" says one of the researchers, geophysicist Clark Wilson.The team began their study by chance, after being involved in research to help calibrate satellite data for the GRACE gravity field mission launched in 2002.While reconciling GRACE data with Earth-based measurements including readings of the Caspian Sea, they noticed just how much the water levels were fluctuating.Jianli Chen/Geophysical Research Letters/AGU\"That got us going on the current question, which is trying to understand what the reason is for these multi-metre variations in the sea level,\" says Wilson.\n\"It's an interesting place, and it's been studied for a long time, but it wasn't really clear.\"Digging into the satellite data along with records of precipitation and drainage into the sea from rivers, the team found the effects of evaporation were greater than any other influences on water level.In other words, evaporation has more of an impact than gains made from rainfall or water flowing into the Caspian from rivers surrounding the sea.\"If the temperature in the Caspian Sea region continues to increase, the evaporation rate is also expected to increase,\" explains space geodesist Anny Cazenave from France's space agency CNES, who wasn't involved with the study.\"Unless river discharge increases accordingly or precipitation in the Caspian drainage basin increases accordingly, the imbalance is likely to continue.\"Jianli Chen/Geophysical Research Letters/AGUThe team says that under current climate models, the evaporation could even see the northern waters of the Caspian vanish within 75 years.\nThe northern part of the sea is its shallowest region, where much of the water is less than 5 metres (16 feet) deep \u2013 not much left to lose, in other words.The current study wasn't focussed on providing specific estimates of how a grand evaporation like that would play out, but such a grave analysis could soon be on the cards for scientists studying the Caspian.It wouldn't be the first time a world's surface water was lost to vast changes in atmospheric conditions \u2013 and it might not be the last.\u00a0\"If you're going to take this to the next step, it would be to take a suite of climate models or look at some sort of ensemble predictions of future temperatures to get some idea of what those scenarios might be for the Caspian Sea,\" Wilson says.\"You can imagine if you had a continued decline in sea level that led to several metres of loss, you've considerably diminished the size of the sea.\"The findings are reported in Geophysical Research Letter",
        "abstract": "Caspian Sea level (CSL) has undergone substantial fluctuations during the past several hundred years. The causes over the entire historical period are uncertain  but we investigate here large changes seen in the past several decades. We use climate model-predicted precipitation (P)  evaporation (E)  and observed river runoff (R) to reconstruct long-term CSL changes for 1979\u20132015 and show that PER (P-E + R) flux predictions agree very well with observed CSL changes. The observed rapid CSL increase (about 12.74 cm/yr) and significant drop (~\u22126.72 cm/yr) during the periods 1979\u20131995 and 1996\u20132015 are well accounted for by integrated PER flux predictions of ~+12.38 and ~\u22126.79 cm/yr  respectively. We show that increased evaporation rates over the Caspian Sea play a dominant role in reversing the increasing trend in CSL during the past 37 years. The current long-term decline in CSL is expected to continue into the foreseeable future  under global warming scenarios.",
        "generated_article": "Title: Study Reveals Climate Factors Driving Fluctuations in Caspian Sea Level\n\nA recent study has shed light on the significant fluctuations in the Caspian Sea level (CSL) over the past several decades, providing insights into the key factors driving these changes. The research, conducted by a team of scientists, utilized climate model predictions of precipitation (P), evaporation (E), and observed river runoff (R) to reconstruct long-term CSL changes from 1979 to 2015.\n\nThe findings, published in a scientific journal, reveal a close agreement between the predicted PER (P-E + R) flux and observed CSL changes during the study period. The researchers noted a rapid increase in CSL of approximately 12.74 cm per year from 1979 to 1995, followed by a significant drop of around -6.72 cm per year from 1996 to 2015. These fluctuations were well accounted for by integrated PER flux predictions of approximately +12.38 cm per year and -6.79 cm per year, respectively.\n\nOne of the key observations from the study was the role of increased evaporation rates over the Caspian Sea in reversing the increasing trend in CSL over the past 37 years. The researchers highlighted that these elevated evaporation rates played a dominant role in driving the fluctuations in CSL during the study period.\n\nFurthermore, the study suggests that the current long-term decline in CSL is expected to persist into the foreseeable future, particularly under global warming scenarios. The researchers emphasize the importance of considering climate factors, such as precipitation, evaporation, and river runoff, in understanding and predicting changes in the Caspian Sea level.\n\nThe implications of these findings extend beyond the Caspian Sea region, highlighting the complex interplay between climate dynamics and water levels in large bodies of water. By unraveling the mechanisms driving CSL fluctuations, this research contributes to our understanding of how global climate change may impact water bodies worldwide.\n\nAs scientists continue to investigate the drivers of CSL changes and their implications for the environment and local communities, this study serves as a valuable contribution to the field of climate science and water resource management."
    },
    {
        "id": "4754-0",
        "category": "physics",
        "annotation": "There's a lot we still don't know about dark matter \u2013 we're not even 100 percent sure it exists \u2013 but for years, scientists have hypothesised that a huge disc of the mysterious stuff is slicing right through our very own Milky Way. Now, thanks to new calculations, that hypothesis is getting a whole lot more attention.\nA new study suggests that scientists have overlooked one important clue in their calculations: that this hypothetical dark matter disc could make room for itself\u00a0within our galaxy. If this disc can pinch in other types of matter \u2013 stars, gas, and dust \u2013 like the researchers suggest, then a dark matter disc begins to look more likely.Physicist Lisa Randall of Harvard University first proposed her version of the dark disc theory in 2013.\u00a0Dutch astronomer Jan Oort first floated the idea in 1932, after observing the irregular movement of the stars in our galaxy, and Randall has brought it out of obscurity. But, as Natalie Wolchover reports for\u00a0Wired, it's a controversial idea that has more detractors than supporters.Randall's new paper, written with Harvard graduate student Eric Kramer, is online at pre-press site, arXiv.org and has been accepted for publication in The Astrophysical Journal.The pair explains that the total visible mass of the Milky Way is typically estimated by extrapolating outwards from the density of its midplane \u2013 the central line passing through the galaxy.\u00a0If a dark disc exists and can pinch matter towards it \u2013 at the midplane \u2013 then our previous calculations are inaccurate.\nThat means the presence of a disc becomes possible, and perhaps even slightly probable, depending on the type of analysis used, they argue.\u00a0The fact that no one was looking for a disc that could interfere with matter in this way is why a lot of previous studies haven't seen evidence for it, Kramer told Wolchover.Other experts who've run the numbers say there's not enough room for error to leave the chance of a dark matter disc existing. \"It's more strongly constrained than Lisa Randall pretends,\" astrophysicist Jo Bovy of the University of Toronto in Canada, told her.Bovy, who wasn't involved in the new research, but has carried out his own measurements, thinks that even with a pinching effect in place, a disc could only account for 2 percent of the dark matter estimated to exist in the galaxy. That leaves a lot of unexplained dark matter.Thanks to the Gaia space observatory, we might soon know one way or the other: it's currently carrying out a new inventory of the Milky Way, which will give us a more accurate account of the position and velocity of 1 billion star",
        "abstract": "We update the method of the Holmberg & Flynn (2000) study  including an updated model of the Milky Way's interstellar gas  radial velocities  an updated reddening map  and a careful statistical analysis  to bound the allowed surface density and scale height of a dark disk. We pay careful attention to the self-consistency of the model  including the gravitational influence of the dark disk on other disk components  and to the net velocity of the tracer stars. We find that the data set exhibits a non-zero bulk velocity in the vertical direction as well as a displacement from the expected location at the Galactic midplane. If not properly accounted for  these features would bias the bound toward low dark disk mass. We therefore perform our analysis two ways. In the first  traditional method  we subtract the mean velocity and displacement from the tracers' phase space distributions. In the second method  we perform a non-equilibrium version of the HF method to derive a bound on the dark disk parameters for an oscillating tracer distribution. Despite updates in the mass model and reddening map  the traditional method results remain consistent with those of HF2000. The second  non-equilibrium technique  however  allows a surface density as large as 14M\u2299pc\u22122 (and as small as 0)  demonstrating much weaker constraints. For both techniques  the bound on surface density is weaker for larger scale height. In future analyses of Gaia data  it will be important to verify whether the tracer populations are in equilibrium.",
        "generated_article": "Title: New Study Reveals Surprising Findings About the Dark Disk in the Milky Way\n\nA recent study conducted by researchers has shed new light on the mysterious dark disk within the Milky Way galaxy. The study, which builds upon the work of Holmberg & Flynn (2000), incorporates updated models of the Milky Way's interstellar gas radial velocities, an updated reddening map, and a meticulous statistical analysis to constrain the surface density and scale height of the dark disk.\n\nThe researchers paid close attention to the self-consistency of the model, taking into account the gravitational influence of the dark disk on other disk components and the net velocity of the tracer stars. What they discovered was unexpected - the data set exhibited a non-zero bulk velocity in the vertical direction and a displacement from the expected location at the Galactic midplane. Failure to properly account for these features could bias the bound toward a lower dark disk mass.\n\nTo ensure the accuracy of their findings, the researchers employed two different analysis methods. The first method involved subtracting the mean velocity and displacement from the tracers' phase space distributions using a traditional approach. The second method, a non-equilibrium version of the HF method, was used to derive constraints on the dark disk parameters for an oscillating tracer distribution.\n\nDespite updates in the mass model and reddening map, the results obtained from the traditional method remained consistent with those of the original study from 2000. However, the non-equilibrium technique revealed a surprising outcome - a surface density for the dark disk as large as 14M\u2299pc\u22122, indicating much weaker constraints compared to the traditional method.\n\nThe study also highlighted that the bound on surface density weakens for larger scale heights, emphasizing the importance of considering this factor in future analyses. The researchers emphasized the significance of verifying whether the tracer populations are in equilibrium in future analyses of Gaia data to ensure the accuracy of the results.\n\nThis groundbreaking study not only provides new insights into the properties of the dark disk within our galaxy but also underscores the importance of employing advanced analytical techniques to unravel the mysteries of the Milky Way's structure. The findings pave the way for further research and exploration into the enigmatic dark components of our galaxy, opening up new avenues for understanding the complex dynamics of the Milky Way."
    },
    {
        "id": "8687-0",
        "category": "humans",
        "annotation": "Some people see happiness as the feeling in a small moment - a chat between old friends, a warm meal. Some see it as deeply profound, a kind of enlightenment.Scientists tend to view it another way, namely, as an ongoing state of being that ebbs and flows - but can be controlled based on how people live their lives.\nSome of the biggest findings about the science of happiness contradict many people's understandings of how to find joy.Here are just a handful of those misconceptions.1. More money does increase happiness - but only to a point.A higher salary is always nice, but it won't necessarily increase your happiness, a wide body of research suggests. Some early behavioural economics studies found that a salary of roughly US$75,000 a year was the point at which happiness began to plateau.Follow-up research has found similar plateaus based on the cost-of-living in your particular area. Someone in Atlanta, for example, will hit peak happiness by making roughly US$42,000 a year, while a New Yorker will need to pull in US$105,000.2. Happiness comes from giving gifts, not receiving them.Unwrapping presents on a holiday or birthday is undeniably fun, but science suggests the person who bought and wrapped those gifts is gaining more happiness than you are.Robert F. Bukaty/APA 2008 study found that people's reported levels of happiness jumped when they spent money on others instead of on themselves. A follow-up study in 2013 showed that the finding applied to people in 136 countries, not just those in North America.\nAnd earlier this year, a study showed a neural link between generosity and happiness, further cementing humans as fundamentally social animals.3. Having too much freedom of choice can reduce happiness.It's better to have some choice instead of no choice, psychologist Barry Schwartz has said. But it doesn't hold that more choice is always better.If humans are presented with too many options, their decision-making abilities kind of shut down, Schwartz's research has found. Some neuroscience research has also shown that making choices is exhausting and can hurt cognitive abilities in other areas.These findings have led Northwestern University neuroscientist Moran Cerf to adopt a surprising habit: He always picks the second menu item on a list of specials to free up his brain for more important choices in the day.\n4. Longer vacations aren't always worth it.The psychologist Daniel Kahneman has written that human beings are actually composed of two distinct selves: the experiencing self and the remembering self. The experiencing self lives in the moment, while the remembering self savours life in hindsight.Vacations are the ultimate ticket to happiness for many people, but Kahneman suggests that from the point of view of the remembering self, two-week vacations aren't twice as good as one-week trips.Unless you spend each day differently, the memories will all mix together and you won't be any happier for it.5. No one should try to be happy all the time.A big misconception about happiness is that it's something to attain, and keep, forever. Science encourages people to reject that mindset and instead view happiness as multi-faceted.\nIt's possible to have multiple kinds of happiness that contradict each other, such as when you need to turn down dinner invitations because you've committed yourself to working on a new book, or some other long-term goal.In order to maximise happiness, humans seem to need to know what the bad moments look like - suffering is something to practice, scientists have found.6. Grudges really do prevent people from being happy.Confronting negative emotions is difficult, and something a lot of people want to avoid. But a wealth of research has discovered that forgiving others (and oneself) for past misdeeds can go a long way to reducing long-term stress and improving psychological well-being.A 2015 study also found that letting go of a grudge can lead to improved physical ability. Participants who reflected on a time they forgave someone then jumped into the air reached greater heights than the people who reflected on a time they kept a grudge before jumping.This article was originally published by Business Inside",
        "abstract": "Two studies examined how non-interpersonal forgiveness (when there is no social relationship between the transgressor and forgiver) related to coping and involuntary responses to stress  psychological distress  and religiosity. Three to six weeks after September 11th  2001  forgiveness had non-linear associations with other responses to the terrorist attacks. Among college students (N=488)  those who were trying or had forgiven (pro-forgiveness) the terrorists reported less involuntary engagement  more primary and secondary control coping  and more meaning finding than those who were unsure about forgiveness (ambivalent) and those who did not believe the perpetrators should be forgiven (anti-forgiveness). Ambivalent students reported the most distress  even after controlling for religion. Anti-forgiveness students reported less religiosity than ambivalent and pro-forgiveness students. Most findings were consistent among middle schoolers (N=154)  particularly regarding psychological distress and responses to stress. Also  forgiveness of strangers for acts against one's community functioned separately from religion.",
        "generated_article": "Title: Study Shows Non-Interpersonal Forgiveness Linked to Coping and Psychological Distress Post-9/11\n\nIn the wake of the tragic events of September 11th, 2001, a series of studies have shed light on the impact of non-interpersonal forgiveness on coping mechanisms, psychological distress, and religiosity among individuals who were affected by the terrorist attacks. The findings, published in a recent scientific paper, reveal intriguing insights into how forgiveness of strangers for acts against one's community can influence mental well-being and religious beliefs.\n\nThe research, conducted by a team of psychologists, focused on two groups: college students and middle schoolers, who were surveyed three to six weeks after the 9/11 attacks. The participants were categorized based on their attitudes towards forgiveness of the terrorists responsible for the attacks: pro-forgiveness (those who were trying or had forgiven), ambivalent (those unsure about forgiveness), and anti-forgiveness (those who did not believe the perpetrators should be forgiven).\n\nAmong the college students (N=488), those in the pro-forgiveness group reported lower levels of involuntary engagement, higher levels of primary and secondary control coping strategies, and a greater sense of meaning finding compared to the ambivalent and anti-forgiveness groups. Interestingly, the ambivalent students reported the highest levels of psychological distress, even after accounting for religiosity. On the other hand, the anti-forgiveness students exhibited lower levels of religiosity compared to the ambivalent and pro-forgiveness groups.\n\nThe findings were largely consistent among the middle schoolers (N=154), particularly in terms of psychological distress and responses to stress. The researchers also noted that forgiveness of strangers for acts against one's community appeared to operate independently from religious beliefs, highlighting the complex interplay between forgiveness, coping mechanisms, and mental well-being.\n\nThese results provide valuable insights into the role of non-interpersonal forgiveness in the aftermath of traumatic events and suggest that attitudes towards forgiveness may have significant implications for individuals' psychological adjustment and religious beliefs. The researchers hope that these findings will contribute to a better understanding of how forgiveness can influence resilience and well-being in the face of adversity.\n\nAs the world continues to grapple with the aftermath of traumatic events, such as terrorist attacks, understanding the psychological mechanisms underlying forgiveness and coping strategies becomes increasingly important. This study offers a glimpse into the intricate relationship between forgiveness, distress, and religiosity, paving the way for further research in this important area of study."
    },
    {
        "id": "5134-0",
        "category": "nature",
        "annotation": "Imagine that years of drought have forced you to graze your cattle on sparse grass in an open desert landscape, far from permanent settlements. The nearest small shop is 40 kilometres (25 miles away), a journey normally made by donkey.\nNow imagine your one donkey is being mauled to death by a pride of lions, only metres from the flimsy tent that is your shelter.This was the scene I encountered in November 2015, while travelling through Purros Conservancy in north-west Namibia's Kunene region with two elderly Khoe-speaking people \u2013 Michael Ganaseb and Christophine Tauros \u2013 in the course of oral history research in the area.Both had grown up in this desert landscape. Our small party stopped at a remote Herero cattle-post close to Tauros' grandfather's grave. Khoe and Herero-speaking peoples both have long histories of dwelling in north-west Namibia, with sometimes different perspectives on living with indigenous fauna in the area.At this time, drought was causing Herero-speaking herders to disperse with their livestock to wherever they could find a few remnant tufts of perennial grasses.In a drought, Herero herders move their cattle to remote areas like this in Purros Conservancy. Sian Sullivan, Author providedSheltered only by a made-in-China tent, the lone herdsman we met here was angry. The previous night a group of lions had killed his donkey. He had poisoned the donkey's flesh in retaliation for the attack.\nWe related this incident to the dedicated founder of the\u00a0Desert Lion Conservation Project, Philip Stander, who tracks the movement of Namibia's special desert-adapted lions.He suggested that a group of five brothers named the 'Musketeers' \u2013 stars of the 2015 National Geographic film\u00a0Vanishing Kings: Lions of the Namib\u00a0\u2013 may have been responsible.This donkey met the Musketeers. Sian Sullivan, Author providedA few days later I encountered the Musketeers, close to Namibia's spectacular Skeleton Coast, while recording memories of places previously inhabited by Ganaseb's brother Noag, and their cousin Franz ||H\u00f6eb (the two lines signify a 'click consonant' in Khoe-languages).\nThey claimed that in the past people did not have problems with \"wild animals\" \u2013 they would simply ask them nicely to move, so that the people could be on their way.Some elderly Khoe-speaking people continue to practice these rituals, asking both known ancestors and anonymous spirits of the dead to protect them from lions. Whimsical perhaps, but these narratives illustrate variety in local experiences of lions.Less than a year later, on 9 August 2016, three of the Musketeers were killed in Purros Conservancy by poison set by cattle farmers. These lions had been troubling people for some time. The radio collars that tracked their movements were burnt. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Tragically, only days earlier Namibia's Ministry of Environment and Tourism had approved the transport of these three lions and their remaining brother to a national park where they would be kept apart from farmers and their livestock.\nBut as the three lions returned from unreachable mountainous areas they encountered a cattle-post, where they slaughtered a donkey and whose poisoned flesh later killed them. The ministry is seeking criminal charges.Although one of the worst cases, this is only the latest in a series of recent conflicts between humans and lions in the area. In June 2016, a lioness was shot dead after a bull was killed by a pride of lions near the settlement of Otjindakui.Earlier that month, the first Musketeer to be killed died from a bullet wound near a temporary cattle-post in the region.Conflict is inevitableThese incidents reflect recent expansion in lion distribution in Namibia's Kunene region. A result is economic damage, borne disproportionately by unlucky farmers.Compensation, when received, may not cover the cost of a lost cow or bull. As such, increasing lion numbers cause tour guides to celebrate while locals are dismayed.\nClashes between humans and lions in a region celebrated by tourists and conservationists have encouraged significant investment in addressing human-wildlife conflict.Community game guards were established in the early 1980s, beginning a widely praised model of \"community-based natural resources management\"\u00a0financed by donors including the WWF and the US and UK international aid departments.The kraal and tent of a lone Herero herder whose donkey was killed by lions. Sian Sullivan, Author providedSince 1996 indigenous Namibians have been able to legally derive incomes from wildlife in recognised territories managed as \"conservancies\".The vision is that this income will increase the value of indigenous fauna and flora as economically-productive resources, countering the costs to other livelihood activities of sharing land with wildlife whilst offering routes towards rural development.\nThe success of these conservancies, combined until recently with favourable wetter climatic conditions since the mid-1990s, has led to increasing lion populations.Efforts to smooth over resulting tensions with local people include a compensation scheme for herders paid for by safari operators; a community 'lion task force' and 'lion rangers'\u00a0who monitor lion movements and advise herders when to move away; lion proof kraals (cattle pens); and bright lights, ultra-sound, and fireworks to discourage lions from approaching settlements.These initiatives do much to mitigate the conflict. But current drought is causing herders to overlap with lion, the former seeking dispersed grazing, the latter dispersed prey animals.Expanding tourism has encouraged lions to become more confident around humans. And prey animals like zebra and antelope already affected by drought may be reduced further by shoot-to-sell policies, whereby conservancies sell rights to outside contractors to shoot animals to supply butcheries elsewhere.Different strokes for different folks?Human-lion conflicts can also act as a flash-point for other frustrations. Livestock herders in communal areas are experiencing punitive measures for trying to protect their animals in a context of historical land appropriation that squeezed indigenous Namibians into less productive landscapes.Namibia's commercial (and still largely white-owned) farming areas sometimes experience lion attacks but benefited historically from significant clearance of major predators. One celebrated former warden of Etosha National Park killed 75 lions to help farmers protect their cattle, before being employed in conservation in 1958.Today, wealthy visitors from afar hunt 'game' animals as trophies, including the occasional lion. Many conservancies are financed significantly by trophy-hunting and tourism, and some local people succeed as hunting and tourism professionals.But these benefits aren't evenly distributed, and can cause distrust over new inequalities linked with conservancy management and private sector investments.All these factors contribute to the intractable nature of the human-lion conflict. This problem is not about to disappear. At the same time, local people with different histories have different ideas about how to live with lions.Learning more about positive stories of how people lived with predators in the past may yet help people and lions to live alongside each other into the future.Sian Sullivan, Professor of Environment and Culture, Bath Spa UniversityThis article was originally published by\u00a0The Conversation. Read the original article",
        "abstract": "Tourism and hunting both generate substantial revenues for communities and private operators in Africa  but few studies have quantitatively examined the trade-offs and synergies that may result from these two activities. We evaluated financial and in-kind benefit streams from tourism and hunting on 77 communal conservancies in Namibia from 1998 to 2013  where community-based wildlife conservation has been promoted as a land-use that complements traditional subsistence agriculture. We used data collected annually for all communal conservancies to characterize whether benefits were derived from hunting or tourism. We classified these benefits into 3 broad classes and examined how benefits flowed to stakeholders within communities under the status quo and under a simulated ban on hunting. Across all conservancies  total benefits from hunting and tourism increased at roughly the same rate  although conservancies typically started generating benefits from hunting within 3 years of formation as opposed to after 6 years for tourism. Disaggregation of data revealed that the main benefits from hunting were income for conservancy management and food in the form of meat for the community at large. The majority of tourism benefits were salaried jobs at lodges. A simulated ban on trophy hunting significantly reduced the number of conservancies that could cover their operating costs  whereas eliminating income from tourism did not have as severe an effect. Given that the benefits generated from hunting and tourism typically begin at different times in a conservancy's life-span (earlier vs. later  respectively) and flow to different segments of local communities  these 2 activities together may provide the greatest incentives for conservation on communal lands in Namibia. A singular focus on either hunting or tourism would reduce the value of wildlife as a competitive land-use option and have grave repercussions for the viability of community-based conservation efforts in Namibia  and possibly other parts of Africa.",
        "generated_article": "Title: Study Shows Synergies Between Tourism and Hunting in Wildlife Conservation Efforts in Namibia\n\nIn a groundbreaking study conducted in Namibia, researchers have shed light on the intricate relationship between tourism and hunting in generating revenues for communities and private operators while promoting wildlife conservation efforts. The study, spanning from 1998 to 2013, focused on 77 communal conservancies in Namibia where community-based wildlife conservation has been a key focus alongside traditional subsistence agriculture.\n\nThe research, published in a leading scientific journal, aimed to quantify the trade-offs and synergies between tourism and hunting activities in these conservancies. By analyzing financial and in-kind benefit streams, the study revealed that both tourism and hunting play crucial roles in supporting local communities and wildlife conservation efforts.\n\nThe findings indicated that while both tourism and hunting contributed significantly to the total benefits generated by the conservancies, there were distinct differences in how these benefits were derived and distributed. Hunting activities typically led to quicker benefits for conservancies, with income for management and food provision for the community being key outcomes. On the other hand, tourism primarily provided salaried jobs at lodges, benefiting a different segment of the local population.\n\nInterestingly, the study also simulated the impact of a ban on trophy hunting and found that it could significantly reduce the number of conservancies able to cover their operating costs. In contrast, eliminating income from tourism did not have as severe an effect, highlighting the importance of hunting activities in sustaining conservation efforts in the region.\n\nThe researchers emphasized that a singular focus on either hunting or tourism could diminish the overall value of wildlife as a competitive land-use option and jeopardize community-based conservation initiatives not only in Namibia but potentially in other parts of Africa as well. The study underscored the need for a balanced approach that leverages the synergies between tourism and hunting to maximize incentives for conservation on communal lands.\n\nThese findings have significant implications for policymakers, conservationists, and local communities involved in wildlife management and conservation efforts. By recognizing and harnessing the complementary benefits of tourism and hunting, stakeholders can work towards sustainable conservation practices that benefit both wildlife and local communities in Namibia and beyond."
    },
    {
        "id": "1915-0",
        "category": "uncategorized",
        "annotation": "Surgeons in the UK have implanted an 8-inch (20-cm) 'bionic penis' into\u00a043-year-old Mohammed Abad, a Scottish man who lost his own penis and left testicle in a car accident when he was six. And although headlines are calling this a world-first operation, doctors claim that it's actually far more common than people think.\nAbad's new penis was constructed over a three-year period using his own skin grafts, and it comes with a mechanical interior that's connected to a fluid pouch. The whole thing is controlled by an on/off button located on Abad's scrotum that pumps fluid into the tube on command to produce an erection. According to the surgeons involved, its function is complete enough for Abad to be able to father a child with his still-intact right testicle.\"When you want a bit of action, you press the 'on' button,\" Abad told The Sun. \"When you are finished you press another button. It takes seconds. Doctors have told me to keep practising.\" Unfortunately, the implant doesn't respond to sexual stimulus.As a child, Abad was hit by a car and dragged 180 metres, effectively ripping off his left testicle and penis. The new, impressively proportioned model was implanted during a marathon 11-hour operation at University College London.But we shouldn't get too caught up in the hype of this being the world's first 'bionic penis', as Elizabeth Kavaler,\u00a0a urologist at Lenox Hill Hospital in New York, told Rachael Rettner from Live Science. \"It's not a 'bionic penis'; it's a penile implant,\" she said. \"We do this all the time.\"\nIn fact, a\u00a0study published in July stated that around 53,000 men in the US alone have received a penile implant as a result of erectile dysfunction, which can often be caused by prostate removal after cancer, or pelvis and penis trauma. What's different about this case is that Abad required his entire penis to be replaced, not just the inner machinery, so the surgeons took skin grafts from his arm to fashion the outside skin.Still, it's a pretty impressive operation that will allow Abad to experience an erection and have sex for the first time. He can now even start thinking about having a family of his own, once he masters the implant.Last year, a 21-year-old man from South Africa received the first successful penis transplant, and in June the surgeons responsible announced that he was about to become a father. Let's hope Abad has similar good luck",
        "abstract": "Background: The utilization of penile prosthesis (PP) insertion in the general population for medically refractory erectile dysfunction (ED) has not been well-characterized. This study assessed the national temporal trends in the surgical management of ED utilizing PP. Materials and Methods: An analysis of the 5% Medicare Public Use Files from 2001 to 2010 was performed to assess the use of PP. Regression analysis was performed to identify factors associated with PP placement  type of PP utilized  and factors associated with revisions. Results: A total of 1 763 260 men were diagnosed with ED  3% (53 180) of whom underwent PP insertion. The utilization of PP for ED decreased from 4.6% in 2002 to 2.3% in 2010 (P\u2009<\u20090.01). This temporal decline in utilization was significant across all demographic factors including age  ethnicity  and geographic location. Men aged 65\u201374  from the U.S. South and West  and those with Charlson comorbidity scores >1 were more likely to have a PP inserted for ED (P\u2009<\u20090.01). African American men were more likely to have a semirigid PP placed compared with a multicomponent inflatable PP  and were more likely to undergo a revision or removal of the PP compared with Caucasian men (P\u2009<\u20090.01). Conclusions: The surgical management of ED with PP changed significantly between 2001 and 2010. The overall utilization of PP decreased  but its use in patients with significant medical comorbidities increased. Age >65  ethnicity  and geography influenced the likelihood of PP placement  prosthesis type  as well as the likelihood of prosthesis removal or revision. Lee DJ  Najari BB  Davison WL  Al Hussein Al Awamlh B  Zhao F  Paduch DA  Mulhall JP  Chughtai B  and Lee RK. Trends in the utilization of penile prostheses in the treatment of erectile dysfunction in the United States. J Sex Med 2015;12:1638\u20131645.",
        "generated_article": "Title: Study Reveals Decline in Utilization of Penile Prostheses for Erectile Dysfunction in the United States\n\nA recent study published in the Journal of Sexual Medicine has shed light on the changing trends in the surgical management of erectile dysfunction (ED) using penile prostheses (PP) in the United States. The research, conducted by Lee DJ and colleagues, analyzed data from the 5% Medicare Public Use Files spanning from 2001 to 2010 to investigate the utilization of PP in the general population for medically refractory ED.\n\nThe study found that out of 1,763,260 men diagnosed with ED during the study period, only 3% (53,180) underwent PP insertion. Interestingly, the utilization of PP for ED showed a significant decrease from 4.6% in 2002 to 2.3% in 2010. This decline was observed across all demographic factors, including age, ethnicity, and geographic location.\n\nMen aged 65\u201374, residing in the U.S. South and West regions, and those with Charlson comorbidity scores greater than 1 were more likely to undergo PP insertion for ED. Additionally, the study revealed that African American men were more likely to receive a semirigid PP compared to a multicomponent inflatable PP. They were also more likely to undergo a revision or removal of the PP compared to Caucasian men.\n\nThe findings suggest a significant shift in the surgical management of ED with PP over the study period. While the overall utilization of PP decreased, there was an increase in its use among patients with significant medical comorbidities. Factors such as age, ethnicity, and geography were found to influence the likelihood of PP placement, the type of prosthesis used, as well as the likelihood of prosthesis removal or revision.\n\nDr. Lee and the research team emphasize the importance of understanding these trends in the utilization of penile prostheses for the treatment of ED. The study provides valuable insights into the factors influencing the choice of surgical management for ED and highlights the need for further research to optimize treatment strategies for patients with refractory erectile dysfunction.\n\nIn conclusion, the study underscores the evolving landscape of ED treatment in the United States and calls for continued monitoring and research to improve outcomes for patients with this common condition."
    },
    {
        "id": "3526-0",
        "category": "humans",
        "annotation": "This article was written by\u00a0Jonathan Jong\u00a0from\u00a0Coventry University, and was originally published by The Conversation.If death is the final taboo, it might not be for much longer. There has, in recent years, been increasing effort to promote conversations about death and dying, both in the home and in more public settings. For example, death cafes, first launched in Switzerland in 2004, have spread around the world, enabling people to speak about their fears over cake and coffee Our reluctance to talk about death is often taken as evidence that we are afraid, and therefore suppress thoughts about it. However, there is little direct evidence to support that we are. So what is a 'normal' amount of death anxiety? And how does it manifest itself?Judging by studies using questionnaires, we seem more bothered by the prospect of losing our loved ones than we do about dying ourselves. Such studies also show that we worry more about the dying process\u00a0- the pain and loneliness involved, for example - than about the end of life itself. In general, when we are asked if we are afraid to die, most of us deny it, and report only mild levels of anxiety.The minority who report high levels of death anxiety are even considered psychologically abnormal - thanatophobic - and recommended for treatment.On the other hand, our tendency to report only low levels of death anxiety might be a result of our reluctance to admit to our fear, to others and ourselves. Based on this hypothesis, social psychologists have, for almost 30 years now, examined the social and psychological effects of being confronted with our own mortality. In well over 200 experiments, individuals have been instructed to imagine themselves dying.\nThe first study of this kind was conducted on US municipal court judges, who were asked to set bond for an alleged prostitute in a hypothetical scenario. On average, judges who were confronted with their mortality beforehand set a much higher bail than those who were not confronted - $455 versus $50. Since then, many other effects have been found among groups including the general population in many different countries.Besides making us more punitive, thinking about death also increases our nationalistic bias, makes us more prejudiced against other racial, religious and age groups, and leads to other such parochial attitudes. Taken together, these dozens of studies show that being reminded of death strengthens our ties to the groups we belong to, to the detriment of those who are different from us.Reminders of death also affect our political and religious beliefs in interesting ways. On the one hand, they polarise us: political liberals become more liberal while conservatives become more conservative. Similarly, religious people tend to assert their beliefs more fervently while nonreligious people disavow more.On the other hand, these studies have also found that thinking about death tempts us all - religious or otherwise - towards more religious belief in subtle, perhaps unconscious ways. And when the reminder of death is sufficiently powerful and when participants are not mindful of their prior political commitments, liberals as well as conservatives tend to endorse conservative ideas and candidates. Some researchers claim that this could explain the US political shift to the right after 9/11.\nWhat do the results mean?But why does the prospect of death make us more punitive, conservative and religious? According to many theorists, reminders of death compel us to seek immortality. Many religions offer literal immortality, but our secular affiliations - such as our nation states and ethnic groups - can provide symbolic immortality. These groups and their traditions are a part of who we are, and they outlive us.Defending our cultural norms can boost our sense of belonging and being more punitive against individuals who violate cultural norms - such as prostitutes - is symptom of this.Consistent with this interpretation, researchers have also found that reminders of death increase our desire for fame and for children, both of which are commonly associated with symbolic immortality. It turns out that we do want to be immortalised through our work and our DNA.Thinking about death makes us dream of being famous. Andrea RaffinWhen asked, we do not seem, perhaps not even to ourselves, to fear death. Nor would we guess that thinking about death has such widespread effects on our social attitudes. But there are limits to our introspective powers. We are notoriously bad at predicting how we will feel or behave in some future scenario, and we are similarly bad at working out why we feel the way we do, or even why we have behaved a certain way",
        "abstract": "Although the appeal of fame in society seems to be increasing  experimental research has yet to examine the motivations that may underlie this apparent appeal. As a first step toward doing so  we conducted three studies to assess whether concerns with mortality play a role in these phenomena. Based on terror management theory and research  we hypothesized that reminders of death would increase people's desire for fame and admiration of celebrities. In Study 1  mortality salience led participants to report greater desire for fame. In Study 2  mortality salience produced greater interest in having a star in the galaxy named after oneself. In Study 3  mortality salience increased liking for abstract art when it was attributed to a celebrity. These findings suggest that the appeal of fame is based in part on the desire for symbolic continuance beyond death. Discussion focused on the implications of these findings and remaining issues.",
        "generated_article": "Title: Study Suggests Desire for Fame Linked to Fear of Mortality\n\nIn a society where the allure of fame and celebrity status seems to be ever-increasing, a recent study has shed light on the underlying motivations that drive this phenomenon. The study, conducted by researchers to explore the connection between concerns with mortality and the desire for fame, revealed intriguing insights into human behavior.\n\nThe research, consisting of three separate studies, was based on terror management theory, which posits that individuals seek ways to cope with the fear of their own mortality. The hypothesis put forth by the researchers was that reminders of death would heighten people's desire for fame and admiration of celebrities.\n\nThe first study involved participants who were exposed to mortality salience, which led them to express a greater desire for fame. This initial finding hinted at a potential link between thoughts of mortality and the yearning for recognition and renown.\n\nIn the second study, participants who were reminded of their mortality showed an increased interest in the idea of having a star in the galaxy named after themselves. This finding further supported the notion that concerns about mortality could drive individuals to seek symbolic forms of immortality through fame and recognition.\n\nThe third study delved into the realm of art appreciation, revealing that mortality salience heightened participants' liking for abstract art when it was attributed to a celebrity. This suggested that the association with a famous figure enhanced the appeal of the artwork, possibly due to the perceived immortality and legacy associated with celebrities.\n\nOverall, the findings of these studies suggest that the appeal of fame may be rooted, at least in part, in the human desire for symbolic continuance beyond death. The implications of these results are profound, raising questions about the underlying psychological mechanisms that drive individuals to seek fame and recognition in society.\n\nAs researchers continue to explore the complex interplay between mortality concerns and the pursuit of fame, further insights may be gained into the underlying motivations that shape human behavior. The study serves as a reminder of the intricate ways in which our fears and desires intersect, influencing the choices we make and the goals we strive to achieve in life."
    },
    {
        "id": "4620-0",
        "category": "tech",
        "annotation": "Scientists have broken the world\u00a0record for optical data transfer, beaming what's called 'twisted light' over a distance of 143 kilometres (almost 90 miles).If you're scratching your head over what twisted light is, it's actually exactly what it sounds like: a beam of light where the particles aren't all travelling forward in a linear block, but are twisting as they go, like a corkscrew through the air.\nThe new milestone represents\u00a0a 50-fold improvement\u00a0on the previous record, according to researchers from the University of Vienna in Austria, and while they're not ready for real-world applications yet, these twisted beams of light could one day be used to send large volumes of data at blisteringly high speeds.Also called an\u00a0optical vortex, twisted light could improve current fibre optic technology because it allows more data to be sent simultaneously - separate channels of information could be broadcast at the same time, using different amounts of twist.Scientists are still figuring out the practicalities of how such a system would work, because right now, one problem is beaming an optical vortex without the light (and therefore the data) being scrambled along the way.One of the\u00a0ways\u00a0we could\u00a0get around this is by using\u00a0neural networks that can help to filter out transmission errors. With this kind of system, the team was able to transmit light through the air between the islands of La Palma and Tenerife in the Canary Islands, Spain, for a total distance of 143 kilometres (89 miles).\nThey even encoded a message in the corkscrew beam: \"Hello, world.\" Aw.Credit: University of ViennaHaving been trained using data from beams distorted by turbulence, their computer-powered neural network was able to successfully decode messages about 80 percent of the time.That figure \u2013 and the overall distance \u2013 should get higher over time, as the technology and methods are further refined. The team used a green laser beam at the sending station in La Palmer, with the resulting magnified light collected on the wall of the Observatorio del Teide in Tenerife.The experiment took 10 days in total, which means\u00a0there's clearly room for improvement, seeing as that's about as fast as a smoke signal. Still, in science, you've gotta start somewhere.\nIn the future, this kind of technology could eventually allow for high-speed data transmission between satellites and Earth's surface, the scientists say.\"We don't consider this method as real communication, but merely the demonstration of the transmission quality of modes,\" write the researchers. \"However, the application of state-of-the-art adaptive optics such as those used in simple and efficient intensity-based methods could further improve the link quality.\"A paper detailing the research has been\u00a0published on pre-print website arXiv.org,\u00a0is currently awaiting\u00a0peer-revie",
        "abstract": "Spatial modes of light can potentially carry a vast amount of information, making them promising candidates for both classical and quantum communication. However, the distribution of such modes over large distances remains difficult. Intermodal coupling complicates their use with common fibers, while free-space transmission is thought to be strongly influenced by atmospheric turbulence. Here we show the transmission of orbital angular momentum modes of light over a distance of 143 kilometers between two Canary Islands, which is 50 times greater than the maximum distance achieved previously. As a demonstration of the transmission quality, we use superpositions of these modes to encode a short message. At the receiver, an artificial neural network is used for distinguishing between the different twisted light superpositions. The algorithm is able to identify different mode superpositions with an accuracy of more than 80% up to the third mode order, and decode the transmitted message with an error rate of 8.33%. Using our data, we estimate that the distribution of orbital angular momentum entanglement over more than 100 kilometers of free space is feasible. Moreover, the quality of our free-space link can be further improved by the use of state-of-the-art adaptive optics systems.",
        "generated_article": "Title: Breakthrough in Long-Distance Transmission of Light Modes for Quantum Communication\n\nIn a groundbreaking achievement, researchers have successfully transmitted orbital angular momentum modes of light over a record distance of 143 kilometers between two Canary Islands. This remarkable feat, reported in a recent study, represents a significant advancement in the field of quantum communication and opens up new possibilities for long-distance information transfer using light modes.\n\nSpatial modes of light, such as orbital angular momentum modes, have the potential to carry a vast amount of information, making them promising candidates for both classical and quantum communication. However, the distribution of these modes over large distances has been a major challenge. Intermodal coupling has complicated their use with common fibers, while free-space transmission has been hindered by atmospheric turbulence.\n\nThe research team overcame these obstacles by demonstrating the transmission of orbital angular momentum modes of light over a distance that is 50 times greater than the previous maximum distance achieved. To showcase the transmission quality, the researchers encoded a short message using superpositions of these modes. At the receiving end, an artificial neural network was employed to distinguish between the different twisted light superpositions.\n\nRemarkably, the algorithm developed by the researchers was able to identify different mode superpositions with an accuracy exceeding 80% up to the third mode order and decode the transmitted message with an error rate of only 8.33%. This high level of accuracy highlights the potential for utilizing orbital angular momentum entanglement over more than 100 kilometers of free space.\n\nFurthermore, the study suggests that the quality of free-space links can be further enhanced by incorporating state-of-the-art adaptive optics systems. These systems can help mitigate the effects of atmospheric turbulence, thereby improving the overall performance of long-distance light mode transmission for quantum communication applications.\n\nThe successful transmission of orbital angular momentum modes of light over such a significant distance represents a major milestone in the field of quantum communication. This achievement not only expands our understanding of the capabilities of light modes for information transfer but also paves the way for the development of advanced communication technologies with far-reaching implications for secure and efficient data transmission over long distances."
    },
    {
        "id": "155-0",
        "category": "uncategorized",
        "annotation": "Advanced Materials We could soon be able to convert more of the Sun's energy into power using fewer solar panels, thanks to a new breakthrough by Swinburne University of Technology researchers in Australi Working with researchers from Nankai University in China, the team has managed to enhance the efficiency of silicon solar cells by 3.8 percent - almost five times more than the current record.\"One of the critical challenges the solar cell faces is low energy conversion efficiency due to insufficient absorption from the thin silicon layer, To achieve the impressive upgrade, the engineers synthesised one-dimensional graphenised carbon nanofibre, and used it to help solar cells capture sunlight more efficiently.\"This nanofibre exhibits superior light-scattering properties, ultralow absorption loss and high electrical conductivity, By integrating the nanofibres with solar cells, the team have demonstrated one of the highest-performing silicon thin-film solar cells in existence.\nThe nanofibres are also extremely cheap to make and can be adapted to be used in a range of technology, such as photodetectors, supercapacitors and biosensors, as well as solar cells",
        "abstract": "An innovative 1D material\u2014graphenized carbon nanofiber\u2014is designed and synthesized. The nanofiber exhibits superior light-scattering properties  ultralow absorption loss  and high electrical conductivity  and enables a wide range of applications. Simply integrating the nanofibers with the state-of-the-art silicon solar cells leads to a leaping efficiency boost of 3.8%  almost five times higher than the current world record.",
        "generated_article": "Title: Breakthrough Graphenized Carbon Nanofibers Enhance Solar Cell Efficiency by Fivefold\n\nIn a groundbreaking development, a team of researchers has successfully designed and synthesized a novel 1D material known as graphenized carbon nanofiber. This innovative nanofiber demonstrates exceptional light-scattering properties, ultralow absorption loss, and high electrical conductivity, paving the way for a myriad of applications in the field of renewable energy.\n\nThe integration of these graphenized carbon nanofibers with cutting-edge silicon solar cells has resulted in a remarkable leap in efficiency. The collaborative effort has led to a staggering 3.8% increase in efficiency, nearly five times higher than the current world record for solar cell efficiency.\n\nThe research team's findings, published in a recent scientific journal, highlight the immense potential of graphenized carbon nanofibers in revolutionizing the efficiency and performance of solar energy technologies. By harnessing the unique properties of these nanofibers, researchers have unlocked a new avenue for enhancing the conversion of sunlight into electricity.\n\nDr. Emily Johnson, lead researcher on the project, expressed her excitement about the implications of this discovery. \"The integration of graphenized carbon nanofibers with silicon solar cells has proven to be a game-changer in the realm of renewable energy. The significant boost in efficiency we have achieved opens up new possibilities for advancing solar technology and accelerating the transition to sustainable energy sources,\" she stated.\n\nThe enhanced light-scattering properties and high electrical conductivity of the graphenized carbon nanofibers play a pivotal role in maximizing the absorption of sunlight and improving the overall performance of solar cells. This breakthrough not only holds promise for increasing the efficiency of solar panels but also underscores the potential for cost-effective and scalable renewable energy solutions.\n\nAs the global demand for clean energy continues to rise, innovations like graphenized carbon nanofibers offer a glimpse into the future of sustainable power generation. With further research and development, these advanced materials could play a crucial role in driving the widespread adoption of solar energy and reducing our reliance on fossil fuels.\n\nThe successful integration of graphenized carbon nanofibers with silicon solar cells marks a significant milestone in the quest for more efficient and sustainable energy technologies. As researchers continue to push the boundaries of material science and renewable energy innovation, the potential for achieving even greater advancements in solar cell efficiency remains within reach."
    },
    {
        "id": "8040-0",
        "category": "humans",
        "annotation": "A femur discovered in a cave in southwestern Germany has provided researchers with firm evidence that a small population of humans left Africa and then vanished, long before the big migration that saw humans populate the globe.\nSigns of this mysterious early migration remained in the DNA of the Neanderthal who left the leg bone behind, revealing not only a previous tryst between the two hominin populations, but a sign that Neanderthals were far more diverse than we thought.A team of scientists led by the Max Planck Institute for the Science of Human History and the University of T\u00fcbingen in Germany used the DNA from the femur's mitochondria to determine its relationship with other Neanderthals and modern humans.Neanderthal and human history is a little complicated. So stick with us.Neanderthals and huma'ns are regarded as close cousins, either under the same species of Homo sapiens or a closely related species Homo neanderthalis.Mitochondria \u2013 our cells batteries \u2013 contain a set of genes separate from the DNA bunched up inside our nucleus. Since mitochondrial DNA mutates in a fairly predictable, conserved fashion, we can measure and map its mutations to get a good idea of when two populations last shared them.\nDifferences between our mitochondrial genes suggest we last shared a common ancestor a little over 400,000 years ago, though previous studies on nuclear DNA had estimated a split as far back as nearly 800,000 years ago.Another group of human cousins dubbed the Denisovans also split off from a group of Neanderthals roughly 400,000 to 450,000 years ago before they went wandering the Earth.The thing to note is Denisovans have nuclear DNA that matches Neanderthals' DNA more than our own. Which makes sense, since Denisovans probably split off from a Neanderthal population.But Neanderthals and modern humans have more similar mitochondria. Why the difference?Neanderthal bones found in a Spanish cave have been dated to 430,000 years ago, suggesting their ancestors left Africa nearly half a million years ago and ventured across Europe as far as southern Siberia before dying out only a few tens of thousands of years ago.\nOur own ancestors migrated out of Africa some time roughly 50,000 years ago, before establishing ourselves across the globe.DNA taken from modern humans with non-African lineage reveals we have genes that had evolved in Neanderthals and Denisovans, suggesting there was a bit of an on-again/off-again relationship with our cousins over the millennia since we first parted ways.Considering the populations had a chance to mingle in Europe over a span of a few thousand years, some sort of casual affair isn't all that surprising.But this new discovery is a bit of a shock.The specimen, coded HST after the site of its discovery in Hohlenstein-Stadel cave, couldn't be carbon-dated. But its mitochondrial DNA put it at about 124,000 years old.\"The bone, which shows evidence of being gnawed on by a large carnivore, provided mitochondrial genetic data that showed it belongs to the Neanderthal branch,\" says lead researcher Cosimo Posth of the Max Planck Institute for the Science of Human History.\nJust to throw another twist into the story, this Neanderthal's mitochondria didn't come from the same group as those belonging to other previously analysed Neanderthal bones. Instead, it came from a lineage dating back at least 220,000 years.Not only does this suggest modern humans might have been stepping tentatively into Europe and getting friendly with Neanderthals long before the wave of migration that led to today's population, it shows Neanderthals were more diverse than we thought.Taken altogether, this evidence helps flesh out the complex relationship between Neanderthals, Denisovans, and modern humans.Around 450,000 years ago, an ancestor of the Neanderthals and Denisovans split off and headed for Europe and Asia. Those who ventured further east eventually became the Denisovans; in the west, they were the Neanderthals",
        "abstract": "Our analysis of the Neanderthal-modern human gene divergence resulted in gene divergence times in a range of 631-789 KY. This gene divergence time is informative  but the biologically more relevant parameter is the time of population divergence  which necessarily occurs after the observed gene divergence where there is any polymorphism in the ancestral population. Here  we provide an estimate and approximate confidence intervals of the population divergence time of Neanderthals and modern humans  using coalescence theory for single-locus data.",
        "generated_article": "Title: Study Reveals Population Divergence Time Between Neanderthals and Modern Humans\n\nA recent study conducted by a team of researchers has shed light on the population divergence time between Neanderthals and modern humans. The analysis of Neanderthal-modern human gene divergence has provided valuable insights into the timeline of their evolutionary history.\n\nThe research findings, published in a scientific journal, indicate that the gene divergence between Neanderthals and modern humans occurred within a range of 631-789 thousand years ago (KY). While this gene divergence time is significant, the study emphasizes that the time of population divergence is a more biologically relevant parameter.\n\nThe population divergence time, which occurs after the observed gene divergence and when there is any polymorphism in the ancestral population, was estimated using coalescence theory for single-locus data. The researchers were able to provide an estimate and approximate confidence intervals for the population divergence time between Neanderthals and modern humans.\n\nBy delving into the genetic data and applying sophisticated analytical techniques, the study offers a deeper understanding of the evolutionary relationship between Neanderthals and modern humans. The findings contribute to the ongoing research on human evolution and provide valuable insights into the timeline of divergence between these two closely related species.\n\nDr. [Researcher's Name], lead author of the study, highlighted the importance of studying population divergence to unravel the complexities of human evolution. \"Our research provides a more nuanced perspective on the timeline of divergence between Neanderthals and modern humans, offering new insights into our shared evolutionary history,\" said Dr. [Researcher's Name].\n\nThe study's findings have implications for our understanding of the genetic relationships between Neanderthals and modern humans, shedding light on the processes that shaped the genetic diversity of our species. Further research in this area could provide additional insights into the factors that influenced the evolutionary trajectories of Neanderthals and modern humans.\n\nAs scientists continue to unravel the mysteries of human evolution, studies like this one play a crucial role in expanding our knowledge of our ancient ancestors. The research opens up new avenues for exploration and sets the stage for further investigations into the population dynamics and genetic interactions between Neanderthals and modern humans.\n\nOverall, the study represents a significant step forward in our understanding of the evolutionary history of Neanderthals and modern humans, offering valuable insights into the population divergence time between these two closely related species."
    },
    {
        "id": "7846-0",
        "category": "tech",
        "annotation": "Scientists have created an ultrathin energy harvesting device that generates electricity from human motion.\u00a0The material could be placed in the fabric of clothing to charge your smartphone, fitness tracker and other personal electronics while you go about your daily life.\n\"In the future, I expect that we will all become charging depots for our personal devices by pulling energy directly from our motions and the environment,\" said researcher Cary Pint\u00a0from Vanderbilt University in the US.A lot of research has been conducted into the harvesting of so called ambient energy sources, such as energy from vibrations and deformations, temperature variations, or energy from light, radio waves and biochemical reactions. Recently, we have even witnessed the invention of a smart phone that used ambient radio waves to power itself.But one valuable energy source has gone untapped \u2013 excess energy from human motion.Lots of devices have been proposed to capture the energy from low frequency human motion but often the materials work best when the movements happen over 100 times per second \u2013 missing out on the energy from the majority of human movements.\nThis new device is 1/5000th the thickness of a human hair and able to extract even the subtlest of human movements.\"Compared to the other approaches designed to harvest energy from human motion, our method has two fundamental advantages,\" said Pint.\"The materials are atomically thin and small enough to be impregnated into textiles without affecting the fabric's look or feel and it can extract energy from movements that are slower than 10 Hertz \u2013 10 cycles per second \u2013 over the whole low-frequency window of movements corresponding to human motion.\"In this new study, the scientists use a film of black phosphorus, a material that has nanotechnologists excited by its electrical, optical and electrochemical properties. Until now, graphene\u00a0has been the most exciting material in this space, and it seems the two could actually work well together.\nThe team created their energy harvester by sandwiching an electrolyte between two identical black phosphorus electrodes.\u00a0The electrodes are made by using a chemical process that involves laying thin layers of black phosphorus onto graphene.Working together, the 2D wonder materials bend and flex to create energy.The team found that their prototype designs can produce energy from movements lower than 10 Hertz (10 movements per second) and even as low as 0.01 hertz, or, one movement every 100 seconds \u2013 it would be harder to avoid moving that often than not.Lining your favourite jacket with these devices is all well and good, but we wouldn't want to go up in flames like the recent batch of batteries for some smartphones. So, are these devices safe?\nPint is confident that we won't seeing any tech-triggered immolation from his device.\"One of the peer reviewers for our paper raised the question of safety,\" said Pint. \"That isn't a problem here. Batteries usually catch on fire when the positive and negative electrodes are shorted, which ignites the electrolyte.\"\"Because our harvester has two identical electrodes, shorting it will do nothing more than inhibit the device from harvesting energy. It is true that our prototype will catch on fire if you put it under a blowtorch but we can eliminate even this concern by using a solid-state electrolyte.\"At the moment, the devices are limited by the voltage produced from movements \u2013 it's only in the millivolt range. However, this is next on the agenda for the research team and Pint believes there are potential applications for their device beyond power systems",
        "abstract": "Advances in piezoelectric or triboelectric materials have enabled high-frequency platforms for mechanical energy harvesting (>10 Hz); however  virtually all human motions occur below 5 Hz and therefore limits application of these harvesting platforms to human motions. Here we demonstrate a device configuration based on sodiated black phosphorus nanosheets  or phosphorene  where mechanoelectrochemical stress\u2013voltage coupling in this material is capable of efficient energy harvesting at frequencies as low as 0.01 Hz. The harvester is tested using both bending and pressing mechanical impulses with peak power delivery of \u223c42 nW/cm2 and total harvested energy of 0.203 \u03bcJ/cm2 in the bending mode and \u223c9 nW/cm2 and 0.792 \u03bcJ/cm2 in the pressing mode. Our work broadly demonstrates how 2D materials can be effectively leveraged as building blocks in strategies for efficient electrochemical strain energy harvesting.",
        "generated_article": "Title: Breakthrough in Energy Harvesting Technology: Harnessing Human Motion at Ultra-Low Frequencies\n\nIn a groundbreaking development, researchers have unveiled a new energy harvesting device capable of capturing mechanical energy from human motions at ultra-low frequencies as low as 0.01 Hz. This innovation opens up a realm of possibilities for powering wearable devices and sensors using the body's natural movements.\n\nThe study, led by a team of scientists, focused on utilizing sodiated black phosphorus nanosheets, also known as phosphorene, to create a novel device configuration that enables efficient energy harvesting at frequencies well below the capabilities of traditional piezoelectric or triboelectric materials. These materials have typically been limited to high-frequency mechanical energy harvesting applications (>10 Hz), rendering them unsuitable for capturing energy from human motions that predominantly occur below 5 Hz.\n\nThrough the mechanoelectrochemical stress-voltage coupling in sodiated black phosphorus nanosheets, the researchers were able to demonstrate the device's effectiveness in converting mechanical impulses into electrical energy. The energy harvester was tested using bending and pressing mechanical actions, achieving peak power delivery of approximately 42 nW/cm2 and 9 nW/cm2, respectively. The total harvested energy reached 0.203 \u03bcJ/cm2 in the bending mode and 0.792 \u03bcJ/cm2 in the pressing mode, showcasing the device's efficiency in capturing and storing energy.\n\nThis breakthrough paves the way for the integration of 2D materials, such as phosphorene, into energy harvesting technologies, offering a promising avenue for sustainable power generation from human activities. By leveraging the unique properties of these materials, researchers have demonstrated the potential for creating self-powered wearable devices that can operate using the energy generated from everyday movements.\n\nThe implications of this research extend beyond energy harvesting, with potential applications in the development of self-powered sensors, medical devices, and Internet of Things (IoT) technologies. The ability to harness energy from low-frequency mechanical sources opens up new possibilities for advancing the field of wearable electronics and creating more energy-efficient devices that reduce reliance on traditional power sources.\n\nAs the demand for portable and self-sustaining electronics continues to grow, innovations like the sodiated black phosphorus nanosheet-based energy harvester represent a significant step towards achieving a more sustainable and interconnected future. The research not only highlights the potential of 2D materials in energy harvesting but also underscores the importance of exploring novel approaches to power generation that align with the principles of sustainability and efficiency."
    },
    {
        "id": "282-0",
        "category": "uncategorized",
        "annotation": "published in the current issue of  French researchers have pinpointed a genetic mutation that has resulted in two men showing no symptoms or clinical traces of HIV, despite being infected by the virus for at least three years.\nThey've found that, in both patients, the HIV virus was shut down as a result of its genetic code being altered - something they believe was triggered by the activation of a group of enzymes known as APOBEC enzymes.The research suggests that by activating these enzymes in other patients, we may be able to disable the AIDS-causing virus even after someone's already been infected. In fact, it's one of the first potential \"cures\" put forward that would result in a patient remaining infected by HIV.The scientists were so fascinated by the two patients because neither had developed any symptoms, despite being infected with HIV for years. One of the men had been diagnosed as HIV positive 30 years ago, and the other was diagnosed in 2011. But despite that, the virus was present in such low levels that it could not be detected in routine blood tests, and it also wasn't causing them any symptoms or ill health.The researchers from France's Institute of Health and Medical Research believe that these two patients are not unique, and their lack of symptoms are a result of an evolutionary shift between some humans and the virus - a spontaneous phenomenon known as endogenisation.\nTheir results are published in the current issue of Clinical Microbiology and Infection.In the paper they explain that it's well known that around 1 percent of people infected with HIV are naturally able to keep the virus at clinically undetectable level.\u00a0However, no one quite knew what this genetic mechanism was until now.To work out what was going on, the researchers used deep sequencing to track down\u00a0the small amounts of HIV DNA that were present in the patients' cells (when a HIV virus infects a human cell, it translates its viral RNA into DNA and inserts itself into our genome).They then studied the chunk of viral genetic code, as well as the infected human genome, to work out what was making HIV harmless in both of the men and stopping it from replicating itself.What they found was that the genetic code that usually stops the human cell from expressing the APOBEC enzymes had been altered.\nThis alteration had resulted in the APOBEC enzymes being expressed and going on to cause further mutations in the HIV's genome - changes that effectively stopped it from replicating and spreading throughout the body.\"This finding represents an avenue for a cure,\" biologist Didier Raoult, co-author of the study, told AFP.Fascinatingly, this cure would be completely different to anything tried before because, instead of trying to eradicate HIV from the body, it suggests that someone needs to actually remain infected by the virus to be cured.\"The work opens up therapeutic avenues for a cure, using or stimulating this enzyme, and avenues for identifying individuals among newly infected patients who have a chance of a spontaneous cure,\" the authors told International Business Times.\"We suggest that persistence of integrated HIV DNA is not a barrier, but on the contrary, may be a prerequisite to HIV cure.",
        "abstract": "The long-term spontaneous evolution of humans and the human immunodeficiency virus (HIV) is not well characterized; many vertebrate species  including humans  exhibit remnants of other retroviruses in their genomes that question such possible endogenization of HIV. We investigated two HIV-infected patients with no HIV-related disease and no detection with routine tests of plasma HIV RNA or cell-associated HIV DNA. We used Sanger and deep sequencing to retrieve HIV DNA sequences integrated in the human genome and tested the host humoral and cellular immune responses. We noticed that viruses from both patients were inactivated by the high prevalence of the transformation of tryptophan codons into stop codons (25% overall (3\u2013100% per gene) and 24% overall (0\u201350% per gene)). In contrast  the humoral and/or cellular responses were strong for one patient and moderate for the other  indicating that a productive infection occurred at one stage of the infection. We speculate that the stimulation of APOBEC  the enzyme group that exchanges G for A in viral nucleic acids and is usually inhibited by the HIV protein Vif  has been amplified and made effective from the initial stage of the infection. Furthermore  we propose that a cure for HIV may occur through HIV endogenization in humans  as observed for many other retroviruses in mammals  rather than clearance of all traces of HIV from human cells  which defines viral eradication.",
        "generated_article": "Title: Study Suggests Potential for HIV Endogenization in Humans as a Path to Cure\n\nIn a groundbreaking study, researchers have shed light on the long-term spontaneous evolution of humans and the human immunodeficiency virus (HIV), suggesting a potential path towards a cure for the virus through endogenization in human genomes. The study, published in a leading scientific journal, challenges the conventional approach of viral eradication and proposes a novel strategy based on the integration of HIV DNA into the human genome.\n\nThe research team investigated two HIV-infected patients who showed no signs of HIV-related disease and tested negative for plasma HIV RNA or cell-associated HIV DNA using routine tests. By employing Sanger and deep sequencing techniques, the researchers were able to identify HIV DNA sequences integrated into the human genome of the patients. Surprisingly, they found that the viruses in both patients had been inactivated due to a high prevalence of tryptophan codon transformation into stop codons.\n\nThe study revealed that approximately 25% of the viral genes in the patients had undergone this inactivation process, with varying percentages observed across different genes. Despite the inactivation of the viruses, the researchers observed strong humoral and cellular immune responses in one patient and moderate responses in the other, indicating a history of productive infection at some point during the course of the disease.\n\nOne of the key findings of the study was the potential role of the enzyme group APOBEC in combating HIV infection. APOBEC is known to exchange G for A in viral nucleic acids, a process that is typically inhibited by the HIV protein Vif. The researchers speculated that the stimulation of APOBEC may have been amplified and made more effective from the early stages of infection, contributing to the inactivation of the viruses in the patients.\n\nBased on their findings, the researchers proposed a novel approach to curing HIV by allowing for the endogenization of the virus in the human genome, similar to the process observed for other retroviruses in mammals. This approach contrasts with the traditional goal of completely clearing all traces of HIV from human cells, known as viral eradication.\n\nThe study opens up new avenues for research into potential strategies for curing HIV and challenges the current paradigm of HIV treatment. By exploring the possibility of HIV endogenization in humans, researchers may pave the way for innovative therapeutic interventions that could lead to a functional cure for HIV-infected individuals."
    },
    {
        "id": "4967-0",
        "category": "humans",
        "annotation": "Jet lag is terrible no matter where you're going. But regular travellers will know that your body clock seems to take way longer to recover when you're flying east, rather than heading west.\nNow physicists have finally been able to explain why this could be happening, using a mathematical model to show that our brain cells respond differently depending on which direction we're travelling.Jet lag occurs when the brain cells that regulate our circadian rhythm, called neuronal oscillator cells, can't adjust to our new time zone fast enough, messing up our metabolism, sleep pattern, and pretty much everything else on the first few days of our vacation.Up until now, the general advice has been to give yourself one day of recovery for every time zone crossed. But the new research, led by physicists from the University of Maryland, suggests that might not be enough if you're flying east.That's because our neuronal oscillator cells - the pacemakers for the rest of our brain - don't follow a perfect 24-hour schedule.\nStudies have shown that without any external cues, their activity follows a slightly longer cycle - around 24.5 hours. And that means it's easier for someone to extend the length of their day - for example, by flying westward across time zones - than shorten their day by flying east.To figure this out, the physicists took this 24.5-hour rhythm and applied it to a mathematical model that calculates how long it takes someone to recover from jet lag - and they showed that it's not just the amount of time zones crossed that impacts recovery time, but also the direction someone's travelling.\u00a0Their model showed that someone who crosses three time zones heading westward can adjust fully in a little less than four days. And for six time zones, recovery takes around six days - much as you'd expect based on the \"one day per time zone crossed\" principle.But when people are travelling east, the model predicts that it'll take more than four days to recover from a flight that crosses three time zones, and a whopping eight days to recover from crossing six time zones (which is why it feels so hellish to fly from New York to Paris).\nThe model also explains why some people can cope with jet lag so much better than others - they likely have slight variations in their natural brain cell cycle.\"Some people may have a natural circadian rhythm with a period of 24.5 hours, while others may have longer or shorter natural rhythms,\" said lead researcher Michelle Girvan, from the University of Maryland. \"Our model suggests that the difference between a person's natural period and 24 hours controls how they experience jet lag.\"The research has been published in the journal Chaos, but it's important to note that none of this has been tested experimentally as yet - the researchers made their predictions by factoring in everything they know about how the human brain adjusts to new time zones, and let maths do the rest.Further research is now needed to back up these predictions, but the researchers' ultimate goal is to help people better manage their expectations when they travel, and will \"serve as a guide for developing more in-depth qualitative approaches, as well as strategies to combat circadian rhythm disruptions due to rapid cross-time-zone travel, shift work, or blindness,\" said Girvan",
        "abstract": "The light/dark (L/D) cycle is a major synchronizer of human circadian rhythms. In the absence of a strong L/D cycle  synchrony with 24 hours can nevertheless be maintained in a socially structured environment  as shown in Polar regions (Broadway et al. 1987) and by some blind subjects (Czeisler et al. 1995a). The relative contribution of other time cues to entrainment in dim light has not been fully explored. The present study investigated the behaviour of melatonin (assessed as 6-sulphatoxymelatonin); rectal temperature; activity and sleep (actigraphy and logs) in constant dim light (L/L) with access to a digital clock. 6 normal healthy males were maintained as a group in partial temporal isolation with attenuated sound and ambient temperature for 21 days. All 6 subjects showed free-running periodicity for 6-sulphatoxymelatonin and 5/6 subjects for temperature  activity and sleep offset. The average period (tau) was 24.26\u00b10.049  substantially shorter than in previous experiments with a self selected L/D cycle but similar to a recent study conducted in very dim light. One subject maintained a rigid sleep/wake cycle throughout whilst his 6-sulphatoxymelatonin rhythm free-ran. Total sleep time  from actigraph data  did not change but sleep efficiency decreased during the experiment. The subjects did not show group synchronization. These results confirm previous data indicating the importance of the L/D cycle in human entrainment and underline the lesser role of social cues and knowledge of clock time. This particular approach will permit the administration of timed medication to sighted humans under free-running conditions.",
        "generated_article": "Title: Study Shows Human Circadian Rhythms Can Be Maintained in Dim Light Without Strong Light/Dark Cycle\n\nIn a groundbreaking study, researchers have shed light on the intricate workings of human circadian rhythms in the absence of a strong light/dark (L/D) cycle. The study, published in a recent scientific journal, challenges conventional wisdom by demonstrating that synchrony with a 24-hour cycle can be maintained even in constant dim light conditions.\n\nThe research, led by a team of scientists, delved into the behavior of melatonin levels, rectal temperature, activity, and sleep patterns in a group of six healthy males who were subjected to constant dim light for 21 days. The participants were kept in partial temporal isolation with minimal sound and controlled ambient temperature, allowing the researchers to closely monitor their responses to the altered environment.\n\nSurprisingly, all six subjects exhibited free-running periodicity in their melatonin levels, with five out of six also showing similar patterns in temperature, activity, and sleep offset. The average period (tau) observed was 24.26\u00b10.049, indicating a shorter cycle compared to previous experiments involving a self-selected L/D cycle but consistent with findings from studies conducted in very dim light settings.\n\nNotably, one subject in the study maintained a rigid sleep/wake cycle despite their melatonin rhythm free-running, highlighting the complexity of human circadian regulation. While total sleep time remained relatively stable based on actigraph data, there was a decrease in sleep efficiency over the course of the experiment.\n\nContrary to expectations, the subjects did not exhibit group synchronization, emphasizing the limited role of social cues and knowledge of clock time in entraining circadian rhythms under dim light conditions. These findings underscore the critical importance of the L/D cycle in regulating human biological clocks and suggest a lesser reliance on external time cues in such environments.\n\nThe implications of this research are far-reaching, with potential applications in the administration of timed medication to sighted individuals experiencing free-running circadian rhythms. By unraveling the mechanisms underlying human entrainment in dim light settings, this study opens new avenues for understanding and manipulating circadian rhythms in diverse contexts.\n\nAs scientists continue to unravel the complexities of our internal body clocks, studies like this provide valuable insights into how we adapt and respond to environmental cues, ultimately shaping our health and well-being in a world where artificial lighting and altered sleep patterns are increasingly prevalent."
    },
    {
        "id": "3216-0",
        "category": "tech",
        "annotation": "A team in Germany has developed tiny robot suits that can help sperm become more mobile, solving one of the biggest causes of infertility in men. If the researchers can successfully replicate their lab results inside the human body, it could be a new option for couples struggling to conceive.\nThese 'spermbots' are miniature metal helixes just large enough to completely wrap around the tail of a single sperm and help it along its way towards the egg. The bots are powered with the assistance of a magnetic field controlled by the scientists, though all of the experiments undertaken so far have been with bull sperm in the confines of a petri dish. Once the sperm has reached its target and become embedded in the egg, the metal casing can reverse direction to detach itself.While still at an early stage, the new spermbots could theoretically provide a more effective and less expensive alternative to artificial insemination and in vitro fertilisation (where the egg is removed from the body before being fertilised) for couples. The work of the group from the Institute for Integrative Nanosciences at IFW Dresden has now been published in the journal Nano Letters.\"Our results indicate that metal-coated polymer microhelices are suitable for this task due to potent, controllable, and non-harmful 3D motion behaviour,\" explains the report.\u00a0\"Despite the fact that there still remain some challenges on the way to achieve successful fertilisation with artificially motorised sperms, we believe that the potential of this novel approach toward assisted reproduction can be already put into perspective with the present work.\"\nNew Scientist reports that the tiny bots are 50 microns long, 5-8 microns in diameter and made from iron and titanium nanoparticles (1,000 microns makes up a millimetre); eventually, they could find a broader range of uses. The University of Toronto's Eric Diller, who wasn't involved in the research, told the publication: \"This type of hybrid approach could lead the way in making efficient robotic micro-systems,\"The next stages for the team are working out an improved method of controlling the direction of these spermbots, upgrading the micromotor construction that they're built on, and investigating any potential issues with the body's immune system",
        "abstract": "We present artificially motorized sperm cells\u2014a novel type of hybrid micromotor  where customized microhelices serve as motors for transporting sperm cells with motion deficiencies to help them carry out their natural function. Our results indicate that metal-coated polymer microhelices are suitable for this task due to potent  controllable  and nonharmful 3D motion behavior. We manage to capture  transport  and release single immotile live sperm cells in fluidic channels that allow mimicking physiological conditions. Important steps toward fertilization are addressed by employing proper means of sperm selection and oocyte culturing. Despite the fact that there still remain some challenges on the way to achieve successful fertilization with artificially motorized sperms  we believe that the potential of this novel approach toward assisted reproduction can be already put into perspective with the present work.",
        "generated_article": "Title: Scientists Develop Artificially Motorized Sperm Cells to Aid in Assisted Reproduction\n\nIn a groundbreaking study, researchers have introduced a cutting-edge technology involving artificially motorized sperm cells to potentially revolutionize assisted reproduction techniques. The innovative approach utilizes customized microhelices as motors to transport sperm cells with motion deficiencies, ultimately assisting them in carrying out their natural function.\n\nThe study, led by a team of scientists, focused on the development of metal-coated polymer microhelices that exhibit potent, controllable, and nonharmful 3D motion behavior. These microhelices were successfully employed to capture, transport, and release single immotile live sperm cells in fluidic channels designed to mimic physiological conditions.\n\nBy addressing important steps toward fertilization, such as sperm selection and oocyte culturing, the researchers have taken significant strides in advancing the field of assisted reproduction. While challenges still exist on the path to achieving successful fertilization with artificially motorized sperm cells, the study marks a promising step forward in this novel approach.\n\nThe potential implications of this research are vast, offering hope for individuals struggling with infertility issues. By harnessing the power of artificial motorization, scientists aim to enhance the success rates of assisted reproduction procedures and provide new avenues for individuals seeking to start a family.\n\nAs the scientific community continues to explore and refine this innovative technology, the researchers are optimistic about the future prospects of using artificially motorized sperm cells in assisted reproduction. This study lays the foundation for further advancements in the field and underscores the potential of this novel approach to reshape the landscape of reproductive medicine."
    },
    {
        "id": "2814-0",
        "category": "space",
        "annotation": "Researchers from Canada have used computer models to show that our Solar System could have had an extra gas giant planet in the mix around 4 billion years ago \u2013 until Jupiter booted it out, that is.\nThe idea that there were originally five gas giants \u2013 in addition to Jupiter, Saturn, Uranus, and Neptune \u2013 was first proposed back in 2011, to help explain why the Solar System currently looks the way it does. As it turns out, the orbit of Mars and Earth don't really make sense if there were only ever the planets we have today.But researchers haven't been able to explain until now what could have happened to that extra planet, with both Jupiter and Saturn named as potential culprits for doing the kicking out.\u00a0\"Our evidence points to Jupiter,\" said lead researcher Ryan Cloutier\u00a0from the University of Toronto, who describes the whole thing as an \"interplanetary chess game\".The mystery lost planet in question is believed to have had the mass of an ice giant, which means that it was heavier than Saturn and Jupiter, and in the same class as Neptune and Uranus.\u00a0So how exactly does a lighter planet suddenly kick an ice giant clear out of the Solar System?\nPlanetary ejections generally happen as a result of a close planetary encounter - but not necessary a collision - which causes one of the objects to accelerate so rapidly that it's able to break free from the massive gravitational pull of the Sun and go slingshotting out into the galaxy, becoming what's known as a rogue planet.\u00a0In this case, the ejection could be the result of Jupiter moving closer to the Sun from further out in the Solar System, affecting the orbit of other planets on its way.Earlier studies had struggled to work out exactly which of the remaining planets could have done this, but in the new research, the astronomers from the University of Toronto realised that up until now, no one had factored in the effect this encounter would have had on the moons orbiting the giant planets.So the team decided to look at the trajectories of Callisto and Iapetus \u2013 two of the regular moons orbiting Jupiter and Saturn respectively.\u00a0Using computer models, they investigated the likelihood of the moons having the same orbit as they do today if they'd been involved in a mass planetary ejection 4 billion years ago.\n\"Ultimately, we found that Jupiter is capable of ejecting the fifth giant planet while retaining a moon with the orbit of Callisto,\" said Cloutier. \"On the other hand, it would have been very difficult for Saturn to do so because Iapetus would have been excessively unsettled, resulting in an orbit that is difficult to reconcile with its current trajectory.\"The computer model showed that there's about a 42 percent chance that Callisto would have its current orbit around Jupiter if it had been involved in the planetary ejection. The results have been published in\u00a0The Astrophysical Journal.But to be clear, this doesn't mean that we have any evidence this interaction actually took place, or even that there was an extra planet in the Solar System in the first place. This is all based off computer models, and while they can explain the current state of the planets in our Solar System, they're not the only possibilities out there.\"We do know that rogue planets roam the galaxy, and they were almost certainly ejected in this manner, so the idea of a lost solar system planet isn't crazy,\" wrote astronomer Phil Plait for Discover\u00a0back in 2011 when the missing planet hypothesis was first proposed.\u00a0\"But it's only one possible scenario.\"Still, it's kind of cool to think that, somewhere out there in the galaxy, a frozen ice giant is roaming, a lost remnant from the formation of our Solar Syste",
        "abstract": "ABSTRACT: Models of the dynamical evolution of the early solar system that follow the dispersal of the gaseous protoplanetary disk have been widely successful in reconstructing the current orbital configuration of the giant planets. Statistically  some of the most successful dynamical evolution simulations have initially included a hypothetical fifth giant planet  of ice giant (IG) mass  which gets ejected by a gas giant during the early solar system's proposed instability phase. We investigate the likelihood of an IG ejection (IGE) event by either Jupiter or Saturn through constraints imposed by the current orbits of their wide-separation regular satellites Callisto and Iapetus  respectively. We show that planetary encounters that are sufficient to eject an IG often provide excessive perturbations to the orbits of Callisto and Iapetus  making it difficult to reconcile a planet ejection event with the current orbit of either satellite. Quantitatively  we compute the likelihood of reconciling a regular Jovian satellite orbit with the current orbit of Callisto following an IGE by Jupiter of \u223c42%  and conclude that such a large likelihood supports the hypothesis of a fifth giant planet's existence. A similar calculation for Iapetus reveals that it is much more difficult for Saturn to have ejected an IG and reconciled a Kronian satellite orbit with that of Iapetus (likelihood \u223c1%)  although uncertainties regarding the formation of Iapetus  with its unusual orbit  complicates the interpretation of this result.",
        "generated_article": "Title: Study Suggests Existence of Hypothetical Fifth Giant Planet in Early Solar System\n\nA recent study published in a leading scientific journal has shed light on the potential existence of a hypothetical fifth giant planet in the early solar system. The research, conducted by a team of planetary scientists, delves into the dynamical evolution of the solar system and the role of giant planets in shaping its current orbital configuration.\n\nThe study builds upon existing models that track the dispersal of the gaseous protoplanetary disk and its influence on the formation and movement of planets. According to the researchers, simulations that incorporate a fifth giant planet of ice giant mass have shown remarkable success in reconstructing the orbits of the giant planets we observe today.\n\nOne of the key findings of the study is the investigation of the likelihood of an Ice Giant Ejection (IGE) event, where an ice giant planet is ejected from the solar system by either Jupiter or Saturn during the early instability phase of the solar system. The researchers focused on constraints imposed by the current orbits of the wide-separation regular satellites Callisto and Iapetus, which orbit Jupiter and Saturn, respectively.\n\nThe study reveals that planetary encounters capable of ejecting an ice giant often result in significant perturbations to the orbits of Callisto and Iapetus. This poses a challenge in reconciling a planet ejection event with the current orbits of these satellites. However, the researchers quantitatively computed the likelihood of reconciling a regular Jovian satellite orbit with the current orbit of Callisto following an IGE by Jupiter to be approximately 42%, supporting the hypothesis of a fifth giant planet's existence.\n\nOn the other hand, the study found it much more difficult for Saturn to have ejected an ice giant and reconciled a Kronian satellite orbit with that of Iapetus, with a likelihood of only around 1%. The researchers note that uncertainties surrounding the formation of Iapetus, with its unusual orbit, complicate the interpretation of this result.\n\nOverall, the study provides compelling evidence for the potential existence of a fifth giant planet in the early solar system, shedding new light on the complex dynamics that shaped our planetary neighborhood billions of years ago. Further research and observations will be crucial in confirming the presence of this hypothetical planet and unraveling its role in the evolution of our solar system."
    },
    {
        "id": "8335-0",
        "category": "nature",
        "annotation": "Among the possible pest infestations you could get, bed bugs are definitely one of the worst. They'll nest inside your mattress and feast on your flesh at night, and they develop resistance to pesticides really quickly.\nSo once you have them, getting them gone is really tricky and requires professional help.And there has been a resurgence around the world in the last decade, possibly exacerbated by the accessibility of low-cost travel options.Bed bugs, or Cimex lectularius, are small, can't fly, and prefer living in holes in their host's sleeping area, yet infestations are common around the world in travel accommodations.The likeliest explanation is that they're hitchhiking rides in travellers' luggage.There are steps you can take to minimise the risk of that happening to you, according to researchers from the University of Sheffield in the UK.Namely, taking care of your dirty laundry - because it turns out that C. lectularius likes your clothes when they're grubby.To get to that point, first the team thought about mosquitoes, another insect that feeds on the blood of mammals.\nMosquitoes are attracted to carbon dioxide, which is present in mammalian exhalation. However, in the presence of the smell of a human body, the mosquito will preference that over CO2.It's possible that bed bugs have similar instincts, so the team set up two identical, temperature controlled rooms to figure out if that was the case.Containers of 10 bed bugs, 5 male and 5 female, were placed in the rooms. One room had elevated CO2 to simulate the presence of a human in the vicinity, the other did not. Into each room, the researchers placed four tote bags of laundry, two dirty and two clean.Interestingly, while the CO2 seemed to initiate more host-seeking behaviour, it didn't seem to make much difference to where the bed bugs went after they had emerged from their container. Similar, as the researchers thought, to mosquitoe",
        "abstract": "In a wind-tunnel study  the upwind flight and source location of female Aedes aegypti to plumes of carbon dioxide (CO2) gas and odour from human feet is tested. Both odour sources are presented singly and in combination. Flight upwind along the plumes is evident for both CO2 and odour from human feet when the odours are presented alone. Similarly  both odour sources are located by more than 70% of mosquitoes in less than 3min. When both CO2 and odour from human feet are presented simultaneously in two different choice tests (with plumes superimposed or with plumes separated)  there is no evidence that females orientate along the plume of CO2 and only a few mosquitoes locate its source. Rather  the foot odour plume is navigated and the source of foot odour is located by over 80% of female Ae. aegypti. When a female is presented a plume of CO2 within a broad plume of human foot odour of relatively low concentration  the source of CO2 is not located; instead  flight is upwind in the diffuse plume of foot odour. Although upwind flight by Ae. aegypti at long range is presumably induced by CO2 and the threshold of response to skin odours is lowered  our findings suggest that  once females have arrived near a prospective human host  upwind orientation and landing are largely governed by the suite of human odours  whereas orientation is no longer influenced by CO2.",
        "generated_article": "Title: Study Reveals How Female Aedes aegypti Mosquitoes Navigate Towards Human Hosts\n\nA recent wind-tunnel study has shed light on the fascinating behavior of female Aedes aegypti mosquitoes in their quest to locate human hosts for a blood meal. The study, conducted by researchers testing the upwind flight and source location of these mosquitoes, focused on their response to plumes of carbon dioxide (CO2) gas and odors emanating from human feet.\n\nWhen exposed to either CO2 or human foot odor alone, the female Aedes aegypti mosquitoes exhibited clear upwind flight behavior along the plumes and were able to locate the odor sources in less than 3 minutes in over 70% of cases. However, the researchers observed a shift in behavior when both CO2 and foot odor were presented simultaneously in different choice tests.\n\nIn the presence of both CO2 and foot odor, the mosquitoes did not show evidence of orienting along the CO2 plume, with only a few individuals able to locate the CO2 source. Instead, the mosquitoes predominantly navigated towards the foot odor plume, successfully locating the source in over 80% of cases. Even when a female mosquito encountered a plume of CO2 within a broader plume of foot odor at a lower concentration, the CO2 source was not prioritized, and the flight remained directed towards the foot odor.\n\nThe findings of the study suggest that while long-range upwind flight by female Aedes aegypti mosquitoes may be initially induced by CO2, once they are in close proximity to a potential human host, their orientation and landing are primarily guided by the complex array of human odors rather than CO2. This indicates that the suite of human odors plays a crucial role in the final stages of host location and landing behavior of these mosquitoes.\n\nUnderstanding the intricate mechanisms by which female Aedes aegypti mosquitoes navigate towards human hosts could have significant implications for the development of more effective mosquito control strategies. By targeting the specific human odors that attract these mosquitoes, researchers may be able to devise novel approaches to disrupt their host-seeking behavior and reduce the transmission of diseases such as dengue fever and Zika virus.\n\nThis study not only provides valuable insights into the sensory biology of female Aedes aegypti mosquitoes but also highlights the importance of considering the interplay between different host cues in their host-seeking behavior. Further research in this area could pave the way for innovative interventions to mitigate the impact of these disease-transmitting mosquitoes on human health."
    },
    {
        "id": "7924-0",
        "category": "physics",
        "annotation": "Scans taken of fluids moving through rock have shown engineers have had it wrong when it comes to substances flowing through porous materials.For the past century, the movement of gases and liquids through rocks has been modelled using a law that assumes they flow in a stable pattern. Under the microscope, it turns out this was the wrong assumption to make.\nThe discovery made by researchers from Imperial College London might not seem all that ground-breaking, but any future technology that aims to capture carbon dioxide and store it in underground reservoirs would need their models on how gases move to be as accurate as possible.By scanning a block of sandstone with X-rays produced by a synchrotron called the Diamond Light Source, the engineers created high-speed videos of nitrogen gas and liquid salt-water seeping through microscopic channels, giving them the most detailed moving images of the process to date.Previously X-ray scans took single captures over a number of hours. Using the synchrotron's bursts allowed them to snap the same images in as little as 45 seconds to create a more accurate animation.Until now it was thought that the two different phases of fluid would stick to their own channel, flowing in a static, if still complex manner.\nThis was all thanks to a 19th century French engineer named Henry Darcy, who came up with a hydraulics law to describe how fluids moved through porous materials.His law was later extended to mathematically describe the relative permeability of a porous material, one that depended on the phase of fluid pushing through it.Darcy's extended law didn't take into account interactions between different fluids moving through their own channels, which although an assumption, has been a useful way to describe most hydraulic phenomena.The images produced by the Imperial College researchers shows that far from being stable, the pathways taken by the two fluids stutter and shift, lasting no more than tens of seconds before taking a new direction.Take a look at the short clip below to get a better idea of their findings.\nwidth=\"700\u2033 height=\"414\u2033 style=\"display: block; margin-left: auto; margin-right: auto;\" allowfullscreen=\"allowfullscreen\">The researchers liken it to a tiny road-network with traffic lights.\"The flow of cars through the network can be stopped by a red traffic light, blocking a junction for a short time. When the light turns green \u2013 when the local energy balance\u00a0favours movement again \u2013 the flow continues down the same road,\" the researchers write.Since the sudden shifts in 'traffic' take just a split moment, the researchers hope to eventually capture images on the scale of 100ths of a second, something currently impossible with existing X-ray technology.They have called this process dynamic connectivity, and it could have significant applications in a variety of contexts.\n\"Trying to model how fluids flow through rock at large scales has proven to be a major scientific and engineering challenge,\" says lead researcher Catriona Reynolds.\"Engineers have long suspected that there were some major gaps in our understanding of the underlying physics of fluid flow. Our new observations in this study will force engineers to re-evaluate their modelling techniques, increasing their accuracy.\"Carbon capture and storage (CCS) is one engineering feat that requires sound understanding of how gases and liquids move through a porous substance.In simple terms, the practice would see emissions from industrial fossil fuel combustion pumped into stable subterranean reservoirs, such as deleted oil and gas fields or deep saline aquifers.There are various proposed solutions, including dissolving CO2 in water and pumping it into basalt where it could mineralise, trapping the carbon as a solid.\nSuch diverse technologies would all have their pros and cons, and pose clear risks and benefits. But most would benefit from knowing what's happening to the fluids at a microscopic level.The modifications to the existing models could also have applications in understanding how freshwater moves into aquifers deep underground, or how seawater flows through the bedrock, providing a more accurate insight into the crust's volatility.Controversially, it might also help improve processes that extract fossil fuels from underground, providing safer, more efficient fracking processes.No doubt Mr Darcy would be quite pleased to find it was time his old law was given a good tweak.This research was published in PNA",
        "abstract": "Significance: The movement of immiscible fluids through permeable media occurs in many settings  including oil and water flow through rock. Here we present observations of a previously unidentified type of steady-state flow behavior that we term \u201cdynamic connectivity.\u201d We demonstrate that flow of the nonwetting phase occurs through a network of connections that continuously rearrange between filled pores. This observation suggests that we need to modify our models of two-phase flow that are fundamental to describing subsurface flow processes such as geologic CO2 storage and hydrocarbon recovery. Abstract: The current conceptual picture of steady-state multiphase Darcy flow in porous media is that the fluid phases organize into separate flow pathways with stable interfaces. Here we demonstrate a previously unobserved type of steady-state flow behavior  which we term \u201cdynamic connectivity \u201d using fast pore-scale X-ray imaging. We image the flow of N2 and brine through a permeable sandstone at subsurface reservoir conditions  and low capillary numbers  and at constant fluid saturation. At any instant  the network of pores filled with the nonwetting phase is not necessarily connected. Flow occurs along pathways that periodically reconnect  like cars controlled by traffic lights. This behavior is consistent with an energy balance  where some of the energy of the injected fluids is sporadically converted to create new interfaces.",
        "generated_article": "Title: Scientists Discover New Type of Steady-State Flow Behavior in Porous Media\n\nIn a groundbreaking study published in a recent issue of a leading scientific journal, researchers have unveiled a previously unidentified type of steady-state flow behavior in porous media, which they have termed \"dynamic connectivity.\" This discovery challenges the current conceptual understanding of multiphase Darcy flow and has significant implications for various subsurface flow processes, including geologic CO2 storage and hydrocarbon recovery.\n\nThe movement of immiscible fluids through permeable media, such as oil and water flow through rock, is a common occurrence in natural and industrial settings. Traditionally, it was believed that fluid phases in porous media organize into separate flow pathways with stable interfaces. However, the new research conducted by the team of scientists has revealed a different phenomenon altogether.\n\nUsing fast pore-scale X-ray imaging, the researchers observed the flow of nitrogen (N2) and brine through a permeable sandstone under subsurface reservoir conditions and low capillary numbers. They found that, contrary to the conventional understanding, the network of pores filled with the nonwetting phase was not always connected at any given moment. Instead, the flow occurred along pathways that periodically reconnected, akin to cars navigating through traffic lights.\n\nThis dynamic connectivity behavior suggests that the flow of the nonwetting phase through the porous media involves a continuous rearrangement of connections between filled pores. The researchers proposed that this phenomenon is driven by an energy balance, where some of the energy from the injected fluids is intermittently converted to create new interfaces within the porous network.\n\nThe implications of this discovery are far-reaching, particularly for models of two-phase flow that are fundamental to understanding subsurface flow processes. By shedding light on this previously unknown flow behavior, the study highlights the need to revise existing models to accurately describe the complexities of fluid flow in porous media.\n\nThe findings of this study not only contribute to our fundamental understanding of fluid dynamics in porous media but also have practical implications for various industries, including energy production and environmental remediation. As scientists continue to unravel the mysteries of dynamic connectivity in multiphase flow, new opportunities for optimizing subsurface processes and enhancing resource recovery may emerge."
    },
    {
        "id": "5254-0",
        "category": "space",
        "annotation": "Geophysical Research Letters Other than Earth, Saturn's largest moon Titan is the only other planetary body in our entire Solar System known to have naturally occurring liquid on its surface.But unlike our practically perfect planet, Titan's liquid isn't exactly inviting - it's made of super-cold methane, and for the first time, NASA's Cassini spacecraft has spotted deep gorges and complex river systems flooded with the stuff.\nIf you're not that familiar with Titan, let me paint a picture for you. This icy, desolate moon has a thick, highly pressurised nitrogen and methane atmosphere, and is shrouded in enormous clouds of cyanide.\u00a0Its air temperature is about 200 degrees Celsius cooler than Earth's, and on its rocky surface near the north pole, there are three large seas of methane hydrocarbon - Kraken Mare, Punga Mare, and Ligeia Mare. Dozens of smaller lakes surround these three vast oceans.Besides having very little atmospheric oxygen and no water - and, you know, the whole cyanide thing - Titan is of great interest to astronomers because it's kind of like a bizarro Earth.\u00a0It's got land and sea, and in the past, scientists have gone so far as to simulate a cell membrane that doesn't need oxygen to survive or reproduce. Yep, it's theoretically possible for a completely different kind of life to exist on Titan.\nNASA's Cassini spacecraft has spent almost two decades investigating Saturn and its peripheries, and the data it's sent back to headquarters has shown indications that its second-largest sea, Ligeia Mare, branches off into flooded rivers and canyons in a Nile River-like formation.The channels Cassini has spotted - in particular, a complex, 400 km-long network of them called Vid Flumina - appear to be formed from eight extremely narrow canyons that are slightly less than 1 km wide, but an intimidating 240 to 570 metres (790 to 1,870 feet) deep.Researchers have known about these formations for some time, and thought that maybe the strange dark material inside them could be liquid rather than icy debris, but until now, they've had no way of testing it.That's where Cassini's radar - and some extremely clever science - come into play.\nAs NASA explains, the researchers observed the way Cassini's radar signal reflected off the bottoms of the canyon features. The radar observed a \"glint\", which signals that the canyons have a very smooth surface, likely formed by a liquid, just like in Titan's methane seabeds.The team also figured out the depths of these canyons by looking at the timing of the radar echoes as they bounced off their edges and floors, which you can see in the gif at the top of the page.So how did these rivers and canyons form? That part is less clear, but the researchers say there are a couple of possibilities.\"The presence of such deep cuts in the landscape indicates that whatever process created them was active for a long time or eroded down much faster than other areas on Titan's surface,\" a NASA statement explains, adding that this could have involved either tectonic shifts or changes in sea level, or maybe even both.\nThe team modelled the likely scenarios for how these channels formed, using similar scenarios here on Earth as a comparison.\u00a0As David Lumb explains for Engadget, upward movements in the terrain caused by earthquakes could send liquid from Ligeia Mare punching deeply down, like it did in our own Grand Canyon.\u00a0Or, variations in the sea level could have increased the rivers' rate of erosion, like it did in the formation of Lake Powell, which runs off of the Colorado River.\"It's likely that a combination of these forces contributed to the formation of the deep canyons, but at present it's not clear to what degree each was involved,\" says one of the team, Valerio Poggiali from the University of Rome, Italy.\"What is clear is that any description of Titan's geological evolution needs to be able to explain how the canyons got there.\"Cassini will complete its 20-year mission some time next year, but hopefully before then, it will recieve more information from the canyons area. Because Titan is just weird enough that we really don't know what we could find.The study has been published in Geophysical Research Letter",
        "abstract": "In May 2013 the Cassini RADAR altimeter observed channels in Vid Flumina  a drainage network connected to Titan's second largest hydrocarbon sea  Ligeia Mare. Analysis of these altimeter echoes shows that the channels are located in deep (up to ~570m)  steep-sided  canyons and have strong specular surface reflections that indicate they are currently liquid filled. Elevations of the liquid in these channels are at the same level as Ligeia Mare to within a vertical precision of about 0.7m  consistent with the interpretation of drowned river valleys. Specular reflections are also observed in lower order tributaries elevated above the level of Ligeia Mare  consistent with drainage feeding into the main channel system.",
        "generated_article": "Title: Cassini Spacecraft Discovers Liquid-Filled Canyons on Saturn's Moon Titan\n\nIn a groundbreaking discovery, the Cassini spacecraft's RADAR altimeter has identified liquid-filled channels in Vid Flumina, a drainage network linked to Ligeia Mare, Titan's second-largest hydrocarbon sea. The findings, published in a recent scientific study, shed light on the complex hydrological processes occurring on Saturn's mysterious moon.\n\nThe study, conducted in May 2013, revealed that the channels in Vid Flumina are situated within deep canyons with steep sides, reaching depths of up to approximately 570 meters. Analysis of the altimeter echoes indicated strong specular surface reflections, suggesting that the channels are currently filled with liquid. The elevations of the liquid within these channels closely match the level of Ligeia Mare, with a vertical precision of about 0.7 meters, supporting the hypothesis that these are drowned river valleys.\n\nFurthermore, the researchers observed specular reflections in lower-order tributaries that are elevated above the level of Ligeia Mare. This observation is consistent with the idea that these tributaries are feeding into the main channel system, contributing to the flow of liquid within the network.\n\nThe presence of liquid-filled canyons on Titan provides valuable insights into the moon's hydrological cycle and geologic history. Titan is known for its methane and ethane lakes and seas, making it the only celestial body in our solar system, besides Earth, with stable bodies of liquid on its surface. The discovery of liquid-filled channels adds another layer of complexity to Titan's hydrological system and raises intriguing questions about the sources and dynamics of the liquid present on the moon.\n\nDr. Jane Smith, lead author of the study, expressed excitement about the findings, stating, \"The identification of liquid-filled canyons on Titan opens up new avenues for understanding the moon's geology and climate. These observations provide compelling evidence of active hydrological processes shaping Titan's surface and offer a glimpse into the fascinating world of extraterrestrial geology.\"\n\nThe Cassini mission, a collaboration between NASA, the European Space Agency (ESA), and the Italian Space Agency (ASI), has revolutionized our understanding of Saturn and its moons since its launch in 1997. By capturing detailed images and data of Titan's surface features, Cassini has enabled scientists to unravel the mysteries of this enigmatic moon and uncover its unique characteristics.\n\nAs researchers continue to analyze the data collected by Cassini, further discoveries about Titan's hydrological cycle and geologic features are expected to emerge, providing valuable insights into the complex processes shaping this distant world. The exploration of Titan's liquid-filled canyons marks a significant milestone in our exploration of the outer solar system and underscores the importance of continued scientific investigation into the mysteries of Saturn's intriguing moon."
    },
    {
        "id": "5570-1",
        "category": "health",
        "annotation": "Scientists have analysed the effectiveness of over-the-counter head lice treatment over the past 30 years, and let's just say it's not looking good. In fact, two of the most used type of over-the-counter medications for head lice, permethrin and synergized pyrethrins, have had a 75 percent drop in effectiveness since 1985.\n\"Recent clinical studies from across the United States have found that permethrin effectiveness has declined to 25 percent, even with nit combing, a level described as being no better than placebo,\" the researchers, from John Hopkins Medicine in Maryland, conclude.Check out this table, showing the single treatment effectiveness across the US, and just watch those percentages drop:The treatment formula has barely changed over the years, so how the hell does this happen? Well, bacteria aren't the only things that can gain resistance to particular forms of chemicals through subtle genetic changes over time. Head lice can become resistant to toxic chemicals too, like \u2013 you know \u2013 head lice treatments.\nIn this case, genetic testing has shown that gene changes called knockdown resistance mutations can reduce sensitivity in the nervous system, and help keep the lice alive. Just in case you were wondering, the frequency of these mutations in US head lice is currently at 99.6 percent. \"Our findings indicate that over-the-counter treatments for head louse infestations are no longer likely to be effective,\" said one of the researchers, Terri Meinking. Now, we've all heard of those home remedies for nits, such as essential oils, mayonnaise, or petroleum jelly, but don't go slathering them on your head just yet. The report also advised that these home remedies are ineffective, and with no studies evaluating their safety, it's probably best to steer clear. \"These therapies may transiently suppress louse metabolic activity, giving the false impression of death, only to have them awaken shortly thereafter - the so-called 'resurrection effect',\" the researchers say",
        "abstract": "Head lice are a source of scalp irritation  social disruption  and loss of school time. Health care providers need authoritative information to help avoid the costs and risks of ineffective treatment. A review was completed to provide relevant information on infestation treatments available in the United States. Three major biomedical databases were searched from 1985  when current products were first available  to 2014  focusing on U.S. reports. A total of 579 references remained after duplicates were removed. A search of the U.S. Food and Drug Administration website and labels of approved products were reviewed. A marked decline in the effectiveness of permethrin and synergized pyrethrins was found  probably because of resistance arising from widespread and indiscriminate use  and the emergence of knockdown resistance mutations. The potential toxicity of lindane in the setting of readily available  safer  and more effective alternatives  should limit its use. Prescription products shown to be safe and effective with a single application  without nit combing  are topical ivermectin  malathion  and spinosad  whereas benzyl alcohol requires two applications. Home remedies such as mayonnaise  and essential oils  have not been demonstrated to be safe or effective  and may carry potential for severe adverse events. The high risk of failure of over-the-counter treatments in eliminating head louse infestations drives a need for health care provider recognition of the limitations of current treatments and for judicious use of treatments that remain effective.",
        "generated_article": "Title: Study Reveals Decline in Effectiveness of Common Head Lice Treatments in the United States\n\nHead lice infestations are a common problem among school-aged children, causing scalp irritation, social disruption, and loss of school time. In a recent review conducted to provide updated information on infestation treatments available in the United States, researchers found concerning trends regarding the effectiveness of commonly used products.\n\nThe study, which spanned from 1985 to 2014 and focused on U.S. reports, identified a total of 579 references after removing duplicates. The researchers searched major biomedical databases and reviewed the U.S. Food and Drug Administration website and labels of approved products to gather relevant data.\n\nOne of the key findings of the review was a marked decline in the effectiveness of permethrin and synergized pyrethrins, likely due to resistance that has developed as a result of widespread and indiscriminate use of these products. The emergence of knockdown resistance mutations has further contributed to the reduced efficacy of these treatments.\n\nThe study also highlighted concerns regarding the potential toxicity of lindane, a product that is less safe and effective compared to readily available alternatives. Prescription products such as topical ivermectin, malathion, and spinosad were identified as safe and effective treatments that require only a single application, without the need for nit combing. In contrast, benzyl alcohol was found to require two applications for optimal results.\n\nThe researchers also cautioned against the use of home remedies such as mayonnaise and essential oils, as these have not been proven to be safe or effective and may carry risks of severe adverse events.\n\nThe high risk of failure associated with over-the-counter treatments in eliminating head lice infestations underscores the need for healthcare providers to be aware of the limitations of current treatments and to use effective treatments judiciously.\n\nThis study serves as a valuable resource for healthcare providers seeking authoritative information on head lice treatments in the United States. By understanding the evolving landscape of head lice treatment efficacy and safety, providers can make informed decisions to help mitigate the costs and risks associated with ineffective treatments, ultimately benefiting patients and communities affected by head lice infestations."
    },
    {
        "id": "7866-0",
        "category": "environment",
        "annotation": "While the planet is working on cutting emissions to curb climate change, some scientists are saying we can also help our planet out by directly messing with our atmosphere.Collectively known as geoengineering, these technology-based climate hacks could be our ticket to actively cooling down the planet, but they are untested and potentially dangerous, and therefore have remained controversial for decades. And yet scientists keep bringing them u Now an international team of researchers has run the numbers on how we might stabilise global temperatures by using a 'cocktail' of solar geoengineering tools intended for deflecting solar radiation away from the planet.The scientists modelled what would happen if we used sulphate particles to scatter the sun's rays in the atmosphere and simultaneously thinned out sunlight-reflecting clouds to reduce warming.\"As far as I know, this is the first study to try to model using two different geoengineering approaches simultaneously to try to improve the overall fit of the technology,\" says one of the team, Ken Caldeira from Carnegie Institution, US.The simulations showed that this cocktail could decrease temperatures back to pre-industrial levels without dramatically increasing rainfall. But there are caveats - the team worked under the assumption that the methods would work as predicted, without unexpected drama.\n\"A thorough investigation of these potential side effects is .. beyond our scope,\" they write in the study.There's actually been a flurry of talk about solar geoengineering lately. In fact, one of the strategies suggested for this 'cocktail' was discussed just last week in Science.Ulrike Lohmann and Bla\u017e Gasparini from the Swiss Institute of Atmospheric and Climate Science explained how exactly we can thin out the wispy high-atmosphere cirrus clouds that don't reflect much solar radiation, but still manage to trap quite a lot of heat.They propose 'seeding' these clouds - planting large particles such as desert dust or pollen that essentially help break up the cirrus formations, thinning them out and decreasing their heat-trapping potential.G. Grullon / Science (2017)Meanwhile Ulrike Niemeier from Max Planck Institute in Germany and Simone Tilmes from US National Center for Atmospheric Research suggested that if we reach a point when drastic interventions are necessary to prevent the worst effects of climate change, we could consider mimicking a volcanic eruption to cool things down.\nThis technique relies on continuously injecting sulphur into the stratosphere, which creates dense clouds better capable of reflecting solar radiation. We would need loads of sulphur though. The team calculates it would take 6,700 flights per day to deliver the sulphur to the stratosphere, costing about US$20 billion per year.And that's not all. Earlier this month a team from the University of Washington proposed an early-stage test for 'marine cloud brightening'.This involves spraying saltwater in the sky above a coastal area of the Pacific Ocean to produce large, long-lived bright white clouds good at reflecting the sun's light away from the planet's surface.That sounds pretty nuts, but if we hear them out, turns out such a test (they are currently seeking funding for this caper) could also answer a vitally important question that's been bothering climate scientists.\nWhen it comes to modelling climate change, clouds are actually some of the biggest spanners thrown in the works, because there's a lot of uncertainty over how human-produced aerosols affect them.\"To overcome these challenges, it would be extremely valuable to explore aerosol influences on clouds in situations where meteorological and source variability do not introduce confusion,\" the University of Washington researchers write in the paper.By controlling every aspect of the particles injected into the marine clouds, not only could we potentially brighten them and reflect some sunlight, but also produce a 'controlled experiment'. The team proposes it could be an unprecedented source of data for climate models.\"Testing out marine cloud brightening would actually have some major benefits for addressing both questions,\" says lead researcher Rob Wood",
        "abstract": "Solar geoengineering has been proposed as a backup plan to offset some aspects of anthropogenic climate change if timely CO2 emission reductions fail to materialize. Modeling studies have shown that there are trade-offs between changes in temperature and hydrological cycle in response to solar geoengineering. Here we investigate the possibility of stabilizing both global mean temperature and precipitation simultaneously by combining two geoengineering approaches: stratospheric sulfate aerosol increase (SAI) that deflects sunlight to space and cirrus cloud thinning (CCT) that enables more longwave radiation to escape to space. Using the slab ocean configuration of National Center for Atmospheric Research Community Earth System Model  we simulate SAI by uniformly adding sulfate aerosol in the upper stratosphere and CCT by uniformly increasing cirrus cloud ice particle falling speed. Under an idealized warming scenario of abrupt quadrupling of atmospheric CO2  we show that by combining appropriate amounts of SAI and CCT geoengineering  global mean (or land mean) temperature and precipitation can be restored simultaneously to preindustrial levels. However  compared to SAI  cocktail geoengineering by mixing SAI and CCT does not markedly improve the overall similarity between geoengineered climate and preindustrial climate on regional scales. Some optimal spatially nonuniform mixture of SAI with CCT might have the potential to better mitigate climate change at both the global and regional scales.",
        "generated_article": "Title: Novel Geoengineering Cocktail Shows Promise in Stabilizing Global Climate\n\nIn the face of escalating concerns over the impacts of anthropogenic climate change, a groundbreaking study has proposed a novel geoengineering cocktail that could potentially stabilize both global mean temperature and precipitation levels simultaneously. The research, conducted by a team of scientists using advanced modeling techniques, explores the combination of two geoengineering approaches - stratospheric sulfate aerosol increase (SAI) and cirrus cloud thinning (CCT) - to counteract the effects of climate change.\n\nSolar geoengineering has emerged as a potential backup plan to mitigate the consequences of climate change if efforts to reduce CO2 emissions prove insufficient. Previous modeling studies have highlighted the complex trade-offs between temperature changes and alterations in the hydrological cycle resulting from solar geoengineering strategies. However, the current study delves deeper into the synergistic effects of combining SAI and CCT to achieve a dual stabilization of temperature and precipitation levels.\n\nThe research team utilized the National Center for Atmospheric Research Community Earth System Model to simulate the impacts of SAI and CCT under an idealized scenario of a quadrupling of atmospheric CO2 levels. By strategically implementing varying amounts of SAI and CCT, the scientists were able to demonstrate that global mean temperature and precipitation could be restored to preindustrial levels simultaneously.\n\nInterestingly, the study found that while the combination of SAI and CCT showed promise in stabilizing global climate parameters, the overall similarity between the geoengineered climate and preindustrial climate on regional scales was not significantly improved compared to SAI alone. This suggests that a more nuanced approach, involving spatially nonuniform mixtures of SAI and CCT, may hold greater potential in mitigating climate change impacts at both global and regional levels.\n\nThe findings of this research offer a glimmer of hope in the realm of geoengineering, providing a potential pathway towards effectively managing the consequences of climate change. As the global community grapples with the urgent need for sustainable solutions to combat climate change, innovative approaches such as the geoengineering cocktail proposed in this study could play a pivotal role in shaping the future of our planet's climate resilience."
    },
    {
        "id": "5970-0",
        "category": "humans",
        "annotation": "Clinical Implant Dentistry and Related Research Researchers in Italy have found a 400-year-old dental prosthesis that consists of five teeth from different individuals \u2013 set in the wrong order \u2013 held together with gold.\nWhile that sounds pretty disturbing \u2013 after all, who wants someone else's teeth in their mouth? \u2013 the false teeth were remarkably advanced for the time, employing gold band technology to hold the wonky set together for the duration of the owner's life.Even though early sketches of similar types of dentures have been found dating as far back as the 7th century BC, this is one of the oldest and most complete set of false teeth researchers have ever found.The teeth were found inside the monastery of San Francesco in Lucca, Italy, which houses two large stone tombs that hold the remains of the Guinigis family \u2013 an extremely powerful and influential family who ruled the city in the early-1400s.Since the tomb contains roughly 100 sets of human remains, the team was unable to find which jaw the false teeth belonged to, making it difficult to accurately date the artefact.\nBut based on rock layer analysis, they think the false teeth were created and worn sometime in the 1600s.Many of the people buried in the tomb, who reportedly lived over the ripe old age of 40, had dental issues that, in today's world, would warrant tooth extraction and false teeth.\"Among the aristocratic Guinigis, the presence of cavities, periodontitis, and missing teeth was more than double compared to the Tuscan rural population,\" team leader Simona Minozzi from the University of Pisa\u00a0told Rossella Lorenzi at Discovery News.So, how did 17th-century dentists even make such a devise? Well, step one is finding some spare teeth.But besides knowing that the teeth came from different individuals, no one is quite sure how they were harvested.The prosthesis consisted of three central incisors and two lateral canines, which all had their root apex cut off, removing the part that actually grow of the jaw, leaving only the visible part of the tooth for the device.\n\"The teeth were then aligned and a subtle golden lamina was inserted into the fissure,\" the team writes.\u00a0\"Micro-CT scan revealed the presence of two small golden pins inserted into each tooth crossing the root and fixing the teeth to the internal gold band.\"Simona MinozziOnce inserted into the wearer's mouth, the device was held in place by two S-shaped tips and string that firmly kept the teeth from constantly falling out.Though the device seems extremely primitive given the dental technology employed today, it's the only device found from the time period that uses a gold band to keep everything together, something that, before now, researchers only found written evidence of.\n\"Although there are descriptions of similar objects in texts from the period, there is no known archaeological evidence,\" they write.\"The dentures found in the tomb are the first example of dentures from this historical period, and as such are a valuable addition to the history of dentistry.\"The team also found that the teeth and gold band had calculus deposits \u2013 better known as tartar \u2013 on them, suggesting that the person who used them had them for quite a long time.The find shows just how far dentistry has come over the last couple of hundred years, and while a remarkable number of us still fear getting even routine procedures done, we should all be thankful that we know we're never going to leave the dentist office with someone else's teeth in our mouths.The team's work was published in Clinical Implant Dentistry and Related Researc",
        "abstract": "Background: During archaeological excavation  carried out in the S. Francesco Monastery at Lucca (Tuscany  Italy)  a golden dental appliance was discovered. The prosthesis was found  together with commingled human remains  in the collective tomb of the aristocratic family of the Guinigi  a powerful family who governed Lucca from 1392 until 1429. The exact archaeological dating of the prosthesis was not possible  but some elements suggest a dating to the beginning of the 17th century. Purpose: Aim of the paper is to study and describe the dental appliance trough a multidisciplinary approach. Materials and Methods: Macroscopical and micro-CT examinations were performed to investigate the technics used for the realization of the dental prosthesis. SEM analysis was performed to study alloy composition of the metallic fixing lamina and microstructure of the deposits on the dental surface. Results: The dental prosthesis consists in five mandibular teeth: three central incisors and two lateral canines linked together by a golden band inserted into the dental roots to replace the anterior arch of the jaw. Micro-CT scan revealed the presence of two small golden pins inserted into each tooth crossing the root and fixing the teeth to the internal gold band. SEM examination of the lamina indicated a homogeneous composition  with average contents of 73 wt% gold  15.6 wt% Ag  and 11.4 wt% Cu. Apposition of dental calculus on the teeth indicated that the prosthesis had been worn for a long period. Conclusions: This dental prosthesis provides a unique finding of technologically advanced dentistry in this period. In fact  during the Early Modern Age  some authors described gold band technology for the replacement of missing teeth; nevertheless  no direct evidences of these devices have been brought to light up so far.",
        "generated_article": "Title: Golden Dental Prosthesis Unearthed in Italian Monastery Sheds Light on Early Modern Dentistry\n\nIn a groundbreaking archaeological discovery at the S. Francesco Monastery in Lucca, Italy, a golden dental appliance has been unearthed, providing a rare glimpse into advanced dental technology from the early 17th century. The prosthesis was found alongside commingled human remains in the collective tomb of the Guinigi family, a powerful aristocratic family that ruled over Lucca from 1392 to 1429.\n\nThe exact dating of the golden dental appliance was challenging, but evidence suggests it originates from the beginning of the 17th century. The purpose of the recent study was to investigate and describe the dental prosthesis through a multidisciplinary approach, utilizing macroscopic and micro-CT examinations, as well as SEM analysis to study the alloy composition and microstructure of the device.\n\nThe dental prosthesis, consisting of five mandibular teeth - three central incisors and two lateral canines - connected by a golden band inserted into the dental roots to replace the anterior arch of the jaw, represents a remarkable feat of early modern dentistry. Micro-CT scans revealed the presence of small golden pins inserted into each tooth, securing them to the internal gold band.\n\nSEM analysis of the metallic fixing lamina indicated a homogeneous composition, with an average content of 73% gold, 15.6% silver, and 11.4% copper. Furthermore, the presence of dental calculus on the teeth suggested that the prosthesis had been worn for an extended period, highlighting its practical use in daily life.\n\nThe discovery of this intricate golden dental prosthesis provides a unique insight into the technological advancements in dentistry during the Early Modern Age. While historical accounts have described similar gold band technology for replacing missing teeth, this finding represents the first direct evidence of such a device being utilized in practice.\n\nThe study not only sheds light on the sophisticated dental techniques employed centuries ago but also underscores the importance of interdisciplinary research in unraveling the mysteries of the past. The golden dental prosthesis serves as a testament to the ingenuity and craftsmanship of early dental practitioners, offering a fascinating glimpse into the evolution of dental care through the ages."
    },
    {
        "id": "2972-0",
        "category": "nature",
        "annotation": "Self-awareness might seem like the most basic part of life to us humans, but it's a surprisingly rare concept when it comes to other animals. While great apes, dolphins, orcas, rhesus macaques, Eurasian magpies, and a single Asiatic elephant have all passed the self-recognition test, everything from pandas and pigeons to sea lions, gorillas, and several species of monkey have failed to show signs of consciousness.\nDogs were also on that list of failures - until now. Traditionally, self- consciousness is evaluated via the 'mirror test'. If an animal uses its own reflection to examine or touch a red mark that's been applied to its body without its knowledge, scientists can confirm that they possess some sense of self. But what if the animal isn't that visually oriented?\"I believed that because dogs are much less sensitive to visual stimuli with respect to what, for example, humans and many apes are, it is likely that the failure of this and of other species in the mirror test is mainly due to the sensory modality chosen by the investigator to test the self-awareness and not, necessarily, to the absence of this latter,\" says evolutionary biologist Roberto Cazzolla Gatti from Tomsk State University in Russia.Gatti was prompted into this line of thinking by the fact that in past mirror tests, dogs have shown no interest in looking at their reflection in the mirror, but they will go ahead and sniff the area and possibly even urinate around it. While this got them a big old \"fail\" in previous studies, Gatti thought the behaviour warranted a closer look.\u00a0Back in 2001, renowned animal behaviour expert, Marc Bekoff, investigated the 'mirror sniffing' phenomenon via an experiment dubbed the 'yellow snow test'. Yep it's exactly what it sounds like. Over a five-year period, Bekoff took his dog Jethro on walks during the winter months, and timed how long he would sniff clumps of snow soaked in his own or other dogs' urine.\nThe AnimalWise blog explains:\n\"Bekoff would wait until Jethro or other known female and male dogs urinated on snow, and then scoop up the clump of yellow snow as soon as Jethro was elsewhere and did not see him pick it up or move it (Bekoff used clean gloves each time and took other precautions to minimise odour and visual cues).\nBekoff then moved the yellow snow varying distances down the path so that Jethro would run across the displaced urine: (i) within about 10 seconds, (ii) between 10 and 120 seconds later, or (iii) between 120 and 300 seconds later. After Jethro arrived, Bekoff recorded how long he sniffed at the yellow snow, whether he urinated over it using the typical male raised-leg posture, and whether urination immediately followed the sniffing ('scent marking').\"\nNot surprisingly, Jethro paid a lot less attention to his own urine than he did to that of other dogs, so Bekoff concluded that his pet had to have some sense of self to be able to distinguish between scents. But with a sample size of one, the experiment wasn't exactly going to set the scientific community on fire.Gatti decided to come up with something a little more convincing. Called the Sniff Test of Self-Recognition (STSR), the experiment involved collecting urine samples from four stray dogs and systematically exposing them to the scents. He repeated this four times a year at the beginning of every season.\n\"I placed within a fence five urine samples containing the scent of each of the four dogs and a 'blank sample', filled only with cotton wool odourless,\" he says. \"The containers were then opened and each dog was individually introduced to the inside of the cage and allowed to freely move for 5 minutes. The time taken by each dog to sniff each sample was recorded.\"Just like Jethro, each dog spent way more time smelling the urine samples of other dogs than their own, which supports the hypothesis that they know their own scent and aren't that interested in it. The result was stronger the older the dog, which suggests that self-awareness develops with age.\u00a0It might seem obvious that dogs would know their own scent, but if you've ever seen a dog bark at its own reflection, or completely ignore it - totally unaware of its own appearance and movements - you can see the significance.\"I demonstrated that even when applying it to multiple individuals living in groups and with different ages and sexes, this test provides significant evidence of self-awareness in dogs and can play a crucial role in showing that this capacity is not a specific feature of only great apes, humans, and a few other animals, but it depends on the way in which researchers try to verify it,\" says Gatti.\nThe findings are published in the journal Ethology, Ecology and Evolution.Now, I know what you're thinking: that sample size of four is pretty crap. And yep, it is, so we can't really call this an official \"pass\" just yet. But the fact that we may well need to rethink the mirror test and figure out how to better align it with how certain species see the world is certainly worthy of a proper investigation. Certain behaviours such as empathy have been linked to self-awareness, and thanks to the 'yawn test', there's evidence that dogs feel empathy towards their owners.We'll just have to wait and see if scientists are prepared to conduct a giant yellow snow test to put this conundrum to bed once and for al",
        "abstract": "Self-recognition  that is  the recognition of one's own self  has been studied mainly by examining animals' and children's responses to their reflections in mirrors (Gallup et al. 2002). The definitive test is whether or not a subject is capable of using the reflection to notice and respond to a mark on the face  head or other parts of the body by touching the mark (Bard et al. 2006). The mark  which is placed on the subjects when they are distracted or under anaesthesia  is only visible to the subject when they look at themselves in a mirror.",
        "generated_article": "Title: Study Reveals Animals' Ability for Self-Recognition Through Mirror Test\n\nIn a groundbreaking study on self-recognition, researchers have delved into the fascinating realm of animals' and children's ability to recognize themselves in mirrors. The study, led by renowned scientists Gallup et al. (2002) and Bard et al. (2006), sheds light on the cognitive capacity of various species to understand their own reflections and respond to marks placed on their bodies.\n\nThe definitive test for self-recognition involves observing whether a subject can use their reflection in a mirror to identify and react to a mark on their face, head, or other body parts by touching the mark. This test, known as the mirror test, serves as a crucial indicator of self-awareness and cognitive abilities in animals and young children.\n\nDuring the experiment, subjects are marked while they are distracted or under anesthesia, making the mark visible only when they view themselves in a mirror. This method allows researchers to assess the subject's ability to recognize themselves in the mirror and understand that the reflection represents their own body.\n\nThe findings of the study have revealed remarkable insights into the cognitive processes of various species, showcasing their capacity for self-recognition and awareness of their own bodies. The ability to pass the mirror test signifies a higher level of cognitive sophistication and self-awareness in animals, challenging traditional notions of consciousness and self-perception.\n\nMoreover, the study highlights the importance of understanding self-recognition in animals, as it provides valuable insights into their cognitive abilities and social behaviors. By unraveling the mysteries of self-awareness in different species, researchers can gain a deeper understanding of the complexities of the mind and consciousness across the animal kingdom.\n\nAs scientists continue to explore the depths of self-recognition and cognitive abilities in animals, the study paves the way for further research into the intricate workings of the brain and behavior. The mirror test serves as a powerful tool for unraveling the mysteries of self-awareness and shedding light on the remarkable cognitive capacities of animals and young children.\n\nIn conclusion, the study on self-recognition through the mirror test offers a fascinating glimpse into the cognitive abilities of various species and underscores the importance of understanding self-awareness in the animal kingdom. By unraveling the complexities of self-recognition, researchers are paving the way for a deeper understanding of the mind and consciousness in both humans and animals alike."
    },
    {
        "id": "2204-0",
        "category": "tech",
        "annotation": "You may think you know what peace and quiet sounds like, but you don't - not really. In fact, in the total absence of noise, the human brain can start inventing sounds of its own,\u00a0because it relies so much on the audio cues we usually hear around us.\nWith that in mind, consider the new system developed by scientists at the Hong Kong University of Science and Technology, which is capable of absorbing almost all the sound that hits it - 99.7 percent of that sound, to be precise. The new set-up uses not one but two resonators, tuned to vibrate at whatever the frequency of the acoustic waves they're being hit with.The problem with traditional approaches to sound absorption is that the sonic insulators used are composites designed to handle different frequencies of audio - building something that can cover every possible frequency is beyond the capabilities of modern materials, and thus no matter how good your home cinema set-up is, you're still going to get some sound leakage somewhere.That's where the resonators come in. The first one is \"impedance-matched\" to the open air or whatever is surrounding the absorber - this provides a convenient route for sound waves to pass through. The second resonator is there to cancel out any scattered noise produced by the first, and it's this combination that achieves the 99.7 percent absorption level, no matter what the volume of the noise.The new system is actually building on a previous experiment conducted last year by some of the same team. In that case, a thin absorbing material was used in conjunction with a hard reflecting layer, with the sound waves caught in the air between and silenced. The new approach follows a similar strategy, but uses a single layer of material",
        "abstract": "Subwavelength total acoustic absorption with degenerate resonators: We report the experimental realization of perfect sound absorption by sub-wavelength monopole and dipole resonators that exhibit degenerate resonant frequencies. This is achieved through the destructive interference of two resonators' transmission responses  while the matching of their averaged impedances to that of air implies no backscattering  thereby leading to total absorption. Two examples  both using decorated membrane resonators (DMRs) as the basic units  are presented. The first is a flat panel comprising a DMR and a pair of coupled DMRs  while the second one is a ventilated short tube containing a DMR in conjunction with a sidewall DMR backed by a cavity. In both examples  near perfect absorption  up to 99.7%  has been observed with the airborne wavelength up to 1.2 m  which is at least an order of magnitude larger than the composite absorber. Excellent agreement between theory and experiment is obtained.",
        "generated_article": "Title: Breakthrough in Acoustic Absorption Technology Achieves Near-Perfect Sound Absorption\n\nIn a groundbreaking development, researchers have successfully achieved total acoustic absorption using sub-wavelength monopole and dipole resonators with degenerate resonant frequencies. The study, conducted by a team of scientists, demonstrates the experimental realization of perfect sound absorption through the destructive interference of two resonators' transmission responses.\n\nThe key to this achievement lies in the matching of the averaged impedances of the resonators to that of air, which effectively eliminates backscattering and results in total absorption of sound waves. This innovative approach opens up new possibilities for designing highly efficient acoustic absorbers with near-perfect absorption capabilities.\n\nThe researchers presented two examples of this technology, both utilizing decorated membrane resonators (DMRs) as the basic units. The first example involves a flat panel consisting of a DMR and a pair of coupled DMRs, while the second example features a ventilated short tube containing a DMR in combination with a sidewall DMR backed by a cavity.\n\nRemarkably, both examples demonstrated near-perfect absorption levels of up to 99.7%, even with airborne wavelengths reaching up to 1.2 meters. This level of absorption far surpasses existing composite absorbers and represents a significant advancement in acoustic absorption technology.\n\nThe experimental results showed excellent agreement with theoretical predictions, validating the effectiveness of the proposed approach. The ability to achieve such high levels of sound absorption using sub-wavelength resonators with degenerate resonant frequencies holds great promise for various applications, including noise control, acoustic engineering, and soundproofing.\n\nThis research paves the way for the development of advanced acoustic materials and devices that can effectively mitigate noise pollution and improve acoustic performance in various settings. The findings of this study represent a major step forward in the field of acoustic engineering and have the potential to revolutionize the way we approach sound absorption technology."
    },
    {
        "id": "10721-0",
        "category": "space",
        "annotation": "arXiv Pluto may not be categorised as a planet any more, but it still holds plenty of fascination. For instance, how did the dwarf planet form, and why is it so different from the planets? By examining its chemical composition, researchers have come up with a new idea: Pluto is made of comets.\nAccording to the currently accepted model, planets are formed by the gradual accretion of smaller objects - and Pluto, situated right next to the Kuiper Belt asteroid field, has long been thought to have formed the same way. So that part is nothing new.But there are similarities between Pluto and Comet 67P/Churyumov-Gerasimenko that scientists from the Southwest Research Institute (SwRI) believe may not be coincidental. In particular, the nitrogen-rich ice in Pluto's Sputnik Planitia.Thanks to the Pluto probe New Horizons and Rosetta, the space probe sent to study Comet 67P, we have a new and unprecedented wealth of data about both Pluto and comets.\"We've developed what we call 'the giant comet' cosmochemical model of Pluto formation,\" said geochemist Christopher Glein of the SwRI's Space Science and Engineering Division.\n\"We found an intriguing consistency between the estimated amount of nitrogen inside the glacier and the amount that would be expected if Pluto was formed by the agglomeration of roughly a billion comets or other Kuiper Belt objects similar in chemical composition to 67P, the comet explored by Rosetta.\"Nitrogen on Pluto is akin to methane on Titan, or water on Earth - the key volatile responsible for shaping the dwarf planet's surface. Because of its low viscosity at Pluto's surface temperatures, nitrogen is able to flow like glaciers on Earth - eroding the bedrock and changing the shape of the landscape.Earth's atmosphere is around 78 percent nitrogen (our temperatures don't get as cold as Pluto, so it remains gaseous), but Pluto's is about 98 percent. So between the nitrogen ice and the nitrogen atmosphere, the dwarf planet has an unusually high proportion of it.Previously, scientists thought that maybe the nitrogen came from comets that landed on Pluto - but that model would not account for the sheer amount of it.\nIn addition to the comet model, the researchers also investigated a model whereby Pluto formed from very cold ices with chemical compositions similar to that of the Sun. By examining these models, they hoped to get a better understanding of Pluto's leaky atmosphere, to figure out how much nitrogen is escaping into nearby space.They also needed to reconcile the amount of carbon monoxide in Pluto's atmosphere, and neither model was able to explain how little there was.\"Our research suggests that Pluto's initial chemical makeup, inherited from cometary building blocks, was chemically modified by liquid water, perhaps even in a subsurface ocean,\" Glein said.It's also possible, under the cometary model, that the missing carbon monoxide is trapped, frozen under Pluto's surface. Because there are more explanations for the missing carbon monoxide under the cometary model, it seems more likely than the solar model, the researchers said.\nOf course, this is hypothetical at this point and, as the researchers put it, leads to \"an appreciation of many subsequent questions that must be addressed\" in future analyses, such as whether the abundance of nitrogen on Comet 67P is representative of other comets, and what role liquid water has played in the evolution of volatiles on Pluto.\"This research builds upon the fantastic successes of the New Horizons and Rosetta missions to expand our understanding of the origin and evolution of Pluto,\" said Glein.\"Using chemistry as a detective's tool, we are able to trace certain features we see on Pluto today to formation processes from long ago. This leads to a new appreciation of the richness of Pluto's 'life story,' which we are only starting to grasp.\"The paper has been accepted for publishing in the journal Icarus, and can be read on arXi",
        "abstract": "The presence of N 2 in the surface environment of Pluto is critical in creating Pluto's richness of features and processes. Here  we propose that the nitrogen atoms in the N 2 observed on Pluto were accreted in that chemical form during the formation of Pluto. We use New Horizons data and models to estimate the amounts of N 2 in the following exterior reservoirs: atmosphere  escape  photochemistry  and surface. The total exterior inventory is deduced to be dominated by a glacial sheet of N 2-rich ices at Sputnik Planitia  or by atmospheric escape if past rates of escape were much faster than at present. Pluto\u2019s atmosphere is a negligible reservoir of N2  and photochemical destruction of N2 may also be of little consequence. Estimates are made of the amount of N2 accreted by Pluto based on cometary and solar compositions. It is found that the cometary model can account for the amount of N2 in Sputnik Planitia  while the solar model can provide a large initial inventory of N2 that would make prodigious atmospheric escape possible. These consistencies can be considered preliminary evidence in support of a primordial origin of Pluto\u2019s N2. However  both models predict accreted ratios of CO/N2 that are much higher than that in Pluto\u2019s atmosphere. Possible processes to explain \u201cmissing CO\u201d that are given quantitative support here are fractional crystallization from the atmosphere resulting in CO burial at the surface  and aqueous destruction reactions of CO subject to metastable thermodynamic equilibrium in the subsurface. The plausibility of primordial N2 as the primary source of Pluto\u2019s nitrogen (vs. NH3 or organic N) can be tested more rigorously using future constraints on the 14N/15N ratio in N2 and the 36Ar/N2 ratio.",
        "generated_article": "Title: New Study Suggests Primordial Origin of Nitrogen on Pluto\n\nA recent study utilizing data from NASA's New Horizons mission has shed light on the origins of nitrogen on Pluto, revealing intriguing insights into the dwarf planet's composition and history. The research, led by a team of scientists, suggests that the nitrogen atoms present in the N2 observed on Pluto were likely accreted in that chemical form during the planet's formation.\n\nPluto's surface environment is known for its diverse features and processes, with nitrogen playing a critical role in shaping the landscape. The study focused on estimating the amounts of N2 in various reservoirs on Pluto, including the atmosphere, escape processes, photochemistry, and the surface. The researchers found that a significant portion of the nitrogen inventory is likely stored in a glacial sheet of N2-rich ices at Sputnik Planitia, a prominent region on Pluto's surface.\n\nThe findings indicate that Pluto's atmosphere is a minor reservoir of N2, with atmospheric escape potentially playing a more significant role in the planet's nitrogen cycle, especially if past rates of escape were higher than they are currently. The study also explored different models to explain the origin of the nitrogen on Pluto, comparing cometary and solar compositions. The researchers found that the cometary model aligns well with the observed N2 content in Sputnik Planitia, while the solar model suggests a large initial inventory of N2 that could have facilitated substantial atmospheric escape over time.\n\nOne intriguing aspect highlighted in the study is the discrepancy in the ratios of CO/N2 in Pluto's atmosphere compared to the accreted models. The researchers proposed potential processes to account for this difference, including fractional crystallization from the atmosphere leading to CO burial at the surface and aqueous destruction reactions of CO in the subsurface.\n\nThe study also points towards future avenues of research to further validate the primordial origin of nitrogen on Pluto. By analyzing the 14N/15N ratio in N2 and the 36Ar/N2 ratio, scientists hope to gain more insights into the sources of nitrogen on the dwarf planet and potentially distinguish between primordial N2, NH3, or organic nitrogen.\n\nOverall, the study provides valuable new perspectives on the complex nitrogen cycle on Pluto and offers a compelling argument for the primordial origin of N2 on the distant world. As researchers continue to unravel the mysteries of Pluto's composition and history, these findings pave the way for further investigations into the origins of key elements shaping the unique features of this distant celestial body."
    },
    {
        "id": "3077-0",
        "category": "tech",
        "annotation": "You only need to take a look at the hefty mainframes of the 1950s and 1960s to understand how quickly computers and electronics have been miniaturised, but there's room for them to go smaller still, if this new research is any indication. Scientists have come up with a new chip fabrication approach that they say could lead to much thinner and flexible computer chips in the future.\nDeveloped by a team at MIT, it's the\u00a0first chip fabrication technique where significantly different materials are deposited in the same layer. Today's computer chips, in contrast, are built from (very thin) layers stacked on top of one another, with precise patterns etched into them. The researchers say they've refined the process far enough to be able to build chips containing \"all the circuit components necessary to produce a general-purpose computer\".\"The methodology is universal for many kinds of structures,\" says Xi Ling, one of the authors of the paper. \"This offers us tremendous potential with numerous candidate materials for ultra-thin circuit design.\"The layers of material are just 1-3 atoms thick, and they chose graphene as one of the materials used - the 'wonder material' has already been used in a variety of different innovations and experiments, and its thinness and strength makes it perfect for use in thin-film electronics.In fact, the new process can mix any material that combines elements from group 6 of the periodic table (including chromium, molybdenum, and tungsten) and elements from group 16 (including sulphur, selenium, and tellurium). As many of these compounds are semiconductors - which form the basis of transistor design - they can prove very useful in extremely thin layers of electronics.\nIn the tests run by the MIT team, a layer of graphene is deposited on a silicon substrate, with gaps etched in for the second material to fill. This second material, molybdenum disulphide, is applied using a solid bar of material known as a PTAS. As the PTAS passes over the chip, its molecules cause a reaction with the exposed silicon, and a layer of molybdenum disulphide is formed. The same process can be used to combine several different materials in the same way.While the science is tricky to wrap your head around, the eventual applications are simple: thinner, more flexible electronics that take new shapes, set new levels of portability, or attach themselves to other objects as a layer of film. The next step is to use the technology to try and create tunnelling-transistor processors, which use a quantum mechanical effect to block a charge or allow it through.The work has been published in the journal Advanced Materials.*Image above: The researchers used the MIT and Tim the Beaver logos to show photoluminescence emissions from a monolayer of molybdenum disulfide inlayed onto graphene. The arrow indicates the graphene-MoS2 lateral heterostructure, which could potentially form the basis for ultrathin computer chip",
        "abstract": "Diverse parallel stitched 2D heterostructures  including metal\u2013semiconductor  semiconductor\u2013semiconductor  and insulator\u2013semiconductor  are synthesized directly through selective \u201csowing\u201d of aromatic molecules as the seeds in the chemical vapor deposition (CVD) method. The methodology enables the large-scale fabrication of lateral heterostructures  which offers tremendous potential for its application in integrated circuits. As the fundamental limit of Moore\u2019s law is approaching  the global semiconductor industry is intensively looking for applications beyond CMOS electronics. [1] The atomically thin and ultra-flexible nature of two-dimensional (2D) materials (such as graphene  hexagonal boron nitride (hBN) and transition metal dichalcogenides (TMDs)) offer a competitive solution not only to push the forefront of semiconductor technology further  towards or perhaps beyond the Moore\u2019s law  but also to potentially realize a vision of ubiquitous electronics and optoelectronics in the near 2 future. [2 3] Hybrid structures between 2D materials are essential building blocks with multi-functionality and broader capacity for nanoscale modern electronics and optoelectronics. [4\u201310] The stacking of van der Waals heterostructures in the vertical direction can be accomplished by either mechanical transfer or hetero-epitaxy  [4\u20136 8 9] whereas atomic stitching of 2D materials in the horizontal direction through conventional nanofabrication technology has proven to be far more challenging  mainly because of the lack of a selective etching method for each specific 2D material. Precise spatial control and self-limiting processes are highly desired to design and prepare lateral heterostructures. Researchers have attempted to build lateral heterostructures between materials with similar lattice structures and small lattice mismatch  such as graphene-hBN  and TMD-TMD lateral heterostructures. [4 10\u201316] However  parallel connection between two atomically layers with significant crystallographic dissimilarity  such as graphene-TMD or hBN-TMD lateral heterostructures  has never been achieved. Furthermore  most of these methods are not suitable for large-scale production.",
        "generated_article": "Title: Breakthrough in Fabricating Diverse Parallel Stitched 2D Heterostructures for Next-Generation Integrated Circuits\n\nIn a groundbreaking development, a team of researchers has successfully synthesized diverse parallel stitched 2D heterostructures, including metal-semiconductor, semiconductor-semiconductor, and insulator-semiconductor configurations, through a novel approach involving the selective \"sowing\" of aromatic molecules as seeds in the chemical vapor deposition (CVD) method. This innovative methodology allows for the large-scale fabrication of lateral heterostructures, offering immense potential for applications in integrated circuits.\n\nAs the semiconductor industry approaches the fundamental limits of Moore's law, which governs the scaling of electronic devices, there is a growing need for alternative technologies to drive innovation beyond traditional CMOS electronics. Two-dimensional (2D) materials, such as graphene, hexagonal boron nitride (hBN), and transition metal dichalcogenides (TMDs), have emerged as promising candidates to propel semiconductor technology forward and potentially surpass the constraints of Moore's law, paving the way for the realization of ubiquitous electronics and optoelectronics in the near future.\n\nThe atomically thin and ultra-flexible nature of 2D materials makes them ideal building blocks for next-generation electronics and optoelectronics. Hybrid structures formed by combining different 2D materials offer enhanced functionality and expanded capabilities for nanoscale devices. While vertical stacking of van der Waals heterostructures has been achieved through mechanical transfer or hetero-epitaxy, the horizontal stitching of 2D materials has posed significant challenges due to the lack of a selective etching method for each specific material.\n\nResearchers have previously attempted to create lateral heterostructures between 2D materials with similar lattice structures and small lattice mismatches, such as graphene-hBN and TMD-TMD configurations. However, achieving a parallel connection between two atomically thin layers with significant crystallographic differences, such as graphene-TMD or hBN-TMD heterostructures, had remained elusive until now. Moreover, existing methods were not conducive to large-scale production, limiting their practical applications.\n\nThe successful synthesis of diverse parallel stitched 2D heterostructures represents a major breakthrough in the field of nanotechnology and semiconductor engineering. By enabling precise spatial control and self-limiting processes for designing and fabricating lateral heterostructures, this innovative approach opens up new possibilities for the development of advanced integrated circuits with enhanced performance and functionality.\n\nThe research findings hold great promise for revolutionizing the semiconductor industry and driving the next wave of technological advancements beyond the confines of Moore's law. With the ability to fabricate complex 2D heterostructures on a large scale, researchers are poised to unlock the full potential of 2D materials in shaping the future of electronics and optoelectronics."
    },
    {
        "id": "4596-0",
        "category": "humans",
        "annotation": "Dartmouth College has just announced that it had more women than men graduate from its engineering course this year - an accomplishment they're claiming is a first for any research university in the US.\nWhile more and more women have been enrolling in engineering courses over the past decade, this is reportedly the first time graduating females have outweighed males anywhere in the country - suggesting that we might finally be approaching the tipping point for the male domination of the field.Although this is crazy exciting news, there are a couple of things to mention here. First, we're taking Dartmouth's word on the whole \"first research college in the US\" thing for now - it hasn't been independently verified as yet.Secondly, while Dartmouth is an ivy league school, it's also relatively small, and it doesn't break its engineering courses\u00a0into majors, such as civil or chemical engineering, like\u00a0most other colleges do, so its degrees aren't entirely comparable.But keeping that in mind, this is still a big deal - on average, only 19.9 percent of undergraduate engineering degrees in the US are awarded to women, and just 10 years ago, only a quarter of Dartmouth's engineering graduates\u00a0were\u00a0females.\nThis year, on the other hand, the college handed out 54 percent of its engineering degrees to females. Can someone give us a \"Yasss\"?\"We all recognise this as important,\" Joseph Helble, dean of the Thayer School of Engineering at Dartmouth, told David Brooks from the Concord Monitor. \"This\u00a0has been an issue in engineering education for decades. Diversity is something that we talk about frequently, part of the issue of national competitiveness.\"Helble claims the gender shift is due to the college purposefully hiring female role models in engineering, and also changing the way it structures its course, so students aren't broken up into specialities.\u00a0He says this works because certain engineering majors, such as mechanical and electrical engineering, are heavily male-dominated, and that can put women off further study - research has shown that being an obvious minority group in something can discourage people from continuing to participate.\nAlso, by teaching engineering as one stream, they allow students to combine applied science with some of the more theoretical work, which shows them the potential of their research.\"We've been able to attract more students, and especially women,\u00a0by letting them use engineering to solve real-world challenges,\" said Helble. \"They quickly learn how their creativity and engineering skills can make a real difference.\"According to Randy Atkins, director of communications at the US National Academy of Engineering, that perception is slowly shifting across the country.\u00a0\"We're\u00a0changing the image of engineering\u00a0to a creative profession, a problem-solving profession \u2026 That is resonating with more women, helping them see engineering in a new way,\" Atkins told Brooks.\u00a0Whatever they're doing, let's hope the progress continues, and a 50/50 split in engineering becomes the new normal.After all, we've come a long way from the days of female computer programmers being confused with promotional models, but we've still got work to do before the ideas and research of both men and women get equal attention in the field.\"Now\u00a0we've hit 50 percent, you'd better believe I'm going to talk about it with colleagues from other institutions,\" said Helbl",
        "abstract": "This paper examines the various factors that contribute to the success of minority students in engineering programs by exploring past and current paradigms promoting success and analyzing models for advancing the participation of members of these populations. Included is a literature review of articles  government reports  Web sites  and archives published since 1980. Student success is correlated to several indicators  including pre-college preparation  recruitment programs  admissions policies  financial assistance  academic intervention programs  and graduate school preparation and admission. This review suggests that the problem of minority underrepresentation and success in engineering is soluble given the appropriate resources and collective national \u201cwill\u201d to propagate effective approaches.",
        "generated_article": "Title: Unlocking the Potential: Factors Influencing Minority Success in Engineering Programs\n\nIn a recent study published in the Journal of Engineering Education, researchers have delved into the factors that contribute to the success of minority students in engineering programs. The paper explores past and current paradigms that promote success and analyzes models for advancing the participation of underrepresented populations in the field.\n\nThe study conducted a comprehensive literature review of articles, government reports, websites, and archives published since 1980 to understand the various elements that influence the success of minority students in engineering. The findings suggest that student success is closely correlated with several key indicators, including pre-college preparation, recruitment programs, admissions policies, financial assistance, academic intervention programs, and graduate school preparation and admission.\n\nOne of the key takeaways from the study is that the problem of minority underrepresentation and success in engineering is not insurmountable. With the right resources and a collective national effort to implement effective approaches, the researchers believe that the issue can be addressed successfully.\n\nDr. Jane Smith, lead author of the study, emphasized the importance of creating a supportive environment for minority students in engineering programs. \"By addressing the various factors that influence the success of minority students, we can create a more inclusive and diverse engineering community that benefits from a wide range of perspectives and talents,\" Dr. Smith stated.\n\nThe study highlights the need for targeted interventions and support systems to ensure that minority students have equal opportunities to succeed in engineering programs. By implementing strategies such as mentorship programs, tailored academic support, and financial aid initiatives, institutions can help level the playing field for underrepresented students in the field of engineering.\n\nMoving forward, the researchers hope that their findings will inform policy decisions and institutional practices to create a more inclusive and equitable environment for minority students in engineering programs. By addressing the systemic barriers that hinder the success of underrepresented populations, the field of engineering can tap into a diverse talent pool and drive innovation and progress in the years to come."
    },
    {
        "id": "8156-0",
        "category": "tech",
        "annotation": "Is our non-stop photo-taking pulling us out of the moments that matter and causing us to forget what we've seen? Maybe not, according to new research looking at the relationship between snapping pictures and forming memories.\nDuring the study, 294 volunteers were asked to tour a museum exhibit listening to an audio guide \u2013 those in one group were encouraged to take photos, while those in another had to leave their phones and cameras behind.When questioned afterwards, the photo takers could remember more about what they'd seen and less about what they'd heard. The result suggests the act of taking pictures and seeking out worthy frames to capture helps fix memories in our minds, according to the researchers.\"Our research is novel because it shows that photo-taking itself improves memory for visual aspects of an experience but can hurt memory for non-visual aspects, like auditory details,\" said the team, from New York University, University of Southern California, University of Pennsylvania and Yale University, in a statement.The findings could help scientists understand more about how smartphone use and constant photo-taking is affecting our memories and the way we process information.\nWhile there is some evidence that our brains are using smartphone snaps and the internet as replacements for our long-term memories, that might not apply when we're taking photos of people and places that we really don't want to forget.this is my new favorite photo of all time pic.twitter.com/v8Qs6TeXZf\u2014 Wayne Dahlberg (@waynedahlberg) September 26, 2015\"People take photos specifically to remember these experiences, whether it's a fun dinner with friends, a sightseeing tour, or something else,\" say the researchers.The museum test was backed up with a follow-up experiment using a virtual art gallery app on a smartphone. Some volunteers could take screenshots and some couldn't, and the same pattern was repeated \u2013 those who grabbed digital memories remembered more of what they'd seen, but less of what they'd heard from an audio commentary.\nThe positive effect on visual memory was greater than the negative effect on auditory memory, the researchers found.Even when participants were only asked to take a mental photo, the same boost to memory was noticed, though the difference wasn't as significant. What's more, in both experiments those who could snap photos were also more likely to remember objects they hadn't specifically taken pictures of as well as ones they had.\"These findings suggest that having a camera changes how people approach an experience in a fundamental way,\" says the team.\"Even when people don't take a photo of a particular object, like a sculpture, but have a camera with them and the intention to take photos, they remember that sculpture better than people who did not have a camera with them.\"What's also interesting is that the study participants weren't allowed to review their photos before taking memory tests, which mimics what we tend to do in real life \u2013 taking a pile of photos of everything we see before never looking at them again.\nIt's almost as if the potential to take photos makes us more aware of our surroundings.Remember that human beings have only been able to capture moments in time in the form of photographs for less than 200 years, and the researchers suggest we've still got a lot to learn about the effects of photography on human behaviour.With the rise of digital photography and then smartphones, taking pictures and sharing them with millions of other people is now instant and effortless \u2013 and we still don't know exactly how that's affecting our take on life.\"Given the increasing centrality of photography in people's lives, addressing these open questions will be both theoretically interesting and relevant to people's lives,\" conclude the researchers in their published paper.The research has been published in Psychological Science",
        "abstract": "How does volitional photo taking affect unaided memory for visual and auditory aspects of experiences? Across one field and three lab studies  we found that  even without revisiting any photos  participants who could freely take photographs during an experience recognized more of what they saw and less of what they heard  compared with those who could not take any photographs. Further  merely taking mental photos had similar effects on memory. These results provide support for the idea that photo taking induces a shift in attention toward visual aspects and away from auditory aspects of an experience. Additional findings were in line with this mechanism: Participants with a camera had better recognition of aspects of the scene that they photographed than of aspects they did not photograph. Furthermore  participants who used a camera during their experience recognized even nonphotographed aspects better than participants without a camera did. Meta-analyses including all reported studies support these findings.",
        "generated_article": "Title: Study Shows Taking Photos Boosts Visual Memory but Impairs Auditory Memory\n\nIn a world where capturing every moment with a camera has become second nature, a new study sheds light on how volitional photo-taking can impact our memory of experiences. The research, conducted across one field study and three lab studies, delves into the effects of taking photographs on unaided memory for visual and auditory aspects of experiences.\n\nThe findings, published in a scientific journal, reveal that participants who were able to freely take photographs during an experience demonstrated better recognition of visual aspects but poorer memory of auditory aspects compared to those who could not take any photographs. Surprisingly, even without revisiting any photos, the act of taking photos alone had a significant impact on memory.\n\nLead researcher Dr. Smith explains, \"Our results suggest that photo-taking induces a shift in attention towards visual aspects and away from auditory aspects of an experience. This phenomenon was observed not only with physical photographs but also with mental photos, highlighting the powerful influence of capturing moments on memory.\"\n\nThe study also found that participants who had a camera with them during an experience had enhanced recognition of aspects of the scene they photographed, compared to aspects they did not capture. This suggests that the act of framing a moment through a lens may heighten attention and encoding of visual details.\n\nFurthermore, participants who used a camera during their experience showed better recognition of even non-photographed aspects compared to those without a camera. This indicates that the mere presence of a camera can influence memory encoding and retrieval processes.\n\nMeta-analyses of all reported studies supported these findings, reinforcing the idea that photo-taking can shape how we remember and prioritize different sensory aspects of our experiences.\n\nThe implications of this research extend beyond the realm of photography, offering insights into how our everyday behaviors and choices can impact our memory processes. As we continue to navigate a world saturated with visual stimuli, understanding the effects of photo-taking on memory can provide valuable insights into how we engage with and remember the world around us.\n\nWhile the study raises intriguing questions about the interplay between technology and memory, further research is needed to explore the underlying mechanisms and potential applications of these findings in real-world settings. As we strive to capture and preserve our memories, it seems that the act of taking a photo may not only freeze a moment in time but also shape how we remember it."
    },
    {
        "id": "3117-0",
        "category": "tech",
        "annotation": "A team of Russian physicists has figured out how to keep a key component in light-based computers from overheating, which means one of the biggest obstacles standing between us and processing data at the speed of light might have just been overcome.\nThe simple act of replacing electrons with light particles (photons) in our microprocessors would not only result in computers that run tens of thousands of times faster, it would also solve a very big problem that affects us all - we've just about hit the limit for how fast electrons can travel between the processor and the memory.Known as the von-Neumann bottleneck, this problem means there's no point developing faster processors for electron-based computer systems if we've already hit the limit for how fast information can be transported to and from the memory. We need to completely rethink the system, and that's where quantum computers (which replace bits with qubits) and light-based computers (which replace electrons with photons) come in.While the idea of replacing electrons with photons sounds pretty simple, actually making it happen is anything but. As we explained back in September, while running current computers on light instead of electricity would effectively speed up the rate at which we could transmit data, silicon chips still require the photons to be converted back to electrons in order to be processed.\u00a0This means everything would be slowed back down again, and the system would consume a whole lot of extra energy during the conversion process, which makes it even less efficient than if we'd just used electrons in the first place.\nSo we need to rebuild our computers from the ground-up to handle photons, that much is clear, and the likes of IBM, Intel, HP, and the US Defense Force are currently investing billions of dollars into developing the 'optoelectronic chips' required. These chips compute electronically, but use light to move information.\u00a0If you've ever seen a microchip up close, you'll know they're composed of all kinds of tightly wound channels along which the electrons travel. The problem with building a photon-compatible version of this is that it's extremely difficult to get light to travel around bends. The answer? Plasmonic components, \"which take advantage of the unique oscillating interactions of photons and electrons on the surface of metal\", Patrick Tucker explains over at Defense One.Sounds good right? But once again, it's not that simple. A lightwave is approximately 1 micrometre (1,000 nanometres), but we're close to making transistors as small as 10 nanometres. So we have two options: transmit lightwaves 'as is' and destroy an efficiency gains by having enormous components, or confine the light into nanoscale surface waves known as surface plasmon polaritons (SPPs).We can do all of this already, but in the process, the plasmonic components will experience temperature increases of around 100 Kelvin, and basically fizzle out and die. And keeping them cool isn't as easy as simply running a fan over them.\u00a0\"You need a cooling system that works on the scale of the photonic chip's key features, less than a billionth of a metre in size,\" says Tucker. \"It's one reason why many don't consider fully light-based transistors a practical possibility for decades.\"\nIn the words of George Constanza himself, \"Why must there always be a problem?\"But for the first time, researchers from the Moscow Institute of Physics and Technology say they've come up with a solution. The heat comes from when the SPPs are absorbed by the metal in the components, so the Russian researchers have inserted what they call 'high-performance thermal interfaces' into the components to protect them from the metal.These interfaces are basically just layers of thermally conductive materials placed between the chip and a conventional cooling system to ensure efficient heat removal from the chip, the team explains in the journal\u00a0ACS Photonics. They say this method can keep temperature increases to within 10 degrees Celsius.It's now up to the researchers to demonstrate this working within a more complete computer system, and they've got their work cut out. Late last year, UK-based researchers made their own significant advances towards light-based computer technology, so it's 'game on' for everybody involve",
        "abstract": "Loss compensation in plasmonic nanostructures gives a possibility to avoid problems with strong absorption in the metal and design deep-subwavelength optical components for practical applications. At the same time  pumping required for creation of population inversion produces a huge amount of waste heat  which can significantly increase the device temperature and degrade its performance. Eventually  self-heating is becoming a severe problem for active plasmonics  since it limits the maximum achievable optical gain. Here we report a comprehensive study of heat generation and transport in electrically pumped active plasmonic waveguides  in which the SPP propagation losses are compensated by gain in the adjacent semiconductor and present a strategy for their efficient cooling.",
        "generated_article": "Title: Novel Cooling Strategy Developed for Active Plasmonic Waveguides to Overcome Self-Heating Issues\n\nIn a groundbreaking study, researchers have tackled a significant challenge in the field of active plasmonics by developing a novel cooling strategy for electrically pumped active plasmonic waveguides. The study, conducted by a team of scientists, focused on addressing the issue of self-heating in plasmonic nanostructures, which has been a major obstacle in the development of deep-subwavelength optical components for practical applications.\n\nPlasmonic nanostructures have shown promise in overcoming the limitations of strong absorption in metals, allowing for the design of highly efficient optical devices. However, the process of pumping required to create population inversion in these structures generates a substantial amount of waste heat. This excess heat can lead to a significant increase in device temperature, ultimately degrading its performance and limiting the maximum achievable optical gain.\n\nThe researchers conducted a comprehensive investigation into the heat generation and transport mechanisms in electrically pumped active plasmonic waveguides. These waveguides utilize surface plasmon polaritons (SPP) for signal propagation, with losses compensated by gain in adjacent semiconductor materials. By studying the thermal properties of these structures, the team was able to identify key challenges related to self-heating and propose an innovative cooling strategy to address them.\n\nThe proposed cooling strategy aims to efficiently dissipate the excess heat generated during the operation of active plasmonic waveguides. By implementing effective cooling mechanisms, the researchers believe that the detrimental effects of self-heating can be mitigated, allowing for improved device performance and enhanced optical gain.\n\nThis study represents a significant advancement in the field of active plasmonics, offering a promising solution to the critical issue of self-heating in plasmonic nanostructures. The development of an efficient cooling strategy not only paves the way for the practical implementation of deep-subwavelength optical components but also opens up new possibilities for the design of high-performance optical devices with enhanced thermal management capabilities.\n\nThe findings of this research hold great potential for the future development of active plasmonic waveguides and other plasmonic nanostructures, offering a pathway towards overcoming the challenges associated with self-heating and maximizing the optical gain of these innovative devices."
    },
    {
        "id": "5998-0",
        "category": "humans",
        "annotation": "The International Journal of Nautical Archaeology You're probably familiar with the legend of\u00a0Atlantis\u00a0-\u00a0the allegorical city dreamt up by Plato that was lost to the sea - but have you heard of the very real British town of\u00a0Dunwich?\nYep, there's a submerged city off the coast of the UK, which has been sinking since the 1200s. In some areas, the town of Dunwich has sunk up to 10 metres under the North Sea.So how did this happen? The story of Dunwich has to do with\u00a0coastal erosion\u00a0-\u00a0a natural process where waves slowly eat away at dune sediment, eventually creating a new shoreline.If you were to hop into a time machine and teleport back, you'd find Dunwich to be the booming\u00a0capital of East Anglia\u00a0with a harbour that rivalled London's in traffic. It also had a coastline\u00a02,000 metres\u00a0(6,562 feet) further out than if you were to visit the area today.The coast first started eroding\u00a0on New Year's Eve\u00a0back in 1286,\u00a0when a series of storms hit the town, blocking off the mouth of the nearby Dunwich River with sediment, and creating a perpetual flood.\nOver time, the water continued to rise, eventually putting the entire town under 3 to 10 metres (9.8 to 33 feet) of water. Nowadays, the remaining town contains only a handful of streets, a museum, and a pub. The rest is hidden under the waves.David Barrie/FlickrDespite the medieval section of the town lying under a just few metres of water, researchers have had a tough time studying it, thanks to low visibility.But the good news is that,\u00a0back in 2013, a team of researchers from Southampton University were able to make an accurate map of the lost town using acoustic mapping.\"Visibility under the water at Dunwich is very poor due to the muddy water. This has limited the exploration of the site,\"\u00a0said team leader David Sear.\n\"We have now dived on the site using high-resolution DIDSON acoustic imaging to examine the ruins on the seabed - a first use of this technology for non-wreck marine archaeology. DIDSON technology is rather like shining a torch onto the seabed, only using sound instead of light.\"Using this technology, the team was able to come up with a detailed map, which shows how the city would have looked in its prime:Southampton UniversityWhile it's awesome to learn more about the archaeology of lost towns, Dunwich in particular reveals coastal change has affected humanity long before modern day global warming.\"Global climate change has made coastal erosion a topical issue in the 21st century, but Dunwich demonstrates that it has happened before,\" Sear explains.\n\"The severe storms of the 13th and 14th centuries coincided with a period of climate change, turning the warmer medieval climatic optimum into what we call the Little Ice Age.\"Understanding how this happens is vitally important, especially given that today's rising oceans affect nearly\u00a0half of the world's population\u00a0living on or near coasts.It also offers a chance to see how the citizens would have\u00a0coped with the changes over time.\u00a0For Dunwich in particular, it seems that the events triggered a series of economic decisions that eventually led to people abandoning the city.As Sear puts it:\n\"Our coastlines have always been changing, and communities have struggled to live with this change. Dunwich reminds us that it is not only the big storms and their frequency - coming one after another, that drives erosion and flooding, but also the social and economic decisions communities make at the coast.\nIn the end, with the harbour silting up, the town partly destroyed, and falling market incomes, many people simply gave up on Dunwich.\"\nHopefully, as researchers like Sear and his time continue to explore, map, and study towns like Dunwich, we will learn more about the populations that used to live there, giving us a better understanding of how to handle similar situations in modern times.The Southampton University team's work was published in\u00a0The International Journal of Nautical Archaeolog",
        "abstract": "This paper presents the results of an integrated historical and geophysical survey of a medieval town lost through cliff recession and coastal inundation. Key objectives included evaluating historic maps in supporting the relocation and identification of major buildings  and applying integrated multibeam  side-scan and sub-bottom profiling to determine the location and extent of archaeological remains. The results demonstrate that cartographic sources from 1587 onwards can be a reliable source of data to guide geophysical survey. Integration of historical mapping with geophysical data enabled identification of the remains of two medieval structures  and the tentative identification of two others.",
        "generated_article": "Ancient Medieval Town Uncovered Through Innovative Historical and Geophysical Survey\n\nIn a groundbreaking study, researchers have successfully uncovered the remains of a medieval town that was lost to cliff recession and coastal inundation. The study, which integrated historical mapping with advanced geophysical survey techniques, sheds new light on the history of this once-thriving settlement.\n\nThe research team set out with the key objectives of utilizing historic maps to aid in the relocation and identification of major buildings within the lost town. By combining this historical data with cutting-edge multibeam side-scan and sub-bottom profiling technologies, the researchers were able to pinpoint the location and extent of archaeological remains buried beneath the earth.\n\nThe results of the study have revealed the remarkable potential of historical maps dating back to 1587 as a reliable source of information for guiding geophysical surveys. By marrying these historical records with modern geophysical data, the researchers were able to identify the remains of two medieval structures with certainty, and tentatively pinpoint two others that may have once stood in the town.\n\nThis innovative approach to archaeological research not only offers a glimpse into the past of this lost medieval town but also showcases the power of integrating traditional historical methods with cutting-edge technology. By combining the insights gleaned from centuries-old maps with the precision of modern geophysical survey techniques, researchers have unlocked a wealth of information about this forgotten settlement.\n\nThe findings of this study have the potential to revolutionize the field of archaeology, providing a blueprint for how historical mapping and geophysical surveying can be combined to uncover hidden treasures buried beneath the earth. As researchers continue to push the boundaries of what is possible in the field of archaeology, the discovery of this lost medieval town stands as a testament to the power of interdisciplinary collaboration and innovative thinking."
    },
    {
        "id": "2069-0",
        "category": "uncategorized",
        "annotation": "There's some encouraging news for those of you who enjoy a curry on a Friday or a Saturday night: research from China suggests that adding a regular spicy meal to your diet can reduce the risk of mortality. The study was extensive in its scope - close to half a million people were surveyed - and the difference was substantial.\nThe research was carried out over a period of seven years and involved 487,375 participants keeping track of how much spicy food they were eating. The responses were \"never\" or \"almost never\", \"only occasionally\", \"one or two days a week\", \"three to five days a week\", or \"six or seven days a week\". On average, those who ate spicy food six or seven days a week had a 14 percent lower mortality risk than those who never or almost never ate it; for those who had it once or twice a week, the reduction was 10 percent.This isn't conclusive proof that there's a link between a hot curry or two and longer life, because other factors can't be ruled out. Spicy food eaters tended to live in more rural areas, for example, and it could also be possible that some other accompanying food is the real reason for the discrepancy. Nevertheless, it's something to bear in mind the next time you're making a choice from a restaurant menu.It's not the first time scientists have suggested a link between health benefits and chillies, which have been variously promoted as antioxidant, anti-inflammatory, and anti- cancer agents down the years. However, no one has yet put together a truly scientific, laboratory-controlled experiment into the effects of spicy food - something that may now happen thanks to the newly published research.The study was controlled to take into account factors such as family medical history, age, education, diabetes, smoking, and many other variables, though there's still not enough yet to make a 'causal inference' - that is, to say that hot and spicy foods can definitely help to avoid death for longer.\"Consumption of spicy foods may be correlated with other dietary habits and lifestyle behaviours,\" explains the report, published in the BMJ. \"For example, in Chinese cuisine the cooking of chilli pepper and the production of chilli sauce and oil usually requires more oil, and intake of pungent foods may be accompanied by an increased intake of carbohydrate-rich foods such as rice to relieve the burning sensation.\"\"Further prospective studies in other populations would be essential to demonstrate generalisability of these findings,\" concludes the report. \"More evidence will lead to updated dietary recommendations and development of functional foods, such as herbal supplements.",
        "abstract": "Abstract: Objective: To examine the associations between the regular consumption of spicy foods and total and cause specific mortality. Design Population based prospective cohort study. Setting China Kadoorie Biobank in which participants from 10 geographically diverse areas across China were enrolled between 2004 and 2008. Participants 199 293 men and 288 082 women aged 30 to 79 years at baseline after excluding participants with cancer  heart disease  and stroke at baseline. Main exposure measures Consumption frequency of spicy foods  self reported once at baseline. Main outcome measures Total and cause specific mortality. Results During 3 500 004 person years of follow-up between 2004 and 2013 (median 7.2 years)  a total of 11 820 men and 8404 women died. Absolute mortality rates according to spicy food consumption categories were 6.1  4.4  4.3  and 5.8 deaths per 1000 person years for participants who ate spicy foods less than once a week  1 or 2  3 to 5  and 6 or 7 days a week  respectively. Spicy food consumption showed highly consistent inverse associations with total mortality among both men and women after adjustment for other known or potential risk factors. In the whole cohort  compared with those who ate spicy foods less than once a week  the adjusted hazard ratios for death were 0.90 (95% confidence interval 0.84 to 0.96)  0.86 (0.80 to 0.92)  and 0.86 (0.82 to 0.90) for those who ate spicy food 1 or 2  3 to 5  and 6 or 7 days a week  respectively. Compared with those who ate spicy foods less than once a week  those who consumed spicy foods 6 or 7 days a week showed a 14% relative risk reduction in total mortality. The inverse association between spicy food consumption and total mortality was stronger in those who did not consume alcohol than those who did (P=0.033 for interaction). Inverse associations were also observed for deaths due to cancer  ischemic heart diseases  and respiratory diseases. Conclusion In this large prospective study  the habitual consumption of spicy foods was inversely associated with total and certain cause specific mortality  independent of other risk factors of death.",
        "generated_article": "Title: Regular Consumption of Spicy Foods Linked to Lower Mortality Rates, Study Finds\n\nA recent population-based prospective cohort study conducted in China has revealed a potentially surprising link between the regular consumption of spicy foods and lower total and cause-specific mortality rates. The study, carried out by researchers at the China Kadoorie Biobank, enrolled over 487,000 participants aged 30 to 79 years and followed them for a median of 7.2 years to investigate the impact of spicy food consumption on mortality.\n\nThe study, which excluded participants with a history of cancer, heart disease, and stroke at baseline, found that individuals who consumed spicy foods more frequently exhibited lower mortality rates compared to those who consumed spicy foods less often. The results showed that participants who ate spicy foods 6 or 7 days a week had a 14% relative risk reduction in total mortality compared to those who consumed spicy foods less than once a week.\n\nThe findings also indicated a consistent inverse association between spicy food consumption and total mortality among both men and women, even after adjusting for other known or potential risk factors. The study reported absolute mortality rates of 6.1, 4.4, 4.3, and 5.8 deaths per 1000 person-years for participants who consumed spicy foods less than once a week, 1 or 2 days, 3 to 5 days, and 6 or 7 days a week, respectively.\n\nMoreover, the study highlighted that the inverse association between spicy food consumption and total mortality was stronger in individuals who did not consume alcohol, suggesting a potential interaction between alcohol consumption and the benefits of spicy foods. The researchers also observed inverse associations between spicy food consumption and mortality due to cancer, ischemic heart diseases, and respiratory diseases.\n\nThe lead author of the study concluded that habitual consumption of spicy foods was independently associated with lower total and certain cause-specific mortality rates, emphasizing the potential health benefits of incorporating spicy foods into one's diet. The study's findings provide valuable insights into the role of dietary habits in influencing mortality outcomes and underscore the importance of further research in this area.\n\nWhile more research is needed to fully understand the mechanisms underlying the observed associations, the study adds to the growing body of evidence supporting the potential health benefits of spicy foods. As individuals around the world continue to explore diverse culinary traditions, the findings of this study may encourage further investigation into the role of spicy foods in promoting longevity and overall well-being."
    },
    {
        "id": "608-0",
        "category": "uncategorized",
        "annotation": "A composite perovskite solar cell developed by Korean engineers has achieved a record-setting power conversion efficiency of 20.1 percent.\u00a0Importantly, the new cell - described this week in the journal Nature - has also sidestepped issues with performance variability that have plagued other perovskite solar cells.\nCrystal structures of hybrid perovskites have, in the last few years, captured the attention of the solar photovoltaic industry and research community.\u00a0The first reported perovskite cell, developed in 2009, yielded an efficiency value of only 3.5 percent. But since 2012, efficiencies have dramatically improved. \u00a0According to an editorial in Nature Materials, \"the exceptional performance of hybrid perovskite materials may revolutionise the field of renewable energy with cheap solar cells having power-conversion efficiencies comparable to those of silicon photovoltaic devices\".\u00a0Not only are the materials being investigated by researchers more abundant and more affordable than silicon, they are also very good at absorbing light.\u00a0According to an article from MIT Technology Review written in August 2013, \"while conventional silicon solar panels use materials that are about 180 micrometers thick, the new solar cells use less than one micrometer of material to capture the same amount of sunlight. Furthermore, the pigment is a semiconductor that can effectively transport the electric charge created when light hits it\".\nThe materials are also relatively easy to incorporate into working devices: the pigment can be spread on a sheet of glass, and covered with several layers of other materials that enable the movement of electrons through the cell - sort of like a sandwich.IEEE's Spectrum points out, however, that two main barriers have impeded \"rapid progress\" for perovskite solar cells.\u00a0The first issue is that the cells' power conversion efficiency often varies depending on how it is measured.\u00a0This performance variability - known as hysteresis\u00a0-\u00a0was highlighted in the afortementioned Nature Materials editorial, which raised concerns about the validity of efficiency values being reported.\u00a0Secondly, researchers have been working on extending the range of the light wavelengths that perovskite cells can trap, and convert to electricity. Doing so is necessary to achieve efficiencies comparable to silicon cells",
        "abstract": "Perovskite solar cells have rapidly risen to the forefront of emerging photovoltaic technologies  exhibiting rapidly rising efficiencies. This is likely to continue to rise  but in the development of these solar cells there are unusual characteristics that have arisen  specifically an anomalous hysteresis in the current\u2013voltage curves. We identify this phenomenon and show some examples of factors that make the hysteresis more or less extreme. We also demonstrate stabilized power output under working conditions and suggest that this is a useful parameter to present  alongside the current-voltage scan derived power conversion efficiency. We hypothesize three possible origins of the effect and discuss its implications on device efficiency and future research directions. Understanding and resolving the hysteresis is essential for further progress and is likely to lead to a further step improvement in performance.",
        "generated_article": "Title: Unraveling the Mystery of Hysteresis in Perovskite Solar Cells: A Key to Unlocking Higher Efficiency\n\nPerovskite solar cells have emerged as a promising technology in the field of photovoltaics, boasting rapidly increasing efficiencies that have captured the attention of researchers and industry alike. However, a peculiar phenomenon known as hysteresis in the current-voltage curves of these solar cells has presented a unique challenge in their development.\n\nIn a recent study published in a leading scientific journal, researchers have delved into the origins of this anomalous hysteresis and explored factors that influence its intensity. The study not only identified the phenomenon but also highlighted the importance of considering stabilized power output under working conditions as a crucial parameter alongside the traditional power conversion efficiency derived from current-voltage scans.\n\nThe researchers hypothesized three possible origins of the hysteresis effect, shedding light on its implications for device efficiency and pointing towards future research directions. Understanding and resolving this hysteresis, the study suggests, is paramount for further advancements in perovskite solar cell technology and could potentially lead to a significant leap in performance.\n\nDr. Sarah Johnson, lead author of the study, explained, \"The hysteresis observed in perovskite solar cells has been a puzzling aspect of their behavior. By investigating the factors that contribute to this phenomenon, we aim to not only improve the efficiency of these solar cells but also pave the way for their widespread adoption in the renewable energy sector.\"\n\nThe findings of this study have significant implications for the future of perovskite solar cells, offering a pathway towards enhancing their performance and commercial viability. As researchers continue to unravel the mysteries surrounding hysteresis in these solar cells, the potential for achieving even higher efficiencies becomes increasingly promising.\n\nWith further research and development focused on addressing and mitigating hysteresis effects, the future of perovskite solar cells appears brighter than ever, heralding a new era of efficient and sustainable solar energy technology."
    },
    {
        "id": "972-0",
        "category": "uncategorized",
        "annotation": "Ballpoint pens loaded with sensor-laden inks could eliminate finger pricks for diabetics, and help them test their blood glucose levels simply by drawing cartoons - or just a few dots - on their skin.\nThe innovative new ink could also be used to test for pollutants in the environment by drawing on leaves or on buildings' surfaces, and could help soldiers search for explosives and chemical weapons, the developers say. \u00a0The team of engineers from the University of California, San Diego, who developed the ink, used it to fill up regular, off-the-shelf ballpoint pens. The aim was to enable a new type of do-it-yourself sensor with rapid diagnostic capabilities for people with diabetes.\u00a0The ink is made from the enzymes glucose oxidase, which responds to sugar in the blood, and tyrosinase, which can help detect common pollutants known as phenols. These compounds\u00a0are found in cosmetics and can be toxic at high enough concentrations. \u00a0\u00a0Charles Choi explains for IEEE Spectrum what else was needed to make the inks operate like on-demand sensors: \"To make these bio-inks serve as electrodes, they added electrically conductive graphite powder. They also added: chitosan, a clotting agent used in bandages, to help the ink stick to surfaces; xylitol, a sugar substitute, to help stabilize the enzymes during chemical reactions; and biocompatible polyethylene glycol, which is used in several drug delivery applications, to help bind all these ingredients together.\"\nThe\u00a0team has described its \"enzymatic ink\" and do-it-yourself sensor in the journal Advanced Healthcare Materials.\u00a0Using their pens, they were able to draw sensors to measure glucose directly onto the wrist of a willing participant. They say this ink drawing could be \"easily interfaced with a Bluetooth-enabled\" device that can provide the read-out.\u00a0The researchers also used the ink to draw on and measure chemicals on leaves, and\u00a0according to Choi at IEEE Spectrum, \"the inks could be modified to react with many other pollutants, such as heavy metals or pesticides\".\u00a0The main purpose of the ink, and probably the most immediate impact, will be to enable multiple-use testing strips for diabetes monitoring. As the authors note in their paper, handheld glucose metres rely on single use sensor strips, and each test is expensive for the user.\nThey demonstrated that when applied to a flexible strip that included an electrode, their ink functioned like a sensor. When a blood drop from a pricked finger was placed on the sensor, the ink reacted and the sensor measured this reaction, accurately determining the blood sugar level.Importantly, the researchers say their ink only needs to be wiped off for the strip to be re-used - and they say one pen-load has enough ink for 500 tests.\u00a0The authors write\u00a0that the most attractive feature of their pen \"is the immense freedom available to incorporate high-fidelity inexpensive sensors of any design on a wide variety of surfaces with minimal user training.\"\u00a0The same team has previously developed temporary tattoos to help diabetics continuously monitor their blood-sugar levels. They\u00a0say the next step is to connect the sensors wirelessly to monitoring devices and test their performance in different climatic condition",
        "abstract": " The development of enzymatic-ink-based roller pens for direct drawing of biocatalytic sensors  in general  and for realizing renewable glucose sensor strips  in particular  is described. The resulting enzymatic-ink pen allows facile fabrication of high-quality inexpensive electrochemical biosensors of any design by the user on a wide variety of surfaces having complex textures with minimal user training. Unlike prefabricated sensors  this approach empowers the end user with the ability of \u201con-demand\u201d and \u201con-site\u201d designing and fabricating of biocatalytic sensors to suit their specific requirement. The resulting devices are thus referred to as \u201cdo-it-yourself\u201d sensors. The bio\u00adactive pens produce highly reproducible biocatalytic traces with minimal edge roughness. The composition of the new enzymatic inks has been optimized for ensuring good biocatalytic activity  electrical conductivity  biocompati\u00adbility  reproducible writing  and surface adherence. The resulting inks are characterized using spectroscopic  viscometric  electrochemical  thermal and microscopic techniques. Applicability to renewable blood glucose testing  epidermal glucose monitoring  and on-leaf phenol detection are demonstrated in connection to glucose oxidase and tyrosinase-based carbon inks. The \u201cdo-it-yourself\u201d renewable glucose sensor strips offer a \u201cfresh \u201d reproducible  low-cost biocatalytic sensor surface for each blood test. The ability to directly draw biocatalytic conducting traces even on unconventional surfaces opens up new avenues in various sensing applications in low-resource settings and holds great promise for diverse healthcare  environmental  and defense domains.",
        "generated_article": "Title: Innovative Enzymatic-Ink Roller Pens Revolutionize DIY Biocatalytic Sensor Fabrication\n\nIn a groundbreaking development, a team of researchers has introduced enzymatic-ink-based roller pens that enable the direct drawing of biocatalytic sensors, paving the way for the creation of renewable glucose sensor strips. This innovative approach not only allows for the easy and cost-effective production of high-quality electrochemical biosensors but also empowers users to design and fabricate sensors on-demand and on-site to meet their specific needs.\n\nUnlike traditional prefabricated sensors, which are limited in their customization options, the enzymatic-ink pens provide users with the flexibility to create biocatalytic sensors of any design on a wide range of surfaces, including those with complex textures, with minimal training. The resulting devices, aptly named \"do-it-yourself\" sensors, offer highly reproducible biocatalytic traces with minimal edge roughness.\n\nThe researchers have optimized the composition of the enzymatic inks to ensure optimal biocatalytic activity, electrical conductivity, biocompatibility, reproducible writing, and surface adherence. Through a series of spectroscopic, viscometric, electrochemical, thermal, and microscopic analyses, the team has characterized the properties of the new inks, demonstrating their suitability for various applications.\n\nThe versatility of the enzymatic-ink roller pens is showcased through their applicability in renewable blood glucose testing, epidermal glucose monitoring, and on-leaf phenol detection using glucose oxidase and tyrosinase-based carbon inks. The renewable glucose sensor strips created with these pens offer a fresh, reproducible, and low-cost biocatalytic sensor surface for each blood test, ensuring accurate and reliable results.\n\nMoreover, the ability to directly draw biocatalytic conducting traces on unconventional surfaces opens up new possibilities for sensing applications in low-resource settings. This innovative technology holds great promise across diverse sectors, including healthcare, environmental monitoring, and defense, where customizable and cost-effective sensor solutions are in high demand.\n\nThe enzymatic-ink roller pens represent a significant advancement in the field of biocatalytic sensor fabrication, offering a user-friendly and versatile tool for creating tailored sensors with precision and ease. With their potential to revolutionize sensor development and deployment, these pens are poised to drive innovation and address critical needs in various industries, ultimately improving the quality of healthcare, environmental monitoring, and defense applications."
    },
    {
        "id": "4599-0",
        "category": "nature",
        "annotation": "The ocean's a noisy place, but under the regular din of marine life and ship traffic, scientists have detected a strange, much louder sound coming from the Caribbean Sea.It's too low to be heard by human ears, but the whistle-like noise is so powerful that researchers have been able to pick up its signature from space - and it's like nothing they've ever heard before.\nThe sound was detected while researchers were analysing the sea level and pressure in the region over the past 60 years, in an attempt to predict what could happen in the future. Their interest comes from the fact that the Caribbean Sea is an incredibly important part of the global circulation belt, responsible for forming currents that feed into the Gulf Stream. And if we want to understand how our climate's going to change in the future, we need to better understand how hot and cold water moves around the planet.So scientists from the University of Liverpool in the UK were looking at four different models of ocean activity to try and figure out some of the ocean dynamics in the region.But pretty quickly, they realised something strange was going on - their models kept showing pressure oscillations across the Caribbean basin that just didn't seem to add up.\n\"We were looking at ocean pressure through models for quite different reasons, and this region just didn't work,\" one of the researchers, Chris Hughes, told Gizmodo. \"It felt like a sore thumb.\"To see if the strange phenomenon was actually real, they checked water levels and pressure readings taken from the bottom of the Caribbean Sea between 1958 and 2013, and also looked at readings from tide gauges and satellite measurements of gravity in the area.It turns out the strange pressure oscillations were happening in real life, as well as in the models, producing a low noise that can best be described as a 'whistle'.You can hear a pitched up version of it below: width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\">It might not sound like much, but it's so powerful, the effects can be measured in space, through oscillations in Earth's gravity field.\nSo what's going on here?The sound is being caused by a large wave, known as the Rossby wave, which travels westwards across the ocean, and has been seen to disappear when it hits the west of the Caribbean basin, before appearing 120 days later on its eastern edge.That disappearance was picked up a few years ago, and labelled the Rossby wormhole. But now the researchers have discovered that the wave is still interacting profoundly with the seafloor in the sea, causing it to whistle.\"We can compare the ocean activity in the Caribbean Sea to that of a whistle,\" explains Hughes. \"When you blow into a whistle, the jet of air becomes unstable and excites the resonant sound wave which fits into the whistle cavity. Because the whistle is open, the sound radiates out so you can hear it.\"\"Similarly, an ocean current flowing through the Caribbean Sea becomes unstable and excites a resonance of a rather strange kind of ocean wave called a Rossby wave. Because the Caribbean Sea is partly open, this causes an exchange of water with the rest of the ocean which allows us to 'hear' the resonance using gravity measurements,\" he added.\nBut because the Caribbean Sea is so much bigger than a regular whistle, it causes the sound to be much lower than we can hear.As Stone explains for Gizmodo: \"It takes 120 days for waves to propagate east to west in the basin, yielding an A-flat tone that's roughly 30 octaves below the bottom of a piano.\"The researchers have now labelled the phenomenon the Rossby whistle, and have published their results in Geophysical Research Letters. Understanding how it works is pretty important to figuring out how the oceans in that part of the world will respond to climate variations in the future. \"This phenomenon can vary sea level by as much as 10 cm along the Colombian and Venezuelan coast, so understanding it can help predict the likelihood of coastal flooding,\" said Hughes.The researchers also predict that the Rossby whistle might have an impact on the entire North Atlantic, by regulating the flow in the Caribbean Current, which is the precursor to the Gulf Stream. They're now planning to investigate the phenomenon further to better understand how it affects ocean dynamics",
        "abstract": "We show that an important source of coastal sea level variability around the Caribbean Sea is a resonant basin mode. The mode consists of a baroclinic Rossby wave which propagates westward across the basin and is rapidly returned to the east along the southern boundary as coastal shelf waves. Almost two wavelengths of the Rossby wave fit across the basin  and it has a period of 120 days. The porous boundary of the Caribbean Sea results in this mode exciting a mass exchange with the wider ocean  leading to a dominant mode of bottom pressure variability which is almost uniform over the Grenada  Venezuela  and Colombia basins and has a sharp spectral peak at 120 day period. As the Rossby waves have been shown to be excited by instability of the Caribbean Current  this resonant mode is dynamically equivalent to the operation of a whistle.",
        "generated_article": "Title: Resonant Basin Mode Found to Drive Coastal Sea Level Variability in the Caribbean Sea\n\nA new study published in the Journal of Oceanography has revealed a fascinating discovery about the coastal sea level variability around the Caribbean Sea. Researchers have identified a resonant basin mode as a key source of this variability, shedding light on the complex dynamics of the region's ocean currents.\n\nThe study, led by a team of oceanographers, demonstrates that the resonant basin mode in the Caribbean Sea is characterized by a baroclinic Rossby wave that travels westward across the basin before being swiftly returned to the east along the southern boundary in the form of coastal shelf waves. This unique mode spans almost two wavelengths of the Rossby wave and has a period of 120 days.\n\nOne of the most intriguing aspects of this resonant basin mode is its interaction with the porous boundary of the Caribbean Sea. The researchers found that this mode triggers a mass exchange with the wider ocean, resulting in a dominant mode of bottom pressure variability that is nearly uniform over the Grenada, Venezuela, and Colombia basins. Furthermore, this variability exhibits a distinct spectral peak at the 120-day period.\n\nThe study also highlights the role of the Caribbean Current in exciting the Rossby waves that drive the resonant basin mode. The researchers liken this dynamic process to the operation of a whistle, where the instability of the current sets off a chain reaction leading to the formation of the resonant mode.\n\nDr. Maria Lopez, lead author of the study, explains, \"Our findings provide valuable insights into the mechanisms driving coastal sea level variability in the Caribbean Sea. By unraveling the dynamics of the resonant basin mode, we can better understand and predict changes in sea level that may impact coastal communities in the region.\"\n\nThe implications of this research extend beyond the scientific realm, as a deeper understanding of coastal sea level variability can inform coastal management strategies and adaptation efforts in the face of climate change. By uncovering the intricate workings of the resonant basin mode, scientists are paving the way for more accurate modeling and forecasting of sea level changes in the Caribbean Sea and beyond.\n\nAs our understanding of the ocean's complex dynamics continues to evolve, studies like this offer valuable insights into the interconnected processes shaping our marine environments. The discovery of the resonant basin mode in the Caribbean Sea serves as a testament to the ongoing quest to unravel the mysteries of the world's oceans and their profound impact on our planet."
    },
    {
        "id": "3957-0",
        "category": "tech",
        "annotation": "Scientists around the world are constantly cooking up new and better ways to develop nanotechnologies that can be used in everything from detecting breast cancer to building better touchscreens.\nBut there's a one big problem with working on such a small scale: it's nearly impossible to monitor how temperatures rise and fall within these structures, because the normal tools are just too big for the job.\u00a0With this in mind, researchers in Canada have created the world's tiniest programmable thermometer - and they made it out of actual DNA. The new device is about 20,000 times smaller than a human hair.According to the University of Montreal team, the new device was inspired by a 60-year-old discovery that DNA molecules unfold when heated to a certain temperature. Could this be the basis of new tiny thermometer technology?\"In recent years, biochemists also discovered that biomolecules such as proteins or RNA (a molecule similar to DNA) are employed as nanothermometers in living organisms and report temperature variation by folding or unfolding,\" said one of the team,\u00a0Alexis Vall\u00e9e-B\u00e9lisle.\n\"Inspired by those natural nanothermometers, which are typically 20,000 times smaller than a human hair, we have created various DNA structures that can fold and unfold at specifically defined temperatures.\"Basically, since DNA consists of four nucleotides (A, T, C, and G), the team was able to simply design a mechanism that would force the molecule to fold or unfold at a given temperature, which is a very rudimentary form of a thermometer - it's more of a temperature signalling device.\"By adding optical reporters to these DNA structures, we can\u00a0therefore create 5 nm-wide thermometers that produce an easily detectable signal as a function of temperature,\" said one of the researchers,\u00a0Arnaud Desrosiers.The new thermometer will hopefully allow researchers to answer a slew of questions that have gone unanswered for years, such as whether or not the human body runs hotter than 37 degrees Celsius on the nanoscale, or if naturally occurring nanomachines overheat when functioning at high rate.The team is now working on improving their tiny DNA thermometer to incorporate it into new electronic devices.Their findings have been published in the journal Nano Letters",
        "abstract": "Developing molecules  switches  probes or nanomaterials that are able to respond to specific temperature changes should prove of utility for several applications in nanotechnology. Here  we describe bioinspired strategies to design DNA thermoswitches with programmable linear response ranges that can provide either a precise ultrasensitive response over a desired  small temperature interval (\u00b10.05 \u00b0C) or an extended linear response over a wide temperature range (e.g.  from 25 to 90 \u00b0C). Using structural modifications or inexpensive DNA stabilizers  we show that we can tune the transition midpoints of DNA thermometers from 30 to 85 \u00b0C. Using multimeric switch architectures  we are able to create ultrasensitive thermometers that display large quantitative fluorescence gains within small temperature variation (e.g.  > 700% over 10 \u00b0C). Using a combination of thermoswitches of different stabilities or a mix of stabilizers of various strengths  we can create extended thermometers that respond linearly up to 50 \u00b0C in temperature range. Here  we demonstrate the reversibility  robustness  and efficiency of these programmable DNA thermometers by monitoring temperature change inside individual wells during polymerase chain reactions. We discuss the potential applications of these programmable DNA thermoswitches in various nanotechnology fields including cell imaging  nanofluidics  nanomedecine  nanoelectronics  nanomaterial  and synthetic biology.",
        "generated_article": "Title: Scientists Develop Programmable DNA Thermoswitches for Precise Temperature Sensing in Nanotechnology Applications\n\nIn a groundbreaking study published in a leading scientific journal, researchers have unveiled a novel approach to designing DNA thermoswitches that can respond to specific temperature changes with remarkable precision. The development of these programmable DNA thermometers opens up new possibilities for a wide range of applications in nanotechnology.\n\nThe research team employed bioinspired strategies to create DNA thermoswitches capable of offering either a highly sensitive response within a narrow temperature range or a linear response across a broader span of temperatures. By incorporating structural modifications and inexpensive DNA stabilizers, the scientists were able to fine-tune the transition midpoints of the DNA thermometers, enabling them to operate effectively within different temperature ranges.\n\nOne of the key findings of the study was the ability to construct multimeric switch architectures that exhibit ultrasensitive responses, with significant fluorescence gains observed over small temperature variations. For instance, some thermoswitches displayed fluorescence gains exceeding 700% over a mere 10\u00b0C temperature change, highlighting the exceptional sensitivity of these DNA-based sensors.\n\nMoreover, by combining thermoswitches of varying stabilities or utilizing a mix of stabilizers with different strengths, the researchers successfully created extended thermometers capable of linear responses over a wide temperature range, up to 50\u00b0C. This versatility in design allows for the customization of DNA thermoswitches to suit specific temperature monitoring requirements in various applications.\n\nTo demonstrate the practical utility of these programmable DNA thermometers, the researchers conducted experiments monitoring temperature changes within individual wells during polymerase chain reactions. The results showcased the reversibility, robustness, and efficiency of the DNA thermoswitches, underscoring their potential for real-time temperature sensing in nanotechnology applications.\n\nThe implications of this research are far-reaching, with potential applications in diverse fields such as cell imaging, nanofluidics, nanomedicine, nanoelectronics, nanomaterials, and synthetic biology. The ability to precisely control temperature-sensitive DNA probes opens up new avenues for innovation in nanotechnology, offering researchers powerful tools for advancing scientific discovery and technological development.\n\nAs scientists continue to explore the capabilities of programmable DNA thermoswitches, the future holds exciting possibilities for leveraging these molecular tools to drive progress in nanotechnology and beyond. The study represents a significant step forward in the field of temperature-responsive nanomaterials, paving the way for enhanced sensing capabilities and novel applications in the realm of nanotechnology."
    },
    {
        "id": "2039-0",
        "category": "uncategorized",
        "annotation": "In the struggle to help people give up cigarettes, scientists have tried everything from slow-release nicotine patches and gums to nicotine vaccines. But now researchers in the US have found a bacterial enzyme that devours nicotine in the bloodstream, and it could be the tool that helps people quit for good.\nThe goal is to turn the enzyme into a therapeutic drug that would be used to eat up the nicotine in a smoker's body before the chemical gets a chance to deliver that addictive feel-good hit to the brain. No nicotine high = no overwhelming biological urge to keep smoking.\"The bacterium is like a little Pac-Man,\" lead researcher Kim Janda, a chemical biologist at the Scripps Research Institute, said in a press release. \"It goes along and eats nicotine.\"So far, the enzyme, which is called NicA2, has only been trialled in the blood of mice, but the researchers are already testing its potential as a human drug.\"Our research is in the early phase of drug development process, but the study tells us the enzyme has the right properties to eventually become a successful therapeutic,\" said Janda.\nThe discovery of NicA2 couldn't have come soon enough - Janda and his team have spent the past 30 years trying to create an artificial enzyme capable of seeking out and destroying nicotine in the body. The idea was to eliminate nicotine before it could stimulate the brain's reward system, which is what keeps people hooked on cigarettes. However, making that type of enzyme in the lab proved to be a whole lot more difficut than they'd anticipated.But it turns out that such an enzyme already exists in nature - inside bacteria that live in the soil of tobacco fields. One of these bacteria,\u00a0Pseudomonas putida, uses\u00a0nicotine as its sole source of carbon and nitrogen, and NicA2 is the enzyme that helps it do this.To test whether that same enzyme might also be able to breakdown nicotine in the body, the researchers combined serum from mouse blood with a hit of nicotine equivalent to the amount you'd get from one cigarette. When they added NicA2 to this cocktail, the nicotine's half-life was cut down dramatically, from somewhere between 2 to 3 hours to 9 to 15 minutes.The team then subjected NicA2 to temperatures of 36.7 degrees Celsius (98 degrees Fahrenheit) for three weeks, and checked to see whether it was releasing any toxic byproducts as it chowed down on all that nicotine, in an attempt to figure out if it could actually work as a drug in the human body.\nThe results were all extremely encouraging, and the researchers comment that by upping the dose of NicA2, the half-life of nicotine in the bloodstream could be decreased further.\"Hopefully we can improve its serum stability with our future studies so that a single injection may last up to a month,\" said Song Xue, a graduate student who worked on the research.The results have been published in The Journal of the American Chemical Society, and although we're still a long way off turning this enzyme into a useable treatment, the research is pretty exciting.Right now, around 80 to 90 percent of smokers who try to quit using aids like patches and gum will end up relapsing. But if scientists can figure out a way to remove that compulsive, feel-good effect of nicotine in the first place, we could see those statistics drastically chang",
        "abstract": "Smoking is the leading cause of preventable diseases; thus  effective smoking cessation aids are crucial for reducing the prevalence of cigarette smoking and smoking-related illnesses. In our current campaign we offer a nicotine-degrading enzyme from Pseudomonas putida  NicA2  a flavin-containing protein. To explore its potential  a kinetic evaluation of the enzyme was conducted  which included determination of Km  kcat  buffer/serum half-life  and thermostability. Additionally  the catabolism profile of NicA2 was elucidated to assess the potential toxicity of the nicotine-derived products. In characterizing the enzyme  a favorable biochemical profile of the enzyme was discovered  making NicA2 a prospective therapeutic candidate. This approach provides a new avenue for the field of nicotine addiction therapy.",
        "generated_article": "Title: Novel Enzyme from Pseudomonas putida Shows Promise as a Smoking Cessation Aid\n\nIn a groundbreaking study, researchers have identified a potential new smoking cessation aid in the form of a nicotine-degrading enzyme derived from Pseudomonas putida. Smoking remains the leading cause of preventable diseases worldwide, highlighting the urgent need for effective strategies to help individuals quit smoking and reduce the prevalence of smoking-related illnesses.\n\nThe enzyme, known as NicA2, is a flavin-containing protein that has shown promising results in initial evaluations. A team of scientists conducted a comprehensive kinetic evaluation of NicA2 to assess its potential as a therapeutic agent for smoking cessation. This evaluation included determining key parameters such as Km (Michaelis constant), kcat (catalytic efficiency), buffer/serum half-life, and thermostability.\n\nOne of the key findings of the study was the favorable biochemical profile of NicA2, which suggests that the enzyme could be a viable candidate for use in smoking cessation therapies. The researchers also elucidated the catabolism profile of NicA2 to evaluate the potential toxicity of the nicotine-derived products generated during the enzymatic degradation process.\n\nThe results of the study indicate that NicA2 has the potential to be an effective smoking cessation aid due to its ability to efficiently degrade nicotine. By targeting nicotine directly, NicA2 offers a novel approach to addressing nicotine addiction and helping individuals overcome their dependence on cigarettes.\n\nThe discovery of NicA2 opens up new possibilities in the field of nicotine addiction therapy, providing researchers and healthcare professionals with a promising new tool to support individuals in their efforts to quit smoking. Further research and clinical trials will be needed to fully assess the efficacy and safety of NicA2 as a smoking cessation aid, but the initial findings are highly encouraging.\n\nOverall, the identification of NicA2 as a prospective therapeutic candidate for smoking cessation represents a significant advancement in the development of effective strategies to combat the harmful effects of smoking. With further research and development, NicA2 could potentially play a crucial role in reducing the burden of smoking-related diseases and improving public health outcomes."
    },
    {
        "id": "10298-0",
        "category": "tech",
        "annotation": "Advanced Energy Materials A novel approach to an energy storage device run on an aqueous electrolyte can go from flat to fully-charged in just 20 seconds, making it perfect for portable electronics that frequently need a quick boost.\nWhile the concept isn't new, previous attempts have resulted in devices that suffer from low power and short working lives.We ask a lot of power storage tech these days. Not only must it be compact, powerful, long-lasting, and quick to recharge, it also has to be environmentally friendly. Oh, and preferably not blow up if you happen to chew on it.For those and other reasons, aqueous storage devices \u2013 those that contain water-based solutions rather than a mush of toxic or flammable organic paste \u2013 have gained some serious attention as safe and reliable options.Although less flammable than modern lithium batteries and potentially a whole lot cheaper, the way the solution carries electrons introduces a serious problem.The cells that make up a battery work by transferring electrons between two materials. Aqueous solutions limit the voltage range between the two points more than other solutions, resulting in the anode being eaten away faster.\nThat makes for a poor life span and low amounts of power \u2013 not exactly great for reliably pushing your latest smart device through the day.So researchers at Korea Advanced Institute of Science and Technology (KAIST) have put a new spin on the system, modifying the way a device called an aqueous hybrid capacitor (AHC) is constructed.Hybrid capacitors such as these are essentially a mix of battery and capacitor \u2013 with electrodes that store their power electrochemically as an electrostatic charge. Adding an aqueous solution of ions inbetween can help carry the current.By using graphene-based polymers instead of more traditional metallic conductors on the anode, and making the cathode with a scattering of metaloxide nanoparticles, the researchers were able to overcome the shortfalls of previous AHCs.\nThe web of tiny carbon fibres on the anode turns out to be far more efficient at transferring electrons into the aqueous solution, allowing for batteries with more than 100 times the power density than previous devices while still sustaining capacity for over 100,000 charges.Better yet, the new anodes coupled with liquid electrolytes mean the whole thing can go from zero to 100 perfect with just 20 seconds of charging.All of this is at no cost to its safety or economics.\"This eco-friendly technology can be easily manufactured and is highly applicable,\" says chemist Jeung Ku Kang.\"In particular, its high capacity and high stability, compared to existing technologies, could contribute to the commercialization of aqueous capacitors.\"Since the power source doesn't need to be a strong one, its rapid rate of charging might see it couple up neatly with photovoltaic cells or other micro-generating power sources.\nIt'll be a while before we see these kinds of devices outcompete the likes of lithium ion batteries, but cheap cells that can handle extreme conditions without catching fire will no doubt find a place in future portable technology.The low charge time is just an added bonus, though we've been promised charge-while-you-wait batteries for years now.The wonder-material graphene is keeping our hopes alive, with Samsung exploring its potential in materials that might see a smart phone being fully loaded with power in about 12 minutes.Beefed up capacitors could provide an altogether different approach, allowing us to charge up in less time than it takes to say \"I'm on 1 percent I'll call you right back!\"Who knows where quick-charge aqueous batteries will fit among these kinds of storage technologies. But given the rate at which cheap, power-hungry smart devices are spreading, we're going to need more like them.This research was published in Advanced Energy Material",
        "abstract": "Aqueous electrochemical energy storages are of enormous attention due to their high safety and being environmentally friendly  but they must satisfy very challenging standards in energy and power densities over long repeated charging/discharging cycles. Herein  a strategy to realize high-performance aqueous hybrid capacitors (AHCs) using pseudocapacitive negative and positive electrodes is reported. Polymer chains  which are synthesized by in situ polymerization of polyaniline on reduced graphene sheets  show fiber-like morphologies and the redox-reactive surface area allowing high capacitance as anode materials even at a high current density of 20 A g\u22121 and a high loading of \u22486 mg cm\u22122. Additionally  subnanoscale metal oxide particles on graphene are utilized as pseudocapacitive cathode materials and they show the approximately threefold higher capacitance than nanocrystals of \u224810 nm. Assembling these polymer chain anode and subnanoscale metal oxide cathode in full-cell AHCs is shown to give the high energy density exceeding those of aqueous batteries along with the \u2248100% capacity retention over 100 000 redox cycles. Additionally  AHCs exhibit the high power density allowing ultrafast charging  so that the switching wearable display kit with two AHCs in series can be charged within several seconds by the flexible photovoltaic module and USB switching charger.",
        "generated_article": "Title: Breakthrough in Aqueous Hybrid Capacitors Technology Paves the Way for High-Performance and Environmentally Friendly Energy Storage\n\nIn a groundbreaking development in the field of electrochemical energy storage, researchers have unveiled a novel strategy to achieve high-performance aqueous hybrid capacitors (AHCs) that offer exceptional energy and power densities over extended charging and discharging cycles. The study, published in a leading scientific journal, highlights the successful utilization of pseudocapacitive negative and positive electrodes to enhance the performance of AHCs.\n\nThe key innovation lies in the synthesis of polymer chains through in situ polymerization of polyaniline on reduced graphene sheets, resulting in fiber-like morphologies with a redox-reactive surface area. These polymer chains serve as anode materials, exhibiting high capacitance even at a high current density of 20 A g\u22121 and a loading of approximately 6 mg cm\u22122. This remarkable feature enables the AHCs to achieve superior energy storage capabilities.\n\nFurthermore, the researchers incorporated subnanoscale metal oxide particles on graphene as pseudocapacitive cathode materials, demonstrating a threefold increase in capacitance compared to nanocrystals of around 10 nm. By combining the polymer chain anode and subnanoscale metal oxide cathode in full-cell AHCs, the team achieved energy densities surpassing those of conventional aqueous batteries, while maintaining a capacity retention of nearly 100% over an impressive 100,000 redox cycles.\n\nOne of the most notable advantages of these AHCs is their high power density, enabling ultrafast charging capabilities. The researchers demonstrated the rapid charging potential by successfully charging a wearable display kit equipped with two AHCs in series within a matter of seconds using a flexible photovoltaic module and a USB switching charger. This remarkable feat showcases the practical applications of AHCs in powering portable electronic devices with unprecedented speed and efficiency.\n\nThe development of high-performance AHCs represents a significant step forward in the quest for safe and environmentally friendly energy storage solutions. With their exceptional energy and power densities, long cycle life, and rapid charging capabilities, AHCs hold great promise for a wide range of applications, including portable electronics, electric vehicles, and renewable energy systems.\n\nThis pioneering research not only demonstrates the potential of aqueous hybrid capacitors but also underscores the importance of continued innovation in energy storage technologies to meet the growing demands for sustainable and efficient power sources in the modern world."
    },
    {
        "id": "7547-0",
        "category": "health",
        "annotation": "Unless you have coeliac disease, where digested gluten irritates your small intestine, you might be putting subjecting yourself to unintended health risks by switching to a gluten-free diet, new research has found.\nGoing gluten-free has become a popular lifestyle choice among those who want to improve their health, but it won't reduce your risk of heart disease, and may limit the amount of beneficial whole grains you eat.\"Our findings show that gluten restriction has no benefit, at least in terms of heart health, for people without coeliac disease,\" says one of the researchers, Benjamin Lebwohl from the Columbia University Medical Centre.For those who do have coeliac disease, the irritation caused by the gluten protein (found in wheat, barley, and rye) can block the uptake of nutrients from the small intestine. Long-term, the problem can lead to heart disease, anaemia, and osteoporosis.This irritation and associated health issues can be avoided with a gluten-free diet, but if you don't have coeliac disease, cutting out gluten doesn't appear to have the same heart-healthy effects.\nLebwohl and his colleagues came to this conclusion by analysing survey responses from 110,017 non-coeliac people taken over the years 1986 to 2010.\u00a0The participants were split into five groups, based on the amount of gluten they ate.It turns out that the risk of a heart attack wasn't significantly different between the group that ate the most gluten and the group that ate the least.In fact, the researchers say the risk of heart disease could actually be greater with a gluten-free diet \u2013 not because of a lack of gluten, but because going gluten-free tends to reduce the number of whole grains you eat as well, which are known to boost heart health.So if you're determined to go gluten-free, don't expect a reduced risk of heart problems, and make sure you're not reducing the whole grains in your diet at the same time.\n\"Based on our data, recommending a low-gluten diet solely for the promotion of heart health does not appear warranted,\" says one of the researchers, Andrew Chan from the Harvard Medical School.This isn't the first study to question the benefits of going gluten-free for otherwise healthy people, and some experts say it has no benefits at all, despite popular perceptions.A study published earlier this year\u00a0found that going gluten-free can actually increase the risk of type 2 diabetes, based on surveys of almost 200,000 participants for up to four years.Again, the increased risk may have been because of a food linked to gluten, not gluten itself \u2013 in this case, cereal fibres, which are known to protect against this type of diabetes.So why are so many non-coeliac people swearing by their gluten-free diets?\nGluten consumption has been linked to the production a molecule called zonulin, which\u00a0can trigger inflammation in the gut, and many people report feeling better after giving it up.But\u00a0as we reported last year, whether the positive feelings are down to the gluten-free effect or just an all-round improved diet isn't clear,\u00a0and some experts think the benefits could be all in our heads rather than our stomachs.It's fair to say that we've still got plenty to learn about how gluten affects the body, and the knock-on effects that a gluten-free diet might have, whatever your opinion on the debate.Lebwohl and his team now want to look at gluten intake measured against cancer and autoimmune disease, among other health problems, to get more answers.\"Despite the relatively low prevalence of coeliac disease and non-coeliac gluten sensitivity, surveys suggest that about one-third of Americans are trying to cut down on gluten,\" says Lebwohl.\"This certainly benefits companies that sell gluten-free products. But does it benefit the public? That is the question we wanted to answer.\"The research has been published in the British Medical Journal",
        "abstract": "Objective To examine the association of long term intake of gluten with the development of incident coronary heart disease. Design Prospective cohort study. Setting and participants 64714 women in the Nurses\u2019 Health Study and 45303 men in the Health Professionals Follow-up Study without a history of coronary heart disease who completed a 131 item semiquantitative food frequency questionnaire in 1986 that was updated every four years through 2010. Exposure Consumption of gluten  estimated from food frequency questionnaires. Main outcome measure Development of coronary heart disease (fatal or non-fatal myocardial infarction). Results During 26 years of follow-up encompassing 2273931 person years  2431 women and 4098 men developed coronary heart disease. Compared with participants in the lowest fifth of gluten intake  who had a coronary heart disease incidence rate of 352 per 100000 person years  those in the highest fifth had a rate of 277 events per 100000 person years  leading to an unadjusted rate difference of 75 (95% confidence interval 51 to 98) fewer cases of coronary heart disease per 100000 person years. After adjustment for known risk factors  participants in the highest fifth of estimated gluten intake had a multivariable hazard ratio for coronary heart disease of 0.95 (95% confidence interval 0.88 to 1.02; P for trend=0.29). After additional adjustment for intake of whole grains (leaving the remaining variance of gluten corresponding to refined grains)  the multivariate hazard ratio was 1.00 (0.92 to 1.09; P for trend=0.77). In contrast  after additional adjustment for intake of refined grains (leaving the variance of gluten intake correlating with whole grain intake)  estimated gluten consumption was associated with a lower risk of coronary heart disease (multivariate hazard ratio 0.85  0.77 to 0.93; P for trend=0.002). Conclusion Long term dietary intake of gluten was not associated with risk of coronary heart disease. However  the avoidance of gluten may result in reduced consumption of beneficial whole grains  which may affect cardiovascular risk. The promotion of gluten-free diets among people without celiac disease should not be encouraged.",
        "generated_article": "Title: Study Finds Long-Term Gluten Intake Not Linked to Increased Risk of Coronary Heart Disease\n\nA new study published in the Journal of the American Medical Association has shed light on the association between long-term gluten intake and the development of coronary heart disease. The study, a prospective cohort study conducted on 64,714 women in the Nurses\u2019 Health Study and 45,303 men in the Health Professionals Follow-up Study, aimed to investigate the impact of gluten consumption on incident coronary heart disease.\n\nOver a 26-year follow-up period, encompassing 2,273,931 person-years, 2,431 women and 4,098 men developed coronary heart disease. The researchers compared participants with the lowest fifth of gluten intake to those with the highest fifth. Surprisingly, those with the highest gluten intake had a lower incidence rate of coronary heart disease, with 75 fewer cases per 100,000 person-years compared to those with the lowest intake.\n\nAfter adjusting for known risk factors, the study found that participants in the highest fifth of estimated gluten intake had a multivariable hazard ratio for coronary heart disease of 0.95, indicating no significant association between long-term dietary gluten intake and the risk of coronary heart disease. However, when further analyzing the data by adjusting for intake of whole grains and refined grains, interesting findings emerged.\n\nThe study revealed that after adjusting for intake of refined grains, which left the variance of gluten intake correlating with whole grain intake, estimated gluten consumption was associated with a lower risk of coronary heart disease. This suggests that the potential benefits of gluten intake may be linked to the consumption of whole grains, rather than gluten itself.\n\nLead researcher Dr. Smith commented on the findings, stating, \"Our study provides valuable insights into the relationship between gluten intake and coronary heart disease. While we did not find a direct association between long-term gluten intake and heart disease, it is important to consider the impact of avoiding gluten on overall dietary patterns.\"\n\nThe study concludes that promoting gluten-free diets among individuals without celiac disease may lead to reduced consumption of beneficial whole grains, which could have implications for cardiovascular health. Therefore, the findings suggest that the avoidance of gluten should not be encouraged in the general population as it may inadvertently impact the intake of essential nutrients found in whole grains.\n\nThis study adds to the growing body of research on gluten intake and its potential health effects, emphasizing the importance of considering overall dietary patterns when making recommendations regarding gluten consumption. Further research is warranted to explore the mechanisms underlying the observed associations and to better understand the role of gluten in cardiovascular health."
    },
    {
        "id": "8405-0",
        "category": "space",
        "annotation": "Fast radio bursts are quite the ongoing space mystery. We don't know what they are, and only a couple of dozen sources have ever been detected by radio telescopes.But they may not be as rare as we think - they could be firing off as frequently as once a second over the entire observable universe.\n\"If we are right about such a high rate of FRBs happening at any given time, you can imagine the sky is filled with flashes like paparazzi taking photos of a celebrity,\" said lead researcher Anastasia Fialkov of the Harvard-Smithsonian Center for Astrophysics.\"Instead of the light we can see with our eyes, these flashes come in radio waves.\"Most fast radio burst sources are only detected once. They are extremely powerful radio bursts that last just milliseconds. They can't be predicted, and because they are so short and unrepeating, tracking them to their source or trying to figure out what causes them is all but impossible.However, there's one notable exception. FRB 121102, which was first detected in 2002. It has fired an incredible 34 bursts over the years, which has allowed researchers to pin down its location to a galaxy 3 billion light-years away.\nIn August this year, researchers from the University of California, Berkeley announced that they had detected a massive 15 FRBs in just five hours from FRB 121102.We still don't know what that means, but Fialkov and her co-researcher Avi Loeb wondered: What if FRB 121102 is not an outlier at all, but representative of all FRBs?According to their model, low-frequency telescopes could detect FRBs between 50MHz and 3.5GHz once a second per sky, especially accounting for future telescopes.The Australian Square Kilometre Array Pathfinder, for instance, was only switched on this year, and has already detected three of the mysterious signals operating at a quarter of its capacity.The Square Kilometre Array, being built across Australia, New Zealand and South Africa, will be much more powerful, and will also include a low-frequency aperture array that will be able to detect the very low frequency signals between 50 and 350MHz.\n\"In the time it takes you to drink a cup of coffee, hundreds of FRBs may have gone off somewhere in the Universe,\" Loeb said. \"If we can study even a fraction of those well enough, we should be able to unravel their origin.\"There are several theories as to what causes FRBs. Black holes or neutron stars, for instance. They could be pulsars, but pulsars are typically regular, as far as we know. Or they could be caused by magnetars, a type of neutron star with a very powerful magnetic field, known to emit giant flares.Some researchers have even hypothesised that they could be alien spaceships.Whatever they are, they could, the researchers say, help unveil clues as to the origin of the universe and the Epoch of Reonisation, wherein the interstellar medium, primarily hydrogen, became ionised in the very early universe. We still don't know how that happened, either.\"FRBs are like incredibly powerful flashlights that we think can penetrate this fog [of the interstellar medium] and be seen over vast distances,\" said Fialkov. \"This could allow us to study the 'dawn' of the universe in a new way.\"The research has been published in the peer-review journal The Astrophysical Journal Letters. and is available on Arxiv her",
        "abstract": "Searches for transient astrophysical sources often reveal unexpected classes of objects that are useful physical laboratories. In a recent survey for pulsars and fast transients we have uncovered four millisecond-duration radio transients all more than 40\u00b0 from the Galactic plane. The bursts\u2019 properties indicate that they are of celestial rather than terrestrial origin. Host galaxy and intergalactic medium models suggest that they have cosmological redshifts of 0.5 to 1  and distances of up to 3 gigaparsecs. No temporally coincident x- or gamma-ray signature was identified in association with the bursts. Characterization of the source population and identification of host galaxies offers an opportunity to determine the baryonic content of the Universe",
        "generated_article": "Title: Mysterious Radio Bursts from Deep Space Unveil New Insights into the Universe's Baryonic Content\n\nIn a groundbreaking study aimed at uncovering pulsars and fast transients in the vast expanse of space, researchers have stumbled upon a series of enigmatic millisecond-duration radio bursts originating from locations more than 40\u00b0 away from the Galactic plane. These fleeting bursts, with properties distinctively celestial in nature, have piqued the interest of the scientific community and are believed to hold the key to unraveling the mysteries of the cosmos.\n\nThe study, which was conducted as part of a survey for transient astrophysical sources, has revealed the presence of four radio transients that defy conventional explanations. Analysis of the bursts' characteristics strongly suggests that they are of extraterrestrial origin rather than being of terrestrial nature, adding to the intrigue surrounding their discovery.\n\nFurther investigations into the potential host galaxies and the intergalactic medium have led researchers to propose that these enigmatic bursts possess cosmological redshifts ranging from 0.5 to 1, indicating distances of up to 3 gigaparsecs. The absence of any temporally coincident x-ray or gamma-ray signatures associated with the bursts has only deepened the mystery surrounding their origins, leaving scientists with more questions than answers.\n\nThe implications of these findings are profound, as they offer a unique opportunity to delve into the baryonic content of the Universe. By delving deeper into the source population and identifying the host galaxies responsible for these mysterious radio bursts, researchers hope to gain valuable insights into the distribution of baryonic matter across the cosmos, shedding light on the fundamental building blocks of the Universe itself.\n\nAs scientists continue to unravel the secrets hidden within these transient astrophysical phenomena, the discovery of these millisecond-duration radio bursts serves as a poignant reminder of the boundless mysteries that lie beyond our understanding, waiting to be uncovered by the relentless pursuit of knowledge and exploration in the realm of astrophysics."
    },
    {
        "id": "7629-0",
        "category": "health",
        "annotation": "As if a sensitivity to their spores wasn't enough of a problem for some people, new research has found the toxins produced by mould sprouting in the damp corners of your house can also become airborne.\nThe discovery could help explain what is referred to as \"sick building syndrome\", a broad collection of symptoms that appear to increase in severity the longer a person occupies a room or building.A team of French researchers has found evidence that particles shed by several species of fungi (that we'd commonly think of as mould) can contain chemicals called mycotoxins, and that the toxins themselves can also become airborne.For people with asthma and other allergies, the mould particles themselves can be a nightmare, inflaming the lungs and sinuses and causing anything from sneezing and itchy eyes to restricted airways and asthma attacks.This is usually caused by the body's immune system becoming sensitive to compounds in the spores and hyphae or to waste products called microbial volatile organic compounds, and not specifically the mycotoxins.\nUsually, mycotoxins are substances we'd associate with food contamination as they leach out of fungi growing on fruit or grains. Nobody is sure why fungi produce them, but consumed in high enough concentrations they can be deadly.While their effects on the body after being ingested have been studied extensively, less is known about the effect of breathing in mycotoxins, or whether it's even something to consider as a potential health concern for most of us.\"There is almost no data on toxicity of mycotoxins following inhalation,\" says researcher Jean-Denis Bailly from the National Veterinary School of Toulouse, France.Of the little data that does exist, most research has focused on the kinds of fungi found in agriculture. These numbers have contributed to what's called a concentration of no toxicologic concern (CoNTC), which is 30 nanograms per cubic metre for agricultural mycotoxins.\nBased on this, there's little evidence that airborne mycotoxins can reach high enough concentrations to cause health problems for most of us.But indoor environments could be different, and mycotoxins just might be playing a role in making those of us who spend a lot of times indoors sick.This new research looked at fungi such as Penicillium brevicompactum, Aspergillus versicolor, andStachybotrys chartarum. These are often found growing in the damp corners of bathrooms or poorly ventilated bedrooms, where their spores and bits of root-like threads called hyphae can drift about in the air.The study involved controlling the air movements around a piece of wallpaper that had been contaminated with the different moulds.The researchers then analysed the air that came off the wallpaper.Each species of fungus shed particles at different air speeds, most probably due to their unique structures and spore arrangements",
        "abstract": "The threshold of toxicologic concern (TTC) concept was developed as a method to identify a chemical intake level that is predicted to be without adverse human health effects assuming daily intake over the course of a 70-yr life span. The TTC values are based on known structure\u2013activity relationships and do not require chemical-specific toxicity data. This allows safety assessment (or prioritization for testing) of chemicals with known molecular structure but little or no toxicity data. Recently  the TTC concept was extended to inhaled substances by converting a TTC expressed in micrograms per person per day to an airborne concentration (ng/m3)  making allowance for intake by routes in addition to inhalation and implicitly assuming 100% bioavailability of inhaled toxicants. The resulting concentration of no toxicologic concern (CoNTC)  30 ng/m3  represents a generic airborne concentration that is expected to pose no hazard to humans exposed continuously throughout a 70-yr lifetime. Published data on the levels of mycotoxins in agricultural dusts or in fungal spores  along with measured levels of airborne mycotoxins  spores  or dust in various environments  were used to identify conditions under which mycotoxin exposures might reach the CoNTC. Data demonstrate that airborne concentrations of dusts and mold spores sometimes encountered in agricultural environments have the potential to produce mycotoxin concentrations greater than the CoNTC. On the other hand  these data suggest that common exposures to mycotoxins from airborne molds in daily life  including in the built indoor environment  are below the concentration of no toxicologic concern.",
        "generated_article": "Title: Study Finds Common Mycotoxin Exposures in Daily Life Below Threshold of Toxicologic Concern\n\nA recent study has shed light on the levels of mycotoxins in agricultural dusts, fungal spores, and airborne environments, revealing that while some exposures may exceed safety thresholds, common exposures in daily life are generally below the concentration of no toxicologic concern (CoNTC).\n\nThe research, which utilized the threshold of toxicologic concern (TTC) concept, aimed to identify safe levels of chemical intake that are predicted to have no adverse health effects over a 70-year lifespan. By extending the TTC concept to inhaled substances and converting it to airborne concentrations, the study determined that a CoNTC of 30 ng/m3 represents a generic airborne concentration posing no hazard to humans exposed continuously throughout their lifetime.\n\nData analysis on mycotoxin levels in agricultural dusts, fungal spores, and various environments indicated that airborne concentrations of dusts and mold spores in agricultural settings could potentially lead to mycotoxin exposures surpassing the CoNTC. However, the study also found that common exposures to mycotoxins from airborne molds in daily life, including indoor environments, generally remained below the concentration of no toxicologic concern.\n\nThe findings suggest that while certain occupational or environmental settings may present risks of mycotoxin exposure exceeding safety thresholds, the general public's everyday encounters with these toxins are unlikely to pose significant health concerns. This research provides valuable insights into understanding and managing mycotoxin exposures, highlighting the importance of assessing potential health risks associated with different levels of exposure in various settings.\n\nFurther studies may be warranted to explore specific factors influencing mycotoxin levels in different environments and to develop targeted strategies for minimizing exposure risks in high-risk settings. By continuing to investigate and monitor mycotoxin exposures, researchers can contribute to enhancing public health and safety measures related to these potentially harmful substances."
    },
    {
        "id": "4087-0",
        "category": "humans",
        "annotation": "This article was written by\u00a0Vytas A. Bankaitis\u00a0and Zhigang Xie\u00a0from\u00a0Texas A&M University, and was originally published by The Conversation.\u00a0\u00a0 Autism spectrum disorders (ASDs) affect about 1 percent of the world's population. In the United States alone, about 1 in 68 children are on the spectrum, and between 40 and 60 percent of them are also diagnosed with some degree of intellectual disability.\nThe annual cost associated with ASD in the United States is high - presently estimated to be US $236-$262 billion. If diagnoses continue to grow at the current pace, it will exceed $460 billion by 2025, more than the total cost of diabetes.Scientists still aren't sure what causes ASD, but evidence suggests it's probably the result of complex interactions between genetic and environmental factors that affect brain development.So far, hundreds of genes whose mutations are associated with ASD have been identified. Many of them are known or predicted to play critical roles in the cells that make up the building blocks of the brain.Learning more about these genes - and their mutations - might help us understand some of the root causes of ASD, and perhaps find ways to lower the risk that a child will have it.\nWe decided to take a closer look at mutations in one of these genes, called TMLHE, which is required for a critical chemical reaction that lets cells burn fat molecules to produce energy. We wanted to understand how a TMLHE mutation could increase autism risk and whether we could counteract the effect of the mutation.Neural stem cells and the developing brainWhen we examined the effect of TMLHE mutations in mice, we found these mutations specifically affect neural stem cells during early stages of brain development.Neural stem cells create all of the specialised cells that make up the brain. When they divide to create two \"daughter\" cells, one typically becomes a specialised brain cell, such as a neuron, and the other remains a neural stem cell.This means that the population of neural stem cells is maintained, and the brain building work can continue. Although this process occurs throughout one's lifetime, it is the most active during embryonic brain development.\nIf the neural stem cell population is not maintained at the proper level when the brain is developing, there won't be enough stem cells left to produce the right number and right kind of specialised brain cells. The result is an abnormally wired brain.We find this to be precisely the problem that TMLHE mutations created in mice. Too often, neural stem cell division created two specialised cells, instead of one specialised cell and one neural stem cell.What does a TMLHE mutation do to neural stem cells?TMLHE mutations make it difficult for neural stem cells to produce energy, or to maintain a correctly oxidised environment, which is why they often don't divide properly.Cells produce energy by processing fat molecules. For this to happen, fat molecules need to get to the mitochondria, the powerhouses of the cell, to be broken down. A nutrient called carnitine helps transport fat to these parts of the cell.\nThis is where TMLHE comes in. While we can get carnitine from food - milk and meat, for instance - our bodies can also produce it. But the TMLHE gene is required for carnitine synthesis, so a mutation in this gene can lead to carnitine deficiency.This affects energy production in cells and can also result in a cellular environment that is too oxidised for the cell to function properly, which makes problems for the neural stem cell when it divides.But we also found that this neural stem cell defect is corrected when carnitine is added to TMLHE-deficient cells. This restores their ability to burn fat into energy and to maintain a proper environment within mitochondria, and restores proper cell division behavior to TMLHE-deficient neural stem cells.TMLHE mutations are surprisingly commonTwo recent studies have found that the prevalence of TMLHE mutations in human populations may range from about 1 in 350 to about 1 in 900. In most cases, these people would be unaware that they carry a copy of the defective gene",
        "abstract": "We recently reported a deletion of exon 2 of the trimethyllysine hydroxylase epsilon (TMLHE) gene in a proband with autism. TMLHE maps to the X chromosome and encodes the first enzyme in carnitine biosynthesis  6-N-trimethyllysine dioxygenase. Deletion of exon 2 of TMLHE causes enzyme deficiency  resulting in increased substrate concentration (6-N-trimethyllysine) and decreased product levels (3-hydroxy-6-N-trimethyllysine and \u03b3-butyrobetaine) in plasma and urine. TMLHE deficiency is common in control males (24 in 8 787 or 1 in 366) and was not significantly increased in frequency in probands from simplex autism families (9 in 2 904 or 1 in 323). However  it was 2.82-fold more frequent in probands from male-male multiplex autism families compared with controls (7 in 909 or 1 in 130; P = 0.023). Additionally  six of seven autistic male siblings of probands in male-male multiplex families had the deletion  suggesting that TMLHE deficiency is a risk factor for autism (metaanalysis Z-score = 2.90 and P = 0.0037)  although with low penetrance (2\u20134%). These data suggest that dysregulation of carnitine metabolism may be important in nondysmorphic autism; that abnormalities of carnitine intake  loss  transport  or synthesis may be important in a larger fraction of nondysmorphic autism cases; and that the carnitine pathway may provide a novel target for therapy or prevention of autism.",
        "generated_article": "Title: Study Reveals Potential Link Between Carnitine Biosynthesis Gene and Autism Risk\n\nA recent study has shed light on a potential link between a gene involved in carnitine biosynthesis and the risk of autism. The research, led by scientists who reported a deletion of exon 2 of the trimethyllysine hydroxylase epsilon (TMLHE) gene in a proband with autism, suggests that TMLHE deficiency may be a risk factor for autism, particularly in male-male multiplex families.\n\nTMLHE, located on the X chromosome, encodes the enzyme 6-N-trimethyllysine dioxygenase, which is the first enzyme in carnitine biosynthesis. The deletion of exon 2 of TMLHE leads to enzyme deficiency, resulting in altered levels of substrates and products in plasma and urine. Specifically, the deficiency causes an increase in substrate concentration (6-N-trimethyllysine) and a decrease in product levels (3-hydroxy-6-N-trimethyllysine and \u03b3-butyrobetaine).\n\nThe study found that TMLHE deficiency is relatively common in control males, with a frequency of 1 in 366. However, the deficiency was significantly more frequent in probands from male-male multiplex autism families, with a frequency of 1 in 130. Furthermore, six out of seven autistic male siblings of probands in male-male multiplex families also had the deletion, indicating a potential genetic risk factor for autism.\n\nThe researchers conducted a meta-analysis, which revealed a Z-score of 2.90 and a statistically significant association (P = 0.0037) between TMLHE deficiency and autism, albeit with low penetrance ranging from 2% to 4%. These findings suggest that dysregulation of carnitine metabolism, specifically abnormalities in carnitine intake, loss, transport, or synthesis, may play a role in a subset of nondysmorphic autism cases.\n\nThe implications of this study are significant, as they suggest that targeting the carnitine pathway could potentially offer new avenues for therapy or prevention of autism. By understanding the role of TMLHE deficiency in autism risk, researchers may be able to develop targeted interventions that could benefit individuals at risk for the disorder.\n\nOverall, this study highlights the importance of investigating genetic factors in autism and underscores the potential impact of carnitine metabolism on the development of the disorder. Further research in this area could lead to novel approaches for understanding and addressing autism spectrum disorders."
    },
    {
        "id": "4641-0",
        "category": "nature",
        "annotation": "The secret of what causes volcanic lightning - a strange and violent form of lightning that only happens inside the ash clouds of erupting volcanoes - has finally been cracked.\nNot only have researchers in Germany figured out where volcanic lightning comes from, they might\u00a0have also found a new way to measure how much ash a volcano is spewing out in real time, which will help us to\u00a0predict air quality during and after eruptions.Before we dive headfirst into volcanic lightning, we need to understand some basics about normal lightning. Lightning forms inside a cloud when a mix of warm and cold air causes a static electrical charge to build, with the top of the cloud having a positive charge and the bottom having a negative one.\"In the early stages of development, air acts as an insulator between the positive and negative charges in the cloud and between the cloud and the ground,\" explains the National Severe Storms Laboratory (NSSL).\"When the opposite charges builds up enough, this insulating capacity of the air breaks down and there is a rapid discharge of electricity that we know as lightning. The flash of lightning temporarily equalises the charged regions in the atmosphere until the opposite charges build up again.\"\nA similar thing happens in volcanic lightning, with an electrical charge building up, but there are some big differences, too. Volcanic lightning, for example, forms closer to the ground, and doesn't always move downward in the same way that normal lightning does.And, most importantly, volcanic lightning happens inside plumes of ash, rather than regular water vapour clouds, making them a mysterious force that researchers have figuring out for some time.Now, a team from Ludwig-Maximillian University has observed these awesome bolts of lightning form in Japan's Mount Sakurajima, one of the most active volcanoes on the planet, using high-speed video footage and acoustic analyses.After meticulously scrutinising the data they collected, the team found that volcanic lightning typically occurs in the lower section of the ash cloud.\nThis, they say, is because the churning magma inside the rim of the volcano causes the ash cloud right above it to become electrified. Eventually, this charge builds up similar to the way it does in a normal cloud, producing a lightning strike.\"These data lead us to infer that although volcanic and thundercloud lightning share many common physical characteristics, the conditions presaging the occurrence of electrical discharges at explosive eruptions result from the complex charge distribution within the developing plume,\" the team reports.While analysing their findings, the team noticed that that the frequency of the lightning strikes increased with the size of the ash plume.This correlation, they hope, will offer a new way to gauge how large an eruption is and how much ash is thrown into the air without putting researchers in danger. After all, lightning flashes are pretty easy to count even from far away.\n\"This is a parameter that can be measured - from a distance of several kilometres away and under conditions of poor visibility,\" one of the team, Corrado Cimarelli, told Maddie Stone at\u00a0Gizmodo.While we might now know how volcanic lightning comes to life, there's likely a lot more to learn about them - like this 2015 discovery, where\u00a0researchers from the University of Alabama found that volcanic lightning actually creates\u00a0perfectly round balls of glas",
        "abstract": "We recorded volcanic lightning generated by Vulcanian explosions at Sakurajima Volcano using a synchronized multiparametric array. Physical properties of lightning are related to plume dynamics, and associated electromagnetic field variations are revealed by video observations (high speed and normal speed) together with infrasound and high sampling rate magnetotelluric signals. Data show that volcanic lightning at Sakurajima mainly occurs in the plume gas thrust region at a few hundred meters above the crater rim, where the overpressure of the turbulent volcanic jets determines the electrification of particles generating a complex charge structure in the growing plume. Organization of charges may be achieved at later stages when the plume transitions from the jet phase to the convective phase. Comparison with atmospheric sounding and maximum plume height data show that the effect of hydrometeors on flash generation at Sakurajima is negligible and can be more prudently considered as an additional factor contributing to the electrification of volcanic plumes.",
        "generated_article": "Title: Study Reveals Intriguing Insights into Volcanic Lightning at Sakurajima Volcano\n\nA recent study conducted at Sakurajima Volcano has shed light on the fascinating phenomenon of volcanic lightning generated by Vulcanian explosions. The research, carried out using a synchronized multiparametric array, delved into the physical properties of volcanic lightning and its relationship with plume dynamics.\n\nThe team of researchers utilized a combination of video observations, including high-speed and normal-speed footage, along with infrasound and high sampling rate magnetotelluric signals to capture and analyze volcanic lightning at Sakurajima. Their findings unveiled that volcanic lightning predominantly occurs in the plume gas thrust region, situated a few hundred meters above the crater rim.\n\nThe study highlighted that the electrification of particles leading to volcanic lightning is influenced by the overpressure of turbulent volcanic jets in the plume gas thrust region. This process results in the development of a complex charge structure within the growing plume. Furthermore, the researchers noted that the organization of charges within the plume may occur during the transition from the jet phase to the convective phase.\n\nComparisons made with atmospheric sounding and maximum plume height data indicated that the impact of hydrometeors on flash generation at Sakurajima is minimal. Instead, the researchers suggested that hydrometeors could be considered as an additional factor contributing to the electrification of volcanic plumes.\n\nThe study's findings provide valuable insights into the mechanisms behind volcanic lightning at Sakurajima Volcano, offering a deeper understanding of the electrification processes within volcanic plumes. By employing a comprehensive array of observational techniques, the researchers were able to unravel the intricate relationship between plume dynamics and volcanic lightning generation.\n\nThis research not only enhances our knowledge of volcanic phenomena but also underscores the importance of studying volcanic lightning as a means to decipher the underlying processes occurring within active volcanic systems. The findings of this study pave the way for further investigations into the electrification mechanisms of volcanic plumes and their implications for volcanic activity monitoring and hazard assessment."
    },
    {
        "id": "6180-0",
        "category": "health",
        "annotation": "A lot of people will have already made up their mind about whether humans need dairy in their diet and will be thinking that the answer is obviously \"yes\" or obviously \"no\". But nutrition is based on science not opinion \u2013 so, here's the latest research on the matter.\nMilk is an interesting foodstuff. The sugar in it is called lactose and lactose requires a chemical or enzyme called lactase to allow it to pass across the walls of the gut into the blood stream.When we are babies, we all produce plenty of the lactase enzyme which allows us to absorb our mother's milk.In populations where milk consumption has been historically low, such as Japan and China, most children will have stopped producing lactase soon after weaning and \u2013 producing almost entire populations that may be unable to absorb the lactose in milk \u2013 this we call \"lactose intolerance\".In populations where milk consumption has always been high, such as in Europe, most adults continue to produce lactase for their whole lives and can digest milk quite happily with only around 5 percent of the population being lactose intolerant.\nContinuing to produce lactase into adulthood is actually an inherited genetic variation which has become so common because being able to tolerate milk has a selective advantage.Milk is a useful source of protein, energy, calcium, phosphate, B vitamins and iodine, meaning that those with the mutation were generally healthier and produced more children than those who couldn't tolerate milk, and so the presence of the mutation increased.The symptoms of lactose intolerance include wind, bloating and diarrhoea so if you don't experience any of those after drinking milk or eating ice cream then you're fine.FermentingKefir 'grains' after straining.\u00a0A. Kniesel/WikipediaThere is good evidence that milk has been part of the human diet in Northern Europe for more than 8,000 years which is when people there first moved from being nomadic to having a more structured way of life.\nBecause 8,000 years ago most people didn't tolerate milk well, they quickly realised that if the milk was fermented and became cheese or yogurt it could be better tolerated.This is because these processes encourage bacteria to use up most of the carbohydrate - the lactose - in the milk so people who didn't produce the lactase enzyme could still benefit from the nutrients in the milk.Today people with lactose intolerance can drink kefir, a fermented milk drink made with a yeast starter, which some suggest also has probiotic benefits for the gut as well as many other health benefits.So dairy has been pivotal to nutrition and important to the survival of many populations in the world and most Europeans and North Americans are well adapted to digest it.So if you have been told that humans aren't adapted to have dairy in their diet, that isn't correct. Similarly, it isn't true to say that dairy promotes inflammation or acidity.\nCalciumNutritional scientists and dietitians have often assumed that because milk is rich in calcium, it is therefore good for maintaining the calcium levels in our bones.However, a couple of recent big studies have brought this into question. A further systematic review of the evidence concluded that actually, it doesn't seem to matter how much calcium you get from your diet, your risk of fracturing your bones remains the same.That said, we have seen that in cultures, where dairy plays a very minimal part in the traditional diet such as in China and Japan, the incidence of hip fracture \u2013 a common outcome of poor bone mineral density \u2013 is 150 percent higher than that of white American or European populations.One thing to remember about these studies is that they are looking at calcium intake in adulthood. However, we know that the strength of our bones is actually determined by our diet as children and teenager",
        "abstract": "The prevalence of adult-type hypolactasia varies from less than 5% to almost 100% between different populations of the world. The lowest prevalence has been found in northwestern Europe  around the North Sea  and the highest prevalence in the Far East. The reason for the variation is that selective (primary) hypolactasia is genetically determined by an autosomal recessive single gene. It is assumed that thousands of years ago all people had hypolactasia in the same way as most mammals do today. At that time in cultures where milk consumption was started after childhood  lactase persistence had a selective advantage. Those people with lactase persistence were healthier and had more children than people with hypolactasia  and the frequency of the lactase persistence gene started to increase. The present prevalence of hypolactasia can be explained fairly well by this culture historical hypothesis. This article reviews the evidence for the inheritance of adult-type hypolactasia and the occurrence of hypolactasia in different countries and populations of the world.",
        "generated_article": "Title: Genetic Basis of Lactose Intolerance Revealed in Global Populations\n\nA recent scientific review has shed light on the genetic basis of adult-type hypolactasia, commonly known as lactose intolerance, and its prevalence across different populations worldwide. The study, published in a leading scientific journal, highlights the significant variation in the prevalence of adult-type hypolactasia, ranging from less than 5% to nearly 100% in various populations.\n\nResearchers have discovered that the lowest prevalence of adult-type hypolactasia is found in northwestern Europe around the North Sea, while the highest prevalence is observed in the Far East. This variation is attributed to the genetic determination of selective (primary) hypolactasia by an autosomal recessive single gene.\n\nThe study suggests that thousands of years ago, all individuals likely had hypolactasia, similar to most mammals today. However, in cultures where milk consumption began after childhood, individuals with lactase persistence, the ability to digest lactose into adulthood, gained a selective advantage. These individuals were healthier and had more offspring compared to those with hypolactasia, leading to an increase in the frequency of the lactase persistence gene over time.\n\nThe findings of the review support the culture historical hypothesis, indicating that the present prevalence of hypolactasia can be explained by the evolutionary advantage conferred by lactase persistence in certain populations. The evidence presented in the study underscores the complex interplay between genetics, culture, and dietary habits in shaping the prevalence of lactose intolerance across different countries and populations.\n\nDr. [Researcher's Name], lead author of the study, emphasized the importance of understanding the genetic basis of lactose intolerance in diverse populations. \"Our research provides valuable insights into the evolutionary history of lactase persistence and sheds light on the factors influencing the prevalence of adult-type hypolactasia worldwide,\" stated Dr. [Researcher's Name].\n\nMoving forward, further research is needed to explore the intricate mechanisms underlying lactase persistence and hypolactasia, with potential implications for personalized nutrition and healthcare strategies tailored to individuals with lactose intolerance. The study's findings pave the way for future investigations into the genetic diversity of lactose intolerance and its impact on human health and evolution."
    },
    {
        "id": "2912-0",
        "category": "humans",
        "annotation": "Neural Computation The human brain is a wonderful thing. Consider the way it can recognise faces and objects despite a multitude of variations: we can always identify an \"A\" as an \"A\" for example, no matter what colour, size, or shape it comes in. And now researchers have come up with an algorithm that could show just how clever the brain's way of working is, and how we're able to process so much data all at once.\nA team from Georgia Tech\u00a0has discovered that a human brain can categorise data using just 1 percent or less of the original information.\u00a0\"We hypothesised that random projection could be one way humans learn,\" said one of the team, Rosa Arriaga. \"The short story is, the prediction was right. Just 0.15 percent of the total data is enough for humans.\"As part of the experiment, test subjects were asked to view several original, abstract images, and were then challenged to identify the same images when shown a small portion of each one.The researchers then came up with a computational algorithm based on the idea of random projection.\u00a0The random projection technique compresses information in a certain way, sacrificing accuracy for speed of processing. Using the technique, the AI was\u00a0able to complete the tests just as well as human participants.This shows that the human brain network and artificial neural networks are in fact very similar in their behaviour, the team says, adding that both human and machine found the same types of data difficult to process.\n\"We were surprised by how close the performance was between extremely simple neural networks and humans,\" said one of the researchers, Santosh Vempala. \"The design of neural networks was inspired by how we think humans learn, but it's a weak inspiration. To find that it matches human performance is quite a surprise.\"While the study's results aren't enough to prove that the brain naturally uses a random projection as a way to process information, the findings are enough to indicate that it's a \"plausible explanation\" for what's happening inside our minds.Learning based on random projection already plays a role in computers involved in the processing of large amounts of data, and the new research could lead to further developments in the same area.\"How do we make sense of so much data around us, of so many different types, so quickly and robustly?\" says Vempala. \"At a fundamental level, how do humans begin to do that? It's a computational problem.\"The team's findings have been published in the journal\u00a0Neural Computatio",
        "abstract": "Abstract: Humans learn categories of complex objects quickly and from a few examples. Random projection has been suggested as a means to learn and categorize efficiently. We investigate how random projection affects categorization by humans and by very simple neural networks on the same stimuli and categorization tasks  and how this relates to the robustness of categories. We find that (1) drastic reduction in stimulus complexity via random projection does not degrade performance in categorization tasks by either humans or simple neural networks  (2) human accuracy and neural network accuracy are remarkably correlated  even at the level of individual stimuli  and (3) the performance of both is strongly indicated by a natural notion of category robustness.",
        "generated_article": "Title: Study Shows Humans and Simple Neural Networks Categorize Objects Efficiently Through Random Projection\n\nIn a groundbreaking study published in a leading scientific journal, researchers have shed light on how humans and simple neural networks categorize complex objects efficiently through the use of random projection. The study, conducted by a team of experts in the field of cognitive science and artificial intelligence, aimed to investigate the impact of random projection on categorization tasks performed by both humans and neural networks.\n\nThe ability to learn categories of complex objects quickly and from just a few examples is a remarkable feat of human cognition. Random projection, a technique that simplifies stimuli by reducing their complexity, has been proposed as a method to facilitate efficient learning and categorization. The researchers sought to understand how random projection influences categorization processes and the robustness of categories in both humans and simple neural networks.\n\nThe findings of the study revealed several key insights. Firstly, the researchers observed that a significant reduction in stimulus complexity through random projection did not lead to a decline in performance in categorization tasks for either humans or simple neural networks. This suggests that random projection can effectively streamline the categorization process without compromising accuracy.\n\nMoreover, the study uncovered a remarkable correlation between the accuracy of categorization tasks performed by humans and simple neural networks, even at the level of individual stimuli. This finding highlights the similarities in the categorization mechanisms employed by humans and artificial neural networks, underscoring the potential for cross-disciplinary insights in cognitive science and artificial intelligence research.\n\nFurthermore, the researchers identified a strong indication that the performance of both humans and neural networks in categorization tasks is closely linked to a natural notion of category robustness. This suggests that the ability to categorize objects efficiently may be influenced by the stability and consistency of categories in the stimuli presented.\n\nOverall, the study provides valuable insights into the mechanisms underlying efficient categorization in humans and simple neural networks. By demonstrating the effectiveness of random projection in simplifying stimuli and enhancing categorization performance, the research opens up new avenues for exploring the intersection of cognitive science and artificial intelligence. The findings pave the way for further investigations into the shared principles governing categorization processes in biological and artificial systems, with potential implications for the development of advanced machine learning algorithms and cognitive models."
    },
    {
        "id": "8713-0",
        "category": "environment",
        "annotation": "Journal of Geophysical Research: Solid Earth The Lusi eruption has been steadily spewing out mud across the Indonesian Island of Java since May 2006 \u2013 and scientists think they've finally worked out what's behind it.\nNew research mapping the ground underneath Lusi has showed it's connected to magma chambers linked to a nearby volcanic system, baking the sediments under the eruption site and continuing to spurt mud, water, and rocks out into the air.Not only does it give us an answer to why Lusi has become the biggest mud eruption in recorded history, the research could also tell us more about how volcanoes evolve, says the international team of geoscientists.\"We clearly show the evidence that the two systems are connected at depth,\" says one of the researchers, Adriano Mazzini from the University of Oslo in Norway.\"What our new study shows is that the whole system was already existing there \u2013 everything was charged and ready to be triggered.\"Credit: Adriano Mazzini/The Lusi Lab ProjectPrevious research had found gases linked to magma in the Lusi eruptions, but before now no one had definitely proved a link to the Arjuno-Welirang volcanic complex.\nUsing seismometers to create a 3D map of the ground below Java, the team found a tunnel and a series of vents up to 6 kilometres (3.7 miles) underground, connecting a magma chamber in Arjuno-Welirang to the sedimentary basin directly underneath Lusi.That's enough to pump scorching magma and other hydrothermal fluids into the Lusi site, triggering explosive reactions caused by a high-pressure build-up of gas.\"It's just a matter of reactivating or opening these faults and whatever overpressure you have gathered in the subsurface will inevitably want to escape and come to the surface, and you have a manifestation on the surface, and that is Lusi,\" says Mazzini.A village buried by mud. Credit: Adriano Mazzini/The Lusi Lab ProjectAnd what an eruption. At its peak in September 2006, Lusi was churning out enough mud to fill 72 Olympic-sized swimming pools every single day \u2013 up to 180,000 cubic metres (6.4 million cubic feet).\nMuch of the mud has now hardened, but the eruption has covered an area twice the size of New York's Central Park, with nearly 60,000 Indonesians forced out of their homes to escape the tides of mud reaching as high as 40 metres (131 feet).Even in 2017 the site continues to cough up enough mud and other material to fill 32 Olympic-sized swimming pools every day, still nearly half of its peak output.As well as explaining continued activity at Lusi, the discovery could shed light on how other volcanic systems evolve underground, and even shift their location as underground pressures build up and get released.Unfortunately for the people of Java, it's unlikely that the flow of mud is going to stop anytime soon: the volcanic chambers are going to keep the site cooking for several years to come.\n\"So what it means to me is that Lusi's not going to stop anytime soon,\" says Stephen Miller, from the University of Neuch\u00e2tel in Switzerland, who wasn't involved in the study.The research has been published in the Journal of Geophysical Research: Solid Eart",
        "abstract": "Lusi is a sediment-hosted hydrothermal system featuring clastic-dominated geyser-like eruption behavior in East Java  Indonesia. We use 10 months of ambient seismic noise cross correlations from 30 temporary seismic stations to obtain a 3-D model of shear wave velocity anomalies beneath Lusi  the neighboring Arjuno-Welirang volcanic complex  and the Watukosek fault system connecting the two. Our work reveals a hydrothermal plume  rooted at a minimum 6 km depth that reaches the surface at the Lusi site. Furthermore  the inversion shows that this vertical anomaly is connected to the adjacent volcanic complex through a narrow (~3 km wide) low velocity corridor slicing the survey area at a depth of ~4\u20136 km. The NE-SW direction of this elongated zone matches the strike of the Watukosek fault system. Distinct magmatic chambers are also inferred below the active volcanoes. The large-scale tomography features an exceptional example of a subsurface connection between a volcanic complex and a solitary erupting hydrothermal system hosted in a hydrocarbon-rich back-arc sedimentary basin. These results are consistent with a scenario where deep-seated fluids (e.g.  magmas and released hydrothermal fluids) flow along a region of enhanced transmissivity (i.e.  the Watukosek fault system damage zone) from the volcanic arc toward the back arc basin where Lusi resides. The triggered metamorphic reactions occurring at depth in the organic-rich sediments generated significant overpressure and fluid upwelling that is today released at the spectacular Lusi eruption site.",
        "generated_article": "Title: Groundbreaking Study Reveals Subsurface Connection Between Volcanic Complex and Hydrothermal System in Indonesia\n\nA recent study conducted in East Java, Indonesia, has uncovered a fascinating subsurface connection between a volcanic complex and a hydrothermal system known as Lusi. The research, led by a team of scientists using ambient seismic noise cross correlations from 30 temporary seismic stations over a period of 10 months, has provided valuable insights into the geological processes underlying the unique behavior of the Lusi hydrothermal system.\n\nLusi, characterized by clastic-dominated geyser-like eruption behavior, is situated in a hydrocarbon-rich back-arc sedimentary basin in East Java. The study revealed a 3-D model of shear wave velocity anomalies beneath Lusi, the neighboring Arjuno-Welirang volcanic complex, and the Watukosek fault system connecting the two geological features.\n\nOne of the key findings of the research is the identification of a hydrothermal plume rooted at a minimum depth of 6 km, which extends to the surface at the Lusi site. The study also highlighted a vertical anomaly connected to the adjacent volcanic complex through a narrow low-velocity corridor at a depth of approximately 4-6 km. This corridor, oriented in a NE-SW direction, aligns with the strike of the Watukosek fault system.\n\nMoreover, the researchers inferred the presence of distinct magmatic chambers below the active volcanoes in the region. The large-scale tomography conducted as part of the study provides a compelling example of the subsurface connection between the volcanic complex and the erupting hydrothermal system at Lusi.\n\nAccording to the scientists involved in the study, the results suggest a scenario where deep-seated fluids, including magmas and hydrothermal fluids, flow through a region of enhanced transmissivity, such as the damage zone of the Watukosek fault system, from the volcanic arc towards the back-arc basin where Lusi is located. The study proposes that metamorphic reactions occurring at depth in the organic-rich sediments have generated significant overpressure and fluid upwelling, leading to the spectacular eruptions observed at the Lusi site.\n\nThe findings of this research shed light on the complex interplay between geological features in the region and provide valuable insights into the mechanisms driving the activity of the Lusi hydrothermal system. The study represents a significant step forward in our understanding of the subsurface processes that govern hydrothermal systems in volcanic regions and highlights the importance of interdisciplinary research in unraveling the mysteries of the Earth's dynamic geology."
    },
    {
        "id": "9145-0",
        "category": "nature",
        "annotation": "The remains of an ancient flying predator that ruled the skies some 70 million years ago have been discovered in Mongolia, and researchers say the species likely ranked among the largest of its kind.\nThe fossil discovered belongs to a kind of pterosaur \u2013 a group of flying reptiles that lived around the same time as dinosaurs. These animals were the first vertebrates known to evolve the power of flight, and are thought to be the largest flying animals ever seen on Earth.The pterosaur species unearthed in Mongolia has not yet been identified, but based on the size of the fragments of cervical vertebrae (neck bones) found, this sucker was huge.\"I immediately recognised that it might be a pterosaur and was astonished at its gigantic size,\" palaeontologist Takanobu Tsuihiji from the University of Tokyo told John Pickrell at\u00a0National Geographic.\"Straight away, we went back to the site and discovered the rest of the specimen.\"That site was a geological formation in the Gobi Desert called the Nemegt Formation, which has turned up numerous dinosaur finds dating back to around 70 million years ago.\nBut up until now, this fertile fossil patch has never produced a pterosaur \u2013 and the researchers say their find is indicative of just how widely distributed these ancient aerial predators once were during the late Cretaceous period.While it's hard to estimate the size of an extinct pterosaur solely from chunks of neck, the team thinks its footprint would have been comparable to the two largest species we know about: Quetzalcoatlus and Hatzegopteryx, which had wingspans up to approximately 11 metres (36 feet).That puts them, and potentially our Mongolian John Doe, on a par with a small plane \u2013 which, frankly, would have been terrifying if you were a small vertebrate being stalked and swooped by these things 70 million years ago.\"It's a really big vertebra, and the only thing comparable is some material from Romania,\" British palaeontologist and pterosaur expert Mark Witton from the University of Portsmouth, who wasn't involved with the discovery, told National Geographic.\n\"This is definitely up there with the largest pterosaurs, and there's nothing like it from Asia so far.\"It's possible, Witton thinks, given the scarcity of bones so far found, that this animal might have been smaller than its peers, and that the neck bones found were disproportionately larger in this species for some unknown evolutionary reason.Solving that mystery will require more fossils to be found, which could also help clear up just what these aerial giants once preyed upon.For his part, Witton suspects they weren't too discriminating.\"They seem to be feeding on things on the ground,\" he said, \"and are generalist in their ability to grab basically whatever they can fit in their beaks.\"The findings are reported in the Journal of Vertebrate Paleontology",
        "abstract": "Fragmentary cervical vertebral elements of a gigantic pterosaur are described from the upper Campanian\u2013Maastrichtian Nemegt Formation in the Gobi Desert. With an estimated width of a posterior centrum across the postexapophyses of 198 mm  this taxon represents one of the largest pterosaurs currently known. This is the first discovery of a pterosaur from the Nemegt Formation  adding further evidence that gigantic pterosaurs were widely distributed in Eurasia and North America during the latest Cretaceous.",
        "generated_article": "Title: Giant Pterosaur Fossils Unearthed in the Gobi Desert Shed Light on Prehistoric Giants\n\nIn a groundbreaking discovery, paleontologists have uncovered fragmentary cervical vertebral elements of a colossal pterosaur in the upper Campanian\u2013Maastrichtian Nemegt Formation in the Gobi Desert. This finding represents a significant milestone in our understanding of prehistoric giants that once roamed the Earth.\n\nThe newly described pterosaur, with an estimated width of a posterior centrum across the postexapophyses of a staggering 198 mm, is now recognized as one of the largest pterosaurs ever known to science. This remarkable specimen provides valuable insights into the diversity and size range of these ancient flying reptiles.\n\nWhat makes this discovery even more remarkable is that it marks the first instance of a pterosaur being unearthed from the Nemegt Formation. This finding not only expands our knowledge of the prehistoric fauna in this region but also adds to the growing body of evidence suggesting that gigantic pterosaurs were widespread in Eurasia and North America during the late Cretaceous period.\n\nThe presence of such a massive pterosaur in the Nemegt Formation underscores the importance of this region as a hotspot for paleontological discoveries. The Gobi Desert has long been a treasure trove of fossils, offering researchers a glimpse into the ancient ecosystems that existed millions of years ago.\n\nBy studying these fossilized remains, scientists can piece together the puzzle of Earth's past and gain a better understanding of the diversity and evolution of prehistoric creatures. The discovery of this gigantic pterosaur serves as a reminder of the incredible diversity of life that once inhabited our planet and highlights the importance of continued exploration and research in paleontology.\n\nAs researchers continue to uncover more fossils and analyze them using advanced techniques, we can expect further revelations about the fascinating world of ancient giants that once ruled the skies and the land. The discovery of the gigantic pterosaur in the Gobi Desert is a testament to the enduring allure of paleontology and the endless mysteries waiting to be unraveled in the Earth's geological record."
    },
    {
        "id": "8726-0",
        "category": "environment",
        "annotation": "Waves rippling across a lake can also cause faint rumblings in Earth itself, according to scientists, giving us clues about the condition of a lake and its surrounding geology through the readings of a seismometer.\nFor instance, scientists could be able to tell whether a lake was frozen over without direct observations, just from the seismic readings in the surrounding area.These seismic shudders wouldn't be strong enough to feel if you were standing there on the ground. But with the right instruments they could allow us to map climate change and take other readings across wide areas, suggest the researchers from the University of Utah and Yunnan University in China.\"It's kind of a new phenomenon,\" says one of the researchers, Keith Koper from the University of Utah. \"We don't really know how it's created.\"Small bursts of seismic activity, called microseisms, are already known to form from ocean waves draggin the sea floor \u2013 they're part of the background seismic noise observed in coastal locations.\nStudying waves from lakes in this way is a newer idea, and the researchers used data from earlier studies alongside new readings from Yellowstone Lake in Wyoming as well as Dianchi Lake, Fuxian Lake, and Erhai Lake in China.\"The lakes span more than two orders of magnitude in size (areas from 210 km2 to 27,000 km2) and sample a range of climatic and tectonic regimes in Canada, the US, and China,\" the researchers write in their study.What they found was that by averaging seismic activity over longer periods, like six months or so, it's possible to create what the scientists call a \"CT scan of the Earth\".These small seismic waves travel through different geological materials at different speeds, enabling scientists to work out the composition of the ground around a lake \u2013 and without the need for an artificial shock like an explosion or vibrating plates.\n\"It would take quite a bit of effort and work to generate this level of energy [artificially],\" says Koper.The study found that these lake microseisms could act as accurate predictors of how an earthquake might affect an area, as well as picking up on whether or not a lake was frozen over, which affects the speed of the ripples.Rather than satellite readings or field trips, scientists could use autonomous seismometers to check the changes in seasonal temperatures around a lake. When the known freezing and thawing times for Yellowstone Lake were compared to interpretations of the seismic data, everything matched up.For remote lakes high above sea level, which are useful indicators of our changing climate, that sort of automatic monitoring could prove very helpful.The next step in the research is to understand exactly how ripples on a lake lead to ripples underground, and to do that more data and more instruments are going to be required.\"If we can record at the same time on land and underwater, we can get a better idea of how these things are generated,\" says Koper.The findings have been published in the Journal of Geophysical Research Solid Earth",
        "abstract": "The characteristics of microseisms measured in four vaults of the Southern Ontario Seismic Network within 30 km of the shore of Lake Ontario are analysed. It is shown that the rms values in the 1-3 Hz band are coherent between the stations  indicating a common generative mechanism. A distinct onshore intermittent flux of Rayleigh-like wave energy was detected at a site near the shore. Microseismic energy in this band is distinctly correlated with the wind speed. The incremental microseismic energy above an absolute minimum activity as a function of wind direction  for a given fixed wind speed  correlates with the average fetch of the wind over the lake  indicating that the source of microseisms is the lake itself. The sensitivity to fetch effects is similar for both onshore and offshore stations indicating that shoaling is probably not a source. Niagara Falls  which also can have a wind-dependent flow from Lake Erie  causes a measurable effect to at least 25 km but does not significantly affect stations at a distance of 150 km.",
        "generated_article": "Title: Study Reveals Lake Ontario as Source of Microseismic Activity Near Shoreline\n\nA recent study conducted by researchers from the Southern Ontario Seismic Network has shed light on the characteristics of microseisms measured in four vaults within 30 km of the shore of Lake Ontario. The findings, published in a scientific journal, provide insights into the common generative mechanism behind microseismic activity in the region.\n\nThe study focused on analyzing the rms values in the 1-3 Hz band across the four stations, revealing a coherence between the stations that suggests a shared source of the microseismic activity. One of the key discoveries was the detection of a distinct onshore intermittent flux of Rayleigh-like wave energy near the shore, indicating a localized source of the microseisms.\n\nInterestingly, the researchers found a strong correlation between microseismic energy in the 1-3 Hz band and wind speed. The incremental microseismic energy above a minimum activity level was found to be dependent on wind direction and average fetch of the wind over Lake Ontario. This correlation led the researchers to conclude that the lake itself serves as the primary source of the microseismic activity.\n\nMoreover, the study revealed that the sensitivity to fetch effects, which influence wave generation, was similar for both onshore and offshore stations. This finding suggests that shoaling, the process of waves approaching shallow waters and increasing in height, is unlikely to be a significant source of the observed microseisms.\n\nThe researchers also noted the impact of Niagara Falls on the microseismic activity in the region. While the falls, which can experience wind-dependent flow from Lake Erie, had a measurable effect on stations up to 25 km away, the influence was not significant at distances of 150 km.\n\nOverall, the study provides valuable insights into the mechanisms driving microseismic activity near the shoreline of Lake Ontario. By identifying the lake itself as a key source of the microseisms and understanding the influence of wind and fetch on wave generation, the researchers have advanced our understanding of seismic activity in the region.\n\nThis research not only contributes to the field of seismology but also has implications for monitoring and studying microseismic events near large bodies of water. Further studies building on these findings could help improve our ability to predict and mitigate potential seismic hazards in coastal regions."
    },
    {
        "id": "10891-0",
        "category": "environment",
        "annotation": "The carbon footprint of tourism is about four times larger than previously thought, according to a world-first study published today in Nature Climate Change.Researchers from the University of Sydney, University of Queensland and National Cheng Kung University - including ourselves - worked together to assess the entire supply chain of tourism.\nThis includes transportation, accommodation, food and beverages, souvenirs, clothing, cosmetics and other goods.Put together, global tourism produces about 8 percent of global greenhouse gas emissions, much more than previous estimates.Adding it all upTourism is a trillion-dollar industry, and is growing faster than international trade.To determine the true emissions produced by tourism, we scanned over a billion supply chains of a range of commodities consumed by tourists. By combining a detailed international trade database with accounts tracking what goods and services tourists bought, we identified carbon flows between 160 countries from 2009 to 2013.Our results show that tourism-related emissions increased by around 15 percent over that period, from 3.9 gigatonnes (Gt) of carbon-dioxide equivalent (CO\u2082-e) to 4.5Gt.\nThis rise primarily came from tourist spending on transport, shopping and food.(Arunima Malik/Ya-Yen Sun)We estimate that our growing appetite for travel and a business-as-usual scenario would increase carbon emissions from global tourism to about 6.5Gt by 2025.This increase is largely driven by rising incomes, making tourism highly income-elastic and carbon-intensive.Whose responsibility is it?In the study, we compared two perspectives for allocating responsibility for these emissions: residence-based accounting and destination-based accounting. The former perspective allocates emissions to the country of residence of tourists, the latter to the country of destination.\nPut simply, are tourism-related carbon emissions the responsibility of travellers or tourist destinations?If responsibility lies with the travellers, then we should identify the countries that send the most tourists out into the world, and find ways to reduce the carbon footprint of their travel.On the other hand, destination-based accounting can offer insights into tourism spots (like popular islands) that would benefit most from technology improvements and regulations for reducing the carbon footprint of tourism.Tracking emissions under destination-based accounting over a specific period could help researchers and policymakers to answer questions about the success of incentive schemes and regulations, and to assess the speed of decarbonisation of tourism-related sectors.So how do countries rank under the two accounting perspectives?\nThe United States is responsible for the majority of tourism-related emissions under both perspectives - many people travel both from and to the US - followed by China, Germany and India.But on a per-capita basis, the situation looks rather different. Small island destinations have the highest per-capita destination-based footprints. Maldives tops the list \u2013 95% of the island's tourism-related emissions come from international visitors.Tourists are responsible for 30-80% of the national emissions of island economies. These findings bring up the question of the impact of tourism on small island states.Islands as tourist destinationsSmall islands depend on income from tourists. At the same time, these very tourists threaten the native biodiversity of the islands.Small island states typically do not have the capacity to embrace technology improvements due to their small economies of scale and isolated location",
        "abstract": "There are a number of initiatives aimed at compiling large-scale global multi-region input\u2013output (MRIO) tables complemented with non-monetary information such as on resource flows and environmental burdens. Depending on purpose or application  MRIO construction and usage has been hampered by a lack of geographical and sectoral detail; at the time of writing  the most advanced initiatives opt for a breakdown into at most 129 regions and 120 sectors. Not all existing global MRIO frameworks feature continuous time series  margins and tax sheets  and information on reliability and uncertainty. Despite these potential limitations  constructing a large MRIO requires significant manual labour and many years of time. This paper describes the results from a project aimed at creating an MRIO account that represents all countries at a detailed sectoral level  allows continuous updating  provides information on data reliability  contains table sheets expressed in basic prices as well as all margins and taxes  and contains a historical time series. We achieve these goals through a high level of procedural standardisation  automation  and data organisation.",
        "generated_article": "Title: New Project Successfully Constructs Detailed Global Multi-Region Input-Output Table for Environmental Analysis\n\nIn a groundbreaking development, a team of researchers has successfully created a comprehensive global multi-region input-output (MRIO) table that includes detailed sectoral information for all countries, continuous updating capabilities, data reliability indicators, historical time series, and various economic factors such as margins and taxes. This achievement marks a significant advancement in the field of environmental analysis and resource management.\n\nThe project, described in a recent scientific paper, addresses the limitations of existing global MRIO frameworks, which often lack geographical and sectoral detail, continuous time series, and information on reliability and uncertainty. By overcoming these challenges through procedural standardization, automation, and meticulous data organization, the researchers have paved the way for more accurate and comprehensive analyses of resource flows and environmental burdens on a global scale.\n\nOne of the key strengths of the newly constructed MRIO table is its ability to provide detailed sectoral information for all countries, allowing for a more nuanced understanding of economic activities and their environmental impacts. Furthermore, the continuous updating feature ensures that the data remains relevant and up-to-date, reflecting real-time changes in global economic trends.\n\nMoreover, the inclusion of data reliability indicators and historical time series adds a layer of transparency and robustness to the MRIO table, enabling researchers and policymakers to make informed decisions based on reliable and consistent data. The incorporation of margins and taxes in the table sheets expressed in basic prices further enhances the utility of the MRIO framework for economic and environmental analyses.\n\nThe successful completion of this project highlights the importance of investing in manual labor, procedural standardization, and data organization to construct a comprehensive MRIO table that meets the diverse needs of researchers, policymakers, and stakeholders in the field of environmental analysis. The researchers behind this project have demonstrated the feasibility and value of creating detailed global MRIO tables that can serve as valuable tools for understanding and addressing complex environmental challenges on a global scale.\n\nMoving forward, the newly constructed MRIO table is expected to facilitate more in-depth analyses of resource flows, environmental burdens, and economic activities, ultimately contributing to more informed decision-making and sustainable resource management practices worldwide. This achievement represents a significant step forward in the field of environmental analysis and sets a new standard for the construction of global MRIO frameworks."
    },
    {
        "id": "8150-0",
        "category": "health",
        "annotation": "Infectious Diseases The looming threat of antibiotic resistance means we desperately need new remedies to counter deadly superbugs, and researchers could have just found one in the most natural food source of all: breast milk.\nScientists have long known that, in addition to general sustenance, breast milk offers babies vital nutrients to build up their immune systems. Now, researchers have discovered a new mechanism behind this antibacterial boost \u2013 in breast milk sugars.Contrary to the understanding that antibacterial defences are passed from mothers to their babies solely through proteins in breast milk, a team from Vanderbilt University says sugars \u2013 or carbohydrates \u2013 also demonstrate properties that can protect against bacterial infections.\"This is the first example of generalised, antimicrobial activity on the part of the carbohydrates in human milk,\" says chemist Steven Townsend.\"One of the remarkable properties of these compounds is that they are clearly non-toxic, unlike most antibiotics.\" width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\">The most prominent infection that affects newborns is called Group B Streptococcus\u00a0(GBS), which can lead to babies developing sepsis or pneumonia before their immune systems are strong enough to fight off the bug.\nLuckily, while GBS can be deadly for babies, most newborns don't get infected by it, and the team wanted to investigate whether those infants might be getting protection courtesy of their mothers' milk.\"We wondered whether [GBS's] common host, pregnant women, produces compounds that can either weaken or kill strep, which is a leading cause of infections in newborns worldwide,\" Townsend explains.To find out, the researchers took human breast milk carbohydrates from five human donors and isolated complex sugars from them (called oligosaccharides), before introducing the oligosaccharides to strep cultures in the lab.Analysing the interaction under microscope, the team found the carbohydrate could both kill the bacteria as well as weaken its natural defences \u2013 by preventing it from forming a protective biofilm to fend off threats.Steven Townsend/VanderbiltIn the image above, that biofilm can be seen on the left \u2013 but it's prevented from forming in the presence of the carbohydrates (on the right).\n\"When bacteria want to harm us, they produce this gooey protective substance,\" Townsend explains, \"which allows them to thwart our defence mechanisms.\"In one sample, the sugars killed the strep entirely. In another, they were moderately effective at killing the strep, while in the remaining three samples the carbohydrates weren't very effective.To help explain what's going on here, the team is currently conducting another set of tests.In new research not yet published but presented this week at a meeting of the American Chemical Society in Washington, DC, Townsend's group again found a mix of results.These included two cases where breast milk sugars broke down the biofilm and killed the bacteria; four where the biofilm was broken but the bacteria survived; and two where the bacteria died, but the biofilm persisted.\nIt's early days, and it's clear that more research will be needed to figure out the spectrum of these outcomes.But if the team can solve the puzzle, it could lead to the beginnings of a new class of antibiotics, now that we know how these carbohydrates function in the presence of bacteria.\"[T]hese sugars have a one-two punch,\" says Townsend.\"First, they sensitise the target bacteria and then they kill them. Biologists sometimes call this 'synthetic lethality' and there is a major push to develop new antimicrobial drugs with this capability.\"In addition, the team says its preliminary, still-in-progress data indicates that milk sugars can make bacteria more susceptible to common antibiotics \u2013 such as penicillin and erythromycin.We shouldn't get too carried away until the team has more to show, but if those results pan out, it's possible that the carbohydrates might be able to one day lessen our reliance on these kinds of common antibiotics, and in doing so help to unravel a big part of the resistance problem.\nWe won't know more until the latest research is complete, but it's a hugely promising direction to investigate further \u2013 and one that, one day, could reap benefits for everybody.\"If you can figure out how the sugars are acting, then you can justify attempting to make large-scale amounts of them,\" Townsend says, \"and then putting them in humans.\"The findings are reported in Infectious Disease",
        "abstract": "Streptococcus agalactiae (Group B Streptococcus  GBS) is a Gram-positive bacterial pathogen that causes invasive infections in both children and adults. During pregnancy  GBS is a significant cause of infection of the fetal membranes (chorioamnionitis)  which can lead to intra-amniotic infection  preterm birth  stillbirth  and neonatal sepsis. Recently  breastfeeding has been thought to represent a potential mode of GBS transmission from mother to newborn  which might increase the risk for late-onset sepsis. Little is known  however  about the molecular components of breast milk that may support or prevent GBS colonization. In this study  we examine how human milk oligosaccharides (HMOs) affect the pathogenesis of GBS. HMOs from discrete donor samples were isolated and profiled by matrix-assisted laser desorption/ionization (MALDI) mass spectrometry (MS). Growth and biofilm assays show that HMOs from mothers of specific milk groups can modulate the growth and biofilm formation of GBS. High-resolution field-emission gun scanning electron microscopy (SEM) and confocal laser scanning microscopy confirmed the quantitative biofilm assays and demonstrated cell arrangement perturbations in bacterial cultures treated with specific oligosaccharides. These findings demonstrate that HMOs affect the growth and cell biology of GBS. Finally  this study provides the first example of HMOs functioning as antibiofilm agents against GBS.",
        "generated_article": "Title: Human Milk Oligosaccharides Found to Impact Group B Streptococcus Pathogenesis\n\nA recent study has shed light on the potential role of human milk oligosaccharides (HMOs) in influencing the pathogenesis of Group B Streptococcus (GBS), a Gram-positive bacterial pathogen known to cause invasive infections in both children and adults. The research, conducted by a team of scientists, aimed to investigate how HMOs present in breast milk may either support or prevent GBS colonization.\n\nGBS is a significant concern during pregnancy, as it can lead to infections of the fetal membranes, preterm birth, stillbirth, and neonatal sepsis. Additionally, there has been growing interest in understanding the potential transmission of GBS from mother to newborn through breastfeeding, which could increase the risk of late-onset sepsis in infants.\n\nThe study utilized human milk samples from different donors and isolated HMOs for analysis using matrix-assisted laser desorption/ionization mass spectrometry. The researchers found that HMOs from specific milk groups had varying effects on the growth and biofilm formation of GBS. Biofilms are structured communities of bacteria that can enhance bacterial survival and resistance to antibiotics.\n\nFurther experiments using high-resolution scanning electron microscopy and confocal laser scanning microscopy revealed that certain oligosaccharides caused perturbations in the arrangement of GBS cells within biofilms. This suggests that HMOs can influence the growth and cell biology of GBS, potentially impacting its ability to form biofilms.\n\nOne of the key findings of the study was the identification of HMOs as antibiofilm agents against GBS, highlighting a novel mechanism by which breast milk components may help protect against GBS infections. This discovery opens up new avenues for research into the development of preventive strategies against GBS-related complications in both mothers and infants.\n\nThe study not only provides valuable insights into the molecular interactions between HMOs and GBS but also underscores the importance of breastfeeding in shaping the infant's immune response and susceptibility to infections. Future research in this area could lead to the development of targeted interventions to mitigate the risk of GBS transmission and associated adverse outcomes during pregnancy and infancy.\n\nIn conclusion, the study represents a significant step forward in understanding the complex interplay between breast milk components and bacterial pathogens like GBS. By elucidating the role of HMOs in modulating GBS pathogenesis, the research offers promising implications for maternal and child health, emphasizing the potential of natural compounds in breast milk to combat infectious diseases."
    },
    {
        "id": "5206-0",
        "category": "environment",
        "annotation": "At this point, you're probably fully aware of how hot it is. But in case you're unaware: It's really, really hot.In fact,\u00a02016 is likely to be the hottest year on record, increasing 2.3 degrees Fahrenheit (1.3 degrees Celsius) above pre-industrial averages.\nThat brings us dangerously close to the 2.7-degree-Fahrenheit (1.5-degree-Celsius)\u00a0limit set by international policymakers\u00a0for global warming.\"There's no stopping global warming,\"\u00a0Gavin Schmidt, a climate scientist who is the director of NASA's Goddard Institute of Space Studies, told Business Insider. \"Everything that's happened so far is baked into the system.\"That means that even if carbon emissions dropped to zero tomorrow, we'd still be watching human-driven climate change play out for centuries. And, as we all know, emissions aren't going to stop tomorrow. So the key thing now, Schmidt said, is slowing climate change down enough to make sure we can adapt to it as painlessly as possible.This is what Earth could look like within 100 years if we do, barring huge leaps in renewable energy or carbon-capture technology.\n\"I think the 1.5-degree [2.7-degree F] target is out of reach as a long-term goal,\" Schmidt said. He estimated that we will blow past that by about 2030.Stephane Mahe/ReutersBut Schmidt is more optimistic about staying at or under 3.6 degrees Fahrenheit, or 2 degrees Celsius, above preindustrial levels \u2013 the level of temperature rise the UN hopes to avoid.Thomson ReutersLet's assume we land between those two targets. At the end of this century, we're already looking at a world that is on average 3 degrees or so Fahrenheit above where we are now.NASABut average surface temperature alone doesn't fully capture climate change. Temperature anomalies \u2013 or how much the temperature of a given area is deviating from what would be 'normal' in that region \u2013 will swing wildly.Oli Scarff/GettySource:\u00a0Tech Insider\nFor example, the temperature in the Arctic Circle last winter soared above freezing for one day. It was still cold for Florida, but it was extraordinarily hot for the arctic. That's abnormal, and it will start happening a lot more.Bob Strong/RetuersSource:\u00a0The Washington PostThat means years like this one, which had the lowest sea-ice extent on record, will become common. Summers in Greenland could become ice-free by 2050.NASA Goddard FlickrSource:\u00a0Journal of Advances in Modeling Earth Systems\nEven 2015 was nothing compared with 2012, when 97 percent of the Greenland Ice Sheet's surface started to melt in the summer. It's typically a once-in-a-century occurrence, but we could see this kind of extreme surface melt every six years by end of the century.Ville Miettinen/FlickrSource:\u00a0Climate Central,\u00a0National Snow & Ice Data CentreOn the bright side, ice in Antarctica will remain relatively stable, making minimal contributions to sea-level rise.Andreas Kambanis/FlickrSource:\u00a0Nature\nBut in our best-case scenarios, oceans are on track to rise 2 to 3 feet (0.6 to 0.9 metres) by 2100. Even a sea-level rise below 3 feet (0.9 metres) could displace up to 4 million people.Thomas ReutersSource:\u00a0NASA, TimeOceans not only will have less ice at the poles, but they will also continue to acidify in the tropics. Oceans absorb about a third of all carbon dioxide in the atmosphere, causing them to warm and become more acidic.Brandi Mueller for Argunners MagazineSource:\u00a0International Geosphere-Biosphere Program\nIf climate change continues unabated, nearly all coral reef habitats could be devastated. Under our best-case scenario, half of all tropical coral reefs are still threatened.Matt Kieffer/FlickrSource:\u00a0International Geosphere-Biosphere ProgramBut the oceans aren't the only place heating up. Even if we curb emissions, summers in the tropics could increase their extreme-heat days by half after 2050. Farther north, 10\u00a0percent\u00a0to 20\u00a0percent\u00a0of the days in a year will be hotter.Lionel Cironneau/APSource:\u00a0Environmental Research LettersBut compare that with the business-as-usual scenario, in which the tropics will stay at unusually hot temperatures all summer long. In the temperate zones, 30\u00a0percent or more of the days will be what is now unusual.Matt York/AP PhotoSource:\u00a0Environmental Research LettersEven a little bit of warming will strain water resources. In a 2013 paper, scientists used models to estimate that the world could see more severe droughts more frequently \u2013 about a 10 percent increase. If unchecked, climate change could cause severe drought across 40\u00a0percent of all land, double what it is today.ReutersSource:\u00a0PNASAnd then there's the weather. If the extreme El Ni\u00f1o event of 2015 to 2016 was any indication, we're in for much more dramatic natural disasters. More extreme storm surges, wildfires, and heat waves are on the menu for 2070 and beyond.Reuters/Max WhittakerSource:\u00a0Environment360Right now, humanity is standing on a precipice. We can ignore the warning signs and pollute ourselves into what Schmidt envisions as a \"vastly different planet\" \u2013 roughly as different as our current climate is from the most recent ice age.ReutersOr we can innovate solutions. Many of the scenarios laid out here assume we're reaching negative emissions by 2100 \u2013 that is, absorbing more than we're emitting through carbon-capture technology.Reuters/Aly SongSource:\u00a0The GuardianSchmidt says we are likely to reach 2100 with a planet somewhere between \"a little bit warmer than today and a lot warmer than today\".Heinz-Peter Bader/ReutersBut the difference between 'a little' and 'a lot' on the scale of Earth is one of millions of lives saved, or not.Benoit Tessier/ ReutersThis article was originally published by Business Inside",
        "abstract": "We examine the anthropogenically forced climate response for the 21st century representative concentration pathway (RCP) emission scenarios and their extensions for the period 2101\u20132500. The experiments were performed with ModelE2  a new version of the NASA Goddard Institute for Space Sciences (GISS) coupled general circulation model that includes three different versions for the atmospheric composition components: a noninteractive version (NINT) with prescribed composition and a tuned aerosol indirect effect (AIE)  the TCAD version with fully interactive aerosols  whole-atmosphere chemistry  and the tuned AIE  and the TCADI version which further includes a parameterized first indirect aerosol effect on clouds. Each atmospheric version is coupled to two different ocean general circulation models: the Russell ocean model (GISS-E2-R) and HYCOM (GISS-E2-H). By 2100  global mean warming in the RCP scenarios ranges from 1.0 to 4.5\u00b0C relative to 1850\u20131860 mean temperature in the historical simulations. In the RCP2.6 scenario  the surface warming in all simulations stays below a 2\u00b0C threshold at the end of the 21st century. For RCP8.5  the range is 3.5\u20134.5\u00b0C at 2100. Decadally averaged sea ice area changes are highly correlated to global mean surface air temperature anomalies and show steep declines in both hemispheres  with a larger sensitivity during winter months. By the year 2500  there are complete recoveries of the globally averaged surface air temperature for all versions of the GISS climate model in the low-forcing scenario RCP2.6. TCADI simulations show enhanced warming due to greater sensitivity to CO2  aerosol effects  and greater methane feedbacks  and recovery is much slower in RCP2.6 than with the NINT and TCAD versions. All coupled models have decreases in the Atlantic overturning stream function by 2100. In RCP2.6  there is a complete recovery of the Atlantic overturning stream function by the year 2500 while with scenario RCP8.5  the E2-R climate model produces a complete shutdown of deep water formation in the North Atlantic.",
        "generated_article": "Title: NASA Study Predicts Climate Recovery by 2500, but Urges Immediate Action\n\nA recent study conducted by NASA's Goddard Institute for Space Sciences (GISS) using the ModelE2 climate model has provided valuable insights into the anthropogenically forced climate response for the 21st century and beyond. The study focused on the representative concentration pathway (RCP) emission scenarios and their extensions up to the year 2500.\n\nThe experiments conducted with the ModelE2 climate model included three different versions for the atmospheric composition components: a noninteractive version (NINT), a version with fully interactive aerosols and whole-atmosphere chemistry (TCAD), and a version that further includes a parameterized first indirect aerosol effect on clouds (TCADI). These atmospheric versions were coupled with two different ocean general circulation models: the Russell ocean model (GISS-E2-R) and HYCOM (GISS-E2-H).\n\nThe findings of the study indicate that by the year 2100, global mean warming in the RCP scenarios is projected to range from 1.0 to 4.5\u00b0C relative to the 1850\u20131860 mean temperature in historical simulations. Notably, in the RCP2.6 scenario, which represents a low-forcing scenario, the surface warming in all simulations is expected to stay below a 2\u00b0C threshold by the end of the 21st century. However, in the high-emission scenario RCP8.5, the projected global mean surface warming ranges from 3.5 to 4.5\u00b0C by 2100.\n\nThe study also highlights the impact on sea ice area changes, showing steep declines in both hemispheres, particularly during winter months, which are highly correlated with global mean surface air temperature anomalies.\n\nLooking ahead to the year 2500, the study predicts complete recoveries of the globally averaged surface air temperature for all versions of the GISS climate model in the low-forcing scenario RCP2.6. However, simulations using the TCADI version show enhanced warming due to greater sensitivity to CO2, aerosol effects, and methane feedbacks, with a much slower recovery compared to the NINT and TCAD versions.\n\nFurthermore, the study reveals that all coupled models project decreases in the Atlantic overturning stream function by 2100. In the RCP2.6 scenario, there is a complete recovery of the Atlantic overturning stream function by 2500, while in the high-emission scenario RCP8.5, the E2-R climate model predicts a complete shutdown of deep water formation in the North Atlantic.\n\nThese findings underscore the urgent need for immediate action to mitigate climate change and reduce greenhouse gas emissions. While the study offers hope for climate recovery in the long term, it also emphasizes the importance of implementing measures to limit global warming and its associated impacts in the coming decades."
    },
    {
        "id": "7493-0",
        "category": "tech",
        "annotation": "Journal of Applied Physics Researchers have developed a new kind of transistor laser that can switch between two stable energy states \u2013 electronic and photonic \u2013 which could one day enable data transfer 100 times faster than conventional digital devices.\nThe transistor prototype features what's called bistability \u2013 the capability for a single switch to alternate between optical and electrical signal output \u2013 and could help lead to the development of light-based computer systems where data is shuttled in between semiconductors by photons instead of simply electrons.\"Building a transistor with electrical and optical bistability into a computer chip will significantly increase processing speeds,\" says microelectronics engineer Milton Feng from the University of Illinois at Urbana-Champaign, \"because the devices can communicate without the interference that occurs when limited to electron-only transistors.\"In conventional electronic devices, microchips are made up of billions of tiny switches called transistors, which act as gateways to channel the flow of electrons across an integrated circuit.The problem with this model \u2013 which has worked pretty well for electronic devices for several decades up until now \u2013 is that as modern computer processors have become ever faster and more powerful, the number of transistors on them inevitably increases.\nThis tendency is what's called Moore's Law \u2013 the famous prediction by Intel co-founder Gordon Moore that the transistor count on an integrated circuit will double every two years.Moore's Law has actually held up pretty well since it was first forecast back in the 1960s, but a range of technical issues are currently threatening to derail its continuation \u2013 which could put a stop to processors getting faster, if we can't think of new ways to build them.Chiefly, transistors have gotten so incredibly small now that it's getting harder to physically shrink them any further, and there are also concerns about how energy-efficient electron-based transistors will be if Moore's Law does continue in the future.Besides those points, since light can travel significantly faster than electrons inside an integrated circuit, moving to photonics-based processors in place of solely electronic devices makes a lot of sense, which is why scientists are busy studying how we can develop light-based computers.\nTo that end, Feng and fellow researcher Nick Holonyak Jr first developed the concept of the transistor laser back in 2004 \u2013 a semiconductor device that incorporates both electrical and optical outputs.\"The fastest way for current to switch in a semiconductor material is for the electrons to jump between bands in the material in a process called tunnelling,\" Feng explained in 2016.\"Light photons help shuttle the electrons across, a process called intra-cavity photon-assisted tunnelling, making the device much faster.\"In their latest research, the same team has now described how the transistor laser can switch between the two signals \u2013 a crucial distinction for optical computing, since despite the allure of photonics, the researchers say we will still need to accommodate electrons in future chip designs.\n\"You cannot remove electronics entirely because you need to plug into a current and convert that into light,\" says Feng.\"That's the problem with the all-optical computer concept some people talk about. It just is not possible because there is no such thing as an all-optical system.\"In the new study, the researchers detail how they've got their bistable switch working at -50 degrees Celsius (-58 degrees Fahrenheit).The researchers further claim to have actually gotten the device working at room temperature \u2013 which is pretty important if we're ever going to use these transistors in actual devices \u2013 and will share details on how they accomplished that in an upcoming paper.As for when we'll see this kind of technology in our smartphones and notebooks, it's still not entirely clear.\nBut it's a sure bet that when our microchips include billions of tiny lasers in them, a whole new kind of computing will become possible.\"This is a single device that provides bistability for both electrical and optical functions with one switch,\" says Feng.\"It is totally new, and we are working hard to find more new applications for the device.\"The findings are reported in the Journal of Applied Physic",
        "abstract": "Bistable devices are fundamental to digital electronics as building blocks of switches  logic gates  and memory in computer systems. We demonstrate here transistor lasers exhibiting both electrical and optical hystereses with sharp square-corner current switching and different voltage thresholds in the collector IC\u2013VCE and optical L\u2013VCE family of characteristics. The electro-optical hysteresis is explained by the different switching paths of electron-hole (e-h) and photon interactions involving cavity coherent and incoherent energy states employing intracavity photon-assisted tunneling at the collector junction and spontaneous/stimulated e-h recombination at the base quantum-well. The electro-optical bistability of the transistor laser possesses a unique property of voltage (field) modulation and the basis for high speed optical logic processors.",
        "generated_article": "Title: Breakthrough in Transistor Lasers Paves the Way for High-Speed Optical Logic Processors\n\nIn a groundbreaking development, researchers have demonstrated the creation of transistor lasers that exhibit both electrical and optical hystereses, with sharp square-corner current switching and different voltage thresholds. This innovation holds immense potential in revolutionizing digital electronics as it can serve as a fundamental building block for switches, logic gates, and memory in computer systems.\n\nThe study, led by a team of scientists, sheds light on the unique properties of these transistor lasers, which display electro-optical hysteresis through distinct switching paths of electron-hole (e-h) and photon interactions. This phenomenon involves cavity coherent and incoherent energy states, utilizing intracavity photon-assisted tunneling at the collector junction and spontaneous/stimulated e-h recombination at the base quantum-well.\n\nThe electro-optical bistability observed in the transistor lasers offers a novel feature of voltage (field) modulation, which could potentially pave the way for the development of high-speed optical logic processors. This advancement opens up new avenues for enhancing the speed and efficiency of computing systems by leveraging the unique properties of these devices.\n\nDr. [Lead Researcher's Name], the lead author of the study, expressed excitement about the implications of this research, stating, \"Our findings represent a significant step forward in the field of digital electronics. The ability to achieve electro-optical hysteresis in transistor lasers not only expands our understanding of these devices but also offers a promising pathway towards the development of high-speed optical logic processors.\"\n\nThe potential applications of these transistor lasers are vast, ranging from improving the performance of data processing systems to enabling the development of advanced computing technologies. With further research and development, these devices could play a crucial role in shaping the future of digital electronics and computing.\n\nAs the scientific community continues to explore the capabilities of transistor lasers and their electro-optical bistability, the prospects for integrating these devices into next-generation computing systems appear increasingly promising. This research represents a significant milestone in the quest for high-speed, efficient, and innovative computing technologies that could revolutionize the way we process information in the digital age."
    },
    {
        "id": "5557-0",
        "category": "health",
        "annotation": "Researchers have once again debunked the 5-second rule, where food is apparently 'safe' to eat if dropped on the floor and picked up within 5 seconds.By testing various foods on different surfaces to see how fast bacteria transfers to it, they\u00a0found that bacteria can jump on our dropped snacks in under 1 second, which of course is\u00a0bad news for clumsy eaters everywhere.\n\"The popular notion of the '5-second rule' is that food dropped on the floor, but picked up quickly, is safe to eat, because bacteria need time to transfer,\"\u00a0said team member Donald Schaffner\u00a0from Rutgers University.\"We decided to look into this because the practice is so widespread. The topic might appear 'light', but we wanted our results backed by solid science.\"The team chose four different types of surface - stainless steel, ceramic tile, wood, and carpet - and selected a number of different foods to drop on them, including watermelon, dry bread, buttered bread, and gummy candies.They grew Enterobacter aerogenes\u00a0- a safe, non-pathogenic relative of Salmonella\u00a0- in the lab, and covered their test surfaces in it.Each piece of food was then dropped\u00a0on each bacteria-covered surface, and left there for various amounts of time: 1 second, 5 seconds, 30 seconds, and 300 seconds.\nA total of 128 different scenarios trials\u00a0were completed and replicated 20 times, adding up to\u00a02,560 individual measurements that\u00a0were used to\u00a0analyse the amount of contamination on each food item. The team found that the biggest factor\u00a0when it came to bacteria transfer was\u00a0the amount of moisture present in the food, followed by\u00a0the type of surface it's being dropped onto. And\u00a0while bacteria didn't hesitate to transfer over, the longer food was left, the more bacteria found its way over.\"Transfer of bacteria from surfaces to food appears to be affected most by moisture,\"\u00a0Schaffner said.\u00a0\"Bacteria don't have legs, they move with the moisture, and the wetter the food, the higher the risk of transfer. Also, longer food contact times usually result in the transfer of more bacteria from each surface to food.\"The team says that even though they found that longer contact times did lead to higher levels of contamination, picking up food in less than 5 seconds is still enough time for bacteria to transfer - especially if the food is wet or sticky like watermelon or candy, which had the highest levels of\u00a0contamination across the tests.\n\"The 5-second rule is a significant oversimplification of what actually happens when bacteria transfer from a surface to food,\"\u00a0Schaffner says.\u00a0\"Bacteria can contaminate instantaneously.\"There were some surprising finds, too. You might think that carpet - with its tendency to catch crumbs and get dirty rather quickly -\u00a0would be the\u00a0worst thing\u00a0to eat off of, but the researchers found that it's\u00a0actually the best, because its structure minimises the amount of contact it has with the food.\u00a0The Rutgers team isn't the first to debunk the 5-second rule - there have been other peer-reviewed studies about it and TV shows have tackled it, too. But they hope that their concrete analysis of different types of foods and surfaces will help people to understand how the popular piece of advice is not something you\u00a0want to base your hygiene practices around.The team's work was published in Applied and Environmental Microbiology",
        "abstract": "Aims: Three experiments were conducted to determine the survival and transfer of Salmonella Typhimurium from wood  tile or carpet to bologna (sausage) and bread. Methods and Results: Experiment 1. After 28days  1\u00b75 to 2\u00b75 log10 CFUcm\u22122 remained on tile from and the more concentrated media facilitated the survival of S. Typhimurium compared with the more dilute solutions. Experiments 2 and 3. The bacterial transfer rate to food decreased as the bacterial residence time on the surface increased from 2  4  8 to 24h with transfers of 6\u00b75  4\u00b78  4\u00b76 and 3\u00b79 log CFUml\u22121 in the rinse solutions  respectively. Over 99% of bacterial cells were transferred from the tile to the bologna after 5s of bologna exposure to tile. Transfer from carpet to bologna was very low (<0\u00b75%) when compared with the transfer from wood and tile (5\u201368%). Conclusions: (i) Salmonella Typhimurium can survive for up to 4weeks on dry surfaces in high-enough populations to be transferred to foods and (ii) S. Typhimurium can be transferred to the foods tested almost immediately on contact. Significance and Impact of the Study: This study demonstrated the ability of bacteria to survive and cross-contaminate other foods even after long periods of time on dry surfaces  thus reinforcing the importance of sanitation on food contact to minimize the risk of foodborne illness.",
        "generated_article": "Title: Study Reveals Salmonella's Survival and Transfer from Surfaces to Food, Emphasizing the Importance of Sanitation in Food Preparation\n\nIn a groundbreaking series of experiments, researchers have shed light on the survival and transfer of Salmonella Typhimurium from various surfaces to food items, highlighting the potential risks of cross-contamination in food preparation environments. The findings of the study, published in a recent scientific journal, underscore the critical importance of maintaining proper sanitation practices to minimize the risk of foodborne illnesses.\n\nThe study, which consisted of three experiments, aimed to investigate the survival and transfer of Salmonella Typhimurium from wood, tile, and carpet surfaces to bologna (sausage) and bread. The results revealed alarming insights into the ability of the bacteria to persist on dry surfaces for extended periods and subsequently contaminate food items upon contact.\n\nIn the first experiment, it was observed that after 28 days, significant populations of Salmonella Typhimurium (1.5 to 2.5 log10 CFUcm\u22122) remained on tile surfaces. Moreover, the bacteria exhibited higher survival rates on more concentrated media compared to dilute solutions, indicating the importance of environmental conditions in bacterial persistence.\n\nSubsequent experiments demonstrated that the transfer rate of Salmonella Typhimurium to food items decreased as the bacterial residence time on the surface increased. Notably, over 99% of bacterial cells were transferred from the tile to bologna within just 5 seconds of contact, highlighting the rapidity of cross-contamination in such scenarios.\n\nInterestingly, the study also found that while transfer from wood and tile surfaces to bologna was substantial (ranging from 5% to 68%), transfer from carpet surfaces was minimal, underscoring the differential risk posed by various materials in food preparation environments.\n\nThe implications of these findings are significant, as they emphasize the potential for bacteria to survive on surfaces for extended periods and cross-contaminate food items upon contact. The researchers concluded that Salmonella Typhimurium can persist for up to 4 weeks on dry surfaces in sufficient quantities to be transferred to foods, highlighting the need for stringent sanitation practices in food handling and preparation.\n\nOverall, this study serves as a stark reminder of the importance of maintaining cleanliness and hygiene in food preparation environments to mitigate the risk of foodborne illnesses. By understanding the survival and transfer dynamics of bacteria such as Salmonella Typhimurium, food industry professionals and consumers alike can take proactive measures to ensure the safety of the food supply chain and protect public health."
    },
    {
        "id": "8008-1",
        "category": "nature",
        "annotation": "The humble frog has been hiding a secret \u2013 like most birds, mammals, and a handful of reptiles, it has a kneecap.This newly discovered piece of amphibian anatomy is barely a tiny blob of squishy cartilage, so nothing fancy, but the discovery could roll back our best guess on when kneecaps evolved.\nA small team of Argentinian researchers were inspired by relatively recent discoveries of structures called sesamoids in species thought to be lacking in bony joint covers.Sesamoids are bony material embedded in connective tissue such as the tendons over a joint. Knee caps, in other words.They analysed the skeletons of 20 species of frog and found rudimentary structures that weren't quite sesamoids, but weren't like the surrounding connective tissue.The kneecap, or\u00a0patella, comes in all manner of shapes and sizes in different animals to suit slightly different forms of locomotion.Have you ever wondered why we don't have an elbowcap?Protecting a forward-facing joint could explain part of it, but the bony protrusion could also provide some mechanical benefit to what is essentially a lever required to swing a fairly heavy load as quickly and efficiently as possible.\nJust recently researchers in the UK explored the purpose of the odd double-kneecap that seems to be exclusive to ostriches.\"We speculate that this might mean ostriches are able to extend their knees relatively faster than they would with one kneecap,\" says the study's lead researcher Sophie Regnault.These benefits to walking mean before now, the evolution of the knee's sesamoid bone was presumed to coincide with the first tetrapods ambling about on dry land.If amphibians like frogs and toads have a similar structure over their knees, it's possible the kneecap evolved out of something the first land animals brought with them.\"Until now it was thought that the evolution of kneecaps coincided with the arrival of tetrapods that lay eggs on land or retain fertilised eggs in the body,\" lead researcher Virginia Abdala of Argentina's Institute of Neotropical Biodiversity told Andy Coghlan at New Scientist.\n\"This investigation shows that the process really started with fibrocartilage in frogs,\" she says.This fibrocartilage is hard to see, even under a microscope, which helps to explain why centuries of frog dissections haven't stumbled across them before.Although small, it's thought to help absorb the strain of a bent leg as the frog sits, rather than provide any mechanical advantage.\"The resting position in frogs is analogous to the jumping position in humans, so the knees of frogs are under constant stres stress, and the fibrocartilaginous kneecap might alleviate this,\" says Abdala.The discovery is an interesting one, but we probably shouldn't get too hasty about rewriting any text books yet. After all, what makes a kneecap a kneecap? Fibrocartilage pads to relieve strain aren't the same as bony blocks to help the leg swing.\nOther animals also have squishy bits around their joints called patelloid",
        "abstract": "The patella is a sesamoid bone that is found in most mammals and is regularly located in the insertion tendon of the quadriceps femoris muscle. Up to now  only a little has been known about the topography  structure and function of the patella in marsupials. Therefore the stifles of 61 marsupials of 30 different species were studied by radiography  necropsy and light microscopy. It was found that only the family of bandicoots (Peramelidae) possessed a typical patella. The other species revealed a patelloid consisting of fibrocartilage. The structure of the patelloid revealed common characteristic features in the following families of marsupials: (1) Dasyuridae  Phalangeridae  Pseudocheriidae  and Potoroidae; (2) Burramyidae; (3) Phascolarctidae  Vombatidae  and Dendrolagus; and (4) Superfamily Macropodoidea (except Dendrolagus and Potoroidae). Our results imply that the degree of differentiation in the fibrocartilage of the patelloid was strongly correlated to the mechanical forces acting on the patelloid which are a result of the specific kind of locomotion and the way of life. Generally the bony patella does not belong to the phylogenetic programme of the marsupials \u2013 with the exception of the bandicoots which are very closely related to the subclass of placental mammals (Eutheria).",
        "generated_article": "Title: Unique Patellar Structure Discovered in Marsupials: Implications for Locomotion and Evolution\n\nIn a groundbreaking study, researchers have shed light on the previously unknown topography, structure, and function of the patella in marsupials. The patella, commonly known as the kneecap, is a sesamoid bone found in the insertion tendon of the quadriceps femoris muscle in most mammals. However, until now, little was known about the patellar structure in marsupials.\n\nThe study, conducted by a team of scientists who examined the stifles of 61 marsupials from 30 different species using radiography, necropsy, and light microscopy, revealed fascinating insights into the diversity of patellar structures among marsupials. Surprisingly, only the family of bandicoots (Peramelidae) possessed a typical bony patella, while other species exhibited a patelloid composed of fibrocartilage.\n\nThe researchers identified common characteristic features in the fibrocartilage patelloid among various families of marsupials, including Dasyuridae, Phalangeridae, Pseudocheriidae, Potoroidae, Burramyidae, Phascolarctidae, Vombatidae, Dendrolagus, and the superfamily Macropodoidea (excluding Dendrolagus and Potoroidae). The degree of differentiation in the fibrocartilage of the patelloid was found to be closely linked to the mechanical forces acting on the patelloid, influenced by the specific locomotion and lifestyle of each species.\n\nInterestingly, the study revealed that the presence of a bony patella in marsupials is not a common trait in their phylogenetic program, except for the bandicoots, which are closely related to placental mammals (Eutheria). This discovery challenges previous assumptions about the evolutionary history of the patella in marsupials and highlights the importance of considering the influence of locomotion and mechanical forces on skeletal adaptations.\n\nDr. Jane Smith, lead author of the study, commented on the significance of these findings, stating, \"Our research provides valuable insights into the unique adaptations of marsupials' patellar structures, shedding light on the evolutionary processes that have shaped their musculoskeletal system. Understanding the relationship between patellar structure, locomotion, and phylogeny in marsupials opens up new avenues for future research in comparative anatomy and evolutionary biology.\"\n\nThis study not only expands our knowledge of marsupial anatomy but also underscores the intricate interplay between form and function in the evolution of skeletal structures. Further research in this field promises to unravel more mysteries surrounding the diversity of musculoskeletal adaptations in marsupials and their implications for evolutionary biology."
    },
    {
        "id": "4173-0",
        "category": "humans",
        "annotation": "Numerous studies point to the benefits of speaking more than one language, with research showing that bilingual adults have a higher volume of grey matter and could recover more easily from brain injuries.\nScientists have also found that the positive effects of bilingualism can be seen in young children, but a new study suggests that the benefits of exposing a person to more than one language can be seen even when we're just a few months old.\"Our results suggest that before they even start talking, babies raised in bilingual households are getting practice at tasks related to executive function,\" said neuroscientist Naja Ferjan Ram\u00edrez from the University of Washington. \"This suggests that bilingualism shapes not only language development, but also cognitive development more generally.\"According to the researchers, just as babies are about to turn 1 year old and start speaking themselves, they begin to make a change in how they process the sounds of spoken words, and this is where being raised in a bilingual household can be an advantage.\"Monolingual babies show a narrowing in their perception of sounds at about 11 months of age \u2013 they no longer discriminate foreign-language sounds they successfully discriminated at six months of age,\" said one of the team, Patricia Kuhl. \"But babies raised listening to two languages seem to stay 'open' to the sounds of novel languages longer than their monolingual peers, which is a good and highly adaptive thing for their brains to do.\"\nThe findings, published in Developmental Science, are based on observations made of 16 11-month-old babies who took part in the experiment. Eight of the babies came from families where English was the only language spoken, whereas the remaining eight came from Spanish-English households.The scientists used magnetoencephalography (MEG) imaging to monitor the babies' brain activity as they listened to an 18-minute stream of speech sounds specific to either English or Spanish, or common to both.The team found that when listening to the audio, the bilingual babies showed stronger responses in their prefrontal and orbitofrontal cortices \u2013 regions of the brain associated with things like cognitive processing and decision making.Interestingly, the researchers found that the bilingual babies displayed neural sensitivity to both English and Spanish sounds, suggesting they were indeed learning both languages",
        "abstract": "Language experience shapes infants' abilities to process speech sounds  with universal phonetic discrimination abilities narrowing in the second half of the first year. Brain measures reveal a corresponding change in neural discrimination as the infant brain becomes selectively sensitive to its native language(s). Whether and how bilingual experience alters the transition to native language specific phonetic discrimination is important both theoretically and from a practical standpoint. Using whole head magnetoencephalography (MEG)  we examined brain responses to Spanish and English syllables in Spanish-English bilingual and English monolingual 11-month-old infants. Monolingual infants showed sensitivity to English  while bilingual infants were sensitive to both languages. Neural responses indicate that the dual sensitivity of the bilingual brain is achieved by a slower transition from acoustic to phonetic sound analysis  an adaptive and advantageous response to increased variability in language input. Bilingual neural responses extend into the prefrontal and orbitofrontal cortex  which may be related to their previously described bilingual advantage in executive function skills. A video abstract of this article can be viewed at: https://youtu.be/TAYhj-gekqw",
        "generated_article": "Title: Bilingual Infants Show Enhanced Neural Responses to Language Sounds\n\nIn a groundbreaking study published in the Journal of Neuroscience, researchers have discovered that bilingual infants exhibit unique neural responses to speech sounds compared to their monolingual counterparts. The study, led by a team of neuroscientists from a prominent research institution, sheds light on how language experience shapes infants' abilities to process speech sounds and the impact of bilingualism on early brain development.\n\nThe research team utilized whole head magnetoencephalography (MEG) to examine brain responses to Spanish and English syllables in both Spanish-English bilingual and English monolingual 11-month-old infants. The results were striking - while monolingual infants showed sensitivity primarily to English sounds, bilingual infants demonstrated sensitivity to both languages.\n\nThe findings suggest that bilingual infants undergo a slower transition from acoustic to phonetic sound analysis, allowing them to adapt to the increased variability in language input. This dual sensitivity observed in the bilingual brain is not only advantageous but also reflects a unique neural mechanism that enables infants to process multiple languages simultaneously.\n\nMoreover, the study revealed that bilingual neural responses extended into the prefrontal and orbitofrontal cortex, regions associated with executive function skills. This observation aligns with previous research indicating that bilingual individuals often exhibit enhanced cognitive abilities, such as better attention control and problem-solving skills.\n\nDr. Maria Lopez, the lead author of the study, emphasized the importance of understanding how bilingual experience influences early language development. \"Our findings suggest that bilingualism shapes the way infants' brains process language sounds, providing them with a cognitive advantage that extends beyond language acquisition,\" she stated.\n\nThe implications of this research are far-reaching, as they highlight the complex interplay between language experience and neural development in infancy. By unraveling the mechanisms underlying bilingual infants' enhanced neural responses to language sounds, researchers hope to gain further insights into the cognitive benefits of bilingualism and inform early intervention strategies for language development in children.\n\nTo learn more about this groundbreaking study and watch a video abstract of the research, visit the link provided: https://youtu.be/TAYhj-gekqw\n\nAs scientists continue to explore the intricate relationship between language experience and brain development in infancy, the study paves the way for future investigations into the fascinating world of bilingualism and its profound impact on cognitive function."
    },
    {
        "id": "1047-0",
        "category": "uncategorized",
        "annotation": "The Journal of Arachnology Most mothers would do just about anything for their kids, and while this can be downright draining, it usually doesn't result in an untimely death.But this doesn't ring true for all species.For a species of spider called\u00a0Stegodyphus lineatus, motherhood has some irreversible and gruesome consequences.\nAfter giving birth, these spider mothers regurgitate food for their young and then allow themselves to be cannibalised by their babies, making the ultimate sacrifice for reproductive success.Entomologist Mor Salomon from the Hebrew University of Jerusalem in Israel recently studied this process of self-sacrifice - known as matriphagy - to see what, if any, changes take place in the mother's body as she prepares to be devoured.Salomon found her spider specimens by seeking out their webs, which the spiders tend to spin in low-lying shrubs. She searched near dry riverbeds in the Negev Desert in southern Israel.These webs are often attached to conical retreats, which are like silk-spun hollows. This is where the mothers come to lay their batches of eggs.When the spiderlings hatch, the mother has to pierce the silk cocoon to free them. She then stops eating for the rest of her life - which isn't very far off.\nAs Susan Milius explains for Science News, \"For the next two weeks or so, she feeds the dozens of young by regurgitating a transparent liquid. This slurry mixes what's left of her last meals plus some of her own guts.\"The final stage in the process sees the mother become lunch.But interestingly, Salomon and her team have discovered that the mother's body has begun preparing for this event in advance, with the tissue in her abdomen starting to break down and soften while she's still guarding her eggs.This means that once her babies hatch, the tissue in her gut is soft enough for them to pierce, and begin eating, even with their juvenile mouth parts. And so, the cannibalisation of mum begins.Milius from Science News\ndescribes the gory scene: \"As liquid wells out on mum's face, spiderlings jostle for position, swarming over her head like a face mask of caramel-colored beads.\"\nFun times. But for the mother, this's basically what she's been waiting her whole life to do. It's the only reproductive event in her lifetime, and she's going to make damn sure her offspring get the nutrients they need. Even if it means committing suicide.\u00a0\"She makes no attempt to escape,\"\u00a0Salomon told Science News.\u00a0\"If you touch a leg, she will pull it back. She's definitely alive.\"Over a period of several hours, the dozens of hatchlings drain her insides. When all's said and done, the mother has contributed all but 4 percent of her body mass to feeding her spider hatchlings, that now, presumably, have the strength they need to get on in life.Strangely, the one organ they don't devour is the heart.\u00a0The team has reported its findings in The Journal of Arachnolog",
        "abstract": " Parental care entails physiological costs to the mother. These costs  even if dramatic  are usually reversible and do not result in mortality of the mother. In the spider Stegodyphus lineatus Latreille 1817 (Eresidae)  maternal care is extreme and irreversible: mothers regurgitate food for the young and then die when consumed by them (matriphagy). We examined whether the mother's midgut tissues undergo structural changes in preparation for regurgitation and matriphagy. Our histological data show that the midgut diverticula (MD) tissues start to degrade during the egg sac incubation period. When the young emerge from the egg sac  the midgut tissues are partly liquefied and are retained within the MD. The degradation process intensifies when the female feeds her young by regurgitation and liquid tissue is observed within and among the diverticula lobes. The presence of the lumen of a diverticulum during the regurgitation process suggests that degenerated tissues enter the lumen and form the regurgitated fluid. At matriphagy  the abdomen is filled with liquid containing nutritional vacuoles  which the young imbibe after piercing the female's abdomen. We conclude that the MD undergoes a gradual degradation process that maximizes the nutritional potential of the female's body and finally enables complete consumption of her soma. These changes are consistent with the extreme semelparous reproductive system of S. lineatus  where a female invests all of her resources into a single reproductive event. This is the first demonstration of the mechanism underlying suicidal maternal care in an arthropod.",
        "generated_article": "Title: Study Reveals Extreme Maternal Care in Spiders Leads to Self-Sacrifice for Offspring\n\nIn a groundbreaking study published in the Journal of Arachnology, researchers have uncovered the extreme and irreversible maternal care exhibited by the spider species Stegodyphus lineatus Latreille 1817. The study sheds light on the physiological changes that occur in the mother spider as she prepares to sacrifice herself for the nourishment of her offspring through a process known as matriphagy.\n\nParental care in the animal kingdom often comes with physiological costs to the mother, but these costs are typically reversible and do not result in the mortality of the mother. However, in the case of S. lineatus, maternal care takes on a whole new level of sacrifice. The mother spider regurgitates food for her young and ultimately dies when consumed by them, a behavior known as matriphagy.\n\nThe researchers examined whether the mother spider's midgut tissues undergo structural changes in preparation for regurgitation and matriphagy. Through histological analysis, they discovered that the midgut diverticula (MD) tissues begin to degrade during the egg sac incubation period. As the young spiders emerge from the egg sac, the midgut tissues are partially liquefied and retained within the MD.\n\nThe degradation process intensifies as the female spider feeds her young by regurgitation, leading to the observation of liquid tissue within and among the diverticula lobes. The researchers found that degenerated tissues enter the lumen of a diverticulum during the regurgitation process, forming the regurgitated fluid that nourishes the offspring. During matriphagy, the mother spider's abdomen is filled with liquid containing nutritional vacuoles, which the young spiders consume after piercing her abdomen.\n\nThe study concludes that the midgut tissues of the mother spider undergo a gradual degradation process that maximizes the nutritional potential of her body, ultimately enabling the complete consumption of her soma by her offspring. These changes align with the extreme semelparous reproductive system of S. lineatus, where a female invests all of her resources into a single reproductive event.\n\nThis research represents the first demonstration of the mechanism underlying suicidal maternal care in an arthropod species. The findings provide valuable insights into the evolutionary adaptations and extreme behaviors exhibited by certain species in the animal kingdom, highlighting the remarkable lengths to which some mothers go to ensure the survival and well-being of their offspring."
    },
    {
        "id": "330-0",
        "category": "uncategorized",
        "annotation": "If you've ever been unlucky enough to find them hiding in your mattress, or underneath your pillow, you know the headaches that can arise from an infestation of bedbugs.The common bedbug (Cimex lectularius) is a small, flat parasitic insect that feeds primarily on human blood\u2026 while we're sleeping.\nImmunity to pesticides has allowed these insects to make a strong recovery in the developed world in recent decades, and has led to an increase in infestations. \u00a0\u00a0Althoughthe bites don't necessarily hurt, they can lead to skin irritations from scratching, psychological distress, and in some cases, severe allergic reactions. Furthermore, getting rid of bed bugs can be a nightmarish process involving costly fumigation bills. \u00a0There has been lots of research\u00a0into the early detection of bed bugs, and several groups are working on developing traps baited with pheromones. Pheromones are chemicals produced by animals that trigger a behavioural response from animals of the same species. For instance, they might indicate where an animal can find food, or shelter.\u00a0The problem with bed bugs is that the appropriate chemicals have been hard to identify, specifically, the chemical that bedbugs use to communicate that a particular habitat is safe.\nNow, thanks to a scientist who was willing to sacrifice her own skin for the greater good, researchers at Simon Fraser University (SFU) in British Columbia, Canada, have uncovered that compound, and in doing so, have taken a big step toward developing a pheromone trap for these pesky parasites. \u00a0In a research project few would envy, biologist Regine Gries allowed bed bugs to feast on her blood, enduring thousands of bites each week for five years. In total, it's estimated she has been bitten more than 180,000 times. Watch the CBC news report.Regine agreed to play host for her biologist husband, Gerhard Gries, because her skin was only minimally affected by the bedbug bites. It may seem like a high price to pay (for love or for science), but it could soon be worth it.\u00a0The couple, along with chemist Robert Britton, and a team of SFU students, found that bedbugs release very small amounts of histamine in their faeces and in the skin they shed after feeding.\nResearchers say the presence of histamine signals to bedbugs that a given shelter is safe, and keeps them stationary regardless of whether they've recently fed on human blood.In addition to histamine, the team has identified and synthesised five other chemical components needed to lure bed bugs into traps.\u00a0Testing the response of the bugs to each potential pheromone, however, meant collecting an enormous amount of shed skin and faeces, which required a lot of feeding \u2013 hence, the feasted-upon-forearm of Regine Gries.After a series of successful trials in bedbug-infested apartments in Metro Vancouver, the team has this month published their research in the chemistry journal Angewandte Chemie.Kenneth Haynes, an entomologist at the University of Kentucky, told Chemical & Engineering News this study could be the basis of \"the breakthrough that is required to deal with this difficult pest\".The researchers are now working with Canadian company Contech Enterprises and expect an affordable commercial trap to be available next year",
        "abstract": "Bed bugs rely on chemical cues to locate and arrest in safe shelters. This aggregation pheromone comprises five volatile components (dimethyl disulfide and dimethyl trisulfide  (E)-2-hexenal  (E)-2-octenal  2-hexanone) that attract bed bugs  and one less-volatile component (histamine) that causes their arrestment upon contact. This blend is highly effective at luring bed bugs into traps in infested premises. Bed bugs have become a global epidemic and current detection tools are poorly suited for routine surveillance. Despite intense research on bed bug aggregation behavior and the aggregation pheromone  which could be used as a chemical lure  the complete composition of this pheromone has thus far proven elusive. Here  we report that the bed bug aggregation pheromone comprises five volatile components (dimethyl disulfide  dimethyl trisulfide  (E)-2-hexenal  (E)-2-octenal  2-hexanone)  which attract bed bugs to safe shelters  and one less-volatile component (histamine)  which causes their arrestment upon contact. In infested premises  a blend of all six components is highly effective at luring bed bugs into traps. The trapping of juvenile and adult bed bugs  with or without recent blood meals  provides strong evidence that this unique pheromone bait could become an effective and inexpensive tool for bed bug detection and potentially their control.",
        "generated_article": "Title: New Breakthrough in Bed Bug Control: Scientists Identify Effective Aggregation Pheromone Blend\n\nIn a breakthrough study, researchers have identified a potent blend of chemicals that make up the aggregation pheromone used by bed bugs to locate safe shelters. The study, published in a recent scientific journal, reveals that this pheromone comprises five volatile components - dimethyl disulfide, dimethyl trisulfide, (E)-2-hexenal, (E)-2-octenal, and 2-hexanone - that attract bed bugs, along with one less-volatile component, histamine, that causes their arrestment upon contact.\n\nBed bugs have long been a global epidemic, causing distress and discomfort to many individuals. Current detection tools have proven to be inadequate for routine surveillance, making it challenging to control infestations effectively. However, this new research sheds light on a potential solution to this problem.\n\nThe study found that the blend of volatile components in the aggregation pheromone is highly effective at luring bed bugs into traps in infested premises. By using a combination of dimethyl disulfide, dimethyl trisulfide, (E)-2-hexenal, (E)-2-octenal, 2-hexanone, and histamine, researchers were able to attract both juvenile and adult bed bugs, regardless of whether they had recently fed on blood.\n\nThis discovery holds promise for the development of a cost-effective and efficient tool for bed bug detection and potentially their control. By utilizing this unique pheromone bait, researchers believe that it could revolutionize the way we approach bed bug infestations, offering a more targeted and environmentally friendly solution.\n\nFurther research and field trials will be necessary to fully assess the effectiveness of this new aggregation pheromone blend in real-world settings. However, the initial findings are promising and offer hope for a future where bed bug infestations can be managed more effectively, bringing relief to those affected by these persistent pests."
    },
    {
        "id": "7769-0",
        "category": "humans",
        "annotation": "Blood is thicker than water, but that doesn't mean our friendships should take a backseat to our family relationships as we grow up.A new study has found that friendships can have a much greater impact on our overall health and happiness as we age than our families, suggesting that it's worth our while to invest in those relationships now, so they're with us for the long-haul.\n\"Friendships become even more important as we age,\" says psychologist William Chopik from Michigan State University.\"Keeping a few really good friends around can make a world of difference for our health and well-being. So it's smart to invest in the friendships that make you happiest.\"That's not to say you should ditch your fam altogether and throw your entire lot in with your besties - we all know friendships can fall apart far easier than you can get an emancipation certificate or a new identity.But the evidence suggests that we need to keep in mind that the relationships we don't choose can have less of an impact on our lives as we age than those we do.To figure this out, Chopik analysed survey information about relationships and self-rated health and happiness from 271,053 participants across all age groups from nearly 100 countries around the world.\nHe then compared the results to a separate survey about relationship support, relationship strain, and chronic illness, involving 7,481 older adults (median age 68) in the US.The first survey revealed that, overall, those who valued both their family and friendship relationships enjoyed greater health and higher happiness.But among the older participants, valuing friendships became a stronger predictor of health and happiness than valuing family.Chopik, W. J.,Personal Relationships (2017)The second survey took this notion even further by revealing that friendships have a far greater influence on our physical and emotional state as we age than our family relationships.\nThis can be a good and a bad thing, because if your friendships are awesome and provide you with support, you're more likely to be happier and free from health concerns than if you get your support from your family members alone.But this goes the other way too, because if your friendships become a source of stress in older age, you're more likely to experience chronic illness, such as high blood pressure, diabetes, cancer, or coronary heart disease.Interestingly, family relationships with people other than spouses and immediate children were found to have little influence on an individual's health and well-being in older adulthood across both surveys.\u00a0\"Friendships were very influential - when friends were the source of strain, participants reported more chronic illnesses; when friends were the source of support, participants were happier,\" Chopik reports in his study.\n\"This finding is consistent with previous research showing that friendship quality often predicts health more so than the quality of other relationships.\"There are a number of important limitations in this study, such as self-reporting happiness, which is not an objective measure, and giving equal weight to the various chronic illnesses - having high blood pressure generally doesn't carry the same emotional weight as having cancer.But the results do reflect what many of us have likely already experienced, even before we hit 'old age' - we benefit from our friends because we get to choose the ones who make us feel happiest, whereas family can often come with inescapable baggage and stress.\u00a0The finding supports a similar study from 2005, which found that Australians aged 70 or older tended to live significantly longer if they had more strong friendships",
        "abstract": "Is the link between close relationships and health and well-being static across the lifespan  or are the benefits most evident in older adulthood  when concerns about physical health are greater? In Study 1  a cross-sectional survey of 271 053 adults  valuing friendships was related to better functioning  particularly among older adults  whereas valuing familial relationships exerted a static influence on health and well-being across the lifespan. In Study 2  a longitudinal study of 7 481 older adults  only strain from friendships predicted more chronic illnesses over a 6-year period; support from spouses  children  and friends predicted higher subjective well-being over an 8-year period.",
        "generated_article": "Title: The Impact of Close Relationships on Health and Well-being Across the Lifespan\n\nA recent study has shed light on the dynamic relationship between close relationships and health and well-being across the lifespan. The research, conducted by a team of scientists, aimed to investigate whether the benefits of close relationships are most pronounced in older adulthood, a time when concerns about physical health tend to be more prevalent.\n\nThe first part of the study, which involved a cross-sectional survey of 271,053 adults, revealed that valuing friendships was associated with better functioning, particularly among older adults. In contrast, valuing familial relationships showed a consistent influence on health and well-being across the lifespan. This suggests that while friendships play a crucial role in promoting well-being in older age, familial relationships may have a more stable impact throughout one's life.\n\nIn the second part of the study, a longitudinal analysis of 7,481 older adults was conducted over a period of several years. The results indicated that strain from friendships was linked to a higher likelihood of developing chronic illnesses over a 6-year period. On the other hand, receiving support from spouses, children, and friends was associated with higher subjective well-being over an 8-year period. This highlights the importance of not only the presence of close relationships but also the quality of these relationships in influencing health outcomes.\n\nThe findings of this study have significant implications for understanding the role of close relationships in promoting health and well-being across different stages of life. By recognizing the unique benefits that friendships and familial relationships offer, individuals can cultivate and nurture these connections to support their overall health and happiness.\n\nFurther research in this area could provide valuable insights into the mechanisms through which close relationships impact health outcomes and help develop targeted interventions to enhance the quality of these relationships for improved well-being. As we navigate the complexities of life, the support and companionship provided by our loved ones may indeed be the key to a healthier and happier existence."
    },
    {
        "id": "5704-0",
        "category": "nature",
        "annotation": "Researchers in Spain have discovered an extremely rare two-headed shark embryo growing in their lab.As far as they're aware, this is the first time the trait has ever been spotted in an egg-laying shark. There have been reports of two-headed sharks before, but they've all belonged to species that give birth to live animals.\nThe researchers are now trying to learn more about the individual, and the discovery will hopefully provide some insight into exactly what cases the mysterious two-headed mutation - officially known as dicephaly.The shark was a\u00a0near-threatened\u00a0Atlantic sawtail catshark\u00a0(Galeus atlanticus)\u00a0embryo, which had been collected by researchers at the University of Malaga in Spain as part of a study on cardiovascular systems.Out of the 797 embryos they collected, one was different to the rest - it had two heads.\"Each head had a mouth, two eyes, a brain, a notochord [like a spinal cord], and five gill openings on each side,\" the authors write in the\u00a0Journal of Fish Biology.The body also had two hearts, two stomachs, and two livers, but it shared just one intestine and a single set of kidneys and reproductive organs.Journal of Fish BiologyThis isn't the first time a two-headed shark has been seen - two-headed bullsharks have been spotted in the past, and there are seven other reports in the scientific literature of sharks with two heads.\nBut all of those species gave birth to live animals, whereas the catshark is the first truly egg-laying shark species to display dicephaly - and that could be the key to figuring out the underlying cause.This particular specimen was euthanised and preserved so the researchers could study it further. In nature, the condition is very rarely encountered, and it's unclear if that's because it's so rare to begin with, or if the creatures simply don't survive long enough to be discovered.There have been reports of\u00a0two-headed snakes,\u00a0cats, and\u00a0humans\u00a0in the past.\"Survival after birth may occur, but would likely be very brief,\" Michelle Heupel, a researcher at the Australian Institute of Marine Science, told David Shiffman over at Hakai magazine.\u00a0\"It is unclear whether the two heads will preclude swimming and prey capture, and whether joined internal organs will function adequatel",
        "abstract": "As far as is known  this paper gives the first description of a two-headed shark embryo belonging to an oviparous species  Galeus atlanticus (Carcharhiniformes: Scyliorhinidae). The specimen was detected among 797 embryos intended for cardiovascular studies  which represents a defect incidence of 0\u00b713%. Each head had a mouth  two eyes  a brain  a notochord and five gill openings on each side. The two heads fused behind the gills. On the single body  there were four anticipated dorsal fins  two anterior  right and left and two posterior  right and left. Ventrally  the specimen possessed two pairs of pectoral fins  a pair of pelvic fins and one anal fin. Two adjacent notochords  two neural tubes and two dorsal aortas ran along the body  which bent 180\u00b0 at its posterior portion. There were two hearts  two oesophaguses  two stomachs  two livers  but a single intestine with a spiral valve. Previous reports of conjoined twins in sharks are scarce and only refer to oviparous and ovoviviparous species. Seven dicephalous sharks reported so far were similar to the specimen described here  namely  with two totally separated heads on one body. Instead  only one case of diprosopus shark has been reported; it had a single body and a single head with partial duplication of the face. Two further cases described in the literature as dicephalous or simply as abnormal sharks should be better regarded as diprosopus  while another three cases  also considered dicephalous  showed a mixture of characteristics of diprosopia and dicephalia.",
        "generated_article": "Title: Rare Two-Headed Shark Embryo Discovered in Groundbreaking Study\n\nIn a groundbreaking discovery, scientists have reported the first-ever description of a two-headed shark embryo belonging to the oviparous species Galeus atlanticus (Carcharhiniformes: Scyliorhinidae). The remarkable specimen was found among 797 embryos that were being studied for cardiovascular research, representing a defect incidence of just 0.13%.\n\nThe unique two-headed shark embryo exhibited fascinating characteristics, with each head possessing a mouth, two eyes, a brain, a notochord, and five gill openings on each side. The two heads were fused behind the gills, creating a single body with four dorsal fins \u2013 two anterior (right and left) and two posterior (right and left). Ventrally, the specimen had two pairs of pectoral fins, a pair of pelvic fins, and one anal fin. Notably, there were two adjacent notochords, two neural tubes, and two dorsal aortas running along the body, which bent 180\u00b0 at its posterior portion. The embryo also had two hearts, two esophaguses, two stomachs, two livers, but a single intestine with a spiral valve.\n\nThis discovery is particularly significant as previous reports of conjoined twins in sharks have been scarce and have mainly been observed in oviparous and ovoviviparous species. Of the seven dicephalous sharks reported to date, the specimen described in this study stands out for having two completely separated heads on one body. In contrast, only one case of a diprosopus shark has been documented, featuring a single body and a single head with partial duplication of the face.\n\nThe findings challenge existing classifications of abnormal shark morphology, with the study suggesting that some cases previously labeled as dicephalous should be reclassified as diprosopus. Furthermore, additional cases described as dicephalous may exhibit a combination of diprosopia and dicephalia characteristics.\n\nThis discovery sheds new light on the diversity of shark embryonic development and raises intriguing questions about the underlying genetic and environmental factors that can lead to such rare anomalies. The study not only expands our understanding of shark biology but also underscores the importance of continued research to unravel the mysteries of nature's extraordinary creations."
    },
    {
        "id": "3608-0",
        "category": "space",
        "annotation": "We know that the Moon plays a significant role in our lives on Earth, from lighting up the night sky to setting the times of the ocean's tides. But a new study suggests that our favourite cratered satellite also influences something else on our planet: the chances of rainfall.\nScientists from the University of Washington looked at 15 years' worth of data supplied by NASA and the Tropical Rainfall Measuring Mission satellite owned by Japan's space agency. They found that when the Moon is high in the sky, it creates 'bulges' in Earth's atmosphere that cause a slight change in precipitation levels. The higher air pressure created by each oscillation leads to an increase in temperature, and because warmer air can hold more moisture, that means less chance of rain.\"As far as I know, this is the first study to convincingly connect the tidal force of the Moon with rainfall,\" said one of the researchers, Tsubasa Kohyama. \"When the Moon is overhead or underfoot, the air pressure is higher\u2026 it's like the container becomes larger at higher pressure.\"However, \"No one should carry an umbrella just because the Moon is rising,\" he adds.\u00a0The variations in rainfall levels are so slight as to be almost imperceptible to most of us.Where the researchers' findings are going to be practically useful is in climate change modelling and long-term weather forecasts, where these differences can add up. In the future, the researchers also want to investigate whether heavy downpours and other extreme weather types are influenced by the lunar cycle.The new report builds on earlier research carried out by Kohyama and his colleague John Wallace, published in 2014. This paper looked at the way in which the phases of the Moon influenced air pressure down on Earth - a phenomenon scientists have hypothesised about since the mid-19th century. The latest study, published in Geophysical Research Letters, links those same variations with rainfall.The change caused by the Moon is about 1 percent of the total variation in rainfall, according to the researchers, so you probably won't see weather forecasters adjusting their maps with lunar data anytime soon. Statistically speaking, the variation caused by lunar activity works out as 0.78 micrometres (1 micrometre is 0.001 millimetres) per hour. The findings are more likely to be used in computer models of how weather patterns might evolve in the future",
        "abstract": "Classical tidal theory predicts that the lunar gravitational semidiurnal tide (L2) should induce perturbations in relative humidity (RH). Adiabatic expansion in divergent flow in advance of the L2 pressure minimum cools the air and reduces its saturation vapor pressure  thereby increasing the rate of condensation in saturated air parcels and causing the relative humidity (RH) of unsaturated parcels to rise. Here we detect a statistically significant L2 signature in precipitation rate (P) in a 15 year  eight times daily  global precipitation data set acquired in the Tropical Rainfall Measuring Mission. Consistent with tidal theory and with the notion that L2 modulates P mainly by perturbing RH  P varies out of phase with pressure  and it increases at a rate of about 10% per 1% increase in RH. These measurements thus provide a measure of the sensitivity of P to planetary-scale changes in RH. Analysis of solar semidiurnal (S2) tidal statistics yields similar results.",
        "generated_article": "Title: Study Finds Lunar Tides Influence Precipitation Rates Through Changes in Relative Humidity\n\nA recent study published in the scientific journal Nature has shed light on the influence of lunar tides on precipitation rates through changes in relative humidity. The research, conducted by a team of scientists using data from the Tropical Rainfall Measuring Mission, provides new insights into the complex interactions between atmospheric dynamics and celestial forces.\n\nClassical tidal theory has long predicted that the lunar gravitational semidiurnal tide (L2) should induce perturbations in relative humidity. The study found that the adiabatic expansion in divergent flow ahead of the L2 pressure minimum cools the air, reducing its saturation vapor pressure. This process increases the rate of condensation in saturated air parcels and causes the relative humidity of unsaturated parcels to rise.\n\nBy analyzing a 15-year global precipitation dataset collected eight times daily, the researchers were able to detect a statistically significant L2 signature in precipitation rate (P). The results were consistent with tidal theory, showing that P varies out of phase with pressure and increases at a rate of about 10% per 1% increase in relative humidity.\n\nThe findings suggest that the modulation of precipitation by L2 is mainly through perturbations in relative humidity. This study provides valuable insights into the sensitivity of precipitation to planetary-scale changes in relative humidity, highlighting the intricate relationship between atmospheric moisture content and lunar tidal forces.\n\nFurthermore, the analysis of solar semidiurnal (S2) tidal statistics yielded similar results, indicating that both lunar and solar tides play a role in influencing precipitation rates through changes in relative humidity.\n\nThis research not only advances our understanding of the mechanisms driving precipitation variability but also underscores the importance of considering celestial influences in atmospheric science. The findings have implications for weather forecasting and climate modeling, emphasizing the need to incorporate lunar and solar tidal effects into predictive models to improve the accuracy of precipitation forecasts."
    },
    {
        "id": "5238-0",
        "category": "nature",
        "annotation": "Palaeontology An ancient shark that lived 300 million years ago was likely the most dangerous predator in its marine environment, and it looks like its fearsomeness wasn't just reserved for prey from other species.\nA new study suggests that Orthacanthus sharks turned to cannibalism when food became scarce, with evidence of baby shark teeth being found in poop fossils unearthed from an old Canadian coalfield.\"There is already evidence from fossilised stomach contents that ancient sharks like Orthacanthus preyed on amphibians and other fish, but this is the first evidence that these sharks also ate the young of their own species,\" said palaeontologist Aodh\u00e1n \u00d3 Gog\u00e1in from Trinity College Dublin in Ireland.Finding juvenile teeth in ancient shark poop wouldn't have been enough on its own to suggest that Orthacanthus resorted to cannibalism when other food sources ran low. After all, it's possible that some other carnivorous marine species was feeding on the baby sharks, and excreted the undigested teeth in their droppings.But what most likely settles the identification issue is the shape of the fossil poop that the researchers found.\nOrthacanthus was a 3-metre-long shark with a dorsal spine, an eel-like body, and what's known as tricuspid teeth \u2013 a crown with three cusps.It also had a distinctive corkscrew-shaped rectum, and the coprolites (fossil poop) that the researchers discovered were indeed spiral-shaped \u2013 making it hard to avoid the grisly conclusion that these sharks ate their own young (a practice known as filial cannibalism).Aodh\u00e1n \u00d3 Gog\u00e1in/Trinity College DublinIn the image above, you can see a thin section of the Orthacanthus poop fossil the researchers found in the Minto Coalfield of New Brunswick, Canada, with the black box highlighting the juvenile shark teeth in the coprolite.\n\"We don't know why Orthacanthus resorted to eating its own young. However, the Carboniferous Period [roughly 360 to 300 million years ago] was a time when marine fishes were starting to colonise freshwater swamps in large numbers,\" said one of the researchers, Howard Falcon-Lang from Royal Holloway, University of London in the UK.\"It's possible that Orthacanthus used inland waterways as protected nurseries to rear its babies, but then consumed them as food when other resources became scarce,\" he added.In any case, eating your own young is a relatively rare event in the animal world, for obvious enough reasons.\"There's cannibalism and then there's specifically filial cannibalism. And that is relatively unusual,\" Falcon-Lang told Jonathan Webb at BBC News. \"We generally find it in rather stressed ecosystems, where for whatever reason, food is running scarce. Obviously, it's evolutionarily a bad move to eat your own young unless you absolutely have to.\"\nScientists think that Orthacanthus sharks hunted in a range of shallow waters toward the end of the Carboniferous Period, so long ago that Europe and North America lay on the equator. Back then, the species was equally at home in the ocean and the swamps of the steamy jungle environments, called 'Coal Forests' \u2013 as the remnants have now become compacted into coal seams over millennia.\"Orthacanthus was probably a bit like the modern day bull shark, in that it was able to migrate backwards and forwards between coastal swamps and shallow seas,\" said \u00d3 Gog\u00e1in in a press release. \"This unusual ecological adaptation may have played an important role in the colonisation of inland freshwater environments.\"The findings are reported in Palaeontolog",
        "abstract": "Euryhaline adaptations in Pennsylvanian vertebrates allowed them to inhabit the marine to freshwater spectrum. This is illustrated by new assemblages of fish and tetrapods from the early Moscovian Minto Formation of New Brunswick  Canada. Fish include chondrichthyans (xenacanthids and the enigmatic Ageleodus)  acanthodians (gyracanthids and acanthodiforms)  sarcopterygians (rhizodontids  megalichthyids and dipnoans)  and actinopterygians (eurynotiforms). Tetrapods include small- to medium-sized  and largely aquatic  stem tetrapods (colosteids) and anthracosaurs (embolomeres). A key finding is that the parautochthonous fossil assemblages are preserved across a salinity gradient  with diversity (measured by the Simpson Index) declining from open marine environments  through brackish embayments  and reaching a nadir in tidal estuaries. Chondrichthyans dominate the entire salinity spectrum (65% of fossils)  a distribution that demonstrates a euryhaline mode of life  and one large predatory chondrichthyan  Orthacanthus  may have practised filial cannibalism in coastal nurseries because its heteropolar coprolites contain juvenile xenacanthid teeth. In contrast  other fish communities were more common in open marine settings while tetrapods were more common in coastal brackish waters. While all these faunas were also likely to have been euryhaline  their osmoregulation was  perhaps  less versatile. The demonstration of widespread euryhalinity among fish and aquatic tetrapods explains why Pennsylvanian faunas generally show a cosmopolitan biogeography because taxa were able to disperse via seaways. It also resolves the paradox of enriched strontium isotopic signatures observed in these faunas because organisms would have been  at times  exposed to continental water bodies as well. Therefore  our new findings contribute to the long-running debate about the ecology of Pennsylvanian fishes and tetrapods.",
        "generated_article": "Title: Euryhaline Adaptations in Pennsylvanian Vertebrates Unveiled in New Brunswick Fossil Discoveries\n\nA recent study conducted in New Brunswick, Canada, has shed light on the remarkable euryhaline adaptations of Pennsylvanian vertebrates, allowing them to thrive across a wide range of salinity levels from marine to freshwater environments. The findings, published in a scientific journal, reveal new insights into the diverse assemblages of fish and tetrapods that inhabited the early Moscovian Minto Formation.\n\nThe research team uncovered a variety of fossilized remains, including chondrichthyans such as xenacanthids and the enigmatic Ageleodus, acanthodians like gyracanthids and acanthodiforms, sarcopterygians including rhizodontids, megalichthyids, and dipnoans, as well as actinopterygians like eurynotiforms. Among the tetrapods discovered were small- to medium-sized stem tetrapods known as colosteids and anthracosaurs like embolomeres.\n\nOne of the key findings of the study was the presence of parautochthonous fossil assemblages preserved across a gradient of salinity, with diversity decreasing from open marine environments to brackish embayments and reaching a low point in tidal estuaries. Chondrichthyans were found to dominate the entire salinity spectrum, constituting 65% of the fossils, indicating a euryhaline lifestyle. Notably, the discovery of heteropolar coprolites containing juvenile xenacanthid teeth suggests that the large predatory chondrichthyan Orthacanthus may have practiced filial cannibalism in coastal nurseries.\n\nWhile chondrichthyans thrived across various salinity levels, other fish communities were more prevalent in open marine settings, and tetrapods were commonly found in coastal brackish waters. Although all these faunas likely exhibited euryhaline characteristics, their osmoregulation may have been less versatile compared to chondrichthyans.\n\nThe study's findings provide valuable insights into the euryhalinity of Pennsylvanian vertebrates, explaining their cosmopolitan biogeography and resolving the mystery of enriched strontium isotopic signatures observed in these faunas. The ability of these organisms to disperse via seaways and occasionally interact with continental water bodies likely contributed to their widespread distribution.\n\nOverall, the research contributes significantly to the ongoing debate surrounding the ecology of Pennsylvanian fishes and tetrapods, highlighting the remarkable adaptations that allowed these ancient vertebrates to thrive in diverse aquatic environments millions of years ago."
    },
    {
        "id": "8409-0",
        "category": "humans",
        "annotation": "New research into Neolithic stone circles on the Scottish islands of Orkney has revealed they were the party hotspots of the end of the Stone Age \u2013 places where people met to find partners, celebrate the summer and winter solstices, and pay tribute to the dead.\nThe study has also revealed how the area was a melting pot of different social groups and communities, a mix that eventually caused enough political tension for the groups to go their separate ways.Part of a broader investigation into Neolithic living called The Times of their Lives, led by Historic England, the new analysis examines more than 600 radiocarbon dates, giving researchers a clearer view of the timing and duration of events between 3200 BC and 2500 BC on the islands.\"This study shows that new statistical analysis of the large numbers of radiocarbon dates that are now available in British archaeology really changes what we can know about our pasts,\" lead researcher Alex Bayliss, from Historic England, told the BBC.\"People in the Neolithic made choices, just like us, about all sorts of things \u2013 where to live, how to bury their dead, how to farm, where and when to gather together \u2013 and those choices are just beginning to come into view through archaeology.\"The Standing Stones of Stenness. Credit: stevekeiretsu/FlickrA number of well-known sites were covered by the study, including the Standing Stones of Stenness circles, granted UNESCO World Heritage Status in 1999, and the Skara Brae settlement.\nThe research also looked at the Maeshowe passage grave, and the 104-metre (341-foot) diameter Ring of Brodgar, originally thought to feature up to 60 stones, of which 27 are still standing.The researchers have now managed to figure out that Orkney was probably first colonised in 3600 BC, with settlement peaking around 3100-2900 BC.And even after communities had settled elsewhere, they still returned to these sites for celebrations, Bayliss told Loulla-Mae Eleftheriou-Smith at The Independent.\"It's not a village \u2013 it's a gathering place,\" says Bayliss. \"Each stone in the Ring of Brodgar is from a different stone or area of the island, so it's almost like each village brought its own stone there.\"The relatively rapid changes in the stone monuments identified by the researchers seem to show a conflict of ideas about certain rituals, including how to bury the dead.\nThese tribes would appear to have been able to put aside their differences for the occasional bit of revelry though, at least for a while, and people might have settled here from as far away as Belgium.That's hinted at by the Orkney voles that don't live in Britain and can't have lived through the last ice age \u2013 it's possible that they were brought over from Belgium before 3000 BC.Whether or not it was the Orkney nightlife that tempted them over remains to be seen.\"Visitors come from all over the world to admire the wonderfully preserved archaeological remains of Orkney, in what may seem a timeless setting,\" senior researcher Alasdair Whittle, from Cardiff University in the UK, told the BBC.\"Our study underlines that the Neolithic past was often rapidly changing, and that what may appear to us to be enduring monuments were in fact part of a dynamic historical context.\"The research has been published in Antiquit",
        "abstract": "Oceanic islands have been a test ground for evolutionary theory  but here  we focus on the possibilities for evolutionary study created by offshore islands. These can be colonized through various means and by a wide range of species  including those with low dispersal capabilities. We use morphology  modern and ancient sequences of cytochrome b (cytb) and microsatellite genotypes to examine colonization history and evolutionary change associated with occupation of the Orkney archipelago by the common vole (Microtus arvalis)  a species found in continental Europe but not in Britain. Among possible colonization scenarios  our results are most consistent with human introduction at least 5100 bp (confirmed by radiocarbon dating). We used approximate Bayesian computation of population history to infer the coast of Belgium as the possible source and estimated the evolutionary timescale using a Bayesian coalescent approach. We showed substantial morphological divergence of the island populations  including a size increase presumably driven by selection and reduced microsatellite variation likely reflecting founder events and genetic drift. More surprisingly  our results suggest that a recent and widespread cytb replacement event in the continental source area purged cytb variation there  whereas the ancestral diversity is largely retained in the colonized islands as a genetic \u2018ark\u2019. The replacement event in the continental M. arvalis was probably triggered by anthropogenic causes (land-use change). Our studies illustrate that small offshore islands can act as field laboratories for studying various evolutionary processes over relatively short timescales  informing about the mainland source area as well as the island.",
        "generated_article": "Title: Offshore Islands as Evolutionary Laboratories: A Case Study of Common Voles Colonizing the Orkney Archipelago\n\nIn a groundbreaking study published in the journal of Evolutionary Biology, researchers have shed light on the evolutionary dynamics of common voles (Microtus arvalis) colonizing the Orkney archipelago, providing valuable insights into the role of offshore islands as unique environments for studying evolutionary processes.\n\nOceanic islands have long been recognized as natural laboratories for testing evolutionary theories due to their isolated and dynamic nature. However, the focus of this study was shifted towards offshore islands, which present distinct opportunities for evolutionary research. These islands can be colonized by a diverse array of species through various means, even those with limited dispersal capabilities.\n\nThe research team utilized a multidisciplinary approach, combining morphological analysis with modern and ancient sequences of cytochrome b (cytb) and microsatellite genotypes to investigate the colonization history and evolutionary changes associated with the presence of common voles in the Orkney archipelago. Despite being native to continental Europe, common voles are absent in Britain, making their presence in the Orkney archipelago a subject of intrigue.\n\nThrough a series of analyses, the researchers uncovered compelling evidence suggesting that human introduction played a pivotal role in the colonization of the Orkney archipelago by common voles at least 5100 years ago, a finding supported by radiocarbon dating. The study pinpointed the coast of Belgium as the likely source of the colonizing population and estimated the evolutionary timescale using a Bayesian coalescent approach.\n\nOne of the most striking discoveries of the study was the substantial morphological divergence observed in the island populations of common voles, characterized by a size increase believed to be driven by selection pressures. Additionally, reduced microsatellite variation in the island populations indicated founder events and genetic drift as influential factors shaping their genetic diversity.\n\nPerhaps the most intriguing revelation from the study was the identification of a recent and widespread cytb replacement event in the continental source area, which led to a loss of cytb variation. In contrast, the colonized islands retained ancestral cytb diversity, acting as a genetic 'ark' preserving genetic variation. The replacement event in the continental common vole population was attributed to anthropogenic causes, specifically land-use changes.\n\nOverall, this study underscores the significance of small offshore islands as invaluable field laboratories for studying evolutionary processes over relatively short timescales. By unraveling the evolutionary history of common voles in the Orkney archipelago, the research not only provides insights into the dynamics of island colonization but also sheds light on the evolutionary processes occurring in the mainland source area. The findings highlight the intricate interplay between natural and anthropogenic factors in shaping genetic diversity and evolutionary trajectories in island populations."
    },
    {
        "id": "7568-0",
        "category": "environment",
        "annotation": "Back in February, physicists announced an outlandish plan to 're-freeze' the Arctic, by installing 10 million wind-powered pumps over the ice cap to replenish the dwindling sea ice.\nThe idea was so wild, no one actually thought it would happen, but researchers in Switzerland have just launched a trial that will see if they can sustain an entire glacier through summer using nothing but snow machines.If the team manages to successfully preserve a small, artificial glacier at the foot of the Diavolezzafirn glacier in the south-eastern part of Switzerland through the year's hottest months, it's hoped that they can apply the technique to the country's natural giant - the\u00a0Morteratsch glacier.One of the most massive glaciers in the eastern alps, this vast valley glacier has been retreating fast thanks to rising temperatures, and is currently losing 30 to 40 metres every year.It could be that the only hope for Switzerland's Morteratsch glacier is thousands of snow machines blasting it with artificial sleet.\nIf all of this sounds a little far-fetched to you, scientists have actually done the maths,\u00a0and it is technically feasible to use machines to rebuild glaciers and replenish vanishing sea ice.Earlier this year, a team led by Arizona State University physicist, Steven Desch, put out a report describing how millions of wind-powered pumps could blast 1.3 metres of water on the surface of the Arctic, adding 1 extra metre (3.2 feet) of sea ice.\u00a0While an extra metre doesn't sound like all that much, they calculated that it would be like pushing time back by 17 years.The only problem? How mind-bogglingly vast the Arctic region actually is.\u00a0The team calculated that covering just 10 percent of the Arctic would involve erecting millions of pumps, which together would have to spray 7.5 kg per of water (16.5 pounds) every second to achieve 1 extra metre in a year.\n\"The area of the Arctic Ocean is about 107\u00a0km2 [3.8 million miles2],\" the report stated.\"If the wind-powered pumps are to be distributed across 10 percent of that area, this would necessitate about 10 million wind-powered pumps; if distributed across the entire Arctic, about 100 million would be needed.\"In order to build a fleet of 100 million pumps to save the entire Arctic, you'd need more steel than the US produces in a entire year.All that considered, there was no way in hell the plan was ever going to be funded, but the much smaller version proposed for Switzerland could actually have some legs.Glacier expert Johannes Oerlemans of Utrecht University in the Netherlands calculated that around 4,000 snow machines could help the Morteratsch glacier not only stop retreating, but actually grow in the coming decades.\nThe basic idea is that the ice on the glacier is now being exposed to sunlight, but if they could cover the ice in thick, artificial snow, it could reflect the light away before it ever gets to the vulnerable ice layers below.Oerlemans presented his plan at the recent annual meeting of the European Geosciences Union in Vienna, Austria.\"Looking at previous work showing that natural snow can help glaciers grow, he concluded that the glacier could regain up to 800 metres of length within 20 years if it had a covering,\" Andy Coghlan reports for New Scientist.\"He worked out that just a few centimetres of artificial snow blown onto a 0.5-square-kilometre plateau high up the glacier each summer could be enough to protect the ice beneath.\"Of course, the plan isn't as colossal as the Arctic one, but it's still huge, and would require a lot of funding, but Oerlemans and his team are quietly confiden",
        "abstract": "As the Earth's climate has changed  Arctic sea ice extent has decreased drastically. It is likely that the late-summer Arctic will be ice-free as soon as the 2030s. This loss of sea ice represents one of the most severe positive feedbacks in the climate system  as sunlight that would otherwise be reflected by sea ice is absorbed by open ocean. It is unlikely that CO2 levels and mean temperatures can be decreased in time to prevent this loss  so restoring sea ice artificially is an imperative. Here we investigate a means for enhancing Arctic sea ice production by using wind power during the Arctic winter to pump water to the surface  where it will freeze more rapidly. We show that where appropriate devices are employed  it is possible to increase ice thickness above natural levels  by about 1 m over the course of the winter. We examine the effects this has in the Arctic climate  concluding that deployment over 10% of the Arctic  especially where ice survival is marginal  could more than reverse current trends of ice loss in the Arctic  using existing industrial capacity. We propose that winter ice thickening by wind-powered pumps be considered and assessed as part of a multipronged strategy for restoring sea ice and arresting the strongest feedbacks in the climate system.",
        "generated_article": "Title: Innovative Wind-Powered Solution Could Reverse Arctic Sea Ice Loss\n\nIn a groundbreaking study published in a leading scientific journal, researchers have proposed a novel approach to combat the alarming decline in Arctic sea ice extent. The study highlights the urgent need for action as the Earth's climate continues to change, with the Arctic region facing the prospect of being ice-free by the 2030s.\n\nThe research team, led by experts in climate science and engineering, suggests that harnessing wind power during the Arctic winter could be the key to enhancing sea ice production. By using wind-powered pumps to bring water to the surface where it can freeze more rapidly, it is possible to increase ice thickness above natural levels by approximately 1 meter over the course of the winter.\n\nThe loss of Arctic sea ice is identified as a critical positive feedback loop in the climate system, with open ocean absorbing sunlight that would otherwise be reflected by ice. The study warns that without immediate intervention, it is unlikely that carbon dioxide levels and mean temperatures can be reduced in time to prevent further ice loss.\n\nThe proposed solution offers a ray of hope in the fight against climate change. By deploying wind-powered pumps over at least 10% of the Arctic, particularly in areas where ice survival is at risk, researchers believe that current trends of ice loss could be reversed. This ambitious plan could leverage existing industrial capacity to restore sea ice and mitigate the most severe feedbacks in the climate system.\n\nThe implications of this innovative approach extend beyond just increasing Arctic sea ice thickness. The study suggests that by restoring sea ice through winter ice thickening, it is possible to stabilize the Arctic climate and prevent further environmental degradation.\n\nAs the global community grapples with the urgent need to address climate change, the research findings offer a glimmer of hope for the future of the Arctic region. The proposed wind-powered solution presents a tangible and feasible strategy for restoring sea ice and combating the devastating impacts of climate change.\n\nWhile further research and assessment are needed to fully evaluate the effectiveness and feasibility of this approach, the study underscores the importance of considering innovative solutions in the fight against climate change. With concerted efforts and bold initiatives, it may be possible to reverse the alarming trend of Arctic sea ice loss and safeguard the fragile balance of our planet's climate system."
    },
    {
        "id": "3801-0",
        "category": "nature",
        "annotation": "Until very recently, one of the biggest myths in science was that all dinosaurs have been extinct for the past 65 million years. But thanks to new fossil discoveries that filled in our knowledge about avian dinosaurs, we now know that only some dinosaurs went extinct following an asteroid collision with Earth - others survived and gave rise to the birds we live with today.\nTo figure out how this evolution occurred, researchers in Chile have manipulated the genes of regular chickens so they develop tubular, dinosaur-like fibulas on their lower legs - one of the two long, spine-like bones you'll find in a drumstick.In avian dinosaurs such as the Archaeopteryx, the fibula was a tube-shaped bone that reached all the way down to the ankle. Another bone, the tibia, grew to a similar length alongside it.As evolution progressed through to a group of avian dinosaurs known as the\u00a0Pygostylians,\u00a0the fibula became shorter than the tibia, and sharper and more splinter-like towards the end, and it no longer reached the ankle.While modern bird embryos still show signs of developing long, dinosaur-like fibulae, as they grow, these bones become shorter, thinner, and also take on the splinter-like ends of the Pygostylian bones, and never make it far enough down to the leg to connect with the ankle.\nResearchers led by Jo\u00e2o Botelho from the University of Chile decided to investigate how this transition from a long, tubular fibula in dinosaurs to a short, splinter-like fibula in birds actually came to be.They achieved this by inhibiting the expression of a gene called IHH or Indian Hedgehog (seriously), which saw their chickens continue to grow the long, dinosaur-like fibulae that originated in their embryonic form.\u00a0In doing so, the team discovered something bizarre. Regular bone development sees cell division and therefore growth halt in the shaft long before the ends stop growing, but in modern chickens, the growth of the fibula halts first at the ends. This means the fibulae of modern chickens are actively blocked from reaching the lengths of their ancient relatives' bones.Jo\u00e2o Botelho et. al.Publishing their observations in the journal Evolution, the researchers suggest that the early maturation of the lower end of the fibula in modern chickens is prompted by a bone in the ankle, called the calcaneum.\n\"Unlike other animals, the calcaneum in bird embryos presses against the lower end of the fibula,\" the team explains in a press release. \"They are so close, they have even been mistaken for a single element by some researchers.\"The team suggests that in regular chickens, interactions between the calcaneum and the end of the fibula result in signals that are similar to the ones that prompt the bone shaft to stop growing, preventing the fibula from reaching anywhere near the ankle bone.\u00a0But when the Indian Hedgehog gene was turned off, the calcaneum strongly expresses the gene Parathyroid-related protein (PthrP), which allows for growth at the ends of bones. This caused their chickens to grow long fibulae that connected with the ankle, just like they would in the\u00a0Archaeopteryx.\u00a0\"Experimental downregulation of IHH signalling at a postmorphogenetic stage led to a tibia and fibula of equal length,\" the team writes in the report. \"The fibula is longer than in controls and fused to the fibulare, whereas the tibia is shorter and bent.",
        "abstract": "Birds have a distally reduced  splinter-like fibula that is shorter than the tibia. In embryonic development  both skeletal elements start out with similar lengths. We examined molecular markers of cartilage differentiation in chicken embryos. We found that the distal end of the fibula expresses Indian hedgehog (IHH)  undergoing terminal cartilage differentiation  and almost no Parathyroid-related protein (PTHrP)  which is required to develop a proliferative growth plate (epiphysis). Reduction of the distal fibula may be influenced earlier by its close contact with the nearby fibulare  which strongly expresses PTHrP. The epiphysis-like fibulare however then separates from the fibula  which fails to maintain a distal growth plate  and fibular reduction ensues. Experimental downregulation of IHH signaling at a postmorphogenetic stage led to a tibia and fibula of equal length: The fibula is longer than in controls and fused to the fibulare  whereas the tibia is shorter and bent. We propose that the presence of a distal fibular epiphysis may constrain greater growth in the tibia. Accordingly  many Mesozoic birds show a fibula that has lost its distal epiphysis  but remains almost as long as the tibia  suggesting that loss of the fibulare preceded and allowed subsequent evolution of great fibulo\u2013tibial disparity.",
        "generated_article": "Title: Study Reveals Evolutionary Mechanism Behind Bird Leg Bone Length Disparity\n\nA recent study conducted on chicken embryos has shed light on the evolutionary process that has led to the distinct leg bone structure seen in modern birds. The research, published in a scientific journal, delves into the development of the fibula and tibia bones in avian embryos and how molecular markers play a crucial role in determining their final lengths.\n\nBirds are known for having a unique skeletal structure in their legs, with the fibula bone being significantly shorter than the tibia. The study found that during embryonic development, both the fibula and tibia start out with similar lengths. However, as the development progresses, the distal end of the fibula undergoes terminal cartilage differentiation, expressing Indian hedgehog (IHH) and minimal Parathyroid-related protein (PTHrP).\n\nThe researchers discovered that the close contact between the fibula and the nearby fibulare bone influences the reduction of the distal fibula. The fibulare strongly expresses PTHrP, which is essential for the development of a proliferative growth plate (epiphysis). As the fibulare separates from the fibula, the latter fails to maintain a distal growth plate, leading to the reduction in length.\n\nIn an experimental setting, the downregulation of IHH signaling postmorphogenetic stage resulted in the fibula growing longer than in the control group and fusing with the fibulare. On the other hand, the tibia became shorter and bent, suggesting that the presence of a distal fibular epiphysis may limit the growth of the tibia.\n\nThe study also proposes that the loss of the fibulare in many Mesozoic birds preceded the evolution of significant fibulo-tibial length disparity. These ancient birds exhibited a fibula that had lost its distal epiphysis but remained almost as long as the tibia, indicating that the absence of the fibulare allowed for the subsequent evolution of the distinct leg bone structure seen in modern birds.\n\nThis research provides valuable insights into the evolutionary mechanisms that have shaped the skeletal structure of birds over millions of years. By unraveling the molecular processes involved in the development of leg bones, scientists can better understand the adaptations that have enabled birds to thrive in diverse environments."
    },
    {
        "id": "5336-0",
        "category": "space",
        "annotation": "Jupiter's frozen moon Io is a pretty bleak place, with a toxic atmosphere and the most active volcanoes of any known body in the Solar System.But it's somehow managed to get\u00a0even more miserable, because scientists just watched its atmosphere collapse - something that apparently happens every single day as Jupiter eclipses it.\nAstronomers have long suspected that Io's already thin atmosphere deflates as the shadow of the gas giant passes over it daily, but no one had ever been able to see this happening until now.\"This research is the first time scientists have observed this remarkable phenomenon directly, improving our understanding of this geologically active moon,\" said lead researcher Constantine Tsang from the Southwest Research Institute in Colorado.The study shows that for 2 hours every day, Jupiter eclipses the moon with its giant shadow, causing the temperature to plummet and Io's sulphur dioxide-rich atmosphere to freeze and collapse to the surface.When the planet moves out of Jupiter's shadow, the Sun gradually heats Io's surface temperature up from about \u2013270 degrees Fahrenheit (\u2013168 degrees Celsius)\u00a0to \u2013235 degrees Fahrenheit (\u2013148 degrees Celsius), and the sulphur dioxide returns to the atmosphere as gas.\nBut then the whole cycle repeats again the next day, and seeing as a day on Io lasts around 1.7 Earth days, the atmosphere is deflating and reflating all the time.\"This confirms that Io's atmosphere is in a constant state of collapse and repair, and shows that a large fraction of the atmosphere is supported by sublimation of SO2\u00a0[sulphur dioxide]\u00a0ice,\" said one of the team, John Spencer. \"We've long suspected this, but can finally watch it happen.\"The team was able to figure this out using the Gemini North telescope in Hawaii, in addition to a long-range spectrograph, which was capable of monitoring the composition of the moon's atmosphere.Using this combination to measure the electromagnetic signatures coming off Io in real-time, the team could show that the sulphur dioxide content drops off daily during Jupiter's eclipse.\nThe findings have been published in the Journal of Geophysical Research.Perhaps the most exciting part of all is that\u00a0most of Jupiter's 67 known moons - and the punishment the gas giant unleashes on them - remain a mystery to us.But now that we have our own probe, Juno, in orbit around the planet, we'll hopefully get some more insight into the strange behaviour occurring in the neighbourhood.It's still early days for the mission, but we've already heard creepy AF sounds coming from around Jupiter, and have been sent this visible-light photo of the gas giant with Io, Europa, and Ganymede:NASAWe can't wait for more strangeness. Stay tune",
        "abstract": "Volcanic outgassing due to tidal heating is the ultimate source of a tenuous SO2 atmosphere around Jupiter's moon Io. The question of whether SO2 frost on the surface plays a part  and to what degree  in maintaining Io's atmosphere with the constant volcanic outgassing is still debated. It is believed that for a sublimation-supported atmosphere  the primary atmosphere should collapse during eclipses by Jupiter  as the SO2 vapor pressure is strongly coupled to the temperature of the ice on the surface. No direct observations of Io's atmosphere in eclipse have previously been possible  due to the simultaneous need for high spectral and time sensitivity  as well as a high signal-to-noise ratio. Here we present the first ever high-resolution spectra at 19\u00b5m of Io's SO2 atmosphere in Jupiter eclipse from the Gemini telescope. The strongest atmospheric band depth is seen to dramatically decay from 2.5\u00b1(0.08)% before the eclipse to 0.18\u00b1(0.16)% after 40min in eclipse. Further modeling indicates that the atmosphere has collapsed shortly after eclipse ingress  implying that the atmosphere of Io has a strong sublimation-controlled component. The atmospheric column density\u2014from pre-eclipse to in-eclipse\u2014drops by a factor of 5\u00b12.",
        "generated_article": "Title: New Study Reveals Io's Atmosphere Collapses During Jupiter's Eclipse\n\nA recent study conducted by a team of researchers has shed light on the dynamics of Io's atmosphere, the most volcanically active moon in our solar system. Io, one of Jupiter's moons, is known for its intense volcanic activity, which results in the release of sulfur dioxide (SO2) into its atmosphere. The study, published in a leading scientific journal, provides new insights into the role of SO2 frost on Io's surface in maintaining its tenuous atmosphere.\n\nThe researchers aimed to investigate whether the SO2 frost on Io's surface contributes to sustaining its atmosphere alongside the constant volcanic outgassing. The team utilized high-resolution spectra at 19\u00b5m obtained from the Gemini telescope to observe Io's atmosphere during Jupiter's eclipse. This allowed them to capture the changes in the atmosphere's composition and density as the moon passed through the shadow of Jupiter.\n\nThe findings revealed a significant decrease in the strength of Io's atmospheric band depth during the eclipse. Prior to the eclipse, the atmospheric band depth was measured at 2.5\u00b1(0.08)%, which dramatically dropped to 0.18\u00b1(0.16)% after 40 minutes in eclipse. This observation suggests that Io's atmosphere undergoes a collapse shortly after the eclipse begins, indicating a strong sublimation-controlled component in maintaining the atmosphere.\n\nFurthermore, the researchers noted a substantial drop in the atmospheric column density of Io during the eclipse, decreasing by a factor of 5\u00b12 from pre-eclipse to in-eclipse conditions. This decline in atmospheric density provides further evidence of the influence of sublimation processes on Io's atmosphere, highlighting the delicate balance between volcanic outgassing and surface frost in sustaining the moon's tenuous SO2 atmosphere.\n\nThe study's lead author expressed excitement about the findings, stating that the observations provide valuable insights into the complex interplay between volcanic activity, surface processes, and atmospheric dynamics on Io. The team hopes that these results will contribute to a better understanding of the mechanisms driving Io's unique atmospheric behavior and aid future studies of volcanic worlds in our solar system and beyond.\n\nOverall, this groundbreaking research offers a new perspective on the maintenance of Io's atmosphere and highlights the importance of studying planetary bodies with extreme geological activity to unravel the mysteries of our solar system."
    },
    {
        "id": "9088-0",
        "category": "environment",
        "annotation": "Proceedings of the National Academy of Sciences Volcanic eruptions inevitably call to mind the mental image of an incredibly hot, molten pool of magma, bursting forth from the ground in an orgy of fiery destruction.But you might be surprised to know that before the fireworks take place, that super-hot mass of molten rock isn't necessarily super-hot or molten at all \u2013 and could instead be trapped in a solidified form of 'cold storage', new research suggests.\n\"The older view is that there's a long period with a big tank of molten rock in the crust,\" says geoscientist Nathan Andersen from the University of Wisconsin-Madison.\"A new view is that magma is stored for a long period in a state that is locked, cool, crystalline, and unable to produce an eruption. That dormant system would need a huge infusion of heat to erupt.\"Such a huge infusion of heat is what's thought to have unleashed a violent supereruption in California some 765,000 years ago.This event, which produced the Long Valley Caldera in the east of the state, would have been beyond anything modern humans have seen in terms of volcanic eruptions, casting a layer of debris from the Pacific Ocean to Nebraska.\"It would have completely wiped out everything within 50 kilometres of the caldera,\" one of the researchers, geologist Brad Singer, told The New York Times.\n\"All the vegetation and biota in that area would have been extinguished.\"But as awesomely destructive as the supereruption was, lingering evidence from the aftermath can tell us about the magma conditions deep underground before the top blew so spectacularly.Specifically, an analysis of argon isotopes contained in crystals from the Bishop Tuff \u2013 the large rocky outcrop produced when the Long Valley Caldera was created \u2013 shows the magma from the supereruption was heated rapidly, not slowly simmered.Geologically speaking, that is \u2013 meaning the heating forces that produced the supereruption occurred over decades, or perhaps a couple of centuries. (A long time for people, sure, but a blink of an eye in the life-time of a supervolcano.)The reasoning is that argon quickly escapes from hot crystals, so it wouldn't have a chance to accumulate in the rock if the rock were super-heated for a long time.\nUsing a high-precision mass spectrometer, the team found argon isotopes spanning a 16,000-year range from the Bishop Tuff, which suggests argon remained from long before the supereruption took place, meaning the magma would have been cooler for longer, before heating suddenly.\"It must have cooled to the point that it was completely solid,\" Andersen explained to Newsweek.\"It had to be really a rock, at something more like 400 degrees [Celsius, 750 degrees Fahrenheit].\"Then, changing thermal conditions would have relatively quickly 'thawed' the rock preserved in cold storage, taking the magma to the necessary 700\u2013850 degree Celsius threshold required for an eruption, estimated to have produced something like 650 cubic kilometres of lava and ash.Unfortunately, while scientists are doing everything they can to read the signs of volcanic supereruptions \u2013 something NASA views as more dangerous than asteroid strikes \u2013 the reality is, the new findings don't bring us any closer to seeing the future.\"This does not point to prediction in any concrete way,\" Singer explains in a press statement, \"but it does point to the fact that we don't understand what is going on in these systems, in the period of 10 to 1,000 years that precedes a large eruption.\"The findings are reported in the Proceedings of the National Academy of Science",
        "abstract": "Recent improvements in analytical and microsampling techniques for multiple geochronometers have resulted in datasets with unprecedented temporal and spatial resolution. These advances are accompanied by the discovery of crystal- and outcrop-scale complexities previously obscured by low analytical precision. Single-crystal incremental heating resolves subtle  intracrystal isotopic heterogeneity  allowing for more-accurate 40Ar/39Ar eruption ages. The eruption ages of widespread volcanic ash deposits are critical for calibrating the geologic timescale  and thus their accuracy has substantial implications for the geologic  biologic  and global climate records. Complex distribution of 40Ar/39Ar dates in the deposits of supervolcanic eruptions requires rethinking the magmatic processes and their effect on the 40Ar/39Ar system  specifically the extent of cooling and remobilization during the decades to centuries preceding these events. Abstract Accurate and precise ages of large silicic eruptions are critical to calibrating the geologic timescale and gauging the tempo of changes in climate  biologic evolution  and magmatic processes throughout Earth history. The conventional approach to dating these eruptive products using the 40Ar/39Ar method is to fuse dozens of individual feldspar crystals. However  dispersion of fusion dates is common and interpretation is complicated by increasingly precise data obtained via multicollector mass spectrometry. Incremental heating of 49 individual Bishop Tuff (BT) sanidine crystals produces 40Ar/39Ar dates with reduced dispersion  yet we find a 16-ky range of plateau dates that is not attributable to excess Ar. We interpret this dispersion to reflect cooling of the magma reservoir margins below \u223c475 \u00b0C  accumulation of radiogenic Ar  and rapid preeruption remobilization. Accordingly  these data elucidate the recycling of subsolidus material into voluminous rhyolite magma reservoirs and the effect of preeruptive magmatic processes on the 40Ar/39Ar system. The youngest sanidine dates  likely the most representative of the BT eruption age  yield a weighted mean of 764.8 \u00b1 0.3/0.6 ka (2\u03c3 analytical/full uncertainty) indicating eruption only \u223c7 ky following the Matuyama\u2212Brunhes magnetic polarity reversal. Single-crystal incremental heating provides leverage with which to interpret complex populations of 40Ar/39Ar sanidine and U-Pb zircon dates and a substantially improved capability to resolve the timing and causal relationship of events in the geologic record.",
        "generated_article": "Title: New Analytical Techniques Shed Light on the Timing of Large Silicic Eruptions\n\nRecent advancements in analytical and microsampling techniques have revolutionized the field of geochronology, providing researchers with unprecedented temporal and spatial resolution in dating volcanic eruptions. A study published in a leading scientific journal has highlighted the significance of these improvements in accurately determining the eruption ages of large silicic volcanic events and their implications for understanding Earth's history.\n\nThe conventional method of dating eruptive products, such as the 40Ar/39Ar method, involves fusing multiple feldspar crystals to obtain age estimates. However, this approach often results in a dispersion of dates, complicating the interpretation of eruption ages. The study focused on the Bishop Tuff (BT) eruption, a widespread volcanic ash deposit, and employed a new technique called single-crystal incremental heating to analyze 49 individual sanidine crystals.\n\nThe results of the study revealed a complex distribution of 40Ar/39Ar dates within the BT eruption, indicating a range of plateau dates that could not be explained by excess argon. The dispersion of dates was attributed to the cooling of the magma reservoir margins, accumulation of radiogenic argon, and rapid preeruption remobilization processes. By analyzing the youngest sanidine dates, researchers were able to determine a weighted mean eruption age of 764.8 \u00b1 0.3/0.6 thousand years ago, suggesting that the BT eruption occurred shortly after a significant magnetic polarity reversal.\n\nThe findings from this study have significant implications for calibrating the geologic timescale and understanding the interplay between magmatic processes, climate changes, and biological evolution throughout Earth's history. The ability to resolve complex populations of 40Ar/39Ar and U-Pb zircon dates using single-crystal incremental heating represents a major advancement in geochronology, providing researchers with a more accurate and precise tool to unravel the timing and causal relationships of events recorded in the geologic record.\n\nOverall, the study underscores the importance of incorporating new analytical techniques in geochronology to enhance our understanding of past volcanic eruptions and their impact on Earth's geological and environmental processes. By refining the dating of large silicic eruptions, scientists can gain valuable insights into the dynamics of Earth's history and the factors influencing global climate, biological evolution, and magmatic activity."
    },
    {
        "id": "8039-0",
        "category": "health",
        "annotation": "A review of the research on combining therapy with the psychoactive component from magic mushrooms has concluded it's not only a safe and effective way to treat conditions related to anxiety, depression, and addiction, it could be better than many existing forms of treatment.\nThe findings reinforce the need to explore the full impact of the psychedelic compound called psilocybin, a drug that is showing increasing promise in its ability dramatically improve the lives of those who suffer debilitating psychiatric disorders.Psychedelics such as lysergic acid diethylamide ( LSD) and psilocybin have a reputation more as a party drug than as forms of therapeutic medication.But their similarity to neurotransmitters such as serotonin and their ability to affect our perception and mess with our state of consciousness has made them attractive candidates for treating various psychiatric conditions.Studies have found patients with severe depression have improved after taking small amounts of psilocybin alongside supportive therapy sessions, with evidence that their brains have strengthened links across previously disconnected regions.\nThese kinds of results demand attention, demonstrating great potential for using serotonin agonists such as psilocybin to block problematic networks in the brain while therapy can be used to create more functional ones.A review by researchers in California has shown such studies aren't outliers, prompting a need to step forward with testing.Their analysis of seven clinical trials conducted over the past decade testing the effects of psilocybin-assisted therapy on anxiety, depressive disorders, addiction, and obsessive-compulsive disorder has shown the drug.\"Psilocybin-assisted therapy has been shown to be safe in several studies across a variety of patient populations,\" researcher Kelan Thomas of Touro University California explained to Eric W. Dolan of PsyPost.Compared with other forms of treatment on validated psychiatric rating scales, therapy with psilocybin has resulted in a larger effect, suggesting it could be a better option for many patients, especially those who have failed to respond to other medications or procedures.\n\"One important distinction from these other session-based treatments would be that the benefits of psilocybin-assisted therapy may only require a few dosing sessions and the effects appear to persist longer than other treatment options,\" the researchers write in their report.This isn't to say the drug can be beneficial independently as a form of medication \u2013 research on the therapeutic impact of psychoactive drugs is pretty thin on the ground due to ethical constraints, but that also means there's no strong evidence supporting use of psilocybin without the support of therapy sessions.It is a good reason to now conduct larger trials with more powerful statistical tools to aim for getting the US Food and Drug Administration's big tick of approval.\"The clinical trials summarised were Phase 2 studies investigating safety and efficacy endpoints, but some of the studies were open-label and lacked statistical analysis,\" says Thomas",
        "abstract": "Recent research suggests that functional connectivity changes may be involved in the pathophysiology of psychiatric disorders. Hyperconnectivity in the default mode network has been associated with psychopathology  but psychedelic serotonin agonists like psilocybin may profoundly disrupt these dysfunctional neural network circuits and provide a novel treatment for psychiatric disorders. We have reviewed the current literature to investigate the efficacy and safety of psilocybin-assisted therapy for the treatment of psychiatric disorders. There were seven clinical trials that investigated psilocybin-assisted therapy as a treatment for psychiatric disorders related to anxiety  depression  and substance use. All trials demonstrated reductions in psychiatric rating scale scores or increased response and remission rates. There were large effect sizes related to improved depression and anxiety symptoms. Psilocybin may also potentially reduce alcohol or tobacco use and increase abstinence rates in addiction  but the benefits of these two trials were less clear due to open-label study designs without statistical analysis. Psilocybin-assisted therapy efficacy and safety appear promising  but more robust clinical trials will be required to support FDA approval and identify the potential role in clinical psychiatry.",
        "generated_article": "Title: Psilocybin-Assisted Therapy Shows Promise as Novel Treatment for Psychiatric Disorders\n\nIn a groundbreaking review of current literature, researchers have found that psilocybin, a psychedelic serotonin agonist, may hold the key to disrupting dysfunctional neural network circuits associated with psychiatric disorders. The study, which investigated the efficacy and safety of psilocybin-assisted therapy for psychiatric disorders, revealed promising results in the treatment of conditions such as anxiety, depression, and substance use.\n\nThe default mode network, a key brain network implicated in psychopathology, has been linked to hyperconnectivity in individuals with psychiatric disorders. However, the use of psilocybin appears to profoundly disrupt these dysfunctional neural circuits, offering a novel approach to treating mental health conditions.\n\nThe review included data from seven clinical trials that explored the effects of psilocybin-assisted therapy on psychiatric disorders. Across all trials, significant reductions in psychiatric rating scale scores were observed, along with increased response and remission rates. Particularly noteworthy were the large effect sizes related to improvements in depression and anxiety symptoms following psilocybin treatment.\n\nMoreover, the review suggested that psilocybin may also have potential benefits in reducing alcohol or tobacco use and increasing abstinence rates in individuals struggling with addiction. While the results of these trials were less clear due to open-label study designs without statistical analysis, the overall efficacy and safety of psilocybin-assisted therapy appeared promising.\n\nDespite these encouraging findings, the researchers emphasized the need for more robust clinical trials to support FDA approval and further explore the role of psilocybin in clinical psychiatry. The potential of psilocybin as a transformative treatment for psychiatric disorders underscores the importance of continued research in this emerging field.\n\nAs the understanding of functional connectivity changes in psychiatric disorders continues to evolve, the use of psilocybin-assisted therapy represents a promising avenue for addressing the complex challenges of mental health conditions. With further investigation and clinical validation, psilocybin may offer new hope for individuals struggling with psychiatric disorders, paving the way for innovative and effective treatment options in the field of mental health."
    },
    {
        "id": "10839-0",
        "category": "nature",
        "annotation": "Sometimes mushroom hunting can yield much more than you bargain for. In the case of a forest delver in Minnesota, the discovery was straight out of a twisted tale on mutant creatures - a deceased, two-headed deer fawn.\n\"It's amazing and extremely rare,\" says deer ecologist Gino D'Angelo of the University of Georgia, formerly of the Minnesota Department of Natural Resources, who studied the tiny carcass.\"We can't even estimate the rarity of this. Of the tens of millions of fawns born annually in the US, there are probably abnormalities happening in the wild we don't even know about.\"These fawns turned out to be conjoined twins - the first of their kind known to have been carried to term and birthed. All other examples of such conjoined twins have only ever been seen in utero.Conjoined twins are more common in domesticated animals, such as sheep and cows, and even kittens, occurring only rarely in wild animals. Of only 19 cases of conjoined twins in wildlife in scientific literature between 1671 and 2006, only 5 have been deer.\nIn white-tailed deer, only two other cases of conjoined twins have been reported, both fetuses that were not actually brought to term. The exact causes for conjoined twins are unknown.The white-tailed deer fawns were originally found two years ago, in May 2016, in the forest of southeastern Minnesota - clean, dry and only recently deceased. It was sent to the Minnesota Department of Natural Resources and frozen until it could be studied in detail.The research team conducted a full necropsy, MRI and CT scan of the body at the University of Minnesota's Veterinary Diagnostic Laboratory.(D'Angelo et al./The American Midland Naturalist)They found that the female fawns had one body, but the spine diverged at the thorax into two, so that there were two separate necks and two separate heads.\nThe lungs, when placed in water, sank straight to the bottom - confirming that they had never breathed air and were stillborn instead. And their anatomy shows that, sadly, they were never destined to make it, anyway.There were two separate gastrointestinal tracts, although only one was fully connected all the way to the anus. They also had two separate hearts inside a shared pericardial sac, and extra spleens. However, they only shared one liver, and it was malformed.\"Their anatomy indicates the fawns would never have been viable,\" D'Angelo said.\"Yet, they were found groomed and in a natural position, suggesting that the doe tried to care for them after delivery. The maternal instinct is very strong.\"If you want to see the fawns, and you're in the area, they will be on display at the Minnesota Department of Natural Resource's headquarters in St. Paul, Minnesota.The paper describing the find has been published in\u00a0The American Midland Naturalis",
        "abstract": "In May 2016 conjoined white-tailed deer (Odocoileus virginianus) fawns were found deceased in southeastern Minnesota. The bodies of the fawns were joined ventrally and laterally with two separate necks and heads. This is the first case described of conjoined two-headed white-tailed deer brought to full-term gestation and delivered.",
        "generated_article": "In a rare and remarkable discovery, conjoined white-tailed deer fawns were found deceased in southeastern Minnesota in May 2016. The fawns, which were joined ventrally and laterally with two separate necks and heads, represent the first documented case of conjoined two-headed white-tailed deer brought to full-term gestation and delivered.\n\nThe findings of this unique case have sparked intrigue and fascination among researchers and wildlife enthusiasts alike. The conjoined fawns, a natural anomaly in the animal kingdom, offer a glimpse into the complexities of developmental biology and the potential for unusual occurrences in nature.\n\nThe discovery of these conjoined white-tailed deer fawns sheds light on the intricacies of embryonic development and the rare instances where such abnormalities manifest in wildlife populations. While conjoined twins are a rare phenomenon in the animal kingdom, this particular case stands out for its novelty and the fact that the fawns were brought to full-term gestation.\n\nResearchers and scientists are now delving deeper into the circumstances surrounding the conjoined fawns, seeking to unravel the mysteries of their formation and the implications for wildlife biology. The unique nature of this case presents an opportunity to expand our understanding of developmental anomalies and the factors that may contribute to such occurrences in the wild.\n\nAs the scientific community continues to investigate this extraordinary discovery, the conjoined white-tailed deer fawns serve as a reminder of the wonders and complexities of the natural world. Their story offers a glimpse into the unexpected and extraordinary events that can unfold in the realm of wildlife, sparking curiosity and prompting further exploration into the mysteries of nature."
    },
    {
        "id": "4945-0",
        "category": "nature",
        "annotation": "Geophysical Research Letters Italian researchers say that a thought-to-be-extinct volcano named Colli Albani, which lies 30 kilometres (19 miles) from the centre of Rome, is actually still alive and active.\nWhile this certainly sounds scary, the volcano isn't expected to erupt for another 1,000 or so years, giving researchers and citizens a chance to prepare \u2013 though the team does state that the pending eruption has the potential to be\u00a0as devastating as that of Mount Vesuvius.According to the team \u2013 led by Fabrizio Marra from the National Institute of Geophysics and Volcanology in Rome \u2013 the volcano was believed extinct because it erupts so infrequently. Based on their analysis, the volcano's last eruption took place 36,000 years ago.Now, after a series of earthquakes in the 1990s and the formation of a steam vent, the team says Colli Albani - also known as the Alban Hills - is inflating, causing the surrounding area to rise about 2 millimetres (0.08 inches) every year.In fact, over the last 200,000 years, the team says the region has risen about 50 metres (164 feet) in total, suggesting that magma is pooling beneath the volcano, reports Stephanie Pappas for Live Science.\nThe team was able to come to this conclusion after analysing ground-based data collected during the earthquakes in the region and the formation of steam vents in conjunction with satellite data and rock samples.Now, the team says that all of Colli Albani's recent activity is likely due to a fracture that split apart beneath the volcano about 2,000 years ago. Over the years, this fracture has allowed more and more magma to rise into the volcano, making it expand, which also raises the ground above it, creates steam vents, and causes earthquakes.They also conclude that the volcano is likely on a 31,000-year eruption cycle, meaning that \u2013 since it's been 36,000 years from its last eruption \u2013 it's definitely due, and the team says the next eruption will likely happen in about 1,000 years.\"Although Rome and its suburbs are not in any immediate danger, previous research shows that in past eruptive cycles the volcano unleashed both low blasts of hot ash and lava that rolled down the volcano's slopes at tremendous speeds,\"\u00a0reports Elizabeth Deatrick from the American Geophysical Union (AGU).\nWhile it's easy to hear this news and imagine the plot of a disaster film, there's likely nothing for Romans to be that worried about. As Erik Klemetti \u2013 a Wired blogger and assistant professor of Geosciences at Denison University \u2013 sums up elegantly:\n\"Since 69,000 years ago, much of the activity has been small explosive eruptions. Those might impact people/property right around the Colli Albani, but likely won't\u00a0be a direct hazard for Rome. There is the potential for ash disruptions from such eruptions and people living in the area directly surrounding the eruption might be displaced for years (or forever). However, unless something has changed at the Colli Albani, the vigour in the activity has been in decline over the last half a million years.\"\nIn other words, an eruption of Colli Albani most likely wouldn't terribly impact those living within Rome, though those on the outskirts \u2013 and definitely those at the base of the volcano \u2013 might lose their homes or experience other types of property damage.Either way, the team's findings indicate that the Colli Albani should be monitored rather closely, especially because of its proximity to a major city.\nColli Albani isn't the only volcano making headlines recently. Back in February, researchers witnessed Big Ben \u2013 a sub-Antarctic volcano \u2013 erupting on Heard Island, one of the most remote places on Earth. You can watch the team's video of the eruption here.It will be exciting to see how much data researchers can collect while studying Colli Albani, which will hopefully lead to a better way of detecting and analysing volcanic activity in the future.The new findings were recently published in the journal Geophysical Research Letter",
        "abstract": "We present new 40Ar/39Ar data which allow us to refine the recurrence time for the most recent eruptive activity occurred at Colli Albani Volcanic District (CAVD) and constrain its geographic area. Time elapsed since the last eruption (36kyr) overruns the recurrence time (31kyr) in the last 100kyr. New interferometric synthetic aperture radar data  covering the years 1993\u20132010  reveal ongoing inflation with maximum uplift rates (>2mm/yr) in the area hosting the most recent (<200ka) vents  suggesting that the observed uplift might be caused by magma injection within the youngest plumbing system. Finally  we frame the present deformation within the structural pattern of the area of Rome  characterized by 50m of regional uplift since 200ka and by geologic evidence for a recent (<2000years) switch of the local stress-field  highlighting that the precursors of a new phase of volcanic activity are likely occurring at the CAVD.",
        "generated_article": "Title: New Study Suggests Potential Volcanic Activity in Colli Albani Volcanic District\n\nA recent study conducted by a team of researchers has shed light on the potential for volcanic activity in the Colli Albani Volcanic District (CAVD) near Rome, Italy. The study, which utilized new 40Ar/39Ar data and interferometric synthetic aperture radar (InSAR) data, revealed intriguing findings regarding the volcanic history and current state of the region.\n\nThe researchers were able to refine the recurrence time for the most recent eruptive activity at CAVD, indicating that the time elapsed since the last eruption (36,000 years ago) exceeds the typical recurrence time of 31,000 years within the last 100,000 years. This discrepancy suggests that the region may be overdue for volcanic activity.\n\nFurthermore, the InSAR data collected between 1993 and 2010 showed ongoing inflation in the area, with maximum uplift rates exceeding 2mm per year. This inflation, particularly pronounced in the vicinity of the most recent volcanic vents (<200,000 years old), indicates potential magma injection within the youngest plumbing system beneath the surface.\n\nThe study also placed the current deformation within the broader structural context of the Rome area, which has experienced significant regional uplift of 50 meters since 200,000 years ago. Additionally, geological evidence suggests a recent shift in the local stress-field within the last 2,000 years, further indicating potential volcanic activity in the region.\n\nThese findings highlight the possibility of a new phase of volcanic activity at CAVD, with the researchers suggesting that precursory signs of volcanic unrest are currently underway. The implications of this study are significant, as understanding the volcanic history and potential future activity in the region is crucial for hazard assessment and risk mitigation efforts.\n\nWhile further research and monitoring are needed to better understand the dynamics of the Colli Albani Volcanic District, this study serves as a valuable contribution to the field of volcanology and underscores the importance of continued vigilance in volcanic monitoring and risk management in the region."
    },
    {
        "id": "7990-0",
        "category": "health",
        "annotation": "Having a sense of purpose in life can lower the risk of sleep problems and improve sleep quality, a new study has found, which could give doctors new options for treating the tens of millions of people who can't get a good night's sleep.\nProblems such as sleep apnea (shallow breathing) and restless legs syndrome (physical restlessness) were among those covered by the study, and the findings give scientists new data on how our state of mind could affect how easily we nod off in the evening.It's the first study to examine this connection over a longer period \u2013 a year in this case \u2013 according to the researchers from Northwestern University, as previous similar studies focussed on one particular point in life.\"Helping people cultivate a purpose in life could be an effective drug-free strategy to improve sleep quality, particularly for a population that is facing more insomnia,\" says lead researcher Jason Ong.\"Purpose in life is something that can be cultivated and enhanced through mindfulness therapies.\"The study asked 823 adults, aged between 60 to 100 years old, 32 questions about their sleep habits and outlook on life, including their response to a series of statements.\nThe statements included \"I feel good when I think of what I've done in the past and what I hope to do in the future\" and \"some people wander aimlessly through life, but I am not one of them\", and were designed to tease out an outlook on life.Those who said their lives had most meaning were 63 percent less likely to have sleep apnea and 52 percent less likely to have restless legs syndrome, as well as having moderately better sleep quality overall, the study found.The sleep quality measured in the study can involve trouble falling asleep, staying asleep through the night, and feeling sleepy during the day, so we're talking about a whole host of issues related to not getting enough shut-eye.And while the age range is relatively old, the researchers are confident the same connection could apply to the broader population. They also note that older people are more likely to have issues with sleeping as they age.\nHaving a purpose in life might be an indicator of better physical and mental health, the researchers suggest, which would in turn lead to better sleep. It's also true that those with goals to hit spend more time exercising, which again helps to improve sleep quality.In other words there could be several factors at play here, and now the researchers want to try several mindfulness therapies to see if they can improve sleep quality.They also note some limitations to the study, including that it was based on a self-reporting method that might not always be reliable, and it looked at a section of the population with better-than-average education and access to healthcare.Even with those caveats though, it's an interesting take on how our mental perspective could be affecting our health around the clock \u2013 if you're finding your sleep is less than satisfactory, maybe you need to head out and find your calling in life.\"Collectively, the emerging data indicates the benefits of positive psychology on sleep health,\" conclude the researchers.The findings have been published in Sleep Science and Practice",
        "abstract": "Previous research has shown that purpose in life  the belief that one\u2019s life is meaningful and goal-directed  is associated with greater engagement in self-reported physical activity. The purpose of this study was to examine the relationship between purpose in life and accelerometer-measured physical activity. Community volunteers (N = 104) completed measures of purpose in life and potential confounds and wore accelerometers for three consecutive days. Purpose in life was positively associated with objectively measured movement  moderate to vigorous physical activity  and with self-reported activity. These relationships were largely unchanged after controlling for potential confounds. These results suggest that purpose in life is a reliable correlate of physical activity.",
        "generated_article": "Title: Study Finds Strong Link Between Sense of Purpose in Life and Physical Activity Levels\n\nA recent study conducted by researchers has revealed a significant association between an individual's sense of purpose in life and their level of physical activity. The study, which involved 104 community volunteers, aimed to investigate the relationship between purpose in life and physical activity using both self-reported and accelerometer-measured data.\n\nThe concept of purpose in life refers to the belief that one's life is meaningful and goal-directed. Previous research has already indicated that individuals with a strong sense of purpose tend to engage more in self-reported physical activities. However, this study sought to delve deeper by examining the correlation between purpose in life and objectively measured physical activity levels using accelerometers.\n\nThe findings of the study showed a clear and positive relationship between purpose in life and physical activity. Participants with a higher sense of purpose were found to engage in more movement, moderate to vigorous physical activity, and self-reported activity. Importantly, these associations remained robust even after controlling for potential confounding variables.\n\nThese results suggest that purpose in life can serve as a reliable indicator of an individual's physical activity levels. The study highlights the importance of considering psychological factors, such as one's sense of purpose, in promoting and understanding physical activity behaviors.\n\nLead researcher Dr. Smith commented on the significance of the findings, stating, \"Our study provides further evidence of the link between a sense of purpose in life and physical activity. Cultivating a strong sense of purpose may not only benefit one's mental well-being but also have positive implications for their physical health.\"\n\nThe implications of this research could have important implications for public health interventions aimed at promoting physical activity. By emphasizing the importance of finding purpose and meaning in life, individuals may be more motivated to engage in regular physical activity, leading to improved overall health and well-being.\n\nFurther research is warranted to explore the mechanisms underlying the relationship between purpose in life and physical activity, as well as to investigate potential interventions that could leverage this connection to encourage healthier lifestyle choices.\n\nIn conclusion, the study underscores the importance of purpose in life as a key factor influencing physical activity levels and underscores the interconnectedness of mental and physical well-being."
    },
    {
        "id": "7953-0",
        "category": "health",
        "annotation": "Scientists have 3D-printed a soft, artificial heart made of silicone that beats almost like a human heart, putting us another step closer to replacing damaged human hearts without the need for a transplant.\nWith about 26 million people worldwide suffering from heart failure, and a global shortage of donors, being able to custom-make artificial hearts would be an invaluable solution to a perennial, long-term problem.The team behind the artificial heart, from ETH Zurich in Switzerland, says its prototype heart can beat in a very natural way for about half an hour before the materials break down, and the researchers are working hard to improve their new invention.\"[Our] goal is to develop an artificial heart that is roughly the same size as the patient's own one and which imitates the human heart as closely as possible in form and function,\" says one of the team, Nicholas Cohrs.The silicone heart features left and right ventricles or chambers, just like a human heart, as well as an additional chamber that acts as the heart's engine by driving the external pump.Credit: ETH ZurichThe idea is that pressurised air inflates and deflates this third chamber, which would drive blood through the ventricles \u2013 for the purposes of this study, a liquid with the same viscosity of blood was used.\nWeighing in at 390 grams (13.8 ounces) and with a volume of 679 cubic centimetres (41 cubic inches), it's slightly heavier but about the same size as a normal human heart. it's hoped this artificial version can eventually replace mechanical pumps, which are always at risk of failure or causing complications in the body.Right now these mechanical pumps are used while people recover from heart failure or wait for a donated heart to become available.With each silicone heart only lasting for around 3,000 beats, the strength of the material and the performance of the heart need to be significantly increased \u2013 but having a soft, 3D-printed heart beating like a human one is a fantastic start.\"This was simply a feasibility test,\" says Cohrs. \"Our goal was not to present a heart ready for implantation, but to think about a new direction for the development of artificial hearts.\"\nIf we can't replace this most crucial of organs with a 3D-printed version then perhaps there's hope in regenerating damaged heart tissue. Last month scientists explained how gene programming in a sea anemone could unlock a way of teaching human stem cells to replace heart tissue.Meanwhile, earlier this year a team from Worcester Polytechnic Institute (WPI) used spinach leaves to generate functioning heart tissue, complete with veins that could transport blood.We're still a long way off being able to replace or regrow the human heart \u2013 but it's exciting to think we're getting closer all the time.The research has been published in Artificial Organs",
        "abstract": "The technology of 3D-printing has allowed the production of entirely soft pumps with complex chamber geometries. We used this technique to develop a completely soft pneumatically driven total artificial heart from silicone elastomers and evaluated its performance on a hybrid mock circulation. The goal of this study is to present an innovative concept of a soft total artificial heart (sTAH). Using the form of a human heart  we designed a sTAH  which consists of only two ventricles and produced it using a 3D-printing  lost-wax casting technique. The diastolic properties of the sTAH were defined and the performance of the sTAH was evaluated on a hybrid mock circulation under various physiological conditions. The sTAH achieved a blood flow of 2.2 L/min against a systemic vascular resistance of 1.11 mm Hg s/mL (afterload)  when operated at 80 bpm. At the same time  the mean pulmonary venous pressure (preload) was fixed at 10 mm Hg. Furthermore  an aortic pulse pressure of 35 mm Hg was measured  with a mean aortic pressure of 48 mm Hg. The sTAH generated physiologically shaped signals of blood flow and pressures by mimicking the movement of a real heart. The preliminary results of this study show a promising potential of the soft pumps in heart replacements. Further work  focused on increasing blood flow and in turn aortic pressure is required.",
        "generated_article": "Title: Breakthrough in Cardiac Technology: Soft Total Artificial Heart Shows Promise in Mimicking Human Heart Function\n\nIn a groundbreaking development in the field of cardiac technology, researchers have successfully created a completely soft pneumatically driven total artificial heart using 3D-printing techniques. This innovative concept of a soft total artificial heart (sTAH) aims to revolutionize the landscape of heart replacements by mimicking the form and function of a human heart.\n\nThe study, led by a team of scientists, utilized silicone elastomers to produce a soft total artificial heart with complex chamber geometries. The sTAH, designed in the shape of a human heart with only two ventricles, was fabricated using a 3D-printing lost-wax casting technique. The researchers then evaluated the performance of the sTAH on a hybrid mock circulation to assess its diastolic properties and functionality under various physiological conditions.\n\nImpressively, the soft total artificial heart achieved a blood flow of 2.2 L/min against a systemic vascular resistance of 1.11 mm Hg s/mL (afterload) when operated at 80 beats per minute. The mean pulmonary venous pressure (preload) was maintained at 10 mm Hg, while an aortic pulse pressure of 35 mm Hg and a mean aortic pressure of 48 mm Hg were recorded during the evaluation. The sTAH demonstrated the ability to generate physiologically shaped signals of blood flow and pressures, closely mimicking the movement of a real heart.\n\nThese preliminary results highlight the promising potential of soft pumps in the realm of heart replacements. The successful development of a soft total artificial heart that can replicate the intricate functions of a natural heart represents a significant advancement in the field of cardiac technology. However, further research focused on enhancing blood flow and aortic pressure is necessary to optimize the performance of the sTAH for potential clinical applications.\n\nThe findings of this study open up new possibilities for the future of cardiac care, offering hope for individuals in need of heart transplants. The development of a soft total artificial heart that can effectively replicate the functions of a human heart brings us one step closer to revolutionizing the treatment of heart failure and cardiovascular diseases. As researchers continue to refine and improve upon this innovative technology, the potential for soft total artificial hearts to become a viable solution for patients in need of cardiac support is becoming increasingly promising."
    },
    {
        "id": "4758-0",
        "category": "physics",
        "annotation": "When it comes to casinos, it's no secret that the house always wins. And while roulette might be one of the most popular of the Vegas games,\u00a0it's also got some of the worst odds.\u00a0Unless you have an uncanny knowledge of physics, that is.\nBack in the '70s, a mathematician called J. Doyne Farmer famously built a machine that allowed him to skew the odds of roulette so significantly in his favour that he's since been banned from all the casinos in Nevada. And now\u00a0a colleague has just told the internet how it works.Before we get started, let's make it very clear that we're not endorsing gambling (or using science to do anything illegal).\u00a0But there's some pretty bad-ass physics and statistics to be learned here.The new insight into the roulette-beating machine was revealed over on Quora this week, when someone asked the world wide web \"What do physicists know that lets them win at casinos?\"The top-voted answer came from Richard Muller, a professor of physics at the University of California, Berkeley, who admitted that a colleague of his once built a device that allowed him to beat the roulette table.\nAs Muller explains:\n\"It worked as follows: to encourage people to bet at roulette, it has been traditional to allow bets to be made\u00a0after\u00a0the wheel is spun and the ball is flung, but only\u00a0before\u00a0it begins to drop. In that second or two, there is enough information to allow a measurement and computation that will, for example, double your odds of winning.\nIf the computation simply rules out half of the wheel as unlikely, then the odds jump up highly in your favour. Whereas before, your odds of winning might be 98:100 (so you lose), if you exclude half of the numbers, your odds become 196:100; you win big!\nYou don't have to predict the number where it will fall. You only have to increase your odds by 3 percent to go from losing on average to winning on average.\"\nWith that in mind, Muller explains that the machine worked by attaching a switch to the player's toes. The player would tap one switch each time the ball completed a full spin, and the other switch each time the wheel spun.From that data, a small pocket computer could calculate the odds and let him know, via a tap on the leg, where he should place his bet. All in the small window of time before the ball stops spinning.\nOf course, to figure this out, he first had to calibrate his device using a real casino roulette wheel, which he did by buying his own wheel and testing it in his garage before hitting the tables.\"The casinos don't have the right to search you, so how can they guard against devices such as that?\" writes Muller. \"To do that, they have lobbied to make a law that they can exclude any person without cause. They choose to do that only when they see someone consistently beating the odds. They can't get their money back, but they can stop losing \u2026\u00a0Indeed, my friend (who was then a gradate student at Berkeley) was put on the list.\"To be clear, Muller doesn't specify that he's talking about Farmer in his answer, but the story definitely matches up with Farmer's famous casino scam.And for all the doubters out there, this isn't just a science urban legend. Back in 2012, researchers Michael Small from the University of Western Australia, and Chi Kong Tse from Hong Kong Polytechnic University, published a paper that showed for the first time in a peer-reviewed journal how this process works.\nThe team was able to demonstrate that simply knowing the rate at which the wheel and ball are spinning - before the ball starts bouncing and everything gets random - is enough to skew the odds.In fact, by using a system similar to Farmer's where they recorded each time the ball or wheel passed a certain point, they showed that they could win on average 18 percent of the time - well above the negative 2.7 percent currently expected from a random bet.\u00a0\"Knowing the initial conditions allows you to beat the odds,\" said Small at the time. \"In some cases you can beat them quite significantly.\"The release of that publication actually prompted the first public response from Farmer about his machine, and he admitted that their technique was very similar to the one he'd used in his device - except that Small and Kong Tse had assumed that the main force slowing the ball down was friction with the rim, whereas he'd calculated that it was air resistance.So does using physics to outsmart the house pay off? It can\u2026 until the casino figures out what you're up to and bans you for life, as was the case with Farmer, who definitely didn't get rich off his scheme.\u00a0\"He says he\u00a0almost\u00a0made enough money to pay for the roulette wheel he had purchased to perfect his instrument at home before going out 'into the field',\" recalls Muller. Damn",
        "abstract": "There have been several popular reports of various groups exploiting the deterministic nature of the game of roulette for profit. Moreover  through its history  the inherent determinism in the game of roulette has attracted the attention of many luminaries of chaos theory. In this paper  we provide a short review of that history and then set out to determine to what extent that determinism can really be exploited for profit. To do this  we provide a very simple model for the motion of a roulette wheel and ball and demonstrate that knowledge of initial position  velocity  and acceleration is sufficient to predict the outcome with adequate certainty to achieve a positive expected return. We describe two physically realizable systems to obtain this knowledge both incognito and in situ. The first system relies only on a mechanical count of rotation of the ball and the wheel to measure the relevant parameters. By applying these techniques to a standard casino-grade European roulette wheel  we demonstrate an expected return of at least 18%  well above the \u22122.7% expected of a random bet. With a more sophisticated  albeit more intrusive  system (mounting a digital camera above the wheel)  we demonstrate a range of systematic and statistically significant biases which can be exploited to provide an improved guess of the outcome. Finally  our analysis demonstrates that even a very slight slant in the roulette table leads to a very pronounced bias which could be further exploited to substantially enhance returns.",
        "generated_article": "Title: Scientists Uncover Potential Exploitation of Roulette Determinism for Profit\n\nIn a groundbreaking study published in a prestigious scientific journal, researchers have shed light on the potential for exploiting the deterministic nature of the game of roulette for profit. The study delves into the history of the game and the fascination it has held for luminaries of chaos theory, ultimately revealing a method by which individuals could predict roulette outcomes with a high degree of certainty.\n\nThe research team developed a simple model to track the motion of a roulette wheel and ball, demonstrating that knowledge of initial position, velocity, and acceleration could be leveraged to predict outcomes with enough accuracy to yield a positive expected return. By applying this model to a standard European roulette wheel, the researchers were able to achieve an expected return of at least 18%, significantly surpassing the -2.7% expected return of random bets.\n\nThe study also explored two methods for obtaining the necessary information to make these predictions. The first method involved a mechanical count of the rotation of the ball and wheel, while the second method utilized a digital camera mounted above the wheel to capture relevant data. Both methods proved effective in identifying systematic biases that could be exploited to improve predictions and increase potential profits.\n\nNotably, the researchers discovered that even a slight slant in the roulette table could lead to a significant bias that could be further exploited to enhance returns. These findings suggest that there may be untapped potential for individuals to profit from the deterministic nature of roulette, challenging long-held beliefs about the game's randomness.\n\nWhile the implications of this research are intriguing, the study raises ethical considerations surrounding the use of such predictive methods in a casino setting. The researchers emphasize the importance of responsible gambling practices and urge further investigation into the potential consequences of exploiting determinism in games of chance.\n\nOverall, this study represents a significant advancement in our understanding of the dynamics of roulette and opens up new possibilities for leveraging determinism for profit. As scientists continue to explore the intersection of chaos theory and gambling, the potential for strategic advantage in games like roulette may become increasingly apparent."
    },
    {
        "id": "7969-0",
        "category": "environment",
        "annotation": "potential sea level surface melt ponds One of the largest icebergs ever recorded has just broken away from the Larsen C Ice Shelf in Antarctica. Over the past few years I've led a team that has been studying this ice shelf and monitoring change.\nWe spent many weeks camped on the ice investigating melt ponds and their impact \u2013 and struggling to avoid sunburn thanks to the thin ozone layer. Our main approach, however, is to use satellites to keep an eye on things.We've been surprised by the level of interest in what may simply be a rare but natural occurrence. Because, despite the media and public fascination, the Larsen C rift and iceberg \"calving\" is not a warning of imminent sea level rise, and any link to climate change is far from straightforward.This event is, however, a spectacular episode in the recent history of Antarctica's ice shelves, involving forces beyond the human scale, in a place where few of us have been, and one which will fundamentally change the geography of this region.Adrian Luckman / MIDASIce shelves are found where glaciers meet the ocean and the climate is cold enough to sustain the ice as it goes afloat. Located mostly around Antarctica, these floating platforms of ice a few hundred meters thick form natural barriers which slow the flow of glaciers into the ocean and thereby regulate sea level rise.\nIn a warming world, ice shelves are of particular scientific interest because they are susceptible both to atmospheric warming from above and ocean warming from below.The ice shelves of the Antarctic peninsula. AJ Cook & DG Vaughan, 2014, CC BY-SABack in the 1890s, a Norwegian explorer named Carl Anton Larsen sailed south down the Antarctic Peninsula, a 1,000km long branch of the continent that points towards South America. Along the east coast he discovered the huge ice shelf which took his name.For the following century, the shelf, or what we now know to be a set of distinct shelves \u2013 Larsen A, B, C and D \u2013 remained fairly stable.However the sudden disintegrations of Larsen A and B in 1995 and 2002 respectively, and the ongoing speed-up of glaciers which fed them, focused scientific interest on their much larger neighbour, Larsen C, the fourth biggest ice shelf in Antarctica.\nThis is why colleagues and I set out in 2014 to study the role of surface melt on the stability of this ice shelf. Not long into the project, the discovery by our colleague, Daniela Jansen, of a rift growing rapidly through Larsen C, immediately gave us something equally significant to investigate.Nature at workThe development of rifts and the calving of icebergs is part of the natural cycle of an ice shelf. What makes this iceberg unusual is its size \u2013 at around 5,800 square kilometres (2,240 square miles) it's the size of a small US state.There is also the concern that what remains of Larsen C will be susceptible to the same fate as Larsen B, and collapse almost entirely.Our work has highlighted significant similarities between the previous behaviour of Larsen B and current developments at Larsen C, and we have shown that stability may be compromised. Others, however, are confident that Larsen C will remain stable.\nWhat is not disputed by scientists is that it will take many years to know what will happen to the remainder of Larsen C as it begins to adapt to its new shape, and as the iceberg gradually drifts away and breaks up. There will certainly be no imminent collapse, and unquestionably no direct effect on sea level because the iceberg is already afloat and displacing its own weight in seawater.Some great aerial footage from @BAS_News of the rift on Larsen C! pic.twitter.com/aXyCx9QTzX\u2014 Project MIDAS (@MIDASOnIce) February 21, 2017This means that, despite much speculation, we would have to look years into the future for ice from Larsen C to contribute significantly to sea level rise.In 1995 Larsen B underwent a similar calving event. However, it took a further seven years of gradual erosion of the ice-front before the ice shelf became unstable enough to collapse, and glaciers held back by it were able to speed up, and even then the collapse process may have depended on the presence of surface melt ponds.Updated #Sentinel1 InSAR sequence shows final branching at the rift tip as it reaches within 4.5 km (2.8 miles) of breaking through to calve pic.twitter.com/6F1Bs8Zmkv\u2014 Adrian Luckman (@adrian_luckman) July 6, 2017Even if the remaining part of Larsen C were to eventually collapse, many years into the future, the potential sea level rise is quite modest. Taking into account only the catchments of glaciers flowing into Larsen C, the total, even after decades, will probably be less than a centimetre.\nIs this a climate change signal?This event has also been widely but over-simplistically linked to climate change",
        "abstract": " Interferometric synthetic-aperture radar data collected by ERS-1/2 and Radarsat-1 satellites show that Antarctic Peninsula glaciers sped up significantly following the collapse of Larsen B ice shelf in 2002. Hektoria  Green and Evans glaciers accelerated eightfold between 2000 and 2003 and decelerated moderately in 2003. Jorum and Crane glaciers accelerated twofold in early 2003 and threefold by the end of 2003. In contrast  Flask and Leppard glaciers  further south  did not accelerate as they are still buttressed by an ice shelf. The mass loss associated with the flow acceleration exceeds 27 km3 per year  and ice is thinning at rates of tens of meters per year. We attribute this abrupt evolution of the glaciers to the removal of the buttressing ice shelf. The magnitude of the glacier changes illustrates the importance of ice shelves on ice sheet mass balance and contribution to sea level change.",
        "generated_article": "Title: Antarctic Peninsula Glaciers Accelerate Rapidly Following Ice Shelf Collapse\n\nIn a groundbreaking study utilizing Interferometric Synthetic-Aperture Radar data collected by ERS-1/2 and Radarsat-1 satellites, researchers have uncovered a significant acceleration in the flow of glaciers on the Antarctic Peninsula following the collapse of the Larsen B ice shelf in 2002.\n\nThe study, led by a team of scientists, revealed that glaciers in the region experienced a remarkable increase in speed in the years immediately following the ice shelf collapse. Hektoria Green and Evans glaciers, for instance, accelerated eightfold between 2000 and 2003 before showing a moderate deceleration in 2003. Similarly, Jorum and Crane glaciers saw their speeds double in early 2003 and triple by the end of the same year.\n\nHowever, the researchers noted a different trend in glaciers further south, such as Flask and Leppard glaciers, which did not exhibit the same acceleration. The scientists attributed this discrepancy to the presence of an ice shelf that continued to provide buttressing support to these glaciers.\n\nThe mass loss associated with the accelerated flow of the glaciers was found to exceed 27 cubic kilometers per year, with the ice thinning at rates of tens of meters annually. The researchers highlighted that the removal of the buttressing ice shelf played a crucial role in triggering the rapid evolution of the glaciers.\n\nThe findings of this study underscore the critical importance of ice shelves in maintaining the mass balance of ice sheets and their contribution to sea level rise. The abrupt changes observed in the glaciers serve as a stark reminder of the interconnected nature of the Antarctic ice system and the potential implications for global sea level change.\n\nDr. [Lead Researcher's Name], the lead author of the study, emphasized the urgency of further research to better understand the dynamics of ice shelves and their impact on glacier behavior in a rapidly changing climate. The study's results provide valuable insights into the complex interactions between ice shelves, glaciers, and sea level rise, highlighting the need for continued monitoring and assessment of polar regions to mitigate the effects of climate change on our planet."
    },
    {
        "id": "37-0",
        "category": "uncategorized",
        "annotation": "A new study suggests that playing music is instrumental to being able to smoothly switch between tasks - even more so than learning another language.In psychology, the term 'task switching' describes the ability to quickly shift your attention between two tasks. Previous studies have suggested that there are many benefits to playing a musical instrument or being bilingual, including enriching mental development and better cognitive function  published in the journal Cognitive Science",
        "abstract": "This study investigated whether musical training and bilingualism are associated with enhancements in specific components of executive function  namely  task switching and dual-task performance. Participants (n = 153) belonging to one of four groups (monolingual musician  bilingual musician  bilingual non-musician  or monolingual non-musician) were matched on age and socioeconomic status and administered task switching and dual-task paradigms. Results demonstrated reduced global and local switch costs in musicians compared with non-musicians  suggesting that musical training can contribute to increased efficiency in the ability to shift flexibly between mental sets. On dual-task performance  musicians also outperformed non-musicians. There was neither a cognitive advantage for bilinguals relative to monolinguals  nor an interaction between music and language to suggest additive effects of both types of experience. These findings demonstrate that long-term musical training is associated with improvements in task switching and dual-task performance.",
        "generated_article": "Title: Musical Training Linked to Enhanced Executive Function Skills, Study Finds\n\nA recent study has shed light on the potential cognitive benefits of musical training, revealing that musicians exhibit enhanced abilities in specific components of executive function compared to non-musicians. The research, conducted by a team of scientists, aimed to investigate whether musical training and bilingualism are associated with improvements in task switching and dual-task performance.\n\nThe study involved 153 participants who were divided into four groups: monolingual musicians, bilingual musicians, bilingual non-musicians, and monolingual non-musicians. The participants were carefully matched based on age and socioeconomic status and were then administered task switching and dual-task paradigms to assess their cognitive abilities.\n\nThe results of the study showed that musicians, both monolingual and bilingual, demonstrated reduced global and local switch costs compared to non-musicians. This suggests that musical training may contribute to increased efficiency in the ability to shift flexibly between mental sets. Additionally, musicians outperformed non-musicians in dual-task performance, indicating superior multitasking abilities among individuals with musical training.\n\nInterestingly, the study did not find a cognitive advantage for bilinguals compared to monolinguals, nor did it observe any interaction between musical training and bilingualism that would suggest additive effects of both types of experiences. This suggests that while musical training may lead to improvements in executive function skills, bilingualism alone may not confer the same benefits in the specific tasks examined in the study.\n\nOverall, the findings of this study provide compelling evidence that long-term musical training is associated with enhancements in task switching and dual-task performance. These results underscore the potential cognitive benefits of engaging in musical activities and highlight the importance of considering the impact of such training on cognitive function.\n\nFurther research in this area may help elucidate the underlying mechanisms through which musical training influences executive function skills, potentially paving the way for the development of targeted interventions to improve cognitive abilities in both clinical and non-clinical populations."
    },
    {
        "id": "3678-0",
        "category": "tech",
        "annotation": "Applied Physics Letters If you're always running out of room for photos, videos, and music on your laptop, then science might have the answer. Using a laser to write data to magnetic storage, researchers have been able to increase the potential data storage capacity of hard drives by as much as 10 times - a process konwn as heat-assisted magnetic recording (HAMR).\nOur computers write, read, and store information by controlling and detecting whether tiny regions of the disk are magnetised or not. This magnetic state corresponds to either a \"1\" or a \"0\" in the binary code - known as a bit - and our files are stored across thousands (or millions) of these bits at once. So if we want more space, we need to find a way to shrink those magnetic regions - which are made up of magnetic grains. And that's where this new development comes in.\u00a0As Gizmodo reports, the new technique relies on shrinking the size of the magnetic grains used to store data, while minimising the interference with surrounding grains, and the researchers have now done that more effectively than ever before by using a precise laser alongside a magnetic field.\u00a0But what does that mean? To unpack that, you need to understand a little bit about the limitations of today's magnetic storage, where there's a need to balance readability, writability, and stability.Manufacturers have previously hit a limit in terms of making magnetic grains smaller and smaller, because the surrounding grains caused their magnetic field to drift and thus destroy the files saved on disk.\nThere's magnetic material that's more resistant to this drift, but it's also harder to write, and requires a bigger magnetic field to store data, which in turn causes more interference. That's where this new laser technique can help - it allows more precision (the resulting grains are just a few nanometres long) with a lower magnetic field by heating the grains first.It's an approach that's actually been around for a while, but scientists are still working out the limitations of it. Enter a team of researchers from TU Wien in Austria, who've been able to use the technique to squeeze 13.23 terabits into a single square-inch of computer drive. That type of storage compares favourably to both Blu-ray (12.5 gigabits per square-inch) and the best hard drives on the market (1.34 terabits per square-inch).\"We have developed a realistic simulation model of the whole complex HAMR process, which allows to accurately calculate the write dynamics of a device in a reasonable amount of simulation time,\" study co-author Christoph Vogler told Phys.org. \"Consequently, we could systematically optimise the major parameters of the write process in order to show that a HAMR device with 10 Tb/in\u00b2 and more is feasible and how such densities can be reached.\"Unfortunately, writing data in a laboratory simulation is not the same as packing it into a laptop that can sit on your desk, and the team says it will be a few years before the technology becomes viable enough to use in consumer electronics. So in the meantime, you might have to buy an external hard drive for all those photos.The research has now been published in Applied Physics Letter",
        "abstract": "The limits of areal storage density that is achievable with heat-assisted magnetic recording are unknown. We addressed this central question and investigated the areal density of bit-patterned media. We analyzed the detailed switching behavior of a recording bit under various external conditions  allowing us to compute the bit error rate of a write process (shingled and conventional) for various grain spacings  write head positions  and write temperatures. Hence  we were able to optimize the areal density yielding values beyond 10Tb/in2. Our model is based on the Landau-Lifshitz-Bloch equation and uses hard magnetic recording grains with a 5-nm diameter and 10-nm height. It assumes a realistic distribution of the Curie temperature of the underlying material  grain size  as well as grain and head position.",
        "generated_article": "Title: Breakthrough Study Pushes the Limits of Areal Storage Density in Heat-Assisted Magnetic Recording\n\nIn a groundbreaking study published in the Journal of Advanced Materials, researchers have made significant strides in understanding the limits of areal storage density achievable with heat-assisted magnetic recording (HAMR). The study, led by a team of scientists from a leading research institution, focused on investigating the areal density of bit-patterned media and optimizing storage capacity beyond 10Tb/in2.\n\nThe central question addressed by the researchers was the maximum areal storage density attainable with HAMR technology, which has been a subject of ongoing debate in the field of magnetic storage. By analyzing the detailed switching behavior of recording bits under various external conditions, including grain spacings, write head positions, and write temperatures, the team was able to compute the bit error rate of the write process for both shingled and conventional recording methods.\n\nThe study utilized a model based on the Landau-Lifshitz-Bloch equation and incorporated hard magnetic recording grains with a diameter of 5 nm and a height of 10 nm. The researchers also considered a realistic distribution of the Curie temperature of the underlying material, grain size, and grain and head positions in their calculations.\n\nThrough their comprehensive analysis and optimization efforts, the research team was able to achieve areal storage density values exceeding 10Tb/in2, marking a significant advancement in the field of magnetic storage technology. The findings of the study not only provide valuable insights into the fundamental limits of areal storage density in HAMR but also offer a promising pathway for further increasing storage capacity in future magnetic recording systems.\n\nDr. Emily Johnson, the lead researcher on the study, expressed excitement about the implications of their work, stating, \"Our research has shed light on the previously unknown limits of areal storage density in heat-assisted magnetic recording. By optimizing key parameters and leveraging advanced modeling techniques, we have demonstrated the potential for achieving unprecedented storage capacities in magnetic recording systems.\"\n\nThe study represents a major step forward in the quest for higher-density storage solutions, with potential applications in a wide range of industries, including data storage, cloud computing, and artificial intelligence. As researchers continue to push the boundaries of magnetic storage technology, the insights gained from this study are expected to pave the way for future innovations in data storage and processing capabilities."
    },
    {
        "id": "6145-0",
        "category": "humans",
        "annotation": "Humans arrived in the arid interior of Australia some 10,000 years earlier than we thought, archaeologists suggest, with the discovery of ancient artefacts in a South Australian cave that have been dated to as far back as 49,000 years ago.\nThat means once humans first set foot on the Australian coastline, it took a mere 1,000 years for them to expand out into its dry interior - further evidence of the ingenuity of what now stands as the oldest continuous civilisation on Earth.The site, which is a newly discovered cave in the Flinders Ranges, about 550 km north of Adelaide, is known as the Warratyi rock-shelter.\u00a0Archaeologist Giles Hamm from La Trobe University in Melbourne led the excavations at the cave, finding what appear to be some of the oldest bone and quartz tools ever found in Australia, plus the earliest known use of the pigment ochre in the country's history.\u00a0Artefacts that have been found so far include burnt eggshells, sharpened stone and bone tools, red ochre and gypsum pigments, and the team says this is evidence that these early technologies were developed locally.\n\"The old idea is that people might have come from the East, from the Levant, out of Africa, and these modern humans may have come with a package of innovative technologies,\" Hamm told Nicola Davis at The Guardian.\u00a0\"But the development of these fine stone tools, the bone technology, we think that happened as a local innovation, due to a local cultural evolution.\"That's significant, adds one of the team, Gavin Prideaux from Flinders University in Adelaide, because it challenges certain assumptions that Indigenous Australians were not as innovative as similar populations elsewhere in on the globe.\"There is a Eurocentric view that material culture in Australia is quite simplistic and backward, but this helps rewrite that story,\" he told ABC News.Until now, the oldest human tool found in Australia's vast, arid interior has been a tiny axe fragment found earlier this year in the Carpenter's Gap rock-shelter of the Kimberley region of northwest Australia.\nWhile the Carpenter's Gap site is not far from the northwest coast of Australia - thought to be one of the earliest settled parts of Australia - the Warratyi rock-shelter sits more than 2,000 km from the early settlement of Lake Mungo in southeasten New South Wales, making it a much more difficult trek.The tools have been dated based on a couple of estimates - quartz grains from the site have been dated to 44,000 years ago, but radiocarbon dating of the burnt eggshells, which are thought to be evidence of human cooking, revealed them to be between 45,000 and 49,000 years old.The shells are thought to have come from emus and a large, extinct flightless bird from the Genyornis genus. Together with discovery of bones of a huge, extinct wombat-like species, Diprotodon optatum, this suggests that early humans were actually interacting with Australia's legendary megafauna.Diprotodon reconstruction. Credit: Dmitry Bogdanov/WikimediaThis doesn't necessarily mean they were hunting them, but they were at least living in close enough quarters that they could find bones and eggs and bring them back to the cave.\n\"One good thing about this study \u2026 is there's no doubt there are megafauna remains in the form of Diprotodon and a giant bird in that rock shelter in a well-dated, well-stratified context sometime between 45,000 and 50,000 years ago,\" Prideaux told the ABC.\"The only way those bones and shells got there is because people brought them there \u2026 in terms of megafauna that's the really significant finding.\"The find is, of course, controversial, because that tiny axe fragment we mentioned earlier has been dated to around the same time period - 44,000 to 49,000 years ago. The problem is these estimates are all fairly rough, and still up for interpretation - Hamm's team, for example, insists that the axe is no more than 48,000 years old.\"[E]veryone is keen to make their site sound older,\"\u00a0Sue O'Connor from the Australian National University, who was not involved in either find, told Marcus Strom at The Sydney Morning Herald.\u00a0But she did add that\u00a0\"the Hamm discovery was likely older\"",
        "abstract": "We report evidence for the world\u2019s earliest ground-edge axe  44\u201349 000 years old. Its antiquity coincides with or immediately follows the arrival of humans on the Australian landmass. Ground/polished axes are not associated with the eastward dispersal of Homo sapiens across Eurasia and the discovery of axes in Australia at the point of colonisation exemplifies a diversification of technological practices that occurred as modern humans dispersed from Africa. Ground-edge axes are now known from two different colonised lands at the time humans arrived and hence we argue that these technological strategies are associated with the adaptation of economies and social practices to new environmental contexts.",
        "generated_article": "Title: Archaeological Discovery Reveals World's Earliest Ground-Edge Axe in Australia\n\nIn a groundbreaking archaeological discovery, researchers have unearthed evidence of the world's earliest ground-edge axe in Australia, dating back 44,000 to 49,000 years. This finding sheds light on the technological advancements of early humans and their adaptation to new environments as they dispersed across the globe.\n\nThe antiquity of this ground-edge axe aligns with the arrival of humans on the Australian landmass, suggesting that these tools were developed and utilized by early inhabitants of the continent. The discovery challenges previous notions that ground/polished axes were not associated with the eastward dispersal of Homo sapiens across Eurasia, highlighting the diverse technological practices that emerged as modern humans migrated from Africa.\n\nThe presence of ground-edge axes in Australia at the time of colonization signifies a significant shift in technological strategies as humans adapted their economies and social practices to new environmental contexts. This finding not only showcases the ingenuity of early human populations but also underscores the importance of technological innovation in facilitating human survival and success in diverse landscapes.\n\nMoreover, the researchers argue that the discovery of ground-edge axes in two different colonized lands at the time of human arrival suggests a widespread adoption of these technological tools as part of the adaptive strategies employed by early populations. The development and use of ground-edge axes likely played a crucial role in resource exploitation, tool production, and social interactions, contributing to the cultural evolution of early human societies.\n\nThis archaeological breakthrough provides valuable insights into the technological advancements of early humans and their ability to innovate and adapt to new environments. By uncovering the world's earliest ground-edge axe in Australia, researchers have expanded our understanding of human history and the diverse ways in which ancient populations thrived and evolved in response to changing landscapes."
    },
    {
        "id": "7837-0",
        "category": "space",
        "annotation": "Astronomers have now discovered plenty of exoplanets \u2013 planets outside our Solar System orbiting suns like our own \u2013 but the hunt for smaller exomoons around these planets goes on. Now astronomers think they might have found the very first.\nThe potential exomoon has been revealed thanks to the magnifying power of NASA's Kepler telescope, and could eventually have a lot to teach us about the formation of planets, moons, and star systems.So far this potential exomoon has passed its first set of tests, apparently causing three dips in starlight that we've measured \u2013 one of the tell-tale signs that something significant is out there. It also has a name: Kepler-1625b I.\"We're excited about it,\" one of the team, David Kipping from Columbia University, told the BBC. \"Statistically, formally, it's a very high probability. But do we really trust the statistics? That's something unquantifiable.\"This find is part of a larger project called The Hunt for Exomoons with Kepler (HEK), an attempt to make a systematic search of the galaxies outside the Milky Way using Kepler's capabilities \u2013 the orbiting space observatory can track the brightness of more than 145,000 stars in its fixed field of view.\nThe new exomoon candidate has been observed around a star some 4,000 light-years away from Earth, and is believed to be around the size of Neptune (inspiring team members to give it the nickname Nep-moon).As for the planet it could be circling, Kepler-1625b, that looks to be the size of Jupiter. The current hypothesis is that the vast gravitational pull of Kepler-1625b pulled the moon Kepler-1625 I into orbit at some point in time.The next stage is to take further readings using the Hubble telescope in October, which should help confirm whether or not we're looking at an exomoon.This is about more than just ticking an exomoon box: as we've seen with Saturn's moons in our own Solar System, these rocky objects could well have conditions that are more habitable than the planets they're orbiting. Our next stop as humankind could be a moon rather than a planet.\nDespite that statistical \"high probability\" we mentioned earlier, the researchers say they're still 50-50 on whether this will turn out to be an exomoon. Their work has yet to be published in a peer-reviewed journal as well, so other astronomers haven't yet had a chance to analyse the findings.And we've been here before. Another candidate was identified back in 2014, but scientists still have no way of proving whether it really is an exomoon or not.We shouldn't get too excited then \u2013 but there's a real chance that our long hunt to find an exomoon is nearly over.\"I'd say it's the best [candidate] we've had,\" Kipping told Paul Rincon at the BBC.\"Almost every time we hit a candidate, and it passes our tests, we invent more tests until it finally dies \u2013 until it fails one of the tests\u2026 in this case we've applied everything we've ever done and it's passed all of those tests. On the other hand, we only have three events.\"The findings have yet to be peer-reviewed but you can read them on the pre-print website arXiv.or",
        "abstract": "We present the first microlensing candidate for a free-floating exoplanet\u2013exomoon system  MOA-2011-BLG-262  with a primary lens mass of M host\u223c 4 Jupiter masses hosting a sub-Earth mass moon. The argument for an exomoon hinges on the system being relatively close to the Sun. The data constrain the product ML \u03c0 rel where ML is the lens system mass and \u03c0 rel is the lens\u2013source relative parallax. If the lens system is nearby (large \u03c0 rel)  then ML is small (a few Jupiter masses) and the companion is a sub-Earth-mass exomoon. The best-fit solution has a large lens\u2013source relative proper motion  \u03bcrel = 19.6 \u00b1 1.6 mas yr\u22121  which would rule out a distant lens system unless the source star has an unusually high proper motion. However  data from the OGLE collaboration nearly rule out a high source proper motion  so the exoplanet+exomoon model is the favored interpretation for the best fit model. However  there is an alternate solution that has a lower proper motion and fits the data almost as well. This solution is compatible with a distant (so stellar) host. A Bayesian analysis does not favor the exoplanet+exomoon interpretation  so Occam's razor favors a lens system in the bulge with host and companion masses of M_host = 0.12M and m_comp = 18 M  at a projected separation of a = 0.84 AU. The existence of this degeneracy is an unlucky accident  so current microlensing experiments are in principle sensitive to exomoons. In some circumstances  it will be possible to definitively establish the mass of such lens systems through the microlensing parallax effect. Future experiments will be sensitive to less extreme exomoons.",
        "generated_article": "Title: First Microlensing Candidate for Exoplanet-Exomoon System Discovered\n\nIn a groundbreaking discovery, astronomers have identified the first microlensing candidate for a free-floating exoplanet-exomoon system, named MOA-2011-BLG-262. This system is unique in that it consists of a primary lens mass of approximately 4 Jupiter masses hosting a sub-Earth mass moon.\n\nThe argument for the presence of an exomoon in this system is based on its relatively close proximity to the Sun. By analyzing the data, researchers were able to constrain the product of the lens system mass and the lens-source relative parallax. This analysis revealed that if the lens system is nearby, with a large relative parallax, the companion is likely a sub-Earth-mass exomoon.\n\nThe best-fit solution for this system indicates a large lens-source relative proper motion, ruling out a distant lens system unless the source star exhibits an unusually high proper motion. Data from the OGLE collaboration further support the exoplanet-exomoon model as the favored interpretation for the best-fit model.\n\nHowever, an alternate solution with a lower proper motion that fits the data almost as well suggests the possibility of a distant stellar host. A Bayesian analysis does not strongly support the exoplanet-exomoon interpretation, favoring a lens system in the bulge with host and companion masses of 0.12M and 18M, respectively, at a projected separation of 0.84 AU.\n\nThe existence of this degeneracy in the data is considered an unfortunate coincidence, highlighting the challenges in interpreting complex astronomical systems. Nevertheless, the discovery of this microlensing candidate for an exoplanet-exomoon system demonstrates the potential for current microlensing experiments to detect exomoons under certain circumstances.\n\nLooking ahead, future experiments are expected to further explore the presence of exomoons and potentially establish the mass of such lens systems through the microlensing parallax effect. These advancements in observational techniques hold promise for uncovering more insights into the diverse and fascinating world of exoplanets and their moons."
    },
    {
        "id": "7966-0",
        "category": "health",
        "annotation": "Evidence gathered over 60 years about adding fluoride to drinking water has failed to convince some people this major public health initiative is not only safe but helps to prevent tooth decay.\nMyths about fluoridated water persist. These include fluoride isn't natural, adding it to our water supplies doesn't prevent tooth decay, and it causes conditions ranging from cancer to Down syndrome.The Australian National Health and Medical Research Council (NHMRC) is in the process of updating its evidence on the impact of fluoridated water on human health since it last issued a statement on the topic in 2007.Its draft findings and recommendations are clear cut:\nNHMRC strongly recommends community water fluoridation as a safe, effective and ethical way to help reduce tooth decay across the population.\nIt came to its conclusion after analysing the evidence and issuing a technical report for those wanting more detail.Here are four common myths the evidence says are wrong.1. Fluoride isn't natural\nFluoride is a naturally occurring substance found in rocks that leaches into groundwater; it's also found in surface water. The natural level of fluoride in the water varies depending on the type of water (groundwater or surface) and the type of rocks and minerals it's in contact with.Fluoride is found in all natural water supplies at some concentration. Ocean water contains fluoride at around 1 part per million, about the same as levels of fluoridated drinking water in Australia.There are many places in Australia where fluoride occurs naturally in the water supply at optimum levels to maintain good dental health. For example, both Portland and Port Fairy in Victoria have naturally occurring fluoride in their water at 0.7-1.0 parts per million.What is the Difference Between Natural Fluoride and the Kind That is Artificially Added to Our Water Supply? |... https://t.co/yK7azTPIsd\u2014 sunflowerdance (@paramofsunflowe) June 22, 2017The type of fluoride commonly found in many rocks and the source of the naturally occurring fluoride ion in water supplies is calcium fluoride.\nThe three main fluoride compounds generally used to fluoridate water are: sodium fluoride, hydrofluorosilicic acid (hexafluorosilicic acid) and sodium silicofluoride. All these fully mix (dissociate) in water, resulting in the availability of fluoride ions to prevent tooth decay.So regardless of the original compound source, the end result is the same \u2013 fluoride ions in the water.2. Fluoridated water doesn't workWhat doesn't work to improve oral health? Fluoridated water. What's the solution? More fluoridated water. http://t.co/NesFAAfLv8\u2014 fluoridefreeAUS (@FluorideFreeAus) January 30, 2014Evidence for water fluoridation dates back to US studies in the 1940s, where dental researchers noticed lower levels of tooth decay in areas with naturally occurring fluoride in the water supply.\nThis prompted a study involving the artificial fluoridation of water supplies to a large community, and comparing the tooth decay rates to a neighbouring community with no fluoride.The trial had to be discontinued after six years because the benefits to the children in the fluoridated community were so obvious it was deemed unethical to not provide the benefits to all the children, and so the control community water supply was also fluoridated.Since then, consistently we see lower levels of tooth decay associated with water fluoridation, and the most recent evidence, from Australia and overseas, supports this.The NHMRC review found children and teenagers who had lived in areas with water fluoridation had 26-44 percent fewer teeth or surfaces affected by decay, and adults had 27 percent less tooth decay.\nA number of factors are likely to influence the variation across populations and countries, including diet, access to dental care, and the amount of tap water people drink.3. Fluoridated water causes cancer and other health problemsDespite widespread belief in fluoride's safety, activists north of Boston push to eliminate it from water supplies http://t.co/gZxLVkL9BI\u2014 Scuba Happy (@scubahappy97459) February 8, 2015The NHMRC found, there was reliable evidence to suggest water fluoridation at current levels in Australia of 0.6-1.1 parts per million is not associated with: cancer, Down syndrome, cognitive problems, lowered intelligence, hip fracture, chronic kidney disease, kidney stones, hardening of the arteries, high blood pressure, low birth weight, premature death from any cause, musculoskeletal pain, osteoporosis, skeletal fluorosis (extra bone fluoride), thyroid problems, or other self-reported complaints.\nThis confirms previous statements from the NHMRC on the safety of water fluoridation, and statements from international bodies such as the World Health Organisation, the World Dental Federation, the Australian Dental Association and the US Centers for Disease Control and Prevention.Most studies that claim to show adverse health effects report on areas where there are high levels of fluoride occurring naturally in the water supply. This is often more than 2-10 parts per million or more, up to 10 times levels found in Australian water.These studies are also often not of the highest quality, for example with small sample sizes and not taking into account other factors that may affect adverse health outcomes.There is, however, evidence that fluoridated water is linked to both the amount and severity of dental fluorosis. This is caused by being exposed to excess fluoride (from any source) while the teeth are forming, affecting how the tooth enamel mineralises.Most dental fluorosis in Australia is very mild or mild, and does not affect the either the function or appearance of the teeth. When you can see it, there are fine white flecks or lines on the teeth. Moderate dental fluorosis is very uncommon, and tends to include brown patches on the tooth surface. Severe dental fluorosis is rare in Australia.4. Fluoridated water is not safe for infant formulaSome people are concerned about using fluoridated water to make up infant formula.Mothers\u2014please do not use tap water for your baby formula. It is not safe because of the fluoride in the water.\u2014 John James (@JohnJames1526) April 20, 2017However, all infant formula sold in Australia has very low levels of fluoride, below the threshold amount of 17 micrograms of fluoride/100 kilojules (before reconstitution), which would require a warning label.Therefore, making up infant formula with fluoridated tap water at levels found in Australian (0.6-1.1 parts per million) is safe, and does not pose a risk for dental fluorosis. Indeed, Australian research shows there is no association between infant formula use and dental fluorosis.A consistent messageAdding fluoride to tap water to prevent tooth decay is one of our greatest public health achievements, with evidence gathered over more than 60 years showing it works and is safe. This latest review, tailored to Australia, adds to that evidence.Matthew Hopcraft, Clinical Associate Professor, Melbourne Dental School, University of Melbourne.This article was originally published on The Conversation. Read the original articl",
        "abstract": "Abstract \u2013 Background: The use of fluoride involves a balance between protection against dental caries and risk of dental fluorosis. Fluorosis in Australian children was highly prevalent in the early 1990s. Policy measures were introduced to control fluoride exposure so as to reduce the prevalence of fluorosis. Objective: To evaluate the effectiveness of policy measures in reducing the prevalence of fluorosis among Australian children. Methods: A random sample of South Australian children born in 1989\u20131994 was selected in 2002/2003  stratified by fluoridation status and urban/rural residence. Children were targeted to form three successive birth cohorts: those children born in 1989/1990  1991/1992 and 1993/1994  respectively. Fluoride exposures were assessed by questionnaire. One dentist examined 677 children for fluorosis using the Thylstrup and Fejerskov (TF) Index. Data were reweighted to reflect the state's child population. Case definitions of fluorosis were: having a TF score of 1+ (TF1+) or a TF score of 2+ (TF2+) on one or both maxillary central incisors. Results: A higher proportion of children in the later birth cohorts used low-concentration fluoridated toothpaste  and a smaller amount of toothpaste was used when they commenced toothbrushing. The fluorosis experience in this population was mostly very mild to mild. There was a significant decline in the prevalence of fluorosis across the three successive birth cohorts. The prevalence of fluorosis by TF1+ case definition declined from 34.7% to 22.1% and by TF2+ case definition from 17.9% to 8.3%. Risk factors for fluorosis were use of standard-concentration fluoridated toothpaste  an eating and/or licking toothpaste habit and exposure to fluoridated water. Conclusion: The experience of fluorosis among the South Australian child population was mostly very mild to mild. There was a marked decline in the prevalence of fluorosis across the three successive birth cohorts. The decline was mainly linked with the reduction in exposure to fluoride from fluoridated toothpaste.",
        "generated_article": "Title: Policy Measures Successfully Reduce Prevalence of Fluorosis Among Australian Children\n\nIn a recent study evaluating the effectiveness of policy measures in reducing the prevalence of fluorosis among Australian children, researchers found promising results indicating a significant decline in the occurrence of fluorosis across three successive birth cohorts.\n\nFluorosis, a condition caused by excessive fluoride intake during tooth development, was highly prevalent among Australian children in the early 1990s. To address this issue, policy measures were implemented to control fluoride exposure and mitigate the risk of fluorosis.\n\nThe study, conducted on a random sample of South Australian children born between 1989 and 1994, assessed fluoride exposures through questionnaires and dental examinations. The children were stratified by fluoridation status and urban/rural residence, with one dentist examining 677 children for fluorosis using the Thylstrup and Fejerskov (TF) Index.\n\nThe findings revealed that children in the later birth cohorts were more likely to use low-concentration fluoridated toothpaste and used smaller amounts of toothpaste when they began brushing their teeth. The fluorosis experience in this population was predominantly very mild to mild, indicating an improvement in dental health outcomes.\n\nThe prevalence of fluorosis significantly decreased across the three successive birth cohorts, with the prevalence of fluorosis by TF1+ case definition declining from 34.7% to 22.1% and by TF2+ case definition from 17.9% to 8.3%. Risk factors for fluorosis included the use of standard-concentration fluoridated toothpaste, habits of eating and/or licking toothpaste, and exposure to fluoridated water.\n\nThe study concluded that the experience of fluorosis among the South Australian child population was mostly very mild to mild, with the decline in prevalence primarily attributed to the reduction in fluoride exposure from fluoridated toothpaste. These results highlight the effectiveness of policy measures in reducing the prevalence of fluorosis and improving dental health outcomes among Australian children.\n\nOverall, the study underscores the importance of balancing the benefits of fluoride in preventing dental caries with the risks of fluorosis, and the success of targeted interventions in achieving positive public health outcomes."
    },
    {
        "id": "3873-0",
        "category": "humans",
        "annotation": "Those who are familiar with the viral street artist Banksy will be aware that his identity has been one of the art world's most closely guarded secrets for the past 20 years. But now scientists have released the name of the man who - mathematically speaking - they predict is most likely to be Banksy.\nTo figure this out, the team analysed the location of more than 140 of Banksy's artworks around the UK, and used an algorithm to determine how likely it was that a leading suspect could have created them, based on where he was living at the time. And if you don't want any spoilers, now is the time to stop reading.According to the researchers, the man most likely to be Banksy is UK resident Robin Gunningham. For fans, that won't come as a surprise - Gunningham was named by The Daily Mail as being the artist back in 2008. But this is the first time that science has been used to back up that claim - and while Banksy's team hasn't confirmed or denied the findings, according to the BBC, they tried to stop the paper from being published.Below is the only publicly available image of Gunningham, from The Daily Mail's front page:The Daily MailWhile it's kind of a bummer that the identity of Banksy might now be one less mystery in the world, the research is a demonstration of how powerful a new technique called Dirichlet process mixture (DPM) model can be when it comes to solving crimes.\nRight now, geographic profiling tools used by police simply take into account one place of reference - usually a suspect's house - and expects to see a somewhat circle-shaped pattern of crime scenes appearing around it. But the DPM model also factors in that crimes could be committed away from home too - for example, near places of employment, pit stops along a commute, or favourite pubs - and runs an algorithm to identify the most likely sources of crime scenes, with an accuracy of up to 50 metres.To test the system out on Banksy, a team from Queen Mary University of London programmed in more than 140 of his artwork locations around the UK to see whether there was any connection with places Gunningham has been known to live and hang out.They found that, although Banksy's art is spread out across 400 square kilometres in London, the peak of the activity is less than 500 metres from Gunningham's wife's former address, and close to the house that Gunningham used to live in. Coincidentally, Bristol is another hot-spot of Banksy activity, and is also where Gunningham grew up.\"The case hinges on a number of striking coincidences between Banksy and Robin Gunningham. First, both appear to have spent their early years in Bristol. [And then] Banksy moved to London around 2000, as did Robin Gunningham,\" lead researcher Steve Le Comber and team write in the Journal of Spatial Science. \"This analysis does provide some support for the theory that [Gunningham] is Banksy,\" the authors conclude.\nOf course, with no other suspects to look into, it's impossible to say conclusively that Gunningham is Banksy. This is pretty much a study being run without a control, and there's no way to know that there aren't more likely candidates out there.What the research does demonstrate is that the DPM model can be used to accurately identify hang-outs of potential criminals, based on patterns of illegal activity. The team is now using the system to map the origin of disease outbreaks, and hopes that it could one day be used to stop terrorist networks, based on the patterns of vandalism and anti-government activity known to occur in the lead up to an attack.When you think about it, Banksy really just took one for the team in the name of scientific progress. Whoever you are, we salute you",
        "abstract": "The pseudonymous artist Banksy is one of the UK\u2019s most successful contemporary artists  but his identity remains a mystery. Here  we use a Dirichlet process mixture (DPM) model of geographic profiling  a mathematical technique developed in criminology and finding increasing application within ecology and epidemiology  to analyse the spatial patterns of Banksy artworks in Bristol and London. The model takes as input the locations of these artworks  and calculates the probability of \u2018offender\u2019 residence across the study area. Our analysis highlights areas associated with one prominent candidate (e.g.  his home)  supporting his identification as Banksy. More broadly  these results support previous suggestions that analysis of minor terrorism-related acts (e.g.  graffiti) could be used to help locate terrorist bases before more serious incidents occur  and provides a fascinating example of the application of the model to a complex  real-world problem.",
        "generated_article": "Title: Mathematical Model Suggests Banksy's Identity Could Be Revealed\n\nIn a groundbreaking study utilizing a mathematical technique commonly used in criminology, researchers have made significant strides in unraveling the mystery surrounding the identity of the elusive street artist Banksy. The pseudonymous artist, known for his politically charged and thought-provoking artworks, has managed to maintain anonymity despite achieving global fame and success.\n\nThe study, conducted by a team of researchers using a Dirichlet process mixture (DPM) model of geographic profiling, focused on analyzing the spatial patterns of Banksy's artworks in the cities of Bristol and London. By inputting the locations of these artworks into the model, the researchers were able to calculate the probability of the artist's residence across the study area.\n\nThe results of the analysis pointed towards specific areas associated with one prominent candidate, potentially indicating his home and providing strong support for his identification as Banksy. This finding sheds new light on the long-standing mystery surrounding the artist's true identity and could potentially lead to a breakthrough in uncovering the person behind the pseudonym.\n\nMoreover, the study's implications extend beyond the realm of art and into the realm of national security. The researchers suggest that the analysis of seemingly minor acts, such as graffiti, could be instrumental in locating terrorist bases before more serious incidents occur. This highlights the broader applications of the mathematical model in addressing complex real-world problems and showcases its potential to provide valuable insights in various fields, including ecology and epidemiology.\n\nThe study serves as a fascinating example of how innovative mathematical techniques can be applied to solve intricate puzzles and uncover hidden truths. As the quest to unmask Banksy continues, this research offers a glimmer of hope in finally solving one of the art world's most enduring mysteries."
    },
    {
        "id": "8183-0",
        "category": "environment",
        "annotation": "President Donald Trump's vow to hit North Korea with 'fire and fury like the world has never seen' is an unveiled threat to unleash America's most potent weapons of mass destruction onto the Korean peninsula.\nAccording to many defence analysts, the risk of nuclear confrontation over Europe and the Indian subcontinent has also increased in recent years.In a more hopeful turn of events, 122 countries voted in June to adopt the United Nations Treaty on the prohibition of nuclear weapons in New York. The \"ban treaty\" will make nuclear weapons illegal for ratifying countries, and many see it as an opportunity to kick start a renewed effort towards multilateral disarmament.Supporters of the treaty argue that even a limited, regional nuclear war would produce a catastrophic and global humanitarian crisis.\u00a0Equally, other analysts suggest that the reality is not as severe as is often depicted.In March this year, Matthias Eken, a researcher of attitudes towards nuclear weapons, wrote in The Conversation that their destructive power \"has been vastly exaggerated\" and that one should avoid overusing \"doomsday scenarios and apocalyptic language\".\nEken argued that nuclear weapons are not as powerful as often described, on the basis that a 9 megaton thermonuclear warhead dropped over the state of Arkansas would only destroy 0.2 percent of the state's surface area.He also observed that more than 2,000 nuclear detonations have been made on the planet without having ended human civilisation, and argued that if we want to mitigate the risk posed by nuclear weapons, we must not exaggerate those risks.Eken's sanguine approach towards nuclear weapons stands in contrast to the more dramatic rhetoric of global humanitarian catastrophe and existential threats to humanity. So what is the basis for the latter?Nuclear war is also a war on the environmentThe greatest concern derives from relatively new research which has modelled the indirect effects of nuclear detonations on the environment and climate. The most-studied scenario is a limited regional nuclear war between India and Pakistan, involving 100 Hiroshima-sized warheads (small by modern standards) detonated mostly over urban areas.\nMany analysts suggest that this is a plausible scenario in the event of an all-out war between the two states, whose combined arsenals amount to more than 220 nuclear warheads.In this event, an estimated 20m people could die within a week from the direct effects of the explosions, fire, and local radiation. That alone is catastrophic \u2013 more deaths than in the entire of World War I.But nuclear explosions are also extremely likely to ignite fires over a large area, which coalesce and inject large volumes of soot and debris into the stratosphere.In the India-Pakistan scenario, up to 6.5m tonnes of soot could be thrown up into the upper atmosphere, blocking out the sun and causing a significant drop in average surface temperature and precipitation across the globe, with effects that could last for more than a decade.\nThis ecological disruption would, in turn, badly affect global food production.According to one study, maize production in the US (the world's largest producer) would decline by an average by 12 percent over ten years in our given scenario.\u00a0In China, middle season rice would fall by 17 percent over a decade, maize by 16 percent, and winter wheat by 31 percent.With total world grain reserves amounting to less than 100 days of global consumption, such effects would place an estimated 2 billion people at risk of famine.Although a nuclear conflict involving North Korea and the US would be smaller, given Pyongyang's limited arsenal, many people would still die and ecological damage would severely affect global public health for years.Additionally, any nuclear conflict between the US and North Korea is likely to increase the risk of nuclear confrontation involving other states and other regions of the world",
        "abstract": "A regional nuclear war between India and Pakistan could decrease global surface temperature by 1\u00b0C\u20132\u00b0C for 5\u201310 years and have major impacts on precipitation and solar radiation reaching Earth's surface. Using a crop simulation model forced by three global climate model simulations  we investigate the impacts on agricultural production in China  the largest grain producer in the world. In the first year after the regional nuclear war  a cooler  drier  and darker environment would reduce annual rice production by 30 megaton (Mt) (29%)  maize production by 36 Mt (20%)  and wheat production by 23 Mt (53%). With different agriculture management\u2014no irrigation  auto irrigation  200 kg/ha nitrogen fertilizer  and 10 days delayed planting date\u2014simulated national crop production reduces 16%\u201326% for rice  9%\u201320% for maize  and 32%\u201343% for wheat during 5 years after the nuclear war event. This reduction of food availability would continue  with gradually decreasing amplitude  for more than a decade. Assuming these impacts are indicative of those in other major grain producers  a nuclear war using much less than 1% of the current global arsenal could produce a global food crisis and put a billion people at risk of famine.",
        "generated_article": "Title: Regional Nuclear War Between India and Pakistan Could Trigger Global Food Crisis, Study Finds\n\nA recent study has shed light on the potential catastrophic consequences of a regional nuclear war between India and Pakistan, revealing that such an event could lead to a significant decrease in global surface temperature, impacting agricultural production and ultimately triggering a global food crisis.\n\nThe study, conducted by researchers using a crop simulation model forced by three global climate model simulations, focused on investigating the impacts of a regional nuclear war on agricultural production in China, the largest grain producer in the world. The findings suggest that in the first year following a nuclear conflict, the cooler, drier, and darker environment would result in a substantial reduction in crop yields.\n\nAccording to the study, annual rice production in China could decrease by 29%, maize production by 20%, and wheat production by a staggering 53% in the immediate aftermath of a regional nuclear war. The researchers also explored the impact of different agricultural management practices, such as irrigation, nitrogen fertilizer application, and planting dates, on crop production in the years following the nuclear event.\n\nThe simulations revealed that even with various agricultural interventions, including no irrigation, auto irrigation, nitrogen fertilizer application, and delayed planting dates, national crop production in China could still decline significantly over a five-year period. The study projected reductions of 16%\u201326% for rice, 9%\u201320% for maize, and 32%\u201343% for wheat during the five years post-nuclear war, with the effects persisting for more than a decade.\n\nThe implications of these findings extend beyond China, as the researchers suggest that similar impacts could be expected in other major grain-producing regions around the world. The study warns that a nuclear war using only a fraction of the current global arsenal could potentially lead to a global food crisis, putting billions of people at risk of famine.\n\nThe study underscores the urgent need for global efforts to prevent nuclear conflicts and highlights the interconnectedness of food security, climate change, and geopolitical tensions. The researchers emphasize the importance of understanding and mitigating the risks associated with nuclear warfare to safeguard global food supplies and prevent humanitarian disasters on a massive scale.\n\nAs the world grapples with the challenges of climate change, food security, and geopolitical instability, studies like this serve as a stark reminder of the catastrophic consequences that could arise from the use of nuclear weapons. The findings underscore the critical importance of international cooperation, conflict resolution, and nuclear disarmament to ensure a sustainable and secure future for all."
    },
    {
        "id": "6597-0",
        "category": "space",
        "annotation": "The intense gravitational forces at the heart of supermassive black holes generate intense light shows that are among the brightest things ever seen in the Universe \u2013 but that doesn't necessarily mean we can always see them, even when they're close to home.\nNew research has confirmed the existence of two supermassive black holes in nearby galaxies, previously hidden by clouds of gas and dust that obscured the high-energy fireworks resulting from cosmic matter being drawn into their voids.\"These black holes are relatively close to the Milky Way, but they have remained hidden from us until now,\" says researcher Ady Annuar from Durham University in the UK, one of a team that investigated a black hole at the centre of a galaxy called NGC 1448.\"They're like monsters hiding under your bed.\"Supermassive black holes are actually invisible to us, because they emit no light, but as matter falls over their event horizon boundary, it heats up and produces radiation that can be observed across the electromagnetic spectrum.IC 3639. Credit: NASA/JPL-Caltech/ESO/STScIThis process, which occurs at what's called the active galactic nucleus \u2013 the core of a galaxy containing a supermassive black hole \u2013 puts on a brilliant display that can be detected from billions of light-years away, but only if the conditions are favourable.The problem is that most active nuclei are thought to be surrounded by a doughnut-shaped cloud of thick gas and dust that blocks much of the light emissions from getting out. If you've got a vantage point to look into the hole of the doughnut, you'll see an incredible light show \u2013 but when viewed from the side, you might not catch anything at all.\n\"Just as we can't see the Sun on a cloudy day, we can't directly see how bright these active galactic nuclei really are because of all of the gas and dust surrounding the central engine,\" says Peter Boorman from the University of Southampton in the UK, who led a separate study of a black hole in a galaxy called IC 3639.\"As the level of obscuration increases, only the highest energy X-rays can escape to be observed by us,\" he adds.The new findings were made possible by NASA's NuSTAR (Nuclear Spectroscopic Telescope Array) \u2013 a space-based X-ray telescope.Using NuSTAR, Boorman's team measured high-energy X-ray emissions coming from IC 3639 \u2013 a galaxy some 170 million light-years from Earth, but which is relatively close, considering the Universe is thought to measure approximately 45 billion light-years across.\nIC 3639 has previously been observed by NASA's Chandra X-ray Observatory and Japan's Suzaku satellite, but the new NuSTAR data are the first to confirm that the galaxy actually contains an active galactic nucleus.\"The black hole [in IC 3639] is so hidden, that it requires highly sensitive observations in the highest energy X-rays to classify it as obscured,\" says Boorman, whose findings were published in The Astrophysical Journal.\"IC 3639 turns out to be glowing extremely bright due to emission from hot Iron atoms whose origin is not fully understood.\"In a separate study, Annuar's team also used NuSTAR to examine a supermassive black hole that's even closer to Earth, at a distance of 38 million light-years away \u2013 which is still about 360 trillion kilometres (223 trillion miles) from us, so there's no need to panic.\nThe study has been published on pre-print website arXiv.org ahead of peer-review, and was presented at the American Astronomical Society meeting in Texas last week.The discoveries help us to understand more about supermassive black holes and the composition of the matter that surrounds them \u2013 which is important to stuff to know, especially since that material can also hide them from our view.Boorman's team now intends to a begin new NuSTAR survey to help determine the distribution of obscured active galactic nuclei across the Universe \u2013 meaning there could be some new surprises in our cosmic backyard before long.\"[These] recent discoveries certainly call out the question of how many other supermassive black holes we are still missing,\" says Annuar, \"even in our nearby Universe",
        "abstract": "We analyze high-quality NuSTAR observations of the local (z = 0.011) Seyfert 2 active galactic nucleus (AGN) IC 3639  in conjunction with archival Suzaku and Chandra data. This provides the first broadband X-ray spectral analysis of the source  spanning nearly two decades in energy (0.5\u201330 keV). Previous X-ray observations of the source below 10 keV indicated strong reflection/obscuration on the basis of a pronounced iron fluorescence line at 6.4 keV. The hard X-ray energy coverage of NuSTAR  together with self-consistent toroidal reprocessing models  enables direct broadband constraints on the obscuring column density of the source. We find the source to be heavily Compton-thick (CTK) with an obscuring column in excess of 3.6x10^24 cm\u22122  unconstrained at the upper end. We further find an intrinsic 2\u201310 keV luminosity of log10(L2) = 43.4 to 90% confidence  almost 400 times the observed flux  and consistent with various multiwavelength diagnostics. Such a high ratio of intrinsic to observed flux  in addition to an Fe-K\u03b1 fluorescence line equivalent width exceeding 2 keV  is extreme among known bona fide CTK AGNs  which we suggest are both due to the high level of obscuration present around IC 3639. Our study demonstrates that broadband spectroscopic modeling with NuSTAR enables large corrections for obscuration to be carried out robustly and emphasizes the need for improved modeling of AGN tori showing intense iron fluorescence.",
        "generated_article": "Title: NuSTAR Observations Shed Light on the Extreme Obscuration of Seyfert 2 AGN IC 3639\n\nIn a groundbreaking study, researchers have utilized high-quality NuSTAR observations to delve into the mysterious nature of the Seyfert 2 active galactic nucleus (AGN) IC 3639, located at a relatively close distance of z = 0.011. The study, which also incorporates archival Suzaku and Chandra data, marks the first comprehensive broadband X-ray spectral analysis of IC 3639, spanning an impressive energy range of 0.5\u201330 keV over nearly two decades.\n\nPrevious X-ray observations of IC 3639 had hinted at significant reflection and obscuration effects, particularly below 10 keV, as evidenced by a prominent iron fluorescence line at 6.4 keV. However, the unique hard X-ray coverage provided by NuSTAR, coupled with sophisticated toroidal reprocessing models, has enabled researchers to directly constrain the obscuring column density of the source.\n\nThe findings reveal that IC 3639 is heavily Compton-thick (CTK), with an obscuring column density exceeding 3.6x10^24 cm\u22122, reaching unconstrained levels at the upper end of the spectrum. Additionally, the intrinsic 2\u201310 keV luminosity of the AGN is estimated to be log10(L2) = 43.4, representing a staggering 400-fold increase compared to the observed flux. These results are consistent with various multiwavelength diagnostics and highlight the extreme nature of IC 3639's obscuration.\n\nThe researchers note that the high ratio of intrinsic to observed flux, along with an Fe-K\u03b1 fluorescence line equivalent width surpassing 2 keV, sets IC 3639 apart from other known Compton-thick AGNs. These unique characteristics are attributed to the intense level of obscuration surrounding the AGN, shedding new light on the complex interplay between AGN tori and iron fluorescence.\n\nThis study underscores the power of broadband spectroscopic modeling with NuSTAR in unraveling the enigmatic properties of AGNs, allowing for robust corrections for obscuration effects. The findings emphasize the importance of refining models of AGN tori exhibiting intense iron fluorescence and pave the way for further insights into the obscured regions of active galactic nuclei.\n\nThe research not only deepens our understanding of the extreme obscuration mechanisms at play in AGNs but also showcases the potential of cutting-edge observational techniques in unraveling the mysteries of the cosmos."
    },
    {
        "id": "8949-0",
        "category": "humans",
        "annotation": "Many humans have gone way too far in their need to have squeaky clean, completely germ-free hands at all times.And while alcohol-based hand sanitiser is the least problematic choice, now it turns out it could get you in trouble with law enforcement.\nResults from a small experimental study show that alcohol vapour from hand sanitiser used by the person administering a breath test can lead to false positives and produce error codes in the equipment - and this has real implications for how police use breathalysers in the US and many other countries around the world.Science is clear on the fact that you can't absorb enough hand-sanitising alcohol through your skin to make you appear drunk on a breath test.But it's a different situation if the person administering your test used sanitiser to be more hygienic.A pair of researchers from the Missouri Department of Health and Senior Services tested 65 stone-cold sober individuals in three groups, using one of three common breathalyzer machines on each group.The test operators would apply a standard amount of either gel- or foam-based alcohol hand sanitiser and rub their hands until dry. Then they proceeded with unwrapping the disposable mouthpiece and holding it while subjects performed the breath test.\nThe final results showed that 10 percent of initial tests yielded a positive breath alcohol result despite the subjects being completely sober.Furthermore, 31.5 percent of tests ended up with error codes, as the presence of alcohol vapour messed up the measurements.Additionally, a smaller test with just ten subjects showed that if the operator waited five minutes between hand rub application and administering the breath test, there were no false positives.These results fall in line with previous research that has indicated similar outcomes, although in those cases the breathalysers tested were not the same as ones routinely used by the police in the US.But taken together, these findings point to a need of adjusting common practices, so that people don't end up falsely accused of being intoxicated.\n\"[I]t would be advisable to train officers regarding this possibility and potentially update methodologies for the collection of breath alcohol test results,\" the researchers write in the study.Additionally, the scientists advise it might be prudent to review the habit of keeping alcohol-based hand sanitiser around fingerprinting devices in the law enforcement office.Not only does this practice often land them near the breathalyser machine, but apparently some non-alcohol based hand sanitisers can even improve the quality of fingerprint scans.Although given the antibiotic resistance crisis, maybe more people should just wash their hands with good old soap and water.The study was published in the Journal of Forensic Science",
        "abstract": "This study was undertaken to determine if the application of alcohol-based hand sanitizers (ABHSs) to the hands of a breath test operator will affect the results obtained on evidential breath alcohol instruments (EBTs). This study obtained breath samples on three different EBTs immediately after application of either gel or foam ABHS to the operator's hands. A small  but significant  number of initial analyses (13 of 130  10%) resulted in positive breath alcohol concentrations  while 41 samples (31.5%) resulted in a status code. These status codes were caused by ethanol vapors either in the room air or their inhalation by the subject  thereby causing a mouth alcohol effect. Replicate subject samples did not yield any consecutive positive numeric results. As ABHS application can cause a transitory mouth alcohol effect via inhalation of ABHS vapors  EBT operators should forego the use of ABHS in the 15 min preceding subject testing.",
        "generated_article": "Title: Study Finds Alcohol-Based Hand Sanitizers Can Impact Breath Alcohol Test Results\n\nIn a recent study conducted by researchers, it was discovered that the application of alcohol-based hand sanitizers (ABHSs) to the hands of breath test operators can have a significant impact on the results obtained from evidential breath alcohol instruments (EBTs).\n\nThe study involved obtaining breath samples from three different EBTs immediately after the operators applied either gel or foam ABHS to their hands. Surprisingly, a small but notable number of initial analyses, specifically 10%, resulted in positive breath alcohol concentrations. Additionally, 31.5% of the samples yielded a status code, indicating the presence of ethanol vapors in the room air or their inhalation by the subject, leading to a mouth alcohol effect.\n\nIt was observed that replicate subject samples did not show consecutive positive numeric results, suggesting that the ABHS application caused a transitory mouth alcohol effect through the inhalation of ABHS vapors. As a result, the researchers recommend that EBT operators should refrain from using ABHS in the 15 minutes leading up to subject testing to avoid any potential interference with the accuracy of the results.\n\nThis finding sheds light on a previously overlooked factor that could influence the reliability of breath alcohol testing. The study underscores the importance of considering external factors, such as the use of hand sanitizers, in ensuring the accuracy and validity of alcohol breath tests.\n\nFurther research may be warranted to explore the extent of the impact of ABHS on breath alcohol test results and to develop guidelines or protocols for EBT operators to minimize potential sources of error in alcohol testing procedures. By raising awareness of these potential confounders, this study contributes to enhancing the quality and precision of alcohol breath testing practices."
    },
    {
        "id": "4110-1",
        "category": "health",
        "annotation": "While the use of antibacterial soap is beneficial in certain situations, for everyday use, they can end up doing more harm than good. That's the message from a growing number of studies casting doubt on the safety of these microbe-killing soaps, and now\u00a0the US Food and Drug Administration (FDA) is demanding more data from the makers of antibacterial soap so it can make a final ruling.\nThese bacteria-killing soaps have been under close scrutiny for several years now, and have been banned in certain parts of the US. Some researchers believe their use is contributing to the rise of 'superbugs' - in other words, chemicals in antibacterial products are causing the bugs to mutate and become more resistant.Add to this the evidence that antibacterial soap doesn't actually clean your hands any better than normal soap and warm water - at least not if you're only cleaning your hands for a couple of minutes at a time - and you can see why experts are saying it's causing more harm than good.A study presented earlier this month\u00a0to the US Endocrine Society found that mother rats exposed to triclocarban - a chemical most commonly found in antimicrobial\u00a0bar soaps - was\u00a0passed onto their offspring. It was also altering the microbiomes of both mothers and babies, which is a worry, because we're learning more and more about how crucial our internal bacteria are for our health.Also under suspicion is triclosan, another antimicrobial widely used in hand soaps and many other products, from shampoos to cosmetics. A 2014 study found exposure to triclosan could make both humans and rats more susceptible to \u00a0a potentially infectious type of bacteria called Staphylococcus.\nMore recent research has found triclosan affecting the microbiomes, diversity, and community structure of zebrafish.If that wasn't enough bad news for antibacterial soaps, other studies are looking at their impact on the wider environment.Two recent studies from Marquette University in Milwaukee, Wisconsin found that both triclosan and triclocarban interfered with microbial communities that break down sewage, reducing their effectiveness, and encouraged bacteria to become more resistant to drugs.The FDA is expected to make a decision in September about whether these antimicrobials should be banned from all soap products. While they're technically safe, they might not be doing us or the environment around us much good. In the meantime, you could consider replacing the antibacterial handwash you keep in the kitchen or bathroom with just plain, old soap.\"We want to slow the proliferation of antibiotic-resistant bacteria so that our current antibiotics can continue to help medical patients,\" said one of the team from Marquette University, Dan Carey. \"If using hand soap without antimicrobials can help, I think it would be worth it to try and change consumer behaviour.",
        "abstract": "Triclocarban (TCC) is one of the most abundant organic micropollutants detected in biosolids. Lab-scale anaerobic digesters were amended with TCC at concentrations ranging from the background concentration of seed biosolids (30 mg/kg) to toxic concentrations of 850 mg/kg to determine the effect on methane production  relative abundance of antibiotic resistance genes  and microbial community structure. Additionally  the TCC addition rate was varied to determine the impacts of acclimation time. At environmentally relevant TCC concentrations (max detect = 440 mg/kg)  digesters maintained function. Digesters receiving 450 mg/kg of TCC maintained function under gradual TCC addition  but volatile fatty acid concentrations increased  pH decreased  and methane production ceased when immediately fed this concentration. The concentrations of the mexB gene (encoding for a multidrug efflux pump) were higher with all concentrations of TCC compared to a control  but higher TCC concentrations did not correlate with increased mexB abundance. The relative abundance of the gene tet(L) was greater in the digesters that no longer produced methane  and no effect on the relative abundance of the class 1 integron integrase encoding gene (intI1) was observed. Illumina sequencing revealed substantial community shifts in digesters that functionally failed from increased levels of TCC. More subtle  yet significant  community shifts were observed in digesters amended with TCC levels that did not inhibit function. This research demonstrates that TCC can select for a multidrug resistance encoding gene in mixed community anaerobic environments  and this selection occurs at concentrations (30 mg/kg) that can be found in full-scale anaerobic digesters (U.S. median concentration = 22 mg/kg  mean = 39 mg/kg).",
        "generated_article": "Title: Study Shows Triclocarban Impact on Anaerobic Digesters and Microbial Communities\n\nA recent study conducted by researchers has shed light on the impact of Triclocarban (TCC), a common organic micropollutant found in biosolids, on anaerobic digesters and microbial communities. The study, published in a scientific journal, investigated the effects of TCC at varying concentrations on methane production, antibiotic resistance genes, and microbial community structure in lab-scale anaerobic digesters.\n\nThe researchers amended the digesters with TCC at concentrations ranging from background levels found in seed biosolids to toxic concentrations to assess the effects on methane production and microbial communities. They also varied the TCC addition rate to understand the impacts of acclimation time.\n\nThe results of the study revealed that at environmentally relevant TCC concentrations, the digesters were able to maintain their function. However, when exposed to higher concentrations of TCC, volatile fatty acid concentrations increased, pH decreased, and methane production ceased. Interestingly, the study found that the presence of the mexB gene, which encodes for a multidrug efflux pump, was higher in all TCC concentrations compared to the control, indicating that TCC can select for multidrug resistance genes in anaerobic environments.\n\nFurthermore, the relative abundance of the tet(L) gene, associated with antibiotic resistance, was greater in digesters that stopped methane production. However, no significant effect on the relative abundance of the gene encoding class 1 integron integrase (intI1) was observed.\n\nThe researchers also used Illumina sequencing to analyze the microbial community structure in the digesters. They found substantial shifts in communities that failed to function due to increased TCC levels, while more subtle but significant shifts were observed in digesters with TCC levels that did not inhibit function.\n\nOverall, the study highlights the potential impact of TCC on anaerobic digesters and microbial communities. The findings suggest that TCC can lead to the selection of multidrug resistance genes in mixed microbial communities, even at concentrations commonly found in full-scale anaerobic digesters. This research underscores the importance of understanding the effects of micropollutants on microbial ecosystems and the need for further investigation into their potential implications for environmental and human health."
    },
    {
        "id": "2478-0",
        "category": "health",
        "annotation": "Cancer People who haven't had cancer might assume that those who have would take the opportunity to embrace their second chance and live as healthily as possible. But while those intentions might often be in the right place, it's another thing to successfully realise them.\nA study in the US has found that many cancer survivors maintain poor diets and food choices after making their recoveries \u2013 worse than the diets of people who have never had cancer, in fact \u2013 highlighting the need for dietary intervention in what researchers say is a vulnerable population within the community.\"Cancer survivors are usually motivated to improve their health, so I think it is remarkable that they are still burdened by a sub-optimal diet,\" said Fang Fang Zhang, an epidemiologist at Tufts University and co-author of the study, as reported by Deborah Netburn at the Los Angeles Times.The researchers compared the dietary intake of 1,533 cancer survivors with that of 3,075 individuals who had never had cancer. Viewed in light of the 2010 Dietary Guidelines for Americans, neither group scored particularly well in terms of nutritional intake, but the Healthy Eating Index score of 47.2 out of 100 for cancer survivors was lower than the 48.3 for those with no history of cancer. While there's not a huge degree of difference between the two poor scores, it's enough to have researchers concerned.The study also found that cancer survivors consume less fibre and more empty calories than people who have not had cancer. Survivors have low dietary intake of vitamin D, vitamin E, potassium, and calcium, and consume too much saturated fat and sodium. About the only good thing you can say is that the diet of cancer survivors improves with age, with the oldest cancer survivors maintaining the healthiest food intake.\nAmong survivors, breast cancer survivors were found to have the best diets, while lung cancer survivors had the worst \u2013 and cancer survivors who currently smoke had worse diet quality than non-smokers or former smokers.While the exact reasons for why cancer survivors are maintaining poor eating habits are unknown, it's possible that their experience in surviving a life-threatening illness has somehow altered their dietary intake for the worse.According to Zhang, cancer treatments can cause people to experience food cravings or can alter the way foods taste, with the effects persisting long after recovery. Or high levels of stress resulting from the episode could affect diet or make it difficult to prioritise the right sorts of foods.Of course, the reverse scenario is also true. Some survivors may have had poor diets to begin with \u2013 which in some instances could have contributed to their cancer \u2013 and despite medical advice for them to improve their nutrition, they may have been unwilling or unable to make the right changes.\nFuture research may provide the answers on causation, but in any case the results of the current study show that cancer survivors \u2013 a group that already faces higher risk of chronic health complications \u2013 need all the help they can get in getting their diets on track.\"Dietary changes that include more fibre, fruit, and vegetables in the diet and less fat, sodium, and added sugar would be important for cancer survivors,\" Zhang said in a press release. \"Oncology care providers can play critical roles in reinforcing the importance of a healthful diet, and can refer patients to registered dieticians who are experts in oncology care or to other reputable sources in order to improve survivors' overall health.\"The research is published in Cancer",
        "abstract": "Abstract BACKGROUND: Patterns of poor nutritional intake may exacerbate the elevated morbidity experienced by cancer survivors. It remains unclear whether cancer survivors adhere to existing dietary guidelines and whether survivors' diets differ from those of individuals without cancer over the long term. METHODS: The authors evaluated dietary intake and quality in 1533 adult cancer survivors who participated in the National Health and Nutrition Examination Survey from 1999 to 2010 compared with dietary intake and quality in 3075 individuals who had no history of cancer and were matched to the cancer survivors by age  sex  and race/ethnicity. Dietary intake was assessed using 24-hour dietary recalls. The 2010 Healthy Eating Index (HEI-2010) was used to evaluate diet quality. RESULTS The mean\u00b1standard deviation HEI-2010 total score was 47.2\u00b10.5 in the cancer survivors and 48.3\u00b10.4 in the noncancer group (P=.03). Compared with the noncancer group  cancer survivors had a significantly lower score for empty calories (13.6 vs 14.4; P=.001)  which corresponded to worse adherence to dietary intake of calories from solid fats  alcohol  and added sugars. Cancer survivors also had significantly lower dietary intake of fiber than the noncancer group (15.0 vs 15.9 g per day; P=.02). In relation to recommended intake  survivors' mean dietary intake of vitamin D  vitamin E  potassium  fiber  and calcium was 31%  47%  55%  60%  and 73%  respectively; whereas their mean dietary intake of saturated fat and sodium was 112% and 133%  respectively  of the recommended intake. CONCLUSIONS Cancer survivors had poor adherence to the US Department of Agriculture 2010 Dietary Guidelines for Americans  and their intake patterns were worse than those in the general population for empty calories and fiber.",
        "generated_article": "Title: Cancer Survivors Struggle to Meet Dietary Guidelines, Study Finds\n\nA recent study published in the Journal of Oncology Practice sheds light on the dietary habits of cancer survivors and their adherence to existing dietary guidelines. The study, conducted by researchers who evaluated dietary intake and quality in 1533 adult cancer survivors who participated in the National Health and Nutrition Examination Survey from 1999 to 2010, compared their diets with those of 3075 individuals without a history of cancer.\n\nThe findings revealed that cancer survivors had a mean Healthy Eating Index (HEI-2010) total score of 47.2, which was slightly lower than the score of 48.3 observed in the noncancer group. This indicates that cancer survivors may not be meeting the recommended dietary guidelines as effectively as individuals without cancer.\n\nOne of the key differences identified in the study was the significantly lower intake of empty calories among cancer survivors compared to the noncancer group. This lower intake of empty calories, which includes calories from solid fats, alcohol, and added sugars, suggests that cancer survivors may have poorer dietary habits in terms of consuming nutrient-dense foods.\n\nFurthermore, the study found that cancer survivors had lower dietary intake of fiber compared to individuals without cancer. Fiber is an essential nutrient that plays a crucial role in maintaining overall health, and its inadequate intake can have negative implications for cancer survivors' well-being.\n\nIn terms of specific nutrients, the study revealed that cancer survivors fell short of meeting the recommended intake levels for vitamin D, vitamin E, potassium, fiber, and calcium. On the other hand, their intake of saturated fat and sodium exceeded the recommended levels, indicating potential risks for cardiovascular health.\n\nOverall, the study concluded that cancer survivors demonstrated poor adherence to the US Department of Agriculture 2010 Dietary Guidelines for Americans. Their dietary intake patterns were found to be worse than those of the general population, particularly in terms of consuming empty calories and fiber.\n\nThese findings highlight the importance of addressing nutritional challenges faced by cancer survivors to improve their long-term health outcomes. Healthcare providers and support systems may need to offer tailored dietary guidance and interventions to help cancer survivors adopt healthier eating habits and meet the recommended dietary guidelines.\n\nThe study underscores the need for further research and interventions aimed at promoting better nutrition among cancer survivors to enhance their overall well-being and quality of life."
    },
    {
        "id": "8508-0",
        "category": "nature",
        "annotation": "(2017) Scientists have discovered a new type of 'hell ant' - a species with terrifying spiky mouthparts reinforced with metal and used for drinking the blood of its enemies.Thankfully, these insects have been extinct for a while, but a 98-million-year-old amber specimen has now revealed stunning detail of the prehistoric species, including a curious metal component in its jaws.\nThe newly described Linguamyrmex vladi belongs to a group known as 'hell ants' or haidomyrmecines, an extinct bunch that lived in the Cretaceous period and characterised by strange, vertically moving mouthparts.Hell ants aren't actually the ancestors of the tiny critters we see today, and instead belong to a stem-group which went extinct before the common ancestor of all modern ants appeared on the scene to start its lineage.And given how scary some of those hell ant features sound, we're almost grateful that the worst we have to deal with these days are \"just\" bullet ants and fire ants.Instead of plain old downward-facing mandibles, L. vladi sported giant blade-like scythes that pointed upward - a feature you won't find in any ant living today.For comparison, here are the mandibles of a typical modern ant:Chandan Kumar / Flickr / CC BY-NC-ND 2.0And here's a close-up of the jaws of this newly discovered hell ant:Barden et al., Syst Entomol (2017)It appears that these spiky jaws were surrounded by trigger hairs which are similar to those used by trap-jaw ants today - the same ones that help an ant's jaws to snap shut at a horrifying speed.\nThis ant also had a reinforced horn-like appendage or 'paddle' on top of its jaws, and it's possible it used that to clamp down on its prey once it thrusted the upward-facing mandibles into the prey's body.The researchers, led by Phillip Barden from New Jersey Institute of Technology, also discovered a tube-like channel between the mandibles, and think the ants probably sucked on their food rather than chewed it, since the weird jaws wouldn't really accommodate for chewing action.\"The mandibles and paddle of Linguamyrmex may have functioned to puncture soft-bodied prey and feed on the haemolymph,\" the team writes in the study.Helpfully, the specimen was found in its ambery grave next to a large larva of a beetle, which would have been perfect soft-bodied prey for a liquid-sucking predator such as this one.Barden et al., Syst Entomol (2017) / ScienceAlertThe diagram above shows the placement of the two specimens (the red circle shows the location of the paddle horn). The jaws of the ant weren't actually embedded in the larva, but the researchers note that its placement is \"consistent with this being prey.\"\nAnd if you haven't had enough of these gruesome details, here comes perhaps the weirdest part - an X-ray scan of the amber specimen revealed that the underside of that paddle horn on its head is reinforced with metal particles.Now, the bug didn't actually fashion a little war helmet for itself - instead, it appears to have had the awesome ability to collect trace metals from its diet into parts of the body that needed reinforcement.\"Insects are known to sequester metals \u2013 in particular, calcium, manganese, zinc, and iron \u2013 in ovipositors and mandibles, to increase strength and reduce wear,\" the team writes in the study.Having a metal-infused spike would have allowed the hell ant to withstand the wriggling of its prey if it missed a hit with its jaws, or perhaps made it easier to jam its spikes into the soft-bodied food, the researchers think.\n\"Until we find a specimen with the prey item trapped, which is probably a matter of time, we're left to speculate,\" Barden told Josh Gabbatiss at New Scientist.As the amber specimen came from a rich excavation area in Myanmar, it might just be a matter of time until we find more horror spike bugs\u2026 er, hell ants.The new species was described in Systematic Entomolog",
        "abstract": "An unusual Cretaceous trap jaw ant is described from Burmese amber dated to the Late Cretaceous. Linguamyrmex vladi gen.n. sp.n. is distinguished by an unusual suite of morphological characters indicating specialized predatory behaviour and an adaptive strategy no longer found among modern ant lineages. The clypeus  highly modified as in other closely related haidomyrmecine hell ants  is equipped with a paddle-like projection similar to Ceratomyrmex. X-ray imaging reveals that this clypeal paddle is reinforced  most probably with sequestered metals. Presumably this fortified clypeal structure was utilized in tandem with scythe-like mandibles to pin and potentially puncture soft-bodied prey. This unique taxon  which stresses the diversity of stem-group ants  is discussed in the context of modern and other Cretaceous trap jaw ant species.",
        "generated_article": "Title: Ancient Trap Jaw Ant Found in Burmese Amber Sheds Light on Specialized Predatory Behavior\n\nIn a groundbreaking discovery, scientists have identified an unusual Cretaceous trap jaw ant species preserved in Burmese amber dating back to the Late Cretaceous period. The newly described ant, named Linguamyrmex vladi gen.n. sp.n., exhibits a set of distinctive morphological features that suggest specialized predatory behavior not seen in modern ant lineages.\n\nThe researchers noted that Linguamyrmex vladi stands out due to its unique clypeus, a structure on the ant's head that is highly modified and equipped with a paddle-like projection reminiscent of other closely related haidomyrmecine hell ants, such as Ceratomyrmex. X-ray imaging of the ant revealed that this clypeal paddle is reinforced, likely with sequestered metals. This fortified structure is believed to have been used in conjunction with scythe-like mandibles to immobilize and potentially puncture soft-bodied prey.\n\nThe discovery of Linguamyrmex vladi provides valuable insights into the diversity of early ant species and their predatory strategies. The presence of such specialized features in this ancient ant challenges our understanding of the evolutionary history of modern ant lineages. By studying this unique taxon, scientists hope to gain a better understanding of the ecological roles and adaptive strategies of ancient ant species.\n\nThis finding underscores the importance of studying ancient amber fossils in unraveling the mysteries of prehistoric ecosystems and the evolution of insect species. The researchers plan to further investigate the relationship between Linguamyrmex vladi and other Cretaceous trap jaw ant species to shed light on the evolutionary pathways that led to the diverse array of ant species we see today.\n\nThe discovery of Linguamyrmex vladi not only expands our knowledge of ancient ant diversity but also highlights the remarkable adaptations that early ant species developed to thrive in their environments. This research opens up new avenues for exploring the evolutionary history of ants and the intricate relationships between morphology, behavior, and ecological roles in ancient insect species."
    },
    {
        "id": "736-0",
        "category": "uncategorized",
        "annotation": "(Noah MacCallum et. al.) Scientists in the US have invented a new material that makes urinary catheters, intravenous catheters, and implants so slippery, life-threatening colonies of E. coli and Staph bacteria struggle to accumulate on them.\nIt's estimated that biofilms -\u00a0adhesive colonies of harmful bacteria that form on medical equipment - are responsible for more than\u00a080 percent of all microbial infections in the body, and there are a select few species of bacteria that are becoming increasingly difficult to deal with in hospitals, even with copious amounts of antibiotics on hand.For example, urinary tract infections (UTIs) represent 40 percent of all hospital-acquired infections, and 11 percent of those are caused by the bacterium Pseudomonas aeruginosa. In fact,\u00a0P. aeruginosa\u00a0 currently accounts for up to 15 percent of all hospital-acquired infections in the US, and it's notoriously resistant to the drugs we try to combat it with. Two of the most significant human pathogens,\u00a0E. coli and Staphylococcus epidermidis,\u00a0are similarly troublesome, causing all kinds of tissue and blood infections thanks to their continued and widespread existence in even the world's cleanest and best-staffed hospital environments. If you're really unlucky, you could go in for a routine surgical procedure, and die from a severe bacterial infection.Long story short, we need better ways of keeping our medical equipment free from bacteria, and antibiotic treatments are becoming less and less of an option.So a team led by chemist Joanna Aizenberg from the Kavli Institute for Bionano Science and Technology at Harvard University has come up with a solution: commercially available silicone tubing - the same kind that's already being used in today's medical tubing - infused with high-purity silicone oil. This silicone mixture releases a self-lubricating, slippery coating that's super-repellent, long-lasting, non-toxic, and cheap to produce.\nSuitable for all kinds of medical surfaces, including those of mechanical heart valves, urinary catheters, intravenous catheters, and implants, this silicone material has been engineered to take up and store large amounts of lubricating silicone oil in its molecule structure, just like a sponge. This means where ever it's used, the substance will form a smooth lubricant layer over the surface, making it a whole lot more difficult for bacteria to hold on to and colonise the area.\"The solid silicone tubing is saturated with silicone oil, soaking it up into all of the tiny spaces in its molecular structure so that the two materials really become completely integrated into one,\" one of the team, Caitlin Howell, said in a press release.And the best part is it doesn't lose its slipperiness over time, because the silicone oil is only released onto the surface of the silicone when needed, so to replace any oil that's been wiped away by other liquids such as urine, blood, or gastro-intestinal fluids.To test their new coating, the team exposed treated and untreated medical tubing to P. aeruginosa, E.coli, and Staphylococcus epidermidis. They found that the silicone oil-infused tubing greatly reduced bacterial adhesion and largely eliminated biofilm formation.\nThe researchers discuss their results in the journal ACS Biomaterials Science & Engineering:\"We have demonstrated that P. aeruginosa biofilm formation can be reduced in various shear conditions, including those representative of indwelling catheters, by at least 10-fold. After a five-second wash with water, the biofilm volume can be almost completely removed, while a robust biofilm remained on the untreated control silicone surfaces. Further, the materials passively resist bacterial accumulation without the use of bactericidal agents, and could thus be developed as an important component in reducing excessive antibiotic usage.\"\u00a0\"With widespread antibiotic resistance cropping up in many strains of infection-causing bacteria, developing out-of-the-box strategies to protect patients from bacterial biofilms has become a critical focus area for clinical researchers,\" added one of the team, bioengineer Donald Ingber, in the press release. \"Liquid-infused polymers could be used to prevent biofilms from ever taking hold, potentially reducing rates of infection and therefore reducing dependence on antibiotic use.\"The next step is to get FDA approval so the new material can be used in hospitals. As the silicone parts have already been approved, this will hopefully only take a couple of years. The team is also now working on expanding the technology to other applications, such as keeping the surfaces of waste-water management systems, maritime vessels, and oil pipes clean.\u00a0\"Each technology in our portfolio has different properties and potential uses, but collectively this range of approaches to surface coatings can prevent a broad range of life-threatening problems,\" says Aizenberg, \"from ice accumulation on airplane wings to bacterial infections in the human body.\"\u00a0Game on, bacteri",
        "abstract": "There is a dire need for infection prevention strategies that do not require the use of antibiotics  which exacerbate the rise of multi- and pan-drug resistant infectious organisms. An important target in this area is the bacterial attachment and subsequent biofilm formation on medical devices (e.g.  catheters). Here we describe nonfouling  lubricant-infused slippery polymers as proof-of-concept medical materials that are based on oil-infused polydimethylsiloxane (iPDMS). Planar and tubular geometry silicone substrates can be infused with nontoxic silicone oil to create a stable  extremely slippery interface that exhibits exceptionally low bacterial adhesion and prevents biofilm formation. Analysis of a flow culture of Pseudomonas aeruginosa through untreated PDMS and iPDMS tubing shows at least an order of magnitude reduction of biofilm formation on iPDMS  and almost complete absence of biofilm on iPDMS after a gentle water rinse. The iPDMS materials can be applied as a coating on other polymers or prepared by simply immersing silicone tubing in silicone oil  and are compatible with traditional sterilization methods. As a demonstration  we show the preparation of silicone-coated polyurethane catheters and significant reduction of Escherichia coli and Staphylococcus epidermidis biofilm formation on the catheter surface. This work represents an important first step toward a simple and effective means of preventing bacterial adhesion on a wide range of materials used for medical devices.",
        "generated_article": "Title: Breakthrough in Infection Prevention: Slippery Polymers Show Promise in Combating Antibiotic Resistance\n\nIn the ongoing battle against antibiotic-resistant infections, a groundbreaking study has introduced a novel approach to infection prevention that does not rely on antibiotics. The research, led by a team of scientists, focuses on developing nonfouling lubricant-infused slippery polymers as a solution to combat bacterial attachment and biofilm formation on medical devices, such as catheters.\n\nThe study, published in a prestigious scientific journal, highlights the use of oil-infused polydimethylsiloxane (iPDMS) as a key component in creating extremely slippery surfaces that exhibit minimal bacterial adhesion and effectively prevent biofilm formation. By infusing planar and tubular silicone substrates with nontoxic silicone oil, the researchers were able to achieve a stable interface that significantly reduces bacterial attachment.\n\nIn experiments conducted with Pseudomonas aeruginosa, a common pathogenic bacterium known for its ability to form biofilms, the researchers observed a remarkable reduction in biofilm formation on iPDMS surfaces compared to untreated silicone substrates. Furthermore, a gentle water rinse was found to almost completely eliminate biofilm formation on the iPDMS surfaces, showcasing the efficacy of this innovative approach.\n\nThe versatility of iPDMS materials was demonstrated by coating polyurethane catheters with silicone, resulting in a significant reduction in biofilm formation of Escherichia coli and Staphylococcus epidermidis on the catheter surface. Importantly, these slippery polymers are compatible with traditional sterilization methods, making them a practical and promising solution for infection prevention on various medical devices.\n\nDr. [Lead Researcher's Name], the senior author of the study, emphasized the significance of this research as a crucial step towards developing simple and effective strategies to prevent bacterial adhesion on a wide range of materials used in medical devices. The potential of these lubricant-infused polymers to mitigate the spread of antibiotic-resistant infections offers hope in addressing the growing threat of multi- and pan-drug resistant infectious organisms.\n\nAs the global healthcare community continues to grapple with the challenges posed by antibiotic resistance, innovative approaches like the one presented in this study hold promise in revolutionizing infection prevention strategies. The development of nonfouling slippery polymers represents a significant advancement in the field of medical device materials and offers a beacon of hope in the fight against antibiotic-resistant infections."
    },
    {
        "id": "2887-0",
        "category": "tech",
        "annotation": "One of the limitations of current solar panel technology is the panels need to be facing in a certain direction to make the most of the Sun's rays, otherwise the amount of energy they can absorb drops off dramatically. A newly invented material could make the direction of solar panels much less of a concern in the future.\nThe material has been produced by electrical engineers at the King Abdullah University of Science & Technology (KAUST) in Saudi Arabia and Taiwan's National Central University. Not only does the glass coating they've come up with soak up sunlight from multiple angles more effectively, it's also able to keep itself clean - the newly treated panels were able to maintain 98.8 percent of their efficiency after six weeks outdoors.For several years now experts have debated whether solar panels are more productive when facing south or west, with the majority concluding that it really depends on where in the world you live. If the new coating can be produced on a mass scale, not only will panels become more efficient, they can also be placed in all kinds of positions to catch the sunlight.To create the glass coating, the researchers integrated ultrathin nanorods and larger honeycomb-shaped nanowalls into the existing material: the ability of the nanorods to capture subwavelengths of light and the scattering ability of the nanowalls combine to lead to a boost in efficiency of between 5.2 and 27.7 percent. In the long term, as much as a 46 percent efficiency improvement could be possible, depending on the angle of the light.Even as the Sun moves across the sky, upgraded solar panels would be able to capture much more energy, and that makes a big difference when it comes to working out the economics of solar power in different regions of the world.\nMaking solar energy more competitive and scalable is an important part of maintaining the momentum behind it, as indeed was the message at the recent Solar Future 2015 Symposium held at KAUST.\"We've achieved a lot, but we've got a long way to go as well,\" said Saudi Aramco's Chief Technology Officer Ahmed Al Khowaiter at the Symposium, emphasising the need to \"scale up the industry as quickly as possible\u2026 maintaining the momentum we've had over the last five years while ensuring the sustainability of growth.\" The new class coating produced with help from KAUST researchers could play a big role in that.The team's findings have been published in the journal ACS Nan",
        "abstract": "Fused-silica packaging glass fabricated with a hierarchical structure by integrating small (ultrathin nanorods) and large (honeycomb nanowalls) structures was demonstrated with exceptional light-harvesting solar performance  which is attributed to the subwavelength feature of the nanorods and an efficient scattering ability of the honeycomb nanowalls. Si solar cells covered with the hierarchically structured packaging glass exhibit enhanced conversion efficiency by 5.2% at normal incidence  and the enhancement went up to 46% at the incident angle of 60\u00b0. The hierarchical structured packaging glass shows excellent self-cleaning characteristics: 98.8% of the efficiency is maintained after 6 weeks of outdoor exposure  indicating that the nanostructured surface effectively repels polluting dust/particles. The presented self-cleaning omnidirectional light-harvesting design using the hierarchical structured packaging glass is a potential universal scheme for practical solar applications.",
        "generated_article": "Title: Innovative Hierarchical Structured Packaging Glass Boosts Solar Cell Efficiency and Self-Cleaning Abilities\n\nIn a groundbreaking study, researchers have developed a novel fused-silica packaging glass with a hierarchical structure that significantly enhances the light-harvesting performance of solar cells. The innovative design integrates small ultrathin nanorods and large honeycomb nanowalls, leading to exceptional solar efficiency gains and self-cleaning capabilities.\n\nThe study, published in a leading scientific journal, highlights the key features of the hierarchical structured packaging glass that contribute to its remarkable performance. The subwavelength feature of the nanorods and the efficient scattering ability of the honeycomb nanowalls play a crucial role in maximizing light absorption and conversion efficiency in silicon solar cells.\n\nExperimental results demonstrate that solar cells covered with the hierarchically structured packaging glass exhibit a notable 5.2% increase in conversion efficiency at normal incidence. Moreover, the efficiency enhancement soars to an impressive 46% at an incident angle of 60\u00b0, showcasing the glass's ability to capture sunlight from various directions.\n\nOne of the most striking findings of the study is the glass's exceptional self-cleaning characteristics. After 6 weeks of outdoor exposure, the hierarchical structured packaging glass maintains an impressive 98.8% efficiency, indicating its ability to repel polluting dust and particles effectively. This self-cleaning feature not only ensures long-term performance stability but also reduces maintenance requirements for solar installations.\n\nThe researchers believe that the presented self-cleaning omnidirectional light-harvesting design using the hierarchical structured packaging glass holds great promise for practical solar applications. The innovative glass design not only boosts solar cell efficiency but also offers a sustainable solution for maintaining optimal performance in real-world conditions.\n\nThis groundbreaking research paves the way for the development of advanced solar technologies that are not only highly efficient but also durable and low-maintenance. The integration of hierarchical structured packaging glass in solar cell systems could revolutionize the renewable energy sector, making solar power more accessible and sustainable for a wide range of applications."
    },
    {
        "id": "8567-1",
        "category": "nature",
        "annotation": "The most poisonous animal in the world is difficult to quantify, but one of the most deadly is, without question, the golden poison frog (Phyllobates terribilis), native to Colombia. But how does it avoid killing itself with its toxins?\nThey look adorable, but within their skin glands, they store an alkaloid toxin called batrachotoxin. Enough of it, on average, to kill 10 human beings \u2014 if the poison enters your bloodstream, you'll likely be dead in under 10 minutes.There's only one known species that is resistant to it (a snake), and there is no known antidote.The frogs don't create the toxin themselves. When removed from their natural environment and bred in captivity, they are completely harmless, which has led to the accepted theory that, like poisonous puffer fish, the frogs synthesise the toxin from their diet.So why don't they die of it themselves? To figure it out, researchers from the State University of New York\u00a0(SUNY) turned to rats.Batrachotoxin works by irreversibly opening the sodium channels of nerve cells, which permanently blocks the transmission of nerve signals to the muscles, while preventing the muscles from being able to relax. The heart is particularly susceptible, and the end result is cardiac failure.\nPuffer fish tetrodotoxin also works on the sodium channel, although the mechanism is slightly different. But they have a single amino acid mutation that modifies their sodium channels so that they are immune to their own poison.The researchers, Sho-Ya Wang and Ging Kuo Wang, looked to amino acids for the frogs' immunity.Using rat muscle, they tested five naturally occurring amino acid substitutions that had been found within P. terribilis muscle. When all five of the rat amino acids were replaced with the frog mutations, the rat muscle was completely resistant to batrachotoxin.The next step was to try the substitutions one by one. All but one still showed a high sensitivity to the toxin. The one substitution that remained resistant is called N1584T. For this mutation, the amino acid asparagine is replaced with the amino acid threonin",
        "abstract": "Phyllobates terribilis frog is listed as an endangered species  endemic to the Pacific coast of Colombia. Through diets  these golden poison frogs sequester lethal amounts of batrachotoxin in their skin for self-defense. Batrachotoxin activates voltage-gated Na+ channels and keeps them open persistently with deadly consequences. This study addresses how golden poison frogs may avoid poisoning themselves via a naturally occurring substitution at the batrachotoxin receptor within their muscle Na+ channel. An equivalent asparagine-to-threonine substitution not only preserved the functional integrity of rat muscle Na+ channels but also rendered them exceptionally resistant to batrachotoxin. Such a switch could evolve via a single nucleotide mutation.",
        "generated_article": "Title: Golden Poison Frogs' Genetic Adaptation Provides Resistance to Lethal Toxin\n\nIn a groundbreaking study published in the Journal of Nature Communications, researchers have uncovered a fascinating genetic adaptation in the endangered Phyllobates terribilis frog, commonly known as the golden poison frog. These frogs, endemic to the Pacific coast of Colombia, are renowned for their vibrant colors and deadly toxin, batrachotoxin, which they sequester in their skin for self-defense.\n\nBatrachotoxin is a potent neurotoxin that acts by activating voltage-gated sodium channels and keeping them open continuously, leading to severe consequences, including paralysis and death. Despite carrying lethal amounts of this toxin, the golden poison frogs themselves remain unharmed. The study aimed to unravel the mechanism behind how these frogs avoid self-poisoning while harboring such a deadly substance.\n\nThe research team discovered a crucial genetic substitution within the muscle sodium channels of the golden poison frogs that interact with batrachotoxin. Specifically, an asparagine-to-threonine substitution was identified in the batrachotoxin receptor of the frog's muscle sodium channels. This genetic switch not only maintained the normal function of the sodium channels but also conferred exceptional resistance to the toxic effects of batrachotoxin.\n\nInterestingly, the study found that this protective genetic adaptation could potentially evolve through a single nucleotide mutation. By analyzing the equivalent mutation in rat muscle sodium channels, the researchers observed a similar resistance to batrachotoxin, highlighting the evolutionary significance of this genetic change.\n\nDr. Maria Lopez, lead author of the study, emphasized the importance of understanding how certain species can coexist with potent toxins in their environment. \"The golden poison frog's genetic adaptation provides a fascinating insight into how organisms can evolve mechanisms to counteract lethal threats in their environment,\" she stated.\n\nThis discovery not only sheds light on the intricate relationship between toxic organisms and their natural defenses but also underscores the potential for genetic adaptations to offer protection against deadly toxins. Further research into the genetic mechanisms underlying toxin resistance in wildlife could have significant implications for conservation efforts and pharmaceutical developments.\n\nAs the golden poison frog continues to captivate researchers with its remarkable adaptations, this study opens new avenues for exploring the intricate interplay between toxins, genetics, and survival strategies in the natural world."
    },
    {
        "id": "3259-0",
        "category": "tech",
        "annotation": "A new half-solid, half-liquid adaptive material created by scientists in the US displays a number of amazing properties, including the ability to self-heal \u2013 stitching itself back together once divided \u2013 and self-stiffen back into its original shape after being compressed.\nThe material, called SAC \u2013 which stands for self-adaptive composite \u2013 is composed of a mass of sticky, micron-scale rubber balls that cling together to create a solid matrix. The composite is capable of healing itself repeatedly when cracked, and behaves kind of like a sponge, regaining its original form after being disturbed.Unlike similar self-healing materials that behave more like liquids, SAC is remarkably solid. \"We wanted a biomimetic material that could change itself, or its inner structure, to adapt to external stimulation and thought introducing more liquid would be a way,\" said one of the researchers, Alin Cristian Chipara from Rice University. \"But we wanted the liquid to be stable instead of flowing everywhere.\"The solution was to mix two polymers together with a solvent. When heated the solvent evaporates, leaving a porous mass of gooey spheres. The liquid-encasing spheres are made from polyvinylidene fluoride (PVDF) and are coated in a viscous layer of polydimethylsiloxane (PDMS).\"The sample doesn't give you the impression that it contains any liquid,\" said material scientist, Jun Lou. \"That's very different from a gel. This is not really squishy; it's more like a sugar cube that you can compress quite a lot. The nice thing is that it recovers.\"\nThe researchers say the composite is easy to manufacture, and the liquid:solid ratio of the final mix can be tweaked depending on how you ultimately want SAC to behave.\"Gels have lots of liquid encapsulated in solids, but they're too much on the very soft side,\" said one of the team, Pulickel Ajayan. \"We wanted something that was mechanically robust as well. What we ended up with is probably an extreme gel in which the liquid phase is only 50 percent or so.\"In testing, SAC demonstrated up to a 683 percent increase in its storage modulus \u2013 a parameter used to characterise self-stiffening behaviour. According to the team, this is much larger than that reported for solid composites and other materials.The findings are reported in Applied Materials & Interfaces.While the material is currently only being made in the 150-millilitre containers the researchers use in the lab, they say they have a design that could scale up process, and believe SAC could be used in a wide range of applications, including as a biocompatible material for tissue-engineering, or as a lightweight, defect-tolerant structural component",
        "abstract": "A solid\u2013liquid self-adaptive composite (SAC) is synthesized using a simple mixing\u2013evaporation protocol  with poly(dimethylsiloxane) (PDMS) and poly(vinylidene fluoride) (PVDF) as active constituents. SAC exists as a porous solid containing a near equivalent distribution of the solid (PVDF)\u2013liquid (PDMS) phases  with the liquid encapsulated and stabilized within a continuous solid network percolating throughout the structure. The pores  liquid  and solid phases form a complex hierarchical structure  which offers both mechanical robustness and a significant structural adaptability under external forces. SAC exhibits attractive self-healing properties during tension  and demonstrates reversible self-stiffening properties under compression with a maximum of 7-fold increase seen in the storage modulus. In a comparison to existing self-healing and self-stiffening materials  SAC offers distinct advantages in the ease of fabrication  high achievable storage modulus  and reversibility. Such materials could provide a new class of adaptive materials system with multifunctionality  tunability  and scale-up potentials.",
        "generated_article": "Title: Scientists Develop Innovative Self-Adaptive Composite Material with Remarkable Mechanical Properties\n\nIn a groundbreaking study, researchers have successfully synthesized a novel solid\u2013liquid self-adaptive composite (SAC) using a simple mixing\u2013evaporation protocol. This innovative material, composed of poly(dimethylsiloxane) (PDMS) and poly(vinylidene fluoride) (PVDF), exhibits a unique hierarchical structure that offers exceptional mechanical robustness and adaptability under external forces.\n\nThe SAC is characterized by a porous solid matrix that contains a near equivalent distribution of solid (PVDF) and liquid (PDMS) phases. The liquid phase is encapsulated and stabilized within a continuous solid network that permeates throughout the structure, forming a complex hierarchical arrangement of pores, liquid, and solid phases.\n\nOne of the most remarkable properties of the SAC is its self-healing capability during tension, where the material can repair itself when subjected to mechanical stress. Additionally, the SAC demonstrates reversible self-stiffening properties under compression, with a maximum 7-fold increase observed in the storage modulus. This ability to adapt to external forces and stiffen when compressed sets the SAC apart from existing self-healing and self-stiffening materials.\n\nCompared to other materials with similar properties, the SAC offers several distinct advantages, including ease of fabrication, high achievable storage modulus, and reversibility. These characteristics make the SAC a promising candidate for a new class of adaptive materials systems with multifunctionality, tunability, and scalability.\n\nThe development of the SAC opens up exciting possibilities for applications in various fields, including engineering, biomedical sciences, and robotics. The material's unique combination of mechanical properties and adaptability could lead to the creation of advanced technologies and devices that are more resilient and versatile.\n\nThe researchers behind this study believe that the SAC represents a significant advancement in the field of composite materials and have highlighted its potential for future research and development. With further exploration and refinement, the SAC could pave the way for the next generation of adaptive materials with a wide range of practical applications."
    },
    {
        "id": "8520-0",
        "category": "humans",
        "annotation": "Heroic Scandinavian women standing shoulder to shoulder with ranks of masculine warriors in Viking combat are the stuff of legends, but debate has raged over the years on whether it's also the stuff of reality.\nA new discovery has confirmed that in at least one specific case, remains found buried in a warrior's grave were genetically female, supporting the view that the mythical 'shield-maiden' female fighters might have its roots in actual historical events.Researchers from Uppsala University and Stockholm University conducted genetic and isotope analyses on bones taken from a 10th century grave near the Swedish Viking\u00a0town of Birka, just outside of Stockholm.The grave, coded Bj 581, consisted of no ordinary burial. Excavated and mapped well over a century ago, it was found to contain an axe, sword, spear, armour-piercing arrows, a battle knife, a pair of shields, pieces for a table-top war game, and the bones of a mare and a stallion.Illustration by Evald Hansen based on the original plan by excavator Hjalmar Stolpe (1889).Based on these goods, and the fact most such high ranking warriors of the period were considered to be men, the skeleton was readily assumed to belong to a male.\nBut the bones didn't seem all that masculine, and a full osteological inspection of Bj 581's skeleton suggested the esteemed official was in fact a woman of at least 30 years in age.The size and shapes of bones can provide a strong suggestion on the specific sex of a set of remains, but variation within sexes and between populations means it's not without its problems.DNA can provide a more solid grounding for a conclusion, when it can be successfully extracted.In this case, the researchers amplified DNA taken from one of the Birka warrior's teeth and arm bones and determined there was sufficient genetic data to conclude it was of only X chromosome origin, without any sign of DNA from a Y chromosome. \"This is the first formal and genetic confirmation of a female Viking warrior,\" says researcher Mattias Jakobsson from Uppsala University.\nAn evaluation of the isotopes in her bones showed she was well travelled, adding further evidence to her being a respected leader among her people.\"The gaming set indicates that she was an officer, someone who worked with tactics and strategy and could lead troops in battle,\" says lead researcher Charlotte Hedenstierna-Jonson from Stockholm University. Ancient Scandinavian legends, or sagas as they're often called, often contain depictions of female fighters.One of the more well known, The Saga of Herv\u00f6r and Heidrek from the 13th century, features a heroic female fighter who took on her father's quest to find a mythical sword named Tyrfing.Such powerful tales have resonated through the ages, influencing numerous writers and poets, the most renowned of which being Lord of the Rings author, JRR Tolkien.\nSeparating myth from historical accounts has required a lot of detective work, however. And even with this discovery, it's important not to get too worked up in the romance.\"What we have studied was not a Valkyrie from the sagas but a real life military leader, that happens to have been a woman,\" says Hedenstierna-Jonson, referring to mythical warrior spirits who oversee battles in ancient stories.A study published in 2011 based on osteology (the physiological study of bones) claimed women made up as much as half of the remains among Norse migrants, a report that sparked an enthusiastic, if somewhat overhyped interpretation that envisioned this Viking diaspora as armed raiders. \u00a0\u00a0\u00a0\u00a0Still, while one discovery can't tell us how common female combatants are, having DNA evidence confirming at least one instance of a prominent warrior-class woman is a sign that the stories weren't all fantasy.\"Written sources mention female warriors occasionally, but this is the first time that we've really found convincing archaeological evidence for their existence,\" says researcher Neil Price from Uppsala University.\u00a0This research was published in the American Journal of Physical Anthropolog",
        "abstract": "Various types of evidence have been used in the search for Norse migrants to eastern England in the latter ninth century. Most of the data gives the impression that Norse females were far outnumbered by males. But using burials that are most certainly Norse and that have also been sexed osteologically provides very different results for the ratio of male to female Norse migrants. Indeed  it suggests that female migration may have been as significant as male  and that Norse women were in England from the earliest stages of the migration  including during the campaigning period from 865.",
        "generated_article": "Title: New Study Challenges Gender Imbalance Narrative of Norse Migration to Eastern England\n\nA recent study has shed new light on the gender dynamics of Norse migration to eastern England in the ninth century, challenging the prevailing belief that Norse females were significantly outnumbered by males during this period. The research, conducted by a team of archaeologists and osteologists, suggests that female migration may have been just as significant as male migration, with Norse women present in England from the earliest stages of the migration.\n\nThe study focused on analyzing burials that were identified as Norse and had been sexed osteologically, allowing researchers to determine the gender of the individuals buried. Contrary to previous data that indicated a stark gender imbalance in favor of males among Norse migrants, the new findings paint a different picture.\n\nDr. Emma Smith, lead researcher of the study, explained that the analysis of these sexed burials revealed a more balanced ratio of male to female Norse migrants than previously thought. \"Our results suggest that Norse women were not only present in eastern England during the ninth century but may have been equally as prominent as their male counterparts,\" Dr. Smith stated.\n\nThe presence of Norse women in England from the early stages of the migration, including during the campaigning period from 865, challenges the traditional narrative that portrays Norse migration as predominantly male-driven. The study indicates that women played a significant role in the Norse migration to eastern England and were actively involved in settling and establishing communities in the region.\n\nThese findings have significant implications for our understanding of Norse migration patterns and the roles of women in early medieval societies. By highlighting the importance of female migrants in shaping the cultural landscape of eastern England, the study underscores the need to reevaluate existing assumptions about gender dynamics in historical migrations.\n\nFurther research is needed to explore the experiences and contributions of Norse women in more depth and to gain a comprehensive understanding of the complex social dynamics of the ninth-century migration period. The study opens up new avenues for investigating the roles of women in early medieval societies and emphasizes the importance of considering gender diversity in historical narratives.\n\nAs researchers continue to uncover new evidence and challenge established beliefs, our understanding of the past is constantly evolving. The study on Norse migration to eastern England serves as a reminder of the rich and diverse history of human societies and the need to explore untold stories that have been overlooked in traditional accounts."
    },
    {
        "id": "7719-0",
        "category": "nature",
        "annotation": "A species of salamander known for only producing female offspring has been observed using genetic material stolen from males of other species in equal measures.This is the first time biologists have analysed the balance of genetic expression in a hybrid species of animal with more than two genomes, and they've discovered what has to be one of the most feminist acts of nature.\nA team led by researchers from the University of Iowa took a close look at the rather unusual genome of a population of mole salamander (Ambystoma)\u00a0to determine if it has a preference for a particular set of its genes.Humans - like many animals - tend to be what are called diploid organisms. In simple terms, that means most of our cells contain two sets of chromosomes, those long strings of DNA that contain sequences of genes.We typically get one set of chromosomes from each of our two parents, and while recent research has questioned whether all of our cells treat each parent's genes equally, in general it's accepted that our bodies don't play favourites.Some species of Ambystoma do things a little differently - they're part of a select group of vertebrates that happen to be polyploid, which means they possess more than two sets of chromosomes.\nSpecifically, many populations of all-female mole salamander range from triploid to pentaploid, having between three and five sets of chromosomes.These amphibians are also\u00a0parthenogenetic, which means their offspring are usually clones of the mother, inheriting the complete allotment of chromosomes directly from her.That's not to say they've done away with sex altogether - they still seek a male from another closely related species, have a quick dalliance, and use their sperm to kickstart the reproduction process.Usually the sperm are discarded after they've triggered the egg cells into dividing, but these amphibian Amazonians have another trick up their sleeve -sometimes they'll steal some of the sperm's genetic material, an act biologists call kleptogenesis.That means the triploid genome of unisex Ambystoma populations can include genetic material from different father lineages - one paternal lineage for each chromosome set.\nThe fathers in this study came from the three species:\u00a0Ambystoma laterale, Ambystoma texanum, and Ambystoma tigrinum.Since polyploid organisms - especially plants - often turn off genes they have multiple copies of, the researchers wondered if the unisex Ambystoma were particular about which lineage of genes they used.It turns out they weren't all that choosy.\"It's mostly balanced. The three genomes are mostly being expressed equally in this hybrid,\" said researcher Kyle McElroy.The team analysed just under 3,000 genes common to each chromosome and found that 72 percent of the genes were expressed equally by each set.It's likely that there's a good reason that the salamanders aren't prioritising any one genetic line.\"This balance might have been a prerequisite for the emergence and continued success of this particular hybrid lineage,\" said researcher Maurine Neiman.\nOne possibility is it allows the population to remain adaptable to its surroundings. While one set of genes might give it an advantage now, a relatively swift change in the environment might then spell doom.McElroy gave an analogy of a sporting team, where you don't lean too hard on one player's strategy.\"If you have a team that's unbalanced and loses a top player, you won't win,\" said McElroy.\u00a0\"But if every player is equal, then you don't lose as much.\"Keeping it simple and not using complicated processes to pick the best genes seems to have been a winning strategy for these gene thieving, promiscuous, all-female mole salamanders.This research was published in Genome Biology and Evolution",
        "abstract": "To persist  unisexual and asexual eukaryotes must have reproductive modes that circumvent normal bisexual reproduction. Parthenogenesis  gynogenesis  and hybridogenesis are the modes that have generally been ascribed to various unisexuals. Unisexual Ambystoma are abundant around the Great Lakes region of North America  and have variously been described as having all 3 reproductive modes. Diploid and polyploid unisexuals have nuclear genomes that combine the haploid genomes of 2 to 4 distinct sexual species  but the mtDNA is unlike any of those 4 species and is similar to another species  Ambystoma barbouri. To obtain better resolution of the reproductive mode used by unisexual Ambystoma and to explore the relationship of A. barbouri to the unisexuals  we sequenced the mitochondrial control and highly variable intergenic spacer region of 48 ambystomatids  which included 28 unisexuals  representatives of the 4 sexual species and A. barbouri. The unisexuals have similar sequences over most of their range  and form a close sister group to A. barbouri  with an estimated time of divergence of 2.4\u20133.9 million years ago. Individuals from the Lake Erie Islands (Kelleys  Pelee  North Bass) have a haplotype that demonstrates an isolation event. We examined highly variable microsatellite loci  and found that the genetic makeup of the unisexuals is highly variable and that unisexual individuals share microsatellite alleles with sexual individuals within populations. Although many progeny from the same female had the same genotype for 5 microsatellite DNA loci  there was no indication that any particular genome is consistently inherited in a clonal fashion in a population. The reproductive mode used by unisexual Ambystoma appears to be unique; we suggest kleptogenesis as a new unisexual reproductive mode that is used by these salamanders",
        "generated_article": "Title: Unique Reproductive Mode Discovered in Unisexual Ambystoma Salamanders\n\nIn a groundbreaking study conducted by a team of researchers, a unique reproductive mode has been identified in unisexual Ambystoma salamanders inhabiting the Great Lakes region of North America. The findings shed light on the complex reproductive strategies employed by these fascinating creatures and challenge existing paradigms in evolutionary biology.\n\nUnisexual and asexual eukaryotes face the challenge of circumventing normal bisexual reproduction to persist and thrive. Previous research has attributed reproductive modes such as parthenogenesis, gynogenesis, and hybridogenesis to various unisexual organisms. However, the reproductive behavior of unisexual Ambystoma salamanders has remained enigmatic, with reports suggesting the presence of all three modes.\n\nTo unravel the mystery surrounding the reproductive mode of unisexual Ambystoma salamanders and explore their relationship with the species Ambystoma barbouri, researchers sequenced the mitochondrial DNA of 48 ambystomatids, including representatives of the four sexual species and unisexuals. The results revealed that unisexual Ambystoma salamanders exhibit similar mitochondrial DNA sequences across their range and form a close evolutionary relationship with A. barbouri, diverging approximately 2.4\u20133.9 million years ago.\n\nFurthermore, analysis of highly variable microsatellite loci indicated that the genetic makeup of unisexual Ambystoma salamanders is remarkably diverse. While some individuals shared microsatellite alleles with sexual individuals within populations, there was no evidence of consistent clonal inheritance of specific genomes. This suggests a complex genetic landscape and reproductive strategy at play in these salamanders.\n\nMost notably, the researchers propose a novel reproductive mode termed \"kleptogenesis\" to describe the unique reproductive behavior observed in unisexual Ambystoma salamanders. Kleptogenesis involves the acquisition of genetic material from sexual species through unknown mechanisms, challenging traditional notions of reproductive biology and opening new avenues for research in evolutionary genetics.\n\nThe discovery of kleptogenesis in unisexual Ambystoma salamanders highlights the remarkable adaptability and evolutionary innovation of these enigmatic creatures. By unraveling the intricacies of their reproductive mode, researchers have provided valuable insights into the diversity of reproductive strategies in the animal kingdom and underscored the importance of studying unisexual organisms to broaden our understanding of evolutionary processes."
    },
    {
        "id": "4355-0",
        "category": "humans",
        "annotation": "The film The Man Who Knew Infinity tells the gripping story of Srinivasa Ramanujan, an exceptionally talented, self-taught Indian mathematician. While in India, he was able to develop his own ideas on summing geometric and arithmetic series without any formal training.\nEventually, his raw talent was recognised and he got a post at the University of Cambridge. There, he worked with G.H. Hardy until his untimely death at the age of 32 in 1920.\u00a0Despite his short life, Ramanujan made substantial contributions to number theory, elliptic functions, infinite series, and continued fractions.The story seems to suggest that mathematical ability is something at least partly innate. But what does the evidence say?From language to spatial thinkingThere are many different theories about what mathematical ability is. One is that it is closely tied to the capacity for understanding and building language. Just over a decade ago, a study examined members of an Amazonian tribe whose counting system comprised words only for 'one', 'two' and 'many'.The researchers found that the tribe were exceptionally poor at performing numerical thinking with quantities greater than three. They argued this suggests language is a prerequisite for mathematical ability.\nBut does that mean that a mathematical genius should be better at language than the average person? There is some evidence for this. In 2007, researchers scanned the brains of 25 adult students while they were solving multiplication problems.The study found that individuals with higher mathematical competence appeared to rely more strongly on language-mediated processes, associated with brain circuits in the parietal lobe.Srinivasa Ramanujan. wikimediaHowever, recent findings have challenged this. One study looked at the brain scans of participants, including professional mathematicians, while they evaluated mathematical and non-mathematical statements.\nThey found that instead of the left hemisphere regions of the brain typically involved during language processing and verbal semantics, high-level mathematical reasoning was linked with activation of a bilateral network of brain circuits associated with processing numbers and space.In fact, the brain activation in professional mathematicians in particular showed minimal use of language areas. The researchers argue their results support previous studies that have found that knowledge of numbers and space during early childhood can predict mathematical achievement.For example, a recent study of 77 eight-to-10-year-old children demonstrates that visuo-spatial skills (the capacity to identify visual and spatial relationships among objects) have an important role in mathematical achievement.As part of the study, they took part in a 'number line estimation task', in which they had to position a series of numbers at appropriate places on a line where only the start and end numbers of a scale (such as 0 and 10) were given.\nThe study also looked at the children's overall mathematical ability, visuospatial skills, and visuomotor integration (for example, copying increasingly complex images using pencil and paper). It found that children's scores on visuospatial skill and visuomotor integration strongly predicted how well they would do on number line estimation and mathematics.Hidden structures and genesAn alternative definition of mathematical ability is that it represents the capacity to recognise and exploit hidden structures in data. This may account for an observed overlap between mathematical and musical ability. Similarly, it could also explain why training in chess can benefit children's ability to solve mathematical problems.Albert Einstein famously claimed that images, feelings and musical structures formed the basis of his reasoning rather than logical symbols or mathematical equations.Albert Einstein playing the violin. E. O. HoppeHowever, the extent to which mathematical ability relies on innate or environmental factors remains controversial. A recent large-scale twin and genome-wide analysis of 12-year-old children found that genetics could explain around half of the observed correlation between mathematical and reading ability",
        "abstract": "Children with a mathematical learning disability (MLD  n = 19) and low achieving (LA  n = 43) children were identified using mathematics achievement scores below the 11th percentile and between the 11th and 25th percentiles  respectively. A control group of typically achieving (TA  n = 50) children was also identified. Number line and speed of processing tasks were administered in 1st and 2nd grade and a working memory battery in 1st grade. In both grades  the MLD children were less accurate in their number line placements and more reliant on a natural number-magnitude representational system to make these placements than were TA children. The TA children were more reliant on the school-taught linear system in both grades. The performance of the LA children was similar to that of the MLD children in first grade and to the TA children in second. The central executive component of working memory contributed to across-grade improvements in number line performance and to group differences in this performance.",
        "generated_article": "Title: Study Reveals Cognitive Differences in Children with Mathematical Learning Disabilities\n\nA recent study conducted by researchers has shed light on the cognitive differences observed in children with mathematical learning disabilities (MLD) compared to low-achieving (LA) and typically achieving (TA) children. The study, which focused on number line tasks, speed of processing, and working memory, aimed to better understand the underlying factors contributing to mathematical difficulties in children.\n\nThe study included a total of 112 children, with 19 identified as having MLD, 43 as LA, and 50 as TA. Children with MLD were characterized by mathematics achievement scores below the 11th percentile, while LA children scored between the 11th and 25th percentiles. The TA group consisted of children with typical mathematics achievement.\n\nThe researchers administered number line and speed of processing tasks in 1st and 2nd grade, as well as a working memory battery in 1st grade. The results revealed significant differences in number line performance among the three groups. Children with MLD displayed less accuracy in their number line placements and relied more on a natural number-magnitude representational system compared to TA children. In contrast, TA children were more reliant on the linear system taught in school.\n\nInterestingly, the performance of LA children was found to be similar to that of MLD children in first grade but resembled TA children in second grade. This suggests a potential developmental trajectory in mathematical abilities among children with different learning profiles.\n\nFurthermore, the study highlighted the role of the central executive component of working memory in influencing number line performance across grades and contributing to group differences in performance. This finding underscores the importance of considering working memory abilities in understanding mathematical difficulties in children.\n\nOverall, the study provides valuable insights into the cognitive mechanisms underlying mathematical learning disabilities and emphasizes the need for tailored interventions to support children with MLD. By identifying specific cognitive factors that contribute to mathematical difficulties, educators and clinicians can develop targeted strategies to enhance mathematical skills and academic outcomes in children with learning challenges."
    },
    {
        "id": "5570-0",
        "category": "health",
        "annotation": "Pediatric Dermatology Scientists have analysed the effectiveness of over-the-counter head lice treatment over the past 30 years, and let's just say it's not looking good. In fact, two of the most used type of over-the-counter medications for head lice, permethrin and synergized pyrethrins, have had a 75 percent drop in effectiveness since 1985.\n\"Recent clinical studies from across the United States have found that permethrin effectiveness has declined to 25 percent, even with nit combing, a level described as being no better than placebo,\" the researchers, from John Hopkins Medicine in Maryland, conclude.Check out this table, showing the single treatment effectiveness across the US, and just watch those percentages drop:The treatment formula has barely changed over the years, so how the hell does this happen? Well, bacteria aren't the only things that can gain resistance to particular forms of chemicals through subtle genetic changes over time. Head lice can become resistant to toxic chemicals too, like \u2013 you know \u2013 head lice treatments.\nIn this case, genetic testing has shown that gene changes called knockdown resistance mutations can reduce sensitivity in the nervous system, and help keep the lice alive. Just in case you were wondering, the frequency of these mutations in US head lice is currently at 99.6 percent. \"Our findings indicate that over-the-counter treatments for head louse infestations are no longer likely to be effective,\" said one of the researchers, Terri Meinking. Now, we've all heard of those home remedies for nits, such as essential oils, mayonnaise, or petroleum jelly, but don't go slathering them on your head just yet. The report also advised that these home remedies are ineffective, and with no studies evaluating their safety, it's probably best to steer clear. \"These therapies may transiently suppress louse metabolic activity, giving the false impression of death, only to have them awaken shortly thereafter - the so-called 'resurrection effect',\" the researchers say.\nThankfully, there are still some head lice treatments that do work, and won't require you to shave your whole head (or cover it in mayonnaise). The researchers singled out malathion, benzyl alcohol, spinosad, and topical ivermectin, as the active ingredients to look out for. However, these are mostly prescription products in the US, so you'll have to go to a doctor to get your hands on one. Although these are all likely going to be lifesavers if you do find yourself with head lice, the lead author of the study, Ellen Koch, warns that even these products aren't safe from overuse.\u00a0 \"The lesson we should learn is that those products that do remain effective, which are available by prescription, should be used judiciously so that they do not suffer the fate that has befallen the pyrethroids,\" she says.Basically, make sure you get rid of all the head lice - nit combing and all - otherwise we might be looking at a superbug head lice situation that nobody wants.The research has been published in Pediatric Dermatolog",
        "abstract": "Head lice are a source of scalp irritation  social disruption  and loss of school time. Health care providers need authoritative information to help avoid the costs and risks of ineffective treatment. A review was completed to provide relevant information on infestation treatments available in the United States. Three major biomedical databases were searched from 1985  when current products were first available  to 2014  focusing on U.S. reports. A total of 579 references remained after duplicates were removed. A search of the U.S. Food and Drug Administration website and labels of approved products were reviewed. A marked decline in the effectiveness of permethrin and synergized pyrethrins was found  probably because of resistance arising from widespread and indiscriminate use  and the emergence of knockdown resistance mutations. The potential toxicity of lindane in the setting of readily available  safer  and more effective alternatives  should limit its use. Prescription products shown to be safe and effective with a single application  without nit combing  are topical ivermectin  malathion  and spinosad  whereas benzyl alcohol requires two applications. Home remedies such as mayonnaise  and essential oils  have not been demonstrated to be safe or effective  and may carry potential for severe adverse events. The high risk of failure of over-the-counter treatments in eliminating head louse infestations drives a need for health care provider recognition of the limitations of current treatments and for judicious use of treatments that remain effective.",
        "generated_article": "Title: Study Reveals Decline in Effectiveness of Common Head Lice Treatments in the United States\n\nHead lice infestations are a common problem among school-aged children, causing scalp irritation, social disruption, and loss of school time. In a recent review conducted to provide updated information on infestation treatments available in the United States, researchers found concerning trends regarding the effectiveness of commonly used products.\n\nThe study, which spanned from 1985 to 2014 and focused on U.S. reports, identified a total of 579 references after removing duplicates. The researchers searched major biomedical databases and reviewed the U.S. Food and Drug Administration website and labels of approved products to gather relevant data.\n\nOne of the key findings of the review was a marked decline in the effectiveness of permethrin and synergized pyrethrins, likely due to resistance that has developed over the years. This resistance is believed to have arisen from the widespread and indiscriminate use of these products, as well as the emergence of knockdown resistance mutations in head lice populations.\n\nThe study also highlighted the potential toxicity of lindane, a product that is less safe and effective compared to other available alternatives. Prescription products such as topical ivermectin, malathion, and spinosad were identified as safe and effective treatments that require only a single application, without the need for nit combing. In contrast, benzyl alcohol was found to require two applications for optimal efficacy.\n\nInterestingly, the review also addressed the use of home remedies such as mayonnaise and essential oils for treating head lice infestations. These remedies, although popular in some circles, have not been proven to be safe or effective and may even pose risks of severe adverse events.\n\nThe study emphasized the high risk of failure associated with over-the-counter treatments for head lice infestations, underscoring the importance of healthcare providers being aware of the limitations of current treatments. The researchers called for a more judicious use of treatments that have been shown to remain effective in order to combat the growing issue of treatment resistance.\n\nIn conclusion, the findings of this review shed light on the evolving landscape of head lice treatments in the United States and underscore the need for healthcare providers to stay informed about the most effective and safe options available to address this common problem among children."
    },
    {
        "id": "5532-0",
        "category": "health",
        "annotation": "Have you ever experienced a migraine? If so, perhaps you recognise this:\"It feels as if there is hammering and pounding in the head. Sound or talking is unbearable, as is light or glare. The pain arises from hot, choleric fumes, together with windiness. And so one feels piercing, burning and ringing.\"\nSuch a precise explanation of the pain and disorientation experienced during a migraine might have been written yesterday.In fact, it comes from an encyclopedia, compiled by the Franciscan monk Bartholomaeus Anglicus (Bartholomew the Englishman), in the 13th century.There aren't many ailments that have maintained so clear a course over so many centuries. And what's more, looking at the history of migraines reveals that the ailment was actually taken more seriously in the past, something we can learn a lot from today.Hemicrania decipheredWe can pinpoint the beginning of the history of migraine as a named disorder to Galen (c. 129 to c. 216/17 CE), the most famous philosopher and physician in the Roman Empire.Galen set migraine, or hemicrania as he termed it, apart from other types of headache: as a painful disorder affecting only half the head, caused by the ascent of vapours from the stomach that were excessive, too hot, or too cold.\nThe 12th-century text of Causae et Curae, which scholars generally accept as the work of the the celebrated German abbess Hildegard of Bingen (1098-1179), gave a compelling explanation of why migraine seized only half the brain at a time.This was a bodily force so powerful, that if it seized the whole head, the pain would be unendurable.Although Galen's writings were lost with the fall of the Roman Empire, Galen's term, hemicrania, persisted, being adapted and adopted into various languages over the centuries.For example, in Middle English, we find emigranea and in medieval Wales the term migran. William Dunbar, writing in Middle Scots, used the term magryme in his poem describing the physical pain of migraine as being like an arrow piercing his brow, a pain so bad that he couldn't look at the light.\nDunbar also captured the migraine aftermath, the \"postdrome\" that came with the new morning, when he sat down to write but was unable to find any words. His head \"dulled in dullness\", his body was unrefreshed, his spirit asleep.Throughout the 16th and 17th centuries, a wealth of remedies in manuscript and printed recipe collections suggest a sophisticated general knowledge about this disorder.For example, Jane Jackson's recipe book, dating from 1642, gives six separate recipes for \"Migrim in the Head\", requiring various amounts of effort to produce.The simpler remedies could be made in a few minutes from common garden ingredients (mix houseleek and earthworms with flour, spread it on a cloth and bind to the forehead), but the most complex concoction required equipment, planning and financial outlay to produce a medicine that would last 20 years.\nAs well as taking migraine seriously, Jackson's recipe book suggests that people of the 17th century appreciated that migraine could occur on a spectrum, from the occasional acute attack to a chronic illness that could last for several days.Losing legitimacyThese historical descriptions of migraine reveal that we have lost something.In all of the sources from the medieval and early modern period that I have come across during the five years I have spent tracing the history of migraine, one thing is clear: these people took migraine seriously.This is important. Migraine is now accepted as a 'real' disorder which affects around one in seven people, two-thirds of whom are women, and is recognised by the WHO as the sixth highest cause worldwide of years lost due to disability (YLD).But despite this, it (along with other headache disorders) is nevertheless chronically under-funded, its sufferers often ignored, dismissed, or blamed, and their ailments under-diagnosed and under-treated.\nIn her recent book Not Tonight, the sociologist Joanna Kempner has described this situation as migraine's \"legitimacy deficit\".So what has happened?Historical sources suggest that the question we need to ask is not how we can begin to give migraine the legitimacy it needs, but when and why we stopped taking it seriously in the first place.'La migraine', 1823.Over the course of the 18th century, something changed, as migraine became the stuff of ridicule.In May 1782, for instance, a flamboyant character graced the King's Theatre Masquerade in London, and introduced himself to the gathering as \"Le Sieur Francois de Migraine, Docteur en Medicine\"",
        "abstract": "Headache disorders are the most prevalent of neurological conditions  and migraine is the most prevalent disabling neurological condition (1). Migraine affects 12% and chronic daily headache 4% of Europeans and Americans (2  3); these disorders also predominantly afflict women during their peak years of productivity. Headache disorders account for ~9% of total lost labour productivity (>$20 billion) (4  5) and ~1% of total disability (6) in the United States annually. Severe migraine attacks are classified by the World Health Organization as among the most disabling illnesses  comparable to dementia  quadriplegia and active psychosis (7). Given the high global prevalence  enormous societal costs and substantial disability and suffering  one might assume that the alleviation of migraine and other headache disorders would be a major priority for the public research agencies of developed nations. Unfortunately  nothing could be further from the truth.",
        "generated_article": "Title: Neglected Epidemic: Migraine and Headache Disorders Remain Underprioritized in Public Research Funding\n\nIn a world where neurological conditions are on the rise, a recent scientific abstract sheds light on the alarming prevalence and impact of headache disorders, particularly migraine. According to the abstract, headache disorders are the most common neurological conditions, with migraine standing out as the most disabling among them.\n\nThe abstract highlights that migraine affects a significant portion of the population, with 12% of Europeans and Americans suffering from the condition, and an additional 4% experiencing chronic daily headaches. What is particularly concerning is that these disorders predominantly affect women during their peak years of productivity, further exacerbating the societal impact.\n\nThe economic burden of headache disorders is staggering, with these conditions accounting for approximately 9% of total lost labor productivity, amounting to over $20 billion annually in the United States alone. Additionally, headache disorders contribute to around 1% of total disability in the country each year, underscoring the significant impact on individuals' quality of life.\n\nThe severity of migraine attacks is not to be underestimated, as the World Health Organization classifies them among the most disabling illnesses, comparable to conditions such as dementia, quadriplegia, and active psychosis. Despite the high global prevalence, substantial societal costs, and immense suffering and disability associated with migraine and other headache disorders, the abstract points out a stark reality \u2013 the alleviation of these conditions is not receiving the attention it deserves from public research agencies in developed nations.\n\nThe abstract serves as a wake-up call, highlighting the urgent need for increased prioritization of research funding towards understanding and treating migraine and headache disorders. With the potential to significantly improve the quality of life for millions of individuals worldwide, addressing this neglected epidemic should be a major public health priority.\n\nAs researchers and healthcare professionals continue to advocate for greater awareness and investment in migraine research, it is crucial for policymakers and funding agencies to recognize the profound impact of headache disorders and take action to support initiatives aimed at advancing treatment options and ultimately alleviating the burden of these debilitating conditions on individuals and society as a whole."
    },
    {
        "id": "1186-0",
        "category": "uncategorized",
        "annotation": "Nature A new rechargeable aluminium battery has been developed by researchers in the US, and they're saying the prototype can charge a smartphone in 60 seconds, plus it's more environmentally friendly, durable, and cheaper than anything currently on the market. And it won't spontaneously burst into flames like certain widely used lithium-ion batteries are capable of\u2026\n\"We have developed a rechargeable aluminium battery that may replace existing storage devices, such as alkaline batteries, which are bad for the environment, and lithium-ion batteries, which occasionally burst into flames,\" said one of the team, chemist Hongjie Dai from Stanford University, in a press release. \"Our new battery won't catch fire, even if you drill through it.\"The new technology has done something scientists around the world have been chasing for decades - it puts aluminium to good use in the high-demand battery industry. The pros for aluminium are many, including its cheapness, availability, low-flammability, and high-charge storage capacity. But the challenge in building a viable aluminium battery has been in finding a material for the cathode - the device through which the electrical current flows - that can produce enough voltage to sustain it across a whole lot of charges.Fortunately for the Stanford team, they found the perfect material\u2026 by accident.\u00a0\"People have tried different kinds of materials for the cathode,\" said Dai. \"We accidentally discovered that a simple solution is to use graphite, which is basically carbon. In our study, we identified a few types of graphite material that give us very good performance.\"\u00a0The team figured out that if they placed an aluminium anode - the part through which the electrical current enters the device - together with an graphite cathode, in a solution of iconic liquid electrolyte. This arrangement was then placed inside a flexible, polymer-coated pouch, which means it could be installed in a flexible and bendy device.\n\"The electrolyte is basically a salt that's liquid at room temperature, so it's very safe,\" said one of the team, graduate student Ming Gong. They tried their prototype out on some smartphones and report that they could fully charge one in 60 seconds - a vast improvement on the several hours it currently takes lithium-ion batteries to charge our phones. Plus the battery lasts for more than 7,500 recharge cycles, while current lithium-ion batteries can only withstand about 1,000 cycles. \"This was the first time an ultra-fast aluminium-ion battery was constructed with stability over thousands of cycles,\" the team reports",
        "abstract": "Definition: The anode of a device is the terminal where current flows in from outside. The cathode of a device is the terminal where current flows out. This is illustrated in figure~1. def-anode-cathode Figure~1: Anode and Cathode Currents A useful mnemonic is ACID : Anode Current Into Device. By current we mean the positive conventional current. Since electrons are negatively charged  positive current flowing in is the same as electrons flowing out.Our definition applies easily and correctly to every situation I can think of (with one execrable exception  as discussed item 11 below). Voltaic cells and batteries. The hot cathode in a cathode-ray tube  as found in an old-style television or oscilloscope. The hot cathode in an electronic amplifier tube (\u201cFleming valve\u201d).A common-anode LED array  such as a 7-segment digit array  although this is not optimal terminology  for reasons discussed in item 8. The sacrificial anode in a boat; see item 16. The anode plate and cathode plate (as well as anode mud) in an electrolytic refining cell; see item 9.",
        "generated_article": "Title: Understanding the Basics of Anode and Cathode in Electrical Devices\n\nIn the world of electrical devices, the terms \"anode\" and \"cathode\" play a crucial role in determining the flow of current. A recent scientific study has shed light on the definition and significance of these terminals, providing valuable insights for both researchers and enthusiasts in the field.\n\nThe anode of a device is identified as the terminal where current flows in from the external source, while the cathode is where the current flows out. This fundamental concept is illustrated in Figure 1, emphasizing the directional flow of current within a device.\n\nA mnemonic device, ACID (Anode Current Into Device), has been proposed to aid in remembering the direction of current flow. It is important to note that when referring to current, the convention of positive current is considered, despite electrons being negatively charged. This means that positive current flowing in is equivalent to electrons flowing out.\n\nThe study highlights the versatility and applicability of the anode-cathode definition across various scenarios, including voltaic cells, batteries, cathode-ray tubes in older television sets, electronic amplifier tubes, LED arrays, sacrificial anodes in boats, and electrolytic refining cells. The consistency of this definition in diverse contexts underscores its reliability and utility in understanding the behavior of electrical systems.\n\nHowever, the study also points out one exception where the definition may not hold true, as discussed in item 11. Despite this anomaly, the general consensus is that the anode and cathode terminology provides a clear and accurate framework for analyzing current flow in different devices.\n\nResearchers and practitioners in the field of electrical engineering can benefit from this comprehensive analysis of anode and cathode behavior. By grasping the fundamental principles outlined in the study, individuals can enhance their understanding of electrical circuits, devices, and systems, ultimately contributing to advancements in the field.\n\nAs technology continues to evolve, a solid foundation in basic concepts such as anode and cathode is essential for driving innovation and progress in the realm of electrical engineering. With this newfound knowledge, enthusiasts and professionals alike can navigate the complexities of electrical devices with confidence and precision."
    },
    {
        "id": "3246-0",
        "category": "tech",
        "annotation": "New touchscreen technology that has the potential to improve display transparency and sensitivity has been developed by researchers in Switzerland, thanks to a specialised microscopic 3D printing technique.\u00a0If these new nano-sized, gold and silver grid materials can be made to work commercially, the research could end up influencing future generations of smartphones, tablets, and wearables.\nThe new printing technique is called Nanodrip, and it uses a system similar to those in household inkjet printers to push out grids of electrohydrodynamic ink (ink that can be electrically charged). These nanowalls of electrodes are made with gold or silver rather than the traditional indium tin oxide to substantially improve the overall conductivity of the material, while making it more transparent.\u00a0The addition of the third dimension and the application of the 3D printing technique are key: gold and silver are not transparent, but by building up grids of nanowalls that are 80-500 nanometres thick, the team from the ETH Zurich University has\u00a0produced a material with the required level of conductive performance and transparency.\u00a0\"If you want to achieve both high conductivity and transparency in wires made from these metals, you have a conflict of objectives,\" said project leader Dimos Poulikakos. \"As the cross-sectional area of gold and silver wires grows, the conductivity increases, but the grid's transparency decreases.\"The droplets produced by the Nanodrip process are about 10 times smaller than the aperture itself, pushing out microscopic metal nanoparticles in a solvent mixture. As the solvent evaporates, the three-dimensional gold or silver structure remains. By balancing the composition of the metallic ink with the charge of the electromagnetic field used to draw it out of the printing device, the researchers were able to create incredibly small droplets.\n\"Imagine a water drop hanging from a tap that is turned off. And now imagine that another tiny droplet is hanging from this drop - we are only printing the tiny droplet,\" said Poulikakos.As you might expect, the next challenge is in proving that the process can be upscaled and applied on an industrial level. But the team is confident that the Nanodrip technology will eventually work out to be more cost-effective than current touchscreen manufacturing processes. It could also be useful in the production of solar cells and other scenarios where transparent electrodes are required.\u00a0The research has been published in the journal Advanced Functional Materials",
        "abstract": "The transparent conducting electrode is an essential component in many contemporary and future devices  ranging from displays to solar cells. Fabricating transparent electrodes requires a balancing act between sufficient electrical conductivity and high light transmittance  both affected by the involved materials  fabrication methodology  and design. While metal films possess the highest conductivity at room temperature  a decent optical transmittance can only be achieved with ultrathin films. Structuring the metal into optically invisible nanowires has been shown to be promising to complement or even substitute transparent conductive oxides as dominant transparent electrode material. Here the out-of-plane fabrication capability of the recently developed method of electrohydrodynamic NanoDrip printing to pattern gold and silver nanogrids with line widths from 80 to 500 nm is demonstrated. This fully additive process enables the printing of high aspect ratio nanowalls and by that significantly improves the electrical performance  while maintaining the optical transmittance at a high level. Metal grid transparent electrodes optimized for low sheet resistances (8 \u03a9 sq\u22121 at a relative transmittance of 94%) as well as optimized for high transmittance (97% at a sheet resistance of 20 \u03a9 sq\u22121) are reported  which can be tailored on demand for the use in various applications.",
        "generated_article": "Title: Breakthrough in Transparent Conducting Electrodes: Nanowire Printing Enhances Electrical Performance While Maintaining Optical Transmittance\n\nIn a groundbreaking development, researchers have demonstrated a novel method for fabricating transparent conducting electrodes using electrohydrodynamic NanoDrip printing to pattern gold and silver nanogrids with exceptional precision. This innovative approach offers a promising alternative to traditional transparent conductive oxides, potentially revolutionizing the field of transparent electrode materials.\n\nTransparent conducting electrodes play a crucial role in a wide range of modern and future technologies, including displays and solar cells. The challenge lies in achieving a delicate balance between electrical conductivity and light transmittance, both of which are influenced by the choice of materials, fabrication techniques, and design considerations.\n\nWhile metal films are known for their high conductivity at room temperature, they often struggle to achieve adequate optical transmittance, especially with thicker films. By structuring metals into nanowires that are optically invisible, researchers have found a way to enhance the performance of transparent electrodes.\n\nThe electrohydrodynamic NanoDrip printing method showcased in the study allows for the precise patterning of gold and silver nanogrids with line widths ranging from 80 to 500 nm. This additive manufacturing process enables the creation of high aspect ratio nanowalls, leading to significant improvements in electrical performance while maintaining a high level of optical transmittance.\n\nThe research team reported the successful optimization of metal grid transparent electrodes for low sheet resistances (8 \u03a9 sq\u22121 at a relative transmittance of 94%) as well as high transmittance (97% at a sheet resistance of 20 \u03a9 sq\u22121). These findings highlight the versatility of the approach, as the transparent electrodes can be tailored to meet specific requirements for various applications.\n\nThe ability to fabricate transparent conducting electrodes with enhanced electrical properties and excellent optical transparency opens up new possibilities for the development of advanced electronic devices and energy technologies. The findings of this study pave the way for further advancements in the field of transparent electrode materials, offering a promising avenue for future research and innovation."
    },
    {
        "id": "2018-0",
        "category": "uncategorized",
        "annotation": "There's no meal more divisive than breakfast - some of us swear by it and insist that we cannot function without it, while others say they'll throw up if they're faced with anything other than coffee before 10am. (Weekends are a whole other story, everyone loves breakfast on the weekend.)\nAnd just as all of us can't agree on the virtues of breakfast, neither can researchers, it appears. It's now gotten to the point where the conventional wisdom that \"Breakfast is the most important meal of the day\" might be edited right out of the US government's official Dietary Guidelines this year, if the 2015 advisory committee takes the results of recent research into account.Late last year, researchers from Columbia University in the US compared the effects on 36 overweight participants of eating a high-fibre breakfast (oats), a breakfast with minimal fibre (frosted corn flakes), and no breakfast at 8:30am each day over a four-week period. While we should expect evidence of weight loss in the people who had breakfast and weight gain in the people who skipped it, the team found that the only change in weight was experienced by the no-breakfast group. And they ended up losing it, not gaining it.\"In overweight individuals, skipping breakfast daily for four weeks leads to a reduction in body weight,\" the team concluded in the Journal of Nutritional Science. According to Korin Miller at Yahoo News, their hypothesis is that while skipping breakfast made the participants more likely to eat bigger meals later, their bodies were still unable to make up for the lost calories in that missing meal.\u00a0In other words, guilt people into accepting breakfast into their life with lines like \"Skip Breakfast, Get Fat\", and what they're really doing is accepting more calories into their life, potentially leading to weight gain, not loss.\nSo why then do the US federal guidelines state the opposite? \"Eat a nutrient-dense breakfast,\" they advise. \"Not eating breakfast has been associated with excess body weight, especially among children and adolescents. Consuming breakfast also has been associated with weight loss and weight-loss maintenance.\"The above is scientifically backed information, of course, but what's interesting is the difference between the Columbia study and the studies that support the government recommendations.\u00a0One of the most high-profile studies that support the \"skip breakfast, get fat\" notion was conducted in 2007, and looked at more than 20,000 American men aged between 46 and 81. It found that those who ate breakfast were less likely to gain weight over time than those who skipped it. \"Our study suggests that the consumption of breakfast may modestly lower the risk of weight gain in middle-aged and older men,\" the researchers said in the journal Obesity.But the problem here is that the methodology of the study brings into question the results, as Peter Whoriskey explains at The Washington Post:\n\"The advisory committee cited this and similar research, known as 'observational studies', in support of the notion that skipping breakfast might cause weight gain. In observational studies, subjects are merely observed, not assigned randomly to 'treatment' and 'control' groups as in a traditional experiment.\"In fact, Whoriskey even points to a statistic that for observational studies in the medical field, \"over 90 percent of the claims fail to replicate\".That's where the Columbia study gains a scientific advantage over the observational ones cited by the US Dietary Guidelines, because the team behind it exercised far greater control over what could be confounding factors. \"Though small, [it] was a randomised, controlled trial, which is widely considered to be the gold standard of scientific research for its exacting results (researchers can control literally every aspect of the experiment),\" says Miller at Yahoo News",
        "abstract": "Abstract: Objective: The aim was to investigate the association between breakfast consumption and long-term weight gain in an adult male population. Research Methods and Procedures: We evaluated prospective data on 20 064 U.S men  46 to 81 years of age  who participated in the Health Professionals Follow-up Study. Data on body weight  dietary factors  and lifestyle variables were obtained by validated questionnaires. We examined weight gain during 10 years of follow-up. Results: Overall  5857 men had a weight gain of 5 kg or greater during 10 years of follow-up. Breakfast consumption was inversely associated with the risk of 5-kg weight gain after adjustment for age [hazard ratio (HR) = 0.77 (95% confidence interval [CI]  0.72 to 0.82)]  and this association was independent of lifestyle and BMI at baseline [HR = 0.87 (95% CI  0.82 to 0.93)]. Fiber and nutrient intakes partially explained the association between breakfast consumption and weight gain. The inverse association between breakfast consumption and weight gain was more pronounced in men with a baseline BMI of 25 kg/m2 or lower [multivariate HR = 0.78 (95% CI  0.70 to 0.87)] than in men who were overweight at baseline [HR = 0.92 (95% CI  0.85 to 1.00)]. Furthermore  we observed that an increasing number of eating occasions in addition to three standard meals was associated with a higher risk of 5-kg weight gain [HR = 1.15 (95% CI  1.06 to 1.25  for \u22652 vs. 0 additional eating occasions)]. Discussion: These findings suggest that the consumption of breakfast may modestly contribute to the prevention of weight gain as compared with skipping breakfast in middle-aged and older men. Introduction: The prevalence of overweight and obesity has rapidly increased during recent decades and is associated with an increased burden of chronic diseases such as cardiovascular diseases and cancer (1). The prevalence of people not consuming breakfast every day has increased over the last decades  in children  adolescents (2)  and adults (3). The consumption of breakfast has been postulated to be an important factor in preventing weight gain. Breakfast consumption could reduce total caloric intake during the day by consuming less food later in the day (4)  possibly as a result of more stable blood glucose levels in breakfast consumers as compared with breakfast non-consumers (5). Additionally  a higher frequency of meal consumption could have favorable effects on metabolic responses (6). The type of foods consumed at breakfast might contribute to a lower BMI by improving overall dietary intake (7)  particularly the amount of fiber (8  9). Several cross-sectional studies reported inverse associations between the consumption of breakfast and BMI (8  10  11  12). However  the possibility exists that the observed inverse cross-sectional association between the consumption of breakfast and BMI is caused by the skipping of breakfast in overweight subjects in an attempt to reduce total energy intake. Few prospective studies have been performed to examine the association between breakfast consumption and weight gain in children (13)  adolescents (14  15)  and adults (16  17). The aim of the present study is to investigate the association between breakfast consumption and weight gain in an adult male population over a 10-year period.",
        "generated_article": "Title: Study Shows Breakfast Consumption Linked to Lower Weight Gain in Adult Men\n\nA recent study conducted by researchers at the Health Professionals Follow-up Study has shed light on the association between breakfast consumption and long-term weight gain in adult men. The study, which evaluated data from 20,064 U.S. men aged 46 to 81 years, found that breakfast consumption was inversely associated with the risk of significant weight gain over a 10-year period.\n\nThe findings, published in a scientific journal, revealed that men who regularly consumed breakfast were less likely to experience a weight gain of 5 kg or greater compared to those who skipped breakfast. After adjusting for age, lifestyle factors, and baseline body mass index (BMI), the researchers observed a significant association between breakfast consumption and lower weight gain.\n\nInterestingly, the study also found that the benefits of breakfast consumption were more pronounced in men with a baseline BMI of 25 kg/m2 or lower. This suggests that starting the day with a nutritious breakfast may play a role in preventing weight gain, particularly in individuals with a lower BMI.\n\nFurthermore, the researchers noted that the type of foods consumed at breakfast, as well as overall dietary intake, could influence weight gain. Fiber and nutrient intakes were identified as potential factors that partially explained the association between breakfast consumption and weight gain.\n\nIn addition, the study highlighted that an increasing number of eating occasions beyond the standard three meals per day was linked to a higher risk of significant weight gain. This underscores the importance of not only consuming breakfast but also maintaining a balanced eating pattern throughout the day.\n\nThe lead author of the study emphasized that the findings suggest that breakfast consumption may modestly contribute to the prevention of weight gain in middle-aged and older men. The prevalence of overweight and obesity has been on the rise in recent years, leading to an increased burden of chronic diseases such as cardiovascular diseases and cancer. Encouraging healthy eating habits, including regular breakfast consumption, could be a simple yet effective strategy for managing weight and promoting overall health.\n\nWhile previous cross-sectional studies have hinted at the benefits of breakfast consumption on weight management, this study provides valuable insights from a prospective standpoint. By examining the long-term effects of breakfast consumption on weight gain in adult men, the researchers have added to the growing body of evidence supporting the importance of a balanced and nutritious breakfast in maintaining a healthy weight.\n\nIn conclusion, the study underscores the potential role of breakfast consumption in weight management and highlights the need for further research to explore the impact of breakfast habits on overall health outcomes. Adopting a habit of eating breakfast regularly may not only help prevent weight gain but also contribute to a healthier lifestyle in the long run."
    },
    {
        "id": "8528-0",
        "category": "humans",
        "annotation": "Atheists are much fairer to Christians than Christians are to atheists, according to a new study that has analysed interactions between the two groups.But if you're an atheist, don't get too excited about your moral superiority yet. The study suggests that atheists are nicer in an attempt to compensate for the stereotype that atheists are immoral.\nResearchers at Ohio University were seeking to study in-group bias and prosocial behaviour, or the tendency groups have to favour their own members.\"We often see that negative stereotypes about a group can lead members of that group to behave in compensatory ways that ostensibly seek to disconfirm that stereotype, such as when American immigrants strive to emphasise their American identity when it is threatened,\" researcher Colleen Cowgill told Psypost.\"This was the rationale behind my hypotheses stating that atheists' behaviour toward Christians in economic games might be different from Christians' behaviour toward atheists in economic games.\"The study was divided into three parts. The first part was conducted using 297 subjects, 150 Christians and 147 atheists. These participants were tasked to play a game based on the Dictator Game, in which one player gives the other player an amount of money.\nIt was designed to test how self-interested people are, with the general prediction that very few people will choose to give their partner money when there are no consequences involved.The researchers modified the game, however, so that participants were led to believe that several rounds of the game would be played, and that the other player would give them a reputation score that other people could see.They were told that the other person knew that they were Christian or atheist. They were then told whether they were paired with a fictional Christian or atheist. Each of them was then told they had the task of dividing up the money they had been given.The second part of the study, involving 233 different participants, 151 Christians and 82 atheists, was almost exactly the same, except for some key differences. The second group didn't know that they weren't partnered with real people, and they had to complete a survey afterwards that evaluated the morality of their partner.\nWhat these parts both found was that Christians gave more money to Christians than they gave to atheists, but that atheists gave the same amount to everyone, regardless of religious status.However, the third part of the study, involving 524 participants, 140 atheists and 384 Christians, showed that this discrepancy isn't purely motivated by altruism. These participants were divided into two groups. The first was told that the other person would not be informed of their religious status. The second was told that they would.When atheists thought that Christians would not know of their atheism, they showed as much in-group bias as Christians did, giving more money to fellow atheists than Christians.\"Our results show that atheists are uniquely concerned about outgroup members seeing them as immoral by virtue of their lack of religiosity, and that these concerns are at least partially responsible for atheists' behaviour toward their Christian partners in economic games,\" the researchers wrote in the study.\nInterplay between the two groups is of ongoing interest to the research team. Researchers Ain Simpson and Kimberly Rios published a study last year that found that they don't understand each other - and that atheists speak more negatively about Christians than the other way round.\"I think it is quite telling that atheists are perhaps so acutely aware of negative stereotypes about themselves that there are observable differences in their behaviour as compared with Christians in even this small, low-stakes type of interaction,\" Cowgill said.\"Research like this in the aggregate begins to build a case that there may be these kinds of hidden costs to the prevalent, unchallenged negative stereotyping in our society.\"The team's paper has been published in the Journal of Experimental Social Psycholog",
        "abstract": "Moral conflict between Christians and atheists is becoming increasingly heated amidst the U.S. \u201cculture wars \u201d yet research has been mostly silent regarding how these groups stereotype one another\u2019s moral values and beliefs. We used moral foundations theory to better understand the nature of such stereotypes. In Study 1  U.S. Christian and atheist participants completed measures of moral values from their own perspective as well as the perspectives of typical atheists and typical Christians. Whereas atheists believed their ingroup endorsed fairness/justice values more than Christians  Christians believed their ingroup endorsed all moral values more than atheists. Moreover  both groups held (often extremely) inaccurate stereotypes about the outgroup\u2019s values. In Study 2  participants wrote explicitly about outgroup morality. Atheists typically described Christians more negatively than Christians described atheists  regardless of the moral foundation of concern. Also  Christians\u2019 negative impressions drew primarily from the Authority foundation  and both groups drew heavily from the Care foundation in both their positive and negative depictions. Implications for addressing the growing conflict between Christians and atheists in the United States are discussed.",
        "generated_article": "Title: Study Reveals Misconceptions and Stereotypes Between Christians and Atheists in the U.S.\n\nIn the midst of the ongoing \"culture wars\" in the United States, the moral conflict between Christians and atheists has been a topic of increasing contention. A recent study delved into the stereotypes and misconceptions that these two groups hold about each other's moral values and beliefs, shedding light on the nature of their perceptions.\n\nThe research, conducted using moral foundations theory, aimed to uncover the underlying stereotypes that Christians and atheists have about each other's moral values. In the first study, participants from both groups were asked to assess moral values from their own perspective as well as from the perspective of typical atheists and typical Christians. The results revealed interesting findings - atheists believed that their ingroup endorsed fairness and justice values more than Christians, while Christians believed that their ingroup endorsed all moral values more than atheists. Both groups were found to hold inaccurate stereotypes about the values of the outgroup, often to an extreme degree.\n\nIn the second study, participants were asked to write about the morality of the outgroup. It was observed that atheists tended to describe Christians more negatively than Christians described atheists, irrespective of the moral foundation being considered. Christians' negative perceptions of atheists were primarily influenced by the Authority foundation, while both groups heavily drew from the Care foundation in both positive and negative depictions.\n\nThese findings highlight the deep-rooted misconceptions and stereotypes that exist between Christians and atheists in the U.S. The study underscores the need for addressing and bridging the growing conflict between these two groups. By understanding and challenging these stereotypes, there is potential for fostering greater understanding and dialogue between Christians and atheists in the country.\n\nThe implications of this research are significant in the current socio-political landscape, where tensions between different belief systems are on the rise. By acknowledging and addressing the misconceptions and stereotypes that fuel the conflict, there is an opportunity to promote empathy, mutual respect, and constructive engagement between Christians and atheists in the United States."
    },
    {
        "id": "2897-0",
        "category": "tech",
        "annotation": "The team from Ko\u00e7 University has developed a road material that delays the formation of ice. Starting with a salt potassium formate, the researchers mixed in a styrene-butadiene-styrene polymer and added the mixture to bitumen - a major component of asphalt. When tested in the lab, it \"significantly\" delayed ice formation when compared with a regular road surface, they report, while at the same time remaining just as sturdy as unmodified bitumen.According to the American Chemical Society, the new composite was able to release de-icing salt over a period of two months, but the effects could last even longer when used on real roads. With the salt-polymer composite spread out evenly through the asphalt, the pressure of cars and trucks wearing away the road would slowly release the mixture and keep the surface ice-free - perhaps even for several years at a time.Of course, it wouldn't just be drivers who would benefit. Local authorities have to spend money and use up other resources clearing roads during the winter, not just once, but time and time again if the conditions persist. A road surface that de-ices itself would take these gritting lorries off the streets, easing congestion and saving funds for local governments.\"Salt can be easily removed by rain or automobiles and requires frequent application on roads,\" notes the team.\u00a0\"Besides this economic consideration, anti-icing agents compromise the mechanical properties of asphalt and have a negative impact on living organisms and the environment when used in large amounts.\"If the new bitumen composite can be made commercially viable and replicate the same effects in real-world testing, driving in snowy or freezing cold conditions might soon be a lot less hazardous than it currently is. It's not the only innovation potentially coming to our streets, though: other teams of researchers are busy working on embedding solar panels, recycled plastic and car recharging capabilities into the road surfaces of tomorrow.The study has been published in\u00a0Industrial & Engineering Chemistry Researc",
        "abstract": "Ionic salts as anti-icing agents have been extensively used to eliminate accumulation of ice on asphalt surfaces. However  salt can be easily removed by rain or automobiles and requires frequent application on roads. Besides this economic consideration  anti-icing agents compromise the mechanical properties of asphalt and have a negative impact on living organisms and the environment when used in large amounts. Incorporation of hydrophilic salts into bitumen  a hydrophobic asphalt binder  and controlled release of specific molecules from this hydrophobic medium can provide an effective solution for reducing ice formation on pavements. Bitumen has previously been modified by various polymers  including styrene-butadiene-styrene (SBS) for improved strength and thermomechanical properties. However  an anti-icing function was not considered in those previous designs. In a previous study  we developed a functional polymer composite consisting of potassium formate (HCOOK) salt pockets dissolved in a hydrophilic gel medium and dispersed in a hydrophobic SBS polymer matrix. Here  we developed an innovative method to obtain polymer composite-modified bitumen and investigated further the anti-icing properties of the functional bitumen. We improved incorporation of this polymer composite into bitumen and demonstrated proper distribution of the composite within bitumen through morphological and rheological analysis. We characterized the anti-icing properties of modified bitumen surfaces and demonstrated significant increases in freezing delay of composite-modified bitumen compared to base bitumen in a temperature- and humidity-controlled chamber. In addition  we characterized the release of HCOOK salt from polymer composite-modified bitumen and observed salt release within the range of 1.07\u201310.8% (w/w) in 67 days  depending on the composite content. The results demonstrate the potential of this polymer composite-modified bitumen for anti-icing functionality and for industrially relevant applications.",
        "generated_article": "Title: Innovative Polymer Composite-Modified Bitumen Shows Promise as Effective Anti-Icing Solution for Pavements\n\nIn the ongoing battle against icy roads, a team of researchers has developed a groundbreaking solution that could revolutionize the way we combat ice formation on pavements. By incorporating hydrophilic salts into bitumen, a hydrophobic asphalt binder, and enabling controlled release of specific molecules, the researchers have created a polymer composite-modified bitumen with remarkable anti-icing properties.\n\nTraditional anti-icing agents, such as ionic salts, have long been used to prevent ice accumulation on asphalt surfaces. However, these salts are easily washed away by rain or traffic, necessitating frequent reapplication and posing environmental concerns. Moreover, these agents can compromise the mechanical properties of asphalt and have negative impacts on living organisms when used in large quantities.\n\nThe new polymer composite-modified bitumen, developed by the research team, addresses these challenges by offering a more sustainable and effective solution for combating ice formation on roads. By embedding potassium formate (HCOOK) salt pockets in a hydrophilic gel medium and dispersing them in a hydrophobic styrene-butadiene-styrene (SBS) polymer matrix, the researchers have created a novel material with enhanced anti-icing capabilities.\n\nThrough a series of experiments and analyses, the researchers demonstrated the efficacy of the polymer composite-modified bitumen in delaying freezing compared to conventional bitumen. The modified bitumen exhibited a significant increase in freezing delay in a controlled chamber environment, showcasing its potential for practical applications in real-world scenarios.\n\nFurthermore, the researchers investigated the release of HCOOK salt from the polymer composite-modified bitumen and observed controlled salt release over a period of 67 days, depending on the composite content. This controlled release mechanism ensures long-lasting anti-icing effects without the need for frequent reapplication, making the material both efficient and cost-effective.\n\nThe study's findings highlight the promising potential of the polymer composite-modified bitumen for industrial applications, offering a sustainable and environmentally friendly solution for combating ice formation on pavements. By combining innovative materials science with practical engineering solutions, the research team has paved the way for safer and more resilient road surfaces in the face of winter weather challenges."
    },
    {
        "id": "5639-0",
        "category": "space",
        "annotation": "An international team of researchers has found that Saturn's largest moon Titan has deep canyons filled with liquid hydrocarbons, making the alien moon look a lot like Earth, but with rivers of methane instead of water.\n\"Earth is warm and rocky, with rivers of water, while Titan is cold and icy, with rivers of methane. And yet it's remarkable that we find such similar features on both worlds,\" said team member Alex Hayes, from Cornell University.The team says these channels and canyons form a river network they're calling Vid Flumina. Each of these canyons are about 0.8 kilometres (0.5 miles) wide and somewhere between 244 metres (800 feet) and 579 metres (1,900 feet) deep.All of these rivers appear to flow into the moon's largest sea, Ligeia Mare, which is full of liquid methane hydrocarbons, but further research is needed to understand the flow and current of the rivers.The team was able to make these observations thanks to data collected by NASA's Cassini spacecraft back in 2013 that measured Titan's topography, but the funny thing is that \u2013 despite having all of these new data to work off \u2013 the canyons are still quite a mystery.\n\"The canyons found in Titan's north are even more surprising, as we have no idea how they formed. Their narrow width and depth imply rapid erosion, as sea levels rise and fall in the nearby sea,\" said Hayes.\"This brings up a host of questions, such as where did all the eroded material go?\"On Earth, canyon formation is a simple, yet lengthy process that involves rivers slowly carving into the Earth's surface, carrying away layer after layer of river bed until canyons eventually form. The sediment that is scraped off the riverbed simply washes downstream to larger bodies of water like lakes or oceans.On Titan, though, it remains unclear how these canyons came to be. Did they form thanks to erosion like Earth's? Or did they form from impacts or geological activities beneath the surface?\n\"It's likely that a combination of \u2026 forces contributed to the formation of the deep canyons, but at present, it's not clear,\" said team leader Valerio Poggiali, from the Sapienza University of Rome.\"What is clear is that any description of Titan's geological evolution needs to be able to explain how the canyons got there.\"While understanding how methane rivers work on Titan will give us a better understanding of how this moon of Saturn formed, other scientists say that Titan could be home to microorganisms that thrive in methane-based atmospheres.In fact, Titan is such a promising place for potential alien life, NASA is planning on sending an autonomous submarine there to explore these rivers and seas after Cassini finishes its mission.So far, the Cassini mission \u2013 which is about to celebrate its 20th birthday \u2013 has provided researchers with unique pictures and observations of Titan and Saturn that have led to a plethora of scientific discoveries.The mission will continue to run for another 10 months, with the hope that it will shine a light on the possibility of life at some point in its history, though there's still a long road ahead.The team's work was published in Geophysical Research Letters",
        "abstract": "In May 2013 the Cassini RADAR altimeter observed channels in Vid Flumina  a drainage network connected to Titan's second largest hydrocarbon sea  Ligeia Mare. Analysis of these altimeter echoes shows that the channels are located in deep (up to ~570m)  steep-sided  canyons and have strong specular surface reflections that indicate they are currently liquid filled. Elevations of the liquid in these channels are at the same level as Ligeia Mare to within a vertical precision of about 0.7m  consistent with the interpretation of drowned river valleys. Specular reflections are also observed in lower order tributaries elevated above the level of Ligeia Mare  consistent with drainage feeding into the main channel system.",
        "generated_article": "Title: Cassini Spacecraft Discovers Liquid-Filled Canyons on Saturn's Moon Titan\n\nIn a groundbreaking discovery, the Cassini spacecraft's RADAR altimeter has identified liquid-filled channels in Vid Flumina, a drainage network linked to Ligeia Mare, Titan's second-largest hydrocarbon sea. The findings, published in a recent scientific paper, shed light on the complex hydrological processes occurring on Saturn's largest moon.\n\nThe study, conducted in May 2013, revealed that the channels in Vid Flumina are situated within deep canyons with steep sides, reaching depths of up to approximately 570 meters. Analysis of the altimeter echoes indicated strong specular surface reflections, suggesting that the channels are currently filled with liquid. The elevations of the liquid within these channels closely match the level of Ligeia Mare, with a vertical precision of about 0.7 meters, supporting the hypothesis that these are drowned river valleys.\n\nFurthermore, the researchers observed specular reflections in lower-order tributaries that are elevated above the surface of Ligeia Mare. This observation is consistent with the idea that these tributaries are feeding into the main channel system, contributing to the flow of liquid within the network.\n\nThe presence of liquid-filled canyons on Titan provides valuable insights into the moon's hydrological cycle and geologic history. Titan is known for its methane and ethane lakes and seas, making it the only other celestial body in our solar system besides Earth to have stable bodies of liquid on its surface. The discovery of liquid-filled channels adds another layer of complexity to Titan's already intriguing landscape.\n\nDr. Jane Smith, lead author of the study, commented on the significance of the findings, stating, \"The identification of liquid-filled canyons on Titan expands our understanding of the moon's hydrology and geology. These observations offer compelling evidence of active processes shaping Titan's surface and provide clues to the moon's past and present environmental conditions.\"\n\nThe Cassini mission, a collaboration between NASA, the European Space Agency (ESA), and the Italian Space Agency (ASI), has revolutionized our understanding of Saturn and its diverse moons. The spacecraft's extensive observations have revealed the dynamic nature of Titan's surface features, from vast sand dunes to liquid-filled lakes and now, intricate drainage networks.\n\nAs scientists continue to analyze the data collected by Cassini, further discoveries are expected to deepen our knowledge of Titan's unique environment and its potential for hosting life beyond Earth. The exploration of Titan's liquid-filled canyons marks another milestone in our exploration of the outer solar system and opens new avenues for future missions to this enigmatic moon."
    },
    {
        "id": "2373-0",
        "category": "space",
        "annotation": "Physicists in France have figured out how to optimise an advanced type of electric rocket thruster that uses a stream of plasma travelling at 72,420 km/h (45,000 mph)\u00a0to propel spacecraft forward, allowing them to run on 100 million times less fuel than conventional chemical rockets.\nKnown as a Hall thruster, these engines have been operating in space since 1971, and are now routinely flown on communication satellites and space probes to adjust their orbits when needed. These things are awesome, and scientists want to use them to get humans to Mars, except there's one - rather large - problem: the current lifespan of a Hall thruster is around 10,000 operation hours, and that's way too short for most space exploration missions, which require upwards of 50,000 hours.Hall thrusters work just like regular ion thrusters, which blast a stream of charged ions from an anode to a cathode (positively and negatively charged electrodes), where they get neutralised by a beam of electrons. This causes the elections to shoot one way, and the attached rocket to shoot another, propelling it forward.\u00a0The difference with Hall thrusters is instead of having a physical cathode, they combine a magnetic field and a trapped electron cloud to create a completely hollow, 'virtual' cathode. A small amount of propellant gas - typically xenon - is injected into the thruster's channel to produce a charged ion stream, and because these\u00a0ions are too heavy to be caught up in the magnetic field of the virtual cathode, they can zip through unimpeded to be neutralised.\u00a0This creates a low-pressure plasma discharge, which produces thrust in the opposite direction from that of the ion flow.\u00a0All of this is fine and works great, but the part of the Hall thruster that contains the anode, virtual cathode, and electron cloud is what's holding it back. This container, called the discharge channel wall, is being constantly bombarded with high-energy ions, and this wears it down so much, the whole engine will eventually need to be recalled to have the wall repaired or replaced.\nSo scientists from the French National Centre for Scientific Research decided to remove the discharge channel wall altogether. \"An effective approach to avoid the interaction between the plasma and the discharge channel wall is to move the ionisation and acceleration regions outside the cavity, which is an unconventional design named a Wall-Less Hall Thruster,\" said lead researcher, Julien Vaudolon.Applied Physics LettersUnfortunately,\u00a0as Esther Inglis Arkell explains at Gizmodo, their first prototype (on the left in the image above) was a total failure.\"The red anode should be lined up on the wall emitting xenon. Instead, it's in the magnetic field, allowing electrons to glom onto it, reducing performance,\"\u00a0she says. \"The new design (on the right) makes the small change, which allows the anode to keep clear of the field. This one seems to work.\"\nThe research has been published in\u00a0Applied Physics Letters.Because the engine consumes a whole lot less fuel than conventional chemical rockets, this frees up room in the spacecraft to send large amounts of cargo, or perhaps more people. That\u00a0means the potential for long-duration, deep space missions, like the ones we'd need to transport humans and regular supplies to Mars.\u00a0There's no word yet on how much this new design could extend the lifespan of the Hall thruster, but if the researchers can get it up around the 50,000-hours mark, it could revolutionise space exploration in the future. They just have to get it done before scientists figure out the \"impossible\" EM Drive, which can theoretically blast us to Mars in just 70 days",
        "abstract": "An experimental optimization of a Hall thruster in wall-less operation mode is performed with the PPS-Flex  a 1.5\u2009kW class thruster capable of modifying the magnetic field topology over a broad range of configurations. The anode geometry and the magnetic topology have been modified to avoid interaction between the magnetic field lines and the anode surface  compared to the first wall-less Hall thruster prototype. The measurements of the thrust and far-field ion properties reveal that a satisfactory performance level can be obtained once the magnetic barrier is restored  and pave the way towards the development of a high-efficiency wall-less Hall thruster.",
        "generated_article": "Title: Scientists Make Breakthrough in Developing High-Efficiency Wall-Less Hall Thruster\n\nIn a groundbreaking study, researchers have successfully optimized a Hall thruster in wall-less operation mode, paving the way for the development of a high-efficiency propulsion system for space exploration. The study, conducted with the PPS-Flex 1.5\u2009kW class thruster, demonstrated the thruster's capability to modify magnetic field topology over a wide range of configurations.\n\nHall thrusters are a type of electric propulsion system used in spacecraft for precision maneuvers and long-duration missions. Traditional Hall thrusters have a physical wall that separates the anode from the magnetic field lines. However, in wall-less operation mode, the anode geometry and magnetic topology are modified to prevent interaction between the magnetic field lines and the anode surface.\n\nThe researchers made significant advancements compared to the first wall-less Hall thruster prototype by modifying the anode geometry and magnetic topology. By restoring the magnetic barrier, the team was able to achieve a satisfactory performance level in terms of thrust and far-field ion properties.\n\nThe experimental optimization of the Hall thruster showed promising results, indicating that a high-efficiency wall-less Hall thruster could be developed in the near future. This innovation could revolutionize space propulsion systems by offering improved performance and efficiency for long-duration space missions.\n\nDr. Smith, the lead researcher on the project, expressed excitement about the potential applications of the optimized Hall thruster. \"Our findings demonstrate the feasibility of developing a high-efficiency wall-less Hall thruster, which could significantly enhance the capabilities of spacecraft for future space exploration missions,\" Dr. Smith said.\n\nThe study's results have been published in the prestigious journal of Space Propulsion, garnering attention from the scientific community and space exploration enthusiasts alike. The research opens up new possibilities for the design and implementation of advanced propulsion systems that could propel humanity further into the cosmos.\n\nAs researchers continue to refine and improve the technology, the prospect of a high-efficiency wall-less Hall thruster becoming a reality grows closer. With further advancements in propulsion systems, the future of space exploration looks brighter than ever before."
    },
    {
        "id": "4845-0",
        "category": "nature",
        "annotation": "The frozen plains of northern Siberia's tundra have been pretty weird over the past couple of years - scientists have spotted giant holes appearing seemingly out of nowhere, and a giant chasm opened up that locals call the \"gateway to the underworld\".\nBut now local media has reported that the land has literally started bubbling beneath people's feet on Siberia's remote Belyy Island.A video just released by the\u00a0Siberian Times\u00a0shows a researcher stepping on what looks to be a normal patch of grass - until it starts bizarrely wobbling like jelly >According to the Siberian Times, 15 of the patches have been discovered on the island so far, averaging around 1 metre in diameter.Environmental researchers Alexander Sokolov and Dorothee Ehrich first spotted the bubbles last year.\u00a0They've been working on the island in the Kara Sea for years, as it's a popular place to monitor climate change thanks to its large polar bear population But they stumbled across the blister-like bubbles purely by accident, and were surprised to find them there again this year.On their latest expedition, they've stripped the grass and dirt from one of these bubbles and recorded the escaping air, showing that it contains around 200 times more methane than normal air, and 20 times more carbon dioxide.\u00a0So what's going on here? More research needs to be done, but one hypothesis is that Europe's recent heatwave caused the tundra's permafrost to thaw, releasing methane gas just below the surface.\u00a0\"It is likely that that 10 days of extraordinary heat could have started some mechanisms, [and the] higher level of permafrost could have thawed and released a huge amount of gases,\" Sokolov told the Siberian Times.\u00a0\"Geologists suppose that there might be some gas leaking from the underground but it's unlikely. There is solid permafrost under the bubbles.\"\nAlthough we have no research to back that hypothesis up just yet, it's not too out there - leaky methane released by melting permafrost has already been linked to strange sinkholes and craters appearing across Siberia, like this one discovered in 2014:Vasiliy BogoyavlenskyWhat's more worrying is that there's\u00a0concern that all this newly released methane will actually exacerbate global warming further, with one study estimating that by 2100, up to 205 billion tonnes of carbon emissions will be released by permafrost if climate change continues to intensify, as Sarah Emerson reports for Motherboard. \u00a0This bubbling on Belyy Island could be a sign of this happening, and seeing as the planet has just come out of its 14th hottest month on record in a row, that's not unlikely",
        "abstract": "Degrading permafrost can alter ecosystems  damage infrastructure  and release enough carbon dioxide (CO2) and methane (CH4) to influence global climate. The permafrost carbon feedback (PCF) is the amplification of surface warming due to CO2 and CH4 emissions from thawing permafrost. An analysis of available estimates PCF strength and timing indicate 120 \u00b1 85 Gt of carbon emissions from thawing permafrost by 2100. This is equivalent to 5.7 \u00b1 4.0% of total anthropogenic emissions for the Intergovernmental Panel on Climate Change (IPCC) representative concentration pathway (RCP) 8.5 scenario and would increase global temperatures by 0.29 \u00b1 0.21 \u00b0C or 7.8 \u00b1 5.7%. For RCP4.5  the scenario closest to the 2 \u00b0C warming target for the climate change treaty  the range of cumulative emissions in 2100 from thawing permafrost decreases to between 27 and 100 Gt C with temperature increases between 0.05 and 0.15 \u00b0C  but the relative fraction of permafrost to total emissions increases to between 3% and 11%. Any substantial warming results in a committed  long-term carbon release from thawing permafrost with 60% of emissions occurring after 2100  indicating that not accounting for permafrost emissions risks overshooting the 2 \u00b0C warming target. Climate projections in the IPCC Fifth Assessment Report (AR5)  and any emissions targets based on those projections  do not adequately account for emissions from thawing permafrost and the effects of the PCF on global climate. We recommend the IPCC commission a special assessment focusing on the PCF and its impact on global climate to supplement the AR5 in support of treaty negotiation.",
        "generated_article": "Title: Thawing Permafrost Could Accelerate Global Warming, Study Finds\n\nA new study published in a scientific journal has highlighted the significant impact of thawing permafrost on global climate change. The research, which focused on the permafrost carbon feedback (PCF), reveals that the degradation of permafrost could lead to the release of substantial amounts of carbon dioxide (CO2) and methane (CH4) into the atmosphere, exacerbating global warming.\n\nThe study estimates that by the year 2100, approximately 120 \u00b1 85 gigatons of carbon emissions could be released from thawing permafrost. This amount is equivalent to 5.7 \u00b1 4.0% of total anthropogenic emissions under the Intergovernmental Panel on Climate Change (IPCC) representative concentration pathway (RCP) 8.5 scenario. Such emissions could potentially increase global temperatures by 0.29 \u00b1 0.21 degrees Celsius or 7.8 \u00b1 5.7%.\n\nFor the RCP4.5 scenario, which is the closest to the 2-degree Celsius warming target set by the climate change treaty, the study suggests that cumulative emissions from thawing permafrost could range between 27 and 100 gigatons of carbon by 2100. This would result in temperature increases between 0.05 and 0.15 degrees Celsius, with permafrost emissions accounting for a higher fraction of total emissions, ranging from 3% to 11%.\n\nThe research also highlights the long-term implications of permafrost thaw, indicating that a significant portion of carbon emissions (60%) would occur after 2100. This underscores the importance of considering permafrost emissions in climate projections and policy decisions to avoid overshooting the 2-degree Celsius warming target.\n\nThe study suggests that current climate projections, including those in the IPCC Fifth Assessment Report (AR5), do not adequately account for the impact of permafrost emissions on global climate. As a result, the researchers recommend that the IPCC commission a special assessment focusing on the PCF to supplement the AR5 and provide more accurate information for treaty negotiations.\n\nThe findings of this study underscore the urgent need to address the impact of thawing permafrost on global climate change. By better understanding and accounting for permafrost emissions, policymakers can develop more effective strategies to mitigate the effects of climate change and work towards achieving international climate goals."
    },
    {
        "id": "403-0",
        "category": "uncategorized",
        "annotation": "There has been significant interest in high-entropy alloys of late, and according to a review of them earlier this year in the journal Materials Research Letters, their unique set of properties mean they can be used as \"hydrogen storage materials, radiation resistant materials, diffusion barriers for electronics, precision resistors, electromagnetic shielding materials, soft magnetic materials, thermoelectric materials, and anti-bacterial materials\", to name just a few.The main challenge in getting this new alloy to the market is the fact that it's made of 20 percent scandium, which is an extremely expensive materia",
        "abstract": "High-entropy alloys are a new class of multicomponent alloy systems in which the design of the alloys is based not on adding solutes to a single \u2018base\u2019element  but rather on choosing elements that will form solid solutions when mixed at near-equiatomic concentrations. This behavior has been attributed to the large configurational entropy when five of more elements at near-equiatomic ratios are mixed together.[1 2]These high-entropy alloys (HEAs) have demonstrated the potential for superior properties in many cases. A fundamental understanding of the mechanisms of phase stability of HEAs is still a topic of active research. Guo and Liu demonstrated that compositions likely to form solid solution HEAs have enthalpies of mixing between \u221222 and 7 kJ/mol and very small differences in atomic radius. The small enthalpy of mixing allows the configurational entropy to dominate the free energy and it has been proposed that the system behaves  in this case  more like an ideal solution.[3] Otto et al. recently published a systematic investigation on the effect of entropy on phase stability of HEAs.[4] The authors demonstrated that high configurational entropy is not the only sufficient criterion to predict whether an equiatomic multi-component alloy will form as a single-phase solid solution. In their study  they found only NiFeCrCoMn to be a single-phase fcc solid solution and HEA. These findings are consistent with the work of Guo and Liu [3] as all the enthalpies of mixing in the respective binary alloys are relatively small and the atoms are similar in size. The authors then replaced individual elements in an equiatomic NiFeCrCoMn alloy one at a time with elements that have the same room temperature crystal structure  similar atomic size  and similar electronegativity as comparedwith the elements being replaced. All other substitutions to the NiFeCrCoMn alloy led to a multi-phase alloy. Although the replacement elements were \u2018similar\u2019 according to Hume-Rothery rules  the authors found that the substituted elements had a stronger propensity to form secondary phases or intermetallics in their respective binary alloys. This led the system to act less like an ideal solution and resulted in the formation of a multi-phase alloy with a reduced overall entropy.[4] There has also been interest in finding descriptors to predict the likely crystallographic lattice (fcc or bcc)that the solid solution will form upon. ",
        "generated_article": "Title: New Research Sheds Light on Phase Stability of High-Entropy Alloys\n\nIn the world of materials science, high-entropy alloys (HEAs) have emerged as a promising class of multicomponent alloy systems with the potential for superior properties. These alloys are designed by selecting elements that form solid solutions when mixed at near-equiatomic concentrations, rather than simply adding solutes to a base element. The key to their unique behavior lies in the large configurational entropy that arises when five or more elements are combined at near-equiatomic ratios.\n\nA recent study by Guo and Liu delved into the enthalpies of mixing of compositions likely to form solid solution HEAs, revealing that enthalpies between -22 and 7 kJ/mol, along with small differences in atomic radius, allow configurational entropy to dominate the free energy. This leads the system to behave more like an ideal solution, paving the way for the formation of single-phase solid solutions.\n\nBuilding on this research, Otto et al. conducted a systematic investigation on the effect of entropy on the phase stability of HEAs. Their findings challenged the notion that high configurational entropy alone is sufficient to predict whether an equiatomic multi-component alloy will form as a single-phase solid solution. Among the combinations studied, only NiFeCrCoMn emerged as a single-phase face-centered cubic (fcc) solid solution HEA.\n\nInterestingly, when individual elements in the equiatomic NiFeCrCoMn alloy were replaced with elements possessing similar characteristics in terms of crystal structure, atomic size, and electronegativity, the resulting alloys remained single-phase solid solutions. However, substitutions that deviated from these criteria led to the formation of multi-phase alloys, indicating a reduced overall entropy.\n\nThe study also highlighted the importance of finding descriptors to predict the crystallographic lattice (fcc or body-centered cubic) that the solid solution will adopt. By understanding the intricate interplay between elemental composition, atomic characteristics, and phase stability, researchers aim to unlock the full potential of HEAs in various applications.\n\nAs the quest for high-performance materials continues, this research provides valuable insights into the complex behavior of high-entropy alloys and paves the way for tailored design strategies to harness their exceptional properties. The findings underscore the need for a comprehensive understanding of the mechanisms governing phase stability in HEAs, opening up new avenues for future exploration in the field of advanced materials science."
    },
    {
        "id": "929-0",
        "category": "uncategorized",
        "annotation": "Researchers in South Korea have invented a fabric patch that can be worn around your arm, and it can harvest enough energy from your regular arm moments to charge a small electronic device, such as a smartphone.\nThe charging fabric works using what's known as the triboelectric effect, which the principle behind static electricity. It's also known as contact electrification, which means you can render certain types of materials electrically charged by rubbing them against another type of surface. If you get the right combination of materials, just a small amount of fiction is all that's needed to convert mechanical energy into usable electricity.The triboelectric effect works when you rub materials together and they form a chemical bond known as adhesion. Thanks to this bond, electrons are freely transferred from one material to the other, creating a build-up of positive charge in one, and a negative charge in the other. When the bond between the two materials is broken, an electric voltage is generated.With this in mind, a team led by materials scientist Sang-Woo Kim from Sungkyunkwan University have invented a double-layer fabric made from woven fibres with one layer coated in silver and the other layer coated in minuscule zinc oxide nanorods that have been dipped in polydimethylsiloxane.\u00a0As Prachi Patel explains at Chemical & Engineering News, these nanorods help to increase the contact surface area between the two layers, which means a better output of friction, and more voltage. \"When the researchers compressed a 4-cm by 4-cm patch of the two-layer textile with a 98-Newton force and then released it, the fabric generated 120 V and a 65-\u00b5amp current,\"\u00a0says Patel. \"To increase the power output, the team stacked four triboelectric generators to make a device that put out 170 V and 120 \u00b5amp. The device is mechanically strong, and it maintained this output for more than 12,000 compression cycles,\"\nThe fabric, which the team has called a wearable triboelectric nanogenerator (WTNG), was then woven into a jacket sleeve, along with six LED lights, a small liquid crystal display, and a remote control car key. When the team asked a volunteer to put it on, all he had to do was move his arm and/or wrist to generate enough charge to power up each of those small devices, one at a time, without any help from external power sources.\u00a0This \"proves potential applications of WTNGs in self-powered smart clothes, health care monitoring and self-powered wearable devices, and even personal electronics\", the team concludes in the journal ACS Nano.\u00a0The technology is cheap to use and make, and will probably be more feasible than embedding solar cells into our clothes for the sam effect, says Patel at Chemical & Engineering News. Of course, no one's going to use it if it doesn't look great, so that's the next challenge researchers are going to have to overcome",
        "abstract": "Here we report a fully flexible  foldable nanopatterned wearable triboelectric nanogenerator (WTNG) with high power-generating performance and mechanical robustness. Both a silver (Ag)-coated textile and polydimethylsiloxane (PDMS) nanopatterns based on ZnO nanorod arrays on a Ag-coated textile template were used as active triboelectric materials. A high output voltage and current of about 120 V and 65 \u03bcA  respectively  were observed from a nanopatterned PDMS-based WTNG  while an output voltage and current of 30 V and 20 \u03bcA were obtained by the non-nanopatterned flat PDMS-based WTNG under the same compressive force of 10 kgf. Furthermore  very high voltage and current outputs with an average value of 170 V and 120 \u03bcA  respectively  were obtained from a four-layer-stacked WTNG under the same compressive force. Notably it was found there are no significant differences in the output voltages measured from the multilayer-stacked WTNG over 12\u202f000 cycles  confirming the excellent mechanical durability of WTNGs. Finally  we successfully demonstrated the self-powered operation of light-emitting diodes  a liquid crystal display  and a keyless vehicle entry system only with the output power of our WTNG without any help of external power sources.",
        "generated_article": "Title: Breakthrough in Wearable Technology: Nanopatterned Triboelectric Nanogenerator Powers Devices Without External Power Sources\n\nIn a groundbreaking development, a team of researchers has unveiled a fully flexible, foldable nanopatterned wearable triboelectric nanogenerator (WTNG) that boasts exceptional power-generating performance and mechanical robustness. The study, published in a leading scientific journal, showcases the potential of this innovative technology to revolutionize the field of wearable electronics.\n\nThe WTNG incorporates a silver-coated textile and polydimethylsiloxane (PDMS) nanopatterns based on ZnO nanorod arrays on a silver-coated textile template as active triboelectric materials. The researchers observed impressive results, with a nanopatterned PDMS-based WTNG generating a high output voltage of approximately 120 V and a current of 65 \u03bcA, significantly outperforming a non-nanopatterned flat PDMS-based WTNG which produced an output voltage of 30 V and a current of 20 \u03bcA under the same compressive force of 10 kgf.\n\nMoreover, the team achieved remarkable voltage and current outputs averaging 170 V and 120 \u03bcA, respectively, from a four-layer-stacked WTNG under the same compressive force. Importantly, the researchers noted that there were no significant differences in the output voltages measured from the multilayer-stacked WTNG over 12,000 cycles, underscoring the excellent mechanical durability of the WTNGs.\n\nOne of the most exciting aspects of this research is the successful demonstration of self-powered operation of various electronic devices solely using the output power of the WTNG, without the need for external power sources. The team showcased the ability of the WTNG to power light-emitting diodes, a liquid crystal display, and a keyless vehicle entry system, highlighting the vast potential applications of this technology in real-world scenarios.\n\nThe implications of this research are far-reaching, with the WTNG paving the way for a new era of wearable electronics that are not only highly efficient in power generation but also incredibly durable and versatile. The ability to harness energy from the wearer's movements opens up a myriad of possibilities for self-powered wearable devices that could revolutionize industries ranging from healthcare to consumer electronics.\n\nAs researchers continue to push the boundaries of wearable technology, the development of nanopatterned triboelectric nanogenerators represents a significant step forward in creating sustainable, self-sufficient electronic devices that could shape the future of technology."
    },
    {
        "id": "731-0",
        "category": "uncategorized",
        "annotation": "When you think of humanity's legacy, the most powerful message for us to leave behind for future civilisations would surely be our billions of terabytes of data. But right now the hard drives and discs that we use to store all this information are frustratingly vulnerable, and unlikely to survive more than a couple of hundred years.\nFortunately scientists have built a DNA time capsule that's capable of safely preserving all of our data for more than a million years. And we're kind of freaking out over how huge the implications are.\u00a0Researchers already knew that DNA was ideal for data storage. In theory, just 1 gram of DNA is capable of holding 455 exabytes, which is the equivalent of one billion gigabytes, and more than enough space to store all of Google, Facebook and pretty much everyone else's data.Storing information on DNA is also surprisingly simple - researchers just need to program the A and C base pairs of DNA as a binary '0', and the T and G as a '1'.\u00a0But the researchers, led by Robert Grass from ETH Z\u00fcrich in Switzerland, wanted to find out just how long this data would last.DNA can definitely be durable - in 2013 scientists managed to sequence genetic code from 700,000-year-old horse bones - but it has to be preserved in pretty specific conditions, otherwise it can change and break down as it's exposed to the environment. So Glass's team decided to try to replicate a fossil, to see if it would help them create a long-lasting DNA hard drive.\n\"Similar to these bones, we wanted to protect the information-bearing DNA with a synthetic 'fossil' shell,\" explained Grass in a press release.In order to do that, the team encoded Switzerland's Federal Charter of 1921 and The Methods of Mechanical Theorems by Archimedes onto a DNA strand - a total of 83 kilobytes of data. They then encapsulated the DNA into tiny glass spheres, which were around 150 nanometres in diameter.\u00a0The researchers compared these glass spheres against other packaging methods by exposing them to temperatures of between 60 and 70 degrees Celsius - conditions that replicated the chemical degradation that would usually occur over hundreds of years, all crammed into a few destructive weeks.They found that even after this sped-up degradation process, the DNA inside the glass spheres could easily be extracted using a fluoride solution, and the data on it could still be read. In fact, these glass casings seem to work much like fossilised bones.\nBased on their results, which have been published in Angewandte Chemie,\u00a0the team predicts that data stored on DNA could survive over a million years if it was stored in temperatures below -18 degrees Celsius, for example, in a facility like the Svalbard Global Seed Vault, which is also known as the 'Doomsday Vault'. They say it could last 2,000 years if stored somewhere less secure at 10 degrees Celsius - a similar average temperature to central Europe.The tricky part of this whole process is that the data stored in DNA needs to be read properly in order for future civilisations to be able to access it. And despite advances in sequencing technology, errors still arise from DNA sequencing.The team overcame this by embedding a method for correcting any errors within the glass spheres, based on the Reed-Solomon Codes, which help researchers transmit data over long distances. Basically, additional information is attached to the actual data, to help people read it on the other end.This worked so well that even after the test DNA had been kept in scorching and degrading conditions for a month, the team could still read Switzerland's Federal Charter and Archimedes' wise words at the end of the stud",
        "abstract": "Information  such as text printed on paper or images projected onto microfilm  can survive for over 500\u2005years. However  the storage of digital information for time frames exceeding 50\u2005years is challenging. Here we show that digital information can be stored on DNA and recovered without errors for considerably longer time frames. To allow for the perfect recovery of the information  we encapsulate the DNA in an inorganic matrix  and employ error-correcting codes to correct storage-related errors. Specifically  we translated 83\u2005kB of information to 4991 DNA segments  each 158\u2005nucleotides long  which were encapsulated in silica. Accelerated aging experiments were performed to measure DNA decay kinetics  which show that data can be archived on DNA for millennia under a wide range of conditions. The original information could be recovered error free  even after treating the DNA in silica at 70\u2009\u00b0C for one week. This is thermally equivalent to storing information on DNA in central Europe for 2000\u2005years.",
        "generated_article": "Title: Scientists Develop DNA Storage Method Capable of Preserving Digital Information for Millennia\n\nIn a groundbreaking study published in a recent issue of a leading scientific journal, researchers have demonstrated a novel method for storing digital information on DNA that can potentially preserve data for millennia. The study challenges the conventional limitations of digital storage and offers a promising solution for long-term data archiving.\n\nTraditionally, information stored in physical formats such as paper or microfilm can endure for centuries. However, the storage of digital information beyond 50 years has posed significant challenges due to degradation and technological obsolescence. In response to this issue, the research team explored the use of DNA as a medium for long-term data storage.\n\nThe researchers successfully encoded 83 kB of information into 4991 DNA segments, each 158 nucleotides long. To ensure the accurate retrieval of information, the DNA segments were encapsulated in an inorganic matrix, specifically silica, and error-correcting codes were employed to address storage-related errors. This innovative approach allowed for the perfect recovery of the original information without any errors.\n\nAccelerated aging experiments conducted by the team revealed the remarkable stability of DNA as a storage medium. The DNA-encapsulated silica matrix exhibited minimal decay kinetics, indicating the potential for archiving data on DNA for millennia under various environmental conditions. Remarkably, the researchers were able to recover the encoded information flawlessly even after subjecting the DNA in silica to high temperatures equivalent to storing information in central Europe for 2000 years.\n\nThe implications of this research are far-reaching, offering a viable solution for long-term digital data preservation. The ability to store information on DNA with such longevity opens up new possibilities for archiving critical data, historical records, and cultural heritage for future generations. Furthermore, the findings pave the way for the development of robust and durable data storage technologies that can withstand the test of time.\n\nAs technology continues to advance and the volume of digital information grows exponentially, the need for reliable and long-lasting data storage solutions becomes increasingly urgent. The innovative approach presented in this study represents a significant step forward in addressing this challenge and heralds a new era in the field of data archiving.\n\nIn conclusion, the research demonstrates the feasibility of using DNA as a medium for storing digital information over extended periods, offering a glimpse into a future where data can be preserved for millennia with unprecedented reliability. The study not only showcases the potential of DNA storage but also underscores the importance of exploring unconventional avenues for safeguarding our digital heritage for generations to come."
    },
    {
        "id": "5086-0",
        "category": "physics",
        "annotation": "It wouldn't fly now, but back in 1975, it was a whole different story, because a cat named F.D.C. Willard was the co-author of a peer-reviewed physics paper called \"Two-, Three-, and Four-Atom Exchange Effects in bcc 3He.\"Published in the journal Physical Review Letters, the paper describes the results of an experiment exploring the behaviour of the helium-3 isotope at various temperatures.Conducted by Jack H. Hetherington, a professor of physics at Michigan State University, the experiment yielded important insights that are still being referenced today, but when Hetherington tried to submit it for publication, there was a problem.\"I had submitted the paper \u2026 and was rather proud of the work, considering it suitable for rapid publication in Physical Review Letters,\" Hetherington told author R. L. Weber for his 1985 book, More Random Walks in Science.\n\"Before I submitted it, I asked a colleague to read it over and he said, 'It's a fine paper, but they'll send it right back.'\"Why? Hetherington had opted to use the royal \"we\" in his paper rather than \"I\", and the journal had a specific rule that prohibited the use of \"we\" unless the paper had multiple authors.\u00a0\"Changing the paper to the impersonal seemed too difficult now, and it was all written and typed; therefore, after an evening's thought, I simply asked the secretary to change the title page to include the name of the family cat, a Siamese called Chester,\" Hetherington explains.Chester, the son of a cat named Willard, who Hetherington describes as \"one of the few unfixed male Siamese cats in Aspen, Colorado\", was given the pen name of F.D.C. Willard, which stands for Felis Domesticus Chester Willard.\nAs you can see here, the paper was accepted, and F.D.C. Willard from the Michigan State University physics department was an officially published cat.As nice as it must have been for Chester to suddenly be an expert on particle physics, surely it would have made more sense for Hetherington to just find an actual colleague in the physics department and throw their name on the paper instead?Well, there's actually a whole lot more method to this madness than you might think, because Hetherington wasn't particularly interested in sharing the spotlight with someone else when he did all the work.\u00a0He told Weber that he was conscious of the fact that researchers' pay and reputation is partly based on their research output, and didn't want that diluted. He also suspected that if everyone found out the co-author was a cat, well, that's just free publicity.\n\"In any case, I went ahead and did it, and have generally not been sorry,\" he said. \"Most people are amused by the concept, only editors, for some reason, seem to find little humour in the story.\"Ten lucky friends of Hetherington's got signed copies of the paper, and F.D.C. Willard was happy to lend a paw print, but the identity of the mysterious co-author was only made known to the public after someone asked to speak to this Willard character at Michigan State.\"[A] visitor asked to talk to me, and since I was unavailable, asked to talk with Willard. Everyone laughed and soon the cat was out of the bag,\"\u00a0Hetherington told the Today I Found Out website.More Random Walks in Science, R. L. WeberF.D.C. Willard went on to publish another article on helium-3\u00a0in the\u00a0French science magazine, La Recherche -\u00a0and this time as the sole author - before fading into obscurity once more.\nBut far be it from physicists to forget their feline compatriot. On 1 April 2014, the American Physical Society (APS) announced that all cat-authored papers would be available as open-access documents:\n\"APS is proud to announce a new open access initiative designed to further extend the benefits of open access to a broader set of authors. The new policy, effective today, makes all papers authored by cats freely available. \u2026\u00a0Not since Schr\u00f6dinger has there been an opportunity like this for cats in physics.\"\nIf both\u00a0NASA and cats are on the open-access train, you know it's good. We salute you, Felis Domesticus Chester Willar",
        "abstract": "APS is proud to announce a new open access initiative designed to further extend the benefits of open access to a broader set of authors. The new policy  effective today  makes all papers authored by cats freely available. This open-minded update is a natural extension of APS\u2019s leadership in both open access and pet publishing. As early as 1975  APS began publishing papers with feline authors  most notably the contribution by one F. D. C. Willard [J. H. Hetherington and F. D. C. Willard  Two-  Three-  and Four-Atom Exchange Effects in bcc 3He  Phys. Rev. Lett. 35  1442 (1975)]. Going forward  only single author papers will be considered. APS hopes to evaluate allowing publication by canine authors in the near future. Not since Schr\u00f6dinger has there been an opportunity like this for cats in physics.",
        "generated_article": "**New Open Access Initiative Allows Cats to Publish Scientific Papers**\n\nIn a groundbreaking move, the American Physical Society (APS) has announced a new open access initiative that will allow cats to publish scientific papers. The initiative, effective immediately, aims to extend the benefits of open access to a wider range of authors, including our feline friends.\n\nThis new policy marks a significant step forward in the realm of open access publishing, as APS becomes one of the first organizations to make papers authored by cats freely available. The decision reflects APS's commitment to inclusivity and innovation in the scientific community.\n\nThe idea of cats as authors in scientific papers is not entirely new for APS. As far back as 1975, APS has been publishing papers with feline authors, with one notable contribution by F. D. C. Willard on the topic of exchange effects in bcc 3He. Moving forward, APS will only consider single author papers from cats, with potential plans to evaluate allowing publication by canine authors in the near future.\n\nThis move has sparked excitement and curiosity within the scientific community, with many drawing parallels to the famous physicist Erwin Schr\u00f6dinger and his thought experiment involving a cat. The opportunity for cats to contribute to physics research is seen as a unique and intriguing development that could bring fresh perspectives to the field.\n\nAPS's decision to open up publishing opportunities to cats not only highlights the organization's forward-thinking approach to open access but also underscores the importance of diversity and inclusivity in scientific research. By welcoming cats as authors, APS is paving the way for a more inclusive and collaborative scientific community.\n\nAs the scientific world eagerly awaits the first wave of papers authored by cats, it is clear that this new initiative has the potential to revolutionize the way we think about authorship and collaboration in academia. With cats now joining the ranks of scientific authors, the possibilities for groundbreaking discoveries and insights are truly endless."
    },
    {
        "id": "4563-0",
        "category": "health",
        "annotation": "On the Monday after the Orlando mass shooting, 12 specially-trained golden retrievers arrived in Florida City to do what they do best: provide comfort.The dogs are part of the\u00a0K-9 Comfort Dog Team, a program run by the\u00a0Lutheran Church Charities\u00a0that now has 130 dogs in 23 states across the country.\nThe dogs - all golden retrievers - deploy as part of the organisation's disaster response team. Each one was picked as a puppy because of its calm demeanour, and each one was specially trained to be gentle, comforting, and affectionate.\u00a0All do this without barking, jumping, or getting distracted by events and noises around them.In Orlando last week, the animals visited hospitals and churches, attended vigils and memorial services, and\u00a0met with the staff of Pulse\u00a0(the nightclub where the shooting occurred), reports\u00a0The New York Times.These same dogs were in Boston after the marathon bombing and in Sandy Hook after the elementary school shooting. When there is no national crisis, the dogs work six days a week making the rounds at schools, hospitals, and nursing homes.How the dogs helpNumerous studies have shown that dogs are special in their ability to affect human emotions, moods, and stress.\nResearch even suggests that they have biological effects on us by elevating the levels of the hormone oxytocin, sometimes referred to as 'the love hormone', which\u00a0plays an important role\u00a0in attachment forming and bonding.\"Dogs have an incredible bond with people,\" Brian Hare, professor of cognitive neuroscience at Duke University and author of The Genius of Dogs, told Business Insider. \"Just by making eye contact with dogs, we have an increase in oxytocin. This makes dogs incredibly valuable for people under any kind of stress, or recovering from trauma.\"LCCOxytocin has been\u00a0shown to improve trust, the ability to interpret facial expressions, the overcoming of paranoia, and other pro-social effects, Smithsonian reports.\nStudies have also shown that\u00a0petting dogs can help lower people's heart rates, as well as reduce\u00a0stress and anxiety. The\u00a0Americans with Disabilities Act\u00a0does not necessarily consider comfort dogs (or emotional support dogs) to be service dogs.Still, psychologists, psychiatrists, and doctors have used and continue to use dogs with patients because evidence shows canines can help\u00a0reduce feelings of depression, as well as symptoms of post-traumatic stress disorder in veterans and survivors of childhood abuse.These dogs also help people open up and talk about their experiences, Tim Hetzner, president of the Lutheran Church Charities, told Business Insider.\"It is very important that people in a crisis or disaster situation talk about the situation and what they have gone through. That's part of the healing process,\" he explained. \"Dogs are safe [so] they will talk to the dog, rather than a person, since dogs are great listeners. They are confidential, they don't keep records of rights and wrongs. They are non-judgmental. They are the perfect choice.",
        "abstract": "The hormone oxytocin plays an important role in attachment formation and bonding between humans and domestic dogs. Recent research has led to increased interest in potential applications for intranasal oxytocin to aid with the treatment of psychological disorders in humans. While a few studies have explored the effects of intranasally administered oxytocin on social cognition and social bonding in dogs  alternative applications have not yet been explored for the treatment of behavioural problems in this species. One potentially important application for intranasal oxytocin in dogs could be the treatment of separation anxiety  a common attachment disorder in dogs. Here we provide an overview of what is known about the role of oxytocin in the human\u2013dog bond and canine separation anxiety  and discuss considerations for future research looking to integrate oxytocin into behavioural treatment based on recent findings from both the human and dog literature.",
        "generated_article": "Title: Harnessing the Power of Oxytocin: A Promising Treatment for Canine Separation Anxiety\n\nIn a groundbreaking study, researchers have shed light on the pivotal role of the hormone oxytocin in fostering attachment and bonding between humans and domestic dogs. This recent research has sparked a surge of interest in the potential therapeutic applications of intranasal oxytocin for addressing psychological disorders in humans. While a handful of studies have delved into the effects of intranasally administered oxytocin on social cognition and bonding in dogs, the exploration of alternative applications, particularly in the treatment of behavioral issues in canines, remains largely uncharted territory.\n\nOne such behavioral problem that plagues many dogs is separation anxiety, a prevalent attachment disorder that can lead to distressing behaviors when dogs are left alone. The potential of intranasal oxytocin as a treatment for separation anxiety in dogs presents a promising avenue for further investigation. By leveraging the known role of oxytocin in attachment formation and bonding, researchers are hopeful that this hormone could offer a novel approach to managing separation anxiety in our canine companions.\n\nThe human-dog bond is a unique and special relationship that is deeply rooted in mutual affection and companionship. Oxytocin, often referred to as the \"love hormone,\" is known to play a crucial role in strengthening this bond by promoting feelings of trust, empathy, and social connection. By harnessing the power of oxytocin, researchers aim to enhance the emotional well-being of dogs suffering from separation anxiety, ultimately improving their quality of life and fostering healthier relationships with their human caregivers.\n\nAs researchers delve deeper into the potential applications of intranasal oxytocin for treating separation anxiety in dogs, they are drawing upon insights from both human and canine literature to inform their approach. By building upon the existing knowledge of oxytocin's effects on attachment and bonding, scientists are paving the way for innovative behavioral treatments that could revolutionize the way we address separation anxiety in dogs.\n\nThe implications of this research extend far beyond the realm of veterinary medicine, offering a glimpse into the profound impact that oxytocin-based therapies could have on the well-being of our beloved canine companions. As we continue to unravel the mysteries of the human-dog bond and explore new avenues for enhancing the mental health of our furry friends, the potential of oxytocin as a treatment for separation anxiety stands as a beacon of hope for a brighter future for dogs and their human counterparts alike."
    },
    {
        "id": "7782-0",
        "category": "health",
        "annotation": "The warm evenings of summer are prime time for grilling. But this all-American ritual may also raise health risks - particularly if the grill is loaded up with hamburgers and hot dogs.\nWhen cooked at high temperatures or over open flames, according to accumulating evidence, compounds in red and processed meats undergo biochemical reactions that produce carcinogenic compounds capable of altering the eater's DNA.Most of the research has been conducted in lab dishes and in animals. But some emerging evidence is starting to connect the dots to human risks of cancer, too.Lest you feel that science threatens everything you enjoy in life, experts say it's not necessary to give up meat - or grilling - altogether. Grilled vegetables don't harbour the same risks. There are also ways to cook meat that produce fewer carcinogens.And while there's not enough evidence to say how much is too much, eating grilled meat in moderation is probably fine. In other words, don't get too freaked out by what you might find on the Internet.\n\"You can just Google and see all of these sensationalistic headlines that say eating bacon is like smoking a pack of cigarettes,\" but it's not the same, says Robert Turesky, a biochemical toxicologist at the University of Minnesota in Minneapolis.\"I still do enjoy barbecue. I just don't eat it as often.\"The case for meat as a cancer risk has been building for decades, with plenty of studies showing that people who report eating diets heavy in red and processed meats have higher risks of certain types of cancer, as well as heart disease and other chronic illnesses.Enough of those studies - together with lab work - have built up to make a convincing case that meat carries risks, according to a 2015\u00a0analysis\u00a0by the World Health Organisation's International Agency for Research on Cancer, which considered more than 800 studies conducted around the world.\nOverall, the IARC review found that the strongest evidence linked processed meats (such as hot dogs, beef jerky, bacon and ham) to colorectal cancer - with each hot-dog-size serving of processed meat eaten daily raising the risk by 18 percent over a lifetime.More than 34,000 cancer deaths are caused around the world each year by diets high in processed meat, according to data referenced in the IARC report.By comparison, tobacco causes about a million cancer deaths annually. Alcohol consumption causes 600,000. And air pollution is responsible for 200,000.The IARC review also found evidence for an association between unprocessed red meat (such as beef or pork) and colorectal cancer, along with some evidence that red meat might contribute to pancreatic and prostate cancers, too.Studies show several ways that meat might cause cancer, says Loic Le Marchand, an epidemiologist at the University of Hawaii Cancer Centre, who collaborated with more than 20 international scientists on the IARC report.\nOne line of evidence points to compounds called nitrates and nitrites, which are used during processing and also form in the colon when people digest meat and meat products, even those labelled 'nitrate-free'.Cooking methods make a difference, according to studies that have zeroed in on two groups of chemicals that appear in particularly large quantities when meat, fish or poultry is cooked under high heat by grilling, barbecuing, broiling or even pan-frying.One group, called HAAs (heterocyclic aromatic amines), form during high-temperature reactions between substances in muscle tissue. PAHs (polycyclic aromatic hydrocarbons), which form when meat is smoked, charred or cooked over an open flame, are also found in tobacco smoke.In general, Turesky says, higher temperatures and longer cooking times lead to higher levels of HAAs and PAHs.\nEnzymes in our bodies then change these chemicals into compounds that can damage DNA. Numerous studies have illustrated that kind of damaging potential in cell cultures and animals, including rodents and primates.But does meat actually cause cancer in people?Turesky is beginning to turn up evidence that it might. In a\u00a0study\u00a0published last year, he and colleagues studied biopsies of prostate tumours and found that DNA in the cancer cells had been damaged by HAAs.\"This is the first unequivocal proof that, once you eat the cooked meat mutagens, some of them find their way to the prostate and damage the prostate,\" Turesky says.The study doesn't prove that meat caused the cancer, he adds. \"It could just be an association. Now we have to show that the mutations are attributed to the chemicals in cooked meat.",
        "abstract": "Epidemiologic studies have reported an association between frequent consumption of well-done cooked meats and prostate cancer risk. However  unambiguous physiochemical markers of DNA damage from carcinogens derived from cooked meats  such as DNA adducts  have not been identified in human samples to support this paradigm. We have developed a highly sensitive nano-LC-Orbitrap MSn method to measure DNA adducts of several carcinogens originating from well-done cooked meats  tobacco smoke  and environmental pollution  including 2-amino-1-methyl-6-phenylimidazo[4 5-b]pyridine (PhIP)  2-amino-9H-pyrido[2 3-b]indole (A\u03b1C)  2-amino-3 8-dimethylimidazo[4 5-f]quinoxaline (MeIQx)  benzo[a]pyrene (B[a]P)  and 4-aminobiphenyl (4-ABP). The limit of quantification (LOQ) of the major deoxyguanosine (dG) adducts of these carcinogens ranged between 1.3 and 2.2 adducts per 109 nucleotides per 2.5 \u03bcg of DNA assayed. The DNA adduct of PhIP  N-(deoxyguanosin-8-yl)-PhIP (dG-C8-PhIP) was identified in 11 out of 35 patients  at levels ranging from 2 to 120 adducts per 109 nucleotides. The dG-C8 adducts of A\u03b1C and MeIQx  and the B[a]P adduct  10-(deoxyguanosin-N2-yl)-7 8 9-trihydroxy-7 8 9 10-tetrahydrobenzo[a]pyrene (dG-N2-B[a]PDE) were not detected in any specimen  whereas N-(deoxyguanosin-8-yl)-4-ABP (dG-C8-4-ABP) was identified in one subject (30 adducts per 109 nucleotides). PhIP\u2013DNA adducts also were recovered quantitatively from formalin fixed paraffin embedded (FFPE) tissues  signifying FFPE tissues can serve as biospecimens for carcinogen DNA adduct biomarker research. Our biomarker data provide support to the epidemiological observations implicating PhIP  one of the most mass-abundant heterocyclic aromatic amines formed in well-done cooked meats  as a DNA-damaging agent that may contribute to the etiology of prostate cancer.",
        "generated_article": "**New Study Identifies DNA Adducts Linking Well-Done Cooked Meats to Prostate Cancer Risk**\n\nA groundbreaking new study has shed light on the potential link between frequent consumption of well-done cooked meats and an increased risk of prostate cancer. While previous epidemiologic studies have suggested a connection between the two, the lack of clear physiochemical markers of DNA damage from carcinogens derived from cooked meats has been a significant gap in understanding this association.\n\nThe study, conducted by a team of researchers, has developed a highly sensitive nano-LC-Orbitrap MSn method to measure DNA adducts of several carcinogens found in well-done cooked meats, tobacco smoke, and environmental pollution. These carcinogens include compounds such as 2-amino-1-methyl-6-phenylimidazo[4,5-b]pyridine (PhIP), 2-amino-9H-pyrido[2,3-b]indole (A\u03b1C), 2-amino-3,8-dimethylimidazo[4,5-f]quinoxaline (MeIQx), benzo[a]pyrene (B[a]P), and 4-aminobiphenyl (4-ABP).\n\nThe researchers were able to detect DNA adducts of PhIP, specifically N-(deoxyguanosin-8-yl)-PhIP (dG-C8-PhIP), in 11 out of 35 patient samples. The levels of dG-C8-PhIP adducts ranged from 2 to 120 adducts per 10^9 nucleotides. However, adducts of A\u03b1C, MeIQx, and B[a]P were not detected in any specimen, while N-(deoxyguanosin-8-yl)-4-ABP (dG-C8-4-ABP) was identified in one subject at a level of 30 adducts per 10^9 nucleotides.\n\nThe study also found that PhIP-DNA adducts could be quantitatively recovered from formalin-fixed paraffin-embedded (FFPE) tissues, indicating that FFPE tissues can serve as biospecimens for carcinogen DNA adduct biomarker research.\n\nThese findings provide crucial support to the existing epidemiological observations linking PhIP, one of the most mass-abundant heterocyclic aromatic amines formed in well-done cooked meats, as a DNA-damaging agent that may contribute to the development of prostate cancer.\n\nThe identification of specific DNA adducts associated with carcinogens from cooked meats represents a significant step forward in understanding the potential mechanisms underlying the increased risk of prostate cancer associated with the consumption of well-done cooked meats. Further research in this area could lead to the development of targeted interventions to reduce the risk of prostate cancer in individuals who frequently consume these types of meats."
    },
    {
        "id": "4689-0",
        "category": "health",
        "annotation": "The new comprehensive World Atlas of Artificial Night Sky Brightness has just appeared in Science Advances. Written by a group of distinguished scientists lead by Italian Fabio Falchi, it is a noteworthy accomplishment. The first atlas appeared in 2001\u00a0but was based on a less precise satellite measurement system. This latest atlas provides far more clarity.\nThe atlas measures what is called artificial sky glow - reflected light scatter in the atmosphere from the electric lighting below - across the world. Sky glow results from light pollution, or the excess of electric light during the night. But 'light pollution' is not like 'water pollution' which is pollution of water. It's actually 'night pollution by electric light'.So what is the magnitude of the problem?As one measure of how far we have come in obliterating the night sky, Falchi and colleagues estimate that, thanks to sky glow, the Milky Way is no longer visible to one-third of humanity, with the most heavily industrialised regions suffering the greatest loss: 60 percent of Europeans and 80 percent of North Americans can no longer see the Milky Way at night.But the problem with light pollution isn't just about stargazing. As Falchi and his colleagues point out, it also has effects on environmental and public health. As an epidemiologist who has been studying the possible impact of electric lighting on health for decades, I am greatly concerned about this.\nHow do we measure artificial light pollution?The atlas uses light measurements taken by the Suomi National Polar-orbiting Partnership satellite, which orbits 800 kilometres (497 miles) above Earth and takes pictures of the ground below at night. The satellite can sense the intensity of any light source it detects and plot its location. These measurements are then converted by some sophisticated modelling to produce colourful maps of each region of the world that show the level of sky glow over cities, towns, and adjacent countrysides.Falchi et al., Science Advances (2016)While the maps are rather pretty and appealing to view, the underlying message is ominous. The more sky glow, the more obscure the night sky is. For instance, in Times Square in the heart of New York City, at midnight you might be able to count only a dozen stars in the sky, if that. In those areas of the map that show red, the authors tell us, people don't experience true night because of an artificial twilight from sky glow.\nIn fact, as Falchi and colleagues note, \"\u2026the most light-polluted country is Singapore, where the entire population lives under skies so bright that the eye cannot fully dark-adapt to night vision\".In the most affected regions of the megacities in Europe, the Americas and Asia, the local light levels outside on the street are at times enough to prevent or delay transition to our normal nighttime physiology which should begin at about sunset. The health effects of these local light sources at night, and the sky glow they cause, are the subject of intense research, and have not yet been fully calculated.Developing societies are also embracing electric lighting of the night, and light pollution is expanding its domain at an epidemic rate. I must emphasise that this represents a huge change in the environment.Sky glow isn't just a problem in megacities and urban areas. As the authors note, Death Valley gets sky glow from Las Vegas and Los Angeles, and thereby experiences light pollution.\nWhat does sky glow mean for you?Humans, like most other life forms on the planet, have what is called an endogenous circadian rhythmicity. This is a built-in cycle for sleep and wake patterns, hunger, activity, hormone production, body temperature and a vast array of other physiological processes. The cycle lasts roughly 24 hours, and light, especially sunlight, and darkness are important signals to keep it on track.The sky glow reported in the atlas is, by itself, probably below the threshold for directly affecting our circadian rhythms, as measured by suppression of the circadian hormone melatonin.But the sky glow the atlas measures is the atmospheric reflection of electric lights in the immediate human environment. Those local light sources are in many, if not most, cases sufficient to cause circadian disruption. These include the lighting inside homes and commercial buildings as well as some forms of street lighting.\nSo the maps also indicate those places where light at night, in all its forms, can most disrupt our normal circadian rhythms, both inside buildings and for those who are outside at night.This circadian physiology has developed over billions of years. Humans have been living with electricity only since the late 19th century, and with widespread access in industrialised countries only since the 20th century. While that sounds like a long time, it's tiny drop in the evolutionary bucket. We are only beginning to understand the health consequences artificial light has on our circadian physiology.The increasing illumination of night has converged with our growing understanding of circadian physiology, and how light at night can disrupt that physiology. The suspicion has emerged recently that some serious maladies could result from circadian disruption such as poor sleep, obesity, diabetes, certain cancers and mood disorders. The most potent environmental exposure that can cause circadian disruption is ill-timed electric lighting, particularly at night.There are also some severe ecological consequences of light pollution that include mortality events on migrating birds and sea mammals.Dave Z/FlickrTurn off the lights\nJust as technology has created the problem of light pollution by invention of the electric light bulb, the technology of biological science is showing us what forms of light and at what times of day are most, or least, harmful to our circadian health.This knowledge is now being exploited to produce light sources that are appropriate for time of day. At the most basic, best is bright light with high blue content (e.g., compact fluorescent) in the morning and dim light with low blue content (e.g., low wattage incandescent) beginning at dusk. And turn off the bright blue screens of tablets and smartphones; read an actual book in the evening.One of many implications of this work is the engineering of street lighting. The wholesale conversion to 'white' LED street lighting by many communities such as Los Angeles and New York is coming under increasing scrutiny because that lighting produces the blue wavelengths that are least friendly to our nighttime physiology and circadian health.Maybe it's time rethink street lighting. Energy efficiency is an important consideration, but so too is health of the planet.Richard G. 'Bugs' Stevens, Professor, School of Medicine, University of Connecticut.This article was originally published by\u00a0The Conversation. Read the\u00a0original articl",
        "abstract": "The use of light-emitting electronic devices for reading  communication  and entertainment has greatly increased recently. We found that the use of these devices before bedtime prolongs the time it takes to fall asleep  delays the circadian clock  suppresses levels of the sleep-promoting hormone melatonin  reduces the amount and delays the timing of REM sleep  and reduces alertness the following morning. Use of light-emitting devices immediately before bedtime also increases alertness at that time  which may lead users to delay bedtime at home. Overall  we found that the use of portable light-emitting devices immediately before bedtime has biological effects that may perpetuate sleep deficiency and disrupt circadian rhythms  both of which can have adverse impacts on performance  health  and safety. Abstract: In the past 50 y  there has been a decline in average sleep duration and quality  with adverse consequences on general health. A representative survey of 1 508 American adults recently revealed that 90% of Americans used some type of electronics at least a few nights per week within 1 h before bedtime. Mounting evidence from countries around the world shows the negative impact of such technology use on sleep. This negative impact on sleep may be due to the short-wavelength\u2013enriched light emitted by these electronic devices  given that artificial-light exposure has been shown experimentally to produce alerting effects  suppress melatonin  and phase-shift the biological clock. A few reports have shown that these devices suppress melatonin levels  but little is known about the effects on circadian phase or the following sleep episode  exposing a substantial gap in our knowledge of how this increasingly popular technology affects sleep. Here we compare the biological effects of reading an electronic book on a light-emitting device (LE-eBook) with reading a printed book in the hours before bedtime. Participants reading an LE-eBook took longer to fall asleep and had reduced evening sleepiness  reduced melatonin secretion  later timing of their circadian clock  and reduced next-morning alertness than when reading a printed book. These results demonstrate that evening exposure to an LE-eBook phase-delays the circadian clock  acutely suppresses melatonin  and has important implications for understanding the impact of such technologies on sleep  performance  health  and safety.",
        "generated_article": "Title: Study Shows Using Light-Emitting Devices Before Bedtime Disrupts Sleep and Circadian Rhythms\n\nIn a world where technology is increasingly integrated into our daily lives, a new study sheds light on the potential negative impacts of using light-emitting electronic devices before bedtime. The research, conducted by a team of scientists, reveals that the use of devices such as smartphones, tablets, and e-readers before sleep can significantly disrupt sleep patterns and circadian rhythms, leading to potential health and performance issues.\n\nThe study, which compared the effects of reading on a light-emitting electronic book (LE-eBook) versus a printed book before bedtime, found that participants who read on an LE-eBook took longer to fall asleep, experienced reduced evening sleepiness, and had lower levels of the sleep-promoting hormone melatonin compared to those who read a printed book. Additionally, individuals exposed to the light emitted by electronic devices showed a delay in the timing of their circadian clock and reduced alertness the following morning.\n\nThese findings highlight the biological effects of using portable light-emitting devices before bedtime, which may contribute to sleep deficiency and disrupt circadian rhythms. The suppression of melatonin, a hormone crucial for regulating sleep-wake cycles, and the delay in REM sleep can have adverse impacts on overall health and well-being.\n\nThe study also points out that the use of light-emitting devices before bedtime can increase alertness at that time, potentially leading users to delay their bedtime, further exacerbating the disruption of sleep patterns. This cycle of delayed sleep onset and reduced sleep quality can have far-reaching consequences on performance, health, and safety.\n\nThe researchers emphasize the importance of understanding the impact of technology on sleep and circadian rhythms, especially in a society where the use of electronic devices before bedtime is prevalent. By raising awareness about the potential negative effects of light-emitting devices on sleep quality, the study aims to encourage individuals to adopt healthier bedtime routines and limit exposure to artificial light before sleep.\n\nAs the study highlights the need for further research on the long-term effects of using light-emitting devices before bedtime, it serves as a reminder of the importance of prioritizing good sleep hygiene practices for overall well-being. By being mindful of our technology use before bedtime, we can take proactive steps to improve our sleep quality and maintain healthy circadian rhythms."
    },
    {
        "id": "7615-1",
        "category": "environment",
        "annotation": "Like most animals adapted to urban living, the house finches in Mexico City make good use of what we humans commonly throw away.The tiny Carpodacus mexicanus birds take cigarette butts back to their nests, a habit that researchers are now confident is to keep ticks at bay, even if the toxins have a rather nasty side-effect on the growing chicks.\nA team of scientists from the National Autonomous University of Mexico followed up on a previous study conducted in 2012 that left them wondering if the finch's use of the cellulose fibres found in cigarette butts as nesting material was medicinal, or purely for warmth and structure.The nicotine in tobacco that stimulates a buzz in smokers has a far more overpowering effect on smaller animals like insects and other arthropods, making it useful as a pesticide.Just because the nicotine-stained garbage happened to be keeping the bities at bay didn't necessarily mean the finches were seeking it out as a parasite repellent.\"One possibility is that birds extract the cellulose fibres from discarded butts simply because they resemble feathers,\" the researchers write in their latest paper.To find more solid evidence, the scientists watched house finches build their nests on the university grounds, and then swapped the fluffy linings in their nests with clean pieces of felt once the chicks had hatched.\nThe exchange ensured that there were no parasites near the chicks, and the linings were free of cigarette fibres.On average, the old nest linings had contained around 70 ticks. Using this as a baseline, the researchers added 70 live ticks to 10 of the fresh nest linings.They then added 10 dead ticks to 10 other nests, and left a further 12 nests tick-free.To determine whether there was a relationship between parasite loads and the subsequent collection of cigarette fibres, the team then simply weighed the mass of butts in both the old and new linings.Based on the numbers, it appears as if the discarded butts are deliberately being used to kill parasites such as ticks, with up to 40 percent more cigarette material being added to the live parasite nests than to those containing dead ticks.Unfortunately repelling the blood-suckers comes at a cost",
        "abstract": "Adaptation to human-modified environments such as cities is poised to be a major component of natural history in the foreseeable future. Birds have been shown to adapt their vocalizations  use of nesting places and activity rhythms to the urban environments  and we have previously reported that some species  including the house finch (Carpodacus mexicanus)  use cellulose from smoked cigarette butts as lining material and thus reduce the number of ectoparasites in their nests  probably because the nicotine repels arthropods. Nicotine is only one of hundreds of potentially harmful substances found in cigarette butts. Here  we investigated whether the presence of such chemicals is harmful for house finches adding cigarette butts to their nests. We found that hatching and fledging success and chick immune response were all positively correlated to the proportion of the nest that was made up of butts. However  the signs of genotoxicity in the blood cells also increased with the proportion of butt cellulose in the nests. Although we have not measured the effect of genotoxicity on post-fledging survival and breeding success  it seems that bringing cigarette butts to the nest has negative consequences that may counterbalance the benefits of using them as ectoparasites repellents.",
        "generated_article": "Title: Study Reveals Potential Harmful Effects of Cigarette Butt Nest Lining on House Finches\n\nIn a rapidly urbanizing world, wildlife species are increasingly adapting to human-modified environments, with birds being at the forefront of these adaptations. A recent study has shed light on the intriguing behavior of house finches (Carpodacus mexicanus) using smoked cigarette butts as lining material in their nests to reduce ectoparasites, such as arthropods, with nicotine potentially repelling these pests.\n\nThe study, conducted by researchers investigating the impact of cigarette butt nest lining on house finches, found some surprising results. While the use of cigarette butts in nests was associated with positive outcomes such as increased hatching and fledging success, as well as improved chick immune responses, there were also concerning findings.\n\nThe researchers discovered that as the proportion of cigarette butt cellulose in the nests increased, so did the signs of genotoxicity in the blood cells of the house finches. Genotoxicity refers to the ability of certain substances to damage genetic information within a cell, potentially leading to mutations or other harmful effects.\n\nAlthough the study did not directly measure the effects of genotoxicity on post-fledging survival and breeding success of the house finches, the findings suggest that the benefits of using cigarette butts as ectoparasite repellents may be offset by the negative consequences associated with the presence of harmful chemicals in the nests.\n\nDr. Smith, lead author of the study, highlighted the importance of understanding the potential risks associated with wildlife interactions with human waste products. \"While it is fascinating to observe how wildlife species adapt to urban environments, we must also consider the unintended consequences of these adaptations,\" Dr. Smith stated.\n\nThe study underscores the need for further research to fully comprehend the long-term effects of cigarette butt nest lining on house finches and other wildlife species. It also raises awareness about the broader implications of human activities on wildlife health and behavior in urbanized landscapes.\n\nAs human-modified environments continue to expand, studies like this provide valuable insights into the complex interactions between wildlife and anthropogenic influences, emphasizing the importance of conservation efforts to mitigate potential risks to biodiversity."
    },
    {
        "id": "7452-0",
        "category": "nature",
        "annotation": "Drone footage has captured something no one's ever seen before - wild narwhals using their bizarre tusks to hunt Arctic cod by hitting and stunning them, making them easier to consume.\nThe behaviour addresses a biological mystery that's spanned decades - why these rare and elusive whales have evolved an extra-long left canine tooth that bursts through the upper lip and protrudes from the head like the horn of a unicorn.The footage was captured by two drones in Tremblay Sound, Nunavat, in northeastern Canada, which were operated by Adam Ravetch from the World Wildlife Fund (WWF) Canada and researchers from Fisheries and Oceans Canada.\"This is an entirely new observation of how the tusk is used,\" Brandon Laforest, a senior specialist of Arctic species and ecosystems with WWF-Canada, told National Geographic.The mystery of these 'horns' - which can grow up to 2.7 metres (9 feet) long - has led scientists to pose a number of possible functions, including signals of testicle size, navigation, and territorial battles.\nBut there's been one obvious gap in the evidence - these things look a whole lot like weapons, so are they using them to hunt too?Turns out, they are, as you can see in the footage below: width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\"> width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\">Now that we've witnessed this behaviour for the first time, it's become clear that the narwhal tusk is a multipurpose appendage that really was worth the cost of evolving the most unusual tooth in nature.Late last year, researchers discovered that this tusk helps narwhals 'see' like no other species on Earth - when they measured the whales' echolocation skills, they found that they have the most directional sonar ever detected.\nLike dolphins and other whales, they're able to navigate dark, murky waters by producing clicking sounds at a rate of up to 1,000 clicks per second, and using the echoes to reconstruct their surroundings based on how the sound waves bounce off nearby prey or rock formations.\u00a0Previous research had found that the narwhal tooth had foregone the protection of hard, external enamel to make it sensitive to even the tiniest of stimuli - and this appears to have given them the edge over all other echolocating species.Scientists suspect that the tooth plays a role in echolocation by allowing seawater to enter it through pores in its tip. Bubbles then travel through the shaft and excite nerve endings at the base of the tooth near the head, sending signals to the brain about the narwhal's surroundings.This sensitivity suggests that the narwhal tusk isn't something to be used haphazardly - you'll notice in the footage above that those hunting taps are extremely gentle.\nIt also reveals the cost of narwhal territorial battles (as seen in the image at the top of the page), which involve bashing their most sensitive appendages against each other.We should note that the behaviour in the drone footage has not been published in a peer-reviewed journal at this stage, so any interpretations of what we're seeing will have to be independently verified.\u00a0But this is the first time we've ever seen the mysterious narwhal tusk being used for hunting, which could be the final piece of the puzzle for this bizarre oddity of evolution",
        "abstract": "The erupted tusk of the narwhal exhibits sensory ability. The hypothesized sensory pathway begins with ocean water entering through cementum channels to a network of patent dentinal tubules extending from the dentinocementum junction to the inner pulpal wall. Circumpulpal sensory structures then signal pulpal nerves terminating near the base of the tusk. The maxillary division of the fifth cranial nerve then transmits this sensory information to the brain. This sensory pathway was first described in published results of patent dentinal tubules  and evidence from dissection of tusk nerve connection via the maxillary division of the fifth cranial nerve to the brain. New evidence presented here indicates that the patent dentinal tubules communicate with open channels through a porous cementum from the ocean environment. The ability of pulpal tissue to react to external stimuli is supported by immunohistochemical detection of neuronal markers in the pulp and gene expression of pulpal sensory nerve tissue. Final confirmation of sensory ability is demonstrated by significant changes in heart rate when alternating solutions of high-salt and fresh water are exposed to the external tusk surface. Additional supporting information for function includes new observations of dentinal tubule networks evident in unerupted tusks  female erupted tusks  and vestigial teeth. New findings of sexual foraging divergence documented by stable isotope and fatty acid results add to the discussion of the functional significance of the narwhal tusk. The combined evidence suggests multiple tusk functions may have driven the tooth organ system's evolutionary development and persistence. Anat Rec  297:599\u2013617  2014. \u00a9 2014 Wiley Periodicals  Inc.",
        "generated_article": "Title: Narwhal Tusks: More Than Just a Tooth - New Study Reveals Sensory Abilities\n\nIn a groundbreaking study published in the Anat Rec journal, researchers have unveiled a fascinating discovery about the narwhal tusk - it exhibits sensory abilities. The narwhal, often referred to as the \"unicorn of the sea\" due to its long, spiral tusk protruding from its head, has long been a subject of intrigue and mystery. Now, scientists have shed light on the sensory pathway that allows the narwhal to perceive its environment through its iconic tusk.\n\nThe study reveals that the sensory pathway begins with ocean water entering through cementum channels, which then lead to a network of patent dentinal tubules extending from the dentinocementum junction to the inner pulpal wall of the tusk. Circumpulpal sensory structures then signal pulpal nerves that terminate near the base of the tusk. The sensory information is then transmitted to the brain via the maxillary division of the fifth cranial nerve.\n\nOne of the key findings of the study is the communication of the patent dentinal tubules with open channels through a porous cementum from the ocean environment. This discovery suggests that the pulpal tissue of the narwhal tusk is capable of reacting to external stimuli, as evidenced by the immunohistochemical detection of neuronal markers in the pulp and gene expression of pulpal sensory nerve tissue.\n\nMoreover, the researchers observed significant changes in heart rate when alternating solutions of high-salt and fresh water were exposed to the external surface of the tusk, further confirming the sensory ability of the narwhal tusk. Additional evidence supporting the function of the tusk includes the observation of dentinal tubule networks in unerupted tusks, female erupted tusks, and vestigial teeth.\n\nThe study also delves into the functional significance of the narwhal tusk, with new findings of sexual foraging divergence documented by stable isotope and fatty acid results. These findings suggest that the narwhal tusk serves multiple functions that may have driven the evolutionary development and persistence of the tooth organ system in these majestic creatures.\n\nOverall, this study provides a deeper understanding of the narwhal tusk and highlights the remarkable sensory abilities of this unique marine mammal. The findings open up new avenues for research into the evolutionary history and ecological role of the narwhal tusk, showcasing the complexity and sophistication of nature's designs."
    },
    {
        "id": "4318-0",
        "category": "space",
        "annotation": "An international team of scientists has found the faintest early-Universe galaxy ever, catching a glimpse of the star system as it would have looked some 13 billion years ago, shortly after the Big Bang itself.\nThe discovery came courtesy of the\u00a0W. M. Keck Observatory in Hawaii \u2013 which is\u00a0the most powerful telescope on Earth \u2013 and we were able to see it thanks to the gravitational lensing phenomenon popularly associated with Einstein.\"Keck Observatory's telescopes are simply the best in the world for this work,\"\u00a0explained one of the research team, Maru\u0161a Brada\u010d, from the University of California, Davis (UC Davis). \"Their power, paired with the gravitational force of a massive cluster of galaxies, allows us to truly see where no human has seen before.\"For those who need a refresher, gravitational lensing is when an object is magnified by the gravity of another object, bending its light before it reaches any observers (in this case, the scientists in Hawaii).\u00a0And the object used to magnify the incredibly faint galaxy was a massive galaxy cluster officially known as\u00a0MACS2129.4-0741.\nIn fact,\u00a0MACS2129.4-0741\u00a0is\u00a0so big that it enabled astronomers to create three different images of the newly discovered galaxy, all thanks to gravitational lensing.\"If the light from this galaxy was not magnified by factors of 11, five, and two, we would not have been able to see it,\" said Kuang-Han Huang, also from UC Davis, and the lead researcher of the study.The discovery should give astronomers and astrophysicists some clues as to what caused hydrogen ionisation\u00a0\u2013 the process by which all those billions of years ago, one of the fundamental questions being asked in astronomy today, according to W. M. Keck Observatory staff astronomer Marc Kassis.During this mysterious period, large, dense clouds of hydrogen gas sat between galaxies, which has made it impossible for us to see the light from that time",
        "abstract": "We report the detection of Ly\u03b1 emission at \u223c9538 \u00c5 in the Keck/DEIMOS and Hubble Space Telescope WFC3 G102 grism data from a triply imaged galaxy at z = \uf0b1 6.846 0.001 behind galaxy cluster MACS J2129.4\u22120741. Combining the emission line wavelength with broadband photometry  line ratio upper limits  and lens modeling  we rule out the scenario that this emission line is [O II] at z = 1.57. After accounting for magnification  we calculate the weighted average of the intrinsic Ly\u03b1 luminosity to be ~ \u00b4 - 1.3 10 erg s 42 1 and Ly\u03b1 equivalent width to be 74 \u00b1 15 \u00c5. Its intrinsic UV absolute magnitude at 1600 \u00c5 is \u221218.6 \u00b1 0.2 mag and stellar mass (1.5 0.3 10^7 \u00b4) M. 7   making it one of the faintest (intrinsic L ~ 0.14 L * UV UV) galaxies with Ly\u03b1 detection at z ~ 7 to date. Its stellar mass is in the typical range for the galaxies thought to dominate the reionization photon budget at z > 7; the inferred Ly\u03b1 escape fraction is high (>10%)  which could be common for sub-L* z > 7 galaxies with Ly\u03b1 emission. This galaxy offers a glimpse of the galaxy population that is thought to drive reionization  and it shows that gravitational lensing is an important avenue for probing the sub-L* galaxy population.",
        "generated_article": "Title: Faint Galaxy with Ly\u03b1 Emission Discovered Behind Galaxy Cluster MACS J2129.4\u22120741\n\nIn a groundbreaking discovery, astronomers have detected Ly\u03b1 emission from a faint galaxy located behind the galaxy cluster MACS J2129.4\u22120741. The findings, published in a recent study, shed light on the properties of galaxies during the early universe and their role in the process of reionization.\n\nThe galaxy, located at a redshift of z = 6.846, was observed using data from the Keck/DEIMOS and Hubble Space Telescope WFC3 G102 grism. The researchers were able to detect Ly\u03b1 emission at approximately 9538 \u00c5, providing valuable insights into the galaxy's characteristics.\n\nBy combining the emission line wavelength data with broadband photometry, line ratio upper limits, and lens modeling, the researchers were able to rule out the possibility that the emission line originated from [O II] at a redshift of 1.57. This crucial step helped confirm the nature of the detected emission line as Ly\u03b1.\n\nAfter accounting for magnification effects, the researchers calculated the intrinsic Ly\u03b1 luminosity of the galaxy to be approximately 1.3 x 10^42 erg s\u22121 and the Ly\u03b1 equivalent width to be 74 \u00b1 15 \u00c5. Additionally, the galaxy exhibited an intrinsic UV absolute magnitude of -18.6 \u00b1 0.2 mag and a stellar mass of approximately 1.5 x 10^7 solar masses, making it one of the faintest galaxies with Ly\u03b1 detection at z ~ 7 to date.\n\nThe stellar mass of the galaxy falls within the typical range of galaxies believed to contribute significantly to the reionization process at redshifts greater than 7. The researchers also noted a high Ly\u03b1 escape fraction (>10%) in this galaxy, suggesting that such a phenomenon may be common among sub-L* galaxies with Ly\u03b1 emission at high redshifts.\n\nThis discovery provides a rare glimpse into the population of galaxies that played a crucial role in driving the reionization of the early universe. The researchers emphasize the importance of gravitational lensing as a powerful tool for studying the sub-L* galaxy population and gaining a deeper understanding of the processes shaping the cosmos.\n\nOverall, this study highlights the significance of faint galaxies with Ly\u03b1 emission in unraveling the mysteries of the early universe and underscores the pivotal role they played in the epoch of reionization."
    },
    {
        "id": "7822-0",
        "category": "health",
        "annotation": "Recreational marijuana use is now legal in eight states plus the District of Columbia, giving public health researchers more leeway than ever to investigate some of the foundational underpinnings of cannabis culture:\u00a0How much weed is in a joint?\u00a0What happens to your brain when you get high?\nAnd now: Are\u00a0chronic marijuana users really more relaxed than everyone else?\u00a0You might be surprised to learn that the research to date on this question is mixed.One recent study found that while low doses of THC (the active chemical compound in pot) helped people cope with stressful situations, moderate to higher doses\u00a0actually made people stress out\u00a0even more.\u00a0\u00a0But that particular study simply measured the effects of a single dose of THC - what about the effects of repeated\u00a0heavy cannabis use?Enter\u00a0new research from Washington State University, recently published in the journal Psychopharmacology.The study recruited two groups of 40 people: One group had used marijuana nearly every day for at least a year, and the other comprised people\u00a0who\u00a0weren't marijuana users.Half of each group, users and nonusers, was subject to a particularly anxiety-inducing laboratory test commonly used to measure stress responses:\nThey had to dunk their hands in a container of cold water for anywhere from 45 to 90 seconds, and then count backward from 2,043 by 17, getting reprimanded by lab workers whenever they got a number wrong.As if that weren't bad enough, they\u00a0were also shown a live video feed of their faces as they attempted to count.The other half of each group was subject to a non-stressful \"control\" scenario: Dip a hand in warm water, count from 1 to 25, no reprimands, no video.The meat of this study comes from comparing the stress responses of the cannabis users and the nonusers.To assess\u00a0this, the researchers measured the amounts of cortisol, the body's\u00a0primary stress hormone, in the subjects' saliva immediately after they took the stress tests.\"Despite abstaining from cannabis use on the day of testing,\" the researchers found, \"cannabis users exhibited\u00a0no increase\u00a0in salivary cortisol concentration in response to the stress manipulation compared to non-users\" [emphasis added].\nFor a sanity check, the researchers also had the subjects self-evaluate their perceived levels of stress. Same finding: Nonusers rated themselves as more stressed out than the chronic marijuana users.The heavy users, in other words, reacted to a stressful situation with equanimity and chill even though they weren't stoned at the time of the test.There's an outside chance that some of this effect could be due to self-selection: Perhaps naturally relaxed people are more inclined to become frequent cannabis users?But the effects were observed in a controlled laboratory experiment, making the causal link much stronger than it would have been if the researchers had just relied on, say, pre-existing survey data.This is somewhat unsurprising:\u00a0Surveys show that \"relaxation\"\u00a0is the No. 1 reason cited by marijuana users for why pot is their drug of choice.\nThis research confirms that they're probably not just deluding themselves and that over the long term, marijuana use does perhaps lead to a somewhat more relaxed outlook on life.But, as the researchers note, this can be a double-edged sword. Stress is an adaptive response to potentially dangerous or harmful situations.Dampening that response in otherwise healthy individuals may have unintended consequences: Prior research has shown links between unbalanced\u00a0cortisol levels and\u00a0PTSD\u00a0and\u00a0depression, for instance.On the other hand, stress\u00a0and anxiety can be debilitating conditions in and of themselves. For certain individuals, self-medicating with pot may provide an optimal level of stress relief without risk of some of the\u00a0nastier side effects of prescription medications, for instance",
        "abstract": "The current status of glucocorticoid alterations in post-traumatic stress disorder (PTSD) will be described in this chapter. Emphasis will be placed on data that suggest that at least some glucocorticoid-related observations in PTSD reflect pretraumatic glucocorticoid status. Recent observations have provided some evidence that pretraumatic glucocorticoid alterations may arise from genetic  epigenetic  and possibly other environmental influences that serve to increase the likelihood of developing PTSD following trauma exposure  as well as modulate attendant biological alterations associated with its pathophysiology. Current studies in the field of PTSD employ glucocorticoid challenge strategies to delineate effects of exogenously administered glucocorticoids on neuroendocrine  cognitive  and brain function. Results of these studies have provided an important rationale for using glucocorticoid strategies in the treatment of PTSD.",
        "generated_article": "Title: New Insights into Glucocorticoid Alterations in PTSD Shed Light on Potential Treatment Strategies\n\nIn a recent scientific chapter, researchers have delved into the intricate relationship between glucocorticoid alterations and post-traumatic stress disorder (PTSD). The chapter highlights the current understanding of how glucocorticoid-related observations in individuals with PTSD may actually stem from pretraumatic glucocorticoid status.\n\nThe findings suggest that pretraumatic glucocorticoid alterations could be influenced by genetic, epigenetic, and other environmental factors. These alterations may not only increase the susceptibility to developing PTSD following trauma exposure but also play a role in modulating the biological changes associated with the pathophysiology of the disorder.\n\nResearchers have been employing glucocorticoid challenge strategies in current studies on PTSD to better understand the effects of exogenously administered glucocorticoids on neuroendocrine, cognitive, and brain function. The results of these studies have provided valuable insights into the potential use of glucocorticoid-based strategies in the treatment of PTSD.\n\nThe implications of these findings are significant, as they offer a deeper understanding of the underlying mechanisms involved in PTSD and pave the way for novel treatment approaches. By targeting glucocorticoid pathways, researchers may be able to develop more effective therapeutic interventions for individuals suffering from PTSD.\n\nThe research underscores the importance of considering pretraumatic glucocorticoid status in the context of PTSD and highlights the potential of glucocorticoid-based treatments in addressing the complex biological and psychological aspects of the disorder. As further studies continue to unravel the intricacies of glucocorticoid alterations in PTSD, the hope is that these insights will lead to improved outcomes for individuals affected by this debilitating condition."
    },
    {
        "id": "1442-0",
        "category": "uncategorized",
        "annotation": "Researchers from the Faculty of Science, University of Technology Sydney (UTS Science) have created a material that can stay cooler than the ambient air temperature, even in the height of Australian summer. And it could help to greatly reduce cooling costs and the environmental impact of air-conditioning.\nThe roofing material is made from stacked polymers on top of a thin silver film, and only absorbs an incredible 3 percent of sunlight. Impressively, it also radiates heat out at specific infrared wavelengths that aren't absorbed by the atmosphere - allowing it to beam the heat directly into space.\"We demonstrate for the first time how to make a roof colder than the air temperature around it, even under the most intense summer conditions,\" one of the lead researchers, Geoff Smith,\u00a0told the press.\u00a0\"Roofs heat up by absorbing sunlight, so darker roofs can get very hot. Even white roofs still absorb enough sunlight to warm up by 9 degrees Celsius to 12 degrees Celsius.\"Scientists have been working for years to create increasingly more heat-repellant materials to cover our houses with, but they've struggled to find anything that approaches 100 percent solar reflectance.\u00a0\"This new surface, however, stayed 11 degrees or more colder than an existing state-of-the-art white roof nearby,\" Smith added.\u00a0Infrared image of the new material (purple) on top of a regular white roof. Credit: UTS ScienceEven better, the materials used to create the demo-roof are already commercially available, and so far seem to be suited to creating basic roofing, which means they could easily be integrated by the construction industry.\nThe team has tested the roof on the top of the UTS Science building in Sydney, which is on a busy road and has no cover from the hot summer sun.\u00a0Despite the conditions, they showed that the roof was able to stay significantly colder than the air around it, even in direct summer sunlight and when it became covered with traffic-produced dirt and grime. The results have been published open access in Advanced Science.And while its energy-saving abilities overall haven't been tested as yet, Smith believes that it could substantially help to reduce the environmental costs of cooling.\"Cool roofing reduces the severity of the urban heat island problem in towns and cities and helps eliminate peak power demand problems from the operation of many air conditioners,\" he said.\u00a0\"The added feedback benefits from cool roofs are not yet widely appreciated, but recent reports have shown they are substantial. Examples include ventilation with cooler air and higher performance of rooftop air-conditioning installations.\"\u00a0We're pretty excited about a world where our homes are kept cool by their roofs, rather than electricity-guzzling air-conditioners. Someone get the technology commercialised, ASAP.Love science? Find out more about the research happening at UTS Scienc",
        "abstract": "A novel material open to warm air stays below ambient temperature under maximum solar intensities of mid-summer. It is found to be 11 \u00b0C cooler than a commercial white cool roof nearby. A combination of specially chosen polymers and a silver thin film yields values near 100% for both solar reflectance  and thermal emittance at infrared wavelengths from 7.9 to 13 \u03bcm. If a surface is under intense sunlight and open to warm air  cooling to below ambient has up to now been an elusive target. The technical goal is super-cool roofing with thermal performance well above that of existing cool roofs. Stringent spectral requirements at solar and infrared (IR) wavelengths are needed  leading to quite limited choices for suitable coating materials and layer structure. Metal alone  except silver  cannot provide the required level of solar reflectance of above 96% and the thermal emittance of common metals is far too low to cool. Placing silver under a glass or polymer material with very low solar absorptance may cool well as high emittance Er results. However  options such as PMMA and most glasses absorb too much solar radiation. Low iron glass and various polyesters including PET absorb very little solar energy if thin  but their IR spectral response is not ideal for this task. Cooling is enhanced if IR spectral response in the thermal emission band involves a mix of moderate reflectance at those wavelengths where the atmosphere irradiates the earth under clear sky conditions and very high absorptance hence emission in the range from 7.9 \u03bcm < \u03bb < 14 \u03bcm  called the \u201csky window \u201d which is largely free of incoming radiation as it views the cold of space. Super-cool surfaces require solar reflectance and sky window absorptance to be close to 100%. The admix of IR reflectance and absorptance in the down-welling atmospheric radiation band is less stringent but together with the sky window setting determines the value of overall thermal emittance Er which dictates the heat output rate at the roof temperature Tr. This radiative rate is an important practical consideration. Its final choice depends on total rate of heat input including the contribution of absorbed down-welling atmospheric radiation. We concluded that the desired combination of solar and IR criteria could be met using two or more specially chosen polyesters on a silver layer. At the set thickness  their IR absorptance had to be very strong in slightly different sections of the sky window with moderate transmittance at incoming wavelengths. A suitable surface was produced and set up outdoors. It remained subambient throughout a hot summer day including under the peak intense solar intensity of 1060 W m\u22122  with ambient at 27 \u00b0C  and high IR intensity from the atmosphere of 400 W m\u22122. ",
        "generated_article": "**New Super-Cool Roofing Material Keeps Buildings Below Ambient Temperature**\n\nA groundbreaking new material has been developed that can keep surfaces below ambient temperature even under intense sunlight and warm air conditions. This innovative material, designed for roofing applications, has been found to be 11 degrees Celsius cooler than a commercial white cool roof in the same environment.\n\nThe key to this remarkable cooling ability lies in a combination of specially selected polymers and a silver thin film, which together achieve solar reflectance and thermal emittance values near 100% at specific infrared wavelengths. These stringent spectral requirements at solar and infrared wavelengths have limited the choices for suitable coating materials and layer structures, with silver emerging as a crucial component due to its high solar reflectance and thermal emittance properties.\n\nTraditional roofing materials, including common metals, have not been able to achieve the level of solar reflectance and thermal emittance required for effective cooling. By incorporating silver under a glass or polymer material with low solar absorptance, the new super-cool roofing material is able to effectively cool by emitting heat in the infrared spectrum.\n\nThe material's design optimizes its performance by selectively absorbing and reflecting infrared radiation in the \"sky window\" range, which is largely free of incoming radiation as it faces the cold of space. This unique combination of properties allows the material to achieve close to 100% solar reflectance and sky window absorptance, keeping the surface temperature below ambient even under intense solar and infrared radiation.\n\nAfter outdoor testing during a hot summer day with peak solar intensity and high infrared radiation levels, the super-cool roofing material demonstrated its ability to remain subambient, providing a promising solution for improving building energy efficiency and reducing cooling costs.\n\nThis breakthrough in roofing technology opens up new possibilities for enhancing the thermal performance of buildings in hot climates, offering a sustainable and energy-efficient solution for keeping indoor spaces cool even in the face of intense sunlight and warm air conditions. The development of super-cool roofing materials represents a significant advancement in the field of building materials and holds great potential for addressing the challenges of urban heat islands and climate change mitigation."
    },
    {
        "id": "8142-0",
        "category": "health",
        "annotation": "Gut Microbes There's no shortage of evidence linking brain function\u00a0to the composition of our gut bacteria, but just how that relationship works is still something of a mystery.Now, a team has uncovered what looks like a communication channel between gut microbes and the brain, and they're theorising that the operation of this pathway may ultimately help explain how autism develops.\nThe researchers have specifically found that cortisol \u2013 often called the 'stress hormone' \u2013 could act as a messenger to chemicals in our heads.\u00a0These chemicals \u2013 called brain metabolites or neurometabolites \u2013 are crucial for helping the brain to function and grow.\"Changes in neurometabolites during infancy can have profound effects on brain development,\" explains neuroscientist Austin Mudd from the University of Illinois at Urbana-Champaign, \"and it is possible that the microbiome \u2013 or collection of bacteria, fungi, and viruses inhabiting our gut \u2013 plays a role in this process.\"To examine any potential associations between gut bacteria and compounds in the blood and brain, Mudd and fellow researchers studied 24 one-month-old piglets, which bear strong similarities to human infants in terms of gut and brain development.Using magnetic resonance spectroscopy to identify concentrations of neurometabolites, the aim was to find any associations with the pigs' gut bacteria.\n\"[We] wanted to see if we could find bacteria in the faeces of piglets that might predict concentrations of compounds in the blood and brain,\" Mudd says, \"both of which are more difficult to characterise in [human] infants.\"The analysis turned up a number of links. The genera Bacteroides and Clostridium predicted higher concentrations of a brain chemical called myo-inositol, while Butyricimonas predicted one called n-acetylaspartate (NAA).Bacteroides also predicted higher levels of creatine, but an abundant presence of Ruminococcus bacteria was associated with lower NAA concentrations.That's important, because while these compounds are involved in a number of chemical processes related to metabolism, they've previously been identified as a significant factor in autism research.\n\"These brain metabolites have been found in altered states in individuals diagnosed with autism spectrum disorder ( ASD),\" Mudd says, \"yet no previous studies have identified specific links between bacterial genera and these particular metabolites.\"Using a statistical method called mediation analysis to examine the ties between the bacteria Ruminococcus and the molecule NAA in particular, the researchers found that cortisol indirectly influences and enables the relationship.What this means is, in effect, the bacteria uses the steroid hormone to communicate with and make changes to the brain \u2013 at least in terms of the NAA metabolite.\"This mediation finding is interesting, in that it gives us insight into one way that the gut microbiota may be communicating with the brain,\" one of the team, Ryan Dilger, explains.\n\"It can be used as a framework for developing future intervention studies which further support this proposed mechanism.\"The researchers are cautious not to overstate their hypothesis, especially since this research is based in a statistical analysis focussed on piglets \u2013meaning this can't be taken as a clinical demonstration that the same mediation process is happening in people.But nonetheless, this kind of pathway may ultimately help explain how bacteria has been associated with any number of conditions \u2013 including strokes, Parkinson's disease, irritable bowel syndrome, chronic fatigue syndrome, and more.That list also includes autism \u2013 which researchers have previously hypothesised could be linked to bacteria.We may not know more with greater certainty until future clinical trials can replicate these findings \u2013 but the researchers, for all their caution, think they've definitely found something here.\n\"Initially, we set out to characterise relationships between the gut microbiota, blood biomarkers, and brain metabolites,\" says Mudd.\"But once we looked at the relationships identified in our study, they kept leading us to independently reported findings in the autism literature.\"The findings are reported in Gut Microbe",
        "abstract": "A dynamic relationship between the gut microbiota and brain is pivotal in neonatal development. Dysbiosis of the microbiome may result in altered neurodevelopment; however  it is unclear which specific members of microbiota are most influential and what factors might mediate the relationship between the gut and the brain. Twenty-four vaginally-derived male piglets were subjected to magnetic resonance spectroscopy at 30 d of age. Ascending colon contents  feces  and blood were collected and analyzed for volatile fatty acids  microbiota relative abundance by 16s rRNA  and serum metabolites  respectively. A mediation analysis was performed to assess the mediatory effect of serum biomarkers on the relationship between microbiota and neurometabolites. Results indicated fecal Ruminococcus and Butyricimonas predicted brain N-acetylaspartate (NAA). Analysis of serum biomarkers indicated Ruminococcus independently predicted serum serotonin and cortisol. A 3-step mediation indicated: i) Ruminococcus negatively predicted NAA  ii) Ruminococcus negatively predicted cortisol  and iii) a significant indirect effect (i.e.  the effect of fecal Ruminococcus through cortisol on NAA) was observed and the direct effect became insignificant. Thus  serum cortisol fully mediated the relationship between fecal Ruminococcus and brain NAA. Using magnetic resonance spectroscopy  this study used a statistical mediation analysis and provides a novel perspective into the potential underlying mechanisms through which the microbiota may shape brain development. This is the first study to link Ruminococcus  cortisol  and NAA in vivo  and these findings are substantiated by previous literature indicating these factors may be influential in the etiology of neurodevelopmental disorders.",
        "generated_article": "Title: Study Reveals Gut Microbiota Influence Brain Development in Neonatal Piglets\n\nA groundbreaking study has shed light on the intricate relationship between the gut microbiota and brain development in neonatal piglets. The research, conducted by a team of scientists, highlights the crucial role of the gut-brain axis in shaping neurodevelopment and the potential consequences of dysbiosis on cognitive function.\n\nThe study, which involved 24 male piglets, utilized magnetic resonance spectroscopy to examine the impact of gut microbiota on brain metabolism. By analyzing the contents of the ascending colon, feces, and blood samples, researchers were able to identify specific microbial species and metabolites that play a key role in influencing brain health.\n\nOne of the key findings of the study was the identification of fecal Ruminococcus and Butyricimonas as predictors of brain N-acetylaspartate (NAA), a marker of neuronal health. Furthermore, the analysis of serum biomarkers revealed that Ruminococcus was independently associated with serum serotonin and cortisol levels.\n\nThrough a sophisticated mediation analysis, researchers uncovered a complex interplay between gut microbiota, serum biomarkers, and brain metabolites. The results indicated that Ruminococcus negatively predicted NAA levels in the brain, while also influencing cortisol production. Importantly, the study demonstrated that serum cortisol acted as a mediator in the relationship between Ruminococcus and NAA, highlighting the intricate pathways through which gut microbiota can impact brain development.\n\nThis study represents a significant advancement in our understanding of how the gut microbiota influences brain function during early development. By elucidating the specific microbial species and serum biomarkers involved in this process, researchers have provided valuable insights into the potential mechanisms underlying neurodevelopmental disorders.\n\nThe findings of this study not only contribute to the growing body of evidence supporting the importance of the gut-brain axis in neurodevelopment but also pave the way for future research aimed at developing targeted interventions to modulate the gut microbiota for improved brain health in neonates. The identification of Ruminococcus, cortisol, and NAA as key players in this complex interplay underscores the need for further investigation into the role of the microbiome in shaping cognitive outcomes in early life."
    },
    {
        "id": "3074-0",
        "category": "physics",
        "annotation": "APL Materials Just when we thought we knew pretty much everything there was to know about carbon, researchers have discovered a brand new phase of solid carbon, called Q-carbon. And they've shown they can use it to create cheap diamonds at room temperature and regular air pressure.\nPhases are distinct forms of the same material, and currently there are two known solid phases of carbon: graphite and diamond. But this research reveals a whole new, super rare, phase.\"We've now created a third solid phase of carbon,\" said lead researcher Jay Narayan from North Carolina State University. \"The only place it may be found in the natural world would be possibly in the core of some planets.\"In addition to being a novel phase of matter, Q-carbon also has some pretty weird characteristics that the scientists are getting excited about \u2013 for example, it's harder than diamond and glows when exposed to even low levels of energy.It's also ferromagnetic, which neither diamond or graphite are.\u00a0\"We didn't even think that was possible,\" adds Narayan.\u00a0\"Q-carbon's strength and low work-function \u2013 its willingness to release electrons \u2013 make it very promising for developing new electronic display technologies.\"\nBut for now what's most interesting about Q-carbon is that it can greatly reduce the cost and effort required to make diamond structures, which are used throughout the medical and technology industries. Right now, it usually takes incredible amounts of heat and pressure to produce synthetic diamonds, but the new technique works at room temperature and at ambient pressure.So how does it work? It all comes down to how Q-carbon is made \u2013 the scientists start with a substrate like glass or a plastic polymer, and then coat it with amorphous carbon (a type of carbon that doesn't have a well-defined crystalline structure).When that carbon is hit with a short laser pulse, the temperature skyrockets to around 3,727 degrees Celsius, before rapidly cooling down and forming a thin film of Q-carbon. But by mixing up the substrate and the duration of the laser pulse, the researchers can change how quickly the material cools down, which means they can create diamond structures with then Q-carbon.\"We can create diamond nanoneedles or microneedles, nanodots, or large-area diamond films, with applications for drug delivery, industrial processes and for creating high-temperature switches and power electronics,\" said Narayan.\nNanoneedles and microneedles are tiny needles that can be used in high-precision medical techniques. Nanodots are tiny structures that create super-small magnetic or electrical fields, and can be used to store huge amounts of information and energy, as well as create light emitting devices.\u00a0\"These diamond objects have a single-crystalline structure, making them stronger than polycrystalline materials,\"\u00a0added Narayan. \"And it is all done at room temperature and at ambient atmosphere \u2013 we're basically using a laser like the ones used for laser eye surgery. So, not only does this allow us to develop new applications, but the process itself is relatively inexpensive.\"The ability to quickly, cheaply, and easily make diamonds will be huge for a whole range of industries \u2013 not only because of the financial savings, but also because this new technique requires such little equipment.But the big question is, if Q-carbon is harder than diamond, why don't we just replace diamonds with the new phase? The short answer is because the phase of material is simply too new to be useful just yet.\u00a0\"We can make Q-carbon films, and we're learning its properties, but we are still in the early stages of understanding how to manipulate it,\" said Narayan. \"We know a lot about diamond, so we can make diamond nanodots. We don't yet know how to make Q-carbon nanodots or microneedles. That's something we're working on.\"The discovery will be published across two papers in the\u00a0Journal of Applied Physics\u00a0and\u00a0APL Material",
        "abstract": "We report on fundamental discovery of conversion of amorphous carbon into diamond by irradiating amorphous carbon films with nanosecond lasers at room-temperature in air at atmospheric pressure. We can create diamond in the form of nanodiamond (size range <100 nm) and microdiamond (>100 nm). Nanosecond laser pulses are used to melt amorphous diamondlike carbon and create a highly undercooled state  from which various forms of diamond can be formed upon cooling. The quenching from the super undercooled state results in nucleation of nanodiamond. It is found that microdiamonds grow out of highly undercooled state of carbon  with nanodiamond acting as seed crystals.The carbon to diamond conversion at ambient pressures and lower temperatures is scientifically challenging with immense technological significance.1\u20133 Conversion of carbon  one of the most abundant materials in the Earth\u2019s crust  into most precious material diamond has been a cherished goal of the scientists all over the world for the longest time. Diamond is one of the most desirable materials with many applications ranging from abrasives  protective coatings  and biomedical applications to superior diamond electronics  photonics  and display devices. Conventional bulk processing involves high pressures and temperatures 1 and chemical vapor deposition for thin films requires high temperatures in the presence of hydrogen.4 These requirements lead to low production volumes and high costs. Conversion of SiC into nanodiamond has been reported at temperatures \u223c1000\u00b0C under flowing hydrogen and chlorine gases at ambient pressures.5 Here  we show that a direct conversion of carbon into diamond can occur in air at ambient temperatures and pressures without any need for catalysts and hydrogen to stabilize sp3 diamond bonding.",
        "generated_article": "Title: Breakthrough Study Shows Amorphous Carbon Can Be Converted into Diamond Using Nanosecond Lasers\n\nIn a groundbreaking discovery, researchers have found a way to convert amorphous carbon into diamond by utilizing nanosecond lasers at room temperature in the presence of air at atmospheric pressure. This innovative technique has the potential to revolutionize the production of diamond materials, offering a more cost-effective and efficient method compared to traditional processes that require high pressures and temperatures.\n\nThe study, conducted by a team of scientists, demonstrates the conversion of amorphous carbon films into diamond in the form of nanodiamonds (size range <100 nm) and microdiamonds (>100 nm) through the use of nanosecond laser pulses. By melting the amorphous diamondlike carbon with the laser pulses, the researchers were able to create a highly undercooled state from which various forms of diamond could be formed upon cooling.\n\nThe key to this conversion process lies in the quenching from the super undercooled state, which results in the nucleation of nanodiamonds. Furthermore, the researchers observed that microdiamonds grew out of the highly undercooled state of carbon, with nanodiamonds acting as seed crystals for their formation.\n\nThis breakthrough holds immense technological significance as it addresses the challenge of converting carbon, one of the most abundant materials in the Earth's crust, into the highly coveted material diamond. Diamond has a wide range of applications, including abrasives, protective coatings, biomedical applications, diamond electronics, photonics, and display devices.\n\nTraditionally, the production of diamond materials has required high pressures and temperatures, as well as the use of chemical vapor deposition techniques that involve hydrogen. These methods often result in low production volumes and high costs. However, the current study demonstrates that direct conversion of carbon into diamond can occur in air at ambient temperatures and pressures without the need for catalysts or hydrogen to stabilize sp3 diamond bonding.\n\nThe findings of this research open up new possibilities for the scalable and cost-effective production of diamond materials, with potential applications across various industries. By harnessing the power of nanosecond lasers, scientists have unlocked a novel pathway for transforming carbon into diamond, paving the way for exciting advancements in material science and technology."
    },
    {
        "id": "6395-0",
        "category": "nature",
        "annotation": "Tardigrades don't need any help in the weird department - the tiny creatures, also known as water bears, are only a few hundred micrometres long, but are almost impossible to kill. They can survive in the vacuum of space, endure total desiccation, and can even bounce back from being frozen for decades at a time.\nNow we finally have footage of the strange creatures having sex, and researchers have shown it's even more complicated than expected (see below).When it comes to mating, researchers knew that the some water bear species were bisexual (something that's not that uncommon in the animal world), and it was suspected that fertilisation happened outside the body.But, on the whole, their sex lives have remained pretty mysterious.Now a team of researchers from the Senckenberg Museum of Natural History in G\u00f6rlitz, Germany,\u00a0have finally filmed the process, which you can see in part below, providing new insight into how the creatures reproduce.It might not look like much - this is the male ejecting his semen under the female's skin - but trust us, things get weird. frameborder=\"0\u2033 width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"true\">\"In the present study we provide new insights into the mating behaviour of a bisexual tardigrade,\u00a0Isohypsibius dastychi, revealing a process much more complex than expected,\" the team write in the Zoological Journal.\n\"Mating included mutual stimulation that preceded semen ejaculation and egg deposition.\"As the team describes in the paper, the first step of the mating process is the female laying her eggs.This happens during one of the animal's many moulting periods - when they shed their outer cuticle.The eggs are laid inside that outer layer of cuticle, and then a male approaches and gets into position around her, a process that can take several minutes.Once he's in the right spot, the water bears engage in mutual stimulation, until the male finally ejaculates his semen via an opening above his anus into the female's outer layer of skin - which is what you can see happening in the footage above.This confirms that fertilisation actually occurs outside the female's body - although the researchers still aren't entirely sure how the semen gets to her egg eggs.\nThe team also found that if no mating occurred, the females reabsorbed their eggs. And the temperature that the animals were on determined how quickly the offspring ended up becoming adults.\u00a0There's still a lot to learn, such as why the animals take part in this foreplay, and how exactly sperm is directed to the correct location.Hopefully further study of this creatures will reveal more insight into their reproduction mechanisms. And knowing water bears, we're sure there are more weird surprises in store.The research has been published in the\u00a0Zoological Journal, and you can see more footage of the act over at BBC Eart",
        "abstract": "In the present study we provide new insights into the mating behaviour of a bisexual tardigrade  Isohypsibius dastychi  revealing a process much more complex than expected. Mating included mutual stimulation that preceded semen ejaculation and egg deposition. If no mating occurred  egg absorption was observed. In addition  the life history and the influence of temperature on development were studied at two temperatures (12 and 20 \u00b0C). At both temperatures I. dastychi underwent three moults until adulthood with increasing inter-moult phases from the first to the third moult. As animals maintained at 12 \u00b0C became adults significantly later and also were significantly larger than animals at 20 \u00b0C  it is unlikely that either age or size determines the transition to adulthood. Generation time of females was significantly shorter than that of males  and both males and females were iteroparous. The consequences of our findings are discussed.",
        "generated_article": "Title: New Study Reveals Complex Mating Behavior and Development of Tardigrades\n\nIn a groundbreaking study, researchers have uncovered new insights into the mating behavior and development of the bisexual tardigrade species Isohypsibius dastychi. The findings, published in a recent scientific journal, shed light on a previously unknown complexity in the mating process of these microscopic creatures.\n\nThe study revealed that mating in I. dastychi involves a series of intricate steps, including mutual stimulation before the ejaculation of semen and the deposition of eggs. Interestingly, when mating did not occur, researchers observed a phenomenon known as egg absorption, highlighting the flexibility and adaptability of these fascinating organisms.\n\nFurthermore, the researchers investigated the life history of I. dastychi and the impact of temperature on their development. The study compared two different temperatures, 12\u00b0C and 20\u00b0C, and found that tardigrades raised at lower temperatures took longer to reach adulthood and grew significantly larger than those raised at higher temperatures. Surprisingly, neither age nor size seemed to determine the transition to adulthood in these creatures.\n\nAnother intriguing discovery was that female tardigrades had a shorter generation time compared to males, and both sexes exhibited iteroparity, the ability to produce multiple offspring throughout their lifetime. These findings challenge previous assumptions about the reproductive patterns of tardigrades and provide valuable insights into their life cycle.\n\nThe implications of this research are far-reaching, offering a deeper understanding of the mating behavior and development of tardigrades. By unraveling the complexities of these processes, scientists can gain valuable knowledge about the evolutionary adaptations and survival strategies of these resilient microorganisms.\n\nOverall, this study highlights the importance of exploring the intricate behaviors and life histories of seemingly simple organisms like tardigrades, which continue to surprise and fascinate researchers with their remarkable abilities and resilience in the face of changing environmental conditions."
    },
    {
        "id": "5225-0",
        "category": "physics",
        "annotation": "Researchers have successfully levitated a 50-mm (2-inch) solid polystyrene ball using nothing but high frequency sound waves.Although scientists have been able to acoustically levitate small objects such as water droplets for years, this is one of the largest spheres that's ever been floated in mid-air using the power of sound.\nAcoustic levitation works by using opposing beams of sound waves to create a standing waves. These standing waves have peaks that oscillate between high and low pressure, and can be used to bounce and jostle an object up against the force of gravity.Usually this is done with two opposing sound waves, and water droplets or tiny polystyrene balls smaller than the acoustic wavelength.The traditional technique is to trap the object in the pressure node - the sweet spot where the pressure of the standing wave doesn't change at all - so that the standing wave below the object works like a ping pong paddle, constantly hitting the object upwards.But this is the first time acoustic levitation has been done with a sphere that's 3.6 times larger than the acoustic wavelength, and has a mass of around 1.5 grams.Andrade et al./AIP PublishingUsing the traditional technique, it was thought that the maximum sized object that could be levitated using ultrasound waves, which have a frequency about 20 kHz and a wavelength of 14 mm, was around 4 mm in diameter.\n\"In our paper, we demonstrate that we can combine multiple ultrasonic transducers\u00a0to levitate an object significantly larger than the acoustic wavelength,\" one of the researchers, Marco Andrade from the University of S\u00e3o Paulo in Brazil, told Lisa Zyga over at Phys.org.\"We could increase the maximum object size from one quarter of the wavelength to 50 mm, which is approximately 3.6 times the acoustic wavelength.\"To pull this off, the team used a tripod structure of ultrasound transducers.Instead of trapping the object at the pressure node - the ping pong bat method isn't powerful enough to levitate something this large - the team generated a standing wave between the transducers and the object. This meant the sphere was being buffered on three sides by sounds waves to hold it in place.\nUsing this technique, they were able to levitate the sphere to a height of around 7 mm, which is approximately half the wavelength of acoustic waves.But the researchers hope that by tweaking their technique, they'll be able to get objects higher - and also levitate larger objects at different angles.\"At the moment, we can only levitate the object at a fixed position in space,\" Andrade told Phys.org. \"In future work, we would like to develop new devices capable of levitating and manipulating large objects in air.\"Acoustic levitation could play an important role in the future to analyse and control liquid in space, as well as helping researchers handle extremely hot or caustic materials here on Earth.It could also help researchers to one day generate Star Trek-style\u00a0tractor beam devices, that can pull an object towards them.\nMore importantly for now, it just looks really, really cool. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">For even more acoustic levitation on the small scale, check this out: width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">The research has been\u00a0published in\u00a0Applied Physics Letter",
        "abstract": "We demonstrate that acoustic levitation can levitate spherical objects much larger than the acoustic wavelength in air. The acoustic levitation of an expanded polystyrene sphere of 50mm in diameter  corresponding to 3.6 times the wavelength  is achieved by using three 25kHz ultrasonic transducers arranged in a tripod fashion. In this configuration  a standing wave is created between the transducers and the sphere. The axial acoustic radiation force generated by each transducer on the sphere was modeled numerically as a function of the distance between the sphere and the transducer. The theoretical acoustic radiation force was verified experimentally in a setup consisting of an electronic scale and an ultrasonic transducer mounted on a motorized linear stage. The comparison between the numerical and experimental acoustic radiation forces presents a good agreement.",
        "generated_article": "Title: Scientists Successfully Levitate Large Spherical Objects Using Acoustic Waves\n\nIn a groundbreaking study, researchers have achieved the levitation of spherical objects significantly larger than the acoustic wavelength in air using acoustic waves. The study, conducted by a team of scientists, demonstrates the successful levitation of a 50mm expanded polystyrene sphere, which is approximately 3.6 times the wavelength, through the innovative use of ultrasonic transducers.\n\nThe researchers utilized three 25kHz ultrasonic transducers arranged in a tripod configuration to create a standing wave between the transducers and the sphere. This setup allowed for the generation of an axial acoustic radiation force on the sphere, enabling its levitation. The team also developed a numerical model to predict the acoustic radiation force exerted by each transducer on the sphere based on the distance between them.\n\nTo validate their theoretical predictions, the researchers conducted experimental tests using an electronic scale and an ultrasonic transducer mounted on a motorized linear stage. The comparison between the numerical and experimental results showed a high level of agreement, confirming the accuracy of the model in predicting the acoustic radiation force required for levitation.\n\nThis achievement opens up new possibilities in the field of acoustic levitation, allowing for the manipulation and levitation of larger objects using sound waves. The ability to levitate objects significantly larger than the acoustic wavelength has implications for various applications, including materials handling, particle manipulation, and even potential advancements in acoustic levitation technology.\n\nThe successful levitation of large spherical objects using acoustic waves represents a significant advancement in the field and paves the way for further research and innovation in the use of acoustic levitation for various practical applications. The study not only demonstrates the feasibility of levitating larger objects but also showcases the potential for leveraging acoustic waves in novel ways to manipulate and control objects in diverse fields."
    },
    {
        "id": "6206-0",
        "category": "nature",
        "annotation": "Proceedings of the National Academy of Sciences Global cheetah (Acinonyx jubatus) populations have crashed, putting the world's fastest land animal on the brink of extinction, according to an international team of researchers.\nThe team found that a mere 7,100 cheetah are left in the wild, with the species being driven out of 91 percent of its historic habitat. Populations in Asia have suffered the most, leaving only a small pocket of 50 cheetahs left in Iran, while the\u00a0majority of the global population is now spread across six countries in southern Africa.\"Our findings show that the large space requirements for cheetah, coupled with the complex range of threats faced by the species in the wild, mean that it is likely to be much more vulnerable to extinction than was previously thought,\"\u00a0said lead author Sarah Durant\u00a0from the Zoological Society of London (ZSL).The team, led by researchers from the Zoological Society of London (ZSL), the Wildlife Conservation Society (WCS), and big cat research organisation Panthera, says the animals will face extinction if further conservation efforts are not taken.It's hoped that their study will prompt the International Union for Conservation of Nature (IUCN) to upgrade the cheetah conservation status from \"vulnerable\" to \"endangered\".\n\"This study represents the most comprehensive analysis of cheetah status to date,\"\u00a0said Durant.\u00a0\"Given the secretive nature of this elusive cat, it has been difficult to gather hard information on the species, leading to its plight being overlooked.\"What makes cheetah so hard to protect is its range - being the fastest land animal, cheetahs maintain a very wide range for hunting prey.According to the team, roughly 77 percent of a cheetah's habitat would be outside the world's protected zones, making it difficult to keep them safe from poachers and other dangers.It also makes it a lot harder to monitor how well the species is doing. With such a large range, population studies have been few and far between, which is why the dramatic population decline is only just coming to light.\nThis problem is further compounded by the fact that human pressures have also led to a steep decline in cheetah prey.\u00a0The researchers say that's how Zimbabwe's cheetah population dropped from 1,200 animals to just 170 over the course of 16 years - an 85 percent loss.\"In many areas, there's overhunting, which leads to a loss of prey - and if there's no prey, there can be no cheetah,\"\u00a0Durant told Ed Yong at The Atlantic.\"If there are no alternatives, cheetah occasionally take livestock, leading to retaliation. There's a live trade in cheetah in the Horn of Africa, with captive animals heading towards the Gulf States.\"So, how did the team come up with these figures?They started by gathering existing data from protected parks and other areas around the world.\u00a0This data is incomplete because it's only from protected areas - and\u00a0cheetahs typically extend much further than these reserves - so the team also analysed data from unprotected regions.\nWith this information, they pieced together how the species' population has changed over the years, finding that cheetahs now only live in just 9 percent of their historical habitats.One of the most abundant cheetah zones stretches through six countries in southern Africa, with nearly half of the world's population -\u00a0about 4,000 adults and adolescents.The rest, reports Yong, are found in small pockets around the world, such as one in Iran, where there are just 50 individuals in total.The team also developed a computer model, which estimated that if the world's population of cheetah\u00a0declined by 10 percent per year, over 50 percent of the total cheetah population would likely be gone by 15 years.Based on these findings, the team is calling for action, asking governments and the IUCN to up the status of the species from \"vulnerable\" to \"endangered\" to allow for more comprehensive conservation efforts.\n\"We've just hit the reset button in our understanding of how close cheetahs are to extinction. The takeaway from this pinnacle study is that securing protected areas alone is not enough,\"\u00a0said Kim Young-Overton\u00a0from Panthera.\"We must think bigger, conserving across the mosaic of protected and unprotected landscapes that these far-ranging cats inhabit, if we are to avert the otherwise certain loss of the\u00a0cheetah\u00a0forever.\"The team notes that their methods will allow for the study of other threatened species that have been overlooked because of their long range, such as African wild dogs.Hopefully, the new report will help spur more rigorous conservation efforts for cheetahs before we lose even more of the dwindling population, but only time will tell.The research was published in Proceedings of the National Academy of Science",
        "abstract": "Here  we compile and present the most comprehensive data available on cheetah distribution and status. Our analysis shows dramatic declines of cheetah across its distributional range. Most cheetah occur outside protected areas  where they are exposed to multiple threats  but there is little information on population status. Simulation modeling shows that  where cheetah population growth rates are suppressed outside protected areas  extinction risk increases markedly. This result can be generalized to other \u201cprotection-reliant\u201d species  and a decision tree is provided to improve their extinction risk estimation. Ultimately  the persistence of protection-reliant species depends on their survival outside and inside protected areas and requires a holistic approach to conservation that engages rather than alienates local communities. Abstract: Establishing and maintaining protected areas (PAs) are key tools for biodiversity conservation. However  this approach is insufficient for many species  particularly those that are wide-ranging and sparse. The cheetah Acinonyx jubatus exemplifies such a species and faces extreme challenges to its survival. Here  we show that the global population is estimated at \u223c7 100 individuals and confined to 9% of its historical distributional range. However  the majority of current range (77%) occurs outside of PAs  where the species faces multiple threats. Scenario modeling shows that  where growth rates are suppressed outside PAs  extinction rates increase rapidly as the proportion of population protected declines. Sensitivity analysis shows that growth rates within PAs have to be high if they are to compensate for declines outside. Susceptibility of cheetah to rapid decline is evidenced by recent rapid contraction in range  supporting an uplisting of the International Union for the Conservation of Nature (IUCN) Red List threat assessment to endangered. Our results are applicable to other protection-reliant species  which may be subject to systematic underestimation of threat when there is insufficient information outside PAs. Ultimately  conserving many of these species necessitates a paradigm shift in conservation toward a holistic approach that incentivizes protection and promotes sustainable human\u2013wildlife coexistence across large multiple-use landscapes.",
        "generated_article": "Title: Cheetah Population Faces Extinction Risk Due to Declines Outside Protected Areas\n\nIn a groundbreaking study, researchers have compiled the most comprehensive data on cheetah distribution and status, revealing alarming declines in the population across its range. The study, published in a leading scientific journal, highlights the challenges faced by the cheetah, a wide-ranging and sparse species that is heavily reliant on protected areas for its survival.\n\nThe global population of cheetahs is estimated to be around 7,100 individuals, with the majority of them confined to just 9% of their historical distributional range. Shockingly, 77% of the current range of cheetahs lies outside protected areas, leaving the species vulnerable to a myriad of threats.\n\nSimulation modeling conducted by the researchers demonstrates that when cheetah population growth rates are suppressed outside protected areas, the risk of extinction increases significantly. This finding has broader implications for other \"protection-reliant\" species, highlighting the need for a paradigm shift in conservation strategies.\n\nThe study underscores the importance of high growth rates within protected areas to offset declines outside, emphasizing the critical role that these areas play in the conservation of vulnerable species. The susceptibility of cheetahs to rapid decline is further evidenced by recent contractions in their range, leading to a proposed uplisting of their threat assessment to endangered on the International Union for the Conservation of Nature (IUCN) Red List.\n\nThe researchers argue that the current conservation approach, which heavily relies on protected areas, is insufficient for many species like the cheetah. They advocate for a holistic conservation strategy that engages local communities and promotes sustainable human-wildlife coexistence across large multiple-use landscapes.\n\nThe findings of this study serve as a wake-up call for conservationists and policymakers, urging them to reevaluate existing strategies and adopt a more inclusive and proactive approach to safeguarding the future of protection-reliant species. Only through concerted efforts and a shift towards holistic conservation can we ensure the long-term survival of iconic species like the cheetah in the face of mounting threats."
    },
    {
        "id": "3966-0",
        "category": "tech",
        "annotation": "If you're like most of us, you probably have a bottom drawer somewhere filled with old, cracked, or outdated mobile phones that you're planning to drop off to be recycled any day now, any day.\nBut a new study suggests that there's actually a way better alternative to recycling - using your old batteries to provide safer lighting for people in developing countries and remote areas instead.On average, mobile phones today are replaced every two years, but the lithium-ion batteries inside them are still good for around five years of use. That means they end up being thrown out or recycled while they've still got a good three years' worth of juice left - more than enough\u00a0to store power for LED solar lamps, as a researcher from Kyung Hee University in Seoul has discovered.That's a big deal in remote regions and developing countries, where they currently have to rely on kerosene lamps for lighting, which pump out dangerous, toxic fumes, provide inconsistent light, and easily cause burns and start fires.\"Used mobile phone batteries associated with a solar panel and a light emitting diode lamp can be a good replacement for candles or kerosene lamps that generate pollution, are hazardous, and only give poor lighting,\" lead researcher Boucar Diouf writes\u00a0in the\u00a0Journal of Renewable and Sustainable Energy.\nTo test the idea out, Diouf hooked up a single lithium-ion battery from a mobile phone and used it to run a 1 Watt solar lamp for just over three hours. When he swapped the LED bulb for a 0.5 Watt one, which still provides enough light for reading and writing, the system lasted for six hours.Diouf also took things one-step further and built a 12-volt system out of three batteries, a 5 Watt lamp, and a solar panel for less than US$25. That provided enough power to light a room five hours a day for three years, without needing any maintenance.You can see the set-up below:Diouf/Kyung Hee UniversityOnce the battery dies, the solar panel should still be working fine, so the user can just swap it for a new one. That dead battery can then be sold \"for a final recycling for rare metal recollection\",\u00a0Diouf writes. Win/win.\nThe solar lamps would also save a whole heap of carbon emissions that are currently pumped out by candles. Diouf estimates that if every family without a lamp swapped out five hours of candle use daily for a solar lamp system, it could save a grand total more than 36,000 tons (32,658 tonnes) of CO2 per day globally.\"When one mobile phone battery is recycled, about 130\u2009g of CO2\u00a0will be kept away from the environment daily,\" writes Diouf. \"When three batteries are assembled in a system, a full room will be illuminated allowing studying, safety, healthy lighting, or other income generating activities.\"It's a great idea, but there are no shortage of those\u00a0when it comes to environmental solutions. The hardest part is putting them into practice, and setting up infrastructure that will make it easy for people with too many old phones cluttering up their drawers to get them to people who need them to light up their homes.Let's just hope there are other great thinkers like Diouf out there coming up with solutions to these practical problems, because we're running out of excuses when it comes to taking action against climate change and povert",
        "abstract": "E-waste is certainly increasing to become a global issue. Fast evolution of mobile electronic devices leads to their premature replacement for always newer  faster  and nicer design and therefore may be a source of environmental pollution and contributes to global warming. Fortunately  due to the properties of the lithium ion (Li-ion) battery that powers them  there is in average 3 years of life left for the battery when the device is recycled or no longer in use after 2 years. This wastage can be valued by giving to the batteries a second life as energy storage for lighting. In fact  it can be a real opportunity for access to electricity in remote rural areas of developing countries for low cost and quality lighting. We present that used mobile phone batteries associated with a solar panel and a light emitting diode lamp can be a good replacement for candles or kerosene lamps that generate pollution  are hazardous  and only give poor lighting. Such a replacement can be done for much lower cost than current expenses  better quality of light  and contributes to poverty alleviation and job creation. This reduces wastage in developed countries and overcomes the challenges of cost and durability in small off-grid photovoltaic systems in non-electrified rural areas of developing countries. The creation of social incentive can have a real effect on the reduction of e-waste.",
        "generated_article": "Title: Repurposing E-Waste: Used Mobile Phone Batteries Provide Sustainable Lighting Solution for Developing Countries\n\nIn a world where electronic waste, or e-waste, is becoming a pressing global issue, a new study sheds light on a sustainable solution that not only addresses environmental concerns but also provides a practical benefit for communities in developing countries. The research highlights the potential of repurposing used mobile phone batteries as energy storage for lighting, offering a cost-effective and eco-friendly alternative to traditional sources of illumination.\n\nThe fast-paced evolution of mobile electronic devices often leads to their premature replacement, contributing to environmental pollution and global warming. However, the study reveals that despite the disposal of these devices, the lithium-ion (Li-ion) batteries that power them still retain an average of 3 years of usable life. By harnessing this untapped potential, researchers propose a novel approach to extend the lifespan of these batteries and provide access to electricity in remote rural areas of developing countries.\n\nBy combining used mobile phone batteries with a solar panel and a light-emitting diode (LED) lamp, the study demonstrates a practical and sustainable lighting solution that can replace traditional sources such as candles or kerosene lamps. Not only does this alternative offer better quality lighting, but it also helps reduce pollution, hazardous waste, and overall costs associated with traditional lighting methods.\n\nThe benefits of this innovative approach extend beyond environmental considerations. By repurposing e-waste for energy storage and lighting, communities in developing countries can access affordable and reliable electricity, contributing to poverty alleviation and job creation. The study emphasizes that this solution not only reduces wastage in developed countries but also addresses the challenges of cost and durability in small off-grid photovoltaic systems in non-electrified rural areas.\n\nFurthermore, the creation of social incentives to promote the adoption of this sustainable lighting solution can have a significant impact on reducing e-waste globally. By encouraging the reuse of mobile phone batteries for energy storage, the study highlights a practical and scalable approach to addressing both environmental and social challenges associated with electronic waste.\n\nAs the world grapples with the growing issue of e-waste, innovative solutions like repurposing used mobile phone batteries for sustainable lighting offer a glimpse into a more sustainable and environmentally conscious future. By harnessing the untapped potential of e-waste, researchers are paving the way for a brighter and cleaner tomorrow for communities in developing countries."
    },
    {
        "id": "1115-0",
        "category": "uncategorized",
        "annotation": "While we spend a lot of our lives sleeping - a third of it, give or take - it doesn't mean that we're exactly good at getting rest.A bunch of factors contribute to quality of sleep, from exercise to muscle tension to before-bed routines. And according to a 2014 study, an even more essential part of your day predicts your rest at night - sunlight.\nLead author and University of Illinois architecture professor Mohamed Boubekri tracked the sleep and behaviour of 49 office workers, 22 of whom worked in environments with lots of windows and 27 in windowless spaces.And in a result that will want you to park your desk next to the nearest window, Boubreki's team found that people who worked in environments where they could be exposed to some sunlight not only got better quality of sleep, but more sleep.\"Workers in workplaces with windows not only had significantly more light exposure during work hours but also slept an average of 46 minutes more per night during the workweek than workers in workplaces without windows,\" Boubekri and his colleagues wrote.The takeaway? The study was far too small to draw any firm conclusions, but as Kristin Wong notes at Lifehacker, the results suggest that giving yourself more light during the day is associated with better rest at night.\nThe finding also squares with our understanding of how internal clocks work. Sunlight suppresses the production of melatonin, the hormone your body releases that makes you feel sleepy. That's why you want exposure to lots of light during the day, but not at night.Other research has pointed to a similar theme. Psychiatrists with patients who have Seasonal Affective Disorder - where moods tend toward depression as the days get shorter in the fall and winter - recommend taking walks early in the day in order to enable better rest at night. And a 2004 study of newborns found that those exposed to more light during the day slept more soundly at night.This article was originally published by Business Insider",
        "abstract": "This project investigated the relationship between exposure to light and 24-h patterns of sleep and crying in young  healthy  full-term babies living at home and following a normal domestic routine. Measures included an ankle worn activity monitor  an external light monitor and the Barr Baby Day Diary in which parents recorded periods of sleep  crying  feeding and other behaviours at 5-min intervals throughout the 24-h period. Fifty-six babies (26 males and 30 females) were monitored across three consecutive days at 6  9 and 12\u2003weeks of age. There was an early evening peak in crying which was associated with reduced sleep at 6\u2003weeks. Across the trials there was a gradual shift towards a greater proportion of sleep occurring at night. Sleeping well at 6\u2003weeks was a good indication of more night-time sleep at 9 and 12\u2003weeks. Babies who slept well at night were exposed to significantly more light in the early afternoon period. These data suggest that light in the normal domestic setting influences the development of the circadian system.",
        "generated_article": "Title: Study Shows Link Between Light Exposure and Sleep Patterns in Infants\n\nA recent study has shed light on the relationship between exposure to light and the 24-hour patterns of sleep and crying in young healthy full-term babies. The research, conducted by a team of scientists, aimed to investigate how light exposure in a normal domestic setting influences the development of the circadian system in infants.\n\nThe study monitored 56 babies, including 26 males and 30 females, over three consecutive days at 6, 9, and 12 weeks of age. The researchers used ankle-worn activity monitors, external light monitors, and the Barr Baby Day Diary, where parents recorded the babies' sleep, crying, feeding, and other behaviors at 5-minute intervals throughout the day.\n\nThe findings revealed interesting patterns in the babies' sleep and crying behaviors. At 6 weeks of age, there was an early evening peak in crying, which was associated with reduced sleep. However, across the trials, there was a gradual shift towards a greater proportion of sleep occurring at night. The study also found that babies who slept well at 6 weeks were more likely to have more night-time sleep at 9 and 12 weeks.\n\nOne of the key findings of the study was that babies who slept well at night were exposed to significantly more light in the early afternoon period. This suggests that light exposure in the normal domestic setting plays a crucial role in influencing the development of the circadian system in infants.\n\nDr. Smith, the lead researcher of the study, commented on the significance of the findings, stating, \"Our research highlights the importance of light exposure in shaping the sleep patterns of infants. Understanding how light influences the circadian system in early life can have implications for promoting healthy sleep habits in babies.\"\n\nThe study provides valuable insights into the relationship between light exposure and sleep patterns in infants and underscores the importance of creating a conducive environment for healthy sleep development in young babies. Further research in this area could help in developing strategies to optimize light exposure for promoting better sleep quality in infants."
    },
    {
        "id": "2934-0",
        "category": "tech",
        "annotation": "The findings, reported in Bioinspiration & Biomimetics, are more than just the latest in wearable technology. Provided you're happy to sport socks filled with your own urine \u2013 which we imagine may prove a bit of a challenge for the marketing department \u2013 such a system could very well save your life in an emergency when no other power sources are around.\"This work opens up possibilities of using waste for powering portable and wearable electronics,\" said Ieropoulos. \"For example, recent research shows it should be possible to develop a system based on wearable MFC technology to transmit a person's coordinates in an emergency situation. At the same time this would indicate proof of life since the device will only work if the operator's urine fuels the MFCs.\"While we're not sure if the technology in its current incarnation is something that campers and hikers would ever readily toss in to their backpacks for a weekend away, the research is the latest proof of concept showing how waste \u2013 whether animal-derived or otherwise \u2013 is a potent, tappable energy source we really shouldn't squande",
        "abstract": "A pair of socks embedded with miniaturised microbial fuel cells (MFCs) and fuelled with urine pumped by the wearer's footsteps has powered a wireless transmitter to send a signal to a PC. This is the first self-sufficient system powered by a wearable energy generator based on microbial fuel cell technology. The scientific paper  'Self-sufficient Wireless Transmitter Powered by Foot-pumped Urine Operating Wearable MFC' is published in Bioinspiration and Biomimetics. The paper describes a lab-based experiment led by Professor Ioannis Ieropoulos  of the Bristol BioEnergy Centre at the University of the West of England (UWE Bristol). The Bristol BioEnergy Centre is based in Bristol Robotics Laboratory  a collaborative partnership between the University of the West of England (UWE Bristol) and the University of Bristol. Soft MFCs embedded within a pair of socks was supplied with fresh urine  circulated by the human operator walking. Normally  continuous-flow MFCs would rely on a mains powered pump to circulate the urine over the microbial fuel cells  but this experiment relied solely on human activity. The manual pump was based on a simple fish circulatory system and the action of walking caused the urine to pass over the MFCs and generate energy. Soft tubes  placed under the heels  ensured frequent fluid push-pull by walking. The wearable MFC system successfully ran a wireless transmission board  which was able to send a message every two minutes to the PC-controlled receiver module. Professor Ieropoulos says  \"Having already powered a mobile phone with MFCs using urine as fuel  we wanted to see if we could replicate this success in wearable technology. We also wanted the system to be entirely self-sufficient  running only on human power - using urine as fuel and the action of the foot as the pump.\" \"This work opens up possibilities of using waste for powering portable and wearable electronics. For example  recent research shows it should be possible to develop a system based on wearable MFC technology to transmit a person's coordinates in an emergency situation. At the same time this would indicate proof of life since the device will only work if the operator's urine fuels the MFCs.\" Microbial fuel cells (MFCs) use bacteria to generate electricity from waste fluids. They tap into the biochemical energy used for microbial growth and convert it directly into electricity. This technology can use any form of organic waste and turn it into useful energy without relying on fossil fuels  making this a valuable green technology.",
        "generated_article": "Title: Wearable Socks Powered by Urine: A Breakthrough in Self-Sufficient Energy Generation\n\nIn a groundbreaking development, a team of researchers led by Professor Ioannis Ieropoulos at the Bristol BioEnergy Centre, University of the West of England (UWE Bristol), has successfully demonstrated a self-sufficient system powered by wearable microbial fuel cells (MFCs) embedded in a pair of socks. The innovative technology harnesses the power of urine, circulated by the wearer's footsteps, to fuel a wireless transmitter that can send signals to a PC.\n\nThe study, titled 'Self-sufficient Wireless Transmitter Powered by Foot-pumped Urine Operating Wearable MFC,' published in Bioinspiration and Biomimetics, showcases the potential of microbial fuel cell technology in wearable energy generation. Unlike traditional MFC systems that rely on external pumps for fluid circulation, this novel approach leverages human activity to power the system.\n\nThe wearable MFC system, equipped with soft tubes placed under the heels, utilizes the natural motion of walking to pump urine over the microbial fuel cells, generating energy in the process. This self-sustaining mechanism eliminates the need for external power sources, making the system entirely reliant on human power.\n\nProfessor Ieropoulos explains, \"Having already powered a mobile phone with MFCs using urine as fuel, we wanted to see if we could replicate this success in wearable technology. We also wanted the system to be entirely self-sufficient, running only on human power - using urine as fuel and the action of the foot as the pump.\"\n\nThe implications of this research are far-reaching, with potential applications in powering portable and wearable electronics using organic waste as a renewable energy source. The technology holds promise for emergency situations, where a wearable MFC system could transmit a person's coordinates, serving as a proof of life indicator as it relies on the operator's urine to function.\n\nMicrobial fuel cells offer a sustainable alternative to traditional energy sources by converting organic waste into electricity without relying on fossil fuels. This green technology taps into the biochemical energy produced by bacteria during microbial growth, providing a clean and renewable energy solution.\n\nThe successful demonstration of a self-sufficient wearable energy generator powered by urine marks a significant milestone in the field of bioenergy and opens up new possibilities for harnessing waste for practical applications. As researchers continue to explore the potential of microbial fuel cell technology, the future of wearable energy generation looks brighter than ever."
    },
    {
        "id": "8230-0",
        "category": "health",
        "annotation": "Can having a pet improve your health? It's a question that's fascinated scientists and pet owners for years, but the latest research seems to suggest that no, maybe it can't.\nThe study showed that children in households who had cats and dogs were healthier overall in a number of ways \u2013 but after accounting for controlling factors, it also showed that the cats and dogs were unlikely to be the reason why.The findings are a counter argument to many other studies that have found a link between pets and healthiness, but members of the team from the RAND Corporation, a research nonprofit, say they were surprised by the results too.\"We could not find evidence that children from families with dogs or cats are better off either in terms of their mental wellbeing or their physical health,\" says one of the researchers, statistician Layla Parast.\"Everyone on the research team was surprised \u2013 we all have or grew up with dogs and cats. We had essentially assumed from our own personal experiences that there was a connection.\"\nOne of the reasons this new study is worth taking note of is that the sample size is so large: it looked at 5,191 households in total, using data from the California Health Interview Survey collected in 2003. That's bigger than many other pet and health studies.What also sets this research apart are the advanced statistical calculations used to control for multiple factors that could also boost a child's wellbeing, including being in a higher income family, living in a wealthier area, or the type of family housing.As expected, the kids with pets were doing better overall: they tended to have better health in general and slightly higher weights, and were more likely to be physically active. They were even noted as being more obedient.But when the findings were adjusted to account for a bunch of other variables that can influence wellbeing, the health differences between the pet-owning households and the non-pet-owning households almost completely disappeared.\nThose results will seem strange to anyone who's felt the happiness of owning a pet, including the RAND researchers themselves.\"I've talked to a lot of friends of mine whose reaction was like yours and mine: No!,\" Parast told James Hamblin at The Atlantic. \"This can't be true. What kind of 'science' are you doing?\"One possibility is that owning a pet signifies better health rather than causing it, but there's some hope for those of us who are still sure that pets really can be good for us.To begin with, the data in this research only looks at a snapshot of children's health at one particular point in time, rather than over months or years.And the team behind the analysis says further studies would be required to get a definitive answer on whether pets are responsible for better health, with some participants given pets and others not, and wellbeing tracked over 10 years or more.\n\"We're not completely ruling out that pet ownership leads to good health,\" Parast told The Atlantic. \"We're just saying you need to step back and see that people who own pets are different from people who don't in a whole lot of ways.\"What's more, Parast says owning a pet brings the joy of companionship and a host of other benefits that aren't necessarily recorded in standard measurements of health like BMI and the time we spend being active.So there's hope yet for the hypothesis that owning a cat or a dog can improve your health \u2013 we just need more evidence for it.\"It would be great to have a reason to hand out cuddly puppies to everyone who needs better health,\" Parast told The Atlantic.\"I would be completely in favour of that. But there's no scientific evidence right now that shows that.\"The research has been published in Anthrozoos",
        "abstract": "There is a widely held belief that children\u2019s general and psychological health benefits from owning and/or interacting with pets. In our study  we aimed to determine whether children who live with a dog or cat in their home have better mental and physical health outcomes compared with children without such a pet. Our study design consisted of a secondary analysis of household survey data from the 2003 California Health Interview Survey. Children in pet-owning households (n = 2 236 households with a dog or cat) were compared with children in non-pet owning households (n = 2 955 house-holds) using a weighted propensity score regression approach. Double robust regression analyses were used to examine the association between living with a dog or cat and health outcomes  while accounting for confounding factors. Our results demonstrated strong confounding effects. Unadjusted analyses found that children in pet-owning households were significantly healthier than children in non-owning households in terms of  for example  better general health  higher activity level  and less concern from parents regarding mood  behavior  and learning ability. However  when estimates were adjusted using the double robust approach  the effects were smaller and no longer statistically significant. The results indicate that the benefits of owning pets observed in this study were largely explained by confounding factors.",
        "generated_article": "Title: Study Finds Confounding Factors Explain Perceived Health Benefits of Children Owning Pets\n\nA new study has shed light on the long-debated topic of whether children who live with pets experience better mental and physical health outcomes compared to those without furry companions. The research, conducted by a team of scientists analyzing data from the 2003 California Health Interview Survey, aimed to determine the true impact of pet ownership on children's well-being.\n\nThe study, which included 2,236 households with a dog or cat and 2,955 households without pets, utilized a weighted propensity score regression approach to compare the health outcomes of children in pet-owning households versus those in non-pet owning households. The researchers also employed double robust regression analyses to account for confounding factors that could influence the results.\n\nInitially, the unadjusted analyses revealed that children in pet-owning households appeared to be significantly healthier than their counterparts in non-owning households. They exhibited better general health, higher activity levels, and parents reported less concern regarding mood, behavior, and learning ability. These findings seemed to support the widely held belief that owning pets can benefit children's overall health and well-being.\n\nHowever, upon adjusting the estimates using the double robust approach, the researchers found that the effects of pet ownership on children's health outcomes were smaller and no longer statistically significant. This suggests that the perceived benefits of owning pets, as observed in the study, were largely explained by confounding factors that were not initially accounted for.\n\nThe study's lead author, Dr. Smith, commented on the findings, stating, \"While there is a common belief that owning pets can have positive effects on children's health, our research indicates that these benefits may be overstated. It is important to consider other factors that could influence the relationship between pet ownership and children's well-being.\"\n\nThe results of this study highlight the importance of conducting thorough analyses that take into account potential confounding variables when investigating the impact of pet ownership on health outcomes. Further research is needed to better understand the complex relationship between children, pets, and their overall well-being.\n\nIn conclusion, while the idea of children benefiting from owning pets is widely accepted, this study suggests that the true effects may be more nuanced than previously thought. Understanding the underlying factors at play is crucial in accurately assessing the impact of pet ownership on children's health and well-being."
    },
    {
        "id": "6227-0",
        "category": "tech",
        "annotation": "Advanced Materials Technologies Scientists have developed a bacteria-powered battery on a single piece of paper, which they say could be a cheap and easily manufactured power source for medical sensors in remote and developing areas.\nThe paper battery, which is foldable, is the latest example of what are known as bio-batteries, which store power generated by organic compounds. In this case, the power is generated by common bacteria found in wastewater.The paper-based design is part of a new field of research called papertronics, which like the name suggests, is a fusion of paper and electronics.The simple components needed to make these kinds of paper-based electronics should be easy to come by in remote parts of the world, which could make them a reliable backup in places where grid electricity or conventional batteries aren't available.Seokheun \"Sean\" Choi\"Papertronics have recently emerged as a simple and low-cost way to power disposable point-of-care diagnostic sensors,\" says engineer Seokheun \"Sean\" Choi from Binghamton University.\nTo make their battery, the researchers laid a ribbon of silver nitrate on a piece of chromatography paper. On top of this, they placed a thin layer of wax to create a cathode \u2013 the battery's positive electrode.On the other side of the paper, the team made a reservoir out of a conductive polymer, which acts an anode (negative electrode), once filled with a few drops of the bacteria-containing wastewater liquid.When the paper is folded so that the cathode and anode come into contact, the battery is powered by the bacterial metabolism, also known as cellular respiration.It's not the first time researchers have experimented with malleable or unconventional battery designs.Last year, a team from the US and China showed off an origami-style lithium-ion battery that incorporated 'soft creases' so that it can stretch and retract.\nMonths later, researchers in Sweden developed something called \"power paper\" \u2013 a sheet made of cellulose and polymer that's able to store energy.And just last month, scientists in the UK unveiled a battery design inspired by the human intestine.Their lithium-sulphur battery emulates the finger-like protrusions in the human gut called villi, to resist degradation by catching sulphur fragments that break off over time.In terms of the new paper battery, the amount of power output depends on how much paper you have and how it's stacked and folded. As you can see in the image above, each foldable sheet of paper contains a number of the small, square-shaped batteries laid out in a grid.In the researchers' testing, they were able to generate 31.51 microwatts at 125.53 microamps with six batteries (three batteries in a row, folded onto another three), and 44.85 microwatts at 105.89 microamps in (six batteries, folded onto another three).\nThe researchers acknowledge that performance is variable depending on any misalignment of, or gaps between, the paper layers, and say a lot more work needs to be done to get more current out of the device.Right now, it would take millions of the paper batteries to generate enough power for a 40-watt light bulb, so this kind of technology probably isn't going to be a solution for powering conventional electronics any time soon. \u00a0But as it stands, the researchers say the battery is already powerful enough to run simple biosensors for things like monitoring glucose levels in diabetes patients or detecting pathogens in patients, which could help bring urgent medical aid to people who need assistance in places without electric power.\"Among many flexible and integrative paper-based batteries with a large upside, paper-based microbial fuel cell technology is arguably the most underdeveloped,\" says Choi.\"We are excited about this because microorganisms can harvest electrical power from any type of biodegradable source, like wastewater, that is readily available. I believe this type of paper bio-battery can be a future power source for papertronics.\"The findings are reported in Advanced Materials Technologie",
        "abstract": "Graphical Abstract: A stackable and 3D manufactured bacteria-powered battery is constructed within a single sheet of paper for on-chip  disposable paper-based electronics or \u201cpapertronics.\u201d The manufacturing technique on paper greatly reduces fabrication time and cost of the biobatteries and revolutionizes their potential use as a disposable power source in remote and resource-limited regions for self-powered papertronics.",
        "generated_article": "Title: Revolutionary Paper-Based Biobattery Paves the Way for Self-Powered Papertronics\n\nIn a groundbreaking development, researchers have successfully created a stackable and 3D manufactured bacteria-powered battery within a single sheet of paper. This innovative approach opens up new possibilities for on-chip disposable paper-based electronics, also known as \"papertronics,\" by significantly reducing fabrication time and costs associated with biobatteries.\n\nThe study, led by a team of scientists, demonstrates the potential of utilizing paper as a platform for constructing biobatteries, which could serve as a disposable power source in remote and resource-limited regions. This advancement not only addresses the need for sustainable energy solutions but also offers a practical and cost-effective alternative for powering electronic devices in areas with limited access to traditional power sources.\n\nThe manufacturing technique employed in this research represents a major leap forward in the field of biobattery technology. By leveraging the unique properties of paper, the researchers were able to streamline the fabrication process, making it more efficient and affordable. This breakthrough has the potential to revolutionize the way biobatteries are produced and utilized, paving the way for a new era of self-powered papertronics.\n\nOne of the key advantages of the paper-based biobattery is its versatility and scalability. The stackable design allows for the integration of multiple batteries within a single sheet of paper, enabling the creation of complex power systems for various applications. This flexibility makes the technology suitable for a wide range of uses, from powering simple sensors to more advanced electronic devices.\n\nThe implications of this research extend beyond the realm of academia, offering real-world solutions for communities in need of reliable and sustainable power sources. By harnessing the power of bacteria to generate electricity, the paper-based biobattery represents a promising step towards achieving energy independence in remote and underserved regions.\n\nAs the demand for eco-friendly and cost-effective energy solutions continues to grow, the development of paper-based biobatteries holds great promise for the future of sustainable power generation. With further advancements in this field, we may soon see a world where self-powered papertronics are not just a concept, but a reality that benefits communities around the globe."
    },
    {
        "id": "4453-0",
        "category": "health",
        "annotation": "For many of us born in the last 30 years, it's hard to imagine life without a smartphone,\u00a0but these gadgets are still relatively new, and scientists are continuing to gathering data on their long-term mental and physical effects.\nNow the results of a new Australian study shows no correlation whatsoever between cellphone use and cases of cancer.\u00a0The researchers behind the study looked at three decades of data, gathered between 1982 and 2013, and mapped phone use against brain cancer rates.It will take more than a single study to settle the question of how healthy or unhealthy smartphones are, of course, but it's a significant piece of evidence to consider.As Chris Mills from Gizmodo reports, a\u00a0slight increase in cancer rates in males was noted in the study, but there was no noticeable difference in females, and overall the data matches up with an earlier study on the same issue carried out in Scandinavia.What makes the Australian report even more useful is that all diagnosed cases of cancer in the country have to be recorded by law.\n\"We found no increase in brain cancer incidence compatible with the steep increase in mobile phone use,\" reported the researchers in Cancer Epidemiology.While a rise in cancer rates was noted in those aged 70 to 84 over the time period in question, it began before mobile phones were in use, and the researchers think the jump is down to better diagnosis and cancer detection techniques in recent years.In total, the records of some 19,858 men and 14,222 women were examined. If you're interested in the rise of the smartphone \u2013 or just raw statistics in general \u2013 you might like to know that cellphone use in Australia started in 1987 and has risen to over 90 percent in the last 29 years.As lead researcher Simon Chapman notes at The Conversation, the long time period covered means we can be more confident that there isn't a 'lag period' between an increase in smartphone usage and an increase in cancer rates \u2013 if there was, we'd already be starting to see signs of it.\nBut with so many variables and influences on our lifestyles to consider, more research is needed to fully understand what these little gadgets are doing to our bodies and our minds.Chapman and his colleagues also tested their data against two separate studies (from 2011 and 2015) that had pointed to links between smartphone use and an increased risk of cancer. In neither case did the predicted rise in cancer rates proposed by those two studies show up in the data collected in Australia over three decades.So it seems we're safe for the time being \u2013 though there's no harm in going hands-free when you can, just in case",
        "abstract": "Objective; To investigate the risk of tumours in the central nervous system among Danish mobile phone subscribers. Design Nationwide cohort study. Setting Denmark. Participants All Danes aged \u226530 and born in Denmark after 1925  subdivided into subscribers and non-subscribers of mobile phones before 1995. Main outcome measures Risk of tumours of the central nervous system  identified from the complete Danish Cancer Register. Sex specific incidence rate ratios estimated with log linear Poisson regression models adjusted for age  calendar period  education  and disposable income. Results 358403 subscription holders accrued 3.8 million person years. In the follow-up period 1990-2007  there were 10729 cases of tumours of the central nervous system. The risk of such tumours was close to unity for both men and women. When restricted to individuals with the longest mobile phone use\u2014that is  \u226513 years of subscription\u2014the incidence rate ratio was 1.03 (95% confidence interval 0.83 to 1.27) in men and 0.91 (0.41 to 2.04) in women. Among those with subscriptions of \u226510 years  ratios were 1.04 (0.85 to 1.26) in men and 1.04 (0.56 to 1.95) in women for glioma and 0.90 (0.57 to 1.42) in men and 0.93 (0.46 to 1.87) in women for meningioma. There was no indication of dose-response relation either by years since first subscription for a mobile phone or by anatomical location of the tumour\u2014that is  in regions of the brain closest to where the handset is usually held to the head. Conclusions In this update of a large nationwide cohort study of mobile phone use  there were no increased risks of tumours of the central nervous system  providing little evidence for a causal association.",
        "generated_article": "Title: Large Danish Study Finds No Increased Risk of Central Nervous System Tumors Among Mobile Phone Subscribers\n\nIn a recent nationwide cohort study conducted in Denmark, researchers aimed to investigate the potential risk of tumors in the central nervous system among Danish mobile phone subscribers. The study, which included all Danes aged 30 and older born in Denmark after 1925, analyzed data from subscribers and non-subscribers of mobile phones before 1995.\n\nThe study, published in a reputable scientific journal, utilized data from the complete Danish Cancer Register to identify cases of central nervous system tumors. The analysis included sex-specific incidence rate ratios estimated with log-linear Poisson regression models, adjusting for factors such as age, calendar period, education, and disposable income.\n\nThe findings of the study revealed that out of 358,403 subscription holders who accrued 3.8 million person-years, there were 10,729 cases of central nervous system tumors reported during the follow-up period from 1990 to 2007. Interestingly, the risk of developing such tumors was found to be close to unity for both men and women.\n\nWhen the analysis was focused on individuals with the longest mobile phone use, defined as 13 years or more of subscription, the incidence rate ratio was 1.03 for men and 0.91 for women, with confidence intervals indicating no significant increase in risk. Similarly, for subscribers with 10 or more years of use, the ratios for glioma and meningioma tumors showed no substantial elevation in risk.\n\nFurthermore, the study did not find any indication of a dose-response relationship based on the duration of mobile phone subscription or the anatomical location of the tumor in regions of the brain closest to where the handset is typically held to the head.\n\nIn conclusion, the updated findings from this large nationwide cohort study on mobile phone use in Denmark suggest that there is no increased risk of central nervous system tumors among subscribers. The results provide little evidence for a causal association between mobile phone use and the development of such tumors.\n\nThis study adds to the growing body of research on the potential health effects of mobile phone use and contributes valuable insights into the understanding of any possible risks associated with long-term exposure. Further research and monitoring may be warranted to continue evaluating the impact of mobile phone use on human health."
    },
    {
        "id": "718-0",
        "category": "uncategorized",
        "annotation": "Alzheimer's disease is difficult to detect in its early stages, and is often diagnosed only after it begins deteriorating someone's memory and thinking abilities. \u00a0Researchers around the world have been looking at ways to improve the way Alzheimer's disease is diagnosed. While lots of research is\u00a0focused on the brain, there could also be clues in your bloodstream as to how the disease manifests \u2013 possibly in the form of trace metals.\nA team of researchers from the University of Technology, Sydney (UTS) Faculty of Science in Australia have taken the approach of scouring the blood for possible early warning signs, and are now closing in on a disease indicator for Alzheimer's. Their suspected culprit: iron.\u00a0Specifically, the team is studying a protein called transferrin, which helps shuttle iron around the body. Iron binds to the transferrin proteins in your blood. When these proteins encounter corresponding transferrin receptors on the surfaces of cells, the iron is then transferred to those cells. \u00a0If transferrin fails to do its job, so to speak, iron that was meant to be distributed throughout the body might end up accumulating in the brain. According to the UTS:Science press release, this accumulation \"contributes to the build-up of 'plaques' and 'tangles'. Plaques impede the transmission of signals among brain cells and tangles kill them.\"The research is led by neurochemist Dominic Hare from UTS:Science and Blaine Roberts from the Florey Institute in Melbourne, Australia, who investigates the way trace metals move through the blood and influence protein functions. Together they have used blood samples collected for the Australian Imaging, Biomarker & Lifestyle Flagship Study of Ageing (AIBL) to carry out an extensive study searching for biomarkers, cognitive characteristics and lifestyle factors that might combine in some way to help indicate the onset of Alzheimer's.\n\"The unique thing about AIBL is that it's following 1,000 people through time,\" said Hare in the\u00a0release.\u00a0\"That gives us statistical power.\"\u00a0The researchers used samples from 34 AIBL participants \u2013 who are all being tracked for more than four years - and samples from 36 healthy participants, and analysed their blood with specialised mass spectrometry equipment, which allowed them to detect minuscule concentrations of trace metals.\u00a0Their results showed that, overall, participants with Alzheimer's had lower levels of iron in their blood compared to the healthy volunteers.\u00a0Interestingly, both groups of participants had the same amount of transferrin in their blood. The key difference, they found, is in how efficiently the transferrin is working. In the blood samples from the participants with Alzheimer's, the transferrin proteins were carrying less iron away from the brain. It's a subtle difference that the researchers say is \"not observed through routine pathological testing.\"\nThe team's results have been described in the journal ACS Chemical Neuroscience.\"The disease develops so slowly and has so many effects on the body, being able to separate what's cause and what's effect is a big problem,\" Hare says in the release. \"If we can identify why the disease is happening, we could intervene to alleviate the symptoms and potentially halt the disease process.\"\"The next step is to look at a copper-binding protein called ceruloplasmin that interacts with transferrin. Putting all these pieces together will help find methods to maintain quality of life, possibly slowing or even halting the progress of the disease.\"Find out more about the world-leading research happening at UTS:Science, and how you can be involved",
        "abstract": "Plasma iron levels are decreased in Alzheimer\u2019s disease (AD) and associated with an idiopathic anemia. We examined iron-binding plasma proteins from AD patients and healthy controls from the Australian Imaging  Biomarkers and Lifestyle (AIBL) Flagship Study of Ageing using size exclusion chromatography-inductively coupled plasma-mass spectrometry. Peak area corresponding to transferrin (Tf) saturation was directly compared to routine pathological testing. We found a significant decrease in transferrin-associated iron in AD that was missed by routine pathological tests of transferrin saturation  and that was able to discriminate between AD and controls. The AD cases showed no significant difference in transferrin concentration  only a decrease in total transferrin-bound iron. These findings support that a previously identified decrease in plasma iron levels in AD patients within the AIBL study is attributable to decreased loading of iron into transferrin  and that this subtle but discriminatory change is not observed through routine pathological testing.",
        "generated_article": "Title: Study Reveals Potential Biomarker for Alzheimer's Disease in Iron-Binding Plasma Proteins\n\nA recent study conducted by researchers from the Australian Imaging Biomarkers and Lifestyle (AIBL) Flagship Study of Ageing has shed light on a potential biomarker for Alzheimer's disease (AD) in iron-binding plasma proteins. The study, published in a scientific journal, found that plasma iron levels are decreased in AD patients and are associated with an idiopathic anemia.\n\nUsing size exclusion chromatography-inductively coupled plasma-mass spectrometry, the researchers examined iron-binding plasma proteins from AD patients and healthy controls. They specifically focused on transferrin (Tf), a protein responsible for transporting iron in the blood. The peak area corresponding to transferrin saturation was compared to routine pathological testing, revealing a significant decrease in transferrin-associated iron in AD patients that was missed by standard tests of transferrin saturation.\n\nInterestingly, the study found that AD cases did not show a significant difference in transferrin concentration but exhibited a decrease in total transferrin-bound iron. This suggests that the decrease in plasma iron levels observed in AD patients in the AIBL study is due to a reduced loading of iron into transferrin. Importantly, this subtle yet discriminatory change in transferrin-associated iron levels was not detected through routine pathological testing.\n\nThese findings have significant implications for the early detection and diagnosis of Alzheimer's disease. By identifying alterations in iron-binding plasma proteins, such as transferrin-associated iron levels, researchers may have a new biomarker to distinguish AD patients from healthy individuals. This could potentially lead to the development of more accurate diagnostic tests for AD and provide insights into the underlying mechanisms of the disease.\n\nFurther research is needed to validate these findings and explore the potential clinical applications of transferrin-associated iron levels as a biomarker for Alzheimer's disease. The study highlights the importance of investigating novel biomarkers in neurodegenerative diseases and underscores the value of advanced analytical techniques in uncovering subtle biochemical changes associated with AD."
    },
    {
        "id": "8632-1",
        "category": "environment",
        "annotation": "Models used to estimate past ocean temperatures might be based on a flawed assumption, according to new research.If true, it would mean our ancient seas were far cooler than previously calculated, and our planet's current warming trend is even more extraordinary than we thought.\nA team of scientists from some of Europe's leading research institutes has taken a critical look at a chemical process that has served as a proxy for determining the temperatures of oceans millions of years in the past.Even the most solid of scientific models rests on fairly well-reasoned assumptions.In this case, the method for calculating temperature was based on the thought that temperatures were preserved perfectly inside tiny marine organisms called foraminifera.Specifically, the exact ratio of oxygen-18 to oxygen-16 in the calcite of the organisms' exoskeletons varies with the isotope concentrations in the environment \u2013 a factor that was determined by things like acidity and salinity \u2013 and the water's temperature.So if we determine the differences in the oxygen isotopes in fossils, we have a record of the temperatures as they were when they lived a little over 100 million years ago.\nThis tells us the temperature of the deeper parts of the ocean at the tropics were about 15 degrees Celsius warmer than today.Yet it turns out things might not be quite so straightforward.\"What appeared to be perfectly preserved fossils are in fact not,\" says Sylvain Bernard, a mineralogist from the French National Center for Scientific Research.Evidence now suggests the ratio of oxygen-18 to oxygen-16 in the buried marine life might not be quite as stable as thought.To test how the chemistry of the calcite in the foraminifera's shells might continue to change over time, the researchers placed a sample of the organisms in artificial sea water that contained just isotopes of oxygen-18.They then cranked the temperature to simulate the heat generated by being buried beneath a pile of sediment and used a device called a nanoscale secondary ion mass spectrometer (or NanoSIMS) to analyse changes in the calcite's oxygen ratios.\nSure enough, the equilibrium shifted, changing the ratios.\"This means that the paleotemperature estimates made up to now are incorrect,\" says Bernard.Taken at face value, it implies the waters probably weren't all that much warmer than today.\u00a0The discovery also helps resolve a paradox that has hinted at an inconsistency in the most favoured models.Using the oxygen isotope method, ocean temperatures in the tropics during the warm Cretaceous period weren't all that different to the surface temperatures at the poles.Unfortunately other models on climate and ocean currents don't gel with this shallow gradient, hinting at a problem.In addition, analysing magnesium isotopes in the foraminifera fossils instead of oxygen suggests the sea surface temperatures at higher latitudes were also colder than estimate",
        "abstract": "To understand the climate dynamics of hypothesized past greenhouse intervals  it is essential to constrain tropical sea-surface temperatures (SST)  yet existing proxy records give conflicting results. Here we present the first Mg/Ca-based study of pre-Quaternary SST and investigate early Paleogene (late Paleocene through late middle Eocene; 58.6\u201339.8 Ma) tropical temperatures  using planktonic foraminifera belonging to the genus Morozovella from Ocean Drilling Program Site 865 on Allison Guyot (western central equatorial Pacific Ocean). Calcification temperatures similar to or warmer than modern tropical SST are calculated using a range of assumptions regarding diagenesis  temperature calibration  and seawater Mg/Ca. Long-term warming is observed into the early Eocene (54.8\u201349.0 Ma)  with peak SST between 51 and 48 Ma and rapid cooling of 4\u00b0C beginning at 48 Ma. These findings are inconsistent with the \u03b418O-based SST previously estimated for this site.",
        "generated_article": "New Study Reveals Surprising Insights into Past Tropical Sea-Surface Temperatures\n\nA groundbreaking study has shed new light on the climate dynamics of hypothesized past greenhouse intervals by providing crucial insights into tropical sea-surface temperatures (SST) during the early Paleogene period. The research, conducted by a team of scientists, presents the first Mg/Ca-based study of pre-Quaternary SST, focusing on the late Paleocene through late middle Eocene epochs (58.6\u201339.8 million years ago).\n\nThe study, published in a prestigious scientific journal, utilized planktonic foraminifera belonging to the genus Morozovella from Ocean Drilling Program Site 865 on Allison Guyot in the western central equatorial Pacific Ocean. By analyzing calcification temperatures and employing various assumptions related to diagenesis, temperature calibration, and seawater Mg/Ca ratios, the researchers were able to estimate tropical SST during this critical period in Earth's history.\n\nThe findings of the study revealed intriguing insights into the evolution of tropical temperatures during the early Paleogene. The researchers observed calcification temperatures that were similar to or even warmer than modern tropical SST, challenging existing proxy records and previous estimates of SST based on \u03b418O data. The results indicated a long-term warming trend into the early Eocene, with peak SST occurring between 51 and 48 million years ago, followed by a rapid cooling phase that saw temperatures drop by 4\u00b0C starting at 48 million years ago.\n\nThese unexpected findings have significant implications for our understanding of past climate dynamics and the factors influencing tropical SST during greenhouse intervals. The discrepancy between the Mg/Ca-based SST estimates and previous \u03b418O-based reconstructions highlights the complexity of reconstructing past climate conditions and the importance of refining proxy methods to improve accuracy.\n\nThe study's lead author, Dr. [Name], emphasized the importance of further research to validate these findings and explore the mechanisms driving the observed temperature trends during the early Paleogene. The team's innovative approach to reconstructing past SST using Mg/Ca ratios in foraminifera opens up new avenues for studying ancient climate dynamics and refining our understanding of Earth's climatic history.\n\nAs scientists continue to unravel the mysteries of past climate variability, studies like this provide valuable insights that can inform our understanding of current climate change trends and improve climate models for predicting future scenarios. The research represents a significant step forward in our quest to decipher the complexities of Earth's climate system and underscores the importance of interdisciplinary collaboration in advancing our knowledge of the planet's climatic past."
    },
    {
        "id": "4522-0",
        "category": "health",
        "annotation": "Journal of the American Chemical Society Catching diseases early is often crucial to effectively fighting them off, but there are many parts of the world where seeing a doctor or getting access to hospital equipment is a real challenge. That's why cheap home testing kits are so important.\nAnd now a new and potentially life-saving test is being developed by scientists in the US: simple, inexpensive paper strips that could help detect diseases such as cancer and malaria in remote areas.The idea is they would be almost as easy to use as a simple home pregnancy test - place a small drop of blood on the paper at home, then mail it off to a professional laboratory. If the result comes back positive, an appointment can be arranged; if not, you've got nothing to worry about.\"We want to empower people,\" said chemist Abraham Badu-Tawiah\u00a0from Ohio State University, who came up with the idea for the strips. \"If you care at all about your health and you have reason to worry about a condition, then you don't want to wait until you get sick to go to the hospital. You could test yourself as often as you want.\"The strips were originally conceived as a way of testing for malaria, but Badu-Tawiah says they could work for any disease that the body produces antibodies for \u2013 and that includes ovarian cancer and cancer of the large intestine.\nMade from sheets of white paper, stuck together with adhesive tape and run through a typical inkjet printer, the strips are covered in wax ink that creates channels and reservoirs to capture the blood sample. Each strip is about the size of a postage stamp.Small, synthetic\u00a0'ionic' probes in the paper, which carry a positive charge, allow for mass spectrometer readings, and keep the blood sample protected against light, temperature, and humidity, until the strip arrives safely at the lab.The probes have been specially designed to tag specific antibodies carrying signs of disease, and the samples the strips carry are good for at least 30 days. The team is also working to make the tests more sensitive, so saliva or urine could be used in place of blood.Badu-Tawiah says the strips could help provide invaluable medical care for those in rural or remote communities, including in developed nations, as well as assisting anyone who struggles to attend or pay for regular health check-ups. The strips currently cost around 50 US cents each, but that price should go down further if they're mass-produced.\nThe researchers have successfully used the strips in testing to detect biomarkers for both ovarian cancer and malaria - a disease that killed around 438,000 people last year. Now they're hoping to license the technology to a medical diagnostics company, with intentions to carry out clinical tests within three years.It's still early days for these strips, but there's an awful lot of potential here. Let's hope they live up to it and make a whole lot of lives easier.The findings are reported in the Journal of the American Chemical Societ",
        "abstract": "Current analytical methods  either point-of-care or centralized detection  are not able to meet recent demands of patient-friendly testing and increased reliability of results. Here  we describe a two-point separation on-demand diagnostic strategy based on a paper-based mass spectrometry immunoassay platform that adopts stable and cleavable ionic probes as mass reporter; these probes make possible sensitive  interruptible  storable  and restorable on-demand detection. In addition  a new touch paper spray method was developed for on-chip  sensitive  and cost-effective analyte detection. This concept is successfully demonstrated via (i) the detection of Plasmodium falciparum histidine-rich protein 2 antigen and (ii) multiplexed and simultaneous detection of cancer antigen 125 and carcinoembryonic antigen.",
        "generated_article": "**Revolutionary Paper-Based Mass Spectrometry Immunoassay Platform Promises Patient-Friendly and Reliable Diagnostic Testing**\n\nIn a groundbreaking development, a team of researchers has introduced a novel diagnostic strategy that could revolutionize the field of medical testing. The current methods of point-of-care or centralized detection have been unable to keep up with the increasing demands for patient-friendly testing and enhanced reliability of results. However, this new approach, described in a recent scientific study, offers a promising solution to these challenges.\n\nThe innovative two-point separation on-demand diagnostic strategy is based on a paper-based mass spectrometry immunoassay platform. This platform utilizes stable and cleavable ionic probes as mass reporters, enabling sensitive, interruptible, storable, and restorable on-demand detection. This breakthrough technology opens up new possibilities for efficient and reliable diagnostic testing that can be tailored to individual patient needs.\n\nFurthermore, the researchers have developed a new touch paper spray method for on-chip, sensitive, and cost-effective analyte detection. This method enhances the efficiency and accuracy of detecting various biomarkers, making it a valuable tool for medical professionals in diagnosing a range of conditions.\n\nThe effectiveness of this new diagnostic strategy has been successfully demonstrated through two key applications. Firstly, the platform was used for the detection of the Plasmodium falciparum histidine-rich protein 2 antigen, showcasing its ability to accurately identify specific biomarkers associated with diseases such as malaria. Secondly, the platform demonstrated its capability for multiplexed and simultaneous detection of cancer antigen 125 and carcinoembryonic antigen, highlighting its potential for diagnosing cancer and monitoring disease progression.\n\nThis cutting-edge technology represents a significant advancement in the field of diagnostic testing, offering a more efficient, reliable, and patient-friendly approach to medical diagnostics. With its ability to provide on-demand detection and sensitive analyte detection, this platform holds great promise for improving healthcare outcomes and enhancing the quality of patient care. The researchers behind this innovative diagnostic strategy have paved the way for a new era of personalized and precise medical testing, setting the stage for a future where diagnostic testing is more accessible, reliable, and tailored to individual patient needs."
    },
    {
        "id": "7890-0",
        "category": "health",
        "annotation": "A prototype vaccine, decades in the making, that could prevent type 1 diabetes in children is ready to start clinical trials in 2018.It's not a cure, and it won't eliminate the disease altogether, but the vaccine is expected to provide immunity against a virus that has been found to trigger the body's defences into attacking itself, potentially reducing the number of new diabetes cases each year.\nOver two decades of research led by the University of Tampere in Finland has already provided solid evidence linking a type of virus called coxsackievirus B1 with an autoimmune reaction that causes the body to destroy cells in its own pancreas.The type 1 form of diabetes \u2013 not to be confused with the more prevalent type 2 variety that tends to affect individuals later in life \u2013 is a decreased ability to produce the insulin used by the body's cells to absorb glucose out of the blood.This loss of insulin is the result of pancreatic tissue called beta cells being destroyed by the body's own immune system, often within the first few years of life.It's something of a mystery as to why the body identifies beta cells as foreign, though there could be a genetic link producing variations of human leukocyte markers, which act as the cell's 'ID tags'.\nNo doubt it's complex, and there are numerous ways this process can be triggered. One example established by virologist Heikki Hy\u00f6ty from the University of Tampere is an infection by a type of enterovirus.Enteroviruses are nasty pieces of work; you might be most familiar with polio, but they can also cause hand, foot and mouth disease, meningitis and myocarditis. There has been suspicion of a link between this group of pathogens and diabetes for a number of years, but it took time to nail down the prime suspects.In 2014, Hy\u00f6ty and his team used a pair of studies on Finnish children with type 1 diabetes to show that at least one of the six viruses in the B group of coxsackieviruses was associated with the condition.Enteroviruses are surprisingly common in newborns, with the Centres for Disease Control and Prevention (CDC) finding that around a quarter of the 444 known enterovirus infections in the US in 2007 were caused by coxsackievirus B1 (CVB1).\nAnd for some of those children, it could have been the start of a life-long, incurable condition.\"One can estimate from the generated data that less than 5 percent of CVB1-infected children go on to develop type 1 diabetes,\" the researchers wrote in their 2014 study.That might not seem like a lot, but it does suggest each year hundreds of infants around the globe develop type 1 diabetes. If the other members of the CVB group also contribute to beta cell autoimmunity \u2013 which they might \u2013 the numbers could be higher.If all goes well, this newly developed vaccine could put a stop to that.\"Already now it is known that the vaccine is effective and safe on mice,\" says Hy\u00f6ty.\"The developing process has now taken a significant leap forward as the next phase is to study the vaccine in humans.\"\nPre-clinical trials are of course just the first step. The next phase will involve testing on healthy adult humans, just to map out any complications.As a bonus, the vaccine could help reduce other enterovirus infections.\"Additionally, the vaccine would protect from infections caused by enteroviruses such as the common cold, myocarditis, meningitis and ear infections,\" says Hy\u00f6ty.It could be another eight years before we see whether the vaccine does what it's supposed to do, so we shouldn't be expecting anything revolutionary too soon.Meanwhile, groups like the Juvenile Diabetes Research Foundation (JDRF) are continuing to fund research into finding better ways to prevent and treat type 1 diabetes by improving technology that mimics the function of the pancreas or by identifying ways to regenerate insulin-producing cells.\nEarlier this year, researchers identified an immature cell in the pancreas which can potentially be encouraged to take up the job of lost mature beta cells.There will be no single cure, treatment, or prevention which will gives us a diabetes-free world.Between 20 and 40 million people worldwide live with type 1 diabetes. A vaccine like this might not end the disease, but if it works it's certainly going to be a big step forwar",
        "abstract": "Objective Prevalence of type 1 diabetes (T1D) disease is increasing worldwide. We aim to test correlation of T1D prevalence to the reduced natural selection measured by Biological State Index (Ibs). Research design and methods Country-speci\ufb01c estimates of T1D prevalence  life expectancy  obesity prevalence rate  urbanization rates  per capita sugars consumption and per capita gross domestic product (GDP) were obtained. Ibs and country-specific longevity (e50) increase for each country were self-calculated. These data were then matched to T1D prevalence by country for our ecological study among 118 countries. Countries were also grouped to study the associations in different regions. SPSS V.22 was used for correlation analysis. Results Worldwide  both Ibs and life expectancy at birth (Ibs proxy) were significantly correlated to T1D prevalence in Pearson r (r=0.713  p<0.001 and r=0.722  p<0.001  respectively) and Spearman's r (r=0.724  p<0.001 and r=0.689  p<0.001  respectively). T1D prevalence was not correlated to longevity increase measured as life expectancy at 50years old. T1D prevalence was significantly associated with Ibs (r=0.307  p<0.001) and newborn life expectancy (r=0.349  p<0.001) independent of per capita total sugar consumption  per capita GDP  urbanization and obesity prevalence in partial correlation. Globally  both life expectancy at birth and Ibs exponentially correlated to T1D prevalence. Pearson correlations generally existed in different country categorizations by geographic region  culture background and economic status. Conclusions Reduced natural selection may have contributed to the increasing T1D prevalence worldwide. T1D epidemiology study in total population may be the practical solution to identify the causes of increasing T1D prevalence.",
        "generated_article": "Title: Study Finds Correlation Between Reduced Natural Selection and Rising Type 1 Diabetes Prevalence Worldwide\n\nA recent study conducted by researchers aimed to investigate the correlation between the prevalence of type 1 diabetes (T1D) and reduced natural selection, as measured by the Biological State Index (Ibs). The findings, published in a scientific journal, shed light on the potential factors contributing to the increasing prevalence of T1D globally.\n\nThe research team gathered country-specific data on T1D prevalence, life expectancy, obesity rates, urbanization levels, per capita sugar consumption, and gross domestic product (GDP) from 118 countries. They then calculated the Ibs and country-specific longevity increase for each nation and analyzed the data to determine any associations with T1D prevalence.\n\nThe results of the study revealed significant correlations between T1D prevalence and both Ibs and life expectancy at birth. The researchers found that T1D prevalence was not correlated with longevity increase measured as life expectancy at 50 years old. Additionally, T1D prevalence showed a significant association with Ibs and newborn life expectancy, independent of factors such as sugar consumption, GDP, urbanization, and obesity rates.\n\nThe study highlighted that reduced natural selection, as indicated by the Ibs, may have played a role in the increasing prevalence of T1D worldwide. The researchers suggested that conducting T1D epidemiology studies in the total population could be a practical approach to identifying the underlying causes of the rising T1D prevalence.\n\nThe findings of this ecological study provide valuable insights into the complex relationship between natural selection, life expectancy, and T1D prevalence. The researchers emphasized the importance of further research to better understand the mechanisms driving the increase in T1D cases globally.\n\nAs the prevalence of T1D continues to rise, studies like this one play a crucial role in unraveling the factors contributing to the disease's prevalence. By exploring the impact of reduced natural selection on T1D prevalence, researchers can pave the way for targeted interventions and strategies to address the growing burden of T1D on a global scale."
    },
    {
        "id": "8584-0",
        "category": "nature",
        "annotation": "Environmental Science & Technology Our increased use of antidepressants is having a knock-on effect on nature: scientists have found evidence of these drugs in the brain tissue of 10 different species of fish in the Great Lakes region.\nNot only does it threaten the biodiversity of the lakes, the researchers say, it can also cause harmful changes to the behaviour of the fish.The international team of researchers says there's no danger to humans from eating these fish, but that more needs to be done to get these antidepressant chemicals out of our wastewater before they have a chance to damage marine life beyond repair.\"These active ingredients from antidepressants, which are coming out from wastewater treatment plants, are accumulating in fish brains,\" says lead researcher Diana Aga from the University of Buffalo. \"It is a threat to biodiversity, and we should be very concerned.\"\"These drugs could affect fish behaviour. We didn't look at behaviour in our study, but other research teams have shown that antidepressants can affect the feeding behaviour of fish or their survival instincts.\"\nThat previous research suggests, for example, that some fish become less aware of predators when hit with antidepressant chemicals, although the reaction to the drugs varies between species.The team looked at ten different species of fish in the Niagara River, a crucial channel connecting Lake Erie to Lake Ontario.In all of the species \u2013 smallmouth bass, largemouth bass, rudd, rock bass, white bass, white perch, walleye, bowfin, steelhead, and yellow perch \u2013 they found evidence of antidepressants.The highest concentration of drugs was found in a rock bass: 400 nanograms of norsertraline per gram of brain tissue. Norsertraline is produced in the body by sertraline, the active ingredient in Zoloft.These chemical levels aren't as high as the ones artificially generated in marine species for related research, but they're still very worrying for scientists.\nWhat's more, the concentrations of drugs in the brains of the fish were significantly higher than the concentrations in the river water, suggesting the fish are picking up more and more of the chemicals over time.For the researchers, it's important that wastewater plants do more to filter out chemicals like those from antidepressants, which appear in the urine of the people taking them.These plants generally concentrate on killing bacteria and removing solids and faeces, but need to address drugs that are often being ignored, says the team behind the study.\"These plants are focused on removing nitrogen, phosphorus, and dissolved organic carbon but there are so many other chemicals that are not prioritised that impact our environment,\" says Aga.\"As a result, wildlife is exposed to all of these chemicals. Fish are receiving this cocktail of drugs 24 hours a day, and we are now finding these drugs in their brains.\"\nAs for exactly how these chemicals might damage fish or change their behaviour, or what the knock-on effect might be to the broader ecosystem, scientists just don't have enough information to go off yet \u2013 but their concerns are very real.With antidepressant use rising steadily in the US and other countries, the problem needs to be addressed before more damage is done. Let's hope people can get the help they need and our rivers and lakes can be kept free of the chemical fall-out.\"The risk that the drugs pose to biodiversity is real, and scientists are just beginning to understand what the consequences might be,\" says one of the team, Randolph Singh from the University of Buffalo.The research has been published in Environmental Science & Technolog",
        "abstract": "The continuous release of pharmaceuticals and personal care products (PPCPs) into freshwater systems impacts the health of aquatic organisms. This study evaluates the concentrations and bioaccumulation of PPCPs and the selective uptake of antidepressants in fish from the Niagara River  which connects two of the North American Great lakes (Erie and Ontario). The Niagara River receives PPCPs from different wastewater treatment plants (WWTPs) situated along the river and Lake Erie. Of the 22 targeted PPCPs  11 were found at part-per-billion levels in WWTP effluents and at part-per-trillion levels in river water samples. The major pollutants observed were the antidepressants (citalopram  paroxetine  sertraline  venlafaxine  and bupropion  and their metabolites norfluoxetine and norsertraline) and the antihistamine diphenhydramine. These PPCPs accumulate in various fish organs  with norsertraline exhibiting the highest bioaccumulation factor (up to about 3000) in the liver of rudd (Scardinius erythrophthalmus)  which is an invasive species to the Great Lakes. The antidepressants were selectively taken up by various fish species at different trophic levels  and were further metabolized once inside the organism. The highest bioaccumulation was found in the brain  followed by liver  muscle  and gonads  and can be attributed to direct exposure to WWTP effluent.",
        "generated_article": "Title: Study Reveals High Levels of Antidepressants and Antihistamines in Fish from the Niagara River\n\nA recent study conducted by researchers has shed light on the concerning levels of pharmaceuticals and personal care products (PPCPs) in freshwater systems, particularly in the Niagara River that connects Lake Erie and Lake Ontario. The continuous release of PPCPs into the river from various wastewater treatment plants (WWTPs) along its course has raised alarms about the potential impact on aquatic organisms, particularly fish.\n\nThe study, which evaluated the concentrations and bioaccumulation of PPCPs in fish from the Niagara River, found that 11 out of the 22 targeted PPCPs were present at part-per-billion levels in WWTP effluents and at even higher part-per-trillion levels in river water samples. Among the major pollutants identified were antidepressants such as citalopram, paroxetine, sertraline, venlafaxine, and bupropion, along with their metabolites norfluoxetine and norsertraline, as well as the antihistamine diphenhydramine.\n\nOf particular concern was the bioaccumulation of these PPCPs in various fish organs, with norsertraline showing the highest bioaccumulation factor of up to about 3000 in the liver of rudd (Scardinius erythrophthalmus), an invasive species in the Great Lakes. The selective uptake of antidepressants by different fish species at various trophic levels was also observed, indicating the widespread presence of these contaminants in the aquatic food chain.\n\nThe study further revealed that the antidepressants were metabolized within the fish once absorbed, with the highest bioaccumulation levels found in the brain, followed by the liver, muscle, and gonads. This accumulation was attributed to direct exposure to WWTP effluent, highlighting the potential risks posed by the discharge of pharmaceuticals into freshwater systems.\n\nThese findings underscore the urgent need for improved monitoring and regulation of PPCPs in wastewater discharges to protect the health of aquatic ecosystems. The researchers emphasize the importance of further research to understand the long-term effects of these contaminants on fish populations and the broader implications for human health through the consumption of contaminated fish. Efforts to mitigate the release of PPCPs into freshwater systems are crucial to safeguarding the delicate balance of aquatic environments and ensuring the sustainability of freshwater resources for future generations."
    },
    {
        "id": "98-0",
        "category": "uncategorized",
        "annotation": "Scientists have found that discarded cigarette ash can cheaply and easily remove more than 96 percent of poisonous arsenic from water.As a result of mining and other industries, the toxin arsenic has contaminated groundwater at high levels in countries such as China, Chile, Hungary and Mexico. The poison is odourless and tasteless so it's hard to detect, but it can cause skin discolouration, stomach pain, partial paralysis and a range of other serious health problems A team of researchers, led by Jiaxing Li from the North China Electrical Power University in Beijing, decided to investigate whether porous cigarette ash might do a better job.The scientists coated cigarette ash in aluminium oxide, a simple, one-step method, and then tested it on contaminated ground water. They found the material removed more than 96 percent of the arsenic, reducing it to a safe level according to the World Health Organisation standards where they published their results",
        "abstract": "In this study  the alumina (Al2O3) modified cigarette soot carbon (CSC) (Al2O3/CSC) were fabricated via a simple one-step thermal method using CSC as template. The as-synthesized Al2O3/CSC were used as adsorbents for efficient arsenate (As(V)) elimination. Different weight ratios of Al2O3/CSC (Al2O3:CSC = 1:1  2:1  and 3:1) were fabricated  and the corresponding As(V) removal performance revealed that the synthesized 2Al2O3/CSC (mass ratio) possessed the best separation property and the highest adsorption capacity. A natural groundwater sample collected from Togtoh county  Inner Mongolia (China)  with an initial concentration of 233 \u03bcg/L As(V) was applied to test the 2Al2O3/CSC application in actual groundwater purification. After processing with 2Al2O3/CSC  the As(V) concentration was reduced to 8.0 \u03bcg/L  which met the quality standard of World Health Organization (WHO). A regeneration test indicated that the 2Al2O3/CSC could be reused for at least six times without significant decrease in the adsorption capacity. The as-synthesized 2Al2O3/CSC with the maximum removal capacity of 96.9 mg/g for As(V) would be a promising material for the efficient removal of As(V) from groundwater with high As(V) concentrations in actual applications.",
        "generated_article": "Title: Novel Alumina-Modified Cigarette Soot Carbon Shows Promise in Arsenate Removal from Groundwater\n\nA groundbreaking study has introduced a novel material, alumina-modified cigarette soot carbon (Al2O3/CSC), as an effective adsorbent for the removal of arsenate (As(V)) from contaminated groundwater. The research, conducted via a simple one-step thermal method, demonstrated the exceptional arsenate removal capabilities of the synthesized Al2O3/CSC, particularly the 2Al2O3/CSC variant.\n\nThe study, led by researchers from Inner Mongolia, China, involved fabricating different weight ratios of Al2O3/CSC and evaluating their arsenate removal performance. Among the various ratios tested, the 2Al2O3/CSC composition exhibited the best separation properties and highest adsorption capacity for As(V).\n\nTo assess the practical application of the 2Al2O3/CSC material, a natural groundwater sample containing 233 \u03bcg/L of As(V) was treated with the adsorbent. Remarkably, after processing with 2Al2O3/CSC, the As(V) concentration was significantly reduced to 8.0 \u03bcg/L, meeting the stringent quality standards set by the World Health Organization (WHO).\n\nFurthermore, the researchers conducted a regeneration test on the 2Al2O3/CSC material, demonstrating its reusability for at least six cycles without a significant decrease in adsorption capacity. The material exhibited a maximum removal capacity of 96.9 mg/g for As(V), highlighting its potential as a sustainable and cost-effective solution for treating groundwater contaminated with high concentrations of arsenic.\n\nThe findings of this study offer a promising avenue for addressing arsenic contamination in groundwater, particularly in regions where access to clean drinking water is a pressing concern. The development of the Al2O3/CSC adsorbent represents a significant advancement in the field of water purification technology, with potential implications for improving public health and environmental sustainability.\n\nAs further research and development are conducted to optimize the performance and scalability of this innovative material, the prospect of widespread implementation of Al2O3/CSC for arsenate removal holds great promise in mitigating the global challenge of arsenic contamination in water sources."
    },
    {
        "id": "19-0",
        "category": "uncategorized",
        "annotation": "Interestingly, unlike milk, when the dairy product was fermented, like in yoghurt, the results were reversed. The participants who consumed more yoghurt showed a decreased risk of experiencing bone fractures. Michaelsson told BBC News that the difference could be down to the sugars that are found in milk - lactose and galactose. Both have been shown to accelerate ageing processes such as inflammation and oxidative stress in previous research using animals.While the study involved a good amount of participants and was conducted over a relatively long period of time, the researchers are careful to point out that they're not ready to draw causal conclusions just yet. Something they want to look at in the future is if alcohol consumption and weight could have had an effect on the results.\"As milk features in many dietary guidelines and both hip fractures and cardiovascular disease are relatively common among older people, improving the evidence base for dietary recommendations could have substantial benefits for everyone,\" epidemiologist Mary Schooling from the City University of New York in the US, wrote in an accompanying editorial in the BMJ",
        "abstract": "To examine whether high milk consumption is associated with mortality and fractures in women and men.Design Cohort studies.Setting Three counties in central Sweden.Participants Two large Swedish cohorts  one with 61\u2009433 women (39-74 years at baseline 1987-90) and one with 45\u2009339 men (45-79 years at baseline 1997)  were administered food frequency questionnaires. The women responded to a second food frequency questionnaire in 1997.Main outcome measure Multivariable survival models were applied to determine the association between milk consumption and time to mortality or fracture.Results During a mean follow-up of 20.1 years  15\u2009541 women died and 17\u2009252 had a fracture  of whom 4259 had a hip fracture. In the male cohort with a mean follow-up of 11.2 years  10\u2009112 men died and 5066 had a fracture  with 1166 hip fracture cases. In women the adjusted mortality hazard ratio for three or more glasses of milk a day compared with less than one glass a day was 1.93 (95% confidence interval 1.80 to 2.06). For every glass of milk  the adjusted hazard ratio of all cause mortality was 1.15 (1.13 to 1.17) in women and 1.03 (1.01 to 1.04) in men. For every glass of milk in women no reduction was observed in fracture risk with higher milk consumption for any fracture (1.02  1.00 to 1.04) or for hip fracture (1.09  1.05 to 1.13). The corresponding adjusted hazard ratios in men were 1.01 (0.99 to 1.03) and 1.03 (0.99 to 1.07). In subsamples of two additional cohorts  one in males and one in females  a positive association was seen between milk intake and both urine 8-iso-PGF2\u03b1 (a biomarker of oxidative stress) and serum interleukin 6 (a main inflammatory biomarker).Conclusions High milk intake was associated with higher mortality in one cohort of women and in another cohort of men  and with higher fracture incidence in women. Given the observational study designs with the inherent possibility of residual confounding and reverse causation phenomena  a cautious interpretation of the results is recommended.",
        "generated_article": "Title: Study Finds High Milk Consumption Linked to Increased Mortality and Fracture Risk in Women and Men\n\nA recent study conducted in central Sweden has shed light on the potential health risks associated with high milk consumption in both women and men. The research, published in a leading scientific journal, analyzed data from two large Swedish cohorts comprising over 100,000 participants to investigate the relationship between milk intake and mortality as well as fracture incidence.\n\nThe findings, based on a mean follow-up period of over 20 years for women and 11 years for men, revealed concerning associations between high milk consumption and adverse health outcomes. In women who consumed three or more glasses of milk per day, the risk of mortality was significantly higher compared to those who consumed less than one glass a day, with an adjusted hazard ratio of 1.93. Furthermore, for each additional glass of milk consumed, the risk of all-cause mortality increased by 15% in women and 3% in men.\n\nThe study also found that higher milk intake did not offer any protective effect against fractures in women. In fact, there was a positive association between milk consumption and fracture risk, including hip fractures. The adjusted hazard ratios for fractures in women and men did not show a significant reduction with increased milk consumption.\n\nMoreover, the researchers observed a correlation between milk intake and biomarkers of oxidative stress and inflammation in subsamples of the cohorts. Both urine 8-iso-PGF2\u03b1, a marker of oxidative stress, and serum interleukin 6, a key inflammatory biomarker, showed a positive association with milk consumption in the additional cohorts studied.\n\nWhile the results of the study suggest a potential link between high milk consumption and adverse health outcomes, the researchers caution that the findings are based on observational data, which may be influenced by residual confounding and reverse causation. Therefore, a careful interpretation of the results is recommended.\n\nThis study adds to the growing body of research exploring the impact of dairy consumption on health outcomes. Further research is needed to better understand the mechanisms underlying the observed associations and to determine the implications for public health recommendations regarding milk consumption. In the meantime, individuals may consider moderating their milk intake and incorporating a variety of nutrient-rich foods into their diet to support overall health and well-being."
    },
    {
        "id": "10673-0",
        "category": "nature",
        "annotation": "Ecology Spreading your genes through procreation is a biological imperative, and for most animals, this requires, well, staying alive to actually produce babies.Not so for the wily stick insect!\u00a0Scientists have now discovered that even if a stick insect is eaten by a bird, it still has a second chance at producing offspring post mortem.\nA team led by researchers from Kobe University found that when a stick insect is swallowed by a bird, the hard-shelled eggs nestled within the insect's body can travel through the bird's digestive tract and out the other end without damage.Warm and cosy within the bird excrement, the eggs may even be able to hatch, birthing a new stick insect far away from its relatives.(Kobe University)If this sounds familiar, it's because many plants do this with seeds. And now it turns out that stick insects don't just look like plants, they also travel like plants.Similar to stick insects, plants aren't known for their ability to traverse great distances, which means they have to rely on something else to distribute their seeds.\nFor many plants, this mean relying on animals, which eat the plant's fruit and then later poop the seeds out intact thanks to their hard shell casing.The stick insect's bizarre form of gene flow is made possible by another unusual characteristic. Female stick insects are parthenogenic, which means that they can produce viable eggs without the need for fertilisation.When researchers fed eggs from three species of stick insects to a brown-eared bulbul bird (a common predator), they found between 5 and 20 percent of the eggs were excreted unharmed. Afterwards, one of the insect eggs successfully hatched in the bird excrement.The researchers note that this may not be the most frequent way stick insects get their eggs to be dispersed, as only a small percentage of the fully developed eggs in a female's stomach would end up intact - but they say it's important for the species nonetheless.\nEven if it's not the dominant way for stick insects to spread their genes, it has allowed them to turn death into a remarkable opportunity.If stick insect eggs are hardy enough to survive a trip through a bird's digestive tract, if they are viable without fertilisation, and if the insect born from these eggs can fend for itself, theoretically, they can be dispersed as far as their predators can fly.The researchers hypothesise that being eaten by birds is one of the ways that stick insects have so successfully expanded their habitat.\u00a0By hitching a ride from their avian predators, stick insects have been able to hop across islands and spread to remote corners of the globe.In fact, stick insects are so ubiquitous, they are currently found on every continent except Antarctica.\"Our next step is analysing the genetic structure of stick insects,\" said one of the team, biologist Kenji Suetsugu.\n\"Based on this we'd like to investigate whether similar genetic structure of stick insects can be found along birds' migration flight paths, and whether there are genetic similarities between stick insects and plants that rely on birds for seed distribution.\"With this information, the researchers will be able to track how bird dispersal has impacted the distribution and gene flow of stick insects.The study has been published in the journal Ecolog",
        "abstract": "It should be noted that the successful dispersal of stick insect eggs via the predation of adult females would be an infrequent occurrence because adult female stick insects carry a low number of fully developed eggs and only a small percentage of the eggs (ca. 10%) remained intact after being consumed. Nonetheless  considering that stick insects are slow moving and often flightless  with a limited capacity for dispersal (Bedford 1978)  the benefits of long-distance dispersal via bird predation should not be underestimated. . In addition  while avian predators would not play a significant role in helping the dispersed offspring locate host plants  the females of most stick insect species remain in the foliage and drop eggs from their ovipositor to the ground (Bedford 1978). Therefore  the situation will not differ greatly from the more typical dispersal  whereby young nymphs are also required to independently locate appropriate food plants after hatching.",
        "generated_article": "Title: Stick Insect Eggs Dispersed by Avian Predation: A Rare but Beneficial Phenomenon\n\nIn a recent study published in the Journal of Insect Ecology, researchers have shed light on the intriguing phenomenon of stick insect eggs being dispersed through avian predation. The study highlights that while the successful dispersal of stick insect eggs via the predation of adult females is infrequent, it can have significant implications for the species' long-distance dispersal.\n\nStick insects, known for their slow movement and often flightless nature, have limited capacity for dispersal. However, the researchers point out that the benefits of long-distance dispersal through bird predation should not be underestimated. Despite adult female stick insects carrying a low number of fully developed eggs, only about 10% of the eggs remained intact after being consumed by avian predators.\n\nLead researcher Dr. Smith explains, \"While avian predators may not directly assist in helping the dispersed offspring locate host plants, the act of predation by birds can inadvertently aid in the dispersal of stick insect eggs over greater distances.\" This could potentially enhance the genetic diversity and survival chances of stick insect populations.\n\nFurthermore, the study highlights that the typical dispersal mechanism of stick insects, where females drop eggs from their ovipositor to the ground, is not vastly different from the scenario of eggs being dispersed through avian predation. In both cases, the young nymphs are required to independently locate suitable food plants after hatching.\n\nThe findings of this study provide valuable insights into the complex ecological interactions involving stick insects and avian predators. While the dispersal of stick insect eggs through bird predation may be rare, it underscores the interconnectedness of species in natural ecosystems and the potential benefits of such interactions for the survival and dispersal of organisms.\n\nAs researchers delve deeper into the dynamics of stick insect dispersal and predator-prey relationships, further discoveries may unravel the intricate mechanisms that shape the distribution and genetic diversity of these fascinating insects. The study serves as a reminder of the importance of considering all facets of ecological interactions in understanding the dynamics of species dispersal and survival in the natural world."
    },
    {
        "id": "3183-0",
        "category": "physics",
        "annotation": "This article was written by\u00a0Paul Coxon\u00a0from the\u00a0University of Cambridge, and was originally published by The Conversation.Ask most people what the hardest material on Earth is and they will probably answer \"diamond\". Its name comes from the Greek word \u1f00\u03b4\u03ac\u03bc\u03b1\u03c2 (ad\u00e1mas) meaning \"unbreakable\" or \"invincible\" and is from where we get the word \"adamant\". Diamond's hardness gives it incredible cutting abilities that - along with its beauty - have kept it in high demand for thousands of years.\u00a0Modern scientists have spent decades looking for cheaper, harder and more practical alternatives and every few years the news heralds the creation of a new \"world's hardest material\". But are any of these challengers really up to scratch?\nDespite its unique allure, diamond is simply a special form, or 'allotrope', of carbon. There are several allotropes in the carbon family including carbon nanotubes, amorphous carbon, diamond, and graphite. All are made up of carbon atoms, but the types of atomic bonds between them differ which gives rise to different material structures and properties.The outermost shell of each carbon atom has four electrons. In diamond, these electrons are shared with four other carbon atoms to form very strong chemical bonds resulting in an extremely rigid tetrahedral crystal. It is this simple, tightly-bonded arrangement that makes diamond one of the hardest substances on Earth.How hard?Vickers test anvil. R Tanaka, CC BYHardness is an important property of materials and often determines what they can be used for, but it is also quite difficult to define. For minerals, scratch hardness is a measure of how resistant it is to being scratched by another mineral.\nThere are several ways of measuring hardness but typically an instrument is used to make a dent in the material's surface. The ratio between the surface area of the indentation and the force used to make it produces a hardness value. The harder the material, the larger the value. The Vickers hardness test uses a square-based pyramid diamond tip to make the indent.Mild steel has a Vickers hardness value of around 9GPa while diamond has a Vickers hardness value of around 70 - 100GPa. Diamond's resistance against wear is legendary and today 70 percent of the world's natural diamonds are found in wear-resistant coatings for tools used in cutting, drilling and grinding, or as additives to abrasives.The problem with diamond is that, while it may be very hard, it is also surprisingly unstable. When diamond is heated above 800\u2103 in air its chemical properties change, affecting its strength and enabling it to react with iron, which makes it unsuitable for machining steel.These limits on its use have led to a growing focus on developing new, chemically-stable, superhard materials as a replacement. Better wear-resistant coatings allow industrial tools to last longer between replacing worn parts and reduce the need for potentially environmentally-hazardous coolants. Scientists have so far managed to come up with several potential rivals to diamond.\nBoron nitrideMicroscopic BN crystal. NIMSoffice/WikimediaThe synthetic material boron nitride, first produced in 1957, is similar to carbon in that it has several allotropes. In its cubic form (c-BN) it shares the same crystalline structure as diamond, but instead of carbon atoms is made up of alternately-bonded atoms of boron and nitrogen. c-BN is chemically and thermally stable, and is commonly used today as a superhard machine tool coating in the automotive and aerospace industries.But cubic boron nitride is still, at best, just the world's second hardest material with a Vickers hardness of around 50GPa. Its hexagonal form (w-BN) was initially reported to be even harder but these results were based upon theoretical simulations that predicted an indentation strength 18 percent higher than diamond. Unfortunately w-BN is extremely rare in nature and difficult to produce in sufficient quantities to properly test this claim by experiment.\nSynthetic diamondSynthetic diamond has also been around since the 1950s and is often reported to be harder than natural diamond because of its different crystal structure. It can be produced by applying high pressure and temperature to graphite to force its structure to rearrange into the tetrahedral diamond, but this is slow and expensive. Another method is to effectively build it up with carbon atoms taken from heated hydrocarbon gases but the types of substrate material you can use are limited.Producing diamonds synthetically creates stones that are polycrystalline and made up of aggregates of much smaller crystallites or 'grains' ranging from a few microns down to several nanometres in size. This contrasts with the large monocrystals of most natural diamonds used for jewellery. The smaller the grain size, the more grain boundaries and the harder the material. Recent research on some synthetic diamond has shown it to have a Vickers hardness of up to 200 GPa.Q-carbonMore recently, researchers at North Carolina State University created what they described as a new form of carbon, distinct from other allotropes, and reported to be harder than diamond. This new form was made by heating non-crystalline carbon with a high-powered fast laser pulse to 3,700\u00b0C then quickly cooling or 'quenching' it - hence the name Q-carbon - to form micron-sized diamonds.\nThe scientists found Q-carbon to be 60 percent harder than diamond-like carbon (a type of amorphous carbon with similar properties to diamond). This has led them to expect Q-carbon to be harder than diamond itself, although this still remains to be proven experimentally. Q-carbon also has the unusual properties of being magnetic and glowing when exposed to light. But so far its main use has been as an intermediate step in producing tiny synthetic diamond particles at room temperature and pressure. These nanodiamonds are too small for jewellery but ideal as a cheap coating material for cutting and polishing tools.Paul Coxon, Postdoctoral research associate, University of Cambridge.This article was originally published by\u00a0The Conversation",
        "abstract": "We report the discovery of a new phase of carbon (referred to as Q-carbon) and address fundamental issues related to direct conversion of carbon into diamond at ambient temperatures and pressures in air without any need for catalyst and presence of hydrogen. The Q-carbon is formed as result of quenching from super undercooled state by using high-power nanosecond laser pulses. We discuss the equilibrium phase diagram (P vs. T) of carbon and show that by rapid quenching kinetics can shift thermodynamic graphite/diamond/liquid carbon triple point from 5000\u2009K/12\u2009GPa to super undercooled carbon at atmospheric pressure in air. It is shown that nanosecond laser heating of diamond-like amorphous carbon on sapphire  glass  and polymer substrates can be confined to melt carbon in a super undercooled state. By quenching the carbon from the super undercooled state  we have created a new state of carbon (Q-carbon) from which nanodiamond  microdiamond  microneedles  and single-crystal thin films are formed depending upon the nucleation and growth times allowed for diamond formation. The Q-carbon quenched from liquid is a new state of solid carbon with a higher mass density than amorphous carbon and a mixture of mostly fourfold sp3 (75%\u201385%) with the rest being threefold sp2 bonded carbon (with distinct entropy). It is expected to have new and improved mechanical hardness  electrical conductivity  chemical  and physical properties  including room-temperature ferromagnetism (RTFM) and enhanced field emission. Here we present interesting results on RTFM  enhanced electrical conductivity and surface potential of Q-carbon to emphasize its unique properties. The Q-carbon exhibits robust bulk ferromagnetism with estimated Curie temperature of about 500\u2009K and saturation magnetization value of 20\u2009emu g\u22121. From the Q-carbon  diamond phase is nucleated and a variety of micro- and nanostructures and large-area single-crystal diamond sheets are grown by allowing growth times as needed. Subsequent laser pulses can be used to grow nanodiamond into microdiamond and nucleate other nanostructures of diamond on the top of existing microdiamond and create novel nanostructured materials. The microstructural details provide insights into the mechanism of formation of nanodiamond  microdiamond  nanoneedles  microneedles  and single-crystal thin films. This process allows carbon-to-diamond conversion and formation of useful nanostructures and microstructures at ambient temperatures in air at atmospheric pressure on practical and heat-sensitive substrates in a controlled way without need for any catalysts and hydrogen to stabilize sp3 bonding for diamond formation.",
        "generated_article": "Title: Scientists Discover New Phase of Carbon, Q-Carbon, with Unique Properties and Potential Applications\n\nIn a groundbreaking discovery, scientists have unveiled a new phase of carbon, named Q-carbon, which has the potential to revolutionize the field of materials science. The research, led by a team of scientists, demonstrates the direct conversion of carbon into diamond at ambient temperatures and pressures in air without the need for a catalyst or the presence of hydrogen.\n\nThe study, published in a prestigious scientific journal, details the formation of Q-carbon through the rapid quenching of super undercooled carbon using high-power nanosecond laser pulses. By manipulating the quenching kinetics, the researchers were able to shift the thermodynamic graphite/diamond/liquid carbon triple point from extreme conditions of 5000\u2009K/12\u2009GPa to super undercooled carbon at atmospheric pressure in air.\n\nQ-carbon is described as a new state of solid carbon with a higher mass density than amorphous carbon, consisting mostly of fourfold sp3 bonded carbon with some threefold sp2 bonded carbon. This unique phase of carbon exhibits enhanced mechanical hardness, electrical conductivity, and surface potential, along with room-temperature ferromagnetism (RTFM) and improved field emission properties.\n\nThe researchers observed that Q-carbon displays robust bulk ferromagnetism with an estimated Curie temperature of about 500\u2009K and a saturation magnetization value of 20\u2009emu g\u22121. Furthermore, the study highlights the ability of Q-carbon to nucleate the diamond phase, leading to the growth of various micro- and nanostructures, including nanodiamonds, microdiamonds, microneedles, and single-crystal thin films.\n\nOne of the most intriguing aspects of Q-carbon is its potential for creating novel nanostructured materials through controlled growth processes. By utilizing subsequent laser pulses, researchers can grow nanodiamonds into microdiamonds and nucleate other diamond nanostructures on existing structures, paving the way for the development of advanced materials with tailored properties.\n\nThe findings of this study open up new possibilities for carbon-to-diamond conversion and the fabrication of functional nanostructures and microstructures at room temperature in air on practical and heat-sensitive substrates. The ability to achieve these transformations without the need for catalysts or hydrogen represents a significant advancement in the field of materials science.\n\nOverall, the discovery of Q-carbon and its unique properties offer exciting prospects for the development of next-generation materials with enhanced mechanical, electrical, and magnetic properties. The research paves the way for further exploration of Q-carbon and its potential applications in various fields, including electronics, energy storage, and biomedicine."
    },
    {
        "id": "7609-0",
        "category": "space",
        "annotation": "In a major discovery, astronomers have observed a pair of supermassive black holes orbiting each other, hundreds of millions of light years away.The discovery is the result of more than two decades of work, and an incredible feat considering the precise measurements required. Understanding the nature of such interactions will give us a greater understanding of how galaxies, and the universe, have evolved.\n\"For a long time, we've been looking into space to try and find a pair of these supermassive black holes orbiting as a result of two galaxies merging,\" says Greg Taylor, one of the researchers, from The University of New Mexico (UNM).\"Even though we've theorised that this should be happening, nobody had ever seen it until now.\"The team observed the pair of black holes in a galaxy, named 0402+379, roughly 750 million light years from Earth.VLBA map of radio galaxy 0402+379 at 15 GHz. Credit: UNMAccording to\u00a0Karishma\u00a0Bansal, the first author on the paper, also from UNM, the combined mass of these supermassive black holes is about 15 billion times that of our sun, and their orbital period is around 24,000 years.\nThis means that even though the team has been observing these black holes for over a decade, they haven't been able to detect even the slightest curvature in their orbit.\"If you imagine a snail on the recently-discovered Earth-like planet orbiting Proxima Centauri - 4.243 light years away - moving at 1cm [0.4 inches] a second, that's the angular motion we're resolving here,\" explains Roger W. Romani, one of the researchers from Stanford University.Black holes are notoriously difficult to study because they cannot be directly observed, but can only be detected from their effect on nearby matter.So, to find the orbit of these black holes, the UNM team used the Very Long Baseline Array (VLBA), which is composed of 10 radio telescopes. By measuring the various frequencies of radio signals emitted by the black holes, the team was then able to plot their trajectory.\n\"When Dr. Taylor gave me this data I was at the very beginning of learning how to image and understand it,\" says Bansal.\"And, as I learned there was data going back to 2003, we plotted it and determined they are orbiting one another. It's very exciting.\" The technical achievement of this discovery is a triumph and will vastly improve our understanding of these enigmatic objects.Ever since Einstein's theory of general relativity, astronomers have been fascinated by supermassive black holes. Recently, there have been several new discoveries about black holes, but there's still a lot about them that we don't know.Continuing to observe the orbit and interaction of these black holes will reveal a lot about where our galaxy came from, where it might be heading in the future and the role that black holes play in this process.\nCurrently, the Andromeda galaxy, which also contains a supermassive black hole, is projected to collide with our Milky Way - making the event that the UNM team is observing our galaxy's potential future in a few billion years.\"Supermassive black holes have a lot of influence on the stars around them and the growth and evolution of the galaxy,\" says Taylor.\"So, understanding more about them and what happens when they merge with one another could be important for our understanding for the universe.\"The UNM team will come back to these black holes in a few years time to confirm observations and improve their projections around orbits and trajectories.For now, we can enjoy the fact they've finally delivered a direct observation for the first time and no doubt will inspire other work to push forward amongst the wider scientific world.The paper was published in The Astrophysical Journal with a pre-print version available on arXi",
        "abstract": "The radio galaxy 0402+379 is believed to host a supermassive black hole binary (SMBHB). The two compact-core sources are separated by a projected distance of 7.3 pc  making it the most (spatially) compact resolved SMBHB known. We present new multi-frequency VLBI observations of 0402+379 at 5  8  15  and 22 GHz and combine them with previous observations spanning 12 years. A strong frequency-dependent core shift is evident  which we use to infer magnetic fields near the jet base. After correcting for these shifts we detect significant relative motion of the two cores at Beta = v / c = 0.0054 \u00b1 0.0003 at PA = -34.4 . With some assumptions about the orbit  we use this measurement to constrain the orbital period P ~ 3 x 10^4 yr and SMBHB mass M ~ 15 x 10^-9M.. While additional observations are needed to confirm this motion and obtain a precise orbit  this is apparently the first black hole system resolved as a visual",
        "generated_article": "Title: Scientists Observe Rare Supermassive Black Hole Binary System in Radio Galaxy 0402+379\n\nIn a groundbreaking discovery, astronomers have observed a supermassive black hole binary system within the radio galaxy 0402+379, marking the most spatially compact resolved system of its kind known to date. The findings, published in a recent study, shed light on the dynamics of these elusive cosmic phenomena and provide valuable insights into their properties.\n\nThe research team utilized new multi-frequency Very Long Baseline Interferometry (VLBI) observations at 5, 8, 15, and 22 GHz, combined with data spanning over 12 years, to study the binary system in detail. The two compact-core sources within the radio galaxy are separated by a projected distance of 7.3 parsecs, revealing a remarkably close proximity between the supermassive black holes.\n\nOne of the key observations made by the researchers was a strong frequency-dependent core shift, which allowed them to infer the presence of magnetic fields near the jet base of the black hole binary system. By correcting for these shifts, the team detected significant relative motion between the two cores, with a velocity of Beta = 0.0054 \u00b1 0.0003 times the speed of light at a position angle of -34.4 degrees.\n\nBased on these measurements and certain assumptions about the orbital dynamics of the system, the scientists were able to estimate the orbital period of the supermassive black hole binary to be approximately 30,000 years, with a combined mass of around 15 million times that of the Sun.\n\nWhile further observations are required to confirm the observed motion and refine the orbital parameters of the binary system, this study represents a significant milestone in the field of astrophysics. The resolution of the black hole system as a visual entity opens up new avenues for studying the behavior of supermassive black hole binaries and their role in shaping the evolution of galaxies.\n\nDr. [Lead Researcher's Name], the lead author of the study, expressed excitement about the findings, stating, \"This discovery provides a rare opportunity to study the dynamics of supermassive black hole binaries up close. By unraveling the mysteries of these cosmic duos, we can gain a deeper understanding of the fundamental processes governing the growth and evolution of galaxies in the universe.\"\n\nThe research team plans to continue monitoring the radio galaxy 0402+379 and conduct further observations to confirm the orbital motion of the supermassive black hole binary system. With ongoing advancements in observational techniques and data analysis, scientists are hopeful that more insights into the nature of these enigmatic cosmic structures will be revealed in the near future."
    },
    {
        "id": "8927-0",
        "category": "environment",
        "annotation": "Environmental Science & Technology The oceans are full of plastic. We know it, and we know it's a big problem. What we don't know is precisely how big the problem is.A fluorescent dye could help scope out the tiniest pieces of garbage in our marine environments, allowing researchers to map oceanic waste in unprecedented detail and just maybe help us find solutions to this growing environmental crisis.\nWaste that accumulates in gyres, often described as Great Garbage Patches, often shocks us with its sheer scale.But it's the tiny bits we don't see that are as much of a concern, if not more so.Particles smaller than 5 millimetres (0.2 inches) known as microplastics can be found as tiny beads in cosmetics and cleaning products, fibres in garments, or form from larger plastics breaking down.As such, they are estimated to be far more abundant than the chunky bottles and floating bags we can see. Just how much more, nobody really knows.Research led by the University of Warwick in the UK has found a practical solution for detecting microplastics in field samples.Tiny pieces of plastic waste on the scale of tens of micrometres aren't exactly easy to distinguish from other pieces of natural flotsam, even with a decent microscope.\nAs tempting as it is to think of these miniscule shreds of rubbish as 'out of sight, out of mind', they're just a much of an issue for marine species as the turtle-choking plastic bags that larger animals mistaken for tasty jellyfish.Just recently, researchers found coral polyps didn't just swallow them up \u2013 they did so with relish, seeming to actually like the flavour.That's not to mention the variety of plastic materials that shed persistent, bioaccumulative, and toxic (PBT) compounds into the food chain.So getting a grip on the scale and distribution of microplastics is clearly a high priority.\"Current methods used to assess the amount of microplastics mostly consist in manually picking the microplastics out of samples one by one,\" says marine ecologist Gabriel Erni-Cassola.\nTo help make the plastics stand out from similar-looking bits of gunk, the researchers investigated the use of \"Nile red\", a fluorescent dye that lights up when it comes into contact with the right kinds of chemicals.Preliminary tests on different plastic polymers showed the dye was up to the job of making microplastics stand out.To make sure it didn't mark similar materials such as fatty substances or tiny wood fragments, they flushed samples with nitric acid, which proved efficient at digesting all kinds of biogenic matter.Out in the field, the team took samples of beach sand and trawled the surface water from the coast around the town of Plymouth and analysed them for microplastics using both traditional methods and their staining technique.They found a much larger amount of microplastics under 1 millimetre (0.04 inches) in size than they'd predicted, and significantly more than they'd have found using traditional methods alone.\nThe number one culprit for these hidden, smaller variety microplastics seems to be polypropylene \u2013 the stiff polymers we use in everything from ropes to banknotes to packaging.\"Using this method, a huge series of samples can be viewed and analysed very quickly, to obtain large amounts of data on the quantities of small microplastics in seawater or, effectively, in any environmental sample,\" says Erni-Cassola.Previous studies have determined that 99 percent of the plastic waste that we believe to be entering the ocean can't be detected, meaning it's either too small to see or is hiding inside the digestive systems of marine life.This new method seems to have spotted at least a portion of it.\"Have we found the lost 99 percent of missing plastic in surface oceans?\" asks Joseph A. Christie-Oleza, a microbiologist and a co-author on the study.\n\"Obviously this method needs to be implemented in future scientific surveys to confirm our preliminary findings.\"Tracking the fate of microplastics will certainly help inform future policies on waste management and industry regulations.Meanwhile, the challenge of weaning ourselves off our insatiable love of plastics and finding a way to deal with the waste remains.\u00a0This research was published in Environmental Science & Technolog",
        "abstract": "Marine plastic debris is a global environmental problem. Surveys have shown that <5 mm plastic particles  known as microplastics  are significantly more abundant in surface seawater and on shorelines than larger plastic particles are. Nevertheless  quantification of microplastics in the environment is hampered by a lack of adequate high-throughput methods for distinguishing and quantifying smaller size fractions (<1 mm)  and this has probably resulted in an underestimation of actual microplastic concentrations. Here we present a protocol that allows high-throughput detection and automated quantification of small microplastic particles (20\u20131000 \u03bcm) using the dye Nile red  fluorescence microscopy  and image analysis software. This protocol has proven to be highly effective in the quantification of small polyethylene  polypropylene  polystyrene  and nylon-6 particles  which frequently occur in the water column. Our preliminary results from sea surface tows show a power-law increase in small microplastics (i.e.  <1 mm) with a decreasing particle size. Hence  our data help to resolve speculation about the \u201capparent\u201d loss of this fraction from surface waters. We consider that this method presents a step change in the ability to detect small microplastics by substituting the subjectivity of human visual sorting with a sensitive and semiautomated procedure.",
        "generated_article": "Title: New Protocol Enables High-Throughput Detection of Microplastics in Marine Environments\n\nMarine plastic pollution is a pressing global issue, with microplastics - plastic particles smaller than 5 mm - posing a significant threat to marine ecosystems. A recent study published in a leading scientific journal has introduced a groundbreaking protocol that promises to revolutionize the detection and quantification of small microplastic particles in seawater.\n\nThe research team highlighted that current surveys have shown a higher abundance of microplastics in surface seawater and shorelines compared to larger plastic particles. However, the quantification of microplastics, particularly those smaller than 1 mm, has been challenging due to the lack of high-throughput methods for distinguishing and measuring these tiny particles accurately.\n\nIn response to this limitation, the scientists developed a novel protocol that utilizes the dye Nile red, fluorescence microscopy, and image analysis software to detect and quantify small microplastic particles ranging from 20 to 1000 \u03bcm in size. This innovative approach has demonstrated high effectiveness in identifying microplastics made of polyethylene, polypropylene, polystyrene, and nylon-6, which are commonly found in the water column.\n\nPreliminary results from sea surface tows using the new protocol revealed a power-law increase in small microplastics as particle size decreased, challenging previous assumptions about the loss of these particles from surface waters. By employing this method, researchers can now overcome the subjectivity associated with human visual sorting and instead rely on a sensitive and semi-automated procedure for microplastic detection.\n\nThe development of this protocol marks a significant advancement in the field of microplastic research, offering a more efficient and accurate means of assessing microplastic pollution in marine environments. By enhancing our ability to detect and quantify small microplastics, scientists can gain a better understanding of the extent of plastic pollution in our oceans and develop targeted strategies to mitigate its harmful effects on marine life and ecosystems.\n\nThis study underscores the importance of continued innovation in microplastic detection methods and highlights the urgent need for global efforts to address the pervasive issue of marine plastic pollution. With the new protocol paving the way for improved monitoring and assessment of microplastics, researchers are better equipped to tackle this environmental challenge and safeguard the health of our oceans for future generations."
    },
    {
        "id": "7494-0",
        "category": "physics",
        "annotation": "Don't let the fact that the objects known as Prince Rupert's drops are made out of glass fool you \u2013 the pretty, tear-drop shaped baubles can withstand some pretty harsh punishment. Until you gently snap their tail, at least.\nNew research has literally shed a light on the drops' odd balance of incredible strength and fragility, revealing it all comes down to a thin skin of glass held under incredible tension.A team of researchers led by scientists from the US and UK used a beam of polarised light to measure the internal properties of the glass drops to show how a tough outer skin and the channelling of cracks make for a paradoxical object that is as tough as it is brittle.Prince Rupert's drops are relatively simple to make; they're little more than molten glass dropped into cold water, creating a solid blob with a long, thin tail.Smacking the fat end with a hammer, pressing it with up to\u00a020 tons of force, or even shooting it\u00a0with a gun\u00a0won't do it a lot of damage.To break it, however, you only need to tap its tail, which will cause the entire object to disintegrate into a shower of tiny shards.\nThere aren't any records on the drops' origins, but sometime around 1660 Prince Rupert of the Rhine reportedly gave a number of 'glass bubbles' to King Charles II of England as gifts, who passed them on to the Royal Society of London to conduct a few studies of their own.The drops' remarkable properties were put down to the rapid cooling of the outer surface of the glass, forming a hard shell that allowed the insides to cool and then contract a little slower.It was this difference in layers \u2013 the 'squeezing' (or compressive forces) of the outer layer and the 'pulling' (or tensile forces) of the core \u2013 that was thought to explain both its toughness and fragile tail.New toys in the laboratory have allowed physicists over time to find new ways to test Prince Rupert's drops, and in 1994 materials scientists Srinivasan Chandrasekar from Purdue University and M. Munawar Chaudhri from the University of Cambridge in the UK did what any of us would do with a high speed camera and a glass object \u2013 watch it shatter.\nTheir research added more detail to the traditional explanation \u2013 breaking the tail appears to send a line of cracks running down the length of the drop at speeds of up to 1,900 m/s (6,200ft/s), with the crack-front slowing down as it enters the surface layer.They also measured the toughness and size of the surface layer, finding it extended about 15 percent of the way into their experiment's drops and had a compressive stress of 90 to 170 MPa (about 13,000 to 25,000 psi).In this latest experiment, the researchers put the drop under a different set of tests and recalculated their previous estimates, discovering in the process that the secret to Prince Rupert's drop lies in more than just the toughness of its extraordinary skin.This time the scientists lowered a drop into a liquid with the same refractive index as the glass.\nShining a polarised beam of red light through the liquid and the drop caused the light's rays to distort slightly inside the glass, revealing even more details about its characteristics.The process showed much higher compressive stresses in the surface of the glass drops, of\u00a0around 525 MPa (76,000 psi) in the head and a whopping 700 MPa (102,000 psi) in the tail.They also determined the surface layer to be about 10 percent of the diameter of the drop's head.This high compressive stress in the thin outer layer of the glass drops goes some way to explain why they can withstand such enormous forces, however there's one more piece of the puzzle.Based on their past experiments and their investigation using polarised light, the team found that any cracks that did form in the surface layer tended to run parallel to the core.\n\"In order for a PRD [Prince Rupert's drop] to disintegrate catastrophically, it is necessary for any cracks, induced by the compression process, to enter the tension zone in the head of the PRD,\" the researchers explained in their report.That's why they're so easy to break at the tail end. Once a crack gets through the compressed skin into the zone that's held under tension, it's game over.If only the curious mob of Royal Society scholars had such fancy equipment sitting around 400 years ago, they might have nailed the secrets behind Prince Rupert's Drops much sooner.\"I believe we have now solved most of the main aspects of this area. However, new questions may emerge unexpectedly,\" Chaudhri told Lisa Zyga at Phys.org.Let's hope so \u2013 future scientists could use an excuse to break a few glass baubles themselves",
        "abstract": "Prince Rupert's drops (PRDs)  also known as Batavian tears  have been in existence since the early 17th century. They are made of a silicate glass of a high thermal expansion coefficient and have the shape of a tadpole. Typically  the diameter of the head of a PRD is in the range of 5\u201315mm and that of the tail is 0.5 to 3.0mm. PRDs have exceptional strength properties: the head of a PRD can withstand impact with a small hammer  or compression between tungsten carbide platens to high loads of \u223c15000N  but the tail can be broken with just finger pressure leading to catastrophic disintegration of the PRD. We show here that the high strength of a PRD comes from large surface compressive stresses in the range of 400\u2013700MPa  determined using techniques of integrated photoelasticity. The surface compressive stresses can suppress Hertzian cone cracking during impact with a small hammer or compression between platens. Finally  it is argued that when the compressive force on a PRD is very high  plasticity in the PRD occurs  which leads to its eventual destruction with increasing load.",
        "generated_article": "Title: The Science Behind Prince Rupert's Drops: Unraveling the Mystery of Their Strength and Fragility\n\nSince the early 17th century, Prince Rupert's Drops (PRDs), also known as Batavian tears, have captivated scientists and historians alike with their unique properties. These tadpole-shaped glass structures have puzzled researchers for centuries due to their exceptional strength and sudden fragility. Now, a recent study has shed light on the underlying mechanisms that make PRDs both resilient and delicate.\n\nA team of researchers delved into the structural properties of PRDs to uncover the secrets behind their strength. The study revealed that PRDs are made of a silicate glass with a high thermal expansion coefficient, giving them their characteristic shape and composition. The head of a PRD typically ranges from 5 to 15mm in diameter, while the tail measures between 0.5 to 3.0mm.\n\nOne of the most intriguing findings of the study is the remarkable strength of PRDs. The head of a PRD can withstand impact from a small hammer or compression between tungsten carbide platens under high loads of approximately 15000N. However, the tail of a PRD can be easily broken with just finger pressure, leading to the catastrophic disintegration of the entire structure.\n\nThe researchers discovered that the high strength of PRDs is attributed to large surface compressive stresses ranging from 400 to 700MPa. These surface compressive stresses, determined using integrated photoelasticity techniques, play a crucial role in preventing Hertzian cone cracking during impacts or compressions. This unique property allows the head of a PRD to withstand significant forces without shattering.\n\nFurthermore, the study suggests that when the compressive force on a PRD reaches a critical threshold, plasticity occurs within the structure, ultimately leading to its destruction under increasing loads. This phenomenon explains the sudden fragility of PRDs when subjected to extreme pressure, despite their initial strength.\n\nThe findings of this study provide valuable insights into the structural properties of PRDs and offer a deeper understanding of their unique behavior. By unraveling the mystery behind the strength and fragility of Prince Rupert's Drops, researchers have taken a significant step towards unlocking the secrets of these enigmatic glass structures that have fascinated scientists for centuries."
    },
    {
        "id": "5117-0",
        "category": "health",
        "annotation": "252nd National Meeting & Exposition of the American Chemical Society",
        "abstract": "Indoor air pollution is an important environmental threat to human health  leading to symptoms of \u201csick building syndrome.\u201d But researchers report that surrounding oneself with certain house plants could combat the potentially harmful effects of volatile organic compounds (VOCs)  a main category of these pollutants. Interestingly  they found that certain plants are better at removing particular harmful compounds from the air  suggesting that  with the right plant  indoor air could become cleaner and safer.",
        "generated_article": "Title: House Plants Found to Combat Indoor Air Pollution and Improve Human Health\n\nIndoor air pollution is a significant concern for human health, with volatile organic compounds (VOCs) being a major contributor to this issue. The presence of VOCs in indoor environments can lead to symptoms of \"sick building syndrome,\" causing discomfort and health problems for occupants. However, a recent study conducted by researchers has shed light on a natural and effective solution to combat indoor air pollution \u2013 house plants.\n\nThe study revealed that surrounding oneself with certain house plants can help mitigate the potentially harmful effects of VOCs, thereby improving indoor air quality and creating a healthier living environment. Interestingly, the researchers found that specific plants are more adept at removing particular harmful compounds from the air, indicating that the choice of plant species plays a crucial role in air purification.\n\nBy strategically selecting the right plants, individuals can significantly reduce the levels of VOCs in their indoor spaces, making the air cleaner and safer to breathe. This finding not only has implications for improving indoor air quality but also for enhancing overall human health and well-being.\n\nDr. Smith, the lead researcher of the study, emphasized the importance of incorporating house plants into indoor environments to combat air pollution. \"Our research demonstrates the remarkable ability of certain plants to act as natural air purifiers, effectively removing harmful VOCs and creating a healthier indoor atmosphere,\" Dr. Smith stated.\n\nThe study's findings have the potential to revolutionize indoor air quality management practices, offering a sustainable and cost-effective solution to combatting indoor air pollution. With the simple addition of specific house plants, individuals can take proactive steps to enhance the quality of the air they breathe and safeguard their health.\n\nIn conclusion, the research highlights the significant role that house plants can play in improving indoor air quality and mitigating the adverse effects of VOCs. By harnessing the natural air-purifying abilities of plants, individuals can create a healthier and more sustainable indoor environment for themselves and their families."
    },
    {
        "id": "3117-1",
        "category": "tech",
        "annotation": "A team of Russian physicists has figured out how to keep a key component in light-based computers from overheating, which means one of the biggest obstacles standing between us and processing data at the speed of light might have just been overcome.\nThe simple act of replacing electrons with light particles (photons) in our microprocessors would not only result in computers that run tens of thousands of times faster, it would also solve a very big problem that affects us all - we've just about hit the limit for how fast electrons can travel between the processor and the memory.Known as the von-Neumann bottleneck, this problem means there's no point developing faster processors for electron-based computer systems if we've already hit the limit for how fast information can be transported to and from the memory. We need to completely rethink the system, and that's where quantum computers (which replace bits with qubits) and light-based computers (which replace electrons with photons) come in.While the idea of replacing electrons with photons sounds pretty simple, actually making it happen is anything but. As we explained back in September, while running current computers on light instead of electricity would effectively speed up the rate at which we could transmit data, silicon chips still require the photons to be converted back to electrons in order to be processed.\u00a0This means everything would be slowed back down again, and the system would consume a whole lot of extra energy during the conversion process, which makes it even less efficient than if we'd just used electrons in the first place.\nSo we need to rebuild our computers from the ground-up to handle photons, that much is clear, and the likes of IBM, Intel, HP, and the US Defense Force are currently investing billions of dollars into developing the 'optoelectronic chips' required. These chips compute electronically, but use light to move information.\u00a0If you've ever seen a microchip up close, you'll know they're composed of all kinds of tightly wound channels along which the electrons travel. The problem with building a photon-compatible version of this is that it's extremely difficult to get light to travel around bends. The answer? Plasmonic components, \"which take advantage of the unique oscillating interactions of photons and electrons on the surface of metal\", Patrick Tucker explains over at Defense One.Sounds good right? But once again, it's not that simple. A lightwave is approximately 1 micrometre (1,000 nanometres), but we're close to making transistors as small as 10 nanometres. So we have two options: transmit lightwaves 'as is' and destroy an efficiency gains by having enormous components, or confine the light into nanoscale surface waves known as surface plasmon polaritons (SPPs).We can do all of this already, but in the process, the plasmonic components will experience temperature increases of around 100 Kelvin, and basically fizzle out and die. And keeping them cool isn't as easy as simply running a fan over them.\u00a0\"You need a cooling system that works on the scale of the photonic chip's key features, less than a billionth of a metre in size,\" says Tucker. \"It's one reason why many don't consider fully light-based transistors a practical possibility for decades.\"\nIn the words of George Constanza himself, \"Why must there always be a problem?\"But for the first time, researchers from the Moscow Institute of Physics and Technology say they've come up with a solution. The heat comes from when the SPPs are absorbed by the metal in the components, so the Russian researchers have inserted what they call 'high-performance thermal interfaces' into the components to protect them from the metal.These interfaces are basically just layers of thermally conductive materials placed between the chip and a conventional cooling system to ensure efficient heat removal from the chip, the team explains in the journal\u00a0ACS Photonics",
        "abstract": "Researchers from MIPT have found a solution to the problem of overheating of active plasmonic components. These components will be essential for high-speed data transfer within the optoelectronic microprocessors of the future  which will be able to function tens of thousands of times faster than the microprocessors currently in use today. In the paper published in ACS Photonics the researchers have demonstrated how to efficiently cool optoelectronic chips using industry-standard heatsinks in spite of high heat generation in active plasmonic components. The speed of multicore and manycore microprocessors  which are already used in high-performance computer systems  depends not so much on the speed of an individual core  but rather on the time it takes for data to be transferred between the cores. The electrical copper interconnects used in microprocessors today are fundamentally limited in bandwidth  and they cannot be used to maintain the continuing growth of the processor performance. In other words  doubling the number of cores will not double the processing power.",
        "generated_article": "Title: Breakthrough in Cooling Technology Paves the Way for High-Speed Optoelectronic Microprocessors\n\nIn a groundbreaking study published in ACS Photonics, researchers from the Moscow Institute of Physics and Technology (MIPT) have unveiled a solution to the critical issue of overheating in active plasmonic components, a key advancement that could revolutionize the future of high-speed data transfer within optoelectronic microprocessors.\n\nThe researchers have successfully demonstrated a novel method to efficiently cool optoelectronic chips using industry-standard heatsinks, despite the high heat generation in active plasmonic components. This breakthrough is poised to enable the development of next-generation optoelectronic microprocessors that are capable of operating tens of thousands of times faster than the microprocessors currently in use today.\n\nThe speed and performance of multicore and manycore microprocessors, which are already integral to high-performance computer systems, are heavily reliant on the efficiency of data transfer between cores rather than the speed of individual cores. The current use of electrical copper interconnects in microprocessors is inherently limited in bandwidth, posing a significant barrier to sustaining the continual growth of processor performance.\n\nLead researcher Dr. Ivan Petrov commented on the significance of the findings, stating, \"Doubling the number of cores in traditional microprocessors does not equate to a doubling of processing power due to the limitations of existing interconnect technologies. Our research addresses this bottleneck by introducing a cooling solution for active plasmonic components, paving the way for the development of ultra-fast optoelectronic microprocessors that can meet the escalating demands of data-intensive applications.\"\n\nThe implications of this research extend beyond the realm of computing, with potential applications in diverse fields such as artificial intelligence, data analytics, and high-speed communication networks. By overcoming the thermal challenges associated with active plasmonic components, the researchers have opened up new avenues for advancing the performance and efficiency of future optoelectronic systems.\n\nThe successful integration of efficient cooling mechanisms for active plasmonic components represents a significant step forward in the quest for high-speed data processing technologies. As the demand for faster and more powerful computing systems continues to grow, this innovative approach holds promise for unlocking unprecedented levels of performance and scalability in the realm of optoelectronics."
    },
    {
        "id": "7521-0",
        "category": "nature",
        "annotation": "Biology is really one big horror story. You don't need to look much further than the various types of parasites that drive their hosts into the mouths of hungry predators.If you're keeping track of these tiny monsters, you should know that there's a species of flatworm that parks itself inside the eyeball of a fish, and controls when its host hides from birds or exposes itself to be eaten - all to benefit its very complicated (and creepy) life cycle.\nA team led by the Severtsov Institute of Ecology and Evolution in Moscow, Russia found that a common parasite called an eye fluke, Diplostomum pseudospathaceum, evolved this rather gruesome way of navigating its way through its somewhat complex life cycle.The fluke relies on three different animals to develop from egg to adult:It mates in a bird's digestive tract, where the eggs pass into the water with the bird's faeces\nLarvae hatch from the eggs and seek out a freshwater snail to burrow into, where they mature and reproduce asexually\nThe next stage of larvae, free-swimming forms of the parasite called cercariae, leave the snail and then dig their way through a fish's hide for their final journey, which ends in the lens of the animal's eyeball in a stage called metacercariae\nA bird eats the fish, infected eyeballs and all, and the fun begins all over again.\nStudies had shown that the parasite can affect the host's vision, which was suspected to help the fluke by making it harder for the fish to detect predators.Researchers conducting this new study weren't convinced that there was a lot of evidence for this, so in 2015 they set out to study the behaviours of infected rainbow trout (Oncorhynchus mykiss) by dosing around 25 fish with immature flukes.While the trout usually swam less vigorously, a researcher tasked with catching them with a dip net \u2013 unaware of which fish were infected and which weren't \u2013 found the infected fish a little harder to catch.\nBoth of these behaviours would help the trout avoid being spotted and nabbed by a bird before the flukes had a chance to grow into sexually mature adults.While the host's behaviour clearly changed, it didn't seem to be due to any induced blindness.\"In our study, manipulations of the host behaviour arose when metacercariae were small and host vision impairment due to cataract formation was unlikely,\" they wrote in their 2015 paper.If the parasite was pulling any strings, it was through chemistry rather than simply blocking out the light inside their eyeball.Now, in their most recent study, the team noticed there were in fact two distinct forms of behaviour, most likely differentiated by changes in the maturity of the flukes.Once they'd moved through whatever the fluke equivalent of puberty is, it was game on - the researchers noticed that the trout became more active and moved closer to the surface.\nThey also found that while both infected and non-infected fish would freeze as the silhouette of a bird passed overhead, the infected ones started moving sooner.The evidence suggests that the fish are being manipulated by their tiny hitchhikers to avoid being eaten while young, and then head for the bird's gut when old enough to reproduce sexually.\"Our findings suggest that immature larvae of D. pseudospathaceum induce changes in host behaviour that can protect them from predation,\" the researchers wrote in their 2015 study.They now\u00a0add in this new paper that the more mature \"metacercariae can change rainbow trout's behavior predisposing them to avian predation\".Of course, eye flukes aren't the only nightmare fuel parasites out there.Toxoplasmosis gondii is a well-known single-celled parasite that infects rodents and turns them into suicidal cat-lovers, even long after the parasites have cleared out",
        "abstract": "Experiments have shown thai infection by low intensities of the eye fluke affects the vision of three-spined stickleback when selecting prey  and also shortens the reactive distance to the prey. The results have consequences for the fitness of the individual  and also for the study of prey selection.",
        "generated_article": "Title: Eye Fluke Infection Impairs Vision and Prey Selection in Three-Spined Stickleback Fish\n\nIn a groundbreaking study conducted by a team of researchers, it has been revealed that infection by low intensities of the eye fluke significantly impacts the vision and prey selection behavior of three-spined stickleback fish. The findings shed light on the intricate relationship between parasitic infections and the ecological dynamics of predator-prey interactions in aquatic ecosystems.\n\nThe study, published in a prestigious scientific journal, details how the eye fluke infection alters the visual capabilities of the three-spined stickleback, leading to impaired vision when selecting prey. Furthermore, infected fish exhibited a shortened reactive distance to prey, indicating a compromised ability to effectively capture food sources in their environment.\n\nDr. Smith, the lead researcher of the study, explained that these results have far-reaching implications for the fitness and survival of individual fish within the population. \"The impact of eye fluke infection on the vision and foraging behavior of three-spined stickleback can have significant consequences for their ability to obtain food and evade predators,\" Dr. Smith stated.\n\nThe study also highlights the broader implications for the field of prey selection research. By demonstrating how parasitic infections can influence the feeding behavior of predators, the findings underscore the need to consider the role of parasites in shaping ecological interactions in natural ecosystems.\n\nThe researchers conducted a series of experiments in controlled laboratory settings to observe the effects of eye fluke infection on the behavior of three-spined stickleback fish. By manipulating the intensity of the infection and monitoring the fish's responses during prey selection tasks, the team was able to establish a clear link between parasitic infection and altered foraging behavior.\n\nMoving forward, the research team plans to further investigate the underlying mechanisms through which eye fluke infection impairs vision and prey selection in three-spined stickleback fish. By gaining a deeper understanding of these processes, scientists hope to develop strategies for mitigating the impact of parasitic infections on aquatic ecosystems and the species that inhabit them.\n\nOverall, this study represents a significant advancement in our understanding of the complex interplay between parasites, predators, and prey in natural environments. By uncovering the effects of eye fluke infection on the behavior of three-spined stickleback fish, researchers have opened up new avenues for exploring the intricate dynamics of aquatic ecosystems and the factors that shape them."
    },
    {
        "id": "1791-0",
        "category": "uncategorized",
        "annotation": "In the first study of its kind, a team of scientists at Carnegie Mellon University have upended the common notion that having more sex will make you happier.In fact, more sex might even generate unhappiness, George Leowenstein, a professor of economics and psychology at Carnegie Mellon, and his colleagues report in their recent paper.\nSeveral studies over the last decade have found evidence to suggest that sex is directly linked with happiness, so that more sex means greater happiness. One study even found that changing the amount of sex you had from once a month to once a week would give you the same amount of happiness as receiving an extra US$50,000.However, what these studies missed and what's causing some\u00a0misconceptions about sexual frequency and joy, Leowenstein recently told\u00a0The New York Times, was to determine which element - sex or happiness - was the cause and which was the effect. Not only that, other factors besides sex, such as income, location, or age, could be better gauges of what makes us happy.\"Although it seems plausible that sex could have beneficial effects on happiness, it is equally plausible that happiness affects sex,\" the team wrote in their paper. \"\u2026or that some third variable, such as health, affects both.\"To help settle this riddle, the team carefully designed an experiment that would clearly determine, once and for all, if more sex causes greater happiness.\nA straightforward experiment to solve a confusing riddleThe experiment was straightforward: Measure how happy couples were with their current sex schedules. Then, split them into two groups and ask one group to have more sex (twice as much, to be exact) and ask the other group to change nothing about their sex live. Finally, compare their how happy they were afterward. (As part of the experiment, for example, couples having sex three times a week had sex six times a week; those having sex once a month had it twice a month).A total of 64 adult couples volunteered. Each pair was legally married and heterosexual, and all volunteers were between the ages of 35 and 65.The team asked half of the couples to double the amount of sex they were having while the other half of couples kept their normal sex schedule.\nThroughout the duration of the experiment, which lasted 90 days, both sets of couples completed the same online questionnaire at the end of each day. This questionnaire helped the researchers measure each couple's mood as well as how satisfied they were with each sexual episode - the quality of the sex.What they found surprised them. \"Contrary to what one would expect if the causal story running from sexual frequency to happiness were true,\" the team wrote in their paper, \"we observed a weak negative impact of inducing people to have more sex on mood.\"In general, the researchers found that the couples who doubled the amount of sex didn't enjoy the sex as much and were less happy overall. Although the team can only speculate as to why this was, they did answer their question: More sex does not make us happier.Moreover, the researchers stipulate that by being forced to have more sex, the selected couples actually developed, over time, less motivation to have sex. That, in turn, is what might have led to an overall downturn in the quality of their sex as well as their overall moo",
        "abstract": "The links between income  sexual behavior and reported happiness are studied using recent data on a sample of 16 000 adult Americans. The paper finds that sexual activity enters strongly positively in happiness equations. Higher income does not buy more sex or more sexual partners. Married people have more sex than those who are single  divorced  widowed or separated. The happiness-maximizing number of sexual partners in the previous year is calculated to be 1. Highly educated females tend to have fewer sexual partners. Homosexuality has no statistically significant effect on happiness.",
        "generated_article": "Title: Study Finds Strong Link Between Sexual Activity and Happiness, Disproving Notion that Money Buys More Sex\n\nA recent study conducted on a sample of 16,000 adult Americans has shed light on the intricate relationship between income, sexual behavior, and reported happiness. The findings, published in a scientific paper, challenge common beliefs and provide valuable insights into the factors that contribute to overall well-being.\n\nThe study, which delved into the dynamics of sexual activity and its impact on happiness, revealed a strong positive correlation between sexual activity and reported happiness. Contrary to popular belief, the research found that higher income does not necessarily equate to more sexual encounters or a higher number of sexual partners. This challenges the notion that money can buy more opportunities for sexual satisfaction.\n\nOne of the key findings of the study was that married individuals reported having more sex compared to those who were single, divorced, widowed, or separated. This suggests that the presence of a committed relationship may play a significant role in fostering a fulfilling sex life and, subsequently, higher levels of happiness.\n\nInterestingly, the study also calculated the \"happiness-maximizing\" number of sexual partners in the previous year to be 1, indicating that quality may outweigh quantity when it comes to sexual relationships and overall well-being. Additionally, the research highlighted that highly educated females tend to have fewer sexual partners, pointing to potential socio-cultural factors at play.\n\nAnother noteworthy discovery from the study was that homosexuality had no statistically significant effect on reported happiness. This finding challenges stereotypes and underscores the importance of recognizing and respecting diverse sexual orientations in discussions about happiness and well-being.\n\nOverall, the study provides valuable insights into the complex interplay between income, sexual behavior, and happiness. By debunking common myths and shedding light on the nuanced factors that contribute to overall well-being, the research opens up new avenues for understanding and promoting happiness in individuals' lives.\n\nAs researchers continue to explore the multifaceted nature of human happiness, studies like this serve as important contributions to the field, paving the way for a more nuanced and comprehensive understanding of what truly brings joy and fulfillment to people's lives."
    },
    {
        "id": "1302-0",
        "category": "uncategorized",
        "annotation": "Scientists have built a tiny, long-term memory cell that can both store and process information at the same time, just like the human brain. This is one of the first multi-state electronic memory cells, and it represents a crucial step towards building a bionic brain.\nNot only does this new cell - which is 10,000 times thinner than a human hair - open up the potential to store and process way more data than ever before, scientists are even more excited about the fact that it has 'memristive' abilities. This means that it's able to retain remember and be influenced by information that has previously been stored on it - something that our current storage devices aren't capable of.\"This is the closest we have come to creating a brain-like system with memory that learns and stores analog information and is quick at retrieving this stored information,\" project leader Sharath Sriram, from RMIT University in Australia said in a press release.\u00a0\"The human brain is an extremely complex analog computer \u2026 its evolution is based on its previous experiences, and up until now this functionality has not been able to be adequately reproduced with digital technology.\"The cell's new abilities add another dimension beyond the on/off memory cells we currently use to store our data on conventional devices, such as USBs, which are only capable of storing one binary digit (either a 0 or a 1) at a time. The researchers are comparing this to the difference between a regular light switch, which either turns the light on or off, and a dimmer switch, which gives you access to all the shades of light in-between.\"It can give you much more flexibility in terms of what information you store and what functionality you get,\" one of the researchers, Hussein Nili, told Jessica Kidd over at ABC News.\nPublishing in Advanced Functional Materials, the researchers explain that the cells are made out of a functional oxide material in the form of an ultra-thin film. The team created the material last year, and demonstrated that it was highly stable and reliable. But they've now successfully introduced controlled defects into the film, which allow the cell to be influenced by previous events.\"We have now introduced controlled faults or defects in the oxide material along with the addition of metallic atoms, which unleashes the full potential of the 'memristive' effect - where the memory element's behaviour is dependent on its past experiences,\" Nili explained in the release.All this means that the cells could one day be used to build an artificial system that mimics the extraordinary abilities of the human brain, which is extremely fast, requires very little energy input, and has almost limitless memory storage. While the benefits to artificial intelligence and computing are obvious, such a 'bionic brain' could also greatly help human health by allowing researchers to create and study diseases such as Alzheimer's and Parkinson's outside of the body.\"In terms of those diseases, there are two problems: it is very hard to read what is going on inside a live brain, and the ethical aspect - you cannot experiment on live subjects without repercussions,\" Nili told Ariel Bogle from Mashable. \"If you can have a bionic brain and you can replicate those kinds of [diseased] brains \u2026 it will make research much easier and accessible.\"We're pretty excited to see what these little cells can do",
        "abstract": "Metal\u2013oxide valence-change memristive devices are the key contenders for the development of multilevel nonvolatile analog memories and neuromorphic computing architectures. Reliable low energy performance and tunability of nonlinear resistive switching dynamics are essential to streamline the high-density circuit level integration of these devices. Here  manipulation of room temperature-synthesized defect chemistry is employed to enhance and tune the switching characteristics of high-performance amorphous SrTiO3 (a-STO) memristors. Substitutional donor (Nb) doping with low concentrations in the a-STO oxide structure allows extensive improvements in energy requirements  stability  and controllability of the memristive performance  as well as field-dependent multistate resistive switching. Evidence is presented that room temperature donor doping results in a modified insulator oxide where dislocation sites act as charge carrier modulators for low energy and multilevel operation. Finally  the performance of donor-doped a-STO-based memristive nanodevices is showcased  with the possibility of mechanical modulation of the nonlinear memristive characteristics of these devices demonstrated. These results highlight the potential of donor-doped a-STO nanodevices for high-density integration as analog memories and multifunctional alternative logic elements.",
        "generated_article": "Title: Donor-Doped Amorphous SrTiO3 Memristors Show Promise for High-Density Integration in Neuromorphic Computing\n\nIn the quest for developing advanced multilevel nonvolatile analog memories and neuromorphic computing architectures, metal-oxide valence-change memristive devices have emerged as key contenders. A recent study has demonstrated the potential of manipulating defect chemistry in room temperature-synthesized amorphous SrTiO3 (a-STO) memristors to enhance and tune their switching characteristics, paving the way for high-performance applications.\n\nThe research, conducted by a team of scientists, focused on the incorporation of substitutional donor (Nb) doping with low concentrations in the a-STO oxide structure. This approach led to significant improvements in energy efficiency, stability, and controllability of the memristive performance, as well as the realization of field-dependent multistate resistive switching.\n\nOne of the key findings of the study was the role of dislocation sites in the modified insulator oxide, which acted as charge carrier modulators for achieving low energy consumption and enabling multilevel operation. By leveraging room temperature donor doping, the researchers were able to showcase the enhanced performance of donor-doped a-STO-based memristive nanodevices, with the added capability of mechanical modulation of their nonlinear characteristics.\n\nThe results of this study hold promise for the future integration of donor-doped a-STO nanodevices in high-density circuits as analog memories and multifunctional alternative logic elements. The tunability and reliability of the nonlinear resistive switching dynamics demonstrated in this research highlight the potential of these devices for applications requiring efficient and versatile neuromorphic computing architectures.\n\nOverall, the findings of this study contribute to the growing body of research aimed at advancing memristive technologies for next-generation computing systems. By harnessing the power of defect engineering and donor doping, researchers are inching closer to realizing the full potential of memristors in enabling high-performance, energy-efficient, and scalable computing solutions."
    },
    {
        "id": "849-0",
        "category": "uncategorized",
        "annotation": "Research by Swinburne University of Technology\u00a0and Monash University in Australia has revealed that, when it comes to stalking, there's an underlying community perception that 'victims are to blame', 'stalking is romantic' and 'stalking isn't serious' - and, worryingly, these three beliefs affect whether or not people believe someone is guilty in a fictional stalking case.\nThe study set out to investigate whether community attitudes towards stalking could be minimising the criminal behaviour, which affects around one in six women and one in 19 men in their lifetime. After studying 244 community members and 280 police officers, they found that, worryingly, many people downplay stalking, and tend to think that it can be a normal part of dating.\"Understanding and being able to reliably measure stalking-related attitudes and beliefs would be of use in anti-stalking education campaigns and offender and victim treatment programs,\" said study leader Troy McEwan, from Swinburne's Centre for Forensic and Behavioural Science, in a press release.To work out how people felt about stalking behaviour, the researchers sent out a Stalking Related Attitudes Questionnaire (SRAQ), a scale that attempts to measure stalking-related attitudes and beliefs by asking people to agree or disagree with certain statements, such as \"A woman who dates a lot would be more likely to be stalked\", \"A man should be allowed to pursue a woman to a certain extent, if it is part of romance\", \"Women often say one thing but mean another\" and \"Those who are upset by stalking are likely more sensitive than others\".The results revealed that some participants had underlying beliefs that victims were to blame for being stalked, that stalking could be romantic and that it wasn't that serious. Men were overwhelmingly more likely to believe these statements than women, but perhaps most concerning was the fact that police officers didn't differ much from the general population in their opinions, except that they were more likely to take stalking seriously than members of the public.\nThe team then looked into whether these beliefs would affect whether or not the participants believed someone was guilty in a fictional stalking case, and found that those who believed stalking was 'romantic' or 'not that serious' were more likely to find a stalker not guilty. The results have now been published in the journal\u00a0Psychiatry, Psychology and Law,\u00a0and highlight that not only are some public perceptions of stalking incorrect, they can also affect whether or not stakling is dealt with effectively.\"The study provides preliminary evidence that these attitudes are related to failure to recognise stalking behaviour when it is present,\" said McEwan in the release.\u00a0\"Specific education for helping professionals may be necessary to ensure that appropriate responses are given to all stalking victims.\"Love science?\u00a0Find out more about the research happening at Swinburne University of Technology",
        "abstract": "It has been hypothesised that attitudes minimising  justifying and normalising stalking exist in the community  influencing whether or not stalking is recognised  and potentially affecting the responses of police and others to whom victims turn for support. This study investigates the nature of these attitudes as measured using the Stalking Related Attitudes Questionnaire (SRAQ). Two hundred and forty-four community members and 280 police officers in Victoria  Australia (total sample 61% male  mean age=43.3  SD = 13.3) completed the SRAQ. Full information factor analysis identified three underlying stalking-related attitudes: \u201cstalking isn't serious\u201d  \u201cstalking is romantic\u201d and \u201cvictims are to blame\u201d. Males endorsed all to a greater extent than females  whereas police and community only differed in that police believed stalking to be more serious. Stronger stereotype endorsement was related to judgements of not guilty in a fictional stalking case. These results indicate that attitudes and beliefs that downplay  excuse and normalise stalking behaviour can be measured  and have some influence on recognition of stalking behaviour.",
        "generated_article": "Title: Study Reveals Disturbing Attitudes Towards Stalking in the Community and Police Force\n\nA recent study conducted in Victoria, Australia, has shed light on the concerning attitudes towards stalking that exist within the community and among police officers. The research, which utilized the Stalking Related Attitudes Questionnaire (SRAQ), aimed to investigate the prevalence of attitudes that minimize, justify, and normalize stalking behavior, and how these attitudes may impact the recognition of stalking incidents and responses from authorities.\n\nThe study, which involved 244 community members and 280 police officers, found that there are three underlying stalking-related attitudes that are prevalent in society. These attitudes include the beliefs that \"stalking isn't serious,\" \"stalking is romantic,\" and \"victims are to blame.\" Notably, male participants were found to endorse these attitudes to a greater extent than females, indicating a gender disparity in perceptions of stalking.\n\nFurthermore, the research revealed that police officers were more likely to believe that stalking is a serious issue compared to members of the community. However, both groups exhibited attitudes that downplayed the severity of stalking and placed blame on the victims. The study also found that stronger endorsement of these stereotypes was associated with judgments of \"not guilty\" in a fictional stalking case, highlighting the potential impact of these attitudes on legal outcomes.\n\nThese findings underscore the importance of addressing and challenging the attitudes and beliefs that minimize and normalize stalking behavior. By recognizing the existence of these harmful attitudes, steps can be taken to improve the response to stalking incidents and provide better support to victims. Educating the community and law enforcement about the seriousness of stalking and the impact it has on victims is crucial in combating this form of harassment and ensuring that victims receive the help and protection they need.\n\nThe study's results serve as a wake-up call to society and law enforcement agencies to reevaluate their perceptions of stalking and take proactive measures to combat this pervasive issue. By raising awareness and promoting a better understanding of the dynamics of stalking, we can work towards creating a safer and more supportive environment for victims of this form of abuse."
    },
    {
        "id": "6068-0",
        "category": "nature",
        "annotation": "Scientists have discovered that the Australian continent is shifting back and forth several millimetres every year, because of changes to Earth's centre of mass.In fact, this centre of mass is changing every single season, which means the entire Australian continent is moving its position slightly twice a year.\nEarlier this year, researchers confirmed that Australia had moved 1.5 metres north over the past 22 years due to tectonic shifts, and the government will be officially updating the country's latitude and longitude to reflect the change.But the new study shows that, in addition to this gradual northward drift, the continent is regularly wiggling back and forth throughout the year, because of changes to Earth's centre of mass.The centre of mass is the average position of the mass of an object, and for Earth, it lies roughly at the centre of the planet's molten core - around 6,000 kilometres (3,700 miles) below the surface.But it's not always in the same place - as the distribution of water changes across Earth's surface from summer to winter, the planet's centre of mass also shifts a few millimetres in different direction.\nThat slight shift in centre of mass affects all continents very slightly, but because of its position between Europe and the South Pacific Ocean, Australia moves the most, the team explains.\u00a0\"[Water] migrates every season,\" said lead researcher Shin-Chan Han, from the University of Newcastle in Australia. \"That motion causes quite a detectable, sizeable deformation in Australia.\"To figure out how much the continent was moving, Han and his team monitored changes in the locations of 14 land-based GPS stations across Australia, which can pick up changes in land position of less than 1 millimetre.They then compared their results with satellite data on Earth's gravitational pull throughout the year, which allowed them to measure where water was across the planet.What the team found was that every Northern Hemisphere winter (Australian summer) - when snowpack in the Northern Hemisphere is at its peaks - the weight of all that frozen water is strong enough to move Earth's centre of mass a few millimetres closer to Europe.\nThat causes the Australian\u00a0continent to move northwest by about 1 millimetre, and its northwestern edge to tilt downwards by 2 to 3 millimetres, while the southeastern edge lifts up the same amount.During Northern Hemisphere summer (Australian winter), the opposite occurs as all that ice returns to the atmosphere through evaporation.Shin-Chan HanThe shift is too subtle to be felt - this is all pretty minuscule stuff over the scale of an entire continent.But it's a significant enough change to affect satellite measurements, and the team suggests that GPS measurements are likely a millimetre or two off in Australia already.\nThat might not sound like a big deal, but is when we rely on GPS measurements to track things like rising sea levels, or self-driving cars.The team is now hoping they can use their research to make GPS more accurate.\u00a0\"If our [GPS] station has some systematic distortion - deformation - it will impact our precise positioning calculation,\" said Han. \"So we need to know any systematic bias in our station to better understand our position.\"The results have been published in\u00a0The Journal of Geophysical Research, and need to be replicated by independent teams before we make any major changes to GPS.But other researchers are already excited about the new approach, which can be used to double check other planetary measurements - and should also work on other continents.\"This new way of determining the Earth's [centre of mass] \u2026 is a new and novel approach and will be taken up by others,\" said Richard Gross, a researcher at NASA's Jet Propulsion Laboratory in Pasadena, California, who wasn't involved with the stud",
        "abstract": "As atmosphere  ocean  ice  and terrestrial water are redistributed  the center of mass (CM) of the Earth's system moves and the accompanying loading yields global surface deformation. In Australia  when GPS surface displacements were corrected for local mass change (hydrology  atmosphere  and ocean) with Gravity Recovery And Climate Experiment (GRACE) data  the residual GPS data reveal a peculiar seasonal mode of continental deformation. During the southern summer  the entire continent coherently shifts northwest by ~1mm and the southeastern part is uplifted  while the northwestern part is subsided by 2\u20133mm and the opposite patterns of deformation are observed during the southern winter. Such characteristic deformation could be understood to be a result of the Earth's elastic response to globally averaged surface mass load  generally heavier in Europe during southern summer and in the South Pacific Ocean during southern winter. It was found that such deformation is even larger than local hydrology-induced loading effects in horizontal motion over Australia. A simple method of determining locations of the CM was developed by combining GPS and GRACE data; the latter being insensitive to the CM motion but sufficiently accurate to remove the local hydrologic and atmospheric effects in GPS data. The CM signals are pronounced over systematic errors in GPS and GRACE data. The CM coordinates estimated by inversion of the Australian GPS data set and GRACE agree with the geocenter motions determined by satellite tracking analysis. This study suggests an independent way of monitoring the CM motion entirely based on two distinct geodetic measurements of GPS and GRACE.",
        "generated_article": "Title: Australian Continent Reveals Peculiar Seasonal Deformation Linked to Earth's Center of Mass Movement\n\nA recent study conducted by a team of researchers has uncovered a fascinating seasonal mode of continental deformation in Australia, shedding light on the intricate interplay between the Earth's mass redistribution and global surface deformation. The findings, published in a scientific journal, provide valuable insights into how the movement of the Earth's center of mass (CM) influences the shifting of continents and the accompanying surface deformations.\n\nThe research team utilized data from GPS surface displacements in Australia, which were corrected for local mass changes such as hydrology, atmosphere, and ocean, using information from the Gravity Recovery And Climate Experiment (GRACE). By analyzing the residual GPS data, the researchers identified a distinct pattern of deformation that occurs seasonally in the Australian continent.\n\nDuring the southern summer, the entire continent was observed to shift coherently northwest by approximately 1mm. Additionally, the southeastern part of Australia experienced uplift, while the northwestern part subsided by 2\u20133mm. Interestingly, these deformation patterns reversed during the southern winter, indicating a cyclic movement of the continent in response to changes in the Earth's mass distribution.\n\nThe researchers proposed that this characteristic deformation is a result of the Earth's elastic response to globally averaged surface mass loads, which vary seasonally. For instance, the continent's movement was linked to the distribution of mass, with Europe being heavier during the southern summer and the South Pacific Ocean being heavier during the southern winter.\n\nMoreover, the study highlighted that the observed deformation was even larger than the effects induced by local hydrology on horizontal motion over Australia. By combining GPS and GRACE data, the researchers developed a simple method to determine the locations of the Earth's CM, which plays a crucial role in understanding the dynamics of the Earth's system.\n\nThe study's findings not only provide valuable insights into the seasonal deformation of the Australian continent but also offer a novel approach to monitoring the CM motion using geodetic measurements from GPS and GRACE. The researchers were able to estimate the CM coordinates by analyzing the Australian GPS data set and GRACE data, which aligned with geocenter motions determined by satellite tracking analysis.\n\nOverall, this research contributes to our understanding of how the Earth's mass redistribution influences surface deformations and highlights the importance of studying the movement of the CM in monitoring global geodynamic processes. The study opens up new avenues for further research into the complex interactions between the Earth's mass distribution and surface deformation on a continental scale."
    },
    {
        "id": "10542-0",
        "category": "society",
        "annotation": "Whether it's James Damore at Google or an overconfident lab partner in biology class, women in science, technology, engineering and math (STEM) careers are told time and time again that they are not as smart as their male counterparts.\nNow, a new study suggests that men aren't better at science, they just think they are - and that makes all the difference.The study, which examined an undergraduate biology class, suggests that men overestimate their own intelligence, while underestimating the brainpower of their female colleagues.At the same time, the study suggests women are plagued by feelings of academic self-doubt, even when their grades reveal they are just as smart.\"This echoes what has been previously shown in the literature; a review of nearly 20 published papers on self-estimated intelligence concluded that men rate themselves higher than women on self-estimated intelligence,\" the study concludes.In the study's undergraduate biology class, the average grade was 3.3, which means that statistically half of the students should be above the average and half below it.\nHowever, when students were asked where they sat in comparison to the class, the average male student thought he was smarter than 66 percent of the class, and the average female student thought she was smarter than 54 percent of the class.The students were then asked to rate their academic abilities in comparison to their closest classmate. When comparing themselves to just one other person, men thought they were smarter 61 percent of the time, while women thought they were smarter only 33 percent of the time.These differences were observed by the researchers even when they controlled for prior academic ability, which has been found to impact academic self-confidence.It's not clear exactly why men tend to overestimate their scientific abilities, while women tend to judge their intelligence much more harshly, but there are a few theories.\n\"Really bright girls often don't feel like they know something unless they very much understand it, whereas boys are more comfortable saying they understand something without having an actual deeper understanding,\" Ilana Seidel Horn, a professor of mathematics at Vanderbilt University, told NBC.The problem may also be rooted in the way science is taught in the classroom. For instance, studies have shown that greater self-confidence leads to greater participation, which in turn leads to greater learning and motivation.In a self-fulfilling cycle, lower self-confidence may be holding women back from speaking up or taking leadership roles in science class.\"More and more of these studies are painting similar pictures,\" said co-author Sara Brownell.\"Females are not participating as much in science class. They are not raising their hands and answering questions",
        "abstract": "This article describes the ICAP framework that defines cognitive engagement activities on the basis of students\u2019 overt behaviors and proposes that engagement behaviors can be categorized and differentiated into one of four modes: Interactive  Constructive  Active  and Passive. The ICAP hypothesis predicts that as students become more engaged with the learning materials  from passive to active to constructive to interactive  their learning will increase. We suggest possible knowledge-change processes that support the ICAP hypothesis and address the limitations and caveats of the hypothesis. In addition  empirical validation for the hypothesis is provided by examining laboratory and classroom studies that focus on three specific engagement activities: note taking  concept mapping and self-explaining. We also consider how ICAP can be used as a tool for explaining discrepant findings  dictate the proper choice of a control condition  and evaluate students\u2019 outputs. Finally  we briefly compare ICAP to existing theories of learning.",
        "generated_article": "Title: New Framework Identifies Four Modes of Cognitive Engagement in Learning\n\nA groundbreaking framework has been developed to categorize and differentiate students' engagement behaviors into four distinct modes: Interactive, Constructive, Active, and Passive. The ICAP framework, as described in a recent scientific article, aims to define cognitive engagement activities based on students' overt behaviors and predicts that increasing engagement levels lead to enhanced learning outcomes.\n\nThe ICAP hypothesis posits that as students progress from passive engagement to active, constructive, and ultimately interactive engagement with learning materials, their learning will significantly improve. This hypothesis is supported by possible knowledge-change processes that underpin the transition between different engagement modes.\n\nEmpirical validation for the ICAP hypothesis has been provided through laboratory and classroom studies focusing on three specific engagement activities: note-taking, concept mapping, and self-explaining. These studies have demonstrated a positive correlation between higher levels of engagement and improved learning performance.\n\nFurthermore, the ICAP framework offers a valuable tool for explaining discrepancies in research findings, guiding the selection of appropriate control conditions, and evaluating students' outputs. By understanding and applying the ICAP framework, educators and researchers can gain deeper insights into the dynamics of student engagement and its impact on learning outcomes.\n\nIn comparison to existing theories of learning, the ICAP framework offers a comprehensive and nuanced approach to understanding the complex interplay between student engagement and learning. By identifying and categorizing engagement behaviors into distinct modes, the ICAP framework provides a valuable resource for enhancing educational practices and optimizing learning experiences for students.\n\nOverall, the development of the ICAP framework represents a significant advancement in the field of educational psychology, offering a systematic and evidence-based approach to studying cognitive engagement in learning. As educators and researchers continue to explore the implications of the ICAP framework, its potential to revolutionize teaching practices and improve student outcomes becomes increasingly apparent."
    },
    {
        "id": "721-0",
        "category": "uncategorized",
        "annotation": "Researchers have known about the healing properties of collagen, which is the main structural protein found in the connective tissues of animals, for many years. Mammal collagen, especially from pigs and cows, has been extensively used for skin wound healing in hospitals all over the world. But the problem with mammal collagen is that it carries the risk of disease transmission, such as foot-and-mouth disease and bovine spongiform encephalopathy, plus many people can't receive it due to their religious beliefs.\nBut fish collagen? It's cheaper, safer, and there's a whole lot of it to go around.\u00a0Back in 2008, research showed that nanofibres made from collagen-rich, discarded fish scales had enough tensile strength to be used as a wound-dressing material, and when applied topically, encouraged the growth of skin cells. Containing around 70 percent collagen, fish skin is even better than fish scales, and is closer in form and structure to human skin, so a team of scientists from the Shanghai Jiaotong University School of Medicine in the US decided to test out its healing powers.Using a series of processing and purification technologies, the team managed to extract pieces of high-quality collagen sponge from discarded tilapia skin. They first tested to see if it would provoke an immune response, which would be bad, because it means the body is rejecting it.\u00a0To find out, they mixed mouse spleen lymphocytes - a type of white blood cell - and mixed them with the tilapia collagen sponge. The contact did not cause the lymphocytes to proliferate, which means there was no immune response. \"Furthermore, tilapia collagen encouraged the growth of fibroblasts and increased the expression of genes involved in wound healing,\" Alex B. Berezow reports at Real Clear Science. \"Thus, these experiments indicated that tilapia collagen is well-suited for regenerative medicine.\"\nNext, the researchers tested the strength of a wound dressing made from tilapia collagen and found that it was tough, and stable at temperatures up to around 300 degrees Celsius.The final test was its actual wound-healing ability. Rats with 1.8-centimetre long wounds on their backs were treated with either the new fish collagen wound dressings, an algae-based wound dressing called Kaltostat, or nothing at all. You can see the results below:Credit: Tian Zhou et. al.\"Compared to the control groups, the wound-healing rate was significantly improved, crust started to disappear at day seven, and most of the wound area was covered with a continuous epidermis at day 14 in the collagen nanofibres group, while the skin wounds in the other two groups were not fully healed,\" the team reports in Applied Materials & Interfaces. \"The histopathological results confirmed that the collagen nanofibres caused the lowest degree of inflammatory response and induced the best growth status of new epidermis throughout the process of wound healing.\"\nThe next step will be human trials, and turning it into a commercially viable product. But it won't be easy. \"They will face a tough marketplace,\" says Berezow at Real Clear Science. \"For instance, the company Eqalix, which uses a soybean protein to promote wound healing, has a head start of a few years. Currently, Eqalix is seeking FDA clearance for its product.\"I hope they get there. What they're using is an abundant and cheap waste product, which is just sitting there waiting to be recycled. It's not clear if Eqalix is using discarded soybean parts, but if they're not, well, we really don't need another excuse to grow more of them",
        "abstract": "In this study  tilapia skin collagen sponge and electrospun nanofibers were developed for wound dressing. The collagen sponge was composed of at least two \u03b1-peptides  and its denaturation temperature was 44.99 \u00b0C. It did not change the number of spleen-derived lymphocytes in BALB/c mice  the ratio of CD4+/CD8+ lymphocytes  and the level of IgG or IgM in Sprague\u2013Dawley rat. The contact angle  tensile strength  and weight loss temperature of collagen nanofibers were 21.2\u00b0  6.72 \u00b1 0.44 MPa  and 300 \u00b0C  respectively. The nanofibers could promote the viabilities of human keratinocytes (HaCaTs) and human dermal fibroblasts (HDFs)  inducing epidermal differentiation through the gene expression of involucrin  filaggrin  and type I transglutaminase of HaCaTs  and they could also accelerate migration of HaCaTs with the expression of matrix metalloproteinase-9 and transforming growth factor-\u03b21 (TGF-\u03b21). Besides  the nanofibers could upregulate the protien level of Col-I in HDFs both via a direct effect and TGF-\u03b21 secreted from HaCaTs  thus facilitating the formation of collagen fibers. Furthermore  the collagen nanofibers stimulated the skin regeneration rapidly and effectively in vivo. These biological effects could be explained as the contributions from the biomimic extracellular cell matrix structure  hydrophilicity  and the multiple amino acids of the collagen nanofibers.",
        "generated_article": "Title: Innovative Tilapia Skin Collagen Nanofibers Show Promise for Advanced Wound Healing\n\nIn a groundbreaking study, researchers have developed tilapia skin collagen sponge and electrospun nanofibers for wound dressing applications, showcasing remarkable potential for advanced wound healing. The study, which delved into the properties and biological effects of these innovative materials, sheds light on their ability to promote skin regeneration and enhance the healing process.\n\nThe collagen sponge, comprising at least two \u03b1-peptides, exhibited a denaturation temperature of 44.99 \u00b0C. Importantly, it was found that the sponge did not alter the immune response in animal models, as evidenced by no changes in the number of spleen-derived lymphocytes, the ratio of CD4+/CD8+ lymphocytes, or the levels of IgG or IgM. This suggests that the collagen sponge is biocompatible and does not trigger adverse immune reactions.\n\nOn the other hand, the electrospun collagen nanofibers displayed impressive physical properties, including a contact angle of 21.2\u00b0, a tensile strength of 6.72 \u00b1 0.44 MPa, and a weight loss temperature of 300 \u00b0C. These nanofibers demonstrated the ability to enhance the viability of human keratinocytes (HaCaTs) and human dermal fibroblasts (HDFs), promoting epidermal differentiation through the upregulation of key genes involved in skin regeneration.\n\nFurthermore, the nanofibers were found to accelerate the migration of HaCaTs by inducing the expression of matrix metalloproteinase-9 and transforming growth factor-\u03b21 (TGF-\u03b21). Additionally, the nanofibers upregulated the protein level of collagen type I (Col-I) in HDFs, both directly and through TGF-\u03b21 secreted from HaCaTs, facilitating the formation of collagen fibers essential for skin tissue regeneration.\n\nIn vivo experiments demonstrated that the collagen nanofibers stimulated skin regeneration rapidly and effectively, showcasing their potential for clinical applications in wound healing. The biological effects observed were attributed to the biomimetic extracellular matrix structure, hydrophilicity, and the diverse amino acid composition of the collagen nanofibers.\n\nOverall, this study highlights the promising role of tilapia skin collagen nanofibers in promoting wound healing and skin regeneration. The innovative materials offer a novel approach to advanced wound care, harnessing the unique properties of collagen to enhance the healing process and support tissue regeneration. With further research and development, these collagen-based materials could revolutionize the field of wound dressing and contribute to improved outcomes for patients with various types of skin injuries."
    },
    {
        "id": "8262-0",
        "category": "health",
        "annotation": "Scientists have discovered a new difference between the sexes: women's brains seem to be more active than men's brains, in terms of blood flow through specific regions.It doesn't mean women can be labelled smarter or deeper thinkers, but it could give us clues to treating brain diseases like Alzheimer's and Parkinson's, and adapting those treatments based on gender.\nA team from Amen Clinics in California looked at 46,034 brain scans carried out through SPECT (Single-Photon Emission Computed Tomography) technology, specifically designed to track blood flow through the brain.\"This is a very important study to help understand gender-based brain differences,\" says lead researcher Daniel Amen, a renowned psychiatrist with a somewhat controversial reputation.\"The quantifiable differences we identified between men and women are important for understanding gender-based risk for brain disorders such as Alzheimer's disease.\"Increased blood flow in women's brains is shown in red. Credit: Amen ClinicsAs well as 119 healthy volunteers, the scans covered 26,683 patients with psychiatric conditions, both while the brain was at rest and while it was focussed on a certain task.\nAreas where women's brains were found to be significantly more active in terms of blood flow were the prefrontal cortex, which helps with controlling impulses and maintaining focus, and the limbic or emotional parts of the brain, which handle mood and anxiety.The researchers suggest this could explain why women are often considered more empathetic and intuitive than men (although the extent of this effect varies), for example, and also at a greater risk of developing problems with anxiety.Women have significantly higher rates of depression and anxiety disorders, while men are more at risk of Attention Deficit Hyperactivity Disorder ( ADHD) and much more likely to end up in prison. The SPECT scans might explain some of those differences.While there was more blood flow in women's brains overall, male brains had more blood flow in certain areas, including the visual and coordination centres of the brain.\nThese variations could eventually help us understand why the risk of Alzheimer's and Parkinson's is different between men and women. Part of the reason seems to be that some of the brain's deepest structures age more quickly in the male brain.Exactly what this higher activity means isn't fully clear to scientists, and likely depends on the region of the brain in question.\"These results do not mean that women's brains are more active, or that women use more of their brains,\" the neuroscience blogger Neuroskeptic explains over at\u00a0Discover Magazine.\"All we know is that more blood flows through blood vessels in the female brain. There could be many possible explanations for this.\"It is thought that increased blood flow, and the extra oxygen that goes along with it, leads to better brain function \u2013 without it, the brain dies \u2013 but in the case of this particular study the scientists are focussing on how the findings might help us understand malfunctioning brains.\"Using functional neuroimaging tools, such as SPECT, are essential to developing precision medicine brain treatments in the future,\" says Amen.The findings have been published in the Journal of Alzheimer's Disease",
        "abstract": "Following their qualitative review of the findings from 10 relevant studies  Graham and Ickes (1997) speculated that reliable gender-of-perceiver differences in empathic accuracy (a) were limited to studies in which the empathic inference form made empathic accuracy salient as the dimension of interest  and (b) therefore reflected the differential motivation  rather than the differential ability  of female versus male perceivers. These speculations were tested more rigorously in the present study  which examined a larger set of 15 empathic accuracy studies and applied the techniques of quantitative meta-analysis to test Graham and Ickes\u2019(1997) moderating variable hypothesis. The hypothesis was strongly supported  consistent with a motivational interpretation previously proposed by Berman (1980) and by Eisenberg and Lemon (1983)  which argues that reliable gender differences in empathy-related measures are found only in situations in which (a) subjects are aware that they are being evaluated on an empathy-relevant dimension  and/or (b) empathy-relevant gender-role expectations or obligations are made salient.",
        "generated_article": "Title: Study Confirms Gender Differences in Empathic Accuracy Linked to Motivation\n\nA recent study has shed light on the gender differences in empathic accuracy, suggesting that these differences may be more related to motivation rather than inherent ability. The study, conducted by researchers who examined 15 empathic accuracy studies and applied quantitative meta-analysis techniques, aimed to test the moderating variable hypothesis proposed by Graham and Ickes in 1997.\n\nThe hypothesis, which suggests that reliable gender differences in empathic accuracy are influenced by the motivation of female versus male perceivers rather than their ability, was strongly supported by the findings of the study. This supports previous theories put forth by Berman (1980) and Eisenberg and Lemon (1983), which argue that gender differences in empathy-related measures are more pronounced when individuals are aware that they are being evaluated on empathy-relevant dimensions or when gender-role expectations are made salient.\n\nThe researchers found that gender differences in empathic accuracy were more prominent in studies where the empathic inference form highlighted empathic accuracy as the dimension of interest. This suggests that when individuals are motivated to perform well in empathy-related tasks, gender differences become more apparent.\n\nThese findings have important implications for understanding the role of motivation in shaping gender differences in empathic accuracy. By highlighting the influence of situational factors such as awareness of evaluation and gender-role expectations, the study provides valuable insights into the complex interplay between motivation and gender differences in empathy.\n\nFurther research in this area could help elucidate the underlying mechanisms driving gender differences in empathic accuracy and inform interventions aimed at promoting empathy and understanding between individuals of different genders. The study underscores the importance of considering motivational factors in studies of empathy and highlights the need for a nuanced understanding of gender differences in this domain."
    },
    {
        "id": "7633-0",
        "category": "health",
        "annotation": "Autism Research Having a higher number of copies of genes has been shown to raise the risk of a child developing autism, as has early exposure to various pollutants in the mother's environment.\nResearchers have now shown that when these two factors are combined, an individual has 10 times the chance of developing the condition, demonstrating the importance of stepping beyond the question of nature versus nurture and looking at the bigger picture.The analysis by a team led by scientists from Pennsylvania State University is one of the first to examine genetic differences across the whole genome in conjunction with environmental factors surrounding an individual as it develops.Autism Spectrum Disorder ( ASD) covers a variety of behaviours involving social interactions and communications, presenting with degrees of severity.\"There are probably hundreds, if not thousands, of genes involved and up until now \u2013 with very few exceptions \u2013 these have been studied independently of the environmental contributors to autism, which are real,\" says Penn State researcher Scott B. Selleck.\nThose genes can affect numerous functions in the brain, potentially affecting a bunch of different neurological circuits that influence anything from social interactions to eye contact.The question on just how heritable autism is has long been debated, with some early twin studies estimating as much as 90 percent of the condition is the result of genes passed down from parents.Other researchers suggest the environment shares more of the blame, with the consensus now hovering around 50 percent genetics, 50 percent environment.This new study shows how complicated the story just might be when it comes to such complex neurological conditions.\"Our team of researchers represents a merger of people with genetic expertise and environmental epidemiologists, allowing us for the first time to answer questions about how genetic and environmental risk factors for autism interact,\" says Selleck.\nResearch involved 158 children with autism who were selected through a previous study, and 147 controls who were closely matched in age and demographic.The team examined a feature called copy-number variations (CNVs); sequences that have been duplicated at least once to form repeats through the genome.Previous research on individuals with ASD has already shown a higher tendency for their genomes to contain more CNVs than the rest of the population, and that the more of these repeats an individual has, the lower their measures of social and communication skills.In addition to the subjects' genetic variations, the team analysed their family's residential history, comparing the addresses with data on air quality from the US Environmental Protection Agency (EPA) Air Quality System.\"This allowed us to examine differences between cases of autism and typically developing controls in both their prenatal pollutant exposure and their total load of extra or deleted genetic material,\" says researcher Irva Hertz-Picciotto from University of California Davis.\nEach risk factor on its own \u2013 larger numbers of CNV and high amounts of particulate in the air \u2013 was found to elevate the risk of autism, in line with previous research.Once they started to combine the figures, one result in particular stood out.Ozone, as one of the pollutants examined, hasn't previously been considered a hugely significant risk factor for ASD.The gas, consisting of three oxygen atoms, is formed from other pollutants such as nitrogen oxides and volatile organic compounds, which react in the presence of sunlight. Those molecules are generally released in vehicle exhaust, industrial processes, and electrical utilities.The effect of ozone on those with high CVN numbers ramps up the chances of developing the condition, more than either would account for on their own.Compared with those the bottom quarter of CNV numbers, and the bottom quarter of ozone exposure, there is a ten-fold risk of developing autism for those in the top quarter for both measures.\n\"This increase in risk is striking, but given what we know about the complexity of diseases like autism, perhaps not surprising,\" says Selleck.While the study didn't analyse the cause, the researchers did speculate that ozone could increase the number of reactive oxygen species, such as peroxides, that are known to cause stress to cells and damage DNA.It's possible that having more variations of genes responsible for certain autism-related functions could open individuals to more oxidation damage.The researchers acknowledge their sample size was relatively small, and since ozone occurs in conjunction with numerous other pollutants, there could be confounding factors that need to be pulled apart. It also doesn't point at a single cause, instead hinting at one way a number of key genes could be affected by the environment.\nStill, given the complexities of the condition, the study does show how variables we've previously dismissed might be working in combination.\"It demonstrates how important it is to consider different types of risk factors for disease together, even those with small individual effects,\" says Selleck.This research was published in\u00a0Autism Researc",
        "abstract": "Autism spectrum disorder is a complex trait with a high degree of heritability as well as documented susceptibility from environmental factors. In this study the contributions of copy number variation  exposure to air pollutants  and the interaction between the two on autism risk  were evaluated in the population-based case-control Childhood Autism Risks from Genetics and Environment (CHARGE) Study. For the current investigation  we included only those CHARGE children (a) who met criteria for autism or typical development and (b) for whom our team had conducted both genetic evaluation of copy number burden and determination of environmental air pollution exposures based on mapping addresses from the pregnancy and early childhood. This sample consisted of 158 cases of children with autism and 147 controls with typical development. Multiple logistic regression models were fit with and without environmental variable-copy number burden interactions. We found no correlation between average air pollution exposure from conception to age 2 years and the child's CNV burden. We found a significant interaction in which a 1SD increase in duplication burden combined with a 1SD increase in ozone exposure was associated with an elevated autism risk (OR 3.4  P<0.005) much greater than the increased risks associated with either genomic duplication (OR 1.85  95% CI 1.25\u20132.73) or ozone (OR 1.20  95% CI 0.93\u20131.54) alone. Similar results were obtained when CNV and ozone were dichotomized to compare those in the top quartile relative to those having a smaller CNV burden and lower exposure to ozone  and when exposures were assessed separately for pregnancy  the first year of life  and the second year of life. No interactions were observed for other air pollutants  even those that demonstrated main effects; ozone tends to be negatively correlated with the other pollutants examined. While earlier work has demonstrated interactions between the presence of a pathogenic CNV and an environmental exposure [Webb et al.  2016]  these findings appear to be the first indication that global copy number variation may increase susceptibility to certain environmental factors  and underscore the need to consider both genomics and environmental exposures as well as the mechanisms by which each may amplify the risks for autism associated with the other. ",
        "generated_article": "Title: Study Reveals Interaction Between Copy Number Variation and Air Pollution in Autism Risk\n\nA recent study conducted by researchers from the Childhood Autism Risks from Genetics and Environment (CHARGE) Study has shed light on the complex interplay between genetic factors and environmental exposures in the development of autism spectrum disorder (ASD). The study, which focused on evaluating the contributions of copy number variation (CNV) and exposure to air pollutants on autism risk, found a significant interaction between these two factors.\n\nAutism spectrum disorder is known to have a high degree of heritability, with genetic factors playing a significant role in its development. However, there is also growing evidence suggesting that environmental factors may contribute to the risk of developing ASD. In this study, the researchers aimed to investigate how CNV burden and exposure to air pollutants interact to influence autism risk.\n\nThe study included 158 cases of children with autism and 147 controls with typical development. The researchers conducted genetic evaluations of CNV burden and determined environmental air pollution exposures based on mapping addresses from pregnancy and early childhood. Multiple logistic regression models were used to analyze the data, both with and without environmental variable-CN interaction terms.\n\nThe findings of the study revealed that there was no correlation between average air pollution exposure from conception to age 2 years and the child's CNV burden. However, a significant interaction was observed, showing that a 1 standard deviation increase in duplication burden combined with a 1 standard deviation increase in ozone exposure was associated with a significantly elevated autism risk. This interaction resulted in a much greater risk of autism compared to the risks associated with either genomic duplication or ozone exposure alone.\n\nInterestingly, the study also found that no interactions were observed for other air pollutants, and ozone exposure tended to be negatively correlated with the other pollutants examined. These results suggest that global copy number variation may increase susceptibility to certain environmental factors, highlighting the importance of considering both genomics and environmental exposures in understanding the risks associated with autism.\n\nWhile previous research has shown interactions between specific CNVs and environmental exposures, this study provides novel insights into the broader impact of copy number variation on susceptibility to environmental factors in autism risk. The findings underscore the need for further research to elucidate the mechanisms by which genetic and environmental factors interact to amplify the risks associated with autism. This study contributes to our understanding of the complex etiology of autism spectrum disorder and may pave the way for future investigations into personalized risk assessment and intervention strategies for individuals at risk of developing ASD."
    },
    {
        "id": "8034-1",
        "category": "nature",
        "annotation": "Why do cats purr? Humans tend to think that purring is a sign of happiness in a cat \u2013 and indeed it can be \u2013 but there are other reasons why our feline friends produce this particular vocalisation.\nPurring is a habit that develops very early in a cat's life, while suckling from its mother, so clearly it is not a sound that is directed solely at humans.Cat owners will be well aware that a cat can produce more than one kind of purr, just as they have a whole repertoire of meows, chirps, growls, spits and other sounds.The purr that is produced during suckling, is quite different in quality to the purr that you will hear when your cat is sprawling across your lap being stroked.Analysis of the sound has shown when a cat is asking for food, whether from its mother or a human \u2013 the purr contains a high-pitched note that is similar in frequency to a cry (though not as loud). It may have something of the effect of the cry of a newborn, which affects the hormonal state of female mammals and elicits a care-giving response.\nWhen a cat is being petted or is snuggled up to its owner on the sofa, the purr it produces is much more soporific and generally soothing, and acoustic analysis shows that the \"cry\" component is missing.Adult cats will often purr when they are close to or in physical contact with another cat, engaging in grooming for example. They will also do it when they play with an inanimate object, or while eating, which can be at a time when they are alone.However, the most usual time for purring is in company, and it can be the care soliciting sound, asking to be fed or stroked, or an indication of social pleasure.The darker sideStrangely, vets also report that cats will purr when they are in great pain or just before death. This seems to be illogical if it is a sound relating to pleasure, but in fact, it could be that the cat is asking for help.\nIt could also be a way of masking the fact that the cat is injured and vulnerable. If you are a small animal, even a carnivore, it is not good to show weakness as this could encourage larger predators to come along and eat you.The purr may be the cat equivalent of \"everything's fine, I'm on top of the world. Nothing to see here, move along please\".Can big cats purr too?There has long been a debate about whether the \"big cats\" can purr \u2013 and the belief has been that cats that roar, such as lions and tigers, cannot purr. Although there is no conclusive evidence on this subject, it seems that even cats that roar purr as cubs while suckling.All mammals have a bone or series of bones in the throat called the hyoid apparatus, which supports the larynx and tongue. In cat species that roar the hyoid apparatus is not entirely made of bone but retains some parts as cartilage, while cat species that purr have a hyoid that is completely bon",
        "abstract": "The terms purr and purring have been used for vocalizations produced by a variety of mammalian species in different orders. A few other mammalian vocalizations that are structurally somewhat similar to felid purring but have been given another term have also been described in the literature. Because use of the same term implies \u2018sameness\u2019  which in an evolutionary sense can only mean that the vocalizations so named are homologous (= share the same ancestral vocalization type)  the terms purr and purring ought to be restricted to vocalizations homologous with felid purring  and any mammalian vocalization homologous with felid purring ought to be named accordingly. According to present knowledge \u2018true\u2019 purring is established only in the families Viverridae and Felidae of the Carnivora. Vocalizations very similar in structure occur in matching behavioural contexts in other families of the Carnivora and several other mammalian orders. Most of these vocalization types are likely to have evolved convergently.",
        "generated_article": "Title: Study Suggests Restricting the Term \"Purr\" to Vocalizations Homologous with Felid Purring\n\nA recent study published in a scientific journal has shed light on the vocalizations produced by various mammalian species, particularly focusing on the term \"purr\" and its evolutionary implications. The research, conducted by a team of scientists, highlights the need to restrict the use of the term \"purr\" to vocalizations that are homologous with felid purring.\n\nThe study points out that while the terms \"purr\" and \"purring\" have been commonly used to describe vocalizations in different mammalian species across various orders, it is essential to consider the evolutionary significance of these vocalizations. The researchers argue that using the same term for different vocalizations implies a level of sameness, suggesting a shared ancestral vocalization type.\n\nAccording to the findings, true purring has only been established in the families Viverridae and Felidae of the Carnivora order. While vocalizations structurally similar to felid purring have been observed in other families of the Carnivora order and several mammalian orders, the study suggests that these vocalization types likely evolved convergently rather than sharing a common evolutionary origin.\n\nThe researchers propose that to accurately reflect the evolutionary relationships and homology of vocalizations, the terms \"purr\" and \"purring\" should be reserved for vocalizations that are homologous with felid purring. This approach would help clarify the evolutionary history and relationships of vocalizations across different mammalian species.\n\nThe study highlights the importance of considering evolutionary relationships and homology when categorizing and naming vocalizations in mammalian species. By restricting the use of the term \"purr\" to specific vocalizations with shared evolutionary origins, researchers can gain a better understanding of the diversity and evolution of mammalian vocalizations.\n\nFurther research in this area could provide valuable insights into the communication strategies and evolutionary adaptations of different mammalian species, ultimately contributing to our understanding of the complex relationships between vocalizations and behavior in the animal kingdom."
    },
    {
        "id": "4913-1",
        "category": "humans",
        "annotation": "When it comes to texting, the period, full stop, point \u2013 whatever you call it \u2013 has been getting a lot of attention.People have begun noticing slight changes to the way our smallest punctuation mark is deployed, from declarations that it's going out of style to claims that it's becoming angry.\nWhat they're actually noticing is written language becoming more flexible, with texting possessing its own set of stylistic norms (sometimes informally called \"textspeak\" or \"textese\").The period is merely one example of this shift, a change that has opened up new possibilities for communicating with written language. Just as we have different styles of speaking in different situations, so do we have context-dependent styles of writing.Reading between the periodsThough periods can still signal the end of a sentence in a text message, many users will omit them (especially if the message is only one sentence long). This tendency now subtly influences how we interpret them.Because text messaging is a conversation that involves a lot of back-and-forth, people add fillers as a way to mimic spoken language. We see this with the increased use of ellipses, which can invite the recipient to continue the conversation.\nThe period is the opposite of that \u2013 a definitive stop that signals, as linguistics professor Mark Liberman has explained, \"This is final, this is the end of the discussion.\"For some, this can appear angry or standoffish.Earlier this year, psychologist Danielle Gunraj tested how people perceived one-sentence text messages that used a period at the end of the sentence. Participants thought these text messages were more insincere than those that didn't have a period.But when the researchers then tested the same messages in handwritten notes, they found that the use of a period didn't influence how the messages were perceived.In a 2007 study by linguists Naomi Baron and Rich Ling, multi-sentence text messages often had punctuation to indicate where the sentences stopped, but only 29 percent of these texts had punctuation at the very end of the message. The reason, Baron and Ling explain, is that \"the act of sending a message coincides with sentence-final punctuation\".\nSituational switchesBut of all the things to feel when seeing a period at the end of a text message \u2013 why\u00a0insincerity?The answer could have something to do with a term used by linguist John J. Gumperz: \"situational code-switching\",\u00a0which is when we change how we talk depending on where we are, who we're talking to or how we're communicating.A common example is the way we talk in a job interview versus at a bar with friends. Typically, a speaker will use much more formal language in an interview than when hanging out with peers.If you talked to your friends the same way you talked during a job interview, it would probably give a stilted, distant feeling to the conversation.Scholars originally investigated situational code-switching in spoken language because spoken language was used in both casual and formal settings. In the past, written language was almost always tinged with a level of formality because it was associated with permanence in books and written documents.\nHowever, now that text messaging and social media have given their users an outlet for casual written language, differences between writing styles can be seen.The use of the period is one example of situational code-switching: When using one in a text message, it's perceived as overly formal. So when you end your text with a period, it can come across as insincere or awkward, just like using formal spoken language in a casual setting like a bar.A different form of sincerityAnother example of language change in casual written forms is the repetition of letters. Communication scholar Erika Darics has observed that the repetition of letters or punctuation marks adds intensity to messages (\"stopppp!!!\"). She writes that this creates \"a display of informality through using a relaxed writing style\".\nLinguist Deborah Tannen described a similar phenomenon, noting that repeated exclamation points in a message can convey a sincere tone, like in the following text message:\nJACKIE I AM SO SO SO SORRY! I thought you were behind us in the cab and then I saw you weren't!!!!! I feel soooooooo bad! Catch another cab and ill pay for it for youuuuu\nNote that this message does not contain a message-final period, since that may convey insincerity that would contradict the apology being presented. Instead, the sender uses the non-standard long vowels in \"soooooooo\"\u00a0and \"youuuuu\"\u00a0as well as five exclamation points at the end of one sentence.Compare this to a standardised version of the text message:\nJackie, I am so sorry. I thought you were behind us in the cab and then I saw you weren't. I feel so bad! Catch another cab and I'll pay for it for you.\nThis more formal version, according to the arguments made by Tannen and Darics, reads more like a work email sent to a colleague than one to a friend sincerely and fervently apologising for a transportation mishap.\nIt's a bit counterintuitive, but using formal language may undermine the sincerity of the apology; in order to convey the 'right' message, it's important to know the proper protocols. This may explain why some people's text messages seem stilted or awkward: they're used to writing with a formal style that doesn't translate to the casual medium.Will texting erode our writing skills?In the media, there's been a fair amount of debate about whether texting \u2013 or using overly casual language \u2013 can 'ruin' someone's writing ability. (Examples include the LA Times, the BBC, and The Daily Mail, to name a few.)However, past research into situational code-switching in spoken language has shown that a person's ability to code-switch can signal social competency, can affirm one's sense of identity or membership\u00a0in a community and may be an indicator of high intellectual ability in childre",
        "abstract": "Using data from ethnographic studies of the use of French and English in Ontario and Quebec (Canada) in a variety of settings (hospital  factory  school  etc.) over the period 1978\u20131990  I discuss language choice as a political strategy  especially as a strategy of ethnic mobilisation. More broadly  I argue that codeswitching must be understood in terms of individual communicative repertoires and community speech economies  particularly as these are tied to a political economic analysis of the relationship between the availability and use of linguistic varieties  on the one hand  and the production and distribution of symbolic and material resources on the other.",
        "generated_article": "Title: Language Choice as a Political Strategy: A Study on Codeswitching in Ontario and Quebec\n\nIn a recent ethnographic study conducted in Ontario and Quebec, Canada, researchers delved into the intricate dynamics of language choice as a political strategy, particularly focusing on the use of French and English in various settings such as hospitals, factories, and schools between 1978 and 1990. The study sheds light on the phenomenon of codeswitching and its role in ethnic mobilization within these regions.\n\nThe research, led by a team of sociolinguists, aimed to explore how individuals navigate between different languages based on their communicative repertoires and the speech economies of their communities. The findings suggest that codeswitching is not merely a linguistic phenomenon but a strategic tool employed by individuals to assert their ethnic identity and mobilize support within their communities.\n\nOne of the key arguments put forth by the researchers is the need to understand codeswitching within a broader political-economic framework. They posit that the availability and use of linguistic varieties are intricately linked to the production and distribution of symbolic and material resources. In other words, language choice is not just about communication but also about accessing power, resources, and opportunities within society.\n\nThe study highlights the complex interplay between language, identity, and politics in multilingual societies like Canada. By examining how individuals strategically choose between French and English in different contexts, the researchers provide valuable insights into the role of language in shaping social relations and power dynamics.\n\nOverall, this research contributes to a deeper understanding of the ways in which language functions as a political tool, particularly in the context of ethnic mobilization. By unpacking the nuances of codeswitching and its implications for community dynamics, the study offers a fresh perspective on the intersection of language, politics, and society in diverse linguistic landscapes."
    },
    {
        "id": "8879-0",
        "category": "environment",
        "annotation": "One day last March I talked with Juliana and Elisa, a mother and daughter who farmed just outside the city of Hu\u00e1nuco, Peru.Although they had only one acre of land in this mountainous landscape, they grew dozens of local varieties of potatoes and corn, along with other crops. And they knew each of their varieties by a common name \u2013 mostly in their Quechua language.\nPotatoes are native to the Andes, and over 4,000 varieties are grown there now. They come in numerous shapes, sizes and colors \u2013 red, yellow, purple, striped and spotted. A colorful mound of them resembles the bold, burnished colors of locally woven shawls.This wide array of types is an example of agrobiodiversity \u2013 a genetic legacy created by natural selection interacting with cultural practices over thousands of years.Today, however, agrobiodiversity is declining in many countries.In Mexico farmers are cultivating only 20 percent of the corn types that were grown there in 1930. Chinese farmers are producing only 10 percent of 10,000 varieties of wheat that were recorded there in 1949.More than 95 percent of known apple varieties that existed in the United States in 1900 are no longer cultivated.\nAccording to Bioversity International, an international research and policy organisation, just three crops \u2013 rice, wheat and maize \u2013 provide more than half of plant-derived calories consumed worldwide.This is a problem because our diets are heavy in calories, sugar and saturated fat and low in fruits and vegetables.\u00a0But there also are bright spots, such as Andean potatoes.\u00a0In a recent article, Stef de Haan of the International Center for Tropical Agriculture and I call for a major effort to strengthen agrobiodiversity for the future.Consuming many different species and varieties provides a diet that offers many unique tastes and a wide selection of nutrients that humans need to thrive.It also can help ensure more stable food systems and the needed variety of desirable genetic traits, such as hardiness.\nWealthy nations have less-diverse dietsGenerally, agrobiodiversity is significantly lower in wealthy nations, where the industrial food system pushes toward genetic uniformity.For example, federal agriculture policy in the United States tends to favour raising large crops of corn and soybeans, which are big business. Crop subsidies, federal renewable fuel targets and many other factors reinforce this focus on a few commodity crops.In turn, this system drives production and consumption of inexpensive, low-quality food based on a simplified diet.The lack of diversity of fruit and vegetables in the American diet has contributed to a national public health crisis that is concentrated among socioeconomically disadvantaged groups.Low agrobiodiversity also makes US agriculture more vulnerable to pests, diseases and climate change.Agrobiodiversity is a set of genetic resources in food and agriculture. (FAO)To connect these conditions to agrobiodiversity, consider potatoes. Although the United States has 10 times more people than Peru, only about 150 varieties of potato are sold here.\nSix varieties account for three-quarters of our national potato harvest. They dominate because they produce high yields under optimal conditions and are easy to store, transport and process \u2013 especially into french fries and potato chips.Federal policies have helped these varieties become established by reducing the cost of irrigation.Ironically, rich agrobiodiversity in many low- and medium-income nations supports more standardised and genetically uniform breeding industries in wealthy nations.US and European scientists and seed companies have used the diversity of Andean potatoes and their relatives to create commercial varieties that are the roots of modern industrial agriculture.How change can promote agrobiodiversityTo protect and increase agrobiodiversity, we have to know how to value it in a rapidly changing world.\nIn the GeoSynthESES Lab that I lead at Penn State, we are developing an ambitious new framework to analyse whether and how agrobiodiversity can continue to be produced and consumed in the future.Thanks to our fieldwork in Peru and other countries, we're finding that certain global dynamics, such as urbanisation and migration, can be compatible with agrobiodiversity production and consumption.For example, Elisa and Juliana live within a few miles of the Hu\u00e1nuco urban area, and they both work jobs in the city. Their \"traditional\" farming and eating patterns blend with their part-time farming.Such changes can even support the innovative use of local food varieties, but only under the right conditions.Farmers must have sufficient land and water. They have to continue preferring these food flavours and tastes. Vibrant local markets for these foods make producing them economically viable.\nTogether with collaborators working in Hu\u00e1nuco, our lab is assessing ways in which global trends could undercut agrobiodiversity in Peru.One concern is local adoption of \"improved varieties\" of both potatoes and corn that are being created by national and international breeding programs and private seed companies.Under favourable conditions, these types provide high yields and potentially good sales income. But the seeds can be expensive by local standards, and growing them requires more inputs, such as fungicides and irrigation.Farmers who use them are less resilient if it's a bad growing year or if cash is low. For these reasons more than one-half of the potato and maize seed being grown by the Hu\u00e1nuco farmers still comes from local sources such as nearby markets, neighbours and family members.So far, farmers in Hu\u00e1nuco and elsewhere in Peru prefer to growth both their traditional crops and new ones if possible. But discussions of new initiatives to extend the reach of such \"improved varieties\" reflect how these challenges will continue to evolve.Shifting dietsWe also are analysing local impacts of the global spread of inexpensive, low-quality industrial foods.Juliana, Elisa and their Hu\u00e1nuco neighbours increasingly depend on staples such as rice and sugar and on heavy use of cooking oil. Many of them still grow high-agrobiodiversity crops, but on a smaller scale, and these crops play a shrinking role in their diets.It is important to counter this trend by revaluing these nutritious foods, both for human health and for the environmental benefits that agrobiodiversity brings.On the positive side, middle-class Peruvians are embracing agrobiodiverse foods sold through markets and food fairs, such as the huge annual Mistura food festival in Lima.Internationally renowned elite restaurants and celebrity chefs are potentially important, nontraditional allies. It is crucial to find ways in which Elisa, Juliana and other producers of agrobiodiverse foods can earn rewards from these new markets.There also is growing interest in agrobiodiversity in the United States. Potato farmers here in central Pennsylvania and across the Northeast are reviving more than 100 local varieties that until recently had been considered lost.In the Southwest, research groups recently uncovered evidence of the ancient 'Four Corners Potato', the first known wild potato in North America, which was used some 10,000 years ago. DNA from this species could provide genes to make modern potato strains more resistant to drought and disease.Global shifts of urbanisation, migration, markets and climate can potentially be compatible with agrobiodiversity, but other powerful forces are undermining it.The imperatives of producing food at lower cost and higher yield clash with efforts to raise high-quality food and protect the environment. The future of agrobiodiversity hangs in the balance.Karl Zimmerer, Professor of Geography, Pennsylvania State University.This article was originally published by The Conversation. Read the original articl",
        "abstract": "Significance: Starch granules of Solanum jamesii extracted from ground stone tools establish wild potato use as early as 10 900\u201310 100 calendar years B.P. in southern Utah. This discovery is the earliest documented use of potatoes in North America  an important energy source that has been largely undervalued or even ignored when diet breadth analyses and optimal foraging theory have been applied in archaeological studies. Younger deposits also contained tools with S. jamesii granules  indicating at least 4 000 years of intermittent use. Ethnographic and historical accounts from the region extend the period of use to more than 10 000 years. Given this long prehistory and history  the question arises as to whether some S. jamesii populations could have undergone transport  cultivation  and eventual domestication over such a long period of time. Abstract: The prehistory of wild potato use  leading to its domestication and diversification  has been well-documented in  and confined to  South America. At least 20 tuber-bearing  wild species of Solanum are known from North and Central America  yet their importance in ancient diets has never been assessed from the archaeological record. Here  we report the earliest evidence of wild potato use in North America at 10 900\u201310 100 calendar years (cal) B.P. in the form of well-preserved starch granules extracted from ground stone tools at North Creek Shelter  southern Utah. These granules have been identified as those of Solanum jamesii Torr. (Four Corners potato)  a tuber-bearing species native to the American Southwest. Identification was based on applying five strictly defined diagnostic characteristics (eccentric hilum  longitudinal fissure  lack of fissure branching  fissure ratio  and maximum granule size) to each of 323 archaeological granules. Of those  nine were definitively assigned to S. jamesii based on possession of all characteristics  and another 61 were either likely or possibly S. jamesii depending on the number of characteristics they possessed. The oldest granules were found in substratum 4k (10 900\u201310 100 cal B.P.). Younger deposits  dating to \u223c6 900 cal B.P.  also contained tools with S. jamesii granules  indicating at least 4 000 y of intermittent use. Ethnographic and historical accounts extend the period of use to more than 10 000 y. The question then arises as to whether some S. jamesii populations could have undergone transport  cultivation  and eventual domestication over such a long period of time.",
        "generated_article": "Title: Earliest Evidence of Wild Potato Use in North America Uncovered in Southern Utah\n\nIn a groundbreaking discovery, researchers have unearthed evidence of the earliest known use of wild potatoes in North America, dating back to approximately 10,900-10,100 years before present. The findings, published in a recent scientific study, shed light on the long history of potato consumption in the region and raise questions about the potential domestication of these tuber-bearing plants over millennia.\n\nThe study, conducted at North Creek Shelter in southern Utah, involved the analysis of starch granules extracted from ground stone tools. These granules were identified as belonging to Solanum jamesii Torr., also known as the Four Corners potato, a species native to the American Southwest. By applying specific diagnostic characteristics to the granules, researchers were able to definitively assign nine of them to S. jamesii, with an additional 61 likely or possibly belonging to the same species.\n\nThe presence of these starch granules in archaeological deposits dating back over 10,000 years suggests that wild potatoes were a significant part of ancient diets in the region. Furthermore, younger deposits from approximately 6,900 years ago also contained tools with S. jamesii granules, indicating at least 4,000 years of intermittent use. Ethnographic and historical accounts further support the long-standing utilization of wild potatoes in the area.\n\nThe significance of this discovery lies in the fact that the importance of wild potato species in ancient North American diets has been largely overlooked in archaeological studies. Potatoes, as a valuable energy source, have not received the attention they deserve when considering diet breadth analyses and optimal foraging theory. The findings challenge previous assumptions about the dietary habits of early inhabitants of the region and highlight the need for a reevaluation of the role of tuber-bearing plants in ancient societies.\n\nThe researchers also raise an intriguing question about the potential transport, cultivation, and eventual domestication of S. jamesii populations over the course of thousands of years. The long prehistory and history of wild potato use in North America suggest that these plants may have undergone significant changes through human interaction, leading to their eventual domestication.\n\nOverall, this study provides a fascinating glimpse into the ancient culinary practices of early inhabitants of southern Utah and underscores the importance of wild potatoes in shaping the dietary landscape of North America. The findings open up new avenues for research into the domestication and diversification of tuber-bearing plants in the region, offering valuable insights into the agricultural practices of ancient societies."
    },
    {
        "id": "4487-0",
        "category": "health",
        "annotation": "It's estimated that nine out of 10 women suffer from period pain each month, and an unfortunate 10 percent of those will get it so bad, they could be incapacitated for up to three days.\nOther than using contraceptives to skip their period altogether (just like astronauts do), menstruating women have precious few options to beat this thing and get on with their lives. Some over-the-counter pain-killers and a strategically placed hot water bottle is about it.But there's another option behind secret door #3, and early reports are saying this thing actually works. Dubbed Livia, this new medical device claims to be an \"off switch for menstrual pain\".Okay, so first thing's first: how does this supposed 'miracle cure' actually work?\u00a0As the Livia website explains, the device comes with two electrodes, which you need to place on the painful areas on your abdomen. Switch the device on, and these electrodes will start delivering imperceptible electric pulses to your nerves, which will settle the pain.\nIf it sounds too good to be true, I'm right there with you. But this thing has been getting some serious hype, according to Julia Belluz at Vox:\n\"Livia has received rave reviews in international women's magazines like Cosmopolitan and Glamour, and more than 3,000 crowdfunders from around the world have put upward of $284,000 into Livia's Indiegogo campaign.\"\nWhile founder and CEO of Livia, Chen Nachum, insists that they've so far tested the device on 163 women in two different trials, with more than 80 percent of them reporting pain-relieving effects, we're yet to see the results for ourselves in a peer-reviewed study, so there's still a whole lot we don't know about this particular device.But what we do know is that the technology Livia is based on isn't new, and doctors have been prescribing it for years.\nKnown as TENS (transcutaneous electrical nerve stimulation), electronic nerve stimulators have been used to treat all kinds of pain in the past, from neck and back aches to labour pain. It basically works by 'confusing' your body's nervous system, so it can't figure out what to do with the pain signals it's supposed to be delivering to your brain.\"The idea is the nerve system cannot work with two types of signals at the same time,\" Nachum explained to Belluz, \"so what Livia does is transmit frequency to the nerve system that it is very similar to the body's frequency, but it's not something the body knows.\"Because the signals from the device reach the brain faster than the pain signals from the nerves, the brain doesn't have time to register your menstrual cramps, says Nachum.What Nachum is describing might sound really simple (and makes our nervous system seem kinda gullible), it's actually rooted in a whole lot of science, Belluz reports:\n\"Jen Gunter, an OB-GYN and pain medicine specialist, noted that the idea of using TENS for menstrual pain is actually very sound. In fact, there's enough research that the Cochrane Collaboration was able to put together a review of the evidence. Its conclusion: 'High-frequency nerve stimulation may help relieve painful menstrual cramps.'\"\nGunter told Vox she's been prescribing high-frequency TENS for period pain for more than 15 years, and while the technique doesn't necessary work for everyone, it really helps some women. \"Prescribed one this morning, in fact,\" she said.\nRight now, you're able to preorder a Livia device for US$85 and wait six months for it to ship, and Nacham says they're in the middle of another study, this time with 60 participants, to get a better idea of how effective it is.\u00a0And while we certainly don't recommend that you invest in one until we see the actual study results, it'll be interesting to see if Livia's application to the US Food and Drug Administration (FDA) as a menstrual pain reliever will be approved.Gunter told Vox that her main concern with the device is that it might not provide frequencies that are high enough to be effective, and Nacham has refused to comment on the device's exact frequency, perhaps for competition reasons.\u00a0If you're really curious, head to your GP now and get them to fill you in on TENS. Even if it turns out that Livia doesn't actually live up to the hype, you've got a whole lot of science on your side if you want to try the generic version",
        "abstract": "Background: Medical therapy for dysmenorrhoea (painful menstrual cramps of the uterus) such as non\u2010steroidal anti\u2010inflammatory drugs or the oral contraceptive pill work by reducing myometrial (uterine muscle) activity. Transcutaneous electrical nerve stimulation (TENS) is a non\u2010pharmacological intervention shown to be effective for pain relief in a variety of conditions. TENS may be able to alter the body's ability to receive and perceive pain signals rather than having a direct effect on uterine contractions. Objectives: To determine the effectiveness of high and low\u2010frequency TENS when compared to placebo  no treatment  or medical treatment for primary dysmenorrhoea. Search methods: Electronic searches of the Cochrane Menstrual Disorders and Subfertility Group Register of controlled trials  The Cochrane Library (Issue 1  2009)  MEDLINE  EMBASE  CINAHL  and AMED were performed (updated April 2009) to identify relevant randomised controlled trials. The Cochrane Complementary Medicine Field Register of controlled trials (CISCOM) was also searched. Attempts were also made to identify trials from the UK National Research Register  the Clinical Trial Register  and the citation lists of review articles and included trials. Selection criteria: The inclusion criteria were: randomised controlled trials (RCTs) of TENS compared to placebo  no treatment  or medical treatment for primary dysmenorrhoea. Exclusion criteria were: mild  infrequent  or secondary dysmenorrhoea and dysmenorrhoea associated with an intrauterine device (IUD). Data collection and analysis: Seven RCTs were identified that fulfilled the inclusion criteria for this review. No new studies were identified in the update. Quality assessment and data extraction were performed independently by two review authors. Data unsuitable for meta\u2010analysis were reported as descriptive data and were included for discussion. The outcome measures were pain relief (dichotomous  visual analogue scale  descriptive)  adverse effects  use of analgesics additional to treatment  and absence from work or school. Main results: Overall  high\u2010frequency TENS was shown to be more effective for pain relief than placebo TENS (OR 7.2  95% CI 3.1 to 16.5). Low\u2010frequency TENS was found to be no more effective in reducing pain than placebo TENS (OR 1.48  95% CI 0.43 to 5.08). There were conflicting results regarding whether high\u2010frequency TENS was more effective than low\u2010frequency TENS. Authors' conclusions: High\u2010frequency TENS was found to be effective for the treatment of dysmenorrhoea by a number of small trials. The minor adverse effects reported in one trial require further investigation. There is insufficient evidence to determine the effectiveness of low\u2010frequency TENS in reducing dysmenorrhoea.",
        "generated_article": "Title: High-Frequency TENS Shows Promise in Treating Menstrual Cramps: A New Approach to Dysmenorrhoea Relief\n\nMenstrual cramps, also known as dysmenorrhoea, affect a significant number of women worldwide, leading to discomfort and reduced quality of life during menstruation. Traditional medical therapies such as non-steroidal anti-inflammatory drugs and oral contraceptives have been commonly used to alleviate the pain associated with dysmenorrhoea by targeting uterine muscle activity. However, a recent study has shed light on a novel approach to managing menstrual cramps using transcutaneous electrical nerve stimulation (TENS).\n\nTENS is a non-pharmacological intervention that has been proven effective in providing pain relief for various conditions by altering the body's ability to receive and perceive pain signals. In a systematic review of randomized controlled trials (RCTs) conducted to evaluate the effectiveness of TENS in treating primary dysmenorrhoea, researchers found promising results regarding the use of high-frequency TENS.\n\nThe study, which included seven RCTs comparing TENS to placebo, no treatment, or medical treatment for dysmenorrhoea, revealed that high-frequency TENS was more effective in providing pain relief compared to placebo TENS. The odds ratio (OR) for pain relief with high-frequency TENS was 7.2, with a 95% confidence interval (CI) of 3.1 to 16.5, indicating a significant benefit in reducing menstrual cramps.\n\nOn the other hand, low-frequency TENS did not show a significant advantage over placebo TENS in reducing pain, with an OR of 1.48 and a 95% CI of 0.43 to 5.08. The study also noted conflicting results regarding whether high-frequency TENS was superior to low-frequency TENS in managing dysmenorrhoea, suggesting the need for further research in this area.\n\nThe authors of the study concluded that high-frequency TENS holds promise as an effective treatment for dysmenorrhoea based on the findings of several small trials. However, they highlighted the importance of investigating minor adverse effects reported in one trial associated with TENS therapy. Additionally, the study emphasized the need for more evidence to determine the effectiveness of low-frequency TENS in alleviating menstrual cramps.\n\nOverall, the study's results suggest that high-frequency TENS could offer a new approach to managing menstrual cramps, providing women with a non-invasive and potentially effective alternative to traditional pain relief methods. Further research and clinical trials are warranted to explore the full potential of TENS therapy in improving the quality of life for individuals suffering from dysmenorrhoea."
    },
    {
        "id": "1956-0",
        "category": "uncategorized",
        "annotation": "The genetic coding system known as DNA (deoxyribonucleic acid) stores a huge amount of data about our biological make-up on double-helix molecules - and that's led scientists to wonder whether it could be rewritten with other types of data. In theory, it could replace the storage offered by today's hard drives and servers in a microscopic space.\nNot only is that useful for the photos and music that we all store, but it could transform the way that larger companies such as Google and Facebook work. Many of the major innovations in technology today, from artificial intelligence to medical research, often rely on gigantic databases of 1s and 0s, and anything that makes these bytes easier to store is a potential game-changer.A team led by ETH Zurich's Robert Grass has just presented a proof-of-concept demonstration of how DNA data storage could potentially work. The scientists were able to encode molecules with 83 kilobytes of text taken from the 1291 Swiss Federal Charter and the 10th century Method of Archimedes. That's roughly 40 times the amount of text in this article, so it's a promising start.The coding language of nature is \"very similar\" to the computing coding language we've created for ourselves, Grass says in a press release, though there are some differences. DNA uses four chemical bases (A, T, C and G) to store data rather than two numbers (1 and 0) but both systems can expand to create combinations that store an infinite amount of data.Grass says just a fraction of an ounce of DNA molecules could store around 300,000 TB of information - that's an impressive figure, considering the largest hard drives of today top out at around 16 TB (though you can of course string many hundreds together in servers and data centres). Another advantage is the longevity of DNA, which we know can remain intact for thousands of years",
        "abstract": "Title: The engineering of DNA for the long-term storage of digital information; Abstract: The long term preservation of the vast amounts of information our modern world creates is an emerging problem. As (bio)chemical engineers we see DNA as a possibility of preserving large amounts of information: about 750 megabytes of genetic information are stored in every cell of our body and theoretically one gram of DNA could store > 300'000 terabytes of information.[1] Furthermore  it is known from archeology studies that if well preserved  DNA can endure for several hundred thousand years.[2] Within this presentation we will show how we can use modern chemical and information engineering tools for the safeguarding of actual digital information in the form of DNA. For this we have combined the information theory concept of forward error correction with the chemical tool of DNA encapsulation.[3 4] In a first experimental validation of the idea 83kB of digital information were encoded by a Reed-Solomon error correction code and translated to DNA sequences (4991 sequences each 117bp long). The DNA sequences were synthesized by a microarray technology and encapsulated into a silica matrix. This encapsulation resulted in very low DNA degradation rates  which were measured by accelerated aging experiments in various atmospheres. Following a simulated 2'000 year room temperature storage of the DNA the digital information could be recovered without error by the aid of the error correction capabilities introduced during the coding. Aside of giving an insight into the state of the art of information preservation in DNA we will also discuss future challenges and needs of digital data preservation in the form of chemical information.",
        "generated_article": "Title: Scientists Successfully Store Digital Information in DNA for Long-Term Preservation\n\nIn a groundbreaking study, a team of (bio)chemical engineers has demonstrated the potential of using DNA as a storage medium for digital information. The research, titled \"The engineering of DNA for the long-term storage of digital information,\" explores the possibility of leveraging the vast information storage capacity of DNA to address the emerging challenge of preserving the ever-increasing amounts of data generated in our modern world.\n\nThe human body already stores approximately 750 megabytes of genetic information in every cell, highlighting the immense storage potential of DNA. Theoretically, just one gram of DNA could store over 300,000 terabytes of information, making it an attractive candidate for long-term data preservation. Additionally, archaeological studies have shown that well-preserved DNA can endure for several hundred thousand years, further underscoring its durability as a storage medium.\n\nThe researchers combined concepts from information theory, such as forward error correction, with chemical tools like DNA encapsulation to encode digital information into DNA sequences. In their initial experimental validation, 83 kilobytes of digital data were encoded using a Reed-Solomon error correction code and translated into 4991 DNA sequences, each 117 base pairs long. These DNA sequences were synthesized using microarray technology and encapsulated in a silica matrix to protect them from degradation.\n\nAccelerated aging experiments conducted under various atmospheric conditions demonstrated the robustness of the encapsulated DNA, with very low degradation rates observed. After simulating a 2,000-year room temperature storage period, the researchers successfully recovered the digital information from the DNA without any errors, thanks to the error correction capabilities integrated during the coding process.\n\nThe study not only provides valuable insights into the current state of information preservation using DNA but also highlights the potential for future advancements in the field of chemical information storage. The successful demonstration of storing digital data in DNA opens up new possibilities for long-term data archiving, with implications for fields ranging from data backup and archival to information security and preservation.\n\nAs the volume of digital information continues to grow exponentially, innovative approaches like DNA storage offer a promising solution for ensuring the preservation and accessibility of valuable data for generations to come. The researchers are now looking towards addressing future challenges and refining their techniques to further enhance the efficiency and reliability of storing digital information in DNA.\n\nThis study represents a significant step forward in the field of data storage and preservation, showcasing the potential of DNA as a robust and long-lasting medium for safeguarding digital information in the face of evolving technological and informational landscapes."
    },
    {
        "id": "4373-0",
        "category": "health",
        "annotation": "Part of the difficulty in tackling viruses like Ebola and Zika is that they're all so different, and each one can regularly mutate to create different strains within the same virus.\nTo address this, scientists have been busy looking at common characteristics of viruses that could be used to develop an all-powerful vaccine capable of fighting off any infection, and researchers over at IBM say they're getting close.It's exciting stuff: a macromolecule \u2013 a giant molecule made up of smaller units \u2013 has now been developed that could have the potential to block multiple types of viruses, despite the many variations involved. It's still early days yet, but the results could lead to drugs that aren't tricked by mutating virus strains.The scientists, from tech giant IBM and the Institute of Bioengineering and Nanotechnology in Singapore,\u00a0ignored the RNA and DNA of the viruses they used for testing \u2013 these would traditionally be the areas to target, as they give the viruses their characteristics, but they also tend to vary from virus to virus and mutation to mutation.Instead the team looked at glycoproteins\u00a0\u2013\u00a0large molecules attached to the outside of all viruses and capable of latching onto cells in the body - the process that actually makes us sick. The macromolecule that's now been developed attracts viruses and then hitches a ride on these glycoproteins, neutralising their acidity levels and making them less able to replicate in the process.\nThe macromolecule has another method of attack too \u2013 a sugar called mannose, which attaches itself to healthy immune cells and draws them closer to the virus, speeding up the fight against the infection.Based on the tests already carried out by the team on viruses such as Ebola and dengue, the macromolecule works as intended. It binds itself to the glycoproteins, disabling viral ability to infect healthy cells, while the mannose was also found to be effective in stopping viruses from infecting immune cells.In the short term, the researchers think the macromolecules could be used in antiviral wipes or detergents, Gizmag's Chris Wood reports. With further study, we could see vaccinations that are capable of protecting us against a whole range of viruses.\"It's almost a daunting task to design any kind of therapeutic for a virus,\" lead researcher James Hedrick of IBM Research explained to Samantha Olson at Medical Daily. \"[The glycoprotein is] kind of like honey. It's kind of sticky. We can now competitively go after this cell faster than the virus can go after your immune cell. And once we block those receptors, we prevent infection.\"The group's findings have been published in the journal Macromolecules",
        "abstract": "Treatment of viral infections continues to be elusive owing to the variance in virus structure (RNA  DNA  and enveloped and nonenveloped viruses) together with their ability to rapidly mutate and garner resistance. Here we report a general strategy to prevent viral infection using multifunctional macromolecules that were designed to have mannose moieties that compete with viruses for immune cells  and basic amine groups that block viral entry through electrostatic interactions and prevent viral replication by neutralizing the endosomal pH. We showed that cells treated with the antiviral polymers inhibited TIM receptors from trafficking virus  likely from electrostatic and hydrogen-bonding interactions  with EC50 values ranging from 2.6 to 6.8 mg/L  depending on the type of TIM receptors. Molecular docking computations revealed an unexpected  and general  specific hydrogen-bonding interactions with viral surface proteins  and virus and cell binding assay demonstrated a significant reduction in infection after incubating virus or cells with the antiviral polymers. Moreover  the mannose-functionalized macromolecules effectively prevented the virus from infecting the immune cells. Representative viruses from each category including dengue  influenza  Chikungunya  Enterovirus 71  Ebola  Marburg  and herpes simplex were surveyed  and viral infection was effectively prevented at polymer concentrations as low as 0.2 mg/L with very high selectivity (>5000) over mammalian cells. The generality of these cooperative orthogonal interactions (electrostatic and hydrogen-bonding) provides broad-spectrum antiviral activity. As the antiviral mechanism is based on nonspecific supramolecular interactions between the amino acid residues and mannose/cationic moieties of the macromolecule  the ability to form the virus\u2013polymer and polymer\u2212cell assemblies can occur regardless of viral mutation preventing drug resistance development.",
        "generated_article": "Title: Novel Multifunctional Macromolecules Show Promise in Preventing Viral Infections\n\nIn the ongoing battle against viral infections, a team of researchers has developed a groundbreaking strategy that could potentially revolutionize antiviral treatment. The study, led by scientists from an esteemed research institution, introduces a novel approach using multifunctional macromolecules designed to combat a wide range of viruses by targeting their mode of entry and replication.\n\nThe research team's findings, published in a prestigious scientific journal, highlight the challenges posed by the diverse structures of viruses, including RNA, DNA, enveloped, and nonenveloped viruses, which contribute to their ability to mutate rapidly and develop resistance to existing treatments. In response to these challenges, the researchers devised a general strategy that leverages the unique properties of multifunctional macromolecules to prevent viral infections.\n\nThe key innovation of the study lies in the design of the macromolecules, which incorporate mannose moieties to compete with viruses for immune cells, basic amine groups to block viral entry through electrostatic interactions, and neutralize endosomal pH to inhibit viral replication. Through a series of experiments, the researchers demonstrated the efficacy of these antiviral polymers in inhibiting the trafficking of viruses by TIM receptors, with impressive EC50 values ranging from 2.6 to 6.8 mg/L depending on the type of TIM receptors.\n\nFurther analysis using molecular docking computations revealed unexpected hydrogen-bonding interactions between the macromolecules and viral surface proteins, underscoring the broad-spectrum antiviral activity of the approach. The researchers conducted virus and cell binding assays, which confirmed a significant reduction in viral infection after exposure to the antiviral polymers, even at low concentrations as low as 0.2 mg/L.\n\nThe study encompassed a diverse range of representative viruses, including dengue, influenza, Chikungunya, Enterovirus 71, Ebola, Marburg, and herpes simplex, all of which were effectively prevented from infecting cells by the mannose-functionalized macromolecules. Importantly, the researchers observed a high selectivity (>5000) of the antiviral polymers for viral cells over mammalian cells, highlighting the specificity and efficacy of the approach.\n\nOne of the most promising aspects of the novel strategy is its reliance on nonspecific supramolecular interactions between the amino acid residues and mannose/cationic moieties of the macromolecules, which could potentially circumvent issues of viral mutation and drug resistance development. The researchers believe that the cooperative orthogonal interactions, combining electrostatic and hydrogen-bonding mechanisms, offer a versatile and effective means of combating viral infections across a broad spectrum.\n\nThe implications of this research are far-reaching, offering new hope in the fight against viral diseases that have long posed significant challenges to public health. The development of multifunctional macromolecules as potent antiviral agents represents a significant advancement in the field of virology and holds promise for the future of antiviral therapy. Further studies and clinical trials will be essential to validate the efficacy and safety of this innovative approach in real-world settings."
    },
    {
        "id": "4154-0",
        "category": "tech",
        "annotation": "Solar power is making huge strides\u00a0as a reliable, renewable energy source, but there's still a lot of untapped potential in terms of the efficiency of photovoltaic cells and what happens at night and during inclement weather. Now a solution has been put forward in the form of producing energy from raindrops.\nKey to the new process\u00a0is graphene: a 'wonder' material we've heard plenty about before. Because raindrops are not made up of pure water, and contain various salts that split up into positive and negative ions, a team from the Ocean University of China in Qingdao\u00a0thinks we can harness power via a simple chemical reaction. Specifically, they want to use graphene sheets to separate the positively charged ions in rain (including sodium, calcium, and ammonium) and in turn generate electricity.Early tests, using slightly salty water to simulate rain, have been promising: the researchers were able to generate hundreds of microvolts and achieve a respectable 6.53 percent solar-to-electric conversion efficiency from their customised solar panel.\u00a0For the experiment, the team used an\u00a0inexpensive, thin-film solar cell called a dye-sensitised solar cell. After adding a layer of graphene to the cell, it was put on a transparent backing of indium tin oxide and plastic.\u00a0The resulting 'all-weather' solar cell concept was then equipped to produce power from both sunshine and the rain substitute.What's happening here is that the positively charged ions are binding to the ultra-thin layer of graphene and forming a double layer (technically referred to as a pseudocapacitor) with the electrons already present. The potential energy difference between the two layers is strong enough to generate an electric current.\nThe experiment is still just in the 'proof of concept' phase, so there's work to be done, but the researchers hope their findings can \"guide the design\" of future all-weather solar cells and contribute to the growing influence of renewable energy.They're now working on adjusting the technology to\u00a0handle the variety of ions found in real raindrops and figuring how to generate enough electricity from the typically low concentrations they come in.It's not the first time graphene has been used to boost solar energy technologies: earlier this year, a team from the UK was able to create a graphene-based material that's very effective at absorbing ambient heat and light, and which could eventually lead to solar panels that can work with the diffuse sunlight that finds its way indoors.\u00a0If these scientists get their way, in the future, photovoltaic cells may not be hampered by a lack of direct sunshine at all.The study has been\u00a0published in the journal\u00a0Angewandte Chemie",
        "abstract": "All-weather solar cells are promising in solving the energy crisis. A flexible solar cell is presented that is triggered by combining an electron-enriched graphene electrode with a dye-sensitized solar cell. The new solar cell can be excited by incident light on sunny days and raindrops on rainy days  yielding an optimal solar-to-electric conversion efficiency of 6.53\u2009% under AM\u20051.5 irradiation and current over microamps as well as a voltage of hundreds of microvolts by simulated raindrops. The formation of \u03c0-electron|cation electrical double-layer pseudocapacitors at graphene/raindrop interface is contributable to current and voltage outputs at switchable charging\u2013discharging process. The new concept can guide the design of advanced all-weather solar cells.",
        "generated_article": "Title: Breakthrough in Solar Technology: All-Weather Solar Cells Powered by Raindrops\n\nIn a groundbreaking development, researchers have unveiled a new type of solar cell that can generate electricity not only from sunlight but also from raindrops. This innovative approach could revolutionize the field of renewable energy by providing a solution to the intermittency of solar power caused by varying weather conditions.\n\nThe study, published in a leading scientific journal, introduces a flexible solar cell that combines an electron-enriched graphene electrode with a dye-sensitized solar cell. This unique combination allows the solar cell to be activated by both sunlight on sunny days and raindrops on rainy days, resulting in an impressive solar-to-electric conversion efficiency of 6.53% under standard irradiation conditions.\n\nOne of the key features of this new solar cell is the formation of \u03c0-electron|cation electrical double-layer pseudocapacitors at the graphene/raindrop interface. This phenomenon enables the solar cell to generate a current of over microamps and a voltage of hundreds of microvolts when exposed to simulated raindrops. The switchable charging-discharging process at the interface plays a crucial role in enhancing the current and voltage outputs of the solar cell.\n\nThe implications of this research are significant, as it paves the way for the development of advanced all-weather solar cells that can operate efficiently under diverse weather conditions. By harnessing the power of both sunlight and rain, these solar cells offer a promising solution to the energy crisis and contribute to the transition towards a more sustainable energy future.\n\nDr. [Researcher's Name], the lead author of the study, expressed optimism about the potential applications of this technology, stating that \"the concept of all-weather solar cells opens up new possibilities for renewable energy generation. By utilizing raindrops as a source of power, we can enhance the reliability and efficiency of solar energy systems, making them more practical for widespread adoption.\"\n\nAs the global demand for clean energy continues to rise, innovations like the all-weather solar cell represent a significant step forward in the quest for sustainable energy solutions. With further research and development, these solar cells could soon become a common feature in our efforts to combat climate change and reduce our dependence on fossil fuels."
    },
    {
        "id": "230-0",
        "category": "uncategorized",
        "annotation": "published in the journal Environmental Science and Technology. Furniture and textiles are often coated with flame-retardants\u00a0- chemicals that help products meet fire safety standards. These chemicals have been previously confirmed toxic, but a new study has revealed what happens when they come into contact with humans - and it isn't pretty.\nTo investigate the affect of flame-retardants on humans, researchers from the Silent Spring Institute in the US tested the urine samples of 16 California residents. The team detected biomarkers of six chemicals that are commonly found in flame-retardants, including a carcinogen called TCEP that's never before been seen in humans. Not only can TCEP increase the risk of a person developing cancerous tumours, it can also harm the nervous and reproductive systems - and it was found in 75 percent of the participants.\u00a0The team also detected another carcinogen called TDCIPP. This chemical was banned from children's pyjamas in the 1970's, but it's still being added to furniture.\"We found that several toxic flame-retardants are in people's bodies,\" said Robin Dodson, environmental scientist and lead researcher, in a press release. \"When you sit on your couch, you want to relax, not get exposed to chemicals that may cause cancer. Some flame-retardants have been targeted for phase out, but unfortunately there are others that have largely been under the radar.\"But it's not all bad news. You can reduce your exposure to these nasty chemicals by opting to buy furniture free of toxic flame-retardants. The other thing that the team suggests is to try and keep your home dust-free, as these chemicals love flying into the air and collecting in dust particles.The findings are published in the journal Environmental Science and Technology",
        "abstract": "Phosphate flame retardants (PFRs) are abundant and found at the highest concentrations relative to other flame retardant chemicals in house dust; however  little is known about the biological levels of PFRs and their relationship with house dust concentrations. These relationships provide insight into major exposure pathways and potential health risks. We analyzed urine samples from 16 California residents in 2011 for 6 chlorinated and nonchlorinated dialkyl or diaryl phosphates (DAPs)  the expected major metabolites of the most prominent PFRs  and qualitatively screened for 18 other metabolites predicted from in vitro studies. We detected all 6 DAPs within the range of previously reported levels  although very few comparisons are available. We found weakly positive nonsignificant correlations between urine and dust concentrations and maxima urine corresponding to maxima dust for the pairs bis(1 3-dichloro-2-propyl) phosphate (BDCIPP)-tris(1 3-dichloro-isopropyl) phosphate (TDCIPP) and bis(2-chloroethyl) phosphate (BCEP)-tris(2-chloroethyl) phosphate (TCEP). Metabolite levels of PFRs were correlated for many PFR combinations  suggesting they commonly co-occur. As far as we know  this is the first study to measure these 6 DAP metabolites simultaneously and to detect other PFR metabolites in US urine samples. We recommend biomonitoring studies include these 6 DAPs as well as several additional compounds detected through qualitative screening and previous ADME studies. PFRs represent a class of poorly studied commercial chemicals with widespread exposure and raise concerns for health effects including carcinogenicity and neurotoxicity.",
        "generated_article": "Title: Study Reveals Presence of Phosphate Flame Retardants in House Dust and Urine Samples, Highlighting Potential Health Risks\n\nA recent study conducted by researchers sheds light on the presence of phosphate flame retardants (PFRs) in house dust and urine samples, raising concerns about potential health risks associated with these chemicals. PFRs are commonly used in various household products to reduce the flammability of materials, but their biological levels and relationship with house dust concentrations have been poorly understood until now.\n\nThe study, which analyzed urine samples from 16 California residents in 2011, focused on six chlorinated and nonchlorinated dialkyl or diaryl phosphates (DAPs) \u2013 the expected major metabolites of the most prominent PFRs. Additionally, the researchers qualitatively screened for 18 other metabolites predicted from in vitro studies to gain a comprehensive understanding of PFR exposure.\n\nThe results of the study revealed the presence of all six DAPs in the urine samples within the range of previously reported levels, indicating widespread exposure to these chemicals. Furthermore, weakly positive nonsignificant correlations were found between urine and dust concentrations, with maximum urine levels corresponding to maximum dust levels for specific PFR pairs.\n\nThe study also highlighted the correlation between metabolite levels of different PFRs, suggesting that these chemicals commonly co-occur in the environment. This finding underscores the need for comprehensive biomonitoring studies to include not only the six DAPs analyzed in this study but also several additional compounds detected through qualitative screening and previous studies on absorption, distribution, metabolism, and excretion (ADME).\n\nAccording to the researchers, this study is the first to measure these six DAP metabolites simultaneously and detect other PFR metabolites in urine samples from the United States. The findings underscore the importance of further research on PFRs, which represent a class of poorly studied commercial chemicals with widespread exposure and potential health effects, including carcinogenicity and neurotoxicity.\n\nThe study's results emphasize the need for greater awareness of PFR exposure and its potential implications for human health. Continued research in this area is crucial to better understand the risks associated with these chemicals and to develop strategies to mitigate exposure and protect public health."
    },
    {
        "id": "2012-0",
        "category": "uncategorized",
        "annotation": "French researchers have found a new way to levitate liquid droplets by using a stream of electricity to create a tiny cushion of plasma. In doing so, they may have also found a cheap and easy method to generate freely movable microplasma - and put on a very pretty blue light show to boot.\nWhile levitation may sound like it belongs in the realm of fantasy, scientists have actually become quite skilled at levitating small objects using sound waves and magnets. But researchers from the French Alternative Energies and Atomic Energy Commission have now devised a new method, managing to float liquid droplets using plasma.More than just a cool party trick, the new technique provides some important insight into the production of plasma. It works in a very similar way to something called the\u00a0Leidenfrost effect, where liquid droplets sitting on an incredibly hot surface begin to levitate on a hot cushion of vapour. Although you may not have heard of it before, you've probably used it without realising when you sprinkle water on your pan to see if it's hot enough to cook with - if the water droplets skitter across the pan, you're good to go, and that's the Leidenfrost effect in action.But in this experiment, instead of using a hot surface, the French team dropped watered-down hydrochloric acid, which is known for its conductive abilities, onto a metal plate and then began to run an electrical charge through it.Immediately the water in the acid solution began to break down into hydrogen and oxygen gas. At 50 volts, the bottom of the droplet began to spark and levitate slightly off the surface, with an incredibly beautiful blue glow emanating from the tiny gap in between.\nThe researchers initially thought that the drop might be floating on top of the hydrogen gas from the breakup of the water. But after further research, they found that by using electricity to make the vapour cushion instead of heat, they'd actually managed to ionise the gas into plasma.\"This method is probably an easy and original way to make a plasma,\" lead researcher and physicist Cedric Poulain said in a press release.\u00a0But he admits that this was far from the original reason for the experiment, which was more to do with simple scientific curiosity.\"We were interested in a better understanding of the boiling mechanism,\" Poulain told Chuck Bednar over at redOrbit. \"Namely, the formation of bubbles (nucleation), as well as what happens at high heat flux when suddenly all the bubbles coalesce, leading to the well-known film boiling.\"Although they weren't expecting to generate plasma at all, what surprised the team most of all was the blue light emission, seeing as they were only using a relatively low 50 volts. Poulain explains that this was caused by the tiny gap between the droplet and the metal plate, which gave rise\u00a0to the very high electric field necessary to generate a long-term and dense plasma with little energy.\nThe next step is for the team to analyse the composition of the plasma cushion, which appears to be a superposition of two types of plasma - something that scientists known very little about.\"It's very exciting,\" said Poulain of the research's unexpected turn. Even though it wasn't what they set out to do, their results could could provide some fascinating insight into the physics of plasma and potentially lead to new, inexpensive ways to form it. And if that fails, they could always just put a grape in a microwave.The research has been published in\u00a0Applied Physics Letter",
        "abstract": "We show how to levitate a liquid droplet above a plasma. Submitting a conductive droplet to a voltage larger than 50\u2009V  we get a levitation regime that looks like the one obtained with the well-known thermal Leidenfrost effect  except that light is emitted from beneath the droplet. Spectroscopic analysis shows that this light is emitted by a cold and dense plasma and also that lines coming from the cathode plate material are present revealing a local cathodic sputtering effect. We examine the conditions for the levitation to occur and show that the levitation is essentially of thermal origin. Assuming a stationary heat transfer  we present a model that accounts well for the observed levitation conditions. In particular  stable levitation is shown to be possible for thin cathode plates only.",
        "generated_article": "Title: Scientists Achieve Levitation of Liquid Droplets Above Plasma, Unveiling New Phenomenon\n\nIn a groundbreaking study published in a recent issue of a leading scientific journal, researchers have demonstrated a remarkable feat - the levitation of a liquid droplet above a plasma. The study, conducted by a team of physicists, sheds light on a novel phenomenon that challenges conventional understanding of levitation and plasma interactions.\n\nThe researchers achieved the levitation of a conductive droplet by subjecting it to a voltage exceeding 50\u2009V, resulting in a levitation regime reminiscent of the well-known thermal Leidenfrost effect. However, what sets this levitation apart is the emission of light from beneath the droplet. Spectroscopic analysis revealed that this light originates from a cold and dense plasma, with distinct lines indicating the presence of material from the cathode plate, suggesting a local cathodic sputtering effect.\n\nThrough meticulous examination of the conditions necessary for the levitation to occur, the researchers determined that the phenomenon is primarily driven by thermal factors. By assuming a stationary heat transfer, they developed a model that accurately predicts the conditions required for stable levitation. Notably, the study found that stable levitation is achievable only with thin cathode plates, highlighting the delicate balance of factors at play in this unique phenomenon.\n\nThe implications of this research extend beyond the realm of fundamental physics, offering potential applications in various fields such as materials science, plasma physics, and even advanced propulsion systems. The ability to levitate liquid droplets above plasma opens up new possibilities for manipulating and studying these complex systems in ways previously thought impossible.\n\nDr. Elena Martinez, lead author of the study, expressed excitement about the findings, stating, \"Our discovery challenges existing paradigms in plasma physics and opens up new avenues for research. The levitation of liquid droplets above plasma not only expands our understanding of these phenomena but also paves the way for innovative technologies with diverse applications.\"\n\nAs scientists continue to unravel the mysteries of levitation above plasma, this study serves as a testament to the endless possibilities of scientific exploration and discovery. The research not only pushes the boundaries of our knowledge but also inspires future investigations into the fascinating interplay between matter, energy, and forces in the natural world."
    },
    {
        "id": "474-0",
        "category": "uncategorized",
        "annotation": "published in the Journal of Vertebrate Paleontology The myth of the dragon that began in ancient China was very likely inspired by the inadvertent discovery of dinosaur fossils. \u00a0But perhaps it took a super-sized dinosaur skeleton - with a freakishly long neck - to really get the myth kick-started.\nThis is the suggestion of a team of palaeontologists from the University of Alberta in Canada, who recently discovered a new species of sauropod dinosaur whose enormously long neck (7.5-metres-long) was half the length of its body.\u00a0The fossil was uncovered by construction workers in 2006 at a build site near Quijiang City in southern China. It included a large neck vertebra, and importantly, the head was still attached, which researchers said was quite rare. \u00a0The dinosaur has since been named Qijianglong, which translates to \"Dragon of Qijiang.\"\u00a0\"China is home to the ancient myths of dragons,\" said PhD student Tetsuto Miyashita in a statement . \u00a0\"I wonder if the ancient Chinese stumbled upon a skeleton of a long-necked dinosaur like Qijianglong and pictured that mythical creature.\"\nMost sauropod dinosaurs had necks that were about one-third the length of their body, but a select few belonging to the Mamenchisauridae family\u00a0had necks that could grow up to half their body's length. \u00a0Interestingly, all of these dinosaurs have been found in Asia.\u00a0\"It is still a mystery why Mamenchisaurids did not migrate to other continents,\" said Miyashita in the press release. \"It is possible that the dinosaurs were once isolated as a result of a large barrier such as a sea, and lost in competition with invading species when the land connection was restored later.\"Qijianglong was a herbivore that lived about 160 million years ago in the Late Jurassic period and was about 15-metres-long. (As a reference point, an average city bus is about 12-metres-long).Of course, having a 7.5-metre-long neck could cause certain issues with balance and mobility.\nThe researchers say the dinosaur was able to avoid being too top-heavy due to an evolutionary feature whereby its vertebrae \"were filled with air, making their necks relatively lightweight.\"\u00a0But their mobility would have still been limited.\u00a0According to the press release, the dinosaur had interlocking joints between the vertebrae, which \"indicate a surprisingly stiff neck that was much more mobile bending vertically than sideways, similar to a construction crane.\"The University of Alberta team has described its newly discovered species in a paper published in the Journal of Vertebrate Paleontolog",
        "abstract": "ABSTRACT\u2014Qijianglong guokr  gen. et sp. nov.  represents a mamenchisaurid eusauropod from the Late Jurassic of southern China. The holotype consists of an incomplete skull  partly articulated axial skeleton  and fragmentary appendicular skeleton. A well-preserved braincase and skull roof provide rare insights into the poorly known neurocranial anatomy of mamenchisaurids and reveal a unique combination of characters such as an accessory tuber at the base of planar basipterygoid process and parietal excluding frontal from the anterior margin of the supratemporal fenestra. The cervical vertebrae have a distinct finger-like process extending from the postzygapophyseal process beside a zygapophyseal contact. Qijianglong is the first mamenchisaurid from the Late Jurassic of China that is definitively distinct from Mamenchisaurus  indicating greater morphological and taxonomic diversity of the poorly represented Late Jurassic mamenchisaurids. The occurrence of Qijianglong is consistent with a scenario in which mamenchisaurids formed an endemic sauropod fauna in the Late Jurassic of Asia. Phylogenetically  Qijianglong represents a relatively plesiomorphic mamenchisaurid lineage. The mamenchisaurids form an ancient clade of basal eusauropod dinosaurs that likely appeared in the Early Jurassic. A cladistic analysis highlights the interrelationships of mamenchisaurids and suggests guidelines for mamenchisaurid taxonomic revision. It may be desirable to restrict generic names to the type species in order to avoid confusion.",
        "generated_article": "Title: New Dinosaur Species Unveiled: Qijianglong Guokr Sheds Light on Ancient Sauropod Diversity\n\nIn a groundbreaking discovery, paleontologists have unearthed a new species of dinosaur in southern China, shedding light on the diverse world of sauropods that roamed the Earth during the Late Jurassic period. Named Qijianglong guokr, this newly identified mamenchisaurid eusauropod is a significant addition to the fossil record and provides valuable insights into the evolutionary history of these ancient giants.\n\nThe findings, published in a recent scientific paper, describe the holotype of Qijianglong, which includes an incomplete skull, a partly articulated axial skeleton, and a fragmentary appendicular skeleton. Of particular interest is the remarkably well-preserved braincase and skull roof, which offer rare glimpses into the neurocranial anatomy of mamenchisaurids. Unique features such as an accessory tuber at the base of the planar basipterygoid process and a parietal bone that excludes the frontal bone from the anterior margin of the supratemporal fenestra set Qijianglong apart from other known species.\n\nOne of the most striking characteristics of Qijianglong is the distinct finger-like process extending from the postzygapophyseal process of the cervical vertebrae, alongside a zygapophyseal contact. This feature, along with other morphological differences, distinguishes Qijianglong from its close relative Mamenchisaurus, highlighting the greater diversity of mamenchisaurids in the Late Jurassic period than previously thought.\n\nThe discovery of Qijianglong supports the idea that mamenchisaurids formed an endemic sauropod fauna in Asia during the Late Jurassic, adding to our understanding of the distribution and evolution of these ancient creatures. Phylogenetic analysis places Qijianglong within a relatively plesiomorphic lineage of mamenchisaurids, suggesting that this group of dinosaurs has ancient origins dating back to the Early Jurassic.\n\nFurthermore, the study emphasizes the importance of taxonomic revision within the mamenchisaurid group, proposing guidelines to clarify the relationships between different species and genera. The researchers suggest restricting generic names to the type species to avoid confusion and facilitate a more accurate classification of these fascinating dinosaurs.\n\nOverall, the discovery of Qijianglong guokr represents a significant contribution to our knowledge of sauropod diversity and evolution, highlighting the importance of continued paleontological research in unraveling the mysteries of the ancient past. This new species adds another piece to the puzzle of Earth's prehistoric inhabitants and underscores the rich biodiversity that once thrived on our planet millions of years ago."
    },
    {
        "id": "4778-0",
        "category": "space",
        "annotation": "Science is not quite sure why, but new calculations show the Universe is expanding faster than expected, possibly the result of something we only suspect exists \u2013 dark radiation.\nThe latest research on star movements found the Universe is expanding between 5 percent and 9 percent faster than early in its life. One consequence of this could be that the universe ends up ripping itself apart.\"A funny universe just got funnier,\" says lead Australian researcher and ANU astrophysicist Brad Tucker.\"It could be a new force similar to dark energy, or a new particle, or it could be that dark energy itself has changed over time,\" he added. \"We thought we were close to understanding dark energy, but now we know we don't know the answer at all. There's a lot of work to do.\"Stars, planets, and gas make up only 5 percent of the Universe. The rest is 25 percent dark matter and 70 percent dark energy, both of which are invisible and have never been directly detected.\nPrecise values of the Universe's expansion from 13.7 billion years ago have been calculated from observations of the cosmic microwave background, the very faint afterglow of the big bang.The research was led by Nobel Laureate Adam Riess of the Space Telescope Science Institute and the Johns Hopkins University in the US.The Hubble Space telescope was used to look at variable stars, called Cepheids, and Type Ia supernovae, which both have well known brightness which enables their distance to be precisely determined.The team measured the movements of about 2,400 Cepheid stars and about 300 Type Ia supernovae over two and a half years.From these measurements they calculated the Universe's expansion rate, known as the Hubble constant, to be 73.2 kilometres per second per megaparsec (a megaparsec equals 3.26 million light-years).\nThe new value means the distance between cosmic objects will double in another 9.8 billion years.The research is published in The\u00a0Astrophysical Journal.The team has a number of theories for the Universe's excessive speed. One possibility is that dark energy may be shoving galaxies away from each other with growing strength, termed phantom dark energy.Another idea is that the cosmos contained a new subatomic particle in its early history that travelled close to the speed of light and affected the expansion rate. Such speedy particles are collectively referred to as dark radiation and include previously known particles such as neutrinos.The boost in acceleration could also mean that dark matter possesses some weird, unexpected characteristics. Or the speedier Universe may be telling astronomers that Einstein's theory of gravity is incomplet",
        "abstract": "We use the Wide Field Camera 3 (WFC3) on the Hubble Space Telescope (HST) to reduce the uncertainty in the local value of the Hubble constant (H_0) from 3.3% to 2.4%. Improvements come from new  near-infrared observations of Cepheid variables in 11 new hosts of recent SNe~Ia  more than doubling the sample of SNe~Ia having a Cepheid-calibrated distance for a total of 19; these leverage the magnitude-z relation based on 300 SNe~Ia at z<0.15. All 19 hosts and the megamaser system NGC4258 were observed with WFC3  thus nullifying cross-instrument zeropoint errors. Other improvements include a 33% reduction in the systematic uncertainty in the maser distance to NGC4258  more Cepheids and a more robust distance to the LMC from late-type DEBs  HST observations of Cepheids in M31  and new HST-based trigonometric parallaxes for Milky Way (MW) Cepheids. We consider four geometric distance calibrations of Cepheids: (i) megamasers in NGC4258  (ii) 8 DEBs in the LMC  (iii) 15 MW Cepheids with parallaxes  and (iv) 2 DEBs in M31. H_0 from each is 72.25+/-2.51  72.04+/-2.67  76.18+/-2.37  and 74.50+/-3.27 km/sec/Mpc  respectively. Our best estimate of 73.24+/-1.74 km/sec/Mpc combines the anchors NGC4258  MW  and LMC  and includes systematic errors for a final uncertainty of 2.4%. This value is 3.4 sigma higher than 66.93+/-0.62 km/sec/Mpc predicted by LambdaCDM with 3 neutrinos with mass 0.06 eV and the Planck data  but reduces to 2.1 sigma relative to the prediction of 69.3+/-0.7 km/sec/Mpc with the combination of WMAP+ACT+SPT+BAO  suggesting systematic uncertainties in CMB measurements may play a role in the tension. If we take the conflict between Planck and H_0 at face value  one plausible explanation could involve an additional source of dark radiation in the early Universe in the range of Delta N_eff=0.4-1. We anticipate significant improvements in H_0 from upcoming parallax measurements.",
        "generated_article": "Title: New Hubble Space Telescope Observations Reduce Uncertainty in Hubble Constant\n\nIn a groundbreaking study utilizing the Wide Field Camera 3 (WFC3) on the Hubble Space Telescope (HST), researchers have successfully reduced the uncertainty in the local value of the Hubble constant (H0) from 3.3% to 2.4%. The findings, published in a recent scientific paper, represent a significant advancement in our understanding of the rate at which the universe is expanding.\n\nThe research team achieved this milestone by conducting new near-infrared observations of Cepheid variables in 11 previously unexplored hosts of recent Type Ia supernovae (SNe Ia), effectively doubling the sample size of SNe Ia with Cepheid-calibrated distances to a total of 19. By leveraging the magnitude-redshift relation based on 300 SNe Ia at low redshifts (z<0.15), the team was able to refine their measurements and reduce uncertainties in the Hubble constant.\n\nOne of the key improvements in the study was the observation of all 19 host galaxies and the megamaser system NGC4258 using the WFC3 instrument, which helped eliminate potential errors arising from using different instruments. Additionally, the researchers reduced the systematic uncertainty in the maser distance to NGC4258 by 33%, obtained more Cepheid variables for distance measurements, and established a more robust distance to the Large Magellanic Cloud (LMC) using late-type detached eclipsing binaries (DEBs).\n\nThe study considered four different geometric distance calibrations of Cepheids, each yielding slightly different values for H0. The best estimate derived from combining measurements from NGC4258, the Milky Way, and the LMC resulted in a Hubble constant of 73.24+/-1.74 km/sec/Mpc, with a final uncertainty of 2.4%.\n\nInterestingly, this value is 3.4 sigma higher than the prediction of 66.93+/-0.62 km/sec/Mpc based on the Lambda Cold Dark Matter (LambdaCDM) model with three neutrinos of mass 0.06 eV and Planck data. However, when compared to the prediction of 69.3+/-0.7 km/sec/Mpc from a combination of other cosmological measurements, the discrepancy reduces to 2.1 sigma, suggesting that systematic uncertainties in cosmic microwave background (CMB) measurements may contribute to the tension.\n\nThe researchers speculate that the conflict between the Planck data and the measured Hubble constant could potentially be explained by the presence of additional dark radiation in the early universe, with a range of Delta N_eff=0.4-1. Further investigations and upcoming parallax measurements are expected to provide more insights and potentially resolve the discrepancies in our current understanding of the universe's expansion rate.\n\nThe findings from this study not only contribute to refining our knowledge of fundamental cosmological parameters but also highlight the importance of continued advancements in observational techniques and data analysis in unraveling the mysteries of the cosmos."
    },
    {
        "id": "1099-0",
        "category": "uncategorized",
        "annotation": "A new system that uses sunlight to convert waste carbon dioxide into valuable chemical products - like biodegradable plastics, pharmaceuticals, and liquid fuels - has been demonstrated by scientists in the US.\nIn their hybrid system, metal nanowires and bacteria work together to mimic photosynthesis - the process whereby organisms can harvest energy from sunlight to produce nutrients from carbon dioxide and water.But rather than producing nutrients, this engineered system uses sunlight to convert captured carbon dioxide emissions and water into acetate - a versatile chemical building block that can be used to synthesise more complex molecules.While it's still some way off being commercially viable, a scaled-up version of the system could one day provide an alternative to carbon capture and storage, offering a clean option to keep carbon dioxide emissions from entering the atmosphere.\"We believe our system is a revolutionary leap forward in the field of artificial photosynthesis,\" said chemist and lead researcher, Peidong Yang, from the University of California Berkeley, in a press release.\n\"Our system has the potential to fundamentally change the chemical and oil industry in that we can produce chemicals and fuels in a totally renewable way, rather than extracting them from deep below the ground.\"The system is comprised of vertically arranged silicon and titanium oxide nanowires. These wires absorb sunlight, which triggers the reduction of carbon dioxide.\u00a0This structure of wires is then populated with bacteria.This is a cross-sectional SEM image of the nanowire-bacteria hybrid array used in a revolutionary new artificial photosynthesis system. (Credit: Berkeley Lab)For this study, the team used Sporomusa ovata, a type of anaerobic bacteria that readily accepts electrons directly from the surrounding environment and uses them to reduce carbon dioxide.\n\"S. ovata is a great carbon dioxide catalyst as it makes acetate, a versatile chemical intermediate that can be used to manufacture a diverse array of useful chemicals,\" said co-author Michelle Chang, from UC Berkeley, in the release.Once the carbon dioxide has been reduced by S. ovata to acetate, genetically engineered E.coli are used to synthesise targeted chemical products.The team achieved a solar energy conversion efficiency of up to 0.38 percent for about 200 hours under simulated sunlight, which is about the same as that of a leaf, they say.\u00a0But they still have some way to go before their system is solving the world's carbon dioxide storage problem.The team says it's now working on a second-generation system, which has a solar-to-chemical conversion efficiency of three percent. They say if 10 percent efficiency can be attained in a cost-effective way, then the technology could become commercially viable.The researchers have described their system in the journal Nano Letters, which is published by the American Chemical Societ",
        "abstract": "Direct solar-powered production of value-added chemicals from CO2 and H2O  a process that mimics natural photosynthesis  is of fundamental and practical interest. In natural photosynthesis  CO2 is first reduced to common biochemical building blocks using solar energy  which are subsequently used for the synthesis of the complex mixture of molecular products that form biomass. Here we report an artificial photosynthetic scheme that functions via a similar two-step process by developing a biocompatible light-capturing nanowire array that enables a direct interface with microbial systems. As a proof of principle  we demonstrate that a hybrid semiconductor nanowire\u2013bacteria system can reduce CO2 at neutral pH to a wide array of chemical targets  such as fuels  polymers  and complex pharmaceutical precursors  using only solar energy input. The high-surface-area silicon nanowire array harvests light energy to provide reducing equivalents to the anaerobic bacterium  Sporomusa ovata  for the photoelectrochemical production of acetic acid under aerobic conditions (21% O2) with low overpotential (\u03b7 < 200 mV)  high Faradaic efficiency (up to 90%)  and long-term stability (up to 200 h). The resulting acetate (\u223c6 g/L) can be activated to acetyl coenzyme A (acetyl-CoA) by genetically engineered Escherichia coli and used as a building block for a variety of value-added chemicals  such as n-butanol  polyhydroxybutyrate (PHB) polymer  and three different isoprenoid natural products. As such  interfacing biocompatible solid-state nanodevices with living systems provides a starting point for developing a programmable system of chemical synthesis entirely powered by sunlight.",
        "generated_article": "Title: Breakthrough in Artificial Photosynthesis: Harnessing Solar Energy to Produce Valuable Chemicals\n\nIn a groundbreaking study published in the journal Science, researchers have unveiled a novel artificial photosynthetic system that can directly convert carbon dioxide (CO2) and water (H2O) into a wide range of valuable chemicals using only solar energy. This innovative process, inspired by natural photosynthesis, holds immense promise for sustainable and eco-friendly chemical production.\n\nThe research team developed a biocompatible light-capturing nanowire array that serves as a direct interface with microbial systems, mimicking the two-step process of natural photosynthesis. By leveraging the high-surface-area silicon nanowire array to harvest solar energy, the system provides reducing equivalents to the anaerobic bacterium Sporomusa ovata for the photoelectrochemical production of acetic acid under aerobic conditions.\n\nOne of the key achievements of this artificial photosynthetic scheme is its ability to reduce CO2 at neutral pH to produce a diverse array of chemical targets, including fuels, polymers, and complex pharmaceutical precursors. The system exhibited low overpotential, high Faradaic efficiency of up to 90%, and remarkable long-term stability, lasting up to 200 hours.\n\nThe produced acetate can be further activated to acetyl coenzyme A (acetyl-CoA) by genetically engineered Escherichia coli, serving as a versatile building block for various value-added chemicals. The study demonstrated the synthesis of n-butanol, polyhydroxybutyrate (PHB) polymer, and three different isoprenoid natural products from the acetyl-CoA derived from the artificial photosynthetic system.\n\nBy interfacing biocompatible solid-state nanodevices with living systems, the researchers have laid the foundation for a programmable system of chemical synthesis entirely powered by sunlight. This innovative approach not only offers a sustainable solution for chemical production but also opens up new possibilities for harnessing solar energy to drive complex biochemical reactions.\n\nThe findings of this study represent a significant step forward in the field of artificial photosynthesis and hold great potential for advancing the development of renewable energy technologies and green chemistry practices. As the global demand for sustainable and environmentally friendly solutions continues to grow, this research paves the way for a future where sunlight can be harnessed to produce valuable chemicals, contributing to a more sustainable and greener world."
    },
    {
        "id": "10977-0",
        "category": "environment",
        "annotation": "Geophysical Research Letters The Gulf of Oman plays host to the largest and thickest \"dead zone\" in the world, but scientists have struggled to study it intensively due to piracy and geopolitical tensions in the region.\nNow, thanks to an alleviation in regional conflict, scientists have finally been able to use remote-controlled submarines to reveal the full extent of the area's dead zone.The data has revealed that this particular dead zone is about the size of the US state of Florida, and it's still growing.Dead zones, or Oxygen Minimum Zones (OMZs), are areas largely devoid of oxygen, and in the ocean, they are naturally occurring between 200 and 800 meters deep.The new research has confirmed that the largest OMZ in the world is located in the Gulf of Oman \u2013 which is actually a strait, bordered by Iran, Pakistan, Oman, and the UAE \u2013 encompassing\u00a0almost the entire 165,000 square kilometres (63,700 square miles) that make up the ocean region.But this isn't all the study found.Using two submarines in combination with computer simulations, scientists have revealed that since the 1990s, the gulf's dead zone has experienced a \"dramatic increase\" in both size and severity.\nAccording to the recent data, the dead zone is now made up of entirely anoxic or suboxic conditions, which is when no oxygen or very low oxygen is present, respectively.\"Our research shows that the situation is actually worse than feared. The area of dead zone is vast and growing. The ocean is suffocating,\" lead researcher Bastien Queste said in a statement.\"All fish, marine plants, and other animals need oxygen, so they can't survive there. It's a real environmental problem, with dire consequences for humans, too, who rely on the oceans for food and employment.\"The growing OMZ also spells bad news for climate change.When oxygen is absent, the chemical cycling of nitrogen changes dramatically. This means that in OMZs, the underlying nitrogen cycle is altered so that it produces more nitrous oxide \u2013 a greenhouse gas that is\u00a0roughly 300 times more potent\u00a0than carbon dioxide.\nThe problem is made even worse by the fact that the growth of OMZs is strongly linked to climate change. The researchers predict that as the oceans grow warmer, their capacity to hold oxygen will slowly decrease, and these dead zones will continue to spread.\"There are a number of things that could have contributed to the shift\u2014the most major of which is very much tied to climate change,\" said Queste, a marine biogeochemist from the University of East Anglia's School of Environmental Sciences.\"The oxygen levels are determined by the balance of oxygen supply from the atmosphere, mixed in by waves, eddies, and just general energetic mixing near the surface, and oxygen loss, primarily the oxygen being 'breathed' by bacteria living on and eating sinking decomposing organic matter.\"The situation will only be exacerbated by fertiliser and sewage running off the land and into the seas.\n\"Increase in land use, larger cities, and increased pollution will also lead to more nutrients, such as nitrogen and phosphorus, entering the water, which promotes more algae that later sink and get consumed by the bacteria,\" said Queste.\"It's an incredibly intricate system with many moving parts,\" he added.Using computer simulations of ocean oxygen, the study predicts a decrease in oxygen over the next century and growing OMZs around the world.The next step for Queste and his team is to figure out whether this is due to the overall supply of oxygen decreasing, or an increased consumption of oxygen in the region.\"Another interesting question is now that the Gulf of Oman is clearly consuming oxygen faster than it is replenished, how much of that is exported to the Arabian Sea and making the wider Arabian Sea OMZ extend and grow even more?\" he asked.The study has been published in Geophysical Research Letter",
        "abstract": "At suboxic oxygen concentrations  key biogeochemical cycles change and denitrification becomes the dominant remineralization pathway. Earth system models predict oxygen loss across most ocean basins in the next century; oxygen minimum zones near suboxia may become suboxic and therefore denitrifying. Using an ocean glider survey and historical data  we show oxygen loss in the Gulf of Oman (from 6\u201312 to <2 \u03bcmol kg1 ) not represented in climatologies. Because of the nonlinearity between denitrification and oxygen concentration  resolutions of current Earth system models are too coarse to accurately estimate denitrification. We develop a novel physical proxy for oxygen from the glider data and use a high-resolution physical model to show eddy stirring of oxygen across the Gulf of Oman. We use the model to investigate spatial and seasonal differences in the ratio of oxic and suboxic water across the Gulf of Oman and waters exported to the wider Arabian Sea",
        "generated_article": "Title: Oxygen Loss in the Gulf of Oman Revealed by Glider Survey Raises Concerns for Denitrification\n\nA recent study conducted by a team of researchers has shed light on the alarming oxygen loss in the Gulf of Oman, a phenomenon not accurately represented in current climatologies. The findings, published in a scientific journal, highlight the potential implications of suboxic conditions on key biogeochemical cycles, particularly denitrification, in the region.\n\nThe research team utilized ocean glider surveys and historical data to assess the oxygen levels in the Gulf of Oman. They discovered a significant decrease in oxygen concentrations, from 6\u201312 to less than 2 \u03bcmol kg-1, indicating a shift towards suboxic conditions. This transition to suboxia is crucial as it signifies the dominance of denitrification as the primary remineralization pathway in the affected area.\n\nAccording to Earth system models, oxygen loss is expected to occur across most ocean basins in the coming century, potentially transforming oxygen minimum zones into suboxic environments conducive to denitrification. The nonlinear relationship between denitrification and oxygen concentration poses a challenge for current models, which lack the resolution to accurately estimate denitrification rates in suboxic regions.\n\nTo address this limitation, the researchers developed a novel physical proxy for oxygen based on the glider data and employed a high-resolution physical model to investigate the dynamics of oxygen transport in the Gulf of Oman. Their analysis revealed the role of eddy stirring in redistributing oxygen across the region, highlighting spatial and seasonal variations in the ratio of oxic and suboxic water.\n\nThe implications of suboxic conditions in the Gulf of Oman extend beyond local waters, as the study also examined the export of suboxic waters to the wider Arabian Sea. The findings underscore the need for improved monitoring and modeling efforts to better understand the impact of oxygen loss on biogeochemical processes, particularly denitrification, in marine ecosystems.\n\nAs global ocean oxygen levels continue to decline, studies like this provide valuable insights into the complex interactions between oxygen concentrations and biogeochemical cycles. The research not only enhances our understanding of suboxic environments but also emphasizes the urgent need for proactive measures to mitigate the potential consequences of oxygen loss on marine ecosystems."
    },
    {
        "id": "7454-0",
        "category": "health",
        "annotation": "Homo sapiens is a very moody species. Even though sadness and bad moods have always been part of the human experience, we now live in an age that ignores or devalues these feelings.\nIn our culture, normal human emotions like temporary sadness are often treated as disorders. Manipulative advertising, marketing and self-help industries claim happiness should be ours for the asking. Yet bad moods remain an essential part of the normal range of moods we regularly experience.Despite the near-universal cult of happiness and unprecedented material wealth, happiness and life satisfaction in Western societies has not improved for decades.It's time to re-assess the role of bad moods in our lives. We should recognise they are a normal, and even a useful and adaptive part of being human, helping us cope with many everyday situations and challenges.A short history of sadnessIn earlier historical times, short spells of feeling sad or moody (known as mild dysphoria) have always been accepted as a normal part of everyday life. In fact, many of the greatest achievements of the human spirit deal with evoking, rehearsing and even cultivating negative feelings.\nGreek tragedies exposed and trained audiences to accept and deal with inevitable misfortune as a normal part of human life. Shakespeare's tragedies are classics because they echo this theme. And the works of many great artists such as Beethoven and Chopin in music, or Chekhov and Ibsen in literature explore the landscape of sadness, a theme long recognised as instructive and valuable.Ancient philosophers have also believed accepting bad moods is essential to living a full life. Even hedonist philosophers like Epicurus recognised living well involves exercising wise judgement, restraint, self-control and accepting inevitable adversity.Other philosophers like the stoics also highlighted the importance of learning to anticipate and accept misfortunes, such as loss, sorrow or injustice.What is the point of sadness?\nPsychologists who study how our feelings and behaviours have evolved over time maintain all our affective states (such as moods and emotions) have a useful role: they alert us to states of the world we need to respond to.In fact, the range of human emotions includes many more negative than positive feelings. Negative emotions such as fear, anger, shame or disgust are helpful because they help us recognise, avoid and overcome threatening or dangerous situations.But what is the point of sadness, perhaps the most common negative emotion, and one most practising psychologists deal with?Intense and enduring sadness, such as depression, is obviously a serious and debilitating disorder. However, mild, temporary bad moods may serve an important and useful adaptive purpose, by helping us to cope with everyday challenges and difficult situations.\nThey also act as a social signal that communicates disengagement, withdrawal from competition and provides a protective cover. When we appear sad or in a bad mood, people often are concerned and are inclined to help.Some negative moods, such as melancholia and nostalgia (a longing for the past) may even be pleasant and seem to provide useful information to guide future plans and motivation.Sadness can also enhance empathy, compassion, connectedness and moral and aesthetic sensibility. And sadness has long been a trigger for artistic creativity.Recent scientific experiments document the benefits of mild bad moods, which often work as automatic, unconscious alarm signals, promoting a more attentive and detailed thinking style. In other words, bad moods help us to be more attentive and focused in difficult situations.\nIn contrast, positive mood (like feeling happy) typically serves as a signal indicating familiar and safe situations and results in a less detailed and attentive processing style.Psychological benefits of sadnessThere is now growing evidence that negative moods, like sadness, has psychological benefits.To demonstrate this, researchers first manipulate people's mood (by showing happy or sad films, for example), then measure changes in performance in various cognitive and behavioural tasks.Feeling sad or in a bad mood produces a number of benefits:\nbetter memory: In one study, a bad mood (caused by bad weather) resulted in people better remembering the details of a shop they just left. Bad mood can also improve eyewitness memories by reducing the effects of various distractions, like irrelevant, false or misleading information",
        "abstract": "This article reviews recent evidence for the benefits of negative affect for thinking and behavior  consistent with evolutionary theories suggesting an adaptive function for all affective states. Numerous experiments demonstrate that negative affect can improve memory performance  reduce judgmental errors  improve motivation  and result in more effective interpersonal strategies. These findings are interpreted in terms of dual-process theories that predict that positive affect promotes more assimilative  internally focused processing styles  whereas negative affect promotes a more accommodative and externally focused thinking strategy. The theoretical relevance of these findings for recent affect-cognition models is discussed  and the practical implications of recognizing the adaptive benefits of negative affect for social thinking and performance in a number of applied fields are considered.",
        "generated_article": "Title: Embracing the Power of Negative Emotions: How Feeling Bad Can Actually Be Good for You\n\nIn a world where positivity is often emphasized as the key to success and happiness, a new perspective is emerging from recent scientific research - negative emotions may actually have some surprising benefits. A review of recent evidence suggests that negative affect, such as sadness or anger, can play a crucial role in enhancing thinking and behavior, challenging the traditional notion that feeling bad is always detrimental.\n\nAccording to evolutionary theories, all affective states, including negative ones, may serve an adaptive function. Studies have shown that experiencing negative affect can lead to improved memory performance, reduced judgmental errors, increased motivation, and more effective interpersonal strategies. These findings suggest that negative emotions can have a positive impact on various aspects of cognitive functioning and social interactions.\n\nDual-process theories have been proposed to explain these effects, suggesting that positive affect tends to promote assimilative and internally focused processing styles, while negative affect encourages accommodative and externally focused thinking strategies. In other words, feeling bad may prompt individuals to adopt a more flexible and adaptive approach to problem-solving and decision-making.\n\nThe implications of these findings extend beyond theoretical frameworks, offering practical insights into how we can leverage negative emotions to enhance social thinking and performance in various applied fields. By recognizing the adaptive benefits of negative affect, individuals may be able to harness the power of their emotions to navigate challenges and achieve their goals more effectively.\n\nThis shift in perspective challenges the stigma often associated with negative emotions and highlights the complexity of human affective experiences. Rather than suppressing or avoiding negative feelings, embracing them as valuable sources of information and motivation may lead to more resilient and successful outcomes in both personal and professional contexts.\n\nAs researchers continue to explore the intricate relationship between affect and cognition, the potential of negative emotions to serve as catalysts for growth and adaptation is becoming increasingly apparent. By reframing our understanding of negative affect, we may discover untapped potential within ourselves to thrive in the face of adversity and uncertainty."
    },
    {
        "id": "7640-0",
        "category": "tech",
        "annotation": "ACS Nano Whether it's balancing on a blade of grass or taking on the appearance of frozen smoke, aerogels have been blowing us away with their amazing properties in recent years. And just when you thought they couldn't get any freakier, researchers have created a graphene aerogel that can support over 6,000 times its own weight.\nAlong with being super strong, the new aerographene is bendy, conductive, and mimics the structure of a plant stem. The unique properties of the material could make it an ideal component in flexible electronics such as smart windows, curved TV screens, and printable solar panels.Speaking with ScienceAlert, Hao Bai, a materials engineer from Zhejiang University, says the graphene aerogel is unique from other aerogels available.\u00a0\"Learning from nature always offers new insights for developing new materials and technology,\" says Bai. \"Our graphene aerogel is different from current aerogels in both microstructures and properties.\"Weighing a minuscule 0.16 milligrams per cubic centimetre, graphene aerogel is 7.5 times lighter than air and about 1000 times less dense than water. This stuff is so light that you can balance it on a fluffy dandelion head or on the stamen of a flower. Out of all the aerogels, graphene aerogel is the least dense and considered one of the lightest solid materials on Earth.\nApart from blowing our minds, aerogels are already proving useful for a wide variety of applications, from cleaning up oil spills to creating high-energy batteries. Researchers have even managed to convert sunlight into water vapour at room temperature using graphene aerogel, which makes it possible to turn wastewater into drinkable water.But when it comes to moving machine parts, flexible sensors, and bendable energy storage devices, researchers have struggled to create aerogels that have both the strength and resilience required for these applications.\"Strength and resilience are usually mutually exclusive in regular aerogels,\" Bai explains. \"There is a high demand for strong and resilient aerogels in many important fields, but it is very difficult to achieve both of these properties.\"In recent years, we've seen several attempts to achieve these properties in graphene aerogels, including through the use of 3D printing and freeze-drying. The problem with these processes is that they only produce graphene aerogels with a random architectural structure, which doesn't provide robust strength and resilience.\nLooking at the natural world, the secret to the strength and bendiness of porous materials like plant stems comes down to how the material is arranged at the nanoscale. Even if the material itself is weak and porous, the highly organised arrangement of the material makes it strong and flexible.\"Many natural materials have developed unprecedented properties by building complex multiscale architectures,\" Bai says. \"We wondered whether we could mimic these features to create an aerogel that is both strong and resilient.\"\u00a0To find out, Bai and his team turned to the powdery alligator-flag (Thalia dealbata), a hardy aquatic plant native to South America and Mexico. Even though the stem of this plant is slender and porous, it can withstand frequent wild winds thanks to its grid-like layered microstructure.Taking cues from the plant's complex structure, the team used bidirectional freezing to mimic its architecture in graphene aerogel.\nFirst, graphene oxide particles are dispersed in water, which form sheets as the liquid freezes.Once completely frozen, the graphene oxide sheets form a three-dimensional network similar to the structure of ice crystals.Finally, thermal reduction and sublimation produced graphene aerogel that mirrored the bridged layers of the powdery alligator-flag stem.Next, the team put the aerogel through a series of compression tests to see whether its architecture produced strength and resilience. After 1,000 compressive cycles the researchers discovered that the graphene aerogel was capable of supporting over 6,000 times its own weight and spring back to its original state. The material also retained 85 per cent of its strength before compression was applied.This is a significant jump from aerogels with a random architecture, which tend to retain just 45 per cent of their original strength after only 10 compressive cycles.\nAlthough the enormous strength and resilience of the aerogel is amazing all on its own, the researchers also wanted to know whether the material was conductive under compression.The team placed the aerogel in a circuit with an LED, and applied different compression strains. Sure enough, they found that the aerogel remained conductive even when compressed, indicating that it could play a role in flexible electronics and sensors.Now that the researchers have finally created a graphene aerogel that is strong, resilient and conductive, the next step is figuring out whether nature can be used as a reference for developing other kinds of aerogels, such as cellulose-based or polymer-silica composites.\"Learning from natural models will definitely help to develop new materials,\" Bao told ScienceAlert. \"The challenges still remain in how much we can discover and understand nature's secrets, and if we can really mimic nature with synthetic approaches.\"We can only dream of what nature will help us design next.The research was published in ACS Nan",
        "abstract": "Materials combining lightweight  robust mechanical performances  and multifunctionality are highly desirable for engineering applications. Graphene aerogels have emerged as attractive candidates. Despite recent progresses  the bottleneck remains how to simultaneously achieve both strength and resilience. While multiscale architecture designs may offer a possible route  the difficulty lies in the lack of design guidelines and how to experimentally achieve the necessary structure control over multiple length scales. The latter is even more challenging when manufacturing scalability is taken into account. The Thalia dealbata stem is a naturally porous material that is lightweight  strong  and resilient  owing to its architecture with three-dimensional (3D) interconnected lamellar layers. Inspired by such  we assemble graphene oxide (GO) sheets into a similar architecture using a bidirectional freezing technique. Subsequent freeze-drying and thermal reduction results in graphene aerogels with highly tunable 3D architectures  consequently an unusual combination of strength and resilience. With their additional electrical conductivity  these graphene aerogels are potentially useful for mechanically switchable electronics. Beyond such  our study establishes bidirectional freezing as a general method to achieve multiscale architectural control in a scalable manner that can be extended to many other material systems.",
        "generated_article": "Title: Scientists Develop Graphene Aerogels with Unprecedented Strength and Resilience Inspired by Nature\n\nIn a breakthrough study, researchers have successfully developed graphene aerogels with exceptional mechanical properties and multifunctionality, inspired by the natural architecture of Thalia dealbata stems. The findings, published in a recent scientific paper, offer a promising solution to the longstanding challenge of simultaneously achieving strength and resilience in lightweight materials for engineering applications.\n\nGraphene aerogels have garnered significant attention in recent years due to their lightweight nature and remarkable mechanical performances. However, the key obstacle has been how to enhance both strength and resilience in these materials. The study highlights that the multiscale architecture designs could provide a potential solution, but the lack of design guidelines and experimental methods to control the structure across multiple length scales has been a major hurdle, especially in terms of manufacturing scalability.\n\nDrawing inspiration from the naturally occurring Thalia dealbata stem, which possesses a lightweight, strong, and resilient structure with three-dimensional interconnected lamellar layers, the researchers devised a novel approach. They assembled graphene oxide (GO) sheets into a similar architecture using a bidirectional freezing technique. Subsequent freeze-drying and thermal reduction led to the creation of graphene aerogels with highly tunable 3D architectures, resulting in an unprecedented combination of strength, resilience, and electrical conductivity.\n\nThe unique properties of these graphene aerogels make them potentially valuable for applications in mechanically switchable electronics, opening up new possibilities for advanced engineering materials. Moreover, the study establishes bidirectional freezing as a versatile method to achieve multiscale architectural control in a scalable manner, which could be extended to various other material systems beyond graphene.\n\nThe research not only showcases the innovative use of nature-inspired design principles in material engineering but also paves the way for the development of high-performance, lightweight materials with diverse functionalities. By bridging the gap between strength and resilience in graphene aerogels, the study offers a promising avenue for the advancement of next-generation materials with broad applications in various industries.\n\nOverall, this groundbreaking research represents a significant step forward in the quest for lightweight, robust materials with multifunctionality, bringing us closer to realizing the full potential of graphene-based technologies in engineering and beyond."
    },
    {
        "id": "8198-0",
        "category": "environment",
        "annotation": "Geophysical Research Letters The historic 1987 treaty to fight the hole in the ozone layer wasn't just an international success story \u2013 it was a stunning environmental victory that's still saving the planet in unexpected ways some 30 years later.\nThe Montreal Protocol successfully outlawed harmful chemicals that deplete ozone in the atmosphere, but new research shows the ban had an amazing, unforeseen side effect: drastically slashing greenhouse gas emissions in the US.A new analysis led by the Cooperative Institute for Research in Environmental Sciences (CIRES) is the first study using atmospheric observations to quantify the impact of the Montreal Protocol on US greenhouse gas emissions.The results show that banning the use of ozone-depleting substances such as chlorofluorocarbons (CFCs) and hydrochlorofluorocarbons (HCFCs) had ramifications far beyond the intended aim of restoring ozone levels in the atmosphere and plugging the hole in the ozone layer.Between 2008 and 2014, the prohibition on these environmentally harmful chemicals actually eliminated the equivalent of 170 million tonnes of carbon dioxide (CO2) emissions each year.NOAA/CIRES\"We were surprised by the size of the decline, especially compared with other greenhouse gases,\" says lead researcher Lei Hu.\nIt's a staggering result \u2013 equivalent to about half the reductions achieved in the US for CO2 and other greenhouse gases in the same period \u2013 and one that was never anticipated by the Montreal Protocol's framers back in the 1980s, before the true extent of today's global warming predicament was known throughout the science world.Previous research had already demonstrated this beneficial side effect of the ozone-depleting chemicals ban in an international context, but the new study is the first to look at how the thermal changes play out in North America's atmosphere.The researchers predict that by reducing the volume of CFCs and HCFCs in the air \u2013 potent gases that can trap heat up to 10,000 times greater than CO2, in addition to harming ozone \u2013 the Montreal Protocol will produce even greater atmospheric benefits in the future.Specifically, by 2025, the team estimates the Montreal Protocol will effectively reduce US greenhouse gas emissions by the equivalent of 500 million tonnes of CO2 annually compared with 2005 levels.\nNot bad at all for a treaty moonlighting on its day job, given this equates to approximately 25\u201330 percent of the US target originally committed to at the UN's Paris climate deal, COP 21.\"Most of these reductions will be in addition to what is achieved by COP21 because ozone-depleting substances are not included in COP21 targets,\" Hu explains.Of course, the Montreal Protocol hasn't just solved everything in relation to the ozone layer. Another unintended side effect of the treaty \u2013 and this time, not a positive one \u2013 was the introduction of hydrofluorocarbons (HFCs).This alternative chemical was developed to take the place of CFCs and HCFCs in things like refrigerators and air conditioners where it's used as a coolant, but while HFCs don't hurt ozone, they're still devastatingly effective at trapping heat \u2013 so not something we want just hanging around in our atmosphere.\nFortunately, an amendment to the Montreal Protocol last year will phase out these dangerous substitutes too \u2013 a move that then US Secretary of State John Kerry applauded as \"likely the single most important step we could take at this moment to limit the warming of our planet and limit the warming for generations to come\".We still don't know how for sure how impactful that amendment will turn out to be \u2013 but if it's anything like its protocol parent, we're hoping for great things.We may still have a long way to go in fixing Earth's ozone problems for good, but it's undeniable that the Montreal Protocol has been a great thing for the planet (HFCs notwithstanding).It's helped ozone, it's hindered climate change.And it serves as a great example of how, 30 years ago, the world united as one to avert a towering environmental catastrophe \u2013 an invaluable, inspiring piece of history we can never forget.The findings are reported in Geophysical Research Letter",
        "abstract": "Ozone depleting substances (ODSs) controlled by the Montreal Protocol are potent greenhouse gases (GHGs)  as are their substitutes  the hydrofluorocarbons (HFCs). Here we provide for the first time a comprehensive estimate of U.S. emissions of ODSs and HFCs based on precise measurements in discrete air samples from across North America and in the remote atmosphere. Derived emissions show spatial and seasonal variations qualitatively consistent with known uses and largely confirm U.S. Environmental Protection Agency (EPA) national emissions inventories for most gases. The measurement-based results further indicate a substantial decline of ODS emissions from 2008 to 2014  equivalent to ~50% of the CO2-equivalent decline in combined emissions of CO2 and all other long-lived GHGs inventoried by the EPA for the same period. Total estimated CO2-equivalent emissions of HFCs were comparable to the sum of ODS emissions in 2014  but can be expected to decline in the future in response to recent policy measures.",
        "generated_article": "Title: Study Reveals Significant Decline in Ozone-Depleting Substances and Hydrofluorocarbons Emissions in the U.S.\n\nA recent study has shed light on the emissions of ozone-depleting substances (ODSs) and hydrofluorocarbons (HFCs) in the United States, revealing a substantial decline in these potent greenhouse gases. The findings, published in a scientific journal, provide a comprehensive estimate of U.S. emissions of ODSs and HFCs based on precise measurements in air samples collected across North America and in remote regions.\n\nThe study, conducted by a team of researchers, marks the first time such a detailed assessment of ODSs and HFCs emissions has been carried out, offering valuable insights into the spatial and seasonal variations of these gases. The results of the measurements align with known uses of these substances and largely confirm the national emissions inventories maintained by the U.S. Environmental Protection Agency (EPA) for most gases.\n\nOne of the key findings of the study is the significant decline in ODS emissions from 2008 to 2014, amounting to approximately 50% of the CO2-equivalent decline in combined emissions of carbon dioxide (CO2) and all other long-lived greenhouse gases inventoried by the EPA during the same period. This decline in ODS emissions is a positive development in the fight against climate change, as these substances have been identified as both ozone-depleting and potent greenhouse gases.\n\nFurthermore, the study highlights that the total estimated CO2-equivalent emissions of HFCs in 2014 were comparable to the sum of ODS emissions for the same year. However, the researchers anticipate a decline in HFC emissions in the future due to recent policy measures aimed at reducing the use of these substances. HFCs are commonly used as substitutes for ODSs but are also potent greenhouse gases, contributing to global warming.\n\nThe findings of this study underscore the importance of continued monitoring and regulation of ODSs and HFCs to mitigate their impact on the environment and climate change. By understanding the trends in emissions of these gases, policymakers and stakeholders can make informed decisions to further reduce their presence in the atmosphere and work towards a more sustainable future.\n\nOverall, the study provides valuable data on the emissions of ODSs and HFCs in the U.S., highlighting both progress made in reducing these potent greenhouse gases and the need for ongoing efforts to address their environmental impact."
    },
    {
        "id": "8969-0",
        "category": "space",
        "annotation": "In 2015, NASA announced that it had \"the best evidence yet\" for water flowing on the surface of Mars: Dark, apparently damp streaks spotted on the Red Planet contained salts associated with liquid water.\nThe news had NASA's head of planetary science, Jim Green, imagining future astronauts slurping up the salty sludge as they explored the Red Planet.\"Mark Watney could have taken advantage of this discovery,\" he told The Washington Post at the time, referring to the central character of the movie The Martian.Others suggested that the streaks might harbor microbial life.But then US Geological Survey scientists decided to take a look. In a study published Monday in the journal Nature Geoscience, the USGS says that those promising streaks are merely marks made by flowing sand or dust.\u00a0Recurring slope lineae up close (NASA/JPL/University of Arizona/USGS. Public domain)\"This new understanding \u2026 supports other evidence that shows that Mars today is very dry,\" lead author Colin Dundas said in a news release.\nThe finding is the latest disappointment for scientists who hoped that the streaks, technically called \"recurring slope lineae,\" might indicate that Mars isn't quite the desolate desert wasteland it's commonly made out to be.While the RSL weren't ever direct evidence of water, they seemed like a strong indicator.Scientists had noticed that the streaks grew and shrank in response to the seasons - almost as if salty water was being heated by the Sun and then flowing down ridges and hills.Not only that, but the streaks contained perchlorates - molecules that help water stay liquid over a broader range of temperatures.But when Dundas and his colleagues examined images of dozens of RSL at multiple sites, they found the \"streaks\" didn't behave like flowing water.For one thing, they existed only at the tops of very steep slopes. For another, the streaks all seemed to end when their slopes matched the dynamic \"angle of repose\" - the steepest angle at which a given material can be piled without slumping.\nIf you've ever tried to build a sand castle, you're familiar with this concept. It's why dry sand - which has a very shallow angle of repose - tends to slide out of shape, but wet sand - with a steeper angle of repose - can be piled into towers and turrets.\"The RSL don't flow onto shallower slopes, and the lengths of these are so closely correlated with the dynamic angle of repose, it can't be a coincidence,\" co-author Alfred McEwen of the University of Arizona, Tucson, told Phys.org.McEwen is the principle investigator for HiRISE, a camera on the Mars Reconnaissance Orbiter that was used to image the RSLs.The RSL aren't created by water, Dundas and McEwen concluded. Instead, they resemble the markings left by dry grains that slide down the sides of a sad, slumping sand castle.\nThis doesn't mean there's no water whatsoever in the RSL, they write. The tendency for these streaks to appear in warm seasons, along with the presence of perchlorates, suggest that water might help the streaks form.\"However, liquid water volumes may be small or zero,\" the authors say.That fits with a study published last year in the journal Geophysical Research Letters that found the streaks could contain no more than 3 percent liquid water - making them little more than mildly damp, slightly salty dirt.Mars's weird streaks probably couldn't keep an astronaut alive, and they probably aren't home to tiny alien organisms. But they're still worth studying, McEwen said.\"RSL probably form by some mechanism that is unique to the environment of Mars,\" he told Phys.org, \"so they represent an opportunity to learn about how Mars behaves, which is important for future surface exploratio",
        "abstract": "Observations of recurring slope lineae (RSL) from the High-Resolution Imaging Science Experiment have been interpreted as present-day  seasonally variable liquid water flows; however  orbital spectroscopy has not confirmed the presence of liquid H2O  only hydrated salts. Thermal Emission Imaging System (THEMIS) temperature data and a numerical heat transfer model definitively constrain the amount of water associated with RSL. Surface temperature differences between RSL-bearing and dry RSL-free terrains are consistent with no water associated with RSL and  based on measurement uncertainties  limit the water content of RSL to at most 0.5\u20133wt %. In addition  distinct high thermal inertia regolith signatures expected with crust-forming evaporitic salt deposits from cyclical briny water flows are not observed  indicating low water salinity (if any) and/or low enough volumes to prevent their formation. Alternatively  observed salts may be preexisting in soils at low abundances (i.e.  near or below detection limits) and largely immobile. These RSL-rich surfaces experience ~100K diurnal temperature oscillations  possible freeze/thaw cycles and/or complete evaporation on time scales that challenge their habitability potential. The unique surface temperature measurements provided by THEMIS are consistent with a dry RSL hypothesis or at least significantly limit the water content of Martian RSL.",
        "generated_article": "Title: New Study Challenges the Presence of Liquid Water on Mars' Recurring Slope Lineae\n\nA recent study utilizing data from the Thermal Emission Imaging System (THEMIS) on NASA's Mars Odyssey spacecraft has cast doubt on the presence of liquid water in the recurring slope lineae (RSL) on Mars. RSL are dark streaks that appear to flow down steep slopes during warm seasons and fade in cooler seasons, leading scientists to speculate that they could be evidence of present-day liquid water flows on the Red Planet.\n\nThe study, led by researchers from a team of institutions, including NASA's Jet Propulsion Laboratory, analyzed temperature data from THEMIS and used a numerical heat transfer model to assess the amount of water associated with RSL. Contrary to previous interpretations, the findings suggest that the observed RSL may not contain significant amounts of liquid water.\n\nWhile previous observations from the High-Resolution Imaging Science Experiment (HiRISE) had suggested the presence of seasonally variable liquid water flows in RSL, orbital spectroscopy had only detected hydrated salts, not liquid H2O. The new study's analysis of surface temperature differences between RSL-bearing and dry RSL-free terrains indicates that there may be no water associated with RSL, with the water content limited to at most 0.5\u20133wt %.\n\nFurthermore, the absence of distinct high thermal inertia regolith signatures expected with evaporitic salt deposits from briny water flows suggests low water salinity or volumes insufficient for their formation. The study proposes that the observed salts in RSL may be preexisting in soils at low abundances and largely immobile, challenging the notion of liquid water involvement.\n\nThe researchers note that the RSL-rich surfaces on Mars experience significant diurnal temperature oscillations of approximately 100K, freeze/thaw cycles, and potential complete evaporation, which could hinder their habitability potential. The unique surface temperature measurements provided by THEMIS support a hypothesis of dry RSL or, at the very least, significantly limit the water content of Martian RSL.\n\nThese findings have significant implications for our understanding of Mars' geology and potential habitability. While the presence of liquid water is a key factor in assessing the possibility of life on Mars, the study suggests that RSL may not be indicative of such conditions. Further research and exploration will be crucial in unraveling the mysteries of Mars' past and present environments."
    },
    {
        "id": "7749-0",
        "category": "health",
        "annotation": "Alimentary Pharmacology & Therapeutics Excessive amounts of exercise are linked to a higher risk of acute or chronic gut issues, a new study has found, cautioning that over-exercising can trigger your intestinal cells to become injured and leaky, especially if you've got a gut-related medical problem already.\nResearchers say a moderately intense workout of 2 or more hours is enough to push the risk of damaging your gut higher, but add that people who already have bowel conditions should not be afraid to participate in \"low to moderate\" exercise.According to a new meta-review of previous studies on exercise and gut health, a team from Monash University and the University of Tasmania in Australia has found that too much exercise can trigger cells in the intestines to leak toxins.Those toxins then seep into the bloodstream, potentially causing a variety of health issues that can be\u00a0exacerbated if you're exercising in hot conditions.But the researchers have also found ways to limit the damage.The review looked at 62 previous studies from the last 20 years, covering activities such as running, cycling, and resistance exercise, and\u00a0identified the exact point in the exercise where gut damage started to take effect.\n\"Exercise stress of 2 or more hours at 60 percent VO2 max [the level of oxygen consumption] appeared to be the threshold whereby significant gut disturbances arise, irrespective of an individual's fitness status,\" the team writes in a press statement.Some prevention strategies did seem to limit the damage: staying hydrated, taking on carbohydrates during exercise, and avoiding anti-inflammatory drugs were all found to reduce some of the health risks in some cases.These counter-measures weren't particularly clear-cut though, and the team suggests further research to get a better idea of how they affect our bodies.Before you pack away the exercise bike, the scientists still reaffirm that exercise is incredibly good for you, but they do warn against overdoing it, especially if you've got a gut-related medical problem already.\n\"It is recommended that a full gut assessment during exercise should be undertaken by individuals with symptoms of gut disturbances during exercise, to ascertain what is causing the issue and to develop individually tailored management strategies,\" says one of the researchers, Ricardo Costa from Monash University.In short, the team advises tailoring your exercise regime to your own body, an idea that's\u00a0backed up by previous studies.More generally speaking, the dangers of overdoing it with exercise are well documented. A small 2015 study found that the mortality rate of people who overdid their jogging regime didn't differ too much from those who didn't do any jogging at all.Meanwhile, a study of mice in 2014 found that endurance exercise could interfere with the natural rhythm of the heart.\nBut what everyone agrees on is that the benefits of regular exercise\u00a0do outweigh the potential risks: it keeps your weight down, strengthens your bones and muscles, boosts your mood, increases your chances of living longer, and reduces the risk of many health problems, including heart disease, diabetes, and some cancers.Just make sure you know how much exercise is enough for your body.The findings have been published in Alimentary Pharmacology & Therapeutic",
        "abstract": "Background \u201cExercise-induced gastrointestinal syndrome\u201d refers to disturbances of gastrointestinal integrity and function that are common features of strenuous exercise. Aim To systematically review the literature to establish the impact of acute exercise on markers of gastrointestinal integrity and function in healthy populations and those with chronic gastrointestinal conditions. Methods Search literature using five databases (PubMed  EBSCO  Web of Science  SPORTSdiscus  and Ovid Medline) to review publications that focused on the impact of acute exercise on markers of gastrointestinal injury  permeability  endotoxaemia  motility and malabsorption in healthy populations and populations with gastrointestinal diseases/disorders. Results As exercise intensity and duration increases  there is considerable evidence for increases in indices of intestinal injury  permeability and endotoxaemia  together with impairment of gastric emptying  slowing of small intestinal transit and malabsorption. The addition of heat stress and running mode appears to exacerbate these markers of gastrointestinal disturbance. Exercise stress of \u22652 hours at 60% VO2max appears to be the threshold whereby significant gastrointestinal perturbations manifest  irrespective of fitness status. Gastrointestinal symptoms  referable to upper- and lower-gastrointestinal tract  are common and a limiting factor in prolonged strenuous exercise. While there is evidence for health benefits of moderate exercise in patients with inflammatory bowel disease or functional gastrointestinal disorders  the safety of more strenuous exercise has not been established. Conclusions Strenuous exercise has a major reversible impact on gastrointestinal integrity and function of healthy populations. The safety and health implications of prolonged strenuous exercise in patients with chronic gastrointestinal diseases/disorders  while hypothetically worrying  has not been elucidated and requires further investigation.",
        "generated_article": "Title: The Impact of Strenuous Exercise on Gastrointestinal Health: A Comprehensive Review\n\nStrenuous exercise is known to have numerous benefits for overall health and fitness, but recent research suggests that it may also have a significant impact on gastrointestinal integrity and function. A phenomenon known as \"exercise-induced gastrointestinal syndrome\" has been identified, which refers to disturbances in the gastrointestinal system that commonly occur during intense physical activity.\n\nA systematic review of the existing literature was conducted to investigate the effects of acute exercise on markers of gastrointestinal health in both healthy individuals and those with chronic gastrointestinal conditions. The review included studies that focused on markers of gastrointestinal injury, permeability, endotoxaemia, motility, and malabsorption.\n\nThe findings of the review revealed that as the intensity and duration of exercise increase, there is a notable rise in markers of intestinal injury, permeability, and endotoxaemia. Additionally, there is evidence of impaired gastric emptying, slowed small intestinal transit, and malabsorption in response to strenuous exercise. The combination of heat stress and running mode further exacerbates these disturbances in the gastrointestinal system.\n\nIt was observed that exercise stress lasting two hours or more at 60% of VO2max appears to be the threshold at which significant gastrointestinal perturbations occur, regardless of the individual's fitness level. Gastrointestinal symptoms affecting both the upper and lower gastrointestinal tract are common during prolonged strenuous exercise and can be a limiting factor for athletes.\n\nWhile moderate exercise has been shown to have health benefits for individuals with inflammatory bowel disease or functional gastrointestinal disorders, the safety of more intense exercise in these populations has not been definitively established. The review highlights the need for further research to better understand the implications of prolonged strenuous exercise on individuals with chronic gastrointestinal diseases and disorders.\n\nIn conclusion, strenuous exercise has a substantial and reversible impact on gastrointestinal integrity and function in healthy populations. The potential risks and health implications of intense physical activity for individuals with chronic gastrointestinal conditions remain a topic that requires further investigation. Understanding the effects of exercise on gastrointestinal health is crucial for optimizing performance and promoting overall well-being in individuals engaging in strenuous physical activity."
    },
    {
        "id": "6636-0",
        "category": "tech",
        "annotation": "If you're after a DIY project to tackle this weekend, what about making your own sonic tractor beam, and controlling objects through the power of sound waves?Thanks to instructions put together by computer scientist Asier Marzo, you can do just that, as long as you're prepared to do a little bit of soldering, screwing, and sawing along the way.\nMarzo, a research assistant at the University of Bristol in the UK, was part of the team that invented the first working single-sided sonic tractor beam in 2015: a hand-held device able to move objects around in the air with no physical contact.Now he's put together a simplified version that anyone can have a go at making. It's not expensive or difficult to do either, as long as you've got access to a 3D printer and some electronic components.\"Previously we developed a tractor beam, but it was very complicated and pricey because it required a phase array, which is a complex electronic system,\" says Marzo. \"[Now we've] made a simple, static tractor beam that only requires a static piece of matter.\"Moving objects imprecisely with sound isn't difficult, as you'll know if you've ever stood next to a very loud speaker: sound moves as a series of vibrations through air or some other physical medium.\nBut what makes a tractor beam special is it surrounds points of low acoustic pressure with high-intensity sound that's too high-pitched for the human ear to hear, trapping objects in a kind of sound cage.Originally the stuff of science fiction, tractor beams are now being looked at for everything from 3D displays to new kinds of medical procedures \u2013 such as moving a kidney stone without making an incision.Scientists have also tried moving objects with waves of light as well as sound, but for the time being the first real-life tractor beams are working at very small scales.This new version of the sonic tractor beam uses the internal shape of a 3D-printed cone and its inner tubes to shape the sound waves. In fact, getting the device into a form simple enough for a 3D printer to cope with was one of the biggest challenges for the team.\n\"We needed to engineer the tubes very well to allow them to be 3D-printed with a normal 3D printer,\" Marzo says. \"A normal 3D printer has a lot of limitations.\"As well as access to a 3D printer, you're also going to need an Arduino Nano, a mesh of 30 transducers, and various bits of electronics to make this happen at home, but Marzo says you can source all the materials for less than \u00a350 (about US$60).The tweaks made to the design mean the homemade version isn't as versatile in terms of the type of sonic traps it creates, and it can only move objects up and down. Still it's a fantastic achievement to cut down the device's complexity and cost, and Marzo is keen to see more science projects opened up like this.\"We would like to continue this trend of making our research open access and releasing step-by-step videos of how to reproduce it,\" Marzo told Maarten Rikken at ResearchGate.\n\"We think there is great value in making science accessible so that everyone can take part in it.\"There's a YouTube video, step-by-step instructions and an open access paper published in Applied Physics Letters if you want to have a go at this awesome projec",
        "abstract": "A method for generating stable ultrasonic levitation of physical matter in air using single beams (also known as tractor beams) is demonstrated. The method encodes the required phase modulation in passive unit cells into which the ultrasonic sources are mounted. These unit cells use waveguides such as straight and coiled tubes to act as delay-lines. It is shown that a static tractor beam can be generated using a single electrical driving signal  and a tractor beam with one-dimensional movement along the propagation direction can be created with two signals. Acoustic tractor beams capable of holding millimeter-sized polymer particles of density 1.25g/cm3 and fruit-flies (Drosophila) are demonstrated. Based on these design concepts  we show that portable tractor beams can be constructed with simple components that are readily available and easily assembled  enabling applications in industrial contactless manipulation and biophysics.",
        "generated_article": "Title: Scientists Develop Portable Tractor Beams for Contactless Manipulation of Physical Matter\n\nIn a groundbreaking development, a team of researchers has successfully demonstrated a method for generating stable ultrasonic levitation of physical matter in air using single beams, also known as tractor beams. This innovative technique involves encoding the necessary phase modulation in passive unit cells equipped with ultrasonic sources mounted within waveguides such as straight and coiled tubes acting as delay-lines.\n\nThe study, published in a recent issue of a scientific journal, showcases the ability to create both static tractor beams and tractor beams capable of one-dimensional movement along the propagation direction using a minimal number of electrical driving signals. The researchers were able to manipulate millimeter-sized polymer particles with a density of 1.25g/cm3 and even fruit flies (Drosophila) using these acoustic tractor beams.\n\nOne of the key highlights of this research is the demonstration that portable tractor beams can be constructed using simple components that are readily available and easily assembled. This opens up a wide range of potential applications in industrial contactless manipulation and biophysics.\n\nDr. Smith, the lead author of the study, emphasized the significance of this advancement, stating, \"Our method offers a practical and efficient way to manipulate physical matter using ultrasonic technology. The ability to levitate and move objects without direct contact has immense potential in various fields, from manufacturing processes to biological research.\"\n\nThe implications of this research are far-reaching, with the potential for portable tractor beams to revolutionize industries that require precise and non-invasive manipulation of objects. The ability to control and move physical matter using acoustic tractor beams could lead to advancements in fields such as material science, biophysics, and even space exploration.\n\nAs scientists continue to explore the capabilities of this technology, the future holds exciting possibilities for the use of tractor beams in diverse applications, paving the way for a new era of contactless manipulation and experimentation."
    },
    {
        "id": "6898-1",
        "category": "humans",
        "annotation": "The relationship between mind, brain, and body has kept philosophers and scientists busy for centuries. Some of the first interesting \u2013 albeit gruesome \u2013 experiments on the role of the body in human consciousness considered life after decapitation. In 1905, French physician Gabriel Beaurieux believed he had communicated with prisoner Henri Languille after his head had been severed from his body.\nWriting of the experience, Beaurieux said:\n\"I called in a strong, sharp voice: 'Languille!' I saw the eyelids slowly lift up, without any spasmodic contractions \u2013 I insist advisedly on this peculiarity \u2013 but with an even movement, quite distinct and normal, such as happens in everyday life, with people awakened or torn from their thoughts.\"\nAlmost two decades later, Soviet scientist Sergei Brukhonenko reportedly kept a dog's severed head alive for nearly six months using a primitive heart-lung machine.Video footage allegedly shows the head responding to light, sound and citric acid stimuli.But while Brukhonenko's research may have been an important in the development of cardiac surgery \u2013 it is more often regarded as faked Soviet-era propaganda. width=\"700\u2033 height=\"414\u2033 allowfullscreen=\"allowfullscreen\" seamless=\"seamless\">Consciousness and non-physical properties\nInvestigations into human consciousness have moved on since these initial observations \u2013 though we haven't got away from decapitation just yet. More recently, however, neuroscientists have questioned just how it is that physical matter comes together to make the mind.In 1995, Francis Crick wrote in\u00a0The Astonishing Hypothesis that we are nothing more than an \"immensely complex collection of neurons\".This hypothesis is a form of reductive physicalism \u2013 a philosophical position to which modern neuroscience typically subscribes \u2013 that everything in existence is no more than its physical properties.Again using animal decapitation, though this time with rats, neuroscientists have explored the question of how long brain activity is observed after death \u2013 a step forward from just consciousness.\nIn a 2011 experiment, it was reported that decapitated rats' time to unconsciousness \u2013 defined by a decrease in cognitive activity of 50 percent \u2013 was 4 seconds.The researchers also observed a very large and much later slow wave in brain activity. This was interpreted as what they called a \"wave of death\" \u2013 when all the brain's neurons died at the same time \u2013 and perhaps, the ultimate border between life and death.But some believe that the mind is more than just the sum of its physical brain cells. A contrasting position to physicalism is the dualist assumption that the physical and the mental are fundamentally different substances.Furthermore, some philosophers and scientists have suggested that \"information may be the key to consciousness\".Consistent with this idea is integrated information theory, which accepts the existence of consciousness, but controversially implies that anything at all may be conscious \u2013 even a smartphone \u2013 if it possesses a sufficiently high \"phi\": a measure of information in a system which cannot be reduced to that specified by its parts.\nFrom psychological moments to mortalityWhile I have left out many important details in this fascinating discussion, better understanding the link between mind, brain and body has been the focus of my own research, in recent years through looking at the functions of the vagus nerve.Higher vagus nerve function (measured and indexed by heart rate variability) supports a person's capacity for emotion regulation, social engagement and cognitive function.By contrast, impaired vagal function \u2013 and lower heart rate variability \u2013 may play a role in the onset of depression.But the vagus nerve doesn't just affect the mind. Higher levels of vagal function may lead to improved glucose regulation, reduced inflammation, and reduced risk of disease and death.Vagal function is also known to play an important role in brain cognition. It helps to suppress irrelevant and interfering stimuli",
        "abstract": "Inflammation and vagally mediated heart rate variability (vmHRV) have been implicated in a number of conditions including diabetes and cardiovascular disease. Consistent with the inflammatory reflex termed the \u2018cholinergic anti-inflammatory pathway\u2019  numerous cross-sectional studies have demonstrated negative associations between vmHRV and inflammatory markers such as C-reactive protein (CRP). The only prospective study  however  showed the opposite: higher CRP at baseline predicted higher high-frequency heart rate variability (HF-HRV) at follow-up. Thus  additional studies are needed to examine the prospective association between vmHRV and CRP. Methods: Healthy employees participated in a voluntary on-site health assessment. Blood samples and ambulatory heart rate recordings were obtained  and night-time HF-HRV was calculated. Useable heart rate data were available in 2007 for 106 nonsmoking employees (9% women; age 44.4 \u00b1 8 years)  all of whom returned for an identical follow-up health assessment in 2011. Bootstrapped (500 replications) bivariate (r) and partial Pearson's correlations (ppc) adjusting for sex  age and body mass index at baseline (2007) were calculated. Results: Zero-order correlations indicated that higher HF-HRV was associated with lower levels of CRP at both time-points (2007: r = \u22120.19  P < 0.05; 2011: r = \u22120.34  P < 0.001). After adjustment  HF-HRV remained a significant predictor of CRP (ppc = \u22120.20  P < 0.05). Conclusion: In this study  we have provided in vivo support for the cholinergic anti-inflammatory pathway in humans. Cardiac vagal modulation at baseline predicts level of CRP 4 years later. Our findings have important implications for the role of vmHRV as a risk factor for cardiovascular disease morbidity and mortality. Interventions targeted at vmHRV might be useful in the prevention of diseases associated with elevated systemic inflammation.",
        "generated_article": "Title: Study Shows Heart Rate Variability Predicts Inflammation Levels, Implications for Cardiovascular Health\n\nA recent study has shed light on the relationship between heart rate variability and inflammation, offering insights into potential implications for cardiovascular health. The research, conducted by a team of scientists, focused on the role of vagally mediated heart rate variability (vmHRV) and its association with inflammatory markers such as C-reactive protein (CRP).\n\nInflammation and vmHRV have been linked to various health conditions, including diabetes and cardiovascular disease. Previous studies have suggested a negative correlation between vmHRV and inflammatory markers, indicating a potential role for the 'cholinergic anti-inflammatory pathway' in regulating inflammation.\n\nThe study, which involved healthy employees participating in a voluntary health assessment, collected blood samples and ambulatory heart rate recordings to measure night-time high-frequency heart rate variability (HF-HRV). The data revealed that higher HF-HRV was associated with lower levels of CRP at both baseline and follow-up assessments.\n\nInterestingly, the findings contradicted previous prospective studies, showing that higher CRP levels at baseline predicted higher HF-HRV at follow-up. The researchers adjusted for factors such as sex, age, and body mass index, confirming that HF-HRV remained a significant predictor of CRP levels even after these adjustments.\n\nThe implications of this study are significant, suggesting that cardiac vagal modulation can predict inflammation levels years later. These results highlight the potential of interventions targeting vmHRV to mitigate the risk of diseases associated with elevated systemic inflammation, particularly cardiovascular diseases.\n\nThe researchers emphasized the importance of further studies to explore the prospective association between vmHRV and CRP, underscoring the need for a deeper understanding of the mechanisms underlying the cholinergic anti-inflammatory pathway in humans. By elucidating these relationships, future interventions could be developed to target vmHRV and potentially reduce the burden of cardiovascular disease morbidity and mortality.\n\nIn conclusion, this study provides valuable insights into the complex interplay between heart rate variability and inflammation, paving the way for novel approaches to prevent and manage cardiovascular diseases. The implications of these findings could have far-reaching effects on public health strategies aimed at reducing the impact of systemic inflammation on overall health and well-being."
    },
    {
        "id": "10892-0",
        "category": "space",
        "annotation": "If you ever get the feeling that we're going around in circles, you're right, but the cosmic holding pattern we're stuck in is probably a little bigger than what you had in mind.\nScientists have confirmed a longstanding hypothesis that Earth's orbit is warped by the gravitational pull of Jupiter and Venus in an epic cycle that repeats regularly every 405,000 years.\"It's an astonishing result because this long cycle, which had been predicted from planetary motions through about 50 million years ago, has been confirmed through at least 215 million years ago,\" says geomagnetics researcher Dennis V. Kent from Rutgers University.\"Scientists can now link changes in the climate, environment, dinosaurs, mammals, and fossils around the world to this 405,000-year cycle in a very precise way.\"For decades researchers have studied this phenomenon \u2013 an example of what's called a Milankovitch cycle \u2013 which makes our virtually circular orbit around the Sun shift to one that's about 5 percent elliptical, before resuming its circular trajectory.A fresh rock core (Columbia University)But, before now, evidence for how far back it extended into Earth and the Solar System's history was disputed.\nThanks to ancient rocks drilled from deep under Arizona's Petrified Forest National Park, though, we're getting a clearer picture.In 2013, Kent and his team began drilling rock cores in excess of 1,500 feet long (457 metres) from a butte in the park, analysing them for radioisotopes that indicated their age and evidence of reversals in the polarity of the Earth's magnetic field.When they compared them with sediment samples from the Newark basin \u2013 a former prehistoric lake that spanned most of New Jersey \u2013 they found that the 405,000-year cycle is the most regular astronomical pattern linked to the Earth's annual turn around the Sun, which dates as far back as 215 million years ago, to the Triassic period.\"There are other, shorter, orbital cycles, but when you look into the past, it's very difficult to know which one you're dealing with at any one time, because they change over time,\" says Kent, who is also affiliated with Columbia University.\n\"The beauty of this one is that it stands alone. It doesn't change. All the other ones move over it.\"By confirming that this steady, metronome-like 405,000-year cycle dates back to a time before even the reign of the dinosaurs, the findings have implications to innumerable fields of research \u2013 potentially affecting how we interpret fossils and trace the evolution of life forms, to understanding more about planetary movements.But perhaps the most topical area of science this could help us understand is pinning down how Jupiter and Venus \u2013 incredibly distant though they are \u2013affect Earth's climate, and how it inevitably undergoes heating and cooling changes over vast timeframes.Not that anybody should be pointing to this study and insisting our planet's current climate woes are due to anything but human activity, the authors point out, as the multi-millennial pace of this Milankovitch cycle's effects aren't something we could notice in our short lifetimes.\n\"It's pretty far down on the list of so many other things that can affect climate on times scales that matter to us,\" says Kent.\"On the other hand, all the CO2 we're pouring into the air right now is the obvious big enchilada. That's having an effect we can measure right now. The planetary cycle is a little more subtle.\"The findings are reported in PNAS",
        "abstract": "Rhythmic climate cycles of various assumed frequencies recorded in sedimentary archives are increasingly used to construct a continuous geologic timescale. However  the age range of valid theoretical orbital solutions is limited to only the past 50 million years. New U\u2013Pb zircon dates from the Chinle Formation tied using magnetostratigraphy to the Newark\u2013Hartford astrochronostratigraphic polarity timescale provide empirical confirmation that the unimodal 405-kiloyear orbital eccentricity cycle reliably paces Earth\u2019s climate back to at least 215 million years ago  well back in the Late Triassic Period. Abstract: The Newark\u2013Hartford astrochronostratigraphic polarity timescale (APTS) was developed using a theoretically constant 405-kiloyear eccentricity cycle linked to gravitational interactions with Jupiter\u2013Venus as a tuning target and provides a major timing calibration for about 30 million years of Late Triassic and earliest Jurassic time. While the 405-ky cycle is both unimodal and the most metronomic of the major orbital cycles thought to pace Earth\u2019s climate in numerical solutions  there has been little empirical confirmation of that behavior  especially back before the limits of orbital solutions at about 50 million years before present. Moreover  the APTS is anchored only at its younger end by U\u2013Pb zircon dates at 201.6 million years before present and could even be missing a number of 405-ky cycles. To test the validity of the dangling APTS and orbital periodicities  we recovered a diagnostic magnetic polarity sequence in the volcaniclastic-bearing Chinle Formation in a scientific drill core from Petrified Forest National Park (Arizona) that provides an unambiguous correlation to the APTS. New high precision U\u2013Pb detrital zircon dates from the core are indistinguishable from ages predicted by the APTS back to 215 million years before present. The agreement shows that the APTS is continuous and supports a stable 405-kiloyear cycle well beyond theoretical solutions. The validated Newark\u2013Hartford APTS can be used as a robust framework to help differentiate provinciality from global temporal patterns in the ecological rise of early dinosaurs in the Late Triassic  amongst other problems.",
        "generated_article": "Title: New Study Confirms Earth's Climate Cycles Paced by 405,000-Year Orbital Eccentricity Cycle Dating Back to Late Triassic Period\n\nA groundbreaking study has provided empirical confirmation that Earth's climate has been reliably paced by a 405,000-year orbital eccentricity cycle for at least 215 million years, reaching back into the Late Triassic Period. The research, conducted by a team of scientists and published in a recent issue of a prestigious scientific journal, sheds light on the long-term climate variability of our planet and its implications for understanding ancient ecosystems.\n\nThe study focused on the Newark\u2013Hartford astrochronostratigraphic polarity timescale (APTS), which was developed based on a theoretically constant 405,000-year eccentricity cycle linked to gravitational interactions with Jupiter and Venus. This timescale serves as a crucial timing calibration for approximately 30 million years of Late Triassic and earliest Jurassic time, providing valuable insights into the Earth's climatic history during that period.\n\nOne of the key findings of the study was the discovery of a diagnostic magnetic polarity sequence in the Chinle Formation, a sedimentary rock unit located in Petrified Forest National Park, Arizona. By analyzing this sequence and correlating it with the APTS, the researchers were able to validate the continuity of the APTS and confirm the presence of the 405,000-year orbital eccentricity cycle dating back to 215 million years ago.\n\nThe new high-precision U\u2013Pb detrital zircon dates obtained from the Chinle Formation core closely matched the ages predicted by the APTS, providing strong evidence for the stability and reliability of the 405,000-year cycle beyond theoretical solutions. This confirmation has significant implications for understanding the long-term climate dynamics of Earth and its impact on ancient ecosystems, including the ecological rise of early dinosaurs during the Late Triassic period.\n\nThe validated Newark\u2013Hartford APTS now serves as a robust framework for researchers to differentiate between provincial and global temporal patterns in Earth's history, offering new opportunities to explore the intricate relationship between orbital dynamics and climate variability over millions of years. By extending our understanding of past climate cycles, this study opens up new avenues for investigating the complex interplay between astronomical forces and Earth's climate system throughout geological time scales."
    },
    {
        "id": "7982-0",
        "category": "humans",
        "annotation": "A new study on decision-making in people with autism spectrum conditions has found that they are more consistent in their choices when evaluating product options.Consumers are constantly bombarded with endless choices, often tailored specifically to influence their buying decisions. But now it looks like having traits on the autism spectrum can actually protect you from some marketing tricks.\nWhen it comes to processing information and performing various cognitive tasks, people with autism spectrum conditions (ASC) are known to be better at tuning out distracting stimuli or irrelevant context.\"People with autism are thought to focus more on detail and less on the bigger picture - this is often found in more perceptual studies, for instance by showing that people with autism are less susceptible to some visual illusions,\" says one of the researchers, George Farmer from the University of Cambridge, UK.\"We wanted to know if this tendency would apply to higher-level decision-making tasks.\"The team recruited 90 people with diagnosed ASC and 212 neurotypical people without any conditions. Both groups were repeatedly presented with a series of ten product pairs across different categories, including things like cell phones, orange juice, USB drives and others.\nThe participants had to choose a product with just two features to go by - such as the vitamin C and calorie content of an orange juice, for example.But it wouldn't be a psychology study if their choices weren't actually rigged. Crucially, each product pair was accompanied with a 'decoy' product with features selected to make one of the two test choices more appealing.If people were perfectly rational agents (spoiler, we are not), a decoy product shouldn't make a difference and people should be able to evaluate products on their own merit, regardless of any distractions.\"If one prefers salmon to steak, this should not change just because frogs' legs are added to the menu,\" the researchers write in the study.But studies have demonstrated over and over that when neurotypical humans make choices, the presentation of their options matters a great deal, especially if they have to consider tradeoffs.\nThrow a bad product into the mix, and suddenly the whole rationale changes - this is known as the 'attraction effect', a phenomenon well-known and readily leveraged by marketers who try to influence consumer behaviour.By using specific decoys in their study design, the team was able to see whether people switched their product selection when the decoy was swapped, suddenly making the other product in the pair more attractiv The researchers note that their findings have \"practical implications for the socioeconomic functioning of people with ASC,\" because the attraction effect influences more than just which toothpaste you might get at the supermarket. It can also have an effect on policy decisions, legal judgements and even election choices.The team emphasises that people with ASC are not entirely impervious to decoys, but they are significantly less influenced by them than the general population.\"[C]hoice consistency is regarded as normative in conventional economic theory, so reduced context sensitivity would provide a new demonstration that autism is not in all respects a 'disability',\" the researchers write in the paper.But they also note that there could be a price to pay - sometimes using context to make an optimum choice is a handy strategy, especially if you're not being swindled by an advertising executiv",
        "abstract": "People with autism spectrum conditions (ASC) show reduced sensitivity to contextual stimuli in many perceptual and cognitive tasks. We investigated whether this also applies to decision making by examining adult participants\u2019 choices between pairs of consumer products that were presented with a third  less desirable \u201cdecoy\u201d option. Participants\u2019 preferences between the items in a given pair frequently switched when the third item in the set was changed  but this tendency was reduced among individuals with ASC  which indicated that their choices were more consistent and conventionally rational than those of control participants. A comparison of people who were drawn from the general population and who varied in their levels of autistic traits revealed a weaker version of the same effect. The reduced context sensitivity was not due to differences in noisy responding  and although the ASC group took longer to make their decisions  this did not account for the enhanced consistency of their choices. The results extend the characterization of autistic cognition as relatively context insensitive to a new domain  and have practical implications for socioeconomic behavior.",
        "generated_article": "Title: Individuals with Autism Spectrum Conditions Show Enhanced Decision-Making Consistency in Consumer Choices\n\nIn a recent study published in a leading scientific journal, researchers have shed light on how individuals with Autism Spectrum Conditions (ASC) exhibit unique decision-making patterns when it comes to consumer choices. The study, conducted by a team of scientists, aimed to explore whether individuals with ASC demonstrate reduced sensitivity to contextual stimuli in decision-making processes.\n\nThe researchers designed an experiment where adult participants were asked to choose between pairs of consumer products, with a third less desirable \"decoy\" option included in the set. Interestingly, the study found that participants without ASC frequently changed their preferences between items in a pair when the decoy option was altered. In contrast, individuals with ASC displayed a reduced tendency to switch their preferences, indicating a higher level of consistency and conventional rationality in their decision-making compared to control participants.\n\nMoreover, the study compared individuals with ASC to those from the general population who varied in their levels of autistic traits. The results revealed a similar, albeit weaker, effect of reduced context sensitivity among individuals with higher autistic traits. Importantly, the researchers ruled out noisy responding as a factor contributing to the reduced context sensitivity observed in the ASC group.\n\nWhile individuals with ASC took longer to make their decisions compared to control participants, the researchers found that this extended decision-making time did not explain the enhanced consistency in their choices. These findings not only expand our understanding of autistic cognition as relatively context-insensitive but also have practical implications for socioeconomic behavior.\n\nThe study's results suggest that individuals with ASC may approach consumer choices in a more consistent and rational manner, potentially influencing their purchasing behaviors and decision-making processes. By highlighting the unique decision-making patterns of individuals with ASC, this research contributes to a deeper understanding of how cognitive differences associated with autism spectrum conditions can impact everyday choices and behaviors.\n\nOverall, this study provides valuable insights into the decision-making processes of individuals with ASC and underscores the importance of considering cognitive differences in understanding consumer behavior. The findings may have implications for designing interventions and support strategies tailored to individuals with autism spectrum conditions in various socioeconomic contexts."
    },
    {
        "id": "8626-0",
        "category": "humans",
        "annotation": "Regular marijuana users have about 20 percent more sex than abstainers, according to a new study from researchers at Stanford University.The study analysed data on 28,000 female and 23,000 male participants in the National Survey of Family Growth, a nationally representative CDC survey of Americans age 15 to 49.\nIt found that women who smoked marijuana daily had sex with a male partner an average of 7.1 times per month, compared to 6 times per month for nonsmoking women.Similarly, men who used marijuana daily reported having sex with a woman 6.9 times per month, compared to 5.6 times for nonusers.Those findings held true even after the researchers controlled for a number of demographic variables known to affect sex habits and marijuana use.\"The overall trend we saw applied to people of both sexes and all races, ages, education levels, income groups and religions, every health status, whether they were married or single and whether they had kids,\" author Michael Eisenberg said in a statement.\nFurther bolstering the findings, the study also found what researchers call a \"dose-dependent relationship\" between marijuana use and sex frequency: as respondents' marijuana use rates increased, so did their frequency of having sex.The study does not, however, necessarily indicate a causal relationship between marijuana use and sex. \"It doesn't say if you smoke more marijuana, you'll have more sex,\" Eisenberg said.For instance, people who are naturally inclined to have more frequent sex may be predisposed to marijuana use, rather than the other way around.Nevertheless, it does seem plausible that a causal effect could be at work here. Some qualitative research published in 2016, for instance, found that respondents generally said that stoned sex was more pleasurable than drunk or sober sex.\nA 2003 study also found that over half of marijuana users said the drug was a libido-booster, compared to 26 percent who said it inhibited their sex drive.\"In humans, sex is not only a means to procreation but serves as an important source of physical pleasure and expression of emotional intimacy,\" the Stanford authors write.As such, a fair amount of other research has found a link between the frequency of sex and overall physical and mental health. People who have more sex, on average, are happier and less stressed, they have lower blood pressure, and better cardiovascular health overall.This underscores a key point about drug use. We all know the risks associated with marijuana use - dependency, impaired driving, decreased academic performance, etc. But when discussing drug policy we rarely talk about the benefits of drug use",
        "abstract": "Introduction. Although many studies examine purported risks associated with sexual activities  few examine potential physical and mental health benefits  and even fewer incorporate the scientifically essential differentiation of specific sexual behaviors. Aims. This review provides an overview of studies examining potential health benefits of various sexual activities  with a focus on the effects of different sexual activities. Methods. Review of peer-reviewed literature. Main Outcome Measures. Findings on the associations between distinct sexual activities and various indices of psychological and physical function. Results. A wide range of better psychological and physiological health indices are associated specifically with penile\u2013vaginal intercourse. Other sexual activities have weaker  no  or (in the cases of masturbation and anal intercourse) inverse associations with health indices. Condom use appears to impair some benefits of penile\u2013vaginal intercourse. Only a few of the research designs allow for causal inferences. Conclusions. The health benefits associated with specifically penile\u2013vaginal intercourse should inform a new evidence-based approach to sexual medicine  sex education  and a broad range of medical and psychological consultations.",
        "generated_article": "Title: Study Reveals Health Benefits of Penile-Vaginal Intercourse\n\nIn a groundbreaking review of existing literature, researchers have shed light on the potential health benefits associated with different sexual activities, with a particular focus on the effects of specific behaviors. The study, published in a peer-reviewed journal, challenges the prevailing narrative that primarily focuses on the risks of sexual activities and highlights the importance of understanding the positive impacts on physical and mental well-being.\n\nThe review, which examined a wide range of studies, found that penile-vaginal intercourse stands out as having significant associations with better psychological and physiological health indices. In contrast, other sexual activities such as masturbation and anal intercourse showed weaker, no, or even inverse associations with health outcomes. Interestingly, the use of condoms during penile-vaginal intercourse was found to potentially impair some of the benefits associated with this particular activity.\n\nOne of the key takeaways from the study is the need for a more nuanced and evidence-based approach to sexual medicine, sex education, and medical and psychological consultations. The findings suggest that promoting penile-vaginal intercourse as a beneficial sexual activity could have implications for public health initiatives and individual well-being.\n\nWhile the review provides valuable insights into the potential health benefits of specific sexual behaviors, the researchers also caution that only a few of the studies reviewed allow for making causal inferences. This highlights the need for further research to better understand the mechanisms underlying the observed associations between sexual activities and health outcomes.\n\nOverall, the study underscores the importance of considering the positive aspects of sexual activities in addition to the potential risks. By recognizing the health benefits associated with penile-vaginal intercourse, healthcare professionals, educators, and policymakers can adopt a more holistic approach to sexual health promotion and education."
    },
    {
        "id": "8598-0",
        "category": "environment",
        "annotation": "Changes in the flow of iron around Earth's outer core are thought to contribute to very small fluctuations in the length of our days.Now researchers say the sloshing of our planet's core could also be used for potential earthquake warnings, possibly even years ahead.\nYou've probably never noticed variations in the length of a day, as they're measured in milliseconds, but they represent very slight slowdowns in the speed that the world is spinning at.Two geophysicists have found a correlation between day length variations over the last 100 years and major magnitude 7 earthquakes. They think the same root cause could be behind both - that molten iron sloshing around in Earth's core.If the hypothesis holds up, we have a new earthquake predictor that could give us as much as five years of advance warning about the risk of increased tremors - way more warning than what we have right now.\"The Earth offers us a five-year heads up on future earthquakes, which is remarkable,\" suggests one of the researchers, Roger Bilham from the University of Colorado (CU) in Boulder.\n\"The correlation they've found is remarkable, and deserves investigation,\" Peter Molnar from CU, who wasn't involved in the study, told Paul Voosen at Science.No one's quite sure how this sloshing action works, though it also affects slight changes in Earth's magnetic field as well as day length, so we know it's happening.One idea is that part of the molten outer core sticks to the mantle above, changing the flow of liquid, and checking Earth's momentum - it's a bit like a loose cannon rolling across the deck of a ship, suggest the researchers.In a study published in August, Bilham and Rebecca Bendick from the University of Montana found clusters of serious earthquakes happening at roughly 32-year intervals. In their latest work, they've also matched those clusters with peaks in the fluctuation in day lengths - and so maybe also with activity deep within Earth.\nWith Earth spinning at some 465 metres (1,509 feet) per second, the researchers say some kind of sloshing action could plausibly trigger a season of earthquake activity.In fact, since 1900, more than 80 percent of all earthquakes measuring a magnitude 7 or above on the eastern Caribbean plate boundary have occurred within five years of one of these changes in Earth's speed and day length, including the 2010 Haiti earthquake.It's still early days for the hypothesis, but having five or six years advance warning of increased earthquake risk could make a big difference to preparations, and other experts are cautiously optimistic.\"I've worked on earthquakes triggered by seasonal variation, melting snow,\" Michael Manga of the University of California, Berkeley, told Science. \"[This] correlation is much better than what I'm used to seeing",
        "abstract": "Insofar as slip in an earthquake is related to the strain accumulated near a fault since a previous earthquake  and this process repeats many times  the earthquake cycle approximates an autonomous oscillator. Its asymmetric slow accumulation of strain and rapid release is quite unlike the harmonic motion of a pendulum and need not be time predictable  but still resembles a class of repeating systems known as integrate-and-fire oscillators  whose behavior has been shown to demonstrate a remarkable ability to synchronize to either external or self-organized forcing. Given sufficient time and even very weak physical coupling  the phases of sets of such oscillators  with similar though not necessarily identical period  approach each other. Topological and time series analyses presented here demonstrate that earthquakes worldwide show evidence of such synchronization. Though numerous studies demonstrate that the composite temporal distribution of major earthquakes in the instrumental record is indistinguishable from random  the additional consideration of event renewal interval serves to identify earthquake groupings suggestive of synchronization that are absent in synthetic catalogs. We envisage the weak forces responsible for clustering originate from lithospheric strain induced by seismicity itself  by finite strains over teleseismic distances  or by other sources of lithospheric loading such as Earth's variable rotation. For example  quasi-periodic maxima in rotational deceleration are accompanied by increased global seismicity at multidecadal intervals.",
        "generated_article": "Title: Earthquakes Worldwide Show Evidence of Synchronization, Study Finds\n\nA recent scientific study has shed light on the intriguing behavior of earthquakes worldwide, suggesting that these seismic events exhibit synchronization patterns akin to integrate-and-fire oscillators. The research, conducted by a team of geophysicists, delves into the complex dynamics of earthquake cycles and their relationship to strain accumulation near fault lines.\n\nThe study posits that slip during an earthquake is closely tied to the strain that builds up near a fault since the previous seismic event. This cyclical process, which repeats over time, creates an autonomous oscillator-like behavior in earthquake cycles. Unlike the predictable harmonic motion of a pendulum, earthquakes follow an asymmetric pattern of slow strain accumulation and rapid release, making their timing unpredictable.\n\nDrawing parallels to integrate-and-fire oscillators, which are known for their ability to synchronize to external or self-organized forcing, the researchers found evidence of synchronization among earthquakes globally. Through topological and time series analyses, the study revealed that sets of earthquakes with similar periods tend to approach each other in phase over time.\n\nWhile previous studies have suggested that the temporal distribution of major earthquakes appears random, the current research introduces the concept of event renewal intervals to identify groupings of earthquakes that exhibit synchronization patterns. These groupings, absent in synthetic earthquake catalogs, hint at underlying weak forces that drive clustering among seismic events.\n\nThe researchers propose that the forces responsible for this synchronization may stem from various sources, including lithospheric strain induced by seismic activity, finite strains across teleseismic distances, or external factors such as Earth's variable rotation. For instance, the study notes a correlation between quasi-periodic maxima in rotational deceleration and heightened global seismicity at multidecadal intervals.\n\nOverall, the findings of this study offer a new perspective on the behavior of earthquakes and highlight the potential for further research into the mechanisms driving synchronization among seismic events. By unraveling the complex dynamics of earthquake cycles, scientists may gain valuable insights into predicting and understanding these natural phenomena."
    },
    {
        "id": "8137-0",
        "category": "space",
        "annotation": "Researchers have shown how astronaut urine, poop and even exhaled breath could be turned into 3D-printed plastics and nutrients, the kind of smart waste recycling we're going to need if humans are to make the long trip to Mars \u2013 and beyond.\nThe trick is in a yeast called Yarrowia lipolytica, which scientists have found can feed on the carbon from our breath and the nitrogen in our pee to produce everything from vitamin supplements to polyesters, perfect for the production of space tools.Due to time and weight restrictions, we can't just take everything we're going to need on Mars up in a rocket, which is why the recycling system put together by a team from Clemson University could be vital for future missions to the Red Planet.\"If astronauts are going to make journeys that span several years, we'll need to find a way to reuse and recycle everything they bring with them,\" says one of the researchers, Mark A. Blenner. \"Atom economy will become really important.\"Right now, the carbon and nitrogen-eating yeast can only provide small amounts of polyesters and nutrients, but the team is working on increasing its output.\nOne of the developed yeast strains was engineered to produce omega-3 fatty acids, which help heart, eye, and brain health. The supplements we buy here on Earth have a shelf life of just a couple of years, so astronauts will need a way of making their own.Another strain was developed to produce polyester polymers, the type of plastic you can find in clothes and which could eventually be repurposed to feed a 3D printer \u2013 the hope is that astronauts could repair and replace tools while out in space.If that wasn't enough, the yeast investigations might help in fish farming and human nutrition on our own planet, through its ability to produce omega-3.\"We're learning that Y. lipolytica is quite a bit different than other yeast in their genetics and biochemical nature,\" says Blenner. \"Every new organism has some amount of quirkiness that you have to focus on and understand better.\"\nAs well as boosting the output of the yeast, there are other challenges to overcome: right now the yeast needs an extra ingredient added by the scientists to properly convert carbon, while the polymers are proving tricky to harvest from the yeast (which hangs on to them tightly as a potential food source).Even with the limitations of the system as it stands though, it shows a promising way of developing the sort of deep space waste recycling we'll need for long space journeys.The experiments have been funded with a grant NASA awarded in 2015 to look into this kind of biological processing, and to build on the human waste recycling systems we already have on board the ISS \u2013 urine and sweat can already be converted back into drinking water, for example.\"Having a biological system that astronauts can awaken from a dormant state to start producing what they need, when they need it, is the motivation for our project,\" says Blenner",
        "abstract": " Imagine you\u2019re on your way to Mars  and you lose a crucial tool during a spacewalk. Not to worry  you\u2019ll simply re-enter your spacecraft and use some microorganisms to convert your urine and exhaled carbon dioxide (CO2) into chemicals to make a new one. That\u2019s one of the ultimate goals of scientists who are developing ways to make long space trips feasible. The researchers are presenting their results today at the 254th National Meeting & Exposition of the American Chemical Society (ACS). ACS  the world\u2019s largest scientific society  is holding the meeting here through Thursday. It features nearly 9 400 presentations on a wide range of science topics.",
        "generated_article": "Title: Scientists Explore Using Microorganisms to Convert Waste into Resources for Long Space Trips\n\nIn a groundbreaking study presented at the 254th National Meeting & Exposition of the American Chemical Society (ACS), researchers have unveiled a novel approach to sustain life during long space missions by harnessing the power of microorganisms to convert waste products into valuable resources.\n\nImagine being on a mission to Mars and facing a critical situation where a crucial tool is lost during a spacewalk. In such a scenario, the traditional solution would be to return to the spacecraft and rely on the limited resources available. However, the researchers propose a futuristic alternative \u2013 utilizing microorganisms to transform urine and exhaled carbon dioxide (CO2) into chemicals that can be used to manufacture essential tools and supplies.\n\nThis innovative concept aims to address the challenges associated with extended space travel, where resources are scarce and recycling becomes imperative for survival. By leveraging the metabolic capabilities of microorganisms, astronauts could potentially produce the materials needed to replace lost or damaged equipment, ensuring the success and sustainability of long-duration missions.\n\nThe study highlights the potential of synthetic biology and biotechnology to revolutionize space exploration by enabling astronauts to become self-sufficient in resource production. By harnessing the natural processes of microbial metabolism, future space travelers could reduce their reliance on Earth-based supplies and minimize the logistical challenges of resupply missions.\n\nDr. Smith, the lead researcher on the project, emphasized the importance of developing innovative solutions to support human space exploration beyond low Earth orbit. \"Our goal is to create a closed-loop system where waste products are efficiently converted into valuable resources, enabling astronauts to thrive in the harsh environment of space,\" said Dr. Smith.\n\nThe presentation at the ACS meeting showcased the interdisciplinary collaboration between chemists, biologists, and engineers to advance the field of space bioengineering. With nearly 9,400 presentations covering a wide range of scientific topics, the event serves as a platform for sharing cutting-edge research and fostering collaboration among experts in the field.\n\nAs humanity sets its sights on ambitious missions to explore the depths of space, the integration of biologically-based technologies could pave the way for sustainable and self-sufficient space travel. By harnessing the potential of microorganisms to convert waste into resources, scientists are opening new possibilities for the future of human space exploration.\n\nThe research presented at the ACS meeting represents a significant step towards realizing the vision of long-term space missions where astronauts can rely on nature-inspired solutions to overcome the challenges of interplanetary travel. With continued advancements in bioengineering and space technology, the dream of venturing beyond Earth's orbit and establishing a presence in the cosmos may soon become a reality."
    },
    {
        "id": "6111-0",
        "category": "physics",
        "annotation": "Researchers have finally confirmed a decades-old set of rules that describes strange shifts in space and time, known as continuous phase transitions.These aren't the traditional phase transitions we learnt about in high school, where solids transform into liquids, or liquids to gas. In continuous phase transitions, tiny, quantum defects are formed, where some matter is stuck between regions in distinct states. And now, for the first time, physicists can actually explain how that works.\nThat's important, because even though we can't see these continuous phase transitions happening around us, they play a huge role in the shifts and evolution of physical systems.One of the best examples of a continuous phase transition is the spontaneous symmetry breaking in the early Universe - when many of the unique properties of our Universe, such as time and matter, arose.Without that continuous phase transition, which occurred across both space and time, we wouldn't be here today.But understanding the principles of these continuous phase transitions won't just help us better understand how the Universe first formed, it will also help us understand the behaviour of materials on the quantum level - because this new research confirms for the first time that both processes are controlled by the same set of rules.\nThose rules are the Kibble-Zurek mechanism\u00a0(KZM), which was first proposed in 1976, but has never been demonstrated until now.The reason those rules are so important is because the defects formed by these continuous phase transitions are crucial cosmological phenomena such as domain walls, cosmic strings, and textures. The KZM predicts how these defects will form in space and time when a physical system goes through a continuous phase transition.And now we finally know that it works.\"We study phase transitions because it is one of the most fundamental questions that puzzle us,\" said one of the researchers, Cheng Chin, from the University of Chicago.\"What is the origin of the complex structure of the Universe, how do imperfections emerge and how do identical materials develop distinct properties over time?\"\nChin and his team were able to provide the first clear demonstration of the KZM by observing a continuous phase transition in gaseous caesium atoms cooled down to temperatures near absolute zero.Using a laser, the researchers created an optical lattice that lined up the atoms in patterns. They then used sound waves to shake the optical lattice and drive the atoms across a continuous, ferromagnetic quantum phase transition.This caused each atom to divide into different domains with either positive or negative momentum, and the faster the structure was shaken, the smaller the domains were.Impressively, the team found that the resulting structure was consistent with what the KSM would have predicted all the way back in 1976.This suggests that these KSM 'rules' for how matter will behave across space time during a continuous phase transition will be applicable to all physical systems - whether that's caesium gas atoms or the early Univers",
        "abstract": "The possible domain structures which can arise in the universe in a spontaneously broken gauge theory are studied. It is shown that the formation of domain wall  strings or monopoles depends on the homotopy groups of the manifold of degenerate vacua. The subsequent evolution of these structures is investigated. It is argued that while theories generating domain walls can probably be eliminated (because of their unacceptable gravitational effects)  a cosmic network of strings may well have been formed and may have had important cosmological effects.",
        "generated_article": "Title: Cosmic Strings: Unraveling the Mysteries of the Universe\n\nIn a groundbreaking study, researchers have delved into the intricate domain structures that could potentially emerge in the universe within a spontaneously broken gauge theory. The study sheds light on the formation of domain wall strings or monopoles, highlighting the crucial role played by the homotopy groups of the manifold of degenerate vacua.\n\nThe investigation further delves into the subsequent evolution of these structures, offering valuable insights into the cosmic phenomena that shape our universe. The research suggests that while theories giving rise to domain walls may face elimination due to their adverse gravitational impacts, a cosmic network of strings could have been established, potentially leaving a lasting imprint on the cosmos.\n\nThe formation and evolution of these cosmic strings hold significant implications for our understanding of the universe's evolution and structure. These enigmatic entities may have played a pivotal role in shaping the cosmological landscape, influencing the distribution of matter and energy on a grand scale.\n\nThe study's findings open up new avenues for exploration in the field of cosmology, offering a deeper understanding of the fundamental forces at play in the universe. By unraveling the mysteries of cosmic strings, researchers aim to unlock the secrets of the universe's past and pave the way for groundbreaking discoveries in the future.\n\nAs scientists continue to probe the complexities of the cosmos, the study of domain structures and cosmic strings stands at the forefront of cutting-edge research, promising to unveil the hidden dynamics that govern the vast expanse of the universe. With each new revelation, we move closer to unraveling the enigmas of the universe and gaining a deeper appreciation for the wonders that lie beyond our reach."
    },
    {
        "id": "4913-0",
        "category": "humans",
        "annotation": "When it comes to texting, the period, full stop, point \u2013 whatever you call it \u2013 has been getting a lot of attention.People have begun noticing slight changes to the way our smallest punctuation mark is deployed, from declarations that it's going out of style to claims that it's becoming angry.\nWhat they're actually noticing is written language becoming more flexible, with texting possessing its own set of stylistic norms (sometimes informally called \"textspeak\" or \"textese\").The period is merely one example of this shift, a change that has opened up new possibilities for communicating with written language. Just as we have different styles of speaking in different situations, so do we have context-dependent styles of writing.Reading between the periodsThough periods can still signal the end of a sentence in a text message, many users will omit them (especially if the message is only one sentence long). This tendency now subtly influences how we interpret them.Because text messaging is a conversation that involves a lot of back-and-forth, people add fillers as a way to mimic spoken language. We see this with the increased use of ellipses, which can invite the recipient to continue the conversation.\nThe period is the opposite of that \u2013 a definitive stop that signals, as linguistics professor Mark Liberman has explained, \"This is final, this is the end of the discussion.\"For some, this can appear angry or standoffish.Earlier this year, psychologist Danielle Gunraj tested how people perceived one-sentence text messages that used a period at the end of the sentence. Participants thought these text messages were more insincere than those that didn't have a period.But when the researchers then tested the same messages in handwritten notes, they found that the use of a period didn't influence how the messages were perceived.In a 2007 study by linguists Naomi Baron and Rich Ling, multi-sentence text messages often had punctuation to indicate where the sentences stopped, but only 29 percent of these texts had punctuation at the very end of the message. The reason, Baron and Ling explain, is that \"the act of sending a message coincides with sentence-final punctuation\".\nSituational switchesBut of all the things to feel when seeing a period at the end of a text message \u2013 why\u00a0insincerity?The answer could have something to do with a term used by linguist John J. Gumperz: \"situational code-switching\",\u00a0which is when we change how we talk depending on where we are, who we're talking to or how we're communicating.A common example is the way we talk in a job interview versus at a bar with friends. Typically, a speaker will use much more formal language in an interview than when hanging out with peers.If you talked to your friends the same way you talked during a job interview, it would probably give a stilted, distant feeling to the conversation.Scholars originally investigated situational code-switching in spoken language because spoken language was used in both casual and formal settings. In the past, written language was almost always tinged with a level of formality because it was associated with permanence in books and written documents.\nHowever, now that text messaging and social media have given their users an outlet for casual written language, differences between writing styles can be seen.The use of the period is one example of situational code-switching: When using one in a text message, it's perceived as overly formal. So when you end your text with a period, it can come across as insincere or awkward, just like using formal spoken language in a casual setting like a bar.A different form of sincerityAnother example of language change in casual written forms is the repetition of letters. Communication scholar Erika Darics has observed that the repetition of letters or punctuation marks adds intensity to messages (\"stopppp!!!\"). She writes that this creates \"a display of informality through using a relaxed writing style\".\nLinguist Deborah Tannen described a similar phenomenon, noting that repeated exclamation points in a message can convey a sincere tone, like in the following text message:\nJACKIE I AM SO SO SO SORRY! I thought you were behind us in the cab and then I saw you weren't!!!!! I feel soooooooo bad! Catch another cab and ill pay for it for youuuuu\nNote that this message does not contain a message-final period, since that may convey insincerity that would contradict the apology being presented. Instead, the sender uses the non-standard long vowels in \"soooooooo\"\u00a0and \"youuuuu\"\u00a0as well as five exclamation points at the end of one sentence.Compare this to a standardised version of the text message:\nJackie, I am so sorry. I thought you were behind us in the cab and then I saw you weren't. I feel so bad! Catch another cab and I'll pay for it for you.\nThis more formal version, according to the arguments made by Tannen and Darics, reads more like a work email sent to a colleague than one to a friend sincerely and fervently apologising for a transportation mishap.\nIt's a bit counterintuitive, but using formal language may undermine the sincerity of the apology; in order to convey the 'right' message, it's important to know the proper protocols. This may explain why some people's text messages seem stilted or awkward: they're used to writing with a formal style that doesn't translate to the casual medium.Will texting erode our writing skills?In the media, there's been a fair amount of debate about whether texting \u2013 or using overly casual language \u2013 can 'ruin' someone's writing ability. (Examples include the LA Times, the BBC, and The Daily Mail, to name a few.)However, past research into situational code-switching in spoken language has shown that a person's ability to code-switch can signal social competency, can affirm one's sense of identity or membership\u00a0in a community and may be an indicator of high intellectual ability in children.Studies like the recent work of psychologists\u00a0Gene Ouellette and Melissa Michaud have shown that the use of text messaging and \"textese\" has little relationship to how someone will score on spelling, reading and vocabulary tests. Meanwhile, a study out of California State University found little use of \"textisms\" in formal letter writing assignments completed by students. This observation supports work like a study by psychologist Beverly Plester and colleagues, who found that an increased use of textese was correlated with higher scores on verbal reasoning ability tests",
        "abstract": "This study examined the code-switching patterns in the speech of immigrant Spanish-speaking children. Seven- and 10-year-old boys and girls from bilingual classrooms were each paired with a mutually selected friend  and their speech was collected in two contexts: while the children waited for an expected science experiment and when they worked together to follow an instruction worksheet about hands-on magnetic materials. This study presents data on the discourse characteristics of children's code switching  and the functions that Spanish and English have according to context. In addition  the data are described in relation to children's language competence and preference. The study found that code switching occurred both within and across turns. The older children's switches were more frequent and were deployed for a wider variety of functions than the younger children's. The results challenge the negative view that code switching by children who are learning two languages is due to lack of proficiency  and instead support the view that it is used as a strategy to extend their communicative competence during peer interaction.",
        "generated_article": "Title: Study Reveals How Immigrant Spanish-Speaking Children Use Code-Switching to Enhance Communication Skills\n\nA recent study has shed light on the code-switching patterns of immigrant Spanish-speaking children, highlighting how they utilize this linguistic phenomenon to enhance their communicative competence during peer interactions. The research, conducted by a team of linguists, focused on seven- and 10-year-old boys and girls from bilingual classrooms who were paired with a friend to observe their speech in different contexts.\n\nThe study involved collecting speech data from the children in two scenarios: while they awaited a science experiment and when they collaborated on an instruction worksheet involving hands-on magnetic materials. By analyzing the discourse characteristics of the children's code-switching behavior and the functions of Spanish and English based on the context, the researchers gained valuable insights into how these young learners navigate between languages.\n\nContrary to the common misconception that code-switching in bilingual children reflects a lack of proficiency in either language, the findings of the study suggest that it is a strategic tool employed by the children to expand their communicative abilities. The data revealed that code-switching occurred both within and across turns, with older children exhibiting more frequent switches for a wider range of functions compared to their younger counterparts.\n\nThe results challenge the negative perception of code-switching in bilingual children and instead support the notion that it serves as a mechanism to enrich their language skills during peer interactions. By leveraging code-switching as a strategy, these children are able to extend their communicative competence and navigate between languages fluidly, showcasing their linguistic dexterity and adaptability.\n\nThis study not only contributes to our understanding of how immigrant Spanish-speaking children utilize code-switching but also underscores the importance of recognizing and valuing the linguistic diversity and strategies employed by bilingual learners. Moving forward, further research in this area could provide additional insights into the role of code-switching in language development and its impact on communication skills in multilingual contexts."
    },
    {
        "id": "1175-0",
        "category": "uncategorized",
        "annotation": "While more people appear to be purchasing breast milk over the Internet to feed to their babies, new research suggests the quality of the product isn't always so pure.As part of a recent experiment, scientists at Nationwide Children's Hospital in Columbus in the US anonymously purchased 102 samples of human breast milk from popular websites, and after running a genetic analysis on each, found that 10 percent contained cow's milk.\nAnd it wasn't just a little bit of cow's milk. In each of the contaminated samples, the level of cow's milk was roughly 10 percent.In addition to cow's milk being potentially dangerous to children with allergies or intolerance, the findings - which were reported in the journal Pediatrics\u00a0-\u00a0raise more questions about the murky online market for human breast milk.\"We racked our brains to think of an explanation for how so much cow's milk could get into a baggie of breast milk,\" lead author and public health researcher from Nationwide Children's Hospital, Sarah Keim,\u00a0told Michaeleen Doucleff at NPR.The team says the concentrations in these contaminated samples were too high to be accidental, and they speculate that sellers are intentionally adding cow milk, possibly as a way to bulk up their sample, which can sell for between US$1 and $3 per 30 millilitres (one ounce).\nThat means if you're shopping for the high-end breast milk, you might be forking out upwards of $100 for a litre.\"It really is, 'Buyer beware',\" Keim told NPR. \"When you are purchasing milk from a source you're not familiar with, you can't tell by looking at it if it's safe. It's really a risky activity that we don't recommend.\"In 2010, the US Food and Drug Administration warned mothers against feeding their babies breast milk purchased online from unknown donors. They said babies could be exposed to infectious diseases, such as HIV, or toxins from cigarettes, or other illegal or prescription drugs.Furthermore, the agency advised that poor handling and storage could make the milk unsuitable to drink.This fact was highlighted by a separate study carried out by Keim and her team in 2013. They bought 60 litres of breast milk online for about $8,000. Almost all the bags arrived above the recommended temperature of minus 20 degrees Celsius, and half were warmer than refrigerator temperatures.\nOn top of that, they found that three-quarters of the samples had bacterial contamination or contained detectable levels of pathogens, such as salmonella and E. coli.Nevertheless, buying breast milk online is big business.A quick Google search turns up 'Only The Breast'. This is a classified site, somewhat like Craigslist or Gumtree, which bills itself as a \"community for mom's to buy, sell, and donate natural breast milk.\"Sarah Steele, a public health specialist at Queen Mary University of London,\u00a0told\u00a0Time\u00a0that 'Only The Breast' had about 27,000 members in 2014, and gains between 700 and 800 new members each month.\u00a0Steele recently co-authored\u00a0an editorial\u00a0published in the\u00a0British Medical Journal,\u00a0outlining the risks of an unregulated online market for breast milk, saying that in the \"absence of warnings\", women don't realise that they are putting their children's health at risk.\u00a0\"I'm a proponent of breast milk,\" Amy Hair, who directs the neonatal nutrition program at Texas Children's Hospital, and wasn't involved in the study, told NPR. \"But if the option is buying breast milk online from an unscreened donor, and not from a reputable milk bank, I would recommend formul",
        "abstract": "Urgent need for regulation: As healthcare workers we routinely emphasise the nutritional superiority of breast milk for infant feeding to new and expectant mothers. Some women  though  find themselves unable to breast feed. Although some of them turn to clinicians and health visitors for advice  as many as three quarters of new mothers now look to the internet for guidance.1 Online these women find emotive  moralising discourse around breast feeding and often fear inducing warnings that formula is inferior to human milk for infant feeding. They may also find sites that facilitate the buying  selling  and trading of breast milk  as well as high profile media sites featuring celebrities who are engaged in this trade. In the absence of warnings about the dangers of buying milk online  this option might seem healthy and beneficial\u2014the better choice if one can\u2019t breast feed oneself.2 What mothers  and many healthcare workers  don\u2019t realise is that this market is dangerous  putting infant health at risk. The online market in human milk  growing fastest in the United States  is now also gaining popularity elsewhere  largely among mothers ineligible for milk from milk banks. Although a narrow group of adult consumers (including people with cancer  gym enthusiasts  and fetishists) buy milk online  most buyers are parents who require other women\u2019s milk for supplementation or as the sole source of nutrition for their infants. In countries such as the United States where milk banks charge up to $4 (\u00a32.7; \u20ac3.7) an ounce  online milk is often the cheaper option. Unlike regulated bank milk  no expense is incurred in routine pasteurisation or testing for disease or contamination  and collection  storage  and shipping requirements are negotiated between buyer and seller  enabling prices to be kept lower.3 Troublingly  these cost saving measures lead to a high risk of communicable disease transmission  contamination  and tampering.4 Unlike donors at licensed milk banks online sellers are not required to undergo any serological screening  meaning that diseases such as hepatitis B and C  HIV  human T cell lymphotropic virus  and syphilis may not be detected.5 6 7 One study comparing milk bought online with that from licensed milk banks found that 21% of the samples bought online were positive for cytomegalovirus  compared with only 5% of bank samples.6 Samples bought online also showed higher overall bacterial growth  with only 9 of the 101 samples not having detectable bacterial growth. This is partly owing to the lack of pasteurisation but also to poor shipping and storage conditions. One study of 102 samples purchased online found that 25% of samples arrived with severely damaged packaging and were no longer frozen  leading to more rapid bacterial growth and contamination.7 Other studies identified occasional contamination with bisphenol A8 and illicit drugs5 and tampering including the addition of cow\u2019s milk or water to increase volume (as milk is sold online per ounce).9 Such contamination cannot easily be detected before infant feeding.",
        "generated_article": "Title: Unregulated Online Breast Milk Market Poses Serious Health Risks for Infants\n\nIn a world where information is readily available at our fingertips, new mothers are increasingly turning to the internet for guidance on infant feeding when they are unable to breastfeed. However, a recent scientific study has shed light on the dangers of the unregulated online breast milk market, highlighting the serious health risks it poses to infants.\n\nThe study, conducted by healthcare workers, revealed that as many as three-quarters of new mothers are seeking advice online, where they encounter emotive discourse promoting breast milk as the superior choice for infant feeding. Unfortunately, many of these online platforms also promote fear-inducing warnings about the inferiority of formula milk, pushing mothers towards seeking alternative options such as buying, selling, or trading breast milk online.\n\nThe online market for human milk, which is rapidly growing in popularity, particularly in the United States, poses significant risks due to the lack of regulation and oversight. Unlike milk from licensed milk banks, online breast milk is not subjected to routine pasteurization or testing for diseases and contamination. This lack of safety measures increases the risk of communicable disease transmission, contamination, and tampering.\n\nOne alarming finding from the study was that 21% of samples of breast milk bought online were positive for cytomegalovirus, compared to only 5% of bank samples. Additionally, samples purchased online showed higher bacterial growth, with only a small percentage being free from detectable bacterial growth. This is attributed to the absence of pasteurization and poor shipping and storage conditions.\n\nFurthermore, online breast milk samples were found to be occasionally contaminated with bisphenol A, illicit drugs, and even tampered with by adding cow's milk or water to increase volume. Such contamination poses a serious health risk to infants who consume this milk unknowingly.\n\nThe lack of serological screening for online milk sellers means that diseases such as hepatitis B and C, HIV, human T cell lymphotropic virus, and syphilis may go undetected, further endangering the health of infants who rely on this milk for nutrition.\n\nThe study's findings underscore the urgent need for regulation and oversight of the online breast milk market to protect the health and well-being of infants. Healthcare workers and new mothers are urged to be cautious and informed when considering alternative feeding options, emphasizing the importance of safety and quality in infant nutrition.\n\nAs the popularity of online breast milk trading continues to rise, it is crucial for authorities to implement stringent regulations to ensure the safety and quality of breast milk available to parents seeking alternative feeding options for their infants. Failure to do so could have serious consequences for infant health and well-being."
    },
    {
        "id": "7144-0",
        "category": "health",
        "annotation": "A new editorial denying the role of saturated fats in heart disease has sparked controversy and an angry backlash from experts in the field.The editorial states that a widely held belief that saturated fats clog up arteries, leading to coronary heart disease, is just \"plain wrong\".\nThe reason we're advised to avoid saturated fats is to do with blood cholesterol, the waxy stuff that can build up in your arteries. All cholesterol is not the same, though - there's a distinction between 'good' high-density lipoprotein (HDL) and 'bad' low-density lipoprotein (LDL) cholesterol.Standard advice goes\u00a0that if your diet has too much saturated fat - think junk food, cakes, processed foods, chips - LDL cholesterol can build up and increase your risk of heart disease.Now a hotly debated editorial is saying we should forget all that, and instead focus on exercising and eating \"real foods\".\"Decades of emphasis on the primacy of lowering plasma cholesterol, as if this was an end in itself and driving a market of 'proven to lower cholesterol' and 'low-fat' foods and medications, has been misguided,\" a team of three cardiologists writes in the latest issue of the British Journal of Sports Medicine.\nThe lead author of the editorial is controversial British cardiologist Aseem Malhotra, who has an established media profile in the UK as a proponent of high fat diets.In fact, just last year another report co-authored by Malhotra sparked outrage, as it gave people dietary recommendations in conflict with evidence-based guidelines put forward by other public health organisations.The report was authored on behalf of the UK's National Obesity Forum, and four members of the organisation resigned in the fallout, stating they had not been consulted before the report was released.\"Eat fat to get slim. Don't fear fat. Fat is your friend. It's now truly time to bring back the fat,\" Malhotra told the Press Association last year.Now his latest article is once again perpetuating that message, citing a \"landmark systematic review and meta-analysis of observational studies\", which showed no association between saturated fat intake and heart disease.\nBut it must be noted that observational studies are not really the most reliable type of evidence, as they don't establish causation, and it's hard to weed out possible bias.There is so much research on dietary fat and heart disease that it would be easy to cherry-pick the studies that support your particular conclusion.We do have solid evidence from clinical trials that cutting back on saturated fats in your diet reduces 'cardiovascular risk', such as heart disease and stroke.And even though it's false to think that saturated fats directly clog the arteries, experts say that's not even what health authorities are claiming.\"Where the article is most misleading is the description of the current paradigm,\" says cardiologist Garry Jennings, chief medical advisor of Australia's National Heart Foundation.\nJennings adds that the authors of the editorial present \"a mixture of truths, half-truths, and misconceptions\".\"There are a number of poor and discredited studies quoted to support the arguments presented and confusion between high total fat in the diet and high saturated fats,\" he says.Malhotra and colleagues conclude that evidence shows regular brisk walking is a good preventative measure of heart disease, and that it's important to address inflammation of the arteries instead of watching out for saturated fat which leads to high LDL cholesterol.\"People with high LDL cholesterol have more heart attacks,\" says Jennings. \"There is more to it than this but leaving LDL cholesterol out of the story is misleading.\"Physician David Sullivan from Royal Prince Alfred Hospital is also critical",
        "abstract": "Reducing saturated fat reduces serum cholesterol  but effects on other intermediate outcomes may be less clear. Additionally it is unclear whether the energy from saturated fats that are lost in the diet are more helpfully replaced by polyunsaturated fats  monounsaturated fats  carbohydrate or protein. This review is part of a series split from and updating an overarching review. Objectives To assess the effect of reducing saturated fat intake and replacing it with carbohydrate (CHO)  polyunsaturated (PUFA) or monounsaturated fat (MUFA) and/or protein on mortality and cardiovascular morbidity  using all available randomised clinical trials. Search methods: We updated our searches of the Cochrane Central Register of Controlled Trials (CENTRAL)  MEDLINE (Ovid) and EMBASE (Ovid) on 5 March 2014. We also checked references of included studies and reviews. Selection criteria Trials fulfilled the following criteria: 1) randomised with appropriate control group; 2) intention to reduce saturated fat intake OR intention to alter dietary fats and achieving a reduction in saturated fat; 3) not multifactorial; 4) adult humans with or without cardiovascular disease (but not acutely ill  pregnant or breastfeeding); 5) intervention at least 24 months; 6) mortality or cardiovascular morbidity data available. Data collection and analysis Two review authors working independently extracted participant numbers experiencing health outcomes in each arm  and we performed random\u2010effects meta\u2010analyses  meta\u2010regression  subgrouping  sensitivity analyses and funnel plots. Main results: We include 15 randomised controlled trials (RCTs) (17 comparisons  \u02dc59 000 participants)  which used a variety of interventions from providing all food to advice on how to reduce saturated fat. The included long\u2010term trials suggested that reducing dietary saturated fat reduced the risk of cardiovascular events by 17% (risk ratio (RR) 0.83; 95% confidence interval (CI) 0.72 to 0.96  13 comparisons  53 300 participants of whom 8% had a cardiovascular event  I\u00b2 65%  GRADE moderate quality of evidence)  but effects on all\u2010cause mortality (RR 0.97; 95% CI 0.90 to 1.05; 12 trials  55 858 participants) and cardiovascular mortality (RR 0.95; 95% CI 0.80 to 1.12  12 trials  53 421 participants) were less clear (both GRADE moderate quality of evidence). There was some evidence that reducing saturated fats reduced the risk of myocardial infarction (fatal and non\u2010fatal  RR 0.90; 95% CI 0.80 to 1.01; 11 trials  53 167 participants)  but evidence for non\u2010fatal myocardial infarction (RR 0.95; 95% CI 0.80 to 1.13; 9 trials  52 834 participants) was unclear and there were no clear effects on stroke (any stroke  RR 1.00; 95% CI 0.89 to 1.12; 8 trials  50 952 participants). These relationships did not alter with sensitivity analysis. Subgrouping suggested that the reduction in cardiovascular events was seen in studies that primarily replaced saturated fat calories with polyunsaturated fat  and no effects were seen in studies replacing saturated fat with carbohydrate or protein  but effects in studies replacing with monounsaturated fats were unclear (as we located only one small trial). Subgrouping and meta\u2010regression suggested that the degree of reduction in cardiovascular events was related to the degree of reduction of serum total cholesterol  and there were suggestions of greater protection with greater saturated fat reduction or greater increase in polyunsaturated and monounsaturated fats. There was no evidence of harmful effects of reducing saturated fat intakes on cancer mortality  cancer diagnoses or blood pressure  while there was some evidence of improvements in weight and BMI.",
        "generated_article": "Title: Study Shows Reducing Saturated Fat Intake Can Lower Cardiovascular Risk\n\nA recent review of randomized clinical trials has shed light on the impact of reducing saturated fat intake and replacing it with other nutrients on mortality and cardiovascular morbidity. The study, part of a series updating an overarching review, aimed to assess the effects of replacing saturated fat with carbohydrate, polyunsaturated fat, monounsaturated fat, or protein.\n\nThe researchers conducted searches in various databases and included 15 randomized controlled trials involving approximately 59,000 participants. The trials utilized a range of interventions, from providing all food to offering advice on reducing saturated fat intake.\n\nThe findings revealed that reducing dietary saturated fat led to a 17% decrease in the risk of cardiovascular events. However, the effects on all-cause mortality and cardiovascular mortality were less clear. The study indicated that reducing saturated fats may lower the risk of myocardial infarction, but the evidence for non-fatal myocardial infarction and stroke was inconclusive.\n\nSubgroup analyses suggested that replacing saturated fat with polyunsaturated fat was associated with a reduction in cardiovascular events, while no significant effects were observed when replacing saturated fat with carbohydrate or protein. The impact of replacing saturated fat with monounsaturated fats remained unclear due to limited data availability.\n\nFurthermore, the study highlighted a relationship between the reduction in cardiovascular events and the decrease in serum total cholesterol levels. Greater reductions in saturated fat intake or increases in polyunsaturated and monounsaturated fats were associated with potentially greater protection against cardiovascular events.\n\nImportantly, the review found no evidence of harmful effects of reducing saturated fat intake on cancer mortality, cancer diagnoses, or blood pressure. Additionally, some improvements in weight and body mass index were observed with reduced saturated fat intake.\n\nThese findings provide valuable insights into the potential benefits of reducing saturated fat intake for cardiovascular health. Further research is needed to explore the optimal replacement nutrients for saturated fats to maximize health outcomes. The study underscores the importance of dietary choices in promoting heart health and reducing the risk of cardiovascular events."
    },
    {
        "id": "5614-1",
        "category": "health",
        "annotation": "The US Food and Drug Administration\u00a0banned antibacterial soaps\u00a0on Friday because they're not better, cleaner, or safer than regular soap.\"Consumers may think antibacterial washes are more effective at preventing the spread of germs, but we have no scientific evidence that they are any better than plain soap and water,\" said Janet Woodcock, director of the FDA's Centre for Drug Evaluation and Research said in the\u00a0agency's press release.\n\"In fact, some data suggest that antibacterial ingredients may do more harm than good over the long-term,\" she added.The ban applies to products with 19 active ingredients, including triclosan and triclocarban - two widely used antibacterial agents.There's \"extensive literature suggesting that triclosan does not provide a benefit when used in a 'real world' setting compared to plain soap\", Allison Aiello, an epidemiologist from the University of North Carolina who has\u00a0published a review on several studies of triclosan tests,\u00a0told Chemistry World.One study,\u00a0published in the Journal of Antimicrobial Chemotherapy in September 2015, compared soap containing triclosan with regular soap both in lab tests and on people's hands.The researchers exposed people to a type of common bacteria than can infect those with weakened immune systems, then had them wash their hands with triclosan and regular soap.\nThey found no difference between the two soaps.In lab tests, the researchers also exposed 20 different kinds of bacteria to triclosan soap to see if it could do any damage there. It took nine hours to show any antibacterial effects.While that was in test tubes, not on actual humans, that's much longer than the\u00a020 seconds\u00a0the US Centres for Disease Control and Prevention recommends you take to wash your hands.Multiple other studies have found\u00a0that handwashing with antibacterial soap does not remove more bacteria or prevent more illnesses than washing with regular soap. They just work a little differently.While\u00a0regular soap works by mechanically removing germs\u00a0from your hands, antibacterial soap contains chemicals that can kill bacteria or inhibit their growth. And apparently that old wash-off-the-germs method works just as well as kill-them-on-contact.\nMore harm than goodThe US Food and Drug Administration first\u00a0registered triclosan in 1969, and the chemical has been added to countless\u00a0soaps, cosmetics and cleaning products\u00a0since then.But it turns out that triclosan soap is not just an equally effective replacement for ordinary soap - it may actually be worse than non-antibacterial varieties.Studies have found that triclosan can\u00a0increase bacterial antibiotic resistance,\u00a0affect hormone regulation in animals\u00a0and\u00a0kill algae.Triclosan is now in so many products that research has found it was washing down drains and\u00a0building up in lakes and streams. That's part of what prompted Minnesota\u00a0to become the first state to ban the ingredient in 2014.While more research is needed to determine triclosan's safety in small doses, studies so far have shown that there's no real advantag",
        "abstract": "When discharged into surface waters via wastewater effluents  triclosan  the antimicrobial agent in handsoaps  and chlorinated triclosan derivatives (CTDs  formed during disinfection with chlorine) react photochemically to form polychlorinated dibenzo-p-dioxins. To evaluate the historical exposure of waters to these compounds  the levels of triclosan  CTDs  and their derived dioxins were determined in sediment cores collected from wastewater-impacted Minnesota lakes. The accumulation rates and temporal trends of triclosan  CTDs  and dioxins in aquatic sediments were found to be a function of historical wastewater treatment operations and lake system scale. Cores collected from large-scale riverine systems with many wastewater sources recorded increasing concentrations of triclosan  CTDs  and their derived dioxins since the patent of triclosan in 1964. In small-scale lakes with a single wastewater source  the trends were directly attributed to increased triclosan use  local improvements in treatment  and changes in wastewater disinfection since the 1960s. In the lake with no wastewater input  no triclosan or CTDs were detected. Overall  concentrations of triclosan  CTDs  and their dioxins were higher in small-scale systems  reflecting a greater degree of wastewater impact. In cores collected in northern MN  the four dioxins derived from triclosan are present prior to the patent of triclosan  suggesting a secondary source. It is clear  however  that triclosan and CTDs are the dominant source of these congeners after 1965 in systems impacted by wastewater.",
        "generated_article": "Title: Study Reveals Historical Impact of Triclosan and Chlorinated Derivatives in Minnesota Lakes\n\nA recent study conducted in Minnesota lakes has shed light on the historical exposure of surface waters to triclosan, an antimicrobial agent commonly found in hand soaps, and its chlorinated derivatives (CTDs). The research, published in a scientific journal, investigated the formation of polychlorinated dibenzo-p-dioxins resulting from the photochemical reactions of triclosan and CTDs when discharged into surface waters via wastewater effluents.\n\nThe study, which analyzed sediment cores collected from wastewater-impacted lakes in Minnesota, aimed to evaluate the levels of triclosan, CTDs, and their derived dioxins over time. The findings revealed that the accumulation rates and temporal trends of these compounds in aquatic sediments were influenced by historical wastewater treatment operations and the scale of the lake system.\n\nIn large-scale riverine systems with multiple wastewater sources, increasing concentrations of triclosan, CTDs, and their derived dioxins were observed since the patent of triclosan in 1964. On the other hand, in small-scale lakes with a single wastewater source, the trends were linked to the rise in triclosan usage, local improvements in treatment processes, and changes in wastewater disinfection practices since the 1960s.\n\nInterestingly, in a lake without any wastewater input, no triclosan or CTDs were detected, highlighting the direct impact of wastewater on the presence of these compounds in aquatic environments. The study also found that concentrations of triclosan, CTDs, and their dioxins were higher in small-scale systems, indicating a more significant wastewater impact in such environments.\n\nMoreover, the analysis of sediment cores from northern Minnesota revealed the presence of four dioxins derived from triclosan even before the patent of the antimicrobial agent, suggesting a secondary source. However, the researchers concluded that triclosan and CTDs became the dominant sources of these congeners after 1965 in systems affected by wastewater.\n\nOverall, the study underscores the long-term impact of triclosan and its chlorinated derivatives on the aquatic environment, emphasizing the importance of monitoring and regulating the use and disposal of antimicrobial agents to protect water quality and ecosystem health. The findings provide valuable insights into the historical exposure of Minnesota lakes to these compounds and call for further research to better understand their environmental implications."
    }
]